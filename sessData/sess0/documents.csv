index,pdf_file,text,topics,year,author,clusterID,citations,type,abstract,globalID,tags,user,words,pages,citationsList,versions,url,notes,title,parent_item,organization,citationArticles
HDQVL9W2,UYMW6IC5,"Semantic Interaction for Visual Text Analytics 
Chris North 
Alex Endert 
Virginia Tech 
Virginia Tech 

Patrick Fiaux 
Virginia Tech 

Blacksburg, VA USA 

aendert@vt.edu 

Blacksburg, VA USA 

pfiaux@vt.edu 

 

Blacksburg, VA USA 

north@vt.edu 

by 

For 

through 

ABSTRACT 
Visual analytics emphasizes sensemaking of large, complex 
datasets 
interactively  exploring  visualizations 
generated 
example, 
statistical  models. 
dimensionality  reduction  methods  use  various  similarity 
metrics to visualize textual document collections in a spatial 
metaphor,  where  similarities  between  documents  are 
approximately  represented  through  their  relative  spatial 
distances  to  each  other  in  a  2D  layout.  This  metaphor  is 
designed to mimic analysts’ mental models of the document 
collection  and  support  their  analytic  processes,  such  as 
clustering similar documents together. However, in current 
methods, users must interact with such visualizations using 
controls  external  to  the  visual  metaphor,  such  as  sliders, 
menus, or text fields, to directly control underlying model 
parameters  that  they  do  not  understand  and  that  do  not 
relate  to  their  analytic  process  occurring  within  the  visual 
metaphor.  In  this  paper,  we  present  the  opportunity  for  a 
new  design  space  for  visual  analytic  interaction,  called 
semantic  interaction,  which  seeks  to  enable  analysts  to 
spatially interact with such models directly within the visual 
metaphor using interactions that derive from their analytic 
process,  such  as  searching,  highlighting,  annotating,  and 
repositioning  documents.  Further,  we  demonstrate  how 
semantic  interactions  can  be  implemented  using  machine 
learning 
tool,  called 
ForceSPIRE, for interactive analysis of textual data within 
a  spatial  visualization.    Analysts  can  express  their  expert 
domain knowledge about the documents by simply moving 
them,  which  guides  the  underlying  model  to  improve  the 
overall layout, taking the user’s feedback into account. 
Author Keywords 
Visualization; visual analytics; interaction 
ACM Classification Keywords 
H5.m.  Information  interfaces  and  presentation  (e.g.,  HCI): 
Miscellaneous.  
General Terms 
Design; Human Factors; Theory 

in  a  visual  analytic 

techniques 

 
Permission to  make digital or hard copies of all or part of this work for 
personal or classroom use is granted without fee provided that copies are 
not made or distributed for profit or commercial advantage and that copies 
bear this notice and the full citation on the first page. To copy otherwise, 
or  republish,  to  post  on  servers  or  to  redistribute  to  lists,  requires  prior 
specific permission and/or a fee. 
CHI’12, May 5–10, 2012, Austin, Texas, USA. 
Copyright 2012 ACM 978-1-4503-1015-4/12/05...$10.00. 
 

 

INTRODUCTION 
Visual analytics bases its success on combining the abilities 
of statistical models, visualization, and human intuition for 
users to gain insight into large, complex datasets [23]. This 
success often hinges on the ability for users to interact with 
the  information,  manipulating  the  visualization  based  on 
their  domain  expertise,  interactively  exploring  possible 
connections, and investigating hypotheses. It is through this 
interactive exploration that users are able to make sense of 
complex  datasets,  a  process  referred  to  as  sensemaking 
[19].  
The  two  primary  parts  of  sensemaking  are  foraging  and 
synthesis. Foraging refers to the stages of the process where 
users filter and gather collections of interesting or relevant 
information.  Then,  using  that  information,  users  advance 
through  the  synthesis  stages  of  the  process,  where  they 
construct  and  test  hypotheses  about  how  the  foraged 
information  may  relate  to  the  larger  plot.  Tools  exist  that 
support users for either foraging or synthesis – but not both. 
In  this  paper  we  present  semantic  interaction,  combining 
the  foraging  abilities  of  statistical  models  with  the  spatial 
synthesis abilities of analysts. Semantic interaction is based 
on the following principles: 
1. Visual  “near=similar”  metaphor  supports  analysts’ 
spatial  cognition,  and  is  generated  by  statistical  models 
and similarity metrics. [22] 

2. Use  semantic  interactions  within  the  visual  metaphor, 
based  on  common  interactions  occurring  in  spatial 
analytic  processes  [4]  such  as  searching,  highlighting, 
annotating, and repositioning documents.  

3. Interpret  and  map  the  semantic  interactions  to  the 
underlying parameters of the model, by updating weights 
and adding information. 

4. Shield  the  users  from  the  complexity  of  the  underlying 

mathematical models and parameters. 

5. Models  learn  incrementally  by  taking  into  account 
interaction during the entire analytic process, supporting 
analysts’ process of incremental formalism [10]. 

6. Provide  visual  feedback  of  the  updated  model  and 

learned parameters within the visual metaphor. 

7. Reuse  learned  model  parameters  in  future  or  streaming 

data within the visual metaphor. 

To  demonstrate  the  concept  of  semantic  interaction,  we 
present  a  prototype  visual  analytics  tool,  ForceSPIRE,  for 
spatial analysis of textual information. In ForceSPIRE, the 
user  interaction  takes on  a deeper,  more  integrated role in 

the  exploratory  spatial  analytic  process.  This  is  done 
through capturing the semantic interaction, interpreting the 
analytical  reasoning  associated  with  the  interaction,  and 
updating the statistical model, and ultimately updating the 
spatialization.  Hence,  users  are  able  to  leverage  semantic 
interaction  to  explore  and  analyze  the  data  interactively, 
while  the  system  is  responsible  for  properly  updating  the 
underlying statistical model.  
RELATED WORK 
Foraging Tools 

 

Figure  1.  A  model  of  interaction  with  foraging  tools.  Users 
interact  directly  with  the  statistical  model  (red),  then  gain 
insight  through  observing  the  change  in  the  visualization 
(blue). 
We  categorize  foraging  tools  by  their  ability  to  pass  data 
through  complex  statistical  models  and  visualize  the 
computed structure of the dataset for the user to gain insight 
(Figure  1).  Thus,  users  interact  with  these  tools  primarily 
through directly manipulating the parameters of the model 
used  for  computing  the  structure.  As  such,  users  are 
required  to  translate  their  domain  expertise  and  semantics 
about  the  information  to  determine  which  (and  by  how 
much) to adjust these parameters. The following examples 
further describe this category of tools. 
Visualizations such as IN-SPIRE’s “Galaxy View” (shown 
in  Figure  3)  present  users  with  a  spatial  layout  of  textual 
information where similar documents are proximally close 
to  one  another  [25].  An  algorithm  creates  the  layout  by 
mapping the high-dimensional collection of text documents 
down  to  a  two-dimensional  view.  In  these  spatializations, 
the  spatial  metaphor  is  one  from  which  users  can  infer 
meaning  of  the  documents  based  on  their  location.  The 
notion  of  distance  between  documents  represents  how 
similar the two documents are (i.e., more similar documents 
are  placed  closer  together).  For  instance,  a  cluster  of 
documents  represents  a  group  of  similar  documents,  and 
documents  placed  between  two  clusters  implies  those 
documents are connected to both clusters. These views are 
beneficial  as  they  allow  users  to  visually  gain  a  quick 
overview  of  the  information,  such  as  what  key  themes  or 
groups  exist  within  the  dataset.  The  complex  statistical 
models  that  compute  similarity  between  documents  are 
based on the structure within the data, such as term or entity 
frequency. In order to interactively change the view, users 
are  required  to  directly  adjust  keyword  weights,  add  or 
remove documents/keywords, or provide more information 
on how to parse the documents for keywords/entities upon 
import. 

 

to  a 

to  understand 

the 

[15].  Through  adjusting 

Similarly, an interactive visualization tool called iPCA uses 
Principal  Component  Analysis  (PCA)  to  reduce  high-
dimensional  data  down 
two-dimensional  plot, 
providing  users  with  sliders  and  other  visual  controls  for 
directly  adjusting  numerous  parameters  of  the  algorithm, 
such  as  individual  eigenvalues,  eigenvectors,  and  other 
components  of  PCA 
the 
parameters,  the  user  can  observe  how  the  visualization 
changes.  This  allows  users  to  gain  insight  into  a  dataset, 
given  they  have  a  thorough  understanding  of  PCA, 
necessary 
the 
changes they are making to the model parameters. 
Alsakran  et  al.  presented  a  visualization 
system, 
STREAMIT,  capable  of  spatially  arranging  text  streams 
based  on  keyword  similarity  [3].  Again,  users  can 
interactively  explore  and  adjust  the  spatial  layout  through 
directly  changing  the  weight  of  keywords  that  they  find 
important.  In  addition,  STREAMIT  allows  for  users  to 
conduct  a  temporal  investigation  of  how  clusters  change 
over time. 
Synthesis Tools 

implications  behind 

 

Figure  2.  A  model  of  interaction  with  synthesis  tools.  Users 
manually  create  a  spatial  layout  of  the  information  to 
maintain and organize their insights about the data. 
Synthesis  tools  focus  on  allowing  users  to  organize  and 
maintain their hypotheses and insight regarding the data in 
a  spatial  medium.  In  large  part,  this  is  done  through 
presenting users with a flexible spatial workspace in which 
they  can  organize  information  through  creating  spatial 
structures,  such  as  clusters,  timelines,  stories,  etc.  (Figure 
2). In doing so, users externalize their thought processes (as 
well  as  their  insights)  into  a  spatial  layout  of  the 
information. 
For example, Analyst’s Notebook [2] provides users with a 
spatial workspace where information can be organized, and 
connections  between  specific  pieces  of  information  (e.g., 
entities, documents, events, etc.) can be created. Similarly, 
The Sandbox [26] enables users to create a series of cases 
(collections  of 
information)  which  can  be  organized 
spatially within the workspace.  
From  previous  studies,  we  found  cognitive  advantages 
associated  with  the  manual  creation  of  a  spatial  layout  of 
the  information  [4].  By  providing  users  a  workspace  in 
which  to  manually  create  spatial  representations  of  the 
information, users were able to externalize their semantics 
of the information into the workspace. That is, they created 
spatial  structures  (e.g.,  clusters,  timelines,  etc.),  and  both 
the structures as well as the locations relative to remaining 
layout  carried  meaning  to  the  users  with  regards  to  their 
sensemaking process. Marshall et al. have pointed out that 

this 

interaction  (and 

From  the  sensemaking  loop  presented  by  Pirolli  and  Card 
[19],  we  learn  that  in  intelligence  analysis,  that  analytic 
process  consists  not  only  of  the  information  that  is 
explicitly  within  the  dataset  being  analyzed,  but  also  the 
domain knowledge of the analyst performing the analysis. It 
is through this domain knowledge that analysts interact and 
explore  the  dataset  to  “make  sense”  of  the  information. 
Thus,  we  believe 
the  domain 
knowledge  associated  with  it)  is  equally  important  as  the 
raw data, and must be incorporated into the visualization by 
tightly coupling the model with the interaction. 
From this body of work, we most notably come away with 
an understanding that 1) analysts fundamentally understand 
the spatial metaphor used in many spatial visualizations, 2) 
many  of  these  systems  are  constructed  using  complex 
mathematical  algorithms  to  transform  high-dimensional 
data  to  two  dimensions,  and  3)  in  most  cases  these 
algorithms  can  be  controlled  by  analysts  largely  through 
visual  controls  (e.g.,  sliders,  knobs,  etc.)  to  directly  adjust 
parameters of the algorithms, updating the spatial layout. 
SEMANTIC INTERACTION 

 

Figure 4. A model of semantic interaction. Users are able to 
interact directly in the spatial metaphor. The system updates 
the corresponding parameters of the statistical model based on 
the analytic reasoning of the users. Finally, the model updates 

the visualization based on the changes, thus unifying the 
synthesis and foraging stages of the sensemaking loop. 

In the purest sense, semantic interaction refers to interaction 
occurring  within  a  spatial  visualization,  with  the  added 
benefit that it is tightly coupled to the model calculating the 
spatial layout (Figure 4). Given the previous work of what 
interaction  in  visual  analytic  tools  is,  semantic  interaction 
occupies a new design space for interaction. It merges the 
ability to change the statistical model while maintaining the 
flexibility  and  familiar  methods  for  interacting  within  the 
metaphor  of  spatial  visualizations.  Users  can  benefit  from 
semantic  interactions  in  that  they  can  interact  within  a 
metaphor  which 
they  are  familiar  with,  performing 
interactions  which  are  part  of  the  spatial  analytic  process 
[4], without having to focus on formal updates to the model.  
Semantic  interaction  leverages  the  cognitive  connection 
formed  between  the  user  and  the  spatial  layout.  The 
following intelligence analysis scenario is representative of 
the strategies and interactions of analysts when performing 
an  intelligence  analysis  task  of  textual  documents  in  a 
spatial visualization, as previously found by Andrews et al. 
[4],  and  further  motivates  and  explains  the  concept  of 
semantic interaction: 

 
Figure  3.  The  IN-SPIRE  Galaxy  View  showing  a 
spatializtiation  of  documents  represented  as  dots.  Each 
cluster of dots represents a group of similar documents.  
 
allowing users to create such informal relationships within 
information  is  beneficial,  as  it  does  not  require  users  to 
formalize these relationships [17].  
From this related work, we believe a trend is emerging in 
how interaction is currently handled in many visual analytic 
systems where complex statistical models are used – users 
are  required  to  go  outside  of  the  metaphor.  That  is,  while 
the  visual  representation  given  to  users  is  spatial,  the 
methods of interaction require users to step outside of that 
metaphor  and  interact  directly  with  the  parameters  of  the 
statistical model using visual controls, toolbars, etc.  
There  has  been  some  work  in  providing  more  easy  to  use 
interactions  for  updating  statistical  models.  For  example, 
relevance feedback has been used for content-based image 
retrieval, where users are able to move images towards or 
away  from  a  single  image  in  order  to  portray  pair-wise 
similarity  or  dissimilarity  [24].  From  there,  an  image 
retrieval algorithm determines the features and dimensions 
shared between the images that the user has determined as 
being  similar.  We  view  this  as  one  example  where  the 
interaction stays in the spatial metaphor of the visualization.  
Also, spatializations of document sets exist that allow users 
to place “points of interest” into the spatial layout. In VIBE, 
users are allowed to define multiple points of interest in the 
spatial  layout  that  correspond  to  a  series  of  keywords 
describing  a  subject  matter  of  interest  to  the  user  [18]. 
Similarly,  Dust  &  Magnet  [27]  allows  users  to  place  a 
series  of  “magnets”  representing  keywords  into  the  space 
and observe how documents are attracted or repelled from 
the  locations  of  these  magnets.  Through  both  of  these 
systems, users can interact in the spatial metaphor through 
these  placements  of  “nodes”  representing  keywords. 
However, the focus of semantic interaction is on interacting 
with  data  (i.e.,  documents),  an 
important  distinction 
discussed in the following section. 

 

 

 
Figure  5.  (top)  The  basic  version  of  the  “visualization 
pipeline”.  Interaction  can  be  performed  on  directly  the 
Algorithm  (blue  arrow)  or  the  data  (red  arrow).  (bottom) 
Our  modified  version  of 
for  semantic 
interaction,  where  the  user  interacts  within  the  spatial 
metaphor (purple arrow). 

the  pipeline 

During her analysis, an intelligence analyst finds a 
suspicious  and 
interesting  phrase  within  a 
document. While reading through the document, she 
highlights  the  phrase  “suspicious  individuals  were 
spotted  at  the  airport”,  in  order  to  more  easily 
recall  this  information  later.  After  she  finishes 
reading the document, she moves the document into 
the  bottom  right  corner  of  her  workspace,  in  the 
proximity of other documents related to an event at 
an airport. To remind herself of her hypothesis, she 
annotates  the  document  with  “might  be  related  to 
Revolution  Now  terrorist  group”.  Now,  with  the 
goal  of 
the 
“airport”, she searches for the term, continuing her 
investigation. 

further  examining 

the  events  at 

investigating 

that  each  of 

instead  point  out 

the  analytic  process  of 

In addition to the three forms of semantic interaction in the 
scenario,  Table  1  provides  a  list  of  various  forms  of 
semantic  interaction,  including  how  each  can  be  used 
within 
textual 
information  spatially.  We  do  not  claim  that  this  list  is 
complete,  but 
these 
interactions  can  relate  to  a  user’s  reasoning  within  the 
analytic process.  
Designing for Semantic Interaction 
In order for analysts to interact with information in a spatial 
metaphor, it must first be created. Following the model of 
the visualization pipeline [13], this creation calls for a series 
of  mathematical  transformations,  turning  raw  data  into  a 
spatial  layout  –  much  the  way  many  of  the  visualizations 
mentioned  previously  are  constructed.  However,  these 
visualizations  fit  this  model,  as  their  user  interactions  are 
primarily  focused  on  directly  modifying  the  statistical 
model  (as  well  as  other  attributes  of  the  visualization  or 
data  transformation).  Designing  for  semantic  interaction 
requires  a  fundamentally  different  model  for  how  tools 
integrate  user  interaction  –  one  that  can  capture  the 
interaction,  interpret  the  associated  analytical  reasoning, 
and update the appropriate mathematical parameters.  
Figure  5  illustrates  this  model,  where  the  spatialization  is 
treated  a  medium  through  which  the  user  can  perceive 

 

Figure 6. Overview of how nodes and edges in ForceSPIRE’s 
force-directed layout are created from documents (Doc) and 
entities (Ent), respectively.  

 

 

it 

interaction, 

information  and  gain  insight,  as  well  as  interact  and 
perform  his  analysis.  Through  expanding  the  pipeline  to 
accommodate  for  semantic 
is  a  more 
appropriate match to the user’s sensemaking process. 
Capturing the Semantic Interaction 
A  non-trivial  first  step  in  the  model  is  capturing  the  user 
interaction.  Much  research  has  been  done  in  this  area, 
primarily  for  the  purpose  of  maintaining  process  history 
(e.g., [5], [21], [12], etc.). When considering how to capture 
interaction,  one  decision  to  be  made  is  at  what  “level”  to 
capture  it.  For  example,  GlassBox  [6]  captures  interaction 
at a rudimentary level (i.e. mouse clicks and key strokes), 
while  Graphical  History  [14]  keeps  track  of  a  series  of 
previous  visualizations  as  a  user  changes  the  visualization 
during the exploration of the data.  
Semantic  interaction  is  captured  at  a  data  level,  as  the 
interactions  occur  on  the  data,  and  within  the  spatial 
metaphor.  Using 
the 
interaction being captured would be: 

the  earlier  analytic  scenario, 

•  The highlighted phrase 
•  When the highlighting occurs (timestamp) 
•  The color chosen for the highlight 
•  The document in which the highlight occurs 
•  The new document location 
•  The text of the annotation 

By  capturing  (and  storing)  the  interaction  history,  we  can 
interpret the analytical reasoning of the user. Thus, we not 
only capture the interaction, but also use it. 
Interpreting the Associated Analytical Reasoning 
In interpreting the interaction, the goal is for the system to 
determine  the  analytical  reasoning  associated  with  the 
interactions  and  update  the  model  accordingly.  From 
previous findings [4], we can associate analytical reasoning 
with  forms  of  semantic  interaction  (see  Table  1).  It  is 
essentially the model’s task to determine  why, in terms of 
the data, the interaction occurred. To answer this question, 
we do not propose that this model can accurately gauge user 
intent.  Instead,  the  goal  is  to  calculate,  based  on  the  data, 

Figure 7. Using ForceSPIRE on a 32 megapixel large, 
high-resolution display. 

 

 
what information is consistent with the captured interaction. 
For  instance,  we  associate  text  highlighting  with  adding 
importance to the text being highlighted. We do not claim 
that we can associate the interaction of highlighting to the 
intuition that spurred the analyst to highlight the text, which 
is far more challenging, and arguably impossible. 
We refer to the captured and interpreted interactions as soft 
data, in comparison to the hard data that is extracted from 
the raw textual information (e.g., term or entity frequency, 
titles,  document  length,  etc.).  We  define  soft  data  as  the 
stored result of user interaction as interpreted by the system. 
In  representing  interaction  as  soft  data,  the  algorithm  can 
calculate  and  reconfigure  the  spatial  layout  accordingly. 
Figure  5  illustrates  how  our  approach  differs  from  the 
traditional visualization pipeline. 
There has been previous work in capturing and interpreting 
reasoning from user interaction. For instance, Dou et al. [7] 
performed  a  study  where  financial  analysts  were  asked 
analyze  a  dataset  using  WireVis,  an  interactive  financial 
transaction visualization. The tool developers then analyzed 
the captured interaction, and assumptions were made about 
the  reasoning  of  the  analysts  at  specific  points  in  the 
investigation. These results were compared to the analysts’ 
self-recorded  reasoning,  and  found  to  be  accurate  up  to 
82%. While our work has similar goals (i.e., interpreting the 
analytical reasoning associated with the analysts through an 
evaluation  of  the  interaction)  our  model  does  so  through 
tightly  integrating  the  interaction  with  the  underlying 
mathematical model. In doing so, the interpretation can be 
done algorithmically. 
Updating the Underlying Model 
Through  metric  learning  of  distance  weights,  the  layout 
uses  the  soft  data  to  update  the  underlying  model. 
Depending  on  the  algorithm  used  to  compute  the  spatial 
layout,  the  precise  parameters  being  updated  will  vary.  In 
general,  this  will  refer  to  weighting  of  a  combination  of 
dimensions  that  will  help  guide  the  model  as  to  which 
dimensions the user finds important.  
FORCESPIRE: SYSTEM OVERVIEW 
ForceSPIRE  is  a  visual  analytics  prototype  designed  for 
specific 
(document 
movement,  text  highlighting,  search,  and  annotation)  for 

forms  of 

interaction 

semantic 

 

Figure  8.  Moving  the  document  shown  by  the  arrow, 
ForceSPIRE  adapts  the  layout  accordingly.  Documents 
sharing entities with the document being moved follow. 

 

interactively exploring textual data. The system has a single 
spatial  view  (shown  in  Figure  12),  where  a  collection  of 
documents is represented spatially based on similarity (i.e., 
documents closer together are more similar).  
ForceSPIRE is designed for large, high-resolution displays 
(such  as  the  one  shown  in  Figure  7).  As  semantic 
interaction emphasizes the importance of context in which 
the  interaction  takes  place  (e.g.,  highlighting  text  in  the 
context  of  the  document),  having  the  full  detail  text 
available  in  the  context  of  the  spatial  layout  is  beneficial 
over having a single document viewer. Further, the physical 

Table  1.  Forms  of  semantic  interaction.  Each  interaction 
corresponds  to  reasoning  of  users  within  the  analytic 
process. 

Form of Semantic 

Interaction 

Document Movement 

Text Highlighting 

Pinning  Document 
Location 
Annotation, “Sticky Note” 

to 

Document Coloring 

Level of Visual Detail 

Query Terms 
 

Associated Analytic Reasoning 

• Similarity/Dissimilarity 
• Create 

spatial  construct 

timeline, list, story, etc) 

• Test 

hypothesis, 

see 
document “fits” in region 

(.e.g 

how 

• Mark 

importance  of  phrase 

(collection of entities) 

• Augment  visual  appearance  of 

document for reference 

to 

in 

• Give 

semantic  meaning 

space/layout 

• Put 

semantic 

information 

workspace, within context 
• Create visual group/cluster 
• Mark group membership 
• Change 

ease 

of 

visually 
referencing  information  (e.g.  full 
detail = more important = easy to 
reference) 

• Expressive search for entity 

(and 

to  match 

is  positioning 

Semantic Interaction in ForceSPIRE 
The  semantic  interactions  in  ForceSPIRE  are:  placing 
information  at  specific  locations,  highlighting,  searching, 
and annotating in order to incrementally change the spatial 
layout 
their  mental  model.  The  primary 
parameters  of  the  force-directed  model  that  are  being 
updated  through  this  learning  model  are  the  importance 
values of the entities.  
Document  Movement.  The  predominant  interaction  in  a 
spatial  workspace 
repositioning) 
documents.  In  previous  work,  we  have  demonstrated  how 
users can perform both exploratory and expressive forms of 
this type of interaction [9]. In ForceSPIRE, we allow for the 
following  exploratory  interaction  (i.e.,  interaction  that 
allows users to explore the structure of the current model, 
but  does  not  change  it).  Users  are  able  to  interactively 
explore the information by dragging a document within the 
workspace, pinning a document to a particular location (see 
Figure  8),  as  well  as  linking  two  documents.  When 
dragging a document, the force-directed system responds by 
finding the lowest energy state of the remaining documents 
given  the  current  location  of  the  dragged  document. 
Mathematically, this adds a constraint to the stress function 
being  optimized  (in  this  case  the  force-directed  model). 
This  allows  users  to  explore  the  relationship  of  that 
document in comparison to the remaining documents.  
In addition to the exploratory dragging of a document, users 
have the ability to pin a document. By pinning a document, 
users  are  able  to  incrementally  add  semantic  meaning  to 
locations in their workspace. By specifying key documents 
to  user-defined  locations,  the  layout  of  the  remaining 
documents will adapt to these constraints. Thus, users can 
explore  how  documents  are  positioned  based  on  their 
similarity  (or  dissimilarity)  to  the  pinned  documents.  For 
instance,  if  the  layout  places  a  document  between  two 
pinned  documents, 
the  particular 
document holds a link between the two pinned documents, 
sharing entities that occur in both. 
Finally,  users  can  perform  an  expressive  form  of  this 
interaction  by  linking  two  documents,  performed  by 
dragging  one  document  onto  another  pinned  document.  In 
doing so, ForceSPIRE calculates the similarity between the 
documents,  and  increases  the  importance  value  of  the 
entities  shared  between  both  documents.  As  a  result,  the 
layout will place more emphasis on the characteristics that 
make those two documents similar. 
Highlighting.  When  highlighting  a  term,  ForceSPIRE 
creates an entity from the term (if not already one), and the 
importance  value  of  that  term  is  increased.  Similarly, 
highlighting  a  phrase  results  in  the  phrase  being  first 
parsed for entities, then increasing the importance value of 
each  of  those  entities.  For  example,  Figure  11  shows  the 
effect of highlighting the terms “Colorado” and “missiles” 
in the document pointed to with the arrow. As a result, the 

it  may 

imply 

that 

 
Figure  9.  The  Effect  of  adding  an  annotation  (“these 
individuals  may  be  related  to  Revolution  Now”)  to  the 
document shown with an arrow. As  a result,  the document 
becomes 
linked  with  other  documents  mentioning  the 
terrorist organization “Revolution Now”.  

presence of these displays creates an environment in which 
the  virtual  information  (in  this  case  the  documents)  can 
occupy  persistent  physical  space.  As  a  result,  users  are 
further  immersed  into  the  spatial  metaphor,  as  they  can 
point and quickly refer to information based on the physical 
locations.  
Constructing the Spatial Metaphor 
The spatial layout of the text documents is determined by a 
modified  version  a  force-directed  graph  model  [11].  This 
model  functions  on  the  principle  of  nodes  with  a  mass 
connected  by  springs  with  varying  strengths.  Thus,  each 
node has attributes of attraction and repulsion: nodes repel 
other  nodes,  and  two  nodes  attract  each  other  only  when 
connected  by  a  spring  (edge).  The  optimal  layout  is  then 
computed  by  iteratively  calculating  these  forces  until  the 
lowest energy state of all the nodes is reached. A complete 
description of this algorithm can be found in [11].  
We  apply  this  model  to  textual  information  by  treating 
documents  as  nodes  (an  overview  is  shown  in  Figure  6). 
The entire textual content of each document is parsed into a 
collection  of  entities  (i.e.,  keywords).  The  number  of 
entities corresponds to the mass of each document (heavier 
nodes  do  not  move  as  fast  as  lighter  nodes).  A spring  (or 
edge) represents one or more matching entities between two 
nodes.  Therefore,  the  initial  distance  metric  is  a  based  on 
co-occurrence  of  terms  between  documents.  For  example, 
two  documents  containing  the  term  “airport”  will  be 
connected  by  a  spring.  The  strength  of  a  spring  (i.e.  how 
close together it tries to place two nodes) is based on two 
factors:  the  number  of  entities  two  documents  have  in 
common,  and  the  importance  value  associated  with  each 
shared entity (initially, importance values are created using 
a  standard  tfidf  method  [16]).  The  sum  of  all  importance 
values add up to 1. 
The resulting spatial layout is one where similarity between 
documents  is  represented  by  distance  relative  to  other 
documents.  Similarity  in  this  system  is  defined  by  the 
strength of the spring between two documents. A stronger 
spring  (and  therefore  a  larger  amount  of  shared  entities) 
will pull two documents closer together, and thus represent 
two similar documents. 

 

 
Figure  10.  Searching  for  the  term  ”Atlanta”,  documents 
containing the term highlight green within the context of the 
spatial  layout.  Additionally,  the  importance  value  of  entity 
“Atlanta” is increased. 

other  documents  containing  that  term  are  clustered  more 
tightly. 
Searching.  When  coming  across  a  term  of  particular 
interest, analysts usually search on that term in order to find 
other  occurrences.  In  a  spatial  workspace,  this  is  of 
particular  importance,  because  the  answer  to  “where  the 
term  is  also  found”  is  not  only  given  in  terms  of  what 
documents,  but  also  where  in  the  layout  those  documents 
occur. The positions of documents containing the term are 
shown in context of the entire dataset, from which users can 
infer the importance of that term (as shown in Figure 10).  
ForceSPIRE  first  creates  an  entity  from  the  search  term 
(unless  it  is  already  one),  then  increases  the  importance 
value  of  the  search  term.  Figure  10  gives  an  example  of 
how a search result appears in ForceSPIRE. Searching for 
the  term  “Atlanta”,  documents  that  contain  the  term  are 
highlighted  green,  and  links  are  drawn  to  show  where  the 
resulting documents are in relation to the current document.  
Annotation.  Annotations  (i.e.,  “sticky  notes”)  are  also 
viewed as a form of semantic interaction, occurring within 
the analytic process, from which analytic reasoning can be 
inferred. When a user creates a note regarding a document, 
that semantic information should be added to the document. 
For example, if Document A refers to “Revolution Now” (a 
suspicious  terrorist  group),  and  Document  B  refers  to  “a 
group of suspicious individuals”, and the user has reason to 
believe  these  individuals  are  related  to  Revolution  Now, 
adding a note to Document B stating “these individuals may 
be  related  to  Revolution  Now”  is  one  way  for  the  user  to 
add semantic meaning to the document.  
ForceSPIRE  handles  the  addition  of  the  note  (shown  in 
Figure 9) by 1) parsing the note for any currently existing 
entities,  then  2)  increasing  the  importance  value  of  each, 
and 3) creating any new springs between other documents 
sharing these entities. In the example in Figure 9, edges are 
created between Document B and Document A (as well as 
any  other  documents  that  mention  “Revolution  Now”). 
Additionally,  if  the  note  contains  any  new  entities  not 
currently in the model, they are created, with the intent that 

 

 
Figure 11. The effect of highlighting a phrase containing the 
entites  “Colorado”  and  “missiles”.  Documents  containing 
these  entities  move  closer,  as  the  increase  in  importance 
value increases the edge strength.  

the 

importance  values  of 

any future entities that may match to that note can be linked 
at that time. ForceSPIRE also handles cases where notes are 
edited,  with  text  added  or  removed  from  the  note,  by 
updating  the  entities  associated  with  the  document,  and 
adjusting 
these  entities 
accordingly. 
Model Updates 
Each  of  the  semantic  interactions  in  ForceSPIRE  impacts 
the  model  by  updating  the  importance  values  of  entities, 
and  the  mass  of  each  document.  The  calculation  for 
updating the importance value of an entity is the same for 
each interaction. If an entity was “hit” (i.e., it was included 
in  a  highlight,  it  was  searched,  it  was  in  a  note,  etc.), 
ForceSPIRE increases its importance value by 10%. As the 
sum  of  all  importance  values  of  entities  adds  up  to  1, 
ForceSPIRE  subtracts  an  equal  amount  from  all  other 
entities’ importance values. As a result, importance values 
decay over time, and entities that are rarely used during the 
analysis  have  less  impact  on  the  layout.  The  mass  of  a 
document  uses  a  similar  calculation,  in  that  each  time  a 
document  is  “hit”  (i.e.,  text  was  highlighted,  it  was  the 
result of a search hit, etc.), it increases by 10%.  
When  undoing  an 
standard 
the 
“Control+Z”  keyboard  shortcut,  a  linear  history  of  the 
interactions will be reversed, and the importance values of 
affected  entities  will  be  returned  to  their  prior  values  (as 
well  as  document  masses).  As  for  the  locations  of  the 
documents,  the  reverted  importance  values  and  document 
masses  will  be  responsible  for  updating 
layout. 
However, this does not guarantee that the layout will return 
to  the  exact  previous  view,  and  the  user  may  find  it 
necessary to perform small adjustments. 
The model updates used in ForceSPIRE serve as an initial 
approach at how to couple semantic interactions with model 
updates. Other, more complex methods may exist, and we 
encourage  further  research  in  this  area.  Sensemaking  is  a 
complex exploratory process. As such, semantic interaction 

interaction  using 

the 

through 

more  central  documents.  While  reading 
the 
documents, he highlighted phrases of interest. For example, 
he highlighted the phrase “Nizar A. is now known to have 
spent six months in Afghanistan”. In doing so, ForceSPIRE 
increased  the  importance  value  of  the  entities  within  the 
phrase,  particularly  “Afghanistan”  and  “Nizar  A”.  As  a 
result, the layout forms more tightly around those entities. 
Each change incrementally changes the layout. 
Continuing  with  his  investigation,  he  began  searching  for 
words  of  interest  (e.g.,  “weapons”,  “Colorado”,  “Atlanta”, 
etc.). ForceSPIRE provided him with quick visual feedback 
on where in the dataset each terms showed up (the search 
result  for  “Atlanta”  is  shown  in Figure  10).  In  addition  to 
gaining an overview of the distribution of the term within 
the  dataset  (by  highlighting  each  document  containing  the 
term  green),  ForceSPIRE  treats  performing  a  search  as 
either  creating  a  new  entity  from  the  search  term,  or 
increasing the importance value if an entity corresponding 
to the search term already exists. As a result of the multiple 
search terms and highlights corresponding to locations (e.g., 
“Atlanta”,  “Los  Angeles”,  “Missouri”,  etc.),  ForceSPIRE 
adapts  the  spatialization  by  creating  a  more  geographic-
oriented layout (shown in the “Mid Stage” layout in Figure 
12).  
During  further  investigation,  he  began  opening  more 
documents and adding annotations to documents where he 
found  information  missing  that  he  knew.  For  example, 
Figure  9  shows  how  he  opened  one  document  where 
“suspicious individuals” were mentioned. Earlier, he read a 
document  containing 
terrorist 
organization  named  “Revolution  Now”.  While  reading 
about  the  suspicious  individuals,  the  other  information  in 
the document triggered him to make a connection between 
these  individuals  and  Revolution  Now.  He  made  added  a 
note  to  the  document  about  the  suspicious  individuals 
stating  “these  individuals  may  be  related  to  Revolution 
Now”. As a result, ForceSPIRE parsed the note for entities, 
added  them  to  the  document,  and  pulled  the  document 
closer to other documents containing the entity “Revolution 
Now”.  
After  continuing  his  investigation  in  this  manner,  he 
ultimately  made  the  connections  within  the  dataset  to 
uncover  the  terrorist  plot.  The  progression  of  the  spatial 
layout,  shown  in Figure 12, shows the final layout, where 
he  was  able  to  pinpoint  regions  of  the  layout  as  being 
important  in  his  finding.  Some  of  the  spatial  locations  of 
clusters  are  a  result  of  him  pinning  documents  to  that 
region (e.g., “Atlanta”, “Los Angeles”, etc.). These pinned 
documents are shown in red. Perhaps more interestingly is 
not the regions that were created as a result of him pinning 
documents  to  that  location,  but  rather  how  the  remaining 
documents respond in the layout. For example, in the final 
state  shown  in  Figure  12,  a  group  of  documents  began  to 
emerge  in  the  middle  of  all  the  pinned  locations.  Upon 
examining  these  documents,  he  discovered  that  these 

information  about  a 

the 

layout 

 

interaction, 

instances  during 

 
Figure 12. The incremental change of the spatial layout (main 
view  of  ForceSPIRE)  from  the  initial  to  the  final  state. 
Through  semantic 
incrementally 
changed  based  on the  semantic  input of the user. We labeled 
the regions based on what the user told us the regions meant to 
him at each stage. 
can  enable  analysts  to  explore  their  hypothesis  in-situ, 
while  the  provenance  of  their  insights  is  captured  and 
stored. An open area of research is what analyzing the soft 
data might reveal about the analytic process. For instance, if 
the  importance  values  of  entities  converge  on  a  small 
number  of  entities,  specific  biases  might  be  revealed. 
Similarly, 
the  analysis  when  new 
hypotheses  are  being  explored  may  be  indicated  by 
diverging importance values. 
Use Case 
We  demonstrate  the  functionality  of  ForceSPIRE  through 
the  following  use  case.  In  this  scenario,  we  simulate  an 
intelligence  analysis  scenario  where  the  task  is  to  find  a 
hidden terrorist plot in a pre-constructed, ficticious textual 
dataset.  The  dataset  consists  of  50 
text  documents, 
containing  a  complex  terrorist  plot  (explosives  are  being 
transported to various cities in the U.S. using trucks). The 
combination of the task of finding the hidden terrorist plot 
and  the  textual  dataset  is  representative  of  daily  work 
performed  by  professional  intelligence  analysts  [8].  The 
analysis  described  below  lasted  70  minutes,  and  was 
performed  by  an  individual  computer  science  graduate 
student.  
The user began the investigation by loading the collection 
of  documents  into  ForceSPIRE.  The  documents  were 
automatically  parsed  for  entities  using 
the  LingPipe 
keyword  extraction  library  [1].  From  these  entities,  an 
initial layout was generated, shown in Figure 12(top). From 
this  layout,  he  began  investigation  by  reading  through  the 

 

interpreting 

leverage 

interactions 

DISCUSSION 
Unifying the Sensemaking Loop 
With the fundamentally different role occupied by semantic 
interaction, we explore a new design space for interaction in 
visual analytic tools. With the addition of soft data, and a 
model  capable  of 
the  user’s  analytical 
reasoning,  we 
that  are  already 
occurring in the spatial analytic process to further aid users 
in their sensemaking process.  
With  semantic  interaction,  the  amount  of  formalization 
between foraging and sensemaking (Figure 13) on the part 
of the user is reduced. For instance, in moving a document, 
users  can  formulate  a  hypothesis  based  on  that  document, 
expecting  similar  documents 
to  follow.  ForceSPIRE 
attempts to update the layout based on the interaction, and 
gives the user feedback. Thus, the foraging stage occurs as 
a  result  of  the  hypothesis  being  formed  through  semantic 
interaction.  By  not  forcing  users  to  over-formalize  their 
analytic  reasoning  too  early  in  order  to  forage  for  the 
relevant  information,  semantic  interaction  creates  a  more 
seamless 
transition  between 
foraging  and  synthesis, 
unifying the sensemaking loop.  
Future Work 
Semantic 
interaction,  as  a  concept,  opens  up  many 
possibilities for further research, such as: what interactions 
to  capture  and  store,  which  parameters  of  the  model  to 
update,  how  to  store  the  soft  data,  and  which  models 
present a metaphor that can be extended upon.  
In  order  to  make  more  concrete  claims  regarding  the 
usability  and  effectiveness  of  ForceSPIRE  (and  thus,  of 
semantic  interaction),  a  formal  user  study  is  needed.  Our 
plan is to introduce ForceSPIRE to professional intelligence 
analysts  and  have  them  solve  scenarios  that  model  their 
daily  task,  such  as  one  of  the  VAST  datasets  [2020].  The 
observations  and  feedback  from  these  users  will  provide 
ecological validity for semantic interaction. 
CONCLUSION 
In  this  paper  we  have  discussed  how  the  concept  of 
semantic  interaction  leads  to  a  new  design  space  for 
interaction 
information. 
Semantic  interactions  occur  directly  within  the  spatial 
metaphor,  support  spatial  cognition,  and  exploit  spatial 
analytic  interactions.  We  describe  semantic  interaction, 
discussing  the  three  components  required  –  capturing  the 
interaction, 
the  analytical  reasoning,  and 
updating  the  mathematical  model.  Further,  we  present 
ForceSPIRE, designed for semantic interaction with textual 
information, discussing its functionality and demonstrating 
how it can be used through a use case. Lastly, we discuss 
how  semantic  interaction  has  the  opportunity  to  unify  the 
sensemaking  loop,  creating  a  more  seamless  analytic 
process.  In  allowing  users  to  interact  within  the  spatial 
metaphor, they can remain more focused on their analysis 
of  the  data,  without  having  to  become  experts  in  the 
underlying mathematical models of the system.  

in  spatializations  of 

interpreting 

textual 

 

Figure  13.  The  sensemaking  loop,  illustrating  the  complex 
sequence  of  steps  used  by  intelligence  analysts  in  order  to 
gain insight into data.  
 
documents  are  about  the  terrorist  organization  using  “U-
Haul”  or  “Ryder”  trucks  for  transportation  between  these 
locations. ForceSPIRE placing these documents in between 
these  cities  in  the  layout  was  helpful,  as  these  documents 
contain  information  “connecting”  the  events  in  these 
locations.  Immediately  after  noticing  this  event,  he  also 
made use of the expressive form of interaction, performed 
by dragging two of these documents together to determine 
what  made  them  similar.  After  seeing  that  it  was  indeed 
terms  such  as  “Ryder”  and  “U-Haul”,  the  layout  formed 
more tightly around these terms. 
ForceSPIRE interpreted the analytical reasoning of the user 
through the creation of new entities that were not found by 
the  initial  keyword  extraction,  as  well  as  the  increase  of 
importance values of existing entities. This is evidenced by 
the  creation  of  39  new  entities  during  the  course  of  the 
analysis.  LingPipe  extracted  89  initial  entities  from  this 
dataset,  and  at  the  time  of  completing  our  investigation 
ForceSPIRE  included  128.  Examples  of  newly  created 
entities  are  “big  event”,  “grenades”,  “Fisher  Island”, 
“weapons”,  and  others.  The  ability  for  new  entities  to  be 
created  via  semantic  interaction  did  not  interfere  with  the 
fluid sensemaking process of the user. Instead, it aided the 
process  by  creating  new  entities,  which  in  turn  created 
semantically relevant connections within the dataset. 
In  addition  to  creating  new  entities,  existing  entities 
dynamically  changed  their  importance  value  based  on  the 
semantic 
interpreted 
reasoning 
interactions.  Examples  of  entities 
their 
importance  values  are  “Atlanta”,  “Revolution  Now”, 
“Colorado”,  “L.A.”,  and  others.  As  a 
the 
ForceSPIRE incrementally adapted the layout based on the 
user  input.  This  shows  that  adjusting  importance  values, 
creating entities, and changing locations of key documents 
helped  the  user  discover  the  structure  of  the  dataset,  and 
ultimately make out the hidden terrorist plot.  

of 
that  changed 

analytical 

result, 

the 

 

ACKNOWLEDGEMENTS 
This research was funded by the NSF grant CCF-0937071 
and the DHS center of excellence. 
REFERENCES 
1.  Alias-i. 2008. LingPipe 4.0.1. City, 2008. 
2.  i2 Analyst's Notebook. City. 
3.  Alsakran, J., Chen, Y., Zhao, Y., Yang, J. and Luo, D. 

STREAMIT: Dynamic visualization and interactive 
exploration of text streams. In Proceedings of the IEEE 
Pacific Visualization Symposium, 2011.  

4.  Andrews, C., Endert, A. and North, C. Space to Think: 
Large, High-Resolution Displays for Sensemaking. In 
Proceedings of the CHI '10, 2010.  

5.  Callahan, S. P., Freire, J., Santos, E., Scheidegger, C. E., 

C, Silva, u. T. and Vo, H. T. VisTrails: visualization 
meets data management. In Proceedings of the 
SIGMOD international conference on Management of 
data (Chicago, IL, USA, 2006). ACM.  

6.  Cowley, P., Haack, J., Littlefield, R. and Hampson, E. 

Glass box: capturing, archiving, and retrieving 
workstation activities. In Proceedings of the workshop 
on Continuous archival and retrival of personal 
experences (Santa Barbara, California, USA, 2006). 
ACM.  

7.  Dou, W., Jeong, D. H., Stukes, F., Ribarsky, W., 

Lipford, H. R. and Chang, R. Recovering Reasoning 
Processes from User Interactions. IEEE Computer 
Graphics and Applications, 2009. 

8.  Endert, A., Andrews, C., Fink, G. A. and North, C. 

Professional Analysts using a Large, High-Resolution 
Display. In Proceedings of the IEEE VAST Extended 
Abstract (2009).  

9.  Endert, A., Han, C., Maiti, D., House, L., Leman, S. C. 

and North, C. Observation-level Interaction with 
Statistical Models for Visual Analytics. IEEE VAST, 
2011. 

10. Frank M. Shipman, I. and Marshall, C. C. Formality 

Considered Harmful: Experiences, Emerging Themes, 
and Directions on the Use of Formal Representations 
inInteractive Systems. ACM CSCW, 8, 4, 1999, 333-352. 

11. Fruchterman, T. M. J. and Reingold, E. M. Graph 

drawing by force-directed placement. Software: Practice 
and Experience, 21, 11 1991, 1129-1164. 

12. Gotz, D. Interactive Visual Synthesis of Analytic 

Knowledge. IEEE VAST, 2006. 
13. Heer, J. prefuse manual, 2006. 
14. Heer, J., Mackinlay, J., Stolte, C. and Agrawala, M. 

Graphical Histories for Visualization: Supporting 
Analysis, Communication, and Evaluation. IEEE 
Transactions on Visualization and Computer Graphics, 
14, 6 , 2008, 1189-1196. 

 

15. Jeong, D. H., Ziemkiewicz, C., Fisher, B., Ribarsky, W. 

and Chang, R. iPCA: An Interactive System for PCA-
based Visual Analytics. Computer Graphics Forum, 28, 
2009, 767-774. 

16. Karen A Statistical Interpretation of Term Specificity 

and its Application in Retrieval. Journal of 
Documentation, 28, 1972, 11-21. 

17. Marshall, C. C., Frank M. Shipman, I. and Coombs, J. 

H. VIKI: spatial hypertext supporting emergent 
structure. In Proceedings of the European conference on 
Hypermedia technology (Edinburgh, Scotland, 1994). 
ACM.  

18. Olsen, K. A., Korfhage, R. R., Sochats, K. M., Spring, 
M. B. and Williams, J. G. Visualization of a document 
collection: the vibe system. Information Process 
Management, 29, 1 1993, 69-81. 

19. Pirolli, P. and Card, S. Sensemaking Processes of 

Intelligence Analysts and Possible Leverage Points as 
Identified Though Cognitive Task Analysis Proceedings 
of the International Conference on Intelligence 
Analysis,2005, 6. 

20. Plaisant, C., Grinstein, G., Scholtz, J., Whiting, M., 

O'Connell, T., Laskowski, S., Chien, L., Tat, A., Wright, 
W., Gorg, C., Zhicheng, L., Parekh, N., Singhal, K. and 
Stasko, J. Evaluating Visual Analytics at the 2007 
VAST Symposium Contest. Computer Graphics and 
Applications, IEEE, 28, 2 2008, 12-21. 

21. Shrinivasan, Y. B. and Wijk, J. J. v. Supporting the 

analytical reasoning process in information 
visualization. In Proceedings of the CHI '08 (Florence, 
Italy, 2008). ACM.  

22. Skupin, A. A Cartographic Approach to Visualizing 
Conference Abstracts. IEEE Computer Graphics and 
Applications, pp. 50-58, January/February, 2002. 

23. Thomas, J. J., Cook, K. A., National, V. and Analytics, 
C. Illuminating the path. IEEE Computer Society, 2005. 
24. Torres, R. S., Silva, C. G., Medeiros, C. B. and Rocha, 

H. V. Visual structures for image browsing. In 
Proceedings of the conference on Information and 
knowledge management (New Orleans, LA, USA, 
2003). ACM.  

25. Wise, J. A., Thomas, J. J., Pennock, K., Lantrip, D., 

Pottier, M., Schur, A. and Crow, V. Visualizing the non-
visual: spatial analysis and interaction with information 
for text documents. Morgan Kaufmann Publishers, 1999. 

26. Wright, W., Schroh, D., Proulx, P., Skaburskis, A. and 

Cort, B. The Sandbox for analysis: concepts and 
methods. In Proceedings of the CHI '06 (New York, 
NY, 2006). ACM.  

27. Yi, J. S., Melton, R., Stasko, J. and Jacko, J. A. Dust & 
magnet: multivariate information visualization using a 
magnet metaphor. Information Visualization, 4, 4, 2005, 
239-256. 

","{""pos"":{""0"":1,""1"":2,""2"":3,""3"":4},""1"":{""0"":""acm*"",""1"":""ieee*"",""2"":""atlanta*"",""3"":""usa*""},""3"":{""0"":""document*"",""1"":""figure*"",""2"":""metaphor"",""3"":""term*""},""6"":{""0"":""spatial*"",""1"":""semantic*"",""2"":""visual*"",""3"":""foraging*""},""4"":{""0"":""users*"",""1"":""entities*"",""2"":""forcespire"",""3"":""models""},""5"":{""0"":""statistical*"",""1"":""workspace*"",""2"":""pipeline*"",""3"":""graphics*""},""2"":{""0"":""result"",""1"":""shown*"",""2"":""a"",""3"":""containing*""},""0"":{""0"":""j"",""1"":""c"",""2"":""m"",""3"":""b*""}}",2012,{},False,False,conferencePaper,False,HDQVL9W2,[],self.user,"{""Unnamed: 0"":{""0"":0,""1"":1,""2"":2,""3"":3,""4"":4,""5"":5,""6"":6,""7"":7,""8"":8,""9"":9,""10"":10,""11"":11,""12"":12,""13"":13,""14"":14,""15"":15,""16"":16,""17"":17,""18"":18,""19"":19,""20"":20,""21"":21,""22"":22,""23"":23,""24"":24,""25"":25,""26"":26,""27"":27,""28"":28,""29"":29,""30"":30,""31"":31,""32"":32,""33"":33,""34"":34,""35"":35,""36"":36,""37"":37,""38"":38,""39"":39,""40"":40,""41"":41,""42"":42,""43"":43,""44"":44,""45"":45,""46"":46,""47"":47,""48"":48,""49"":49,""50"":50,""51"":51,""52"":52,""53"":53,""54"":54,""55"":55,""56"":56,""57"":57,""58"":58,""59"":59,""60"":60,""61"":61,""62"":62,""63"":63},""C"":{""0"":8.4266472061,""1"":11.2896869022,""2"":20.1440855562,""3"":5.9718055352,""4"":7.0487790416,""5"":14.7837064376,""6"":7.1267305366,""7"":12.1121254103,""8"":7.9500130407,""9"":4.8974849172,""10"":5.3110256908,""11"":18.078332817,""12"":7.5682456791,""13"":10.8088348285,""14"":5.511061034,""15"":6.3740280947,""16"":29.1033319649,""17"":28.0128756912,""18"":8.4711840759,""19"":7.2706540282,""20"":10.2422514657,""21"":6.1074203174,""22"":4.7909956393,""23"":10.442184723,""24"":9.3334214408,""25"":10.9062732047,""26"":10.6768702293,""27"":5.7744811753,""28"":5.6706345749,""29"":10.0247219358,""30"":8.7807160348,""31"":5.651198606,""32"":10.5572880095,""33"":12.5448712135,""34"":6.9549925865,""35"":4.7037035622,""36"":11.7821753009,""37"":6.0135480384,""38"":4.7688877124,""39"":10.1144264323,""40"":4.7812199605,""41"":6.0536825246,""42"":8.3557215606,""43"":5.6415313773,""44"":4.8787214593,""45"":6.6525628838,""46"":5.4309345201,""47"":7.5229964972,""48"":6.3393032342,""49"":6.038552072,""50"":5.3938706788,""51"":6.4153499066,""52"":4.7147427449,""53"":5.923364503,""54"":6.0478015784,""55"":5.7843108461,""56"":6.0198175516,""57"":6.5889660473,""58"":7.429214174,""59"":6.2834932146,""60"":4.9709260215,""61"":6.1928146421,""62"":4.7177444158,""63"":4.7177444158},""count"":{""0"":186,""1"":174,""2"":128,""3"":124,""4"":116,""5"":116,""6"":102,""7"":90,""8"":76,""9"":70,""10"":66,""11"":66,""12"":64,""13"":56,""14"":54,""15"":48,""16"":44,""17"":40,""18"":34,""19"":32,""20"":32,""21"":30,""22"":30,""23"":28,""24"":26,""25"":24,""26"":24,""27"":22,""28"":22,""29"":22,""30"":20,""31"":20,""32"":20,""33"":20,""34"":18,""35"":18,""36"":18,""37"":16,""38"":16,""39"":16,""40"":14,""41"":14,""42"":14,""43"":12,""44"":12,""45"":12,""46"":12,""47"":12,""48"":10,""49"":10,""50"":10,""51"":10,""52"":10,""53"":10,""54"":10,""55"":10,""56"":10,""57"":10,""58"":10,""59"":8,""60"":8,""61"":8,""62"":6,""63"":6},""sigma_nor"":{""0"":1.5915740858,""1"":1.8205250827,""2"":2.6969215221,""3"":1.5020334735,""4"":1.612946636,""5"":2.2996277526,""6"":1.6566849233,""7"":2.1912677815,""8"":1.8359009285,""9"":1.525438363,""10"":1.5859204851,""11"":3.0482485684,""12"":1.8555597198,""13"":2.3035789069,""14"":1.6614936169,""15"":1.8069994833,""16"":4.9334253894,""17"":4.9351730364,""18"":2.2398914197,""19"":2.0822805523,""20"":2.5431984716,""21"":1.9231515785,""22"":1.7137411529,""23"":2.6541670573,""24"":2.5126870474,""25"":2.8279600872,""26"":2.7882486612,""27"":1.9665828468,""28"":1.9480272495,""29"":2.7260275996,""30"":2.5515321648,""31"":1.9730959769,""32"":2.87990021,""33"":3.2472699652,""34"":2.2540412355,""35"":1.8225608886,""36"":3.1792154132,""37"":2.1102124507,""38"":1.862162489,""39"":2.9274817951,""40"":1.8939603201,""41"":2.1584905672,""42"":2.6370578526,""43"":2.1124857434,""44"":1.9464613743,""45"":2.3325351476,""46"":2.0666496713,""47"":2.5219836434,""48"":2.3141015646,""49"":2.245288151,""50"":2.0977817309,""51"":2.3315014345,""52"":1.9423937649,""53"":2.2189326425,""54"":2.2474044857,""55"":2.1871164503,""56"":2.2410015963,""57"":2.3712257009,""58"":2.5634787961,""59"":2.3513756262,""60"":2.0342697675,""61"":2.3294683999,""62"":1.9937215647,""63"":1.9937215647},""vocab_index"":{""0"":0,""1"":1,""2"":2,""3"":3,""4"":4,""5"":5,""6"":6,""7"":9,""8"":10,""9"":12,""10"":13,""11"":14,""12"":15,""13"":16,""14"":17,""15"":22,""16"":26,""17"":28,""18"":31,""19"":37,""20"":38,""21"":39,""22"":43,""23"":46,""24"":53,""25"":59,""26"":61,""27"":67,""28"":68,""29"":70,""30"":73,""31"":78,""32"":80,""33"":81,""34"":84,""35"":89,""36"":90,""37"":99,""38"":100,""39"":101,""40"":102,""41"":128,""42"":129,""43"":132,""44"":150,""45"":155,""46"":157,""47"":159,""48"":169,""49"":184,""50"":198,""51"":199,""52"":200,""53"":201,""54"":202,""55"":203,""56"":204,""57"":205,""58"":206,""59"":260,""60"":264,""61"":266,""62"":267,""63"":268},""word"":{""0"":""interaction"",""1"":""documents"",""2"":""document"",""3"":""spatial"",""4"":""semantic"",""5"":""users"",""6"":""model"",""7"":""entities"",""8"":""forcespire"",""9"":""figure"",""10"":""visual"",""11"":""importance"",""12"":""data"",""13"":""visualization"",""14"":""metaphor"",""15"":""term"",""16"":""j"",""17"":""c"",""18"":""statistical"",""19"":""result"",""20"":""values"",""21"":""models"",""22"":""shown"",""23"":""a"",""24"":""value"",""25"":""nodes"",""26"":""search"",""27"":""foraging"",""28"":""workspace"",""29"":""note"",""30"":""m"",""31"":""individuals"",""32"":""containing"",""33"":""proceedings"",""34"":""acm"",""35"":""phrase"",""36"":""ieee"",""37"":""atlanta"",""38"":""b"",""39"":""r"",""40"":""usa"",""41"":""computer"",""42"":""d"",""43"":""domain"",""44"":""arrow"",""45"":""context"",""46"":""pinned"",""47"":""h"",""48"":""dimensional"",""49"":""pipeline"",""50"":""increases"",""51"":""began"",""52"":""vast"",""53"":""2008"",""54"":""conference"",""55"":""2006"",""56"":""w"",""57"":""graphics"",""58"":""k"",""59"":""regions"",""60"":""t"",""61"":""v"",""62"":""virginia"",""63"":""tech""},""vector"":{""0"":""[-2.0760272  -3.9527576   1.6058933  -0.26295686  1.1727626  -3.885831\n -1.1800379   0.84985095  1.4850519  -1.1371748 ]"",""1"":""[-2.0180693  -4.224605    0.5766338  -0.45848954  1.2964014  -3.460757\n -1.4152985   0.24521269  1.0346856  -1.331255  ]"",""2"":""[-2.040509   -4.1052775   0.71464396 -0.6045664   1.209646   -3.036401\n -1.2754481   0.60534483  0.94742966 -1.2553163 ]"",""3"":""[-2.424216   -3.8857598   1.4997066   0.16929394  1.1796304  -3.9276958\n -0.6426815   1.0114235   1.6533327  -0.563506  ]"",""4"":""[-2.5276299  -4.100531    1.4112842   0.03826109  1.0119734  -3.7630723\n -0.92405176  1.0157508   1.4384438  -0.68174493]"",""5"":""[-2.0280778  -4.2934823   0.5025683  -0.5283739   1.1154435  -4.072942\n -1.5396972  -0.26462743  1.3588439  -1.352999  ]"",""6"":""[-2.0451262  -3.9336782   1.4607671  -0.85842055  0.9315798  -3.5830398\n -1.5828886   0.35456815  1.3455088  -1.5223922 ]"",""7"":""[-1.8963565  -4.456026    0.6326965  -0.89714086  1.0650439  -3.9299257\n -1.8020388  -0.05880952  1.2668842  -1.4644961 ]"",""8"":""[-1.814643   -4.3386374   0.7394708  -1.1389039   0.9207771  -3.6692245\n -1.727132    0.10633936  1.3034351  -1.506614  ]"",""9"":""[-2.033555   -3.9489179   1.2535721  -1.1406101   0.75441283 -3.1419015\n -1.5171361   0.5855932   1.1468679  -1.5537817 ]"",""10"":""[-2.295977   -3.7540364   1.6058445   0.13088436  1.1294402  -3.913082\n -0.70725507  0.90972555  1.7227799  -0.7900047 ]"",""11"":""[-2.1337636  -3.7395663   0.5215157  -0.7300483   0.61498755 -3.346241\n -0.9938626   0.5459547   0.9850336  -1.6922679 ]"",""12"":""[-2.2231405  -3.8915849   0.8949661  -0.0813191   1.1584787  -3.9780974\n -1.141829    0.11137156  1.3480015  -1.3593857 ]"",""13"":""[-2.175844   -3.7188356   1.542038    0.10868473  1.2803384  -4.171825\n -0.9161002   0.4721127   1.6884156  -1.0869907 ]"",""14"":""[-1.9941245  -3.810522    1.5881014  -0.76541144  0.88913584 -3.5133595\n -1.3134847   0.7922548   1.373734   -1.4883187 ]"",""15"":""[-1.9075251 -4.115653   1.1548989 -0.8292261  1.0426414 -3.0559528\n -1.3154233  1.1334767  1.1047342 -1.2954503]"",""16"":""[-1.9356426  -2.3808327   0.14399514 -0.72052807 -0.3579331  -3.458246\n  0.04521462 -0.24645029  1.1746631  -2.7159424 ]"",""17"":""[-1.5067745  -2.3463323  -0.16106424 -1.0048194  -0.5059979  -3.1239283\n  0.0865353   0.18019171  1.040093   -2.9673738 ]"",""18"":""[-2.4026122  -3.959294    1.126735    0.1571233   1.154545   -3.8511107\n -0.81455654  0.65879667  1.5072391  -0.86004686]"",""19"":""[-2.112338   -3.9498203   0.8197345  -1.2294639   0.62910926 -2.5439324\n -1.0978396   1.1191032   1.1439294  -1.0667816 ]"",""20"":""[-2.0681143  -3.8222013   0.5828435  -0.75428224  0.671151   -3.6839786\n -1.3344549  -0.07085162  1.1169233  -1.7860787 ]"",""21"":""[-2.054613   -4.10758     1.1554841  -0.68555564  1.059924   -3.807297\n -1.6600633   0.03103539  1.3501108  -1.4431511 ]"",""22"":""[-2.4234152  -3.647306    0.8353395  -1.4359183   0.12144421 -2.2047703\n -0.84347653  1.1963571   1.1222647  -0.76690894]"",""23"":""[-2.4136403  -3.8385758   0.9624092  -0.9070172   0.5414494  -2.627889\n -0.74764466  1.2019993   1.2113094  -0.7280896 ]"",""24"":""[-2.0706954  -3.4122524   0.52673423 -0.83937746  0.34593552 -3.3810866\n -0.8680278   0.21706535  1.078225   -1.9526036 ]"",""25"":""[-1.98039    -4.1438813   0.7167793  -0.5129263   1.046631   -4.2455187\n -1.3607969  -0.13416998  1.5320674  -1.3646777 ]"",""26"":""[-2.1809218 -4.0895605  1.2584411 -0.6444343  1.0652157 -2.942627\n -1.1511317  1.0983347  1.1649387 -0.8970814]"",""27"":""[-2.309      -4.0224185   1.5617685  -0.12665242  1.1090108  -3.6707711\n -0.9566397   1.1054115   1.4773438  -0.7170663 ]"",""28"":""[-2.2575293  -3.6207898   1.3407074   0.10263612  1.1697232  -4.260681\n -0.88094723  0.2084571   1.6005156  -1.3397533 ]"",""29"":""[-2.1707432  -3.8736799   0.98773354 -1.1395516   0.6095934  -2.686896\n -1.2012265   0.91917217  0.94889116 -1.3391066 ]"",""30"":""[-1.7316813  -2.1988993   0.03956232 -1.1718515  -0.5464808  -3.1489873\n  0.09441414 -0.11608406  1.0041564  -2.6747007 ]"",""31"":""[-2.0213027  -4.267555    0.43919918 -0.78130245  0.8778628  -3.8386602\n -1.6010802  -0.15222369  1.2158651  -1.4943525 ]"",""32"":""[-2.370275  -3.8414505  0.8998812 -1.0057483  0.5310208 -2.3945937\n -0.8303901  1.1165347  1.0368711 -0.6961535]"",""33"":""[-1.8609784  -3.9046502   0.57403743 -0.1991848   1.3210754  -3.5156608\n -0.9318244   0.5805983   1.1539876  -1.5045208 ]"",""34"":""[-2.0496924  -2.5979445   0.36194178 -0.39763933  0.05147735 -3.8311996\n -0.08601171 -0.18467279  1.3128986  -2.5081398 ]"",""35"":""[-2.0647538  -4.042675    1.271912   -0.9429255   0.96685684 -2.9693878\n -1.3872027   0.88808435  1.0696466  -1.4309219 ]"",""36"":""[-2.1338382  -2.840574    0.5077376  -0.26325282  0.3665732  -3.9791765\n -0.28924948 -0.13704017  1.3485118  -2.267533  ]"",""37"":""[-2.2300029  -2.4767087   0.6602654  -0.2823264   0.15613505 -3.998199\n  0.04833233 -0.24106333  1.4734178  -2.5308647 ]"",""38"":""[-1.5935541  -2.162749    0.17461213 -0.99723405 -0.47062513 -3.3084667\n  0.20779641  0.09644508  1.1841177  -2.8417761 ]"",""39"":""[-1.7641952  -2.2929986  -0.01322422 -0.6988882  -0.6750739  -3.3967607\n  0.28062567 -0.10375006  1.2850828  -3.0362945 ]"",""40"":""[-2.3939433  -2.7153842   0.76121217 -0.40757054  0.3654376  -4.1042266\n -0.18444808 -0.4073084   1.5427917  -2.386829  ]"",""41"":""[-2.2201614  -3.5605373   1.1049459   0.13196197  1.0386235  -4.1645617\n -0.64903957  0.31096902  1.6432159  -1.4688588 ]"",""42"":""[-1.6648612  -2.2884388   0.11792584 -1.1863977  -0.44959006 -3.0059507\n  0.26993385  0.07623356  1.1828005  -2.6561837 ]"",""43"":""[-1.9793987  -4.2132587   0.97936106 -0.6710094   0.8857132  -3.940568\n -1.4572169   0.667243    1.2306385  -1.5996331 ]"",""44"":""[-2.0316927 -3.4447427  1.3723872 -1.0586466  0.3888369 -3.2735639\n -1.0282857  0.7185317  1.3453703 -1.6233071]"",""45"":""[-1.960764  -4.106357   1.0351623 -0.7763414  0.9328349 -3.4436605\n -1.4102571  0.8537575  1.0587919 -1.5651753]"",""46"":""[-2.396928   -3.591406    0.8757469  -1.2865001   0.11623593 -2.2772496\n -0.7574492   1.1085895   1.0248028  -0.8286262 ]"",""47"":""[-1.868576   -2.2426848  -0.06449252 -0.7828658  -0.5432289  -3.2938201\n  0.0689782  -0.2255992   1.0595843  -2.942292  ]"",""48"":""[-2.404205   -3.9457643   1.7137485   0.21264674  1.092635   -4.0626273\n -0.9288596   0.8988016   1.7235978  -0.76300734]"",""49"":""[-2.0540106  -3.7789207   1.0973002   0.01766122  1.3086836  -4.121137\n -1.0711989   0.21199511  1.5167572  -1.4568911 ]"",""50"":""[-2.3873782  -3.802389    0.69994426 -1.2124313   0.3698611  -2.436029\n -0.8114016   1.0885388   1.1709398  -0.794497  ]"",""51"":""[-2.4216824  -3.6465013   0.68539196 -1.3787256   0.12325592 -2.3892133\n -0.71028155  1.1065226   1.209764   -0.8846094 ]"",""52"":""[-2.4661057  -3.8971367   0.87656224 -0.7919004   0.58400506 -2.8555727\n -0.75287473  1.050594    1.30832    -0.6627628 ]"",""53"":""[-1.5592159  -3.8510895   0.68324906 -1.0594401   0.78744483 -2.858954\n -1.1356859   0.7926992   1.0684828  -1.7277783 ]"",""54"":""[-1.8712896  -3.7628622   0.71844643 -0.3777265   1.1514897  -3.3618681\n -0.89552784  0.6003843   1.1804801  -1.5845866 ]"",""55"":""[-1.6974669  -3.9328978   0.6395929  -0.9429118   0.86025876 -2.882132\n -1.1825538   0.67480284  1.00573    -1.5840213 ]"",""56"":""[-1.5231050e+00 -2.3594429e+00 -2.6491837e-04 -1.1383098e+00\n -4.9126264e-01 -3.1649523e+00  2.0202965e-01  2.2186315e-01\n  1.2292761e+00 -3.0195916e+00]"",""57"":""[-2.1710496  -3.7705808   1.1598155   0.15650217  1.1845074  -4.1027393\n -0.76330155  0.44241974  1.6947106  -1.2092975 ]"",""58"":""[-1.9080521  -2.4377708   0.026186   -0.7579486  -0.5284374  -3.4038265\n -0.02512371 -0.04198295  1.1876687  -2.8899329 ]"",""59"":""[-1.8578643  -4.2990813   0.6000928  -0.769723    0.9919755  -4.0500383\n -1.4839443   0.09241693  1.4063281  -1.4527943 ]"",""60"":""[-1.7356282  -2.3182642  -0.02073603 -1.059151   -0.6037897  -3.1119528\n  0.27388957 -0.12939341  1.1701733  -2.7747574 ]"",""61"":""[-1.7031875  -2.240814    0.00382503 -0.87879395 -0.6063827  -3.3351662\n  0.25289518  0.03183333  1.2521178  -3.0730548 ]"",""62"":""[-2.2469196  -2.6261683   0.68074465 -0.22915977  0.30361533 -4.03525\n -0.04227466 -0.24620166  1.5112847  -2.3827949 ]"",""63"":""[-2.2271924e+00 -3.1628749e+00  9.2551535e-01 -1.6839743e-03\n  7.7628332e-01 -4.1208744e+00 -4.1515478e-01  7.6763891e-02\n  1.5555624e+00 -1.8479096e+00]""},""topic"":{""0"":-1,""1"":-1,""2"":3,""3"":6,""4"":6,""5"":4,""6"":-1,""7"":4,""8"":4,""9"":3,""10"":6,""11"":-1,""12"":-1,""13"":-1,""14"":3,""15"":3,""16"":0,""17"":0,""18"":5,""19"":2,""20"":-1,""21"":4,""22"":2,""23"":2,""24"":-1,""25"":-1,""26"":-1,""27"":6,""28"":5,""29"":-1,""30"":0,""31"":4,""32"":2,""33"":-1,""34"":1,""35"":3,""36"":1,""37"":1,""38"":0,""39"":0,""40"":1,""41"":-1,""42"":0,""43"":-1,""44"":-1,""45"":3,""46"":2,""47"":0,""48"":6,""49"":5,""50"":2,""51"":2,""52"":-1,""53"":-1,""54"":-1,""55"":-1,""56"":0,""57"":5,""58"":0,""59"":4,""60"":0,""61"":0,""62"":1,""63"":-1},""exemplar"":{""0"":null,""1"":null,""2"":""*"",""3"":""*"",""4"":""*"",""5"":""*"",""6"":null,""7"":""*"",""8"":null,""9"":""*"",""10"":""*"",""11"":null,""12"":null,""13"":null,""14"":null,""15"":""*"",""16"":null,""17"":null,""18"":""*"",""19"":null,""20"":null,""21"":null,""22"":""*"",""23"":null,""24"":null,""25"":null,""26"":null,""27"":""*"",""28"":""*"",""29"":null,""30"":null,""31"":""*"",""32"":""*"",""33"":null,""34"":""*"",""35"":""*"",""36"":""*"",""37"":""*"",""38"":""*"",""39"":null,""40"":""*"",""41"":null,""42"":null,""43"":null,""44"":null,""45"":""*"",""46"":""*"",""47"":""*"",""48"":""*"",""49"":""*"",""50"":""*"",""51"":null,""52"":null,""53"":null,""54"":null,""55"":null,""56"":null,""57"":""*"",""58"":null,""59"":""*"",""60"":""*"",""61"":""*"",""62"":""*"",""63"":null},""word*"":{""0"":""interaction"",""1"":""documents"",""2"":""document*"",""3"":""spatial*"",""4"":""semantic*"",""5"":""users*"",""6"":""model"",""7"":""entities*"",""8"":""forcespire"",""9"":""figure*"",""10"":""visual*"",""11"":""importance"",""12"":""data"",""13"":""visualization"",""14"":""metaphor"",""15"":""term*"",""16"":""j"",""17"":""c"",""18"":""statistical*"",""19"":""result"",""20"":""values"",""21"":""models"",""22"":""shown*"",""23"":""a"",""24"":""value"",""25"":""nodes"",""26"":""search"",""27"":""foraging*"",""28"":""workspace*"",""29"":""note"",""30"":""m"",""31"":""individuals*"",""32"":""containing*"",""33"":""proceedings"",""34"":""acm*"",""35"":""phrase*"",""36"":""ieee*"",""37"":""atlanta*"",""38"":""b*"",""39"":""r"",""40"":""usa*"",""41"":""computer"",""42"":""d"",""43"":""domain"",""44"":""arrow"",""45"":""context*"",""46"":""pinned*"",""47"":""h*"",""48"":""dimensional*"",""49"":""pipeline*"",""50"":""increases*"",""51"":""began"",""52"":""vast"",""53"":""2008"",""54"":""conference"",""55"":""2006"",""56"":""w"",""57"":""graphics*"",""58"":""k"",""59"":""regions*"",""60"":""t*"",""61"":""v*"",""62"":""virginia*"",""63"":""tech""},""pos"":{""0"":1,""1"":2,""2"":1,""3"":1,""4"":2,""5"":1,""6"":3,""7"":2,""8"":3,""9"":2,""10"":3,""11"":4,""12"":5,""13"":6,""14"":3,""15"":4,""16"":1,""17"":2,""18"":1,""19"":1,""20"":7,""21"":4,""22"":2,""23"":3,""24"":8,""25"":9,""26"":10,""27"":4,""28"":2,""29"":11,""30"":3,""31"":5,""32"":4,""33"":12,""34"":1,""35"":5,""36"":2,""37"":3,""38"":4,""39"":5,""40"":4,""41"":13,""42"":6,""43"":14,""44"":15,""45"":6,""46"":5,""47"":7,""48"":5,""49"":3,""50"":6,""51"":7,""52"":16,""53"":17,""54"":18,""55"":19,""56"":8,""57"":4,""58"":9,""59"":6,""60"":10,""61"":11,""62"":5,""63"":20},""x2D"":{""0"":3.4429502487,""1"":1.7186383009,""2"":2.773298502,""3"":3.3921365738,""4"":3.7900855541,""5"":0.5012694001,""6"":1.3329570293,""7"":0.7520440817,""8"":0.8515430689,""9"":2.1136651039,""10"":3.591168642,""11"":2.4618709087,""12"":1.9881079197,""13"":2.955663681,""14"":1.7733489275,""15"":2.6457614899,""16"":0.0473445691,""17"":-0.4778982103,""18"":3.2357096672,""19"":3.3400990963,""20"":1.3330878019,""21"":0.9379726052,""22"":3.1788158417,""23"":3.063788414,""24"":2.2398502827,""25"":0.7784737945,""26"":2.7625176907,""27"":3.8954560757,""28"":2.5274178982,""29"":3.1147172451,""30"":-0.1222137064,""31"":0.9722135067,""32"":3.1605210304,""33"":2.1498217583,""34"":0.3805108964,""35"":2.4656469822,""36"":0.3022448123,""37"":0.3772436976,""38"":0.0725777,""39"":0.4124247432,""40"":0.1723284274,""41"":2.1801445484,""42"":-0.1175186411,""43"":1.4169316292,""44"":1.8586673737,""45"":2.2102911472,""46"":3.4879188538,""47"":0.0595579483,""48"":3.4002895355,""49"":2.2845692635,""50"":3.3303244114,""51"":3.4444918633,""52"":3.1501162052,""53"":2.9157962799,""54"":2.3943748474,""55"":2.5689425468,""56"":0.0237375069,""57"":2.6316597462,""58"":0.1082082689,""59"":0.6897674203,""60"":-0.2210573107,""61"":0.2420788407,""62"":0.5093231797,""63"":2.0470690727},""y2D"":{""0"":2.385068655,""1"":4.1913161278,""2"":5.1845693588,""3"":1.6308220625,""4"":2.0437316895,""5"":4.1091985703,""6"":5.3574500084,""7"":4.4263882637,""8"":4.5091567039,""9"":5.7572026253,""10"":1.7979795933,""11"":4.5182042122,""12"":2.7402222157,""13"":1.9943349361,""14"":5.6989893913,""15"":5.6871972084,""16"":-9.525478363,""17"":-10.5443210602,""18"":2.0446989536,""19"":6.5028743744,""20"":4.3291788101,""21"":4.8173074722,""22"":7.413693428,""23"":6.946931839,""24"":4.685441494,""25"":3.9583954811,""26"":6.2091712952,""27"":2.1435828209,""28"":1.7824909687,""29"":6.0603871346,""30"":-10.2029056549,""31"":4.1920671463,""32"":7.1539478302,""33"":3.9644598961,""34"":-8.1933765411,""35"":5.9162535667,""36"":-7.8361167908,""37"":-7.7635416985,""38"":-10.4354867935,""39"":-9.9720973969,""40"":-7.8247485161,""41"":1.9542143345,""42"":-10.5813274384,""43"":4.8428087234,""44"":5.3846960068,""45"":5.4794259071,""46"":7.3702607155,""47"":-9.9715232849,""48"":1.6104204655,""49"":2.2304933071,""50"":6.9944806099,""51"":7.2554430962,""52"":6.6876239777,""53"":5.2724967003,""54"":4.1761593819,""55"":5.0032944679,""56"":-10.5469808578,""57"":2.0252234936,""58"":-9.7544727325,""59"":4.4018602371,""60"":-10.2464189529,""61"":-10.2540340424,""62"":-7.8518695831,""63"":1.6580380201}}",False,False,False,,"<p>The paper claims that current analytical methods make users interact with the statistical model by using sliders menus and text requiring them to go outside of the visual metaphor.</p>
<p>They define <strong>semantic interaction</strong> as an interaction that seeks to enable analysts to spatially interact with the models directly inside the statistical metaphor, using interactions that derive from their analytic process, such as searching, highlighting, annotating and repositioning documents. The focus of semantic interaction is on interacting with data directly not with the dimensions for example as in dust and magnet. <strong>I dont know whats the problem for doing both</strong></p>
<p>Semantic Interaction is based on the following principles:</p>
<p>1. Visual: Near= similar [citation 22]</p>
<p>2. Use the interactions within the visual metaphor [citation 4]</p>
<p>3. Interpret and map the interactions to the parameters of the model by updating weights and information</p>
<p>4. Shield users from the complexity</p>
<p>5. Model learns incrementally based on the interaction</p>
<p>6. Provide instant feedback of the updated model within the visual metaphor</p>
<p>7. Reuse learned model parameters in future,</p>
<p>Space to think found cognitive advantages associated with the manual creation of layout information.</p>
<p>[Cite 17] found that allowing users to create informal relationships within information is beneficial, as it does not require users to formalize these relationships.</p>
<p>Relevance Feedback has been used for content-based image retrieval by moving images closer or separate from each other to portray pair-wise similarity [cite 24]</p>
<p>Semantic interaction leverages the cognitive connection formed between the user and the spatial layout.</p>
<p>The captured interactions define a new type of data, the important part of this interactions is discovering intent from the specific interaction. For example we can give more importance to a piece of text that has been highlighted. This new data stored in the interaction is named as <strong>soft data</strong> in comparison with <strong>hard data</strong> extracted from the actual information.</p>
<p> </p>
<p><strong>Table of interactions and associated analytic reasoning in page 5, table 1.</strong></p>
<p> </p>
<p>The system is called <strong>ForceSpire </strong> documents are visualized as nodes that have more or less mass depending on the size of the document. Values are calculated using TFIDF</p>
<p> </p>
<p>Interactions:</p>
<p>Document Movement: Dragging, pinning or linking.</p>
<p>    Dragging changes similarity of documents</p>
<p>    Pinning gives meaning to the space surrounding a document</p>
<p>    Linking changes the relationships among documents</p>
<p> Highlighting: Gives importance to the highlighted text.</p>
<p> Annotations: Adds semantic meaning to a document or a link or the space.</p>
<p>Search: If the search is a new term it creates the term if not it gives more importance to the already created term.</p>
<p><strong>FUTURE WORK</strong><br />What interactions to capture and store, which parameters in the model to update, how to store the soft data. Which models have a good metaphor that can be extended upon.   </p>",Semantic interaction for visual text analytics,HDQVL9W2,False,False
ENF2YTJG,W7TVPE7L,Parsing Error,False,2018,{},False,False,journalArticle,False,ENF2YTJG,"[{u'tag': u'analytics'}, {u'tag': u'clustering'}, {u'tag': u'dimension reduction'}, {u'tag': u'projection'}, {u'tag': u'visual'}]",self.user,False,False,False,False,,"<p>The paper explores the decisions and design factors that have to be taken into account in the case of combining dimension reduction and clustering into the same visualization system.</p>
<p>Interesting Sentence:</p>
<p><strong>To better model the pipelines and models we need to extend the discussion into the realm of the visualization and interaction; algorithms alone are insufficient for complex cognition.</strong></p>
<p>They list different Dimension reduction algorithms:</p>
<p>    Linear:</p>
<p>        Factor Analysis</p>
<p>        PCA</p>
<p>        Probabilistic PCA</p>
<p>        Projection Pursuit</p>
<p>   </p>
<p>    Both:</p>
<p>        Feature Selection</p>
<p>        Independent Component Analysis</p>
<p>        Multidimensional Scaling</p>
<p>        Weighted MDS</p>
<p>    Non-Linear:</p>
<p>        Glimmer</p>
<p>        Isomap</p>
<p>        LDA</p>
<p>        T-SNE</p>
<p>Manhattan distances are preferable to Euclidian distances for high-dimensional data.</p>
<p>They define several tasks performed over Dimensionality reduction and clustering:</p>
<p>   Change the projection</p>
<p>   Identify similarity based on distance</p>
<p>   Positioning elements close to each other is a clustering task.</p>
<p>They mention that in order to create this interaction between both algorithms the pipeline order is important in order to understand how the interaction should affect the model:</p>
<p>    1. Independent Algorithms</p>
<p>    2. Dimension reduction then clustering</p>
<p>    3. Clustering preprocessing for dimension reduction</p>
<p>    4. Execute one of them cluster or reduce the dimensions on the result.</p>
<p>    5. Global and local combinations</p>
<p>    6 Iterative, Alternating Algorithms</p>
<p>But they also mention that this is hidden from the user.</p>
<p> </p>
<p>They have a lot of citation and papers about interaction with projection and clusters.</p>
<p>They define <strong>OLI</strong>: Observation Level interaction that refers to the direct manipulation of the observations which in turn triggers a black solving routing o learn new parameter.</p>
<p>This OLI interaction adds another level of complexity which is expressed by the authors as ""With respect to what"" detailed in citation 80.</p>
<p>For example for clusters:</p>
<p>       1. Moving an observation into a cluster</p>
<p>        2. Moving an observation out of a cluster</p>
<p>        3. Moving an observation from a cluster into another</p>
<p>        4. Moving an observation without changing cluster membership.</p>
<p><strong>The outcome of dimension reduction algorithm helps to explain the meaning of the clusters in the space, while the cluster themselves help to explain the meaning of the space. </strong>This is how in data context map they are able to add the context into the space by using the clusters.</p>",Towards a Systematic Combination of Dimension Reduction and Clustering in Visual Analytics,ENF2YTJG,False,False
7N8IFD7Z,WSWI9XMV,"See	discussions,	stats,	and	author	profiles	for	this	publication	at:	https://www.researchgate.net/publication/6451414

Value	and	Relation	Display:	Interactive	Visual
Exploration	of	Large	Data	Sets	with	Hundreds	of
Dimensions

Article		in		IEEE	Transactions	on	Visualization	and	Computer	Graphics	·	May	2007

DOI:	10.1109/TVCG.2007.1010	·	Source:	PubMed

CITATIONS
37

5	authors,	including:

READS
78

Matthew	Ward
Worcester	Polytechnic	Institute

133	PUBLICATIONS			3,082	CITATIONS			

Elke	Rundensteiner
Worcester	Polytechnic	Institute

567	PUBLICATIONS			7,531	CITATIONS			

SEE	PROFILE

SEE	PROFILE

All	content	following	this	page	was	uploaded	by	Matthew	Ward	on	12	March	2014.

The	user	has	requested	enhancement	of	the	downloaded	file.

Value and Relation Display: Interactive Visual
Exploration of Large Datasets with Hundreds of

Dimensions

1

Jing Yang

Dept of Computer Science

UNC Charlotte

jyang13@uncc.edu

Daniel Hubball
Dept of Computer Science
University of Wales Swansea

csdan@swansea.ac.uk

Matthew Ward
Dept of Computer Science

Worcester Polytechnic Institute

matt@cs.wpi.edu

Elke Rundensteiner
Dept of Computer Science

Worcester Polytechnic Institute

rundenst@cs.wpi.edu

William Ribarsky
Dept of Computer Science

UNC Charlotte

ribarsky@uncc.edu

Abstract— Few existing visualization systems can handle large
datasets with hundreds of dimensions, since high dimensional
datasets cause clutter on the display and large response time in
interactive exploration. In this paper, we present a signiﬁcantly
improved multi-dimensional visualization approach named Value
and Relation (VaR) display that allows users to effectively and
efﬁciently explore large datasets with several hundred dimen-
sions. In the VaR display, data values and dimension relationships
are explicitly visualized in the same display by using dimension
glyphs to explicitly represent values in dimensions and glyph
layout to explicitly convey dimension relationships. In particular,
pixel-oriented techniques and density-based scatterplots are used
to create dimension glyphs to convey values. Multi-dimensional
scaling, Jigsaw map hierarchy visualization techniques, and
an animation metaphor named Rainfall are used to convey
relationships among dimensions. A rich set of interaction tools
have been provided to allow users to interactively detect patterns
of interest in the VaR display. A prototype of the VaR display
has been fully implemented. The case studies presented in this
paper show how the prototype supports interactive exploration of
datasets of several hundred dimensions. A user study evaluating
the prototype is also reported in this paper.

Index Terms— Multi-dimensional visualization, high dimen-

sional datasets, visual analytics.

datasets in the Information Visualization ﬁeld. They include:
(cid:129) Using condensed displays to provide as much information
as possible to users. Typical approaches include pixel-
oriented techniques [12], [13] and density-based displays
[9], [24]. For example, in pixel-oriented techniques, infor-
mation is so condensed that each pixel presents a single
data value.

(cid:129) Examining relationships among dimensions to discover
lower dimensional spaces with signiﬁcant features. Ex-
ample approaches include ranking low dimensional pro-
jections by their features such as linear relationships [19],
and placing dimensions in a layout revealing their rela-
tionships to help users construct meaningful subspaces
[28].

(cid:129) Providing a rich set of interactions to allow users to
explore datasets from multiple coordinated views. In
these views, different subsets of dimensions and/or data
items can be examined at different levels of detail us-
ing different visualization techniques. Examples of such
approaches include the Hierarchical Parallel Coordinates
[10] and the VIS-5D system [11].

I. INTRODUCTION

Large datasets with hundreds of dimensions are common
in applications such as image analysis, ﬁnance, bioinformatics
and anti-terrorism. For example, in order to detect the semantic
contents of large image collections, it is common to analyze
hundreds of low level visual attributes of the images. It is
a challenge to make decisions based on these datasets, since
they are hard to analyze due to the dimensionality curse [5],
i.e., the lack of data separation in high dimensional space.
Using multi-dimensional visualization techniques to present
this data to analysts and allowing them to interactively explore
and understand the datasets are an important approach to
addressing this challenge. However, most traditional multi-
dimensional visualization techniques suffer from visual clutter
and only scale up to tens of dimensions. Up to now, few multi-
dimensional visualization systems have claimed to be scalable
to datasets with hundreds of dimensions. In this paper, we
present such a system, called the Value and Relation (VaR)
display, which is an improved version of a technique reported
in an earlier paper [27].

Our work is based on multiple concepts proposed and
explored in prior efforts toward visual exploration of large

The concepts above are signiﬁcant features of the VaR
display since its initial version [27]. In the ﬁrst version (see
ﬁgures 1a and b), pixel-oriented displays were used to show
data values and group them into dimension glyphs representing
individual dimensions. The dimension glyphs were then po-
sitioned on the screen using a fast Multi-dimensional scaling
(MDS) algorithm [4] according to dimension correlations to
reveal their inter-relationships (dimension correlation is used
since it is a typical measure of dimension relationships, but
other relationship measures can also be used). A rich set
of interactions were provided to facilitate navigation in the
display and generate lower dimensional spaces of interest. To
differentiate the ﬁrst version from the improved version, we
call it the Pixel MDS VaR display.

In the improved version of VaR presented in this paper,
these features are signiﬁcantly strengthened. A density-based
scatterplot [9], [24] has been added to the system as an alter-
nate approach to generating dimension glyphs. A Jigsaw map
layout [23] and the Rainfall metaphor have been added into the
system as alternate dimension glyph layout approaches. The
new version also supports a broader range of interaction tools
than the original version, including a new data item selection

2

Fig. 1.
(a) Illustration of the VaR display. On the left is the spreadsheet of a 4-dimensional dataset with each column representing a dimension. On the
bottom is a matrix that records the pair-wise relationships (such as correlations) among the dimensions. In the middle is the glyph of the fourth dimension.
On the right is the VaR display of the dataset. (b) The Pixel MDS VaR display of the Image-89 dataset (89 dimensions, 10,417 data itmes). (c) The X-Ray
scatterplot MDS VaR display of the same dataset.

and highlighting tool. The labeling issue, which was ignored in
the initial version, is addressed in this version. A case study is
included in this paper involving the visual analysis of a dataset
with 838 dimensions. A user study comparing the VaR display
with the rank-by-feature framework [19], [20] is also reported.
This paper is organized as follows. Section II reviews
related work. Section III brieﬂy introduces the original Pixel
MDS VaR display. Section IV presents the approach of us-
ing density-based scatterplots to generate dimension glyphs.
Section V describes the new Jigsaw and Rainfall dimension
glyph layout strategies. Section VI summarizes the correlation
calculation algorithm used in the VaR display. Section VII
presents the interaction tools. Section VIII addresses the
labeling issue. Section IX describes the implementation of
the VaR display and addresses the scalability issue.Section X
discusses visual exploration approaches with the VaR display.
Section XI presents a case study and Section XII presents
a user study for the VaR display. Section XIII presents our
conclusions and future work.

II. RELATED WORK

Many techniques exist for generating condensed displays
for large datasets. The work most related to our work is pixel-
oriented techniques and scatterplots. Pixel-oriented visualiza-
tion techniques [12], [13] are a family of multi-dimensional
display techniques that map each data value to a pixel on
the screen and arrange the pixels into subwindows to convey
relationships. The patterns of the subwindows may reveal
clusters, trends, and anomalies. Pixel-oriented techniques are
one among several options to create the dimension glyph in
the VaR display.

Scatterplots visualize 2-D datasets or 2-D projections of
multi-dimensional datasets. In a scatterplot, there is a hori-
zontal axis and a vertical axis, which are associated with two
dimensions (X and Y). The data items are plotted onto the
display according to their coordinates on X and Y. Scatterplots
are widely used since they provide rich information about the

relationship between two dimensions, such as strength, shape
(line, curve, etc), direction (positive or negative), and presence
of outliers [18]. Density-based scatterplots [24], [9] scale to
large datasets by using intensity of the spot in a scatterplot
to indicate the data density in that spot. We use the density-
based scatterplot as an option for generating the dimension
glyph and treat the areas with no data items in a scatterplot in
a different way from existing approaches due to the possible
overlaps among the scatterplots.

Scatterplots of multi-dimensional datasets are often orga-
nized together to show multiple 2D projections of the datasets.
Scatterplot matrices [7] organize the scatterplots of all N x (N-
1)/2 2-D projections of an N-dimensional dataset into a matrix.
Scatterplot matrices easily get cluttered when the number of
dimensions increases. Rather than displaying all 2D projec-
tions, we display N scatterplots between all dimensions and
a focus dimension and position them in a manner conveying
dimension relationships in our density-based scatterplot VaR
option.

There exist multiple visualization approaches to examining
relationships among dimensions to discover lower dimen-
sional spaces with signiﬁcant features. The rank-by-feature
framework [19] ranks 1D or 2D axis-parallel projections of
multi-dimensional datasets using statistical analysis to help
users detect 1D or 2D projections with desired features such
as linearly related dimensions. [16] visualizes correlations
between each pair of dimensions in a matrix and allows users
to interactively select dimensions from the matrix to con-
struct lower dimensional spaces. The interactive hierarchical
dimension reduction approach [28] visually conveys dimension
relationships using a dimension hierarchy to facilitate lower
dimensional space construction. The VaR display is different
from these approaches since it integrates data value visual-
ization with dimension relationship visualization in the same
display to use screen space more efﬁciently.

Multi-dimensional Scaling (MDS) [4], [15] is an itera-
tive non-linear optimization algorithm for projecting multi-

dimensional data down to a reduced number of dimensions.
It is often used to convey relationships among data items
of a multi-dimensional dataset. For example, IN-SPIRE [25]
uses MDS to map data items from a document dataset to
a 2D space. It generates a Galaxies display as a spatial
representation of relationships within the document collection.
In our approach, MDS is used in a different way, namely to
convey relationships among dimensions rather than data items.
The Jigsaw map [23] is a recent space ﬁlling hierarchy
layout method. By placing the leaf nodes of a hierarchy into
a 1D layout using a depth ﬁrst traversal and mapping the
1D layout
into a rectangular 2D mesh using space-ﬁlling
curves, this method creates hierarchy displays of nicely shaped
regions, good continuity and stability. When all leaf nodes are
of the same size, a Jigsaw map can draw all leaf nodes without
any distortion in shape, namely, they can be all equal-sized
squares. This property of the Jigsaw map makes it a perfect
option for us to lay out dimensions organized into a hierarchy
on a 2D mesh, with each dimension drawn as a square glyph.
The similarity based dimension arrangement proposed in
[1] also addressed the problem of arranging pixel oriented
subwindows (dimensions) on a 2D mesh. It aimed to place
similar dimensions close to each other on the 2D mesh. The
Jigsaw map dimension layout is different in that it aims to
use the dimension layout to convey the hierarchical structure
among the dimensions. As a consequence, not only similar
dimensions but also outlier dimensions are revealed.

[29] presents a multi-dimensional visualization technique
called Dust & Magnet. It represents dimensions as magnets
and data items as dust particles and attracts dust particles using
magnets to reveal data item values in the dimensions. The
Rainfall metaphor proposed in this paper was inspired by Dust
& Magnet. The difference is that the Rainfall metaphor attracts
dimensions using dimensions, while Dust & Magnet attracts
data items using dimensions.

III. PIXEL MDS VAR DISPLAY

Figure 1a illustrates the approach to generating a Pixel
MDS VaR display. First, a dimension glyph, called a glyph in
short, is generated to represent data values in each dimension,
i.e., values in the same column in the spreadsheet, using
pixel oriented techniques [13]. In particular, each value is
represented by a pixel whose color indicates a high or low
value, and pixels representing values from the same dimension
are grouped together to form a glyph. In a glyph, each pixel
occupies a unique position without overlap. In the original
version, a spiral pixel layout was used. Rows in the spreadsheet
are ordered according to their values in one dimension (Note:
actually any 1D order can be used). Data values in each
column are positioned into a spiral according to this order. In
all glyphs, pixels representing values in the same row occupy
the same position so that glyphs can be associated with each
other.

Second, the correlations among the dimensions are cal-
culated and recorded into an N x N matrix (where N is
the dimensionality of the dataset). In order to calculate the
correlations, different approaches can be used according to

3

different purposes. For example, if users are most interested
in linearly related dimensions, Pearson’s correlation coefﬁ-
cient can be used to capture the linear relationships among
dimensions. We proposed a scalable and ﬂexible correlation
calculation algorithm [27] and applied it in the VaR display.
We will brieﬂy introduce it in Section VI for the purpose of
completeness.

Third, the N x N relationship matrix is used to generate N
positions in a 2-D space, one position for each dimension. The
proximity among the positions reﬂects relationships among
the dimensions, i.e., closely related dimensions are spatially
close to each other, and unrelated dimensions are positioned
far way from each other. In particular, a multi-dimensional
scaling algorithm [4] is used to create the 2-D positions upon
the relationship matrix.

Finally, the dimension glyphs are placed in the 2-D space
in their corresponding positions to form the VaR display.
Figure 1b shows an example of the VaR display. It shows
the Image-89 dataset of 89 dimensions and 10,417 data items.
It is a real dataset containing 88 low level visual attributes
and classiﬁcation information for 10,417 image segments
generated by an image analysis approach [8]. In the ﬁgure,
each block is a dimension glyph and there are 89 glyphs.
In each glyph, data values of the dimension are mapped to
colors of pixels, and pixels are ordered in a spiral manner. The
closeness of the glyph positions reveals the correlations among
the dimensions calculated by the underlying algorithm. For
example, several clusters of closely correlated dimensions and
a few dimensions that are distinct from most other dimensions
can be detected from the glyph positions in Figure 1b.

The above approach can be summarized as dimension glyph
generation and layout. Glyphs explicitly convey data values
and their layout explicitly conveys dimension relationships.
Moreover, dimension relationships are also revealed by the
patterns of the glyphs. Similarity among glyph patterns in-
dicates dimension relationships, whether there is a linear or
non-linear relationship, or they are partially correlated (such
as dimensions for which a subset of the data items is closely
related). Since humans are good at pattern recognition, the
patterns of the glyphs provide straightforward and intuitive
comparison of the dimensions. On the one hand, the layout
approach brings related dimensions close to each other to make
the pattern comparison easier. On the other hand, the patterns
allow users to conﬁrm or refute the relationships suggested by
the layout using their eyes, and reveal how the dimensions are
related in detail.

Besides the techniques used in the original VaR display,
there are other approaches to creating glyphs and laying them
out, which will be introduced in the following sections. Since
glyph generation and layout are independent from each other,
they can be combined freely to form various VaR displays.

IV. DIMENSION GLYPH ALTERNATIVE: X-RAY

SCATTERPLOTS

The glyph generation approach used in the original VaR
display is not the only approach for creating dimension glyphs.
For example, different layouts of the pixels within a glyph

reveal different patterns. As an example, organizing pixels
into a calendar pattern according to the time stamps of the
data items can reveal time-dependant patterns among the data
items. Since these techniques have been widely studied in
pixel-oriented techniques [12] and they can be integrated
into the VaR display easily by replacing the original pixel-
oriented dimension glyph generation approach, they will not
be discussed in this paper. Instead, we present our work
on customizing a density-based scatterplot glyph (called an
X-Ray glyph) generation approach. This approach has been
introduced into the improved version (see Figure 1c for an
example VaR display using the scatterplot approach).

In the VaR display, a scatterplot

is generated for each
dimension. The Y dimension of a scatterplot dimension glyph
is the dimension it represents, while all of the glyphs have the
same X dimension. We choose to use the same X dimension
since it will be hard for users to associate different dimension
glyphs if both X and Y dimensions change from one glyph
to another. Although this causes information loss, users can
always interactively change the X dimension guided by the
semi-automatic selection tool (see Section VII) and their visual
exploration (see Section XI).

The VaR display is targeted at large datasets. It is time
consuming to draw the projection of each data item on each
of the N scatterplots. Also, the large number of projections
would clutter the glyph. In order to avoid clutter and increase
scalability, we store each glyph as an M X M pixel matrix,
where M is an adjustable integer, and divide the 2D space
within the value range of the dataset into M X M equal-
size bins. The number of projections falling into each bin
is recorded and translated into the color of its corresponding
pixel in the pixel matrix. In particular, the intensity of the pixel
is proportional to data density of the area it represents.

Fig. 2. X-Ray Scatterplots (a) The ﬁrst solution (b) The second solution (c)
The X-Ray scatterplot solution.

The ﬁrst image (Figure 2a) we generated is disappointing,
since it is hard to differentiate unoccupied area (areas with
zero data items) from areas with a few data items. In order
to solve this problem, we assign a different hue to the pixels
representing unoccupied areas. In the image generated (Figure
2b), there are no data items in the blue area. We then observed
that,
to glyphs generated using pixel-oriented
techniques where every pixel represents a data value, there
are often large contiguous unoccupied areas in a scatterplot
glyph, especially when the X and Y dimensions are closely
related. Recalling that some glyph layout approaches, such

in contrast

4

as MDS, could cause overlaps among different glyphs, we
made the unoccupied areas semi-transparent so that users can
see hidden glyphs through the unoccupied areas of the hiding
glyphs. Figure 2c shows this ﬁnal solution. Since in the ﬁgure
the glyphs look very much like X-Ray photos, we named
this VaR display the X-Ray scatterplot VaR display. To give
users more ﬂexibility, we allow them to interactively choose
the color and transparency of the unoccupied areas. If users
dislike the semi-transparent unoccupied areas, they are able to
set them to opaque.

V. DIMENSION LAYOUT ALTERNATIVES: JIGSAW MAP

LAYOUT AND RAINFALL

A. Jigsaw Map Glyph Layout

The MDS approach is effective in conveying dimension
relationships. However, using the MDS approach, the positions
of two glyphs could be very close to each other if they are
closely related. Glyphs might overlap in this case, which is
sometimes undesired by the users. Besides allowing the users
to reduce overlaps in the MDS layout using interactions (see
Section VII), we propose a Jigsaw Map dimension layout
based on the recently proposed Jigsaw map [23]. In this
approach, dimensions are grouped into a dimension hierarchy.
The Jigsaw map, which is a space-ﬁlling hierarchy visualiza-
tion method, is then used to lay the dimensions on a grid.
This approach not only prevents glyphs from overlapping, but
also conveys the hierarchical structure among the dimensions.
Figure 3 shows VaR displays with a Jigsaw layout.

The motivation of this approach is that grouping dimensions
of high dimensional datasets into dimension hierarchies makes
it easy to capture the relationships among the dimensions.
In a dimension hierarchy, dimensions are organized into a
hierarchy of clusters. Dimensions within a cluster have closer
relationships among each other than with dimensions outside
the cluster. Clusters in different levels of the hierarchy divide
the dimensions into groups of different granularity. With the
dimension relationship matrix, it is convenient to generate
a dimension hierarchy using existing hierarchical clustering
approaches. In the hierarchy, each leaf node is a dimension in
the high dimensional dataset.

In order to turn the dimension hierarchy into the dimension
layout, we examined existing hierarchy visualization tech-
niques. The basic requirements are 1) the layout should be
space efﬁcient since our target is high dimensional datasets
and 2) each dimension should be assigned a space of the
same size, shape and orientation since it is difﬁcult for users
to compare and associate glyphs with different sizes, shapes,
or orientations. Since node-linked diagrams do not use space
efﬁciently, we only considered the space-ﬁlling hierarchy
visualization techniques [3], [21], [23]. Among them, only
the Jigsaw map [23] and quantum treemaps [3] are capable
since all other techniques assign areas of different shapes or
orientations to leaf nodes. We chose the Jigsaw map since it
generates layouts of nicely shaped regions and is stable with
regards to changing tree structures and leaf nodes [23].

To generate the Jigsaw map layout, we ﬁrst hierarchically
cluster the N dimensions in a dataset based on their pair-
wise distances (a pair of more closely related dimensions

5

Fig. 3. The Image-838 dataset (838 dimensions, 11,413 data items). (a) The Pixel Jigsaw map VaR display with separated dimensions selected and labeled
(b) The X-Ray scatterplot Jigsaw map VaR display with dimension Coarseness as the X dimension. The X dimension is in a pink frame and labeled. (c)
The X-Ray scatterplot Jigsaw map VaR display with dimension angle 135 as the X dimension. The X dimension is at the left bottom corner of the map and
dimensions closely related to it are in red frames. (d) A zoomed in display of the selected dimensions with their labels shown.

has a smaller distance than a pair of less related dimensions)
using the minimum single linkage metrics [17]. Then, the N
dimensions are ordered into a 1-D sequence according to their
positions in the hierarchy using a depth-ﬁrst traversal of the
hierarchy, and then the sequence is mapped to a 2-D L x K (
L x K >= N) mesh by applying a space-ﬁlling curve called
an H curve (please refer to [23] for more details). Figure 3a
shows an example of the Jigsaw layout. In this ﬁgure, similar
dimensions are close to each other and signiﬁcant boundaries
of groups of closely related dimensions, such as the group of

dimensions in the left bottom part of the map, can be detected.
Outlier dimensions, such as the dimensions on the left top part
of the map, are also distinguishable since their textures look
different from their neighbors.

B. Rainfall Metaphor

When exploring a high dimensional dataset, users are often
interested in the relationships between a single dimension of
interest with all other dimensions. Beside the X-Ray scatter-
plot, which reveals the relationships using glyph textures, we

6

Fig. 4. The Rainfall Metaphor. (a) At the beginning of the rain. Dimensions more closely related to the dimension of interest in the bottom are falling in a
faster acceleration than less related dimensions. (b) The rain continues. The dimensions with different correlations to the dimension of interest are separated.
It can be seen that there are roughly three levels of association between the dimension of interest and other dimensions. (c) The Rain is close to its end.
Dimensions signiﬁcantly distinct from the dimension of interest are revealed. The dataset is the Image-89 dataset. The glyphs are pixel-oriented glyphs (pixels
are ordered in a line by line (horizontal lines) manner.

provide a simple animation approach to dynamically illustrate
the relationships by changing glyph positions. This approach is
named the Rainfall Metaphor since it imitates rain (see Figure
4 for an example).

In the beginning of the animation, the dimension of interest
is placed in the center bottom of the display (the ground) and
all other dimensions (raindrops) are placed in the top of the
display (the sky). The horizontal positions of the raindrops
are randomly generated. After the rain starts, a raindrop falls
toward the ground in an acceleration that is proportional to
its correlation with the dimension of interest. Thus, a raindrop
moves toward the ground faster than another raindrop if it has
a closer relationship to the dimension of interest. A raindrop
stops its movement after it hits the ground. There is a timer
that starts from the beginning of the rain and ends when
all raindrops hit the ground. Users can interactively play the
animation by moving the slider representing the timer. Users
can also interactively select the dimension of interest for the
animation.

Figure 4a-c shows some screen captures of the Rainfall
layout. Using this metaphor, users can focus on the relation-
ships between the dimension of interest and other dimensions,
without being distracted by relationships among the other
dimensions. In different moments of the rain, either similar
dimensions or distinct dimensions to the dimension on the
ground attract the users’ attention.

VI. CORRELATION CALCULATION

In the VaR display, a binning based correlation calculation
algorithm is used. We only brieﬂy introduce it here since
it has been presented in full detail in [27]. We claim that
any relationship calculation algorithm can be used in the VaR
display as long as it scales to large datasets. The layout of
the glyphs reﬂects the type of relationship calculated by the
underlying algorithm.

In our algorithm, distribution of the value differences (be-
tween the different dimensions for the same data item) is
recorded into bins. In particular, the possible range of value
differences between a pair of dimensions is divided into a
sequence of bins. The number of data items whose value
differences between these two dimensions fall into the bins is
recorded. For an N dimensional dataset, N x (N-1)/2 sequences
of bins (one sequence for each pair of dimensions) are created.
A pair of dimensions is considered to be closely related if
a large number of data items fall info a small number of
bins (K) in its sequence. With a given K, the correlations
can be calculated in this way: sort the bins in the sequence
according to their populations, and sum up the populations
of K bins with the highest populations. The sum divided by
the total population of the data items is proportional to the
correlation between the dimensions. K is selected to be the
number of bins that make the global variance of correlations
for all dimensions maximum. This algorithm scales to a large
number of data items. Except for the ﬁrst scan, which can
be done with minimal cost when inserting the dataset into
the database, its efﬁciency is only related to the number of
dimensions.

The above algorithm is a heuristic approach whose purpose
is to maximize the visibility of the structure of the MDS and
Jigsaw layout. There are many other optimization problems
in the VaR display, such as selecting a dimension ordering
the pixel-oriented display in the initial view to provide the
maximum information to users at a ﬁrst glance. A detailed
discussion of such problems is presented in [27] and not
repeated here.

VII. INTERACTIVE TOOLS IN THE VAR DISPLAY

A rich set of interaction tools has been developed for the
VaR display. Navigation tools help users reduce clutter in the
display and discover information about the dataset. Automatic
and manual dimension selection tools allow users to perform

human-driven dimension reduction by selecting subsets of
dimensions for further exploration in the VaR display as well
as other multi-dimensional visualizations. Data item selection
tools allow users to select subsets of data items for further
exploration. In addition, the data item masking tool allows
users to examine details of selected data items within the
context of unselected data items.

Most of the interactive tools make no special assumption
about the glyph positioning and generation strategies, i.e., they
can be applied to any realization of the VaR display. These
tools are called general tools. Unless speciﬁcally noted, an in-
teraction tool is a general tool in the following sections, where
details of each navigation and selection tool are presented.

A. Tools for Glyph Layout

The MDS dimension layout causes overlaps among the
glyphs. Overlaps emphasize close relationships among the
dimensions because glyphs overlap only if their dimensions
are closely related. However, overlaps can prevent a user
from seeing details of an overlapped glyph. We provide the
following operations to overcome this problem (see [27] for
more detail).

(cid:129) Showing Names: By putting the cursor on the VaR
display, the dimension names of all glyphs under the
cursor position are shown in a message bar. Thus a user
can be aware of the existence of glyphs hidden by other
glyphs.

(cid:129) Layer Reordering: With a mouse click, a user can force
a glyph to be displayed in front of the others. In this
way he/she can view details of a glyph that is originally
overlapped. Users can also randomly change the ordering
of all dimension glyphs by clicking a button in the control
frame. In addition, selected dimensions are automatically
brought to the front of the display.

(cid:129) Manual Relocation: By holding the control key, a user
can drag and drop a glyph to whatever position he/she
likes. In this way a user can separate overlapping glyphs.
(cid:129) Extent Scaling: Extent scaling allows a user to interac-
tively decrease the sizes of all the glyphs proportionally to
reduce overlaps, or to increase them to see larger glyphs.
(cid:129) Dynamic Masking: Dynamic masking allows users to
hide the glyphs of unselected dimensions from the VaR
display.

(cid:129) Automatic Shifting: This operation automatically re-
duces the overlaps among the glyphs by slightly shift-
ing the positions of the glyphs. There are many more
advanced overlap reducing algorithms that can be used,
such as those listed in [22].

(cid:129) Distortion: Users can interactively enlarge the size of
some glyphs while keeping the size of all other glyphs
ﬁxed. In this way users are allowed to examine details
of patterns in the enlarged glyphs within the context
provided by the other glyphs.

(cid:129) Zooming and Panning: Users can zoom in, zoom out
and pan the VaR display. For example, in order to reduce
overlaps, sometimes the size of the glyphs has to be set
very small when there are a large number of dimensions.

7

Zooming into the display will enlarge the glyphs so that
the user can have a clear view of the patterns in the
glyphs.

(cid:129) Reﬁning: A reﬁned VaR display can be generated for
a selected subset of dimensions and a selected subset
of data items. The selected dimensions and data items
are treated as a new dataset. The relationship calculation,
glyph generation and positioning are applied to the new
dataset.

B. Tools for Glyph Regeneration

In the Pixel-Oriented dimension glyphs, the dimension used
to sort the data items affects the glyph patterns signiﬁcantly.
Clusters in subspaces including this dimension can be easily
detected while clusters in other subspaces are not. Similarly, in
the X-Ray scatterplot dimension glyphs, relationships between
other dimensions and the X dimension are easier to detect
than relationships among other dimensions. We allow users to
interactively select the sorting dimension in the pixel-oriented
mode and the X dimension in the X-Ray scatterplot mode
by clicking the mouse button on the glyph of the desired
dimension or selecting from a combo-box.

In addition, a comparing mode can be used in the pixel-
oriented glyphs in order to compare the dimensions with a
dimension of interest. In this mode, except the glyph of the
base dimension, the pixels of all other glyphs will be colored
according to the differences between the values of the base
dimension and their dimensions. A ﬁgure of the comparing
mode can be found in [27].

C. Dimension Selection Tools

Dimension selection tools enable users to select dimen-
sions of interest for further exploration using other multi-
dimensional visualization techniques. They can also be used
as a ﬁlter to reduce the number of glyphs displayed in a VaR
display, since we allow users to hide glyphs of unselected
dimensions using dynamic masking (see Section VII-A). The
selection tools we provide to users include automatic selec-
tion tools for closely related dimensions and well separated
dimensions, in addition to manual selection.

The automatic selection tool for related dimensions
takes a user-assigned dimension and correlation threshold as
input. Here we assume that a pair of more closely related
dimensions has a larger correlation measure than a pair of
less related dimensions. Users pick the assigned dimension by
clicking its glyph and adjust the threshold through a slider. The
tool automatically selects all dimensions whose correlation
measures to the input dimension are larger than the threshold
by traversing the dimension relationship matrix. This tool
enables the users to select a set of closely related dimensions.
The automatic selection tool for separated dimensions
takes a user-assigned dimension and correlation threshold
as input and returns a set of dimensions that describe the
major features of the dataset. The assigned dimension will
be included in the returned set of dimensions. Between each
pair of dimensions in the result set, the correlation measure is
smaller than the threshold. For any dimension that is not in

8

Fig. 5. Masking of Unselected Data Items. Unselected data items are covered by a mask with adjustable color and transparency. (a) No mask or fully
transparent mask. (b) Opaque mask. (b) Semi-transparent mask. The dataset is the Image-89 dataset. The glyphs are pixel-oriented glyphs (pixels are ordered
in a line by line (vertical lines) manner.

the result set, there is at least one dimension in the result set
whose correlation measure with it is larger than the threshold.
Using this tool, a user is able to select a set of dimensions
to construct a lower dimensional subspace revealing the major
features of the dataset without much redundancy. In Figure 1b
separated dimensions selected automatically are labeled.

The following algorithm can be used for automatic selection

of separated dimensions:

1) Get the assigned dimension and the selection threshold.
2) Set the assigned dimension as “selected” and all other

dimensions as “unselected”.

3) Find all unselected dimensions whose correlation mea-
sures to all existing selected dimensions are smaller than
the threshold. Mark them as “candidates”.

4) If there is no candidate dimension, go to step 5. Else, set
one candidate dimension as “selected” and every other
candidates as “unselected”. Go back to step 3.

5) Return all dimensions marked as “selected”.
It is interesting that it is not deﬁned how to pick one dimen-
sion among the candidate dimensions in step 4. Thus it can
be customized according to the task of interest. For example,
in Section VIII, this approach is customized to reduce the
clutter among the labels of the selected dimensions for a good
labeling result. Here we present another customization.

When users start to explore an unknown dataset, it is often
desired to ﬁnd dimension groups containing large numbers of
closely related dimensions. Thus a heuristic approach can be
used in step 4: setting a threshold, for each candidate dimen-
sion counting the number of dimensions having correlation
measures to it that are larger than the threshold, and selecting
the dimension with the highest count. Using this approach
dimensions with a larger number of closely related dimensions
have higher priority to be selected.

Manual selection allows a user to manually select a dimen-
sion by clicking its corresponding glyph. The user can unselect
the dimension by clicking the glyph again. The combination of
manual and automatic selection makes the selection operation

both ﬂexible and easy to use.

D. Data Item Selection and Masking Tools

Rather than allowing a user to select data items directly from
the glyphs in the VaR display (which is hard when glyphs
are small), we allow the user to select data items from a
dialog. Firstly, the user selects a dimension name from a name
list in the dialog. Then a brief summary of the dimensions
will be provided to help the user set up the selection criteria
for the selected dimension. If the dimension is a categorical
dimension, the distinct values in that dimension as well as the
number of data items for each value will be provided. The user
can then select the desired distinct values. If the dimension is
a numeric dimension, a histogram of the dimension will be
provided. The user then set up a minimum value and maximum
value for the selection using two sliders. The user can set the
selection ranges for multiple dimensions.

After the user sets the selection criteria, he/she can click a
button in the dialog to trigger the selection. A problem here is
how to highlight the selected data items. In most visualization
systems, selected data items are highlighted using either a
special color, or a surrounding box around the selected items.
However, in the VaR display with pixel-oriented techniques,
color has been used to represent the values, and it is hard
to put a surrounding box in a condensed glyph, especially if
the selected data items are not adjacent to each other in the
glyphs.

A straightforward solution to this problem is to display only
the selected data items. This is a general solution suitable for
all realizations of the VaR display. However, a drawback of
this approach is that the context provided by unselected data
items is lost. Such a context is often useful. For example, the
users might want to compare the selected data items with the
unselected data items among the dimensions.

In order to overcome this drawback, we developed an
approach called data item masking. This approach is only
useful for VaR displays using pixel-oriented techniques. In

9

Fig. 6. Labeling Solutions (a) All dimensions are labeled with names (b) Dimensions selected by the labeling algorithm are labeled. Clutter is reduced. (c)
Angled text is used to label all dimensions in the Jigsaw map layout. The dataset is the Image-89 dataset.

according to the following two heuristic criteria: 1) they should
be distinct dimensions, i.e., two similar dimensions should
not be labeled at the same time. Dimensions distinct from all
other labeled dimensions should be labeled. 2). they should be
separated from each other as much as possible to avoid clutter
on the screen. In addition, we allow users to interactively
change the number of dimensions labeled to get a less cluttered
view or to see more labels.

Criterion 1 is exactly the criterion used for automatic se-
lection of separated dimensions (see Section VII-C). Criterion
2 adds more constraints to the selection. Recall that there is
some freedom in step 4 of the selection algorithm, i.e., any
dimensions in the candidate dimension set can be selected; we
modiﬁed the algorithm for labeling as follows:

1) Assign a dimension and a selection threshold.
2) Set the assigned dimension as “selected” and all other

dimensions as “unselected”.

3) Find all unselected dimensions whose correlations with
all existing selected dimensions are smaller than the
threshold. Mark them as “candidates”.

4) If there is no candidate dimension, go to step 5. Else, set
the candidate dimension which is the most far way on
the screen from its closest existing selected dimension
as “selected” and other candidates as “unselected”. Go
back to step 3.

5) Return all dimensions marked as “selected” and label

this approach, both selected and unselected data items are
drawn on the screen. Unselected data items are covered by
a mask. Users can interactively change the color of the mask,
and adjust the transparency of the mask though a slider. When
the mask is opaque, as shown in Figure 5b, unselected data
items are hidden. When the mask is fully transparent, as shown
in Figure 5a, the selected data items are not highlighted. When
the mask is semi-transparent, as show in Figure 5c, the selected
data items are highlighted within the context provided by
the unselected data items. Users can interactively change the
transparency of the mask to adjust the strength of the context.
The implementation of this masking operation is simple.
First, a mask is generated using an approach similar to the
generation of a normal dimension glyph. The only difference
is that the pixels are set to be transparent for selected data
items and with user assigned color and transparency for
unselected data items. Our mask generation mechanism has
no dependency on the order of the data items,
is
not necessary for the selected data items to be adjacent to
each other in the glyphs. Since the color and shape of the
masks are the same for all
the mask is only
generated once, stored as a texture object, and pasted in the
front of all the glyphs. Since the texture mapping operation is
efﬁcient in OpenGL, displaying masks has minimal effect on
the rendering of a VaR display.

the glyphs,

i.e.,

it

VIII. LABELING

them.

In the original version of the VaR display, dimension names
are labeled horizontally in the middle top region above the
dimension glyph for all dimensions shown on the screen (see
Figure 6a). The labels clutter the screen seriously for a high
dimensional dataset, thus we did not provide the labeling
option to users. Rather, when users moved the cursor over
a glyph, the glyph name showed in the message bar below
the display. However, users complained that ﬁnding dimension
names in this way was tiring. They argued that the VaR display
without dimension labels is much less meaningful than one
with names labeled. In order to solve this problem, we chose to
label a subset of dimensions on the screen for the MDS layout
(see Figure 6b). The dimensions to be labeled are selected

When calculating the screen distance between two dimen-
sions in step 4, we must consider the fact that horizontal labels
are used. Their lengths are much larger than their widths.
Assume that labels have 5 characters on average and the
characters have equal height and width, the screen distance
between two dimensions d1 and d2 D(d1, d2) = fabs((d1.x
- d1.x)) + 5 * fabs((d1.y - d2.y)), where x and y are the
screen coordinates of the dimensions. The equation means that
we prefer dimensions separated in the vertical direction than
the horizontal direction. Figure 6b shows the same display as
Figure 6a with selected dimensions labeled using the above
algorithm.

The same labeling approach can be applied to the Jigsaw

map layout. In addition, since the glyphs are placed in a regular
mesh in the Jigsaw map, applying an angle on all the labels
greatly reduces the clutter on the screen even when all labels
are shown. Figure6c shows the Image-89 datasets in the Jigsaw
map layout with all dimension names displayed at a 20 degree
angle. Almost all of the dimension names can be distinguished
from this display.

In our prototype we bind labeling with selections,

i.e.,
users have the option to show labels of selected dimensions
only. When a user chooses this option and uses the automatic
selection tool for separated dimensions, it is exactly the above
clutter-reducing labeling approach. When a user uses the
selection tool for related dimensions, the dimensions closely
related to the user-assigned dimensions are labeled (see Figure
3d for an example).

IX. IMPLEMENTATION AND SCALABILITY ISSUE

When there are several hundred dimensions, the datasets
can easily contain millions of data values even if they only
contain thousands of data items. Datasets often have a higher
number of data items. Such large datasets not only cause large
response time during interactions and problems in storing the
data structures in a visualization system, but also cause clutter
on the display. Scalability is a critical issue for visualization
systems aimed at high dimensional datasets.

We have implemented a fully working prototype of the VaR
display. The biggest dataset that has been successfully loaded
into the VaR display so far is an image classiﬁcation dataset
containing 838 dimensions and 11413 data items, which means
over 9 million data values (see Figure 3 for its VaR display).
Most interactions can be processed within a few seconds on a
typical PC for this dataset. This dataset is the biggest dataset
we currently have. In the future, we will test larger datasets
on the prototype.

The critical techniques we used in the prototype for increas-
ing scalability are texture mapping, binning, and sampling
techniques. Using the texture mapping techniques provided by
OpenGL, our prototype stores all dimension glyphs (including
the mask in the masking operation) as texture objects and
pastes them on the screen as needed. As long as the glyph
textures do not change,
the dataset does not need to be
rescanned, which is time consuming for large datasets. By
keeping the texture objects small (such as hundreds of pixels),
which is reasonable since each dimension glyph will not be
too big on the screen in order to reduce clutter, the system can
draw hundreds of dimension glyph textures on the screen in
almost real time. This approach greatly reduces the response
time for most interactions because, except for reordering for
pixel-oriented glyphs and resetting the X dimension for X-Ray
scatterplot glyphs, almost all other interactions do not change
the glyph textures. Rather, they refresh, resize, reposition, or
reorder the glyphs.

According to our experience, drawing fonts in OpenGL is
a time consuming task. Our prototype stores all dimension
name labels as texture objects. These texture labels are created
one time, and can be quickly pasted on the screen until users
change the contents or colors of the labels. The texture labels
can be scaled and rotated easily on the screen.

10

Binning, i.e., using buckets to stored statistic information
about groups of values rather than recording them individually,
is an approach widely used in data mining techniques for large
datasets. We use binning techniques to increase the speed of
the correlation calculation algorithm (see section VI) and the
X-Ray scatterplot glyph generation (see section IV).

The prototype stores datasets in an Oracle database server.
It dynamically requests data from the server when needed,
making use of the sorting and query functions provided by
the database server. When generating a VaR display for a
dataset containing a large number of data items, we use a
random sampling approach to reduce the response time for
fetching data items from the server, as well as the number
of values to be processed. In particular, the system keeps a
default maximum number. When the number of data items
contained in a dataset exceeds it, a uniform random sampling
is performed on the dataset to only fetch the maximum number
of data items. Users are allowed to interactively adjust the
maximum number in order to trade between the response time
and visualization accuracy.

Random sampling is easy to implement. However, it has
the big drawback that a large sampling rate is needed in order
to reduce small group loss in the samples [6]. In order to
overcome this problem, many solutions have been proposed,
such as biased sampling [14] or dynamic sample selection
[2]. It has been shown in the literatures that these approaches
successfully reduce small group loss. We will explore these
approaches in the future.

X. DISCUSSION

The VaR display can serve as an overview tool for a high
dimensional dataset. Starting from the VaR display, other
visualization techniques can be used for more detailed visual
analysis. For example, the VaR display is coordinated with
parallel coordinates, star glyphs, and scatterplot matrix views
in our prototype. Although these techniques could not handle
hundreds of dimensions, they work well in examining data
items and dimensions selected by the VaR display. Recently,
we completed an interesting project in coordinating the VaR
display with an image exploration interface. The VaR display
was used to show the high dimensional image content anno-
tations. Users were allowed to select images by contents from
the VaR display. The images were then examined in detail in
an image exploration interface. This work is described in [26].
The MDS and Jigsaw map glyph layout approaches have
their advantages and disadvantages. From its nature, MDS
is better in capturing high dimensional relationships than the
hierarchical approach. However, the non-overlap feature of the
Jigsaw map layout makes it a popular approach for users of
the VaR display thus far.

Although the pixel-oriented glyphs are mentioned less than
the X-Ray scatterplot glyphs in this paper, this is only because
the usage of the pixel-oriented techniques has been widely
studied and their effectiveness has been shown in many papers.
Compared to scatterplots, the pixel-oriented glyphs are more
effective in pixel usage since they make use of each pixel.
However, it is easier to compare the relationship between a

11

Fig. 7.
(a) The Pixel MDS VaR display of the Image-838 dataset with separated dimensions selected and labeled. (b)(c) The X-Ray scatterplot Jigsaw map
VaR display of the Image-89 dataset. The dimension in a yellow frame is non-linearly related to the X dimension. (c) The X-Ray scatterplot Jigsaw map VaR
display with another X dimension (the dimension highlighted by the yellow frame in (b)).

dimension of interest and all other dimensions using the scat-
terplot glyphs. Users ﬁnd it difﬁcult to compare the patterns
of pixel-oriented glyphs if they are far from each other.

Compared to scatterplot matrices, the X-Ray scatterplot VaR
display has its advantages and disadvantages. For datasets with
a small number of dimensions, scatterplot matrices might be
preferred since all possible axis-parallel 2-D projections are
provided in them. However, for datasets with tens, hundreds
or thousands of dimensions, the X-Ray scatterplot VaR display
might be preferred since it causes less clutter. Its disadvantage
that only part of possible 2-D projections are displayed is
leveraged by two facts: ﬁrst, dimension relationships conveyed
by the VaR display give strong hints on the shapes of the
undisplayed 2-D projections; second, users can interactively
access 2-D projections of interest through interactions.

Compared to approaches that rank the 1D or 2-D projections
according to their features and allow users to examine detail
of a projection by selecting it from diagrams or lists conveying
the ranking (such as the rank-by-feature framework [19]),
the VaR display also has its advantages and disadvantages.
Obviously for tasks such as ﬁnding the most linearly corre-
lated dimensions the ranking approaches are better choices.
However, the VaR display is better in helping users grasp the
global relationships among the dimensions.

XI. CASE STUDY

We have explored several real datasets using the VaR dis-
play, including the Image-838 dataset [8] with 838 dimensions
and 11,413 data items and the Image-89 dataset [8] with 89
dimensions and 10,471 data items. They all contain low level
visual attributes for image classiﬁcation. Image analysts are
interested in ﬁnding outlier dimensions that are uncorrelated to
most other dimensions, and dimensions representing a group of
correlated dimensions (a dimension cluster) in order to reduce
the number of low level visual attributes used in the image
classiﬁcation process.

For both datasets, we selected a Pixel MDS VaR display
with all dimensions displayed as the initial view, since the

pixel-oriented glyphs have a higher pixel usage efﬁciency
and the MDS display conveys dimension relationships more
accurately than the Jigsaw map layout. Figure 7a and Figure 1b
show the Pixel MDS VaR displays of the Image-838 dataset
and the Image-89 dataset respectively. From the ﬁgures, we
found that there are dimension outliers and clusters in both
datasets. We then applied automatic selections for separated
dimensions. Both outlier dimensions and dimensions repre-
senting dimension clusters were selected.

Then, we switched to the Jigsaw map layout. Figure 3a
shows the Pixel Jigsaw map VaR display of the Image-838
dataset. There are several distinguishable regions that can be
seen in the map where adjacent glyphs in the regions have
similar patterns. For example, there is a distinguishable region
composed of bright blue glyphs at the left bottom of the
map. If only one dimension is selected in such a region, it
means that the neighbors of the selected dimension are closely
related to it, since selection for separated dimensions was used.
Thus they are a dimension cluster and the selected dimension
can represent the cluster. The selected and labeled dimension
angle 135 at the left bottom corner is such a representative
dimension. Meanwhile, selected dimensions crowded together,
such as the selected dimensions in the left top of the map,
are potential outliers since they are distinct from their closest
neighbors. The selected and labeled dimension Coarseness at
the left top corner is such suspicious outlier.

In order to examine if dimension Coarseness is an outlier,
an X-Ray scatterplot VaR display was created using it as
the X dimension (see Figure 3b). From scatterplots in Figure
3b it can be seen that no other dimensions show strong
correlations with dimension Coarseness. Thus it is conﬁrmed
that dimension Coarseness is an outlier dimension.

Figure 3c examines if dimension angle 135 is a repre-
sentative dimension. The X dimension of the scatterplots is
dimension angle 135 and dimensions closely correlated to
dimension anagle 135 are selected and highlighted. It can be
seen that a large number of dimensions are selected and they
all contain a clear diagonal pattern which indicates a strong

linear correlation. Figure 3d shows a zoomed in display of the
selected dimensions in which their labels are shown.

A similar exploration approach was conducted for the
Image-89 dataset. An interesting pattern in this dataset was
found when we were examining dimension Channel Energy 5
using the X-Ray scatteplot Jigsaw map VaR display (Figure
7b): there was a glyph with a curved band (the glyph with a
yellow frame, the frame was manually added into the ﬁgure
for highlighting). It seemed that
this dimension was non-
linearly related to the target dimension. It raised our interest
and became our next target.

We clicked this dimension to set it as the X dimension in
the X-Ray scatterplots and got Figure 7c. It is labeled in
Figure 7c as Texture Brightness DC. Figure 7c shows that
dimension Texture Brightness DC is non-linearly related to
most dimensions in this dataset. The curved bands are fairly
thin in some dimensions, which means strong non-linear
relationships.

XII. USER STUDY

A user study has been conducted to evaluate the VaR display
by comparing it to the Rank-by-Feature feature of HCE [19].
To form a comparable study, we considered the X-Ray scat-
terplot glyph style of VaR and the scatterplot prism from the
HCE system, namely its 2D projection ranking, selection and
visualization feature. In HCE, 2D projections are ranked by
features such as strength of linear relationship or least square
error for curvilinear regression. The ranking is visualized in
both a matrix and a list. A window beside the ranking windows
shows the scatterplot of the 2D projection selected by the user.
Our assumption was that the VaR display would better help
users grasp global relationships among the dimensions in a
high dimensional dataset. The reason is that VaR provides a
detailed view of all dimensions at the same time while users
of HCE need to take efforts to associate multiple dimensions
since they can only examine a few detailed views at the same
time.

Eight subjects participated in the user study. The subjects
vary in educational backgrounds: one was a psychology grad-
uate student, two were computer science undergraduate stu-
dents, three were graduate students in the ﬁeld of visualization,
and two were researchers/post-doctorates in visualization. The
subjects completed the user study one by one on the same
computer with the same instructor. Each subject tested both
systems. The order of using VaR and HCE was alternated for
the subjects.

The study began with a 10 minute training session using
both VaR and HCE and a further 10 minutes to allow subjects
to explore the tools and ask the instructor questions. A set of
tasks were then completed by the subjects using both tools. A
post-test survey to ﬁnd user preferences and a discussion were
conducted immediately following the completion of the tasks.
We used the Image-89 dataset of 89 dimensions and 10,471
data items. As shown in the case study (Section XI), there
are some strong linearly related dimensions and some strong
non-linearly related dimensions in the Image-89 dataset.

The ﬁrst

task was to describe relationships between a
given dimension and each of the other dimensions using the

12

scatterplot displays by approximating the numbers of different
scatterplot shapes involved with the given dimension. Samples
of typical shapes, such as diagonal thin straight bands for lin-
ear relations, curved bands for non-linear relations, and evenly
distributed scatterplot indicating unrelated dimensions were
provided to users. The second task required users to describe
relationships among ﬁve randomly assigned dimensions using
their scatterplot shapes.

The majority of users performed the ﬁrst task quicker and
evaluated the task to be easier using the VaR display. The
average time was 3.2 minutes and the standard deviation was
0.5 minutes for VaR, and the average time was 4.7 minutes
and the standard deviation was 3.2 minutes for HCE. On a
scale of 0 (hard) to 5 (easy), the mean scores of 3.5 and 2.1
were given to VaR and HCE respectively. A similar trend was
identiﬁed in the second task: the average time was 3.5 minutes
and the standard deviation was 0.4 minutes for VaR, and the
average time was 8.5 minutes and the standard deviation was
2.9 minutes for HCE. The scores are 3.6 for VaR and 1.0 for
HCE. Results from these tasks highlighted the advantage of
the VaR display in providing a global view of the dimension
relationships.

Qualitative results and qualitative feedback from the post-
test survey were also encouraging. Users typically preferred
using VaR over HCE for the given tasks. The reasons given
by each user were generally similar and can be summarized by
the ability to examine details of multiple relations on a single
display. One user in the study preferred HCE over VaR due to
the more detailed and visible scatterplots in the HCE system.
Users were also asked if they agreed with the statement “this
tool is useful for exploring high dimensional data”. On a scale
of 0 (disagree) to 5 (agree), users responded with a mean score
of 4.3 and 3.5 for VaR and HCE respectively.

A number of comments and suggestions were made by the
users regarding both systems. Positive feedback from VaR
included an intuitive interface, the instantaneous global view
and ability to quickly select the X dimension of all scatterplots.
Improvements suggested by the users involved ranking the
dimensions by features, and using color and best-ﬁt-lines to
enhance the scatterplot displays which were considered too
dense. In addition, users suggested ordering the dimension
glyphs according to the shapes of the scatterplot using au-
tomatic image analysis techniques. For the HCE system, users
preferred the ranking features and the scatterplot display with
rich features and interactions. Users suggested that the global
view provided by the prism in HCE lacked details compared
to the VaR display. Future work may beneﬁt by combining the
best features of these two systems.

XIII. CONCLUSION

In this paper, the VaR display, which allows users to inter-
actively explore large datasets with hundreds of dimensions,
was presented. The essential
idea of the VaR display is
to represent each dimension in a high dimensional dataset
using an information-rich glyph, and arranging the glyphs to
reveal the relationships among the dimensions. By integrating
existing techniques such as MDS, Jigsaw map, pixel-oriented

13

[12] D.A. Keim. Designing pixel-oriented visualization techniques: Theory
IEEE Transactions on Visualization and Computer

and applications.
Graphics, 6(1):1–20, January-March 2000.

[13] D.A. Keim, H.-P. Kriegel, and M. Ankerst. Recursive pattern: a
technique for visualizing very large amounts of data. Proc. IEEE
Visualization ’95, pages 279–286, 1995.

[14] G. Kollios, D. Gunopulos, N. Koudas, and S. Berchtold. Efﬁcient
biased sampling for approximate clustering and outlier detection in large
IEEE Transactions on Knowledge and Data Engineering,
data sets.
15(5):1170–1187, 2003.

[15] J.B. Kruskal and M. Wish. Multidimensional Scaling. Sage Publications,

1978.

[16] A. MacEachren, X. Dai, F. Hardisty, D. Guo, and G. Lengerich. Explor-
ing high-d spaces with multiform matrices and small multiples. Proc.
IEEE Symposium on Information Visualization, pages 31–38, 2003.

[17] F. Murtagh. A survey of recent advances in hierarchical clustering

algorithms. Computer Journal, 26(4):354–359, 1983.

[18] NetMBA.

http://www.netmba.com/statistics/plot/scatter/.

[19] J. Seo and B. Shneiderman. A rank-by-feature framework for un-
supervised multidimensional data exploration using low dimensional
projections. Proc. IEEE Symposium on Information Visualization, pages
65–72, 2004.

[20] J. Seo and B. Shneiderman. A rank-by-feature framework for inter-
active exploration of multidimensional data. Information Visualization,
4(2):96–113, 2005.

[21] B. Shneiderman. Tree visualization with tree-maps: A 2d space-ﬁlling

approach. ACM Transactions on Graphics, 11(1):92–99, Jan. 1992.

[22] M.O. Ward. A taxonomy of glyph placement strategies for multidi-
mensional data visualization. Information Visualization, 1(3-4):194–210,
2002.

[23] M. Wattenberg. A note on space-ﬁlling visualizations and space-ﬁlling
curves. Proc. IEEE Symposium on Information Visualization, pages 181–
186, 2005.

[24] E.J. Wegman and Q. Luo. High dimensional clustering using parallel
coordinates and the grand tour. Computing Science and Statistics,
28:361–368, 1997.

[25] J.A. Wise, J.J. Thomas, K. Pennock, D. Lantrip, M. Pottier, A. Schur,
and V. Crow. Visualizing the non-visual: Spatial analysis and interaction
with information from text documents. Proc. IEEE Symposium on
Information Visualization, pages 51–58, 1995.

[26] J. Yang, J. Fan, D. Hubball, Y. Gao, H. Luo, W. Ribarsky, and
M. Ward. Semantic image browser: Bridging information visualization
with automated intelligent image analysis. Proc. IEEE Symposium on
Visual Analytics Science and Technology, pages 191–198, 2006.

[27] J. Yang, A. Patro, S. Huang, N. Mehta, M. Ward, and E. Rundensteiner.
Value and relation display for interactive exploration of high dimensional
datasets. Proc. IEEE Symposium on Information Visualization, pages
73–80, 2004.

[28] J. Yang, M.O. Ward, E.A. Rundensteiner, and S. Huang. Visual
hierarchical dimension reduction for exploration of high dimensional
datasets. Eurographics/IEEE TCVG Symposium on Visualization, pages
19–28, 2003.

[29] J. Yi, R. Melton, J. Stasko, and J. Jacko. Dust & magnet: Multivariate
information visualization using a magnet metaphor. Information Visual-
ization, 4:239–256, 2005.

techniques, and scatterplots, and allowing users to interactively
explore large datasets according to their interests, the VaR
display provides a rich metaphor for interactive exploration
of high dimensional datasets. The case studies and user study
conducted proved that the VaR display is an effective approach
with high scalability.

Although work presented in this paper has greatly extended
the functionality of the original VaR display [27], we believe
that
the VaR display still has much potential for further
development. Time-dependant dimension glyph generation or
layout, the ability to convey spatial information, and the ability
to visualize dynamically changing data streams, are future
directions we want to explore in the VaR display. In addition,
detecting features by analyzing and comparing textures of
dimension glyphs using automatic image analysis techniques
is also an appealing future work. Another important future
work is to conduct user studies to evaluate different options
provided by the VaR display.

ACKNOWLEDGMENT

We gratefully thank Dr. Daniel A. Keim for giving many
valuable suggestions for this work, Dr. Jianping Fan, Yuli Gao,
and Hangzai Luo for providing us the datasets, and the users
who participated in the user study.

This work was performed with partial support from NSF
grant IIS-0119276 and the National Visualization and Ana-
lytics Center (NVAC(tm)), a U.S. Department of Homeland
Security Program, under the auspices of the Southeastern Re-
gional Visualization and Analytics Center. NVAC is operated
by the Paciﬁc Northwest National Laboratory (PNNL), a U.S.
Department of Energy Ofﬁce of Science laboratory.

REFERENCES

[1] M. Ankerst, S. Berchtold, and D.A. Keim. Similarity clustering of
dimensions for an enhanced visualization of multidimensional data.
Proc. IEEE Symposium on Information Visualization, pages 52–60,
1998.

[2] B. Babcock, S. Chaudhuri, and G. Das. Dynamic sample selection
for approximate query processing. Proc. ACM SIGMOD International
Conference on Management of Data, pages 539–550, 2003.

[3] B. Bederson, B. Shneiderman, and M. Wattenberg. Ordered and quantum
treemaps: Making effective use of 2d space to display hierarchies. ACM
Transactions on Graphics, 21(4):833–854, 2002.

[4] C.L. Bentley and M.O. Ward. Animating multidimensional scaling
to visualize n- dimensional data sets. Proc. IEEE Symposium on
Information Visualization, pages 72–73, 1996.

[5] K. Beyer, J. Goldstein, R. Ramakrishnan, and U. Shaft. When is “nearest
neighbor” meaningful? Lecture Notes in Computer Science, 1540:217–
235, 1999.

[6] S. Chaudhuri, R. Motwani, and V. Narasayya. Random sampling for
histogram construction: how much is enough? Proc. ACM SIGMOD
International Conference on Management of Data, pages 436–447, 1998.
[7] W.S. Cleveland and M.E. McGill. Dynamic Graphics for Statistics.

Wadsworth, Inc., 1988.

[8] J. Fan, Y. Gao, and H. Luo. Multi-level annotation of natural scenes
using dominant image components and semantic image concepts. Proc.
ACM international conference on Multimedia, pages 540 – 547, 2004.
Interactive information visualization of
a million items. Proc. IEEE Symposium on Information Visualization,
pages 117–124, 2002.

[9] J.-D. Fekete and C. Plaisant.

[10] Y. Fua, M.O. Ward, and E.A. Rundensteiner. Hierarchical parallel
coordinates for exploration of large datasets. Proc. IEEE Visualization,
pages 43–50, Oct. 1999.

[11] B. Hibbard and D. Santek. The vis-5d system for easy interactive

visualization. Proc. IEEE Visualization, pages 28–35, 1990.

View publication stats
View publication stats

","{""pos"":{""0"":1,""1"":2,""2"":3,""3"":4,""4"":5},""6"":{""0"":""items*"",""1"":""pages*"",""2"":""positions"",""3"":""areas*"",""4"":""bins""},""1"":{""0"":""figure"",""1"":""screen"",""2"":""mask"",""3"":""version*"",""4"":""threshold*""},""2"":{""0"":""x*"",""1"":""n*"",""2"":""m*"",""3"":""j*"",""4"":""0*""},""3"":{""0"":""var*"",""1"":""ieee*"",""2"":""hce"",""3"":""proc*"",""4"":""d1*""},""0"":{""0"":""selected*"",""1"":""different*"",""2"":""multi"",""3"":""labeled"",""4"":""unselected""},""4"":{""0"":""user*"",""1"":""study*"",""2"":""computer*"",""3"":""science*"",""4"":""institute*""},""5"":{""0"":""dimensions*"",""1"":""dimension*"",""2"":""values"",""3"":""density*"",""4"":""leaf*""}}",2007,{},False,False,journalArticle,False,7N8IFD7Z,"[{u'tag': u'metafor'}, {u'tag': u'multidimensional data'}, {u'tag': u'visualization'}]",self.user,"{""Unnamed: 0"":{""0"":0,""1"":1,""2"":2,""3"":3,""4"":4,""5"":5,""6"":6,""7"":7,""8"":8,""9"":9,""10"":10,""11"":11,""12"":12,""13"":13,""14"":14,""15"":15,""16"":16,""17"":17,""18"":18,""19"":19,""20"":20,""21"":21,""22"":22,""23"":23,""24"":24,""25"":25,""26"":26,""27"":27,""28"":28,""29"":29,""30"":30,""31"":31,""32"":32,""33"":33,""34"":34,""35"":35,""36"":36,""37"":37,""38"":38,""39"":39,""40"":40,""41"":41,""42"":42,""43"":43,""44"":44,""45"":45,""46"":46,""47"":47,""48"":48,""49"":49,""50"":50,""51"":51,""52"":52,""53"":53,""54"":54,""55"":55,""56"":56,""57"":57,""58"":58,""59"":59,""60"":60,""61"":61,""62"":62,""63"":63,""64"":64,""65"":65,""66"":66,""67"":67,""68"":68,""69"":69,""70"":70,""71"":71,""72"":72,""73"":73,""74"":74,""75"":75,""76"":76,""77"":77,""78"":78},""C"":{""0"":16.8056686489,""1"":16.0379904008,""2"":6.4429595732,""3"":8.7058822885,""4"":8.6223357982,""5"":10.8893552729,""6"":29.9402387205,""7"":7.7098324881,""8"":8.816603319,""9"":7.4098142356,""10"":9.478251861,""11"":11.7469964043,""12"":7.6184037877,""13"":10.8706530408,""14"":9.2580306488,""15"":6.3902672737,""16"":6.892769299,""17"":7.1869709614,""18"":9.2769471585,""19"":8.5459267678,""20"":9.8465188367,""21"":7.3331129569,""22"":14.6788559857,""23"":13.3219552817,""24"":9.2824997855,""25"":21.1244581221,""26"":23.7565836538,""27"":15.1479403111,""28"":9.465555362,""29"":19.9886580871,""30"":24.488760516,""31"":21.5470436057,""32"":7.2338553671,""33"":7.9205651303,""34"":20.092479274,""35"":8.5912047765,""36"":6.5104857409,""37"":8.9355002184,""38"":8.9355002184,""39"":17.075501175,""40"":8.3050959502,""41"":7.5646586731,""42"":9.978471643,""43"":11.7735883866,""44"":7.3981512291,""45"":8.5628995494,""46"":10.6369574524,""47"":6.8228967991,""48"":13.5593668015,""49"":7.8003619335,""50"":11.2686753455,""51"":7.8223047273,""52"":14.9221573836,""53"":7.94407177,""54"":7.5860553611,""55"":10.7137562149,""56"":7.9853009899,""57"":11.7810321707,""58"":11.5066048076,""59"":10.2253437726,""60"":6.3177492857,""61"":8.8546783903,""62"":10.0687076118,""63"":7.7942533617,""64"":10.1873619022,""65"":8.3987123129,""66"":8.4154164353,""67"":8.5412277762,""68"":8.0776557208,""69"":6.3744134665,""70"":6.466547658,""71"":6.3948726377,""72"":6.3948726377,""73"":6.3948726377,""74"":6.5284336757,""75"":6.6317111488,""76"":6.574636718,""77"":6.5036746253,""78"":6.5036746253},""count"":{""0"":406,""1"":362,""2"":218,""3"":158,""4"":122,""5"":114,""6"":104,""7"":98,""8"":88,""9"":82,""10"":80,""11"":78,""12"":76,""13"":64,""14"":48,""15"":42,""16"":40,""17"":40,""18"":40,""19"":38,""20"":38,""21"":38,""22"":36,""23"":36,""24"":36,""25"":36,""26"":34,""27"":32,""28"":32,""29"":32,""30"":32,""31"":32,""32"":30,""33"":30,""34"":30,""35"":28,""36"":26,""37"":24,""38"":24,""39"":24,""40"":22,""41"":22,""42"":22,""43"":22,""44"":20,""45"":20,""46"":20,""47"":20,""48"":20,""49"":18,""50"":18,""51"":18,""52"":18,""53"":16,""54"":16,""55"":16,""56"":14,""57"":14,""58"":14,""59"":14,""60"":12,""61"":12,""62"":12,""63"":12,""64"":12,""65"":10,""66"":10,""67"":10,""68"":10,""69"":10,""70"":10,""71"":8,""72"":8,""73"":8,""74"":8,""75"":8,""76"":8,""77"":8,""78"":8},""sigma_nor"":{""0"":1.8176223199,""1"":1.8246056992,""2"":1.4182286074,""3"":1.6596821899,""4"":1.735606573,""5"":1.9614727225,""6"":3.7807295267,""7"":1.7244193326,""8"":1.871279134,""9"":1.7525041051,""10"":1.9781536733,""11"":2.2303423679,""12"":1.8002214395,""13"":2.238953209,""14"":2.185986574,""15"":1.853104361,""16"":1.9406943208,""17"":1.982407208,""18"":2.2787309633,""19"":2.1988875859,""20"":2.3871979355,""21"":2.0232864898,""22"":3.1318453606,""23"":2.9310318938,""24"":2.3332158122,""25"":4.0857572471,""26"":4.5544821737,""27"":3.30410904,""28"":2.4227268533,""29"":4.0549420893,""30"":4.7529430439,""31"":4.2966598272,""32"":2.1023393794,""33"":2.2115778237,""34"":4.1478266371,""35"":2.3517810646,""36"":2.0383649504,""37"":2.4868040691,""38"":2.4868040691,""39"":3.8959010748,""40"":2.4187600811,""41"":2.2864567043,""42"":2.7177634696,""43"":3.0385198851,""44"":2.2959894066,""45"":2.5112726231,""46"":2.8946257036,""47"":2.189663755,""48"":3.4347816101,""49"":2.4160640833,""50"":3.0807984012,""51"":2.4202696225,""52"":3.7810219975,""53"":2.4949490152,""54"":2.4235994633,""55"":3.0469230005,""56"":2.560051701,""57"":3.3491403041,""58"":3.2920900299,""59"":3.0257306825,""60"":2.2596634989,""61"":2.8118220958,""62"":3.0760536309,""63"":2.5810222698,""64"":3.101878549,""65"":2.7853049591,""66"":2.7891269483,""67"":2.8179132305,""68"":2.7118455587,""69"":2.3221349664,""70"":2.3432157435,""71"":2.3782840144,""72"":2.3782840144,""73"":2.3782840144,""74"":2.4105513055,""75"":2.4355023266,""76"":2.4217135953,""77"":2.4045697146,""78"":2.4045697146},""vocab_index"":{""0"":0,""1"":1,""2"":3,""3"":5,""4"":8,""5"":9,""6"":11,""7"":13,""8"":15,""9"":17,""10"":19,""11"":20,""12"":21,""13"":26,""14"":35,""15"":41,""16"":45,""17"":46,""18"":48,""19"":50,""20"":52,""21"":53,""22"":58,""23"":62,""24"":63,""25"":64,""26"":68,""27"":69,""28"":70,""29"":71,""30"":72,""31"":73,""32"":79,""33"":80,""34"":81,""35"":83,""36"":90,""37"":96,""38"":97,""39"":103,""40"":106,""41"":108,""42"":116,""43"":121,""44"":122,""45"":123,""46"":127,""47"":132,""48"":134,""49"":135,""50"":148,""51"":149,""52"":150,""53"":170,""54"":171,""55"":172,""56"":180,""57"":193,""58"":196,""59"":197,""60"":217,""61"":228,""62"":231,""63"":239,""64"":240,""65"":245,""66"":289,""67"":291,""68"":294,""69"":295,""70"":296,""71"":299,""72"":300,""73"":301,""74"":303,""75"":353,""76"":362,""77"":367,""78"":368},""word"":{""0"":""dimensions"",""1"":""dimension"",""2"":""var"",""3"":""glyphs"",""4"":""items"",""5"":""x"",""6"":""selected"",""7"":""visualization"",""8"":""datasets"",""9"":""relationships"",""10"":""scatterplot"",""11"":""user"",""12"":""map"",""13"":""figure"",""14"":""different"",""15"":""values"",""16"":""scatterplots"",""17"":""tools"",""18"":""n"",""19"":""multi"",""20"":""space"",""21"":""screen"",""22"":""hierarchy"",""23"":""m"",""24"":""labeled"",""25"":""unselected"",""26"":""j"",""27"":""ieee"",""28"":""study"",""29"":""mask"",""30"":""hce"",""31"":""pages"",""32"":""2d"",""33"":""labels"",""34"":""proc"",""35"":""based"",""36"":""version"",""37"":""cid"",""38"":""129"",""39"":""threshold"",""40"":""computer"",""41"":""prototype"",""42"":""positions"",""43"":""texture"",""44"":""science"",""45"":""density"",""46"":""areas"",""47"":""s"",""48"":""symposium"",""49"":""ward"",""50"":""bins"",""51"":""masking"",""52"":""minutes"",""53"":""names"",""54"":""larger"",""55"":""step"",""56"":""presents"",""57"":""unoccupied"",""58"":""rain"",""59"":""candidate"",""60"":""leaf"",""61"":""sequence"",""62"":""ground"",""63"":""strong"",""64"":""subjects"",""65"":""dept"",""66"":""mode"",""67"":""d1"",""68"":""0"",""69"":""multidimensional"",""70"":""acm"",""71"":""worcester"",""72"":""polytechnic"",""73"":""institute"",""74"":""edu"",""75"":""raindrop"",""76"":""server"",""77"":""standard"",""78"":""deviation""},""vector"":{""0"":""[ 0.40500817  3.6101959  -2.2985282   2.2859585   0.2209759   2.020192\n  8.651902   -1.1950281  -3.1988058   0.02181797]"",""1"":""[ 0.23907687  3.8086655  -2.0605998   2.224402    0.47647566  1.8926847\n  8.698212   -1.6314613  -3.1405952   0.11596227]"",""2"":""[ 1.7715262e-01  3.7727280e+00 -2.5137596e+00  9.8487735e-01\n -1.9043845e-01 -1.0303416e-01  7.6163392e+00 -2.3544998e+00\n -3.6356864e+00 -1.4692226e-03]"",""3"":""[ 1.0553936   3.4074454  -2.7316375   1.8709614  -0.16129349  1.716216\n  8.594441   -1.0740126  -3.2306523   0.29481915]"",""4"":""[ 1.3291916   3.4367723  -2.2814906   2.315379   -0.08329578  1.3012143\n  9.00568    -0.48952046 -3.1328368  -0.13161997]"",""5"":""[ 0.01037123  3.8299363  -2.3261008   1.072128   -0.02083251  0.6299069\n  7.750192   -2.6593933  -3.3265228   0.12595843]"",""6"":""[ 0.22387272  3.2387528  -2.6165698   2.1858747   0.23729888  0.6512464\n  8.757017   -1.8527592  -2.2633505  -0.2581093 ]"",""7"":""[ 0.9564165  3.7270064 -2.8412437  1.9632181  0.0620293  1.4726803\n  8.5115385 -0.9148437 -3.4391356  0.4994387]"",""8"":""[ 0.7905602   3.6271768  -2.8752246   2.0281765  -0.11702808  1.3567053\n  8.440078   -0.74730957 -3.280057    0.25448936]"",""9"":""[ 0.83694285  3.6207893  -2.1230166   2.2992358   0.07714071  1.9804387\n  9.0324135  -0.7157385  -2.944864   -0.08373384]"",""10"":""[ 0.54101896  3.5940335  -2.963961    1.7859464  -0.18786314  1.242435\n  8.284824   -1.087274   -3.251245    0.36873487]"",""11"":""[ 1.6635933   3.373083   -2.1146092   1.7363487  -0.17644672  1.1753008\n  8.897859   -1.224722   -3.2093177   0.0247024 ]"",""12"":""[ 1.0652332   3.51121    -2.526053    1.904507    0.14197706  1.4625666\n  8.8424425  -1.5668212  -2.9392822   0.4869387 ]"",""13"":""[ 1.1370074   3.7965713  -1.8821921   2.07509     0.57172567  1.3182733\n  9.23639    -1.8526864  -2.784638    0.5306769 ]"",""14"":""[ 0.01017377  3.2807071  -2.3992538   2.2842054   0.31627995  1.0428613\n  8.65624    -2.1584215  -2.2328985  -0.23905869]"",""15"":""[ 0.69311106  3.5765023  -2.0675557   2.2695167   0.10416554  2.0161355\n  8.9809065  -0.9477573  -2.897903   -0.10278725]"",""16"":""[ 0.5268405   3.6194987  -3.0119514   1.8815247  -0.12878492  1.2796574\n  8.237605   -1.0533395  -3.2402213   0.28489444]"",""17"":""[ 1.2576584e+00  3.6437235e+00 -2.5388150e+00  2.1232293e+00\n  6.9385576e-03  1.3467438e+00  8.8033276e+00 -6.4032716e-01\n -3.2972257e+00  2.4525939e-01]"",""18"":""[ 0.18558224  3.7651234  -2.2275176   1.1334534  -0.08541908  0.7075227\n  7.8793783  -2.563259   -3.2283025   0.13293993]"",""19"":""[-0.11956546  3.4363637  -2.3458998   2.1674852   0.25006622  1.2646983\n  8.392944   -2.1916986  -2.529024   -0.14940639]"",""20"":""[ 0.47279033  3.7275288  -2.0376894   2.353066    0.5971435   1.3953859\n  8.971267   -1.239243   -3.4560974  -0.20376664]"",""21"":""[ 1.2795237   3.779388   -2.0307264   1.7640606   0.5072945   1.1512228\n  8.929702   -1.9702084  -3.372873    0.45491084]"",""22"":""[ 1.0155646   3.5949118  -1.9418136   2.4496746   0.11418694  1.9851526\n  9.185805   -0.8138125  -2.7401595   0.0446739 ]"",""23"":""[ 0.12476763  3.8827014  -2.1325722   1.0322028  -0.06082572  0.8968749\n  7.8203564  -2.5805151  -3.3852131   0.13636753]"",""24"":""[ 0.55932194  3.2127175  -2.5978744   2.389232    0.22324196  0.98063266\n  9.083615   -1.3571119  -2.2718089  -0.19530596]"",""25"":""[ 0.20480075  3.3305793  -2.7606273   2.0569847   0.14297009  0.67318624\n  8.554885   -1.6800929  -2.5717587  -0.17411657]"",""26"":""[ 0.12856126  3.8645499  -2.3525193   0.9276774  -0.17735863  0.5170293\n  7.6563263  -2.4653318  -3.5139344   0.12343072]"",""27"":""[ 0.40203705  3.8458328  -2.6879435   0.77649117 -0.41859093  0.10073486\n  7.504394   -1.9235122  -3.9251235   0.09509654]"",""28"":""[ 1.4488949   3.7785525  -2.3031168   1.7031001   0.27881354  0.59656805\n  8.881628   -1.0009882  -3.8836548   0.12038129]"",""29"":""[ 0.89392585  3.6786833  -2.2878463   1.9785274   0.74310166  1.200384\n  9.164839   -2.0637448  -2.7330205   0.5074309 ]"",""30"":""[ 0.69637066  3.8230138  -2.6366105   0.9195473  -0.36154273  0.21629322\n  7.8107457  -1.8063854  -3.7164204   0.21524477]"",""31"":""[ 1.5394597   3.3261623  -2.1635416   1.9410982  -0.20272681  1.2279744\n  8.962027   -0.80140257 -3.2885993  -0.19440986]"",""32"":""[ 0.27170193  3.6493711  -2.2341957   1.4361405   0.05964051  0.8681017\n  8.115007   -2.5513816  -3.009515    0.11451514]"",""33"":""[ 1.0038041e+00  3.2925003e+00 -2.5051029e+00  2.3268557e+00\n  2.2586223e-03  1.3684397e+00  9.1089106e+00 -8.0010301e-01\n -2.6252737e+00 -1.0478499e-01]"",""34"":""[ 2.8409040e-01  3.7987847e+00 -2.6446369e+00  9.0648609e-01\n -3.6538318e-01 -4.9725114e-03  7.5367284e+00 -2.0568891e+00\n -3.7722015e+00  8.0701999e-02]"",""35"":""[ 0.19529775  3.2210472  -2.429411    2.3256795   0.362514    0.9058048\n  8.856075   -2.114813   -2.086542   -0.21770994]"",""36"":""[ 1.1693522   3.5995939  -1.8532431   1.7832918   0.21274918  1.2579747\n  8.796084   -2.211648   -2.9087524   0.30912212]"",""37"":""[ 3.6925790e-01  3.8391719e+00 -2.3040073e+00  9.4393378e-01\n -8.7826505e-02 -1.6192162e-01  7.7135596e+00 -2.3518448e+00\n -3.8487327e+00 -2.1622339e-03]"",""38"":""[ 0.11583198  3.4926236  -2.3341465   1.6915674   0.10951906  0.7040659\n  8.245902   -2.4278014  -2.6906812  -0.08894484]"",""39"":""[ 0.8257588   3.7835305  -1.547266    2.245828    0.5271867   1.2604302\n  9.155422   -1.9268417  -2.6674094   0.13703375]"",""40"":""[ 1.5326896   3.6698627  -2.1233654   1.5855011   0.09002285  0.9688039\n  8.71264    -1.4917166  -3.6695938   0.22765984]"",""41"":""[ 1.3507428   3.5623343  -1.8998713   1.8433881   0.23524618  1.1176283\n  8.892371   -2.048661   -3.025897    0.31968772]"",""42"":""[ 1.1261694   3.580775   -1.9395983   2.2798877   0.14879823  1.5623144\n  9.277831   -0.73292834 -2.9479432  -0.15028793]"",""43"":""[ 0.35408753  3.923612   -2.3077283   2.208311    0.6250471   1.8659284\n  8.767411   -1.4749435  -3.4392915   0.3580592 ]"",""44"":""[ 1.3437881   3.8004103  -2.1673288   1.741048    0.27537534  0.83405894\n  8.84205    -1.0369213  -3.9791214   0.03456837]"",""45"":""[ 0.46803123  3.8000116  -2.2306902   2.231263    0.49130425  1.8725669\n  8.886717   -1.2718186  -3.3847935   0.27054313]"",""46"":""[ 1.1890478   3.5446823  -2.0863397   2.218525    0.17796785  1.2646688\n  9.195296   -0.693521   -3.2727265  -0.18350089]"",""47"":""[ 0.26617843  3.8737495  -2.0138917   1.1947372   0.05122     1.0882272\n  8.067491   -2.4761484  -3.2782822   0.11571328]"",""48"":""[ 1.1346475   3.9771764  -2.3317475   1.6655471   0.32112354  0.6641792\n  8.619067   -1.0575126  -4.1543474   0.17610985]"",""49"":""[ 1.290788    3.8235447  -2.0237963   1.9406184   0.26972988  0.5412427\n  9.17932    -1.1361701  -3.04747     0.18200454]"",""50"":""[ 0.88916326  3.4876251  -2.427254    2.435215    0.11311485  1.2003562\n  9.014741   -0.6139343  -2.9811404  -0.14734642]"",""51"":""[ 0.5872106   3.4984257  -2.5153434   2.1768413   0.6843739   1.1207137\n  9.145089   -1.9459506  -2.4299154   0.29865107]"",""52"":""[ 1.3929803   3.5065587  -1.8875275   2.186453   -0.12510528  1.2434868\n  8.945253   -0.7861811  -3.2528315  -0.2162046 ]"",""53"":""[ 1.3134135   3.318155   -2.2430778   2.1296527  -0.09086706  1.4867262\n  9.169141   -0.83288515 -2.732759   -0.10870168]"",""54"":""[-2.8393646e-03  3.3010297e+00 -2.2794700e+00  2.3828945e+00\n  3.2453740e-01  1.1840864e+00  8.6787920e+00 -2.0187128e+00\n -2.3779948e+00 -3.1626606e-01]"",""55"":""[ 0.91223735  3.888546   -1.7157874   2.077851    0.68284696  1.0928437\n  9.202009   -1.9279449  -2.8679016   0.2830267 ]"",""56"":""[ 0.46934223  3.206869   -2.6011028   2.3315864   0.3490896   0.81501025\n  9.051247   -1.7222741  -2.161016   -0.16403413]"",""57"":""[ 0.4565343   3.5805476  -2.2112415   2.4368463   0.5173558   1.1457176\n  9.067315   -1.1371335  -3.1246243  -0.28099012]"",""58"":""[ 0.73940116  4.0764217  -1.925756    2.141831    0.81348735  1.2167748\n  9.063294   -1.3913375  -3.7963004   0.22031513]"",""59"":""[ 1.2344038   3.7795897  -1.8339717   1.9821986   0.31560373  0.7286132\n  9.238617   -1.3755175  -2.8351972   0.1311571 ]"",""60"":""[ 0.5712502   4.0551744  -2.1541514   2.1389437   0.75212365  1.6217684\n  8.924151   -1.5166341  -3.6023798   0.45117852]"",""61"":""[ 0.8459535   3.9184613  -1.8454167   1.7868632   0.6478922   1.1342628\n  8.934735   -2.1667597  -3.1204505   0.33561334]"",""62"":""[ 6.3229185e-01  3.9138660e+00 -1.9036826e+00  2.2800524e+00\n  7.4645185e-01  1.2517418e+00  9.1141882e+00 -1.3565785e+00\n -3.4996710e+00  6.1032586e-03]"",""63"":""[-0.13583341  3.4360085  -2.2778146   2.3866985   0.47984353  1.2631228\n  8.634673   -2.1598506  -2.3622992  -0.17324387]"",""64"":""[ 1.4368312   3.4647574  -2.2426367   1.9887102   0.06098389  1.0031719\n  9.108998   -0.65749997 -3.422481   -0.1993498 ]"",""65"":""[ 1.1126864   3.8073256  -2.359849    1.0561192  -0.31133798 -0.05266273\n  8.014398   -1.487385   -4.03579     0.10494095]"",""66"":""[ 0.8227216   3.7411795  -1.7200626   1.8072549   0.3563416   1.1986414\n  8.710618   -2.296359   -3.026489    0.14950909]"",""67"":""[ 0.23544422  3.7799518  -2.6365988   1.049984   -0.30662203  0.13049334\n  7.640484   -2.025371   -3.576923    0.09725371]"",""68"":""[ 0.12317652  3.7102     -2.4211156   1.1862699  -0.11631458  0.35255322\n  7.812353   -2.407      -3.2564676   0.02810601]"",""69"":""[ 0.05022649  3.613787   -2.4301734   2.282689    0.3262116   1.7505741\n  8.51236    -1.603221   -2.9235687   0.04988984]"",""70"":""[ 0.48078907  3.8226316  -2.4743526   0.95908713 -0.27195486 -0.15556684\n  7.672728   -2.0335546  -3.856998    0.07317702]"",""71"":""[ 0.72505736  3.8327155  -2.4437163   0.913498   -0.34647438 -0.19012156\n  7.7436166  -1.8242188  -3.9720387   0.08231395]"",""72"":""[ 1.2108787   3.8322244  -2.330219    1.2002393  -0.12922259  0.17565253\n  8.236635   -1.3901986  -4.0419993   0.11746942]"",""73"":""[ 1.3307451   3.87118    -2.2448604   1.5305841   0.14903332  0.49342716\n  8.6228285  -1.1257646  -4.029449    0.11950114]"",""74"":""[ 0.90895617  3.838414   -2.416398    0.9952659  -0.25887892 -0.07761554\n  7.8769236  -1.6623809  -4.0826645   0.08475132]"",""75"":""[ 0.7619734   4.097839   -2.058266    2.0117195   0.77093834  1.417324\n  8.936583   -1.5776501  -3.7665064   0.46757305]"",""76"":""[ 1.5630682   3.5102837  -2.172646    1.5140406  -0.23784354  0.98391527\n  8.55851    -1.441718   -3.454312    0.15342005]"",""77"":""[ 6.5210724e-01  3.5387001e+00 -1.7335169e+00  2.1117370e+00\n  2.6793605e-01  1.2973624e+00  8.7908192e+00 -2.2369168e+00\n -2.5597484e+00 -7.5668693e-03]"",""78"":""[ 0.7069082   3.6232529  -1.7222819   2.1727235   0.28440028  1.6145936\n  8.853641   -1.9938201  -2.6930196   0.1061047 ]""},""topic"":{""0"":5,""1"":5,""2"":3,""3"":-1,""4"":6,""5"":2,""6"":0,""7"":-1,""8"":-1,""9"":-1,""10"":-1,""11"":4,""12"":-1,""13"":1,""14"":0,""15"":5,""16"":-1,""17"":-1,""18"":2,""19"":0,""20"":-1,""21"":1,""22"":-1,""23"":2,""24"":0,""25"":0,""26"":2,""27"":3,""28"":4,""29"":1,""30"":3,""31"":6,""32"":-1,""33"":-1,""34"":3,""35"":0,""36"":1,""37"":-1,""38"":-1,""39"":1,""40"":4,""41"":1,""42"":6,""43"":-1,""44"":4,""45"":5,""46"":6,""47"":-1,""48"":-1,""49"":-1,""50"":6,""51"":-1,""52"":6,""53"":6,""54"":0,""55"":1,""56"":0,""57"":-1,""58"":-1,""59"":-1,""60"":5,""61"":1,""62"":5,""63"":0,""64"":6,""65"":-1,""66"":1,""67"":3,""68"":2,""69"":-1,""70"":3,""71"":3,""72"":-1,""73"":4,""74"":3,""75"":-1,""76"":-1,""77"":1,""78"":1},""exemplar"":{""0"":""*"",""1"":""*"",""2"":""*"",""3"":null,""4"":""*"",""5"":""*"",""6"":""*"",""7"":null,""8"":null,""9"":null,""10"":null,""11"":""*"",""12"":null,""13"":null,""14"":""*"",""15"":null,""16"":null,""17"":null,""18"":""*"",""19"":null,""20"":null,""21"":null,""22"":null,""23"":""*"",""24"":null,""25"":null,""26"":""*"",""27"":""*"",""28"":""*"",""29"":null,""30"":null,""31"":""*"",""32"":null,""33"":null,""34"":""*"",""35"":""*"",""36"":""*"",""37"":null,""38"":null,""39"":""*"",""40"":""*"",""41"":null,""42"":null,""43"":null,""44"":""*"",""45"":""*"",""46"":""*"",""47"":null,""48"":null,""49"":null,""50"":null,""51"":null,""52"":""*"",""53"":null,""54"":""*"",""55"":""*"",""56"":null,""57"":null,""58"":null,""59"":null,""60"":""*"",""61"":""*"",""62"":""*"",""63"":""*"",""64"":""*"",""65"":null,""66"":""*"",""67"":""*"",""68"":""*"",""69"":null,""70"":""*"",""71"":null,""72"":null,""73"":""*"",""74"":null,""75"":null,""76"":null,""77"":null,""78"":null},""word*"":{""0"":""dimensions*"",""1"":""dimension*"",""2"":""var*"",""3"":""glyphs"",""4"":""items*"",""5"":""x*"",""6"":""selected*"",""7"":""visualization"",""8"":""datasets"",""9"":""relationships"",""10"":""scatterplot"",""11"":""user*"",""12"":""map"",""13"":""figure"",""14"":""different*"",""15"":""values"",""16"":""scatterplots"",""17"":""tools"",""18"":""n*"",""19"":""multi"",""20"":""space"",""21"":""screen"",""22"":""hierarchy"",""23"":""m*"",""24"":""labeled"",""25"":""unselected"",""26"":""j*"",""27"":""ieee*"",""28"":""study*"",""29"":""mask"",""30"":""hce"",""31"":""pages*"",""32"":""2d"",""33"":""labels"",""34"":""proc*"",""35"":""based*"",""36"":""version*"",""37"":""cid"",""38"":""129"",""39"":""threshold*"",""40"":""computer*"",""41"":""prototype"",""42"":""positions"",""43"":""texture"",""44"":""science*"",""45"":""density*"",""46"":""areas*"",""47"":""s"",""48"":""symposium"",""49"":""ward"",""50"":""bins"",""51"":""masking"",""52"":""minutes*"",""53"":""names"",""54"":""larger*"",""55"":""step*"",""56"":""presents"",""57"":""unoccupied"",""58"":""rain"",""59"":""candidate"",""60"":""leaf*"",""61"":""sequence*"",""62"":""ground*"",""63"":""strong*"",""64"":""subjects*"",""65"":""dept"",""66"":""mode*"",""67"":""d1*"",""68"":""0*"",""69"":""multidimensional"",""70"":""acm*"",""71"":""worcester"",""72"":""polytechnic"",""73"":""institute*"",""74"":""edu"",""75"":""raindrop"",""76"":""server"",""77"":""standard"",""78"":""deviation""},""pos"":{""0"":1,""1"":2,""2"":1,""3"":1,""4"":1,""5"":1,""6"":1,""7"":2,""8"":3,""9"":4,""10"":5,""11"":1,""12"":6,""13"":1,""14"":2,""15"":3,""16"":7,""17"":8,""18"":2,""19"":3,""20"":9,""21"":2,""22"":10,""23"":3,""24"":4,""25"":5,""26"":4,""27"":2,""28"":2,""29"":3,""30"":3,""31"":2,""32"":11,""33"":12,""34"":4,""35"":6,""36"":4,""37"":13,""38"":14,""39"":5,""40"":3,""41"":6,""42"":3,""43"":15,""44"":4,""45"":4,""46"":4,""47"":16,""48"":17,""49"":18,""50"":5,""51"":19,""52"":6,""53"":7,""54"":7,""55"":7,""56"":8,""57"":20,""58"":21,""59"":22,""60"":5,""61"":8,""62"":6,""63"":9,""64"":8,""65"":23,""66"":9,""67"":5,""68"":5,""69"":24,""70"":6,""71"":7,""72"":25,""73"":5,""74"":8,""75"":26,""76"":27,""77"":10,""78"":11},""x2D"":{""0"":5.432662487,""1"":5.0601673126,""2"":-4.7633743286,""3"":6.5959205627,""4"":7.8458919525,""5"":-3.7569262981,""6"":1.98371768,""7"":6.7200675011,""8"":6.9119701385,""9"":8.3587322235,""10"":6.7315611839,""11"":7.0244669914,""12"":6.1896500587,""13"":4.5768733025,""14"":1.9041810036,""15"":8.0013027191,""16"":6.8696899414,""17"":7.3163137436,""18"":-3.8352386951,""19"":2.1980221272,""20"":5.5486483574,""21"":4.9007930756,""22"":8.268532753,""23"":-3.7952849865,""24"":2.6725084782,""25"":2.1951253414,""26"":-4.1589393616,""27"":-4.5761637688,""28"":6.7585377693,""29"":4.0775475502,""30"":-4.5572295189,""31"":7.4840550423,""32"":-3.4311153889,""33"":7.9200782776,""34"":-4.8439369202,""35"":2.189643383,""36"":4.5307641029,""37"":-4.8361554146,""38"":-3.0386126041,""39"":4.257188797,""40"":6.7361893654,""41"":4.9953794479,""42"":8.4591493607,""43"":4.9336905479,""44"":6.6130170822,""45"":5.2392578125,""46"":8.2544822693,""47"":-3.5830960274,""48"":6.7188639641,""49"":6.1294827461,""50"":7.7873549461,""51"":3.0997753143,""52"":7.9211177826,""53"":8.1843509674,""54"":2.4328348637,""55"":4.373650074,""56"":2.5197956562,""57"":5.5950498581,""58"":5.0357642174,""59"":5.4302825928,""60"":4.9872665405,""61"":4.5420241356,""62"":5.2159581184,""63"":2.2795579433,""64"":7.7392497063,""65"":-5.1433310509,""66"":4.3959841728,""67"":-4.5559492111,""68"":-4.1174836159,""69"":4.7831692696,""70"":-4.5923166275,""71"":-4.7835950851,""72"":-5.2243108749,""73"":6.6835064888,""74"":-4.9013991356,""75"":5.0939903259,""76"":6.6030535698,""77"":3.8476638794,""78"":3.8737664223},""y2D"":{""0"":3.0557563305,""1"":3.0163714886,""2"":-0.7717799544,""3"":1.8632006645,""4"":1.3957731724,""5"":-0.5104376674,""6"":0.7464931607,""7"":1.9874696732,""8"":2.143112421,""9"":2.3146824837,""10"":2.2757751942,""11"":0.7270725369,""12"":1.5059556961,""13"":-0.2110471278,""14"":0.3467648923,""15"":2.4535040855,""16"":2.3935050964,""17"":1.7210255861,""18"":-0.2605203986,""19"":0.2694201469,""20"":2.4259297848,""21"":0.4192943871,""22"":2.2380950451,""23"":-0.5736699104,""24"":1.1104073524,""25"":0.7025232911,""26"":-0.620010376,""27"":-1.2589076757,""28"":-0.0271796007,""29"":-0.0649815723,""30"":-1.3989540339,""31"":0.8902829885,""32"":-0.3137071133,""33"":1.8497253656,""34"":-1.1926553249,""35"":0.4519121647,""36"":0.1078864187,""37"":-0.8851607442,""38"":-0.1938990653,""39"":0.1370436847,""40"":0.4185042083,""41"":0.006892507,""42"":1.8619589806,""43"":2.7485079765,""44"":0.0737147257,""45"":2.8208096027,""46"":1.4859013557,""47"":-0.4896282852,""48"":0.1332602352,""49"":0.2506507039,""50"":1.6510890722,""51"":0.4473304152,""52"":1.0112578869,""53"":1.5319513083,""54"":0.2350485325,""55"":0.5222976208,""56"":0.8959318399,""57"":2.453486681,""58"":2.0656607151,""59"":0.2331135571,""60"":2.4311966896,""61"":0.3241696656,""62"":2.2626447678,""63"":0.4306158125,""64"":1.0309108496,""65"":-1.6847448349,""66"":0.2338085771,""67"":-1.1025612354,""68"":-0.4057189226,""69"":3.1587688923,""70"":-1.5082998276,""71"":-1.6428090334,""72"":-1.6960599422,""73"":-0.0715309232,""74"":-1.428619504,""75"":2.1677782536,""76"":0.6871113181,""77"":0.352353245,""78"":0.2805634141}}",False,False,False,http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4135655,"<p>They show a system to visualize hundreds of dimensions using metafors.</p>
<p>&nbsp;</p>
<p>Could be a citable paper or could be a paper to get some ideas from for an attraction 2 paper.</p>",Value and Relation Display: Interactive Visual Exploration of Large Data Sets with Hundreds of Dimensions,7N8IFD7Z,False,False
PN7N37WR,VKS2ZMVM,"Visual Interaction with Dimensionality Reduction:

A Structured Literature Analysis

Dominik Sacha, Leishi Zhang, Michael Sedlmair, John A. Lee, Jaakko Peltonen,

Daniel Weiskopf, Stephen North, Daniel A. Keim

Abstract— Dimensionality Reduction (DR) is a core building block in visualizing multidimensional data. For DR techniques to be
useful in exploratory data analysis, they need to be adapted to human needs and domain-speciﬁc problems, ideally, interactively, and
on-the-ﬂy. Many visual analytics systems have already demonstrated the beneﬁts of tightly integrating DR with interactive visualizations.
Nevertheless, a general, structured understanding of this integration is missing. To address this, we systematically studied the visual
analytics and visualization literature to investigate how analysts interact with automatic DR techniques. The results reveal seven
common interaction scenarios that are amenable to interactive control such as specifying algorithmic constraints, selecting relevant
features, or choosing among several DR algorithms. We investigate speciﬁc implementations of visual analysis systems integrating DR,
and analyze ways that other machine learning methods have been combined with DR. Summarizing the results in a “human in the loop”
process model provides a general lens for the evaluation of visual interactive DR systems. We apply the proposed model to study and
classify several systems previously described in the literature, and to derive future research opportunities.
Index Terms—Interactive visualization, machine learning, visual analytics, dimensionality reduction

1 INTRODUCTION
Dimensionality Reduction (DR) is one of the major data abstraction
techniques in Visual Analytics (VA). In a typical setup, data is pro-
cessed by a DR algorithm, and the output is visualized and presented
to the analyst (Figure 1). DR aims at representing multidimensional
data in low-dimensional spaces, while preserving most of its relevant
structure, such as outliers, clusters, or underlying manifolds [36]. DR
is commonly applied to map data from many dimensions down to just
3 or 2, so that salient structures or patterns can be perceived while
exploring data visually, for example distances between data points in
a scatterplot. It is also used as preprocessing for other algorithms, to
improve performance by mitigating the curse of dimensionality [15].
Faced with a plethora of existing DR methods [54], it can be difﬁcult
for analysts to choose a good one, interpret the results, and apply DR
to the best advantage in a broader VA process. A common approach to
overcome this challenge is to involve analysts more closely, enabling
them to investigate and adapt standard methods through interactive
visualizations [39]. In such situations, tight integration of algorithmic
techniques and visualizations is essential. Contributing tools that sup-
port this duality is one of the major goals of VA [34]. Indeed, many VA

• Dominik Sacha is with the University of Konstanz, Germany.

E-mail: dominik.sacha@uni-konstanz.de

• Leishi Zhang is with the Middlesex University, UK.

E-mail: l.x.zhang@mdx.ac.uk

• Michael Sedlmair is with the University of Vienna, Austria.

E-mail: michael.sedlmair@univie.ac.at

• John A. Lee is a Research Associate with the Universit´e catholique de
Louvain (UCL/SSS/IREC/MIRO) and with the Belgian F.R.S.-FNRS.
E-Mail: john.lee@uclouvain.be

• Jaakko Peltonen is with Helsinki Institute for Information Technology HIIT,

Aalto University, and with the University of Tampere, Finland.
E-mail: jaakko.peltonen@aalto.ﬁ

• Daniel Weiskopf is with VISUS, University of Stuttgart, Germany.

E-mail: weiskopf@visus.uni-stuttgart.de

• Stephen C. North directs Infovisible LLC, Oldwick, U.S.A. and graphviz.org.

E-mail: s.c.n@ieee.org

• Daniel A. Keim is with the University of Konstanz, Germany.

E-mail: daniel.keim@uni-konstanz.de

Manuscript received xx xxx. 201x; accepted xx xxx. 201x. Date of Publication
xx xxx. 201x; date of current version xx xxx. 201x. For information on
obtaining reprints of this article, please send e-mail to: reprints@ieee.org.
Digital Object Identiﬁer: xx.xxxx/TVCG.201x.xxxxxxx

Fig. 1: A basic DR pipeline maps data to a DR algorithm. The results
are visualized and presented to the analyst. Interaction feeds back to
the pipeline components.

applications have been proposed that offer solutions for speciﬁc DR
methods and analysis problems. In these examples, the goal is usually
to support the analyst in steering the underlying algorithms through
effective interactions in a visual interface (e.g., [6]), a concept that has
become known as “semantic interaction” [18].

Despite these efforts, more general solutions that blend machine
learning and VA still do not exist. Yet, it is these more general tools
that are needed to deal successfully with real-world challenges [21,
48]. Aiming at a more general understanding of how to integrate
algorithmic and visual components, a wide variety of theoretical VA
models and frameworks have been proposed [12, 20, 34, 47, 48]. These
models, however, often focus on high-level, abstract views, and fail to
successfully characterize how a strong interplay between algorithms
and visualizations would be realized and exploited.

To better understand the integration of DR and visual user interfaces,
we formed an interdisciplinary group of VA and machine learning re-
searchers. The motivating questions considered were “Exactly how do
analysts interact with the DR pipeline?” and “How can we incor-
porate our ﬁndings into the interactive DR process?”. To answer
these questions, we conducted a semi-automated review of 1850 papers
from the visualization and VA literature. In the ﬁrst step, 377 relevant
papers were selected and subsequently reviewed to identify speciﬁc
examples of how DR interactions are realized, and to get a comprehen-
sive, well-grounded understanding of the overall area. We summarize
our main ﬁndings in the form of seven guiding scenarios that describe
ways of combining DR with visualization (to an extent, inspired by
previous work on guiding scenarios for visualization evaluation [35])
(Section 4). We also present some relevant statistics about DR and
interaction techniques (Section 5). To relate our work to existing theo-
retical models in VA, we incorporate the ﬁndings of the literature study
in a conceptual process for interactive DR [47]. We illustrate how such
models describe and support reasoning about dedicated systems, and
enumerate ﬁve open research opportunities derived from our analysis
(Section 6). Finally, we consider limitations of our work, and outline
topics we plan to address in the future (Section 7 and 8).

2 RELATED WORK
This study is related to previous work in several ways: it is concerned
with general theoretical models of VA and their relationship to machine
learning; it makes use of DR methods; it adopts basic ways of inter-
acting with data visualizations; and it is related to the general idea of
self-reﬂection in the visualization and VA community.

2.1 Theoretical Models
In the standard VA model [34], the discovery process is characterized
by interaction between data, models of the data, visualizations, and the
analyst. User interaction in this framework is aimed at model building
and parameter reﬁnement. Sacha et al. [48] extended it to describe the
human knowledge generation process. The extended model clariﬁes the
role of the analyst in knowledge generation, and highlights the impor-
tance of tight integration of human and machine by enabling interaction
with the system. The previous models apply to VA in a generic manner.
In contrast, the study presented here focuses speciﬁcally on interacting
with DR methods. Another framework describes the problem of DR as
a two-stage process [12]: it ﬁrst maps high-dimensional data to a lower-
dimensional space, then allows another stage to reduce it to 2D for
visualization. While this framework generalizes speciﬁc DR methods,
it focuses on a speciﬁc application to clustered data and is limited to the
two-stage process as described. The framework for observation-level
interaction with statistical models [20] focuses on interaction by direct
manipulation of visualization by different projection techniques. There-
fore, it yields a generic approach toward interacting with the output
of DR methods, which is one part of our human-in-the-loop process
model; i.e., observation-level interaction directly ﬁts in our proposed
process of interaction with DR methods. Another general model is
semantic interaction [18], taking acquired interaction data as a means
to build user models and guide the VA system.

2.2 Surveys of DR and Interaction Techniques
DR maps data into fewer dimensions aiming to preserve structure like
cluster gaps or local manifold continuity. In linear DR output axes are
linear combinations of original features, for example directions of
largest variation in principal component analysis (PCA), maximally
statistically independent directions in independent component analysis
(ICA) [26], directions of maximal between-class and minimal
within-class variation in linear discriminant analysis (LDA), or
directions of maximal correlation between feature subsets in canonical
correlation analysis (CCA). Nonlinear DR ﬁnds either a mapping
function or only output coordinates for the data set,
interpreted
through proximities or distances of output data; for example, mappings
are sought to preserve pairwise data distances in multidimensional
scaling (MDS), small distances in Sammon mapping, distances along
a neighborhood graph in Isomap, or neighborhood relationships in
neighbor embedding methods [54, 55]. Some methods seek mappings
onto a regular grid of units as in self-organizing maps (SOMs) or
generative topographic mapping (GTM). Details on PCA, MDS,
Sammon mapping, Isomap, SOM, and GTM are available in books
such as [36] and for LDA and CCA in [1].

Van der Maaten et al. [54] offer a comparative review of the state
of the art in DR techniques, focusing on the performance of nonlinear
techniques from the machine learning perspective. Similarly, Wism¨uller
et al. [57] survey nonlinear DR, manifold and topological learning tech-
niques. Bengio et al. [3] give an overview on representation learning in
the context of deep learning. However, all the aforementioned works do
not take into account VA or user interaction. A survey by Liu et al. [39]
covers visualization of high-dimensional data, including DR as one of
the main techniques. They include a short discussion of interaction,
and embed examples into the traditional visualization pipeline. How-
ever, they focus on general interaction techniques and not speciﬁcally
how users interact with DR. Furthermore, they enumerate interactive
model manipulation as a future research opportunity. Similarly, Buja
et al. [9] review interaction techniques in the general setting of high-
dimensional data visualization. Hoffman and Grinstein [24] and Bertini
and Lalanne [4] discuss visualization methods for high-dimensional

Fig. 2: Our four stage analysis process: 1. Automated ﬁltering, 2.
Manual ﬁltering, 3. Manual coding, 4. Manual sample validation.

data mining, including projection and interaction methods. Keim [33]
structures such visualization approaches according to the type of data
to be visualized, the actual visualization technique, and the interaction
and distortion method. However, none of these surveys performed a
systematic exploration of the existing literature, nor did they focus on
interaction techniques for DR.

2.3 Interaction Taxonomies
Our study addresses interaction in the context of DR. Therefore, re-
lated work includes general models of interaction for visualization. For
example, Yi et al. [58] identify seven interaction method categories:
select, explore, reconﬁgure, encode, abstract/elaborate, ﬁlter, and con-
nect. Brehmer and Munzner [7] provide a comprehensive description
of visualization tasks, leading to a multi-level typology of abstract tasks
(which includes the ones by Yi et al.). However, model interactions
only arise in tasks they call “aggregate” or “derive” tasks. Von Lan-
desberger et al. [56] deﬁne an interaction taxonomy that is suitable for
tracking and analyzing user actions in VA, and provides two types of
data processing interactions: data changes, such as editing or selecting
data, and processing changes, such as scheme or parameter changes. In
contrast, our work focuses less on a general description of user tasks,
but rather on the process of interacting with DR methods.

2.4 Self-Reﬂection in the Visualization and VA Community
Because our study is based on a systematic review, coding, and anal-
ysis of previous work in the visualization and VA community, it is
also related to previous work on self-reﬂection of empirical studies in
information visualization [35], evaluation in visualization research in
general [28], or affordance in human computation and human-computer
interaction [14]. While we adopt the methodology of systematic analy-
sis of previous work, our paper has a very different focus.

3 METHODS
To obtain a general understanding of visual interactive DR systems,
we systematically reviewed the IEEE InfoVis, IEEE VAST, TVCG,
and EuroVis literature. We ﬁrst automatically identiﬁed a relevant
subset of papers from these conferences and journals. Then, we carried
out a qualitative in-depth analysis of the relevant papers, iteratively
extracting and reﬁning visual DR interaction characteristics. Our over-
all approach to this analysis was inspired by Grounded Theory [11],
in which data is systematically analyzed until meaningful categories
emerge (see Section 4). This methodological approach is based on
identifying and reﬁning categories from a representative set of qualita-
tive data, here papers, which are then used to incrementally build up a
theoretical model (Section 6). This approach has been used in visual-
ization research [28, 35, 51] and related areas such as HCI before [25],
and its importance for building up the much needed theoretical foun-
dation in visualization has been recognized [45, 51]. We next describe
our method, followed by more detailed sub-sections on our analysis
procedure and ﬁndings.

3.1 Methodological Choices
We began our endeavor with a curated list of landmark publications in
interactive machine learning and visualization. Using these candidate
papers, we ﬁrst tried an open coding approach to identify “interesting”
aspects at the intersection of VA and machine learning in general.
This approach turned out to be very time consuming, and, ultimately,

impractical. While it led to a high level framework [47], our initial
goals of thoroughly and systematically depicting how the VA and
machine learning can be combined were largely unsatisﬁed. Hence
we decided to analyze a much larger set of sample papers, resulting in
three implications for our methodological choices. (1) We realized the
need to focus on a speciﬁc machine learning problem (in our case, DR)
to make the analysis more concrete, relevant, and actionable. (2) We
needed automated methods to reduce the set of potentially interesting
papers. (3) We opted for crisp, clear criteria for manual coding and
ﬁltering of papers. During this process, we reﬁned the process, ﬁltering
criteria, and coding options several times. Our ﬁnal workﬂow was
then composed of four major steps, shown in Figure 2: 1.) Automated
keyword-based paper ﬁltering, 2.) Manual paper ﬁltering, 3.) Manual
paper coding, and 4.) Manual sample validation.

3.2 Sample Set of Papers
Our overall goal was to identify which DR methods are used, and how
interaction is implemented in the VA and visualization communities.
We decided to take a representative sample of papers, constituted of all
IEEE VIS papers (1221) and EuroVis papers (629) from 2005 to 2015,
for a total of 1850 papers. From EuroVis we included all full and
short papers, as well as EuroVA publications. The IEEE VIS papers
included all InfoVis, VAST and TVCG papers. Our main focus was
abstract, multi-dimensional data; consequently we did not include IEEE
SciVis/Vis papers in the analysis, which generally focus on 3D spatial
data (e.g., ﬂow and volume rendering).

3.3 Automated Keyword-Based Filtering
We implemented a basic NLP pipeline to analyze the initial set of
papers. The pipeline parses the full text of each paper, applying a
tokenizer and a snowball stemmer implemented from StanfordNLP
components1. The same was done with keyword lists, one list for DR
and another for interaction keywords. From this, a feature vector of
all keyword occurrences was derived. Papers without any keyword
occurrences were deemed irrelevant and ﬁltered out, and the remaining
papers were listed in a csv ﬁle with associated keyword counts. This
ﬁle was the basis for the subsequent manual ﬁltering and coding steps.
For the keyword deﬁnition, we examined previously published sur-
veys and taxonomy papers in related ﬁelds, and formed a set of primary
papers in DR and interactive visualization. The keywords of these
papers were extracted and processed using the NLP pipeline. A manual
validation process then followed to reﬁne the keyword lists. For exam-
ple, ambiguous abbreviations (such as, LLC), or words that become
ambiguous after stemming (such as projection, which stems to project,
or some, which stems to SOM) were removed. The ﬁnal keyword
lists and statistics from the automated ﬁltering process are provided as
supplemental material.

After the automated process, the initial set of 1850 papers was ﬁl-
tered to 382 relevant papers based on DR keywords, then reduced to 377
papers (108 EuroVis, 247 VIS) based on interaction keywords. Figure 3
illustrates a histogram of the keyword frequencies in a logarithmic scale.
DR keywords are colored green and interaction keywords are shown
in light blue. Interact is the outlier with the maximum occurrence in
interaction keywords, while MDS and PCA are the most frequently
occurring DR methods.

3.4 Manual Expert Filtering
The remaining 377 papers were manually checked using the following
criteria. First, we checked if the paper is a visualization application
or technique paper, and if it handles “abstract data.” (We intended to
exclude theory and evaluation papers, as well as papers focused on
unrelated or tangential topics such as volume rendering or physical ﬂow
data). Second, we checked if the paper addresses the combination of
visualization, DR and interaction, and if the interaction feeds back to
the DR. For example Joia et al. [32] present an interesting technique for
sampling and feature selection. However, there is no interaction that
causes a recalculation of the DR. Given our focus on interactive DR,

1http://nlp.stanford.edu/software/

Fig. 3: The top keyword occurrences in the automatically identiﬁed
papers shown in a log-scale histogram. DR keywords are colored in
green and interaction keywords are colored in light blue.

we excluded interactions that do not feed back to the analysis pipeline,
such as exploration/navigation/DoD (Details on Demand) interactions.
Finally, we listed the DR techniques employed. Based on this, we
obtained a candidate set of 70 relevant papers.

3.5 Manual Paper Coding
We next analyzed these 70 papers in detail, by open coding the “inter-
esting” aspects of interaction described in each paper. For each paper,
we extracted a brief description of the proposed interaction, including
how interaction is performed and which parts of the DR pipeline are
affected. In addition, we iteratively identiﬁed and reﬁned a set of cri-
teria. A more general model [47] and the different components of the
DR pipeline (data, preprocessing, DR) served as initial set of criteria
to encode which parts are affected by the analysts feedback. However,
we had to adapt, split, and reﬁne these criteria several times. As a
result we arrived at seven scenarios for DR interaction, encoding “how
the DR pipeline is changed” (see Section 4), the interaction paradigm
(“how the interaction is performed”, see Section 5), the DR Method(s)
or Algorithm(s), and combined machine learning techniques such as
clustering or classiﬁcation. During our process we had to discard
several aspects that we initially were interested in. We started, for
example, to encode “who” is expected to perform the actual interaction
(e.g., DR expert or novice user), and “why” the human input is needed.
However, investigating these aspects turned out to be challenging as
the necessary information was not provided in many cases. A more
detailed description of the ﬁnal criteria and options is provided in the
following sections. 8 more papers were ﬁltered out in this iteration.

3.6 Manual Sample Validation
In a ﬁnal validation iteration, we aimed at more detailed analysis of
borderline cases and ended up removing 4 more papers. Our ﬁnal
corpus included 58 relevant papers, with the encoded information and
the corresponding feature vector of keyword occurrences. We “cleaned”
the encoded information and grouped the identiﬁed DR methods into
higher-level categories (see Section 5.2).

4 SEVEN GUIDING SCENARIOS FOR DR INTERACTION
We next describe the interaction scenarios that emerged from our
literature review. By examining the interactive machine learning
pipeline proposed in [47], we identiﬁed the main potential interactions
in data analysis, and classiﬁed them into seven guiding scenarios. This
categorization is based on the outcome of several iterations of the paper
ﬁltering and open coding process, and is one of the major ﬁndings of
our study. It enables us to evaluate various methods for “how the DR
pipeline is controlled through interaction”. In the following, we brieﬂy
describe these seven DR interaction scenarios “along the DR pipeline”
and illustrate them with examples:

S1 Data Selection & Emphasis: This group of interactions affects
the data records (or observations) that will be supplied to the actual
DR method. We found many examples in which a ﬁlter is applied
to the data, and the DR pipeline is re-run on the remaining subset.
In this scenario, we further identiﬁed several realizations. In some
situations, analysts select subsets directly in a two-dimensional visual
representation. In others, analysts specify conditions or ﬁlters through
control panels. Furthermore, we identiﬁed various preprocessing
conﬁgurations or parameters that can be adjusted by the analyst. An
example is J¨ackle et al.’s temporal MDS plot technique [29], where a
parameter sets the size of a sliding window. The resulting slices are
taken as input for subsequent DR by one-dimensional MDS. S1 Data
Selection & Emphasis was identiﬁed 26 times.

S2 Annotation & Labeling: A second group of operations enrich
data with annotations or labels on instances. In some systems, data may
be enriched with additional information. For example, StarSPIRE [6]
allows analysts to annotate documents with additional terms that will
be included in the similarity calculation. Other systems enable the
analyst to assign classiﬁcation or cluster labels if the DR is combined
with another form of machine learning (e.g. [23]). The cluster or classi-
ﬁcation labels, as well as data structures (such as a hierarchy obtained
from hierarchical clustering) are then translated into constraints for the
DR algorithm (e.g., cluster preservation).

In the classiﬁcation case, the analyst provides class labels within the
two-dimensional embedding to train a classiﬁer. Labels are provided
for data instances, or in some settings, for pairs of instances. The
classiﬁcation result inﬂuences subsequent DR (e.g., [22]).
In the
clustering case, the analyst deﬁnes cluster memberships, such as by
grouping elements into clusters, by adding or removing elements, or
by splitting or merging clusters. Resulting clusters are used by the
next iteration of DR. For example, the Bubble Cluster approach [23]
lets the analyst re-position points or draw cluster boundaries in a 2D
projection of the data, and use the new cluster assignments to update
the projection. S2 Annotation & Labeling was found in 15 papers.

S3 Data Manipulation: Some VA systems let the analyst explicitly
manipulate data values by moving points in a spatialization, or
by editing data in a table view. This interaction helps analysts to
investigate “what if” scenarios. For example the iPCA system [30]
allows the analyst to re-position a point in the 2D projection, and see
how other values change. Interestingly, Jeong et al. reported that
adjusting data values could be counter-intuitive to some of the subjects
in their study. However, they argued that these interactions are still
useful for revealing relationships in the data that might otherwise not
be recognized. S3 Data Manipulation was only rarely used (7 times).

S4 Feature Selection & Emphasis: We found many interaction
examples that feed back to the initial data space by adapting the
metric for calculating similarities or dissimilarities between data
instances. Many DR applications adopt a “default” metric such as
Euclidean distance. However, the default metric may not correspond
well with the analyst’s “notion” of dissimilarity, and the metric needs
to be adapted to the application. One way to do this is to associate
adjustable weights with each data dimension. Distances can be
calculated accordingly, giving more inﬂuence to relevant dimensions.
For example, iPCA [30] provides the analyst with weighting sliders for
each dimension. Another possibility is to infer the dimension loadings
from direct manipulation interactions of visual elements. An example
can be found in [43] where the analyst rearranges points serving as
control points for a subsequent optimization of the projection matrix.
Similarly in Dis-Function [8], an analyst drags and selects points on a
2D scatterplot, and a compatible distance function is learned by the
system. When the user is ﬁnished with manipulations, a button is
pressed to learn the distance function and re-render the result. Other
systems such as [44] provide analysts with drop-down menus to select
a distance metric. Further options are to let the analyst determine
interesting features in combination with subspace clustering (e.g., [41])
or quality metrics (e.g., [31]). S4 Feature Selection & Emphasis was

the most frequently implemented interaction scenario (37).

S5 DR Parameter Tuning: Some DR algorithms contain speciﬁc
parameters that can be tuned, such as LDA regularization in [13]. An
approach proposed by Schreck et al [49] allows the analyst to set
the grid dimensions of a self-organizing map (number of neurons,
DR structure). Some systems have parameters related to quality and
accuracy, such as thresholds or level-of-detail parameters. Garg et
al. [22] provide a similarity cutoff parameter that determines edges
with low similarity to be removed from a graph layout. Others
have parameters affecting visual appearance. For example, [16]
allows adjusting node padding or forcing strength in a force-directed
embedding. We also found examples where the analyst can deﬁne
algorithmic variants (by setting parameters), that animate or show
transitions between multiple DR results. In [43] a transition parameter
(slider) is set to compare and track changes. Finally, parameter sets
or conﬁgurations can be set indirectly, such as when the analyst is
offered several visualization recommendations or previously deﬁned
parameter sets, and may compare them to select the most appropriate
one. However, we did not identify any mature, ready-to-use system
incorporating this kind of parameter tuning. S5 DR Parameter Tuning
was found in 20 papers.

S6 Deﬁning Constraints: Interactions can be translated directly to
DR algorithm constraints. We identiﬁed several examples in which an
analyst directly arranges points in the visualization. These modiﬁed
points are interpreted as anchor points in the subsequent DR iteration,
in which their positions should remain ﬁxed to help the analyst track
other changes. For example, Endert et al. [20] introduced Guided
MDS, where user-deﬁned anchor points are used to ﬁx positions
and adjust similarities for maintaining consistency in visualization.
A similar example can be found in [6], where nodes representing
objects are marked as “ﬁxed” and subsequently not rearranged by a
force-directed algorithm. Constraints such as region or containment,
as well as visual constraints have also been proposed. For example
the technique introduced by [17] allows analysts to group points and
deﬁne regions that should not be split or overlap with others.
In
addition, constraints for the edges may be deﬁned, such as pointing
edge downward. Note, that in combination with another ML method,
the ML output can be thought of as a constraint for DR, e.g., items
that belong to the same cluster or classiﬁcation should be placed close
to each other, or a hierarchy obtained from hierarchical clustering
should be preserved. In some systems, these constraints can also be
interactively controlled (providing labels, setting parameters for the
clustering, etc.). S6 Deﬁning Constraints was described in 15 papers.

S7 DR Type Selection: Visual embeddings of high-dimensional
data can be generated by various DR algorithms and vary in terms
of layout and quality. For example, linear methods project data to
new axes, such as directions of maximal variance in PCA, whereas
methods such as MDS aim to preserve distances or neighborhoods
of data records. While some systems, such as iPCA and StarSPIRE,
focus on one DR technique, others implement multiple algorithms
so the analyst can select and compare their results while analyzing
data. A system by Rieck and Leitte [46] visualizes and ranks
embeddings from several DR algorithms according to quality
measures. Another system by Liu et al. [40] lets the analyst select
DR algorithms and compare them based on visualization of distortion
measures. We can even envision approaches for indirect S7 DR
Type Selection. Although we did not ﬁnd examples,
it seems
potentially useful to infer an appropriate DR Type from user inputs
automatically, on the ﬂy. We elaborate on this idea in Section 6. S7 DR
Type Selection had the lowest occurrence (4) among the seven scenarios.

Note that some of the seven guiding scenarios overlap. For example,
S1-S3 affect data items, and S5-S7 involve the choice of DR algorithm.
However, we identiﬁed these particular scenarios as useful descriptions
of the papers we studied. We found it useful to distinguish scenarios
based on the way interaction affects the DR pipeline. For example, to

Table 1: Result of the proposed coding process. Blue, orange, yellow
and green setups appear more frequently. Red points denote papers
implementing 4 different interaction scenarios. The three main column
groups specify interaction scenarios, combinations with other machine
learning methods, and interaction paradigms.

Fig. 4: Embedding of 58 papers based on interaction scenarios. The plot
shows a diverse set of interaction combinations. The main interaction
scenarios are S4 Feature Selection & Emphasis (blue cluster), S1 Data
Selection & Emphasis (orange cluster), the combination of S1 & S4
(yellow cluster), and S4 combined with S2 Data Manipulation (green
cluster). The red cluster contains papers that combine 4 different
interaction scenarios.

Observations: The ﬁnal result of our coding process is shown in
Table 1 and Figure 4. To provide an overview of the coded results, we
created a 2D projection of the papers using Multiscale Jensen-Shannon
Embedding [37], which aims to place papers with similar codes nearby
in the projection. Together with Table 1 we can investigate combi-
nations of interaction scenarios. In total, we identiﬁed 29 different
combinations. We found a maximum of 4 scenarios per paper (in 4
papers, colored in red). Papers colored blue only cover S4 Feature Se-
lection & Emphasis. This was the most frequent “setup” and appeared
in 9 papers. The ﬁve orange dots denote papers that only include S1
Data Selection & Emphasis, and the ﬁve yellow dots represent papers
with combinations of S1 and S4. Work applying S2 Annotation & La-
beling and S4 Feature Selection & Emphasis occurred 4 times (green
dots). We color the rest of the papers gray, as their combinations of
interactions occur less frequently. These gray dots generally appear
further away from the center of the view. For example, papers including
S5 DR Parameter Tuning are placed in the upper area, or S2. Annotation
& Labeling papers are placed near the upper left corner.

We further observe from Table 1 that some interaction scenarios
appear more frequently than others. This applies to S4, S1, and S5
maybe because they are more general or convenient than others. S3
Data Manipulation is used least. One reason might be that manipulat-
ing observations—often considered “ground truth”—is not common
practice in many domains (e.g., machine learning). Also note that S3
only appears in combination with other interaction scenarios.

In this respect, it would be interesting to investigate in more detail
why some interaction scenarios appear more or less frequently. This
naturally raises the question about the effectiveness of certain interac-
tion scenarios. In-depth investigation of effectiveness, however, goes
beyond the scope of this paper. Previous work has shown that assessing
effectiveness of interactive DR solutions depends heavily on context
factors, such as users, data, domain, and tasks at hand [50, 52]. A
generic comparison of the scenarios’ usefulness and effectiveness is
thus a non-trivial endeavor, and further work is needed. The study in
this paper is descriptive with the goal to characterize existing interaction
scenarios, and can be used as a starting point for such endeavors.

distinguish S2 Annotation & Labeling from S6 Deﬁning Constraints
interactions, we note that both add information to data items (e.g., a
class label vs. a “pinned” information), but S2 Annotation & Labeling
focuses on information about input data items, while S6 Deﬁning
Constraints involves information about desired results or outputs of
the DR. Note also that the role of the VA system is to translate these
similar inputs to different interaction scenarios (see Section 5).

Table 2: Identiﬁed DR techniques shown with interaction scenarios.

Fig. 5: Different interaction paradigms: Typical Direct Manipulation in-
teractions are shown in the upper half. On the bottom, control elements
are shown. DR-Interfaces are usually composed of both.

Table 3: Temporal statistics of interaction and DR Techniques.

5 FURTHER INSIGHTS
In this section, we analyze the interaction scenarios in different contexts,
such as the interaction paradigm, the combined DR algorithms or other
machine learning methods, as well as a temporal perspective.

5.1 Interaction Paradigm & Usability
Each interaction scenario can be realized in multiple ways. Therefore,
our analysis also encoded interaction paradigms, including Direct
Manipulation of visual elements, Controls (sliders, buttons, etc.),
Command Line Interface (CLI), Other (such as gestures or speech
input), or NA (if interaction was not described in the paper). The
results (see Table 1-right side columns) reveal balanced usage of Direct
Manipulation (36) and Controls (33). However, novel interaction
paradigms (Other) only appeared once (multi-touch in [59]) and
another set of papers omits details of how interaction is performed
(NA, 12). It is also worth mentioning that the amount of provided
information about the realization and implementation, as well as
discussions about usability of interactions strongly varies between the
analyzed papers.

Our results show that analysts interact with DR either directly in
the visualization, or using control elements. During our study we
noticed, especially in Direct Manipulation, similar actions may have
different meanings or implementations (see upper half of Figure 5 as
an example). An analyst can move points, select data records (followed
by an operation such as deletion), mark (label, or annotate) points, or
draw borders in a plot. However, the meaning of an action may vary.
Data movement can be “translated” to S2 Annotation & Labeling if a
point is moved outside a cluster, or to S3 Data Manipulation if the data
value is changed. Alternatively, the movement can be “translated” to
S4 Feature Selection & Emphasis by deriving (dis)similarities from
user deﬁned distances between data points, or S6 Deﬁning Constraints
if a data point being moved is interpreted as an anchor point. In such
cases visualization has to act as a “mediator” between human and
machine and translate the interactions to appropriate DR pipeline
components.
In contrast, control elements (Figure 5-bottom) are
usually directly coupled to speciﬁc DR pipeline components. The UI
provides, for example, sliders to directly control dimension loading
or DR parameters, drop-down menus to select metrics, or buttons to
trigger speciﬁc operations. There are also cases where natural language
text inputs are accepted. On the other hand, Command Line Interfaces
offer a powerful, well-speciﬁed language for programmers, but they
are not always convenient or even accessible to analysts.

The ﬁnal implementation determines the “complexity” of performing
an interaction scenario, which depends on user and task characteristics
though. DR experts, for instance, might require a large set of directly
steerable parameters, and accept a more complex interface. Other users,
however, might require less ﬂexibility, but simple ways to provide
feedback based on their domain knowledge.

5.2 DR & Machine Learning Algorithms
The interaction scenarios appeared with several different DR algo-
rithms. Each algorithm was assigned to a higher-level category of
Distance Based (DB), Linear Projection (LP), Graph/Force-Directed
(FD), Neural Network (NN), General, or Other (one approach did not
match any others – “data driven feature selection”). Table 2 lists these
DR algorithms as columns and interaction scenarios as rows. We see
that Distance Based methods (mainly MDS) were used alone most fre-
quently (17), followed by Linear Projections (mainly PCA) alone (12)
and Graph/Force-Directed methods alone (10). General approaches
appear in 5 papers, whereas Neural Networks were used 3 times (all
self organizing maps). The other columns show examples where var-
ious DR algorithms are used in combination. Note that only one of
the mixed approaches (other than General approaches) lets the analyst
switch between DR algorithms. Interestingly, S4 Feature Selection &
Emphasis was used in all of these DR algorithm combinations. We can
further derive from Table 1 that Clustering and Classiﬁcation appeared
in 31 papers. Clustering was used 28 and Classiﬁcation 12 times, while
in 9 papers both of them are used in combination.

5.3 Temporal Perspective
We did not ﬁnd any relevant papers on interactive DR in 2005. As
shown in Table 3, in the corpus we studied, published work on visual
interactive DR ﬁrst appeared in 2006, with one paper that reported
work in S1 Data Selection & Emphasis. This was followed by 5 related
papers published in 2007, where a wider range of interaction techniques
such as S4 Feature Selection & Emphasis, S2 Annotation & Labeling,
and S5 DR Parameter Tuning were included. These four interaction
scenarios appear to be more “established” than the others, as work was
continuously reported in these areas in the following years, whereas the
development of other interaction techniques have breaks in between.
For example S7 DR Type Selection ﬁrst appeared in 2007, but then there
is a gap until 2012, after which it appears consistently. We admit these
trends may not be fully representative due to the limited number of
papers and scenarios in our study. One obvious pattern is the number of
papers published by year. Years 2009 (9) and 2011 (10) are peaks. Of
course, a larger number of papers does not necessarily describe a richer
set of interaction scenarios (as shown in the “AVG Interaction/Paper”
row where large paper counts do not strongly correspond to large
average interaction counts).

Fig. 6: Proposed “human in the loop” process model for interactive DR. The analyst can iteratively reﬁne the analysis by interacting with the DR
pipeline. The visualization interface serves as a “lens” that interactively mediates between the DR pipeline and the analyst, presenting DR results
or updates and accepting feedback.

6 THE INTERACTIVE DR PROCESS

With the goal of making our study more broadly applicable, we sum-
marize our ﬁndings in a general process model for interactive DR in
VA. This model is shown in Figure 6. It depicts an expanded version
of the basic model in Figure 1 and is a specialized model of our gen-
eral pipeline model for visual interactive machine learning [47]. Note
that the general model is a superset of the model shown in Figure 6
and was needed to arrive at a more specialized version for interactive
DR, which contains speciﬁc steps, knowledge, and details tailored to
interactive DR, and is therefore much more actionable. At the top,
we add the seven scenarios of interacting with DR techniques, and
arrange them along the analysis pipeline. S1-S3 operate on the data,
such as by changing data values or annotating labels (blue); S4 operates
on the feature space, such as by changing distance functions or the
projection matrix (cyan); and S5-S7 directly affect the DR algorithms
(or additional ML models) (green). At the bottom, the results of the
DR process are propagated back to the analyst (yellow).

The core of our process model is the interactive visual interface
(red), which connects these two streams and serves as a lens for the
human analyst on the algorithmic building blocks. While our work
focused primarily on characterizing the forms of interaction shown by
the top arrows, it is also interesting to consider how DR results can be
visually presented to the user. We found dimensionally-reduced data is
typically presented in scatterplots or node-link diagrams, conﬁrming
previous empirical ﬁndings [50]. Yet, our model also draws attention
to the fact that other aspects of the process model can be visually repre-
sented. For instance, the dimensions (or eigenvector) can be mapped
to a parallel coordinate plot [30]. Furthermore, the quality of the DR
pipeline can potentially be visualized, either separately, or embedded in
the low dimensional representation. Some DR types calculate or iden-
tify errors, and in combination with other machine learning methods,
additional quality information might be obtained (e.g., the precision
of a classiﬁer [42]). Furthermore, different DR pipeline variants (e.g.,
pre-deﬁned DR conﬁgurations or automatically built recommendations)
can be visualized [27]. These different perspectives on the DR pipeline
support the analyst’s interpretation and validation process.

In many VA tools, the analyst has not only the ability to visually
inspect and validate the data, but also the ability to provide interactive
feedback to control the analysis through the interface. As discussed
previously, this feedback is usually in the form of controls and direct ma-
nipulation interactions, such as setting positions, selecting, or grouping
data items; other interaction paradigms such as command line scripts,
gestures and speech input are also possible. The VA system maps user
inputs to the speciﬁed interaction scenario(s), providing an instance
of a typical continuous and iterative process, as it is usually targeted
in VA [34, 47]. Note that the ability of the analyst to provide useful
feedback depends on the interpretability of visual observations but also

on the accessibility (implementation) of the interaction. These aspects
further depend on both, the technical competence (DR expertise) and
domain knowledge of the analyst, as well as the analysis task (e.g.,
analyzing data records vs. dimensions [50]). Especially novice analysts
with less mathematical skills face problems of interpreting different
DR concepts (e.g., linear vs. non-linear models) in a 2D-representation
where the actual meaning of the axis is lost.

We now demonstrate how the proposed process model can be used
for comparative, as well as generative purposes [2]. We ﬁrst use it to
describe and compare four existing examples. We then use it to identify
and reason about open research opportunities.

6.1 Descriptive Use of the Process Model – Examples
Figure 7b instantiates the DR process model on four examples. Their
representation in the proposed model provides a consistent way to
understand these systems and compare their capabilities for interaction.
iPCA (S1, S3, S4) The iPCA system [30] (Figure 7a-1) addresses
typical data and feature space interactions. Several aspects of PCA
are visualized in linked views, including projection, data, eigenvector,
and correlation views. Each view supports a wide range of interactions
including navigation, selection, and linking & brushing, however, the
authors focused on three interactions that require re-computation of
PCA. First, for S1 Data Selection & Emphasis an analyst can remove
data items (e.g., outliers) and observe the resulting changes in data- and
eigen-space. Second, the analyst can modify data values in some views
or spaces (S3 Data Manipulation). Finally, iPCA offers sliders for each
dimension for S4 Feature Selection & Emphasis, enabling the analyst to
modify each dimension’s contribution to the ﬁnal PCA calculation. This
lets the analyst test how the DR is affected by removing or “dimming”
the importance of certain dimensions.

Interactive Cluster Separation (S4, S6, other ML) Molchanov
and Linsen [43] present another way to infer feature weights from
interactions (Figure 7a-2). They invert the process of modifying the
projection matrix in a star coordinates widget by allowing the analyst
to specify the desired conﬁguration directly in the projection view (by
rearranging control points). They show an example where S4 Feature
Selection & Emphasis is inferred from direct manipulation of data
points. In addition, the control points serve as S6 Deﬁned Constraints
for the projection. To achieve an appropriate DR output, the projection
matrix is recalculated “based on an LS solution of an over determined
system of linear equations”. The control points can be selected by
the analyst, however, the authors recommend using cluster medians or
centroids for better cluster separation. This implies that the labels must
be contained in the data or determined by a classiﬁer beforehand.

StarSPIRE (S1, S2, S4, S6) Bradel et al. [6] extends the Force-
SPIRE system proposed by Endert et al. [19]. Their extension offers
a richer set of interaction scenarios. A modiﬁed force-directed layout

(a) Images for each example.

(b) Interactive DR process model instances for each example.

Fig. 7: Analyzed examples for DR interaction: 1.) iPCA, 2.) Interactive cluster separation, 3.) StarSPIRE, and 4.) Persistent Homology.

algorithm visualizes text documents under a computed similarity metric
(Figure 7a-3). They extend ForceSPIRE with an additional model for
relevance-based document retrieval that performs S1 Data Selection
& Emphasis inferred from user interactions. The analyst can also S2
Annotate text documents with further information (terms) that update
the similarity calculation and cause a change to the document layout. S4
Feature Selection & Emphasis is inferred from user interaction by ad-
justing the weightings of document terms. This is done in conjunction
with annotation, but also by re-sizing elements, searching, highlighting
and overlapping documents. In addition it is possible to rearrange and
pin document nodes in the spatialization. The pinned document serves
as a S6 Deﬁned Constraint for the force-directed layout.

Persistent Homology (S5, S7) Rieck and Leitte [46] describe
an approach to comparing DR parameter settings across various DR
types, such as PCA, t-SNE, HLLE and Isomap. Quality measures
are computed to validate and rank the DR setup conﬁgurations. The
proposed approach visualizes various DR embeddings together with
additional quality information (Figure 7a-4). Their study does not
explain in detail how an analyst would create the different combinations
of S5 Parameter Settings and S7 DR Type Selections (we encoded
this work as NA). However, several examples illustrate different DR
algorithms and parameterizations created by the authors (we assume
using CLI).

Comparison Figure 7b shows interactions supported by the
above-mentioned systems. For instance, while iPCA offers the ability
to S3 manipulate data items, StarSPIRE allows the analyst to S2
annotate documents with additional terms. iPCA, Cluster Separation,
and StarSPIRE allow S4 Feature Selection & Emphasis, however,
in different ways.
iPCA offers slider controls directly coupled to
dimension loading. Cluster Separation and StarSPIRE infer S4 Feature
Selection & Emphasis from direct manipulation, through optimization
and term weighting. Cluster Separation and StarSPIRE allow the
analyst to S6 Deﬁne Constraints for the DR process, by positioning
and pinning data items. The Persistent Homology approach focuses
on the validation and comparison of different DR setups by choosing
among several S7 DR Type Selections and S5 Parameter Settings.

The examples and their comparison illustrate the applicability of
the proposed interactive DR process model. It supports evaluating
systems with respect to the identiﬁed interaction scenarios and their
implementations, and can be used to derive further interaction scenarios
and implementations not present in current VA systems. We next detail
5 opportunities for research in visual interactive DR systems.

6.2 Generative Use of the Process Model – Opportunities
We can apply our study and process model to better understand and
reason about research opportunities. We recommend these directions:
Semantic Interaction Design One challenge in the design of
interactive DR systems is the semantic translation of front-end interac-
tions. Section 5.1 illustrates that the same front-end interaction can be
mapped to several different back-end computations. Ideally, intuitive
interactions would direct back-end computation and correctly express
the intention of the analyst. For example in StarSPIRE, by moving
points closer to each other in the visualization the analyst can have
the similarity measures and the layout updated accordingly. While
many systems provide good examples of semantic interaction design,
the translation only applies to a subset of interaction scenarios (e.g.,
feature weighting, similarity computation). Consistently mapping user
inputs to more complex actions covering the entire pipeline is an open
challenge. Especially in DR, interaction designers have to consider that
DR concepts and algorithms are often hard to understand and interpret.
Therefore, interaction needs to be accessible and interpretable for end
users, enabling them to work with distances and neighborhoods, clus-
ters and class memberships, or importance of dimensions. Scalability
of computation will play a crucial role in such interactive systems, as
delaying responses hinders usability [10].

Guidance on DR Type Selection Our study revealed that S7 DR
Type Selection has rarely been implemented. Furthermore, semantic
interactions derived from direct manipulation interactions are mostly
limited to DR pipeline adaptions of the feature space or DR parameters
and constraints. We envision future systems that can also infer an
appropriate DR algorithm from user inputs. Such VA systems would
probably need to implement, calculate and compare various DR types,
to identify the “best” results on the ﬂy. Work proposed by Rieck
and Leitte [46] shows a promising step in this direction. However,
realization and implementation of direct manipulation interactions and
translation to DR type selections is still missing. Such techniques, that
balance user ﬂexibility with system automation, have great potential for
guiding users through complex data analyses, so this is an important
area for further investigation. On the algorithmic side, the challenge
is to formulate speciﬁc DR algorithms as parametric instances that
allow smooth transitions between different DR types. For example,
continuous model spaces [37, 55] enable analysts to track and interpret
model switching and avoid abrupt and confusing transitions.

Evaluating DR Interactions As pointed out in Section 4 we are
not aware of studies evaluating the effectiveness of DR interactions
in a structured and general setup. It will be a challenge to design and

conduct a fair comparative assessment of different interaction scenar-
ios, as they depend on many factors, such as implementation, user
experience or tasks. However, it would be useful to gather insights
about effectiveness of the respective interaction scenarios under certain
conditions. This would guide researchers and developers in designing
interactive DR systems for their speciﬁc domains, tasks and data. Horn-
bæk provides a comprehensive overview of usability measures from
HCI [25] that could be applied to a comparative DR setup.

Fully Integrated Process As discussed in Section 4 and illus-
trated in Figure 7b, existing systems implement only a small subset
of possible interactions. While many previous systems have proven
useful for speciﬁc tasks and problems, more powerful, general-purpose
interactive DR tools are needed. An ideal system would provide ﬂexible
access to a range of DR algorithms, distance functions, optimization
algorithms or quality metrics, and offer many of the interaction types
we identiﬁed. It will be a challenge to conceptually integrate and steer
a wide range of algorithm speciﬁc parameters or different combinations
of computations. At the same time, the burden of choosing suitable
data, features, parameters and models could be mitigated by tightly
integrating the DR pipeline with interactive visualization.

Analytic Provenance Given the complex nature of many analysis
tasks, the analyst often has to go through many steps and even false
starts before reaching sound conclusions. Although analytic provenance
has been introduced as a research topic in VA, not much work has been
reported on recording interactions to support exploratory data analysis
for DR. A major task will be to compare and assess different DR
results in a sequence of interactions. For example, when switching
between different states, the resulting changes have to be observable
and measurable to automatically identify impactful actions within an
analysis session. Lehmann and Theisel provide a promising approach to
measure the (dis)similarity of projections [38]. However, more research
considering a larger set of DR types and interactions is needed.

as an add-on to our proposed scenarios. Considering quality measures
was a main concern when we began this study, but as the work matured
we decided to focus exclusively on interaction scenarios with DR.

8 CONCLUSION AND FUTURE WORK
Giving humans more interactive control over the DR process is a great
opportunity for improving exploratory data analysis.
It allows the
analyst to explore data, feature, parameter and model spaces, taking
advantage of their understanding of the data, application domain, and
experience in the analysis task at hand.

In this study, we systematically analyzed the visualization literature
with the goal of identifying common DR operations amendable to
interactive control. We summarized our ﬁndings in seven guiding
scenarios, which we contextualize in a conceptual process model for
visual interactive DR. Our analysis revealed several ways that DR can
be enriched by user interaction, how these strategies are supported
by current VA systems, and points to future research directions in
interactive DR. We hope that our contributions help other researchers
investigating, designing and evaluating interactive DR systems.

In future work, we plan to develop a system capable of inferring and
adapting its settings in a larger design space than current systems for
visual interactive DR. We plan to extend our analysis to papers from
related domains, such as machine learning and human-computer inter-
action. Beyond this, we would like to perform a literature analysis and
process modeling study focused on interactive clustering, classiﬁcation,
and regression analysis in VA.

ACKNOWLEDGMENTS
This paper is a result of Dagstuhl Seminar 15101, “Bridging Infor-
mation Visualization with Machine Learning”. The authors thank all
participants for inspiring and fruitful discussions. This work was par-
tially supported by the EU project VALCRI (FP7-SEC-2013-608142).

7 LIMITATIONS
Our work comes with certain limitations that result from the approach
we adopted. To keep the study focused and manageable, we had to
limit our literature analysis to a representative set of examples. After
many discussions, we decided to focus on the visualization literature.
Our goal was to identify papers that include DR, interaction and visu-
alization. We ﬁnd these mainly in the visualization community. We
primarily aimed at actionable and extensible results, and with that at
transparency and reproducibility by thoroughly describing our method.
Nevertheless, we are conﬁdent that we analyzed a representative sub-
set of the literature and that our derived model is stable regarding the
interaction scenarios. It would be interesting to evaluate the stabil-
ity of our results by performing an expanded “cross validation” study
that also includes/adds papers from machine learning (e.g., KDD) and
human-computer interaction (e.g., CHI). Note that we initially started
our analysis with landmark publications from all domains and had to
limit the set of papers to keep the work manageable.

In our analysis of the literature, we identiﬁed several contributions
that offer useful interactions to explore and validate DR results, without
directly feeding back to a DR calculation. We had long discussions
about including these interactions as another scenario, but ﬁnally de-
cided to exclude these papers to keep the work focused. An example is
the system proposed by Stahnke et al. [53] that provides interactions to
interpret and interrogate DR results. Their system allows an analyst to
investigate approximation errors, examine positions of data points, and
“overlay” the inﬂuence of speciﬁc data dimensions. However, these
interactions do not feed back to a subsequent DR calculation.

Similarly, other facets may be involved in interactive DR in speciﬁc,
and interactive machine learning in general. An important facet is
DR quality measures. A framework by Bertini et al. [5] describes an
enriched VA pipeline with quality-metric-driven automation. Quality
is measured at each stage of the pipeline, with the analyst steering the
entire process. Quality measures can augment user interaction at these
stages with automatic conﬁgurations or recommendations. However,
quality measures do not interact with the DR pipeline, and can be seen

2014.

[2] M. Beaudouin-Lafon. Designing interaction, not interfaces. In Conf. on

Advanced Visual Interfaces (AVI), pages 15–22. ACM, 2004.

REFERENCES
[1] E. Alpaydin. Introduction to Machine Learning, 3rd Edition. MIT Press,

[3] Y. Bengio, A. C. Courville, and P. Vincent. Representation learning: A
review and new perspectives. IEEE Trans. Pattern Anal. Mach. Intell.,
35(8):1798–1828, 2013.

[4] E. Bertini and D. Lalanne. Surveying the complementary role of automatic
data analysis and visualization in knowledge discovery. In Proceedings of
the ACM SIGKDD Workshop on Visual Analytics and Knowledge Discov-
ery: Integrating Automated Analysis with Interactive Exploration, pages
12–20, 2009.

[5] E. Bertini, A. Tatu, and D. Keim. Quality metrics in high-dimensional
data visualization: An overview and systematization. IEEE Trans. on
Visualization and Computer Graphics, 17(12):2203–2212, Dec 2011.

[6] L. Bradel, C. North, L. House, and S. Leman. Multi-model semantic
interaction for text analytics. IEEE Conf. on Visual Analytics in Science
and Technology (VAST), pages 163–172, 2014.

[7] M. Brehmer and T. Munzner. A multi-level typology of abstract visu-
alization tasks. IEEE Trans. on Visualization and Computer Graphics,
19(12):2376–2385, 2013.

[8] E. T. Brown, J. Liu, C. E. Brodley, and R. Chang. Dis-function: Learning
distance functions interactively. IEEE Conf. on Visual Analytics in Science
and Technology (VAST), pages 83–92, 2012.

[9] A. Buja, D. Cook, and D. F. Swayne. Interactive high-dimensional data
visualization. Journal of Computational and Graphical Statistics, 5:78–99,
1996.

[10] S. K. Card, G. G. Robertson, and J. D. Mackinlay. The information
visualizer, an information workspace. ACM SIGCHI Conf. Human Factors
in Computing Systems (CHI), page 181186, 1991.

[11] K. Charmaz. Constructing grounded theory. Sage, 2014.
[12] J. Choo, S. Bohn, and H. Park. Two-stage framework for visualization
of clustered high dimensional data. IEEE Conf. on Visual Analytics in
Science and Technology (VAST), pages 67–74, 2009.

[13] J. Choo, H. Lee, J. Kihm, and H. Park.

iVisClassiﬁer: An interactive
visual analytics system for classiﬁcation based on supervised dimension

reduction. IEEE Conf. on Visual Analytics in Science and Technology
(VAST), pages 27–34, 2010.

[14] R. J. Crouser and R. Chang. An affordance-based framework for hu-
man computation and human-computer collaboration. IEEE Trans. on
Visualization and Computer Graphics, 18(12):2859–2868, 2012.

[15] D. Donoho. High-Dimensional Data Analysis: The Curse and Blessings
of Dimensionality. Aide-m´emoire for a lecture for the American Math.
Society “Math. Challenges of the 21st Century”, 2000.

[16] P. Drieger. Visual Text Analytics using Semantic Networks and Interactive
In K. Matkovic and G. Santucci, editors, EuroVA
3D Visualization.
2012: International Workshop on Visual Analytics. The Eurographics
Association, 2012.

[17] T. Dwyer, Y. Koren, and K. Marriott. Ipsep-cola: An incremental proce-
dure for separation constraint layout of graphs. IEEE Trans. on Visualiza-
tion and Computer Graphics, 12(5):821–828, 2006.

[18] A. Endert, R. Chang, C. North, and M. X. Zhou. Semantic interaction:
Coupling cognition and computation through usable interactive analytics.
IEEE Computer Graphics and Applications, 35(4):94–99, 2015.

[19] A. Endert, P. Fiaux, and C. North. Semantic interaction for visual text
analytics. ACM SIGCHI Conf. Human Factors in Computing Systems
(CHI), pages 473–482, 2012.

[20] A. Endert, C. Han, D. Maiti, L. House, S. Leman, and C. North.
Observation-level interaction with statistical models for visual analyt-
ics. IEEE Conf. on Visual Analytics in Science and Technology (VAST),
pages 121–130, 2011.

[21] A. Endert, M. S. Hossain, N. Ramakrishnan, C. North, P. Fiaux, and
C. Andrews. The human is the loop: new directions for visual analytics. J.
Intell. Inf. Syst., 43(3):411–435, 2014.

[22] S. Garg, I. V. Ramakrishnan, and K. Mueller. A visual analytics ap-
proach to model learning. IEEE Conf. on Visual Analytics in Science and
Technology (VAST), pages 67–74, 2010.

[23] C. Heine and G. Scheuermann. Manual clustering reﬁnement using inter-

action with blobs. Computer Graphics Forum, pages 59–66, 2007.

[24] P. E. Hoffman and G. G. Grinstein. Information visualization in data
mining and knowledge discovery. chapter A Survey of Visualizations for
High-dimensional Data Mining, pages 47–82. Morgan Kaufmann, San
Francisco, CA, USA, 2002.

[25] K. Hornbæk. Current practice in measuring usability: Challenges to
usability studies and research. International Journal of Man-Machine
Studies, 64(2):79–102, 2006.

[26] A. Hyv¨arinen, J. Karhunen, and E. Oja. Independent Component Analysis.

Wiley, 2001.

[27] S. Ingram, T. Munzner, V. Irvine, M. Tory, S. Bergner, and T. M¨oller.
Dimstiller: Workﬂows for dimensional analysis and reduction. IEEE Conf.
on Visual Analytics in Science and Technology (VAST), pages 3–10, 2010.
[28] T. Isenberg, P. Isenberg, J. Chen, M. Sedlmair, and T. M¨oller. A system-
atic review on the practice of evaluating visualization. IEEE Trans. on
Visualization and Computer Graphics, 19(12):2818–2827, 2013.

[29] D. J¨ackle, F. Fischer, T. Schreck, and D. A. Keim. Temporal MDS plots for
analysis of multivariate data. IEEE Trans. on Visualization and Computer
Graphics, 22(1):141–150, 2016.

[30] D. H. Jeong, C. Ziemkiewicz, B. D. Fisher, W. Ribarsky, and R. Chang.
iPCA: An interactive system for pca-based visual analytics. Computer
Graphics Forum, 28(3):767–774, 2009.

[31] S. Johansson and J. Johansson.

Interactive dimensionality reduction
through user-deﬁned combinations of quality metrics. IEEE Trans. on
Visualization and Computer Graphics, 15(6):993–1000, 2009.

[32] P. Joia, F. Petronetto, and L. G. Nonato. Uncovering representative groups
in multidimensional projections. Computer Graphics Forum, 34(3):281–
290, 2015.

[33] D. A. Keim. Information visualization and visual data mining. IEEE Trans.

on Visualization and Computer Graphics, 8(1):1–8, 2002.

[34] D. A. Keim, J. Kohlhammer, G. P. Ellis, and F. Mansmann. Mastering the
Information Age - Solving Problems with Visual Analytics. Eurographics
Association, 2010.

[35] H. Lam, E. Bertini, P. Isenberg, C. Plaisant, and S. Carpendale. Empirical
studies in information visualization: Seven scenarios. IEEE Trans. on
Visualization and Computer Graphics, 18(9):1520–1536, 2012.

[36] J. Lee and M. Verleysen. Nonlinear dimensionality reduction. Springer,

2007.

[37] J. A. Lee, E. Renard, G. Bernard, P. Dupont, and M. Verleysen. Type 1
and 2 mixtures of Kullback-Leibler divergences as cost functions in di-
mensionality reduction based on similarity preservation. Neurocomputing,

112:92–108, 2013.

[38] D. J. Lehmann and H. Theisel. Optimal sets of projections of high-
dimensional data. IEEE Trans. on Visualization and Computer Graphics,
22(1):609–618, 2016.

[39] S. Liu, D. Maljovec, B. Wang, P.-T. Bremer, and V. Pascucci. Visualiz-
ing High-Dimensional Data: Advances in the Past Decade. Computer
Graphics Forum, 2015.

[40] S. Liu, B. Wang, P. Bremer, and V. Pascucci. Distortion-guided structure-
driven interactive exploration of high-dimensional data. Computer Graph-
ics Forum, 33(3):101–110, 2014.

[41] S. Liu, B. Wang, J. J. Thiagarajan, P. Bremer, and V. Pascucci. Visual ex-
ploration of high-dimensional data through subspace analysis and dynamic
projections. Computer Graphics Forum, 34(3):271–280, 2015.

[42] G. M. H. Mamani, F. M. Fatore, L. G. Nonato, and F. V. Paulovich.
User-driven feature space transformation. Computer Graphics Forum,
32(3):291–299, 2013.

[43] V. Molchanov and L. Linsen. Interactive Design of Multidimensional
Data Projection Layout. In N. Elmqvist, M. Hlawitschka, and J. Kennedy,
editors, EuroVis - Short Papers. The Eurographics Association, 2014.

[44] J. E. Nam and K. Mueller. Tripadvisorn-d: A tourism-inspired high-
dimensional space exploration framework with overview and detail. IEEE
Trans. on Visualization and Computer Graphics, 19(2):291–305, 2013.

[45] A. Oulasvirta and K. Hornbæk. Hci research as problem-solving. In ACM

SIGCHI Conf. Human Factors in Computing Systems (CHI).

[46] B. Rieck and H. Leitte. Persistent homology for the evaluation of dimen-
sionality reduction schemes. Computer Graphics Forum, 34(3):431–440,
2015.

[47] D. Sacha, M. Sedlmair, L. Zhang, J. A. Lee, D. Weiskopf, S. C. North,
and D. A. Keim. Human-Centered Machine Learning Through Interac-
tive Visualization: Review and Open Challenges. Proceedings of the
24th European Symposium on Artiﬁcial Neural Networks, Computational
Intelligence and Machine Learning, 2016.

[48] D. Sacha, A. Stoffel, F. Stoffel, B. C. Kwon, G. P. Ellis, and D. A. Keim.
Knowledge generation model for visual analytics. IEEE Trans. on Visual-
ization and Computer Graphics, 20(12):1604–1613, 2014.

[49] T. Schreck, J. Bernard, T. Tekusova, and J. Kohlhammer. Visual cluster
analysis of trajectory data with interactive kohonen maps. IEEE Conf. on
Visual Analytics in Science and Technology (VAST), pages 3–10, 2008.

[50] M. Sedlmair, M. Brehmer, S. Ingram, and T. Munzner. Dimensionality
reduction in the wild: Gaps and guidance. Technical Report TR-2012-03,
Dept. of Computer Science, University of British Columbia, 2012.

[51] M. Sedlmair, C. Heinzl, S. Bruckner, H. Piringer, and T. Moller. Visual
IEEE Trans. on

parameter space analysis: A conceptual framework.
Visualization and Computer Graphics, 20(12):2161–2170, 2014.

[52] M. Sedlmair, T. Munzner, and M. Tory. Empirical guidance on scatterplot
and dimension reduction technique choices. IEEE Trans. on Visualization
and Computer Graphics, 19(12):2634–2643, 2013.

[53] J. Stahnke, M. D¨ork, B. M¨uller, and A. Thom. Probing projections: Inter-
action techniques for interpreting arrangements and errors of dimension-
ality reductions. IEEE Trans. on Visualization and Computer Graphics,
22(1):629–638, 2016.

[54] L. van der Maaten, E. Postma, and H. van den Herik. Dimensionality
reduction: A comparative review. Technical report, Tilburg Centre for
Creative Computing, Tilburg University, 2009.

[55] J. Venna, J. Peltonen, K. Nybo, H. Aidos, and S. Kaski. Information
retrieval perspective to nonlinear dimensionality reduction for data visual-
ization. Journal of Machine Learning Research, 11:451–490, 2010.

[56] T. von Landesberger, S. Fiebig, S. Bremm, A. Kuijper, and D. W. Fellner.
Interaction taxonomy for tracking of user actions in visual analytics ap-
plications. In Handbook of Human Centric Visualization, pages 653–670.
Springer, New York, 2014.

[57] A. Wism¨uller, M. Verleysen, M. Aupetit, and J. A. Lee. Recent advances
in nonlinear dimensionality reduction, manifold and topological learn-
ing. In ESANN 2010, 18th European Symposium on Artiﬁcial Neural
Networks,Bruges, Belgium, April 28-30, 2010, Proceedings, 2010.

[58] J. S. Yi, Y.-a. Kang, J. T. Stasko, and J. A. Jacko. Toward a deeper
understanding of the role of interaction in information visualization. IEEE
Trans. on Visualization and Computer Graphics, 13(6):1224–1231, 2007.
[59] B. Yu, R. Liu, and X. Yuan. MLMD: Multi-Layered Visualization for
Multi-Dimensional Data. In M. Hlawitschka and T. Weinkauf, editors,
EuroVis - Short Papers. The Eurographics Association, 2013.

","{""pos"":{""0"":1,""1"":2,""2"":3,""3"":4,""4"":5,""5"":6,""6"":7},""4"":{""0"":""visualization*"",""1"":""computer*"",""2"":""analytics*"",""3"":""graphics*"",""4"":""algorithms*"",""5"":""paper"",""6"":""literature""},""2"":{""0"":""dr"",""1"":""s"",""2"":""j"",""3"":""m"",""4"":""d*"",""5"":""t"",""6"":""c*""},""6"":{""0"":""papers*"",""1"":""scenarios*"",""2"":""analysis"",""3"":""process"",""4"":""model"",""5"":""interactions"",""6"":""selection""},""0"":{""0"":""starspire*"",""1"":""2013*"",""2"":""2014*"",""3"":""sedlmair*"",""4"":""2010*"",""5"":""201x*"",""6"":""konstanz*""},""1"":{""0"":""ieee"",""1"":""s4*"",""2"":""s1*"",""3"":""s2*"",""4"":""s3*"",""5"":""s5*"",""6"":""s6""},""5"":{""0"":""a*"",""1"":""different*"",""2"":""high*"",""3"":""reduction*"",""4"":""vast*"",""5"":""separation"",""6"":""theoretical""},""3"":{""0"":""shown*"",""1"":""found*"",""2"":""frequently*"",""3"":""appear*"",""4"":""appeared*"",""5"":""ability*"",""6"":""offers*""}}",2017,{},False,False,journalArticle,False,PN7N37WR,[],self.user,"{""Unnamed: 0"":{""0"":0,""1"":1,""2"":2,""3"":3,""4"":4,""5"":5,""6"":6,""7"":7,""8"":8,""9"":9,""10"":10,""11"":11,""12"":12,""13"":13,""14"":14,""15"":15,""16"":16,""17"":17,""18"":18,""19"":19,""20"":20,""21"":21,""22"":22,""23"":23,""24"":24,""25"":25,""26"":26,""27"":27,""28"":28,""29"":29,""30"":30,""31"":31,""32"":32,""33"":33,""34"":34,""35"":35,""36"":36,""37"":37,""38"":38,""39"":39,""40"":40,""41"":41,""42"":42,""43"":43,""44"":44,""45"":45,""46"":46,""47"":47,""48"":48,""49"":49,""50"":50,""51"":51,""52"":52,""53"":53,""54"":54,""55"":55,""56"":56,""57"":57,""58"":58,""59"":59,""60"":60,""61"":61,""62"":62,""63"":63,""64"":64,""65"":65,""66"":66,""67"":67,""68"":68,""69"":69,""70"":70,""71"":71,""72"":72,""73"":73,""74"":74,""75"":75,""76"":76,""77"":77,""78"":78,""79"":79,""80"":80,""81"":81,""82"":82,""83"":83,""84"":84,""85"":85,""86"":86,""87"":87,""88"":88,""89"":89,""90"":90,""91"":91,""92"":92,""93"":93,""94"":94,""95"":95,""96"":96,""97"":97,""98"":98,""99"":99,""100"":100,""101"":101},""C"":{""0"":29.6618663732,""1"":12.3465638988,""2"":19.1027707895,""3"":7.5715936606,""4"":12.0381058408,""5"":8.1124797109,""6"":5.241510009,""7"":6.3962207333,""8"":8.3239634904,""9"":5.9522170842,""10"":20.4960679947,""11"":5.3418118668,""12"":7.9878539608,""13"":20.3293084487,""14"":20.6343516681,""15"":8.5999176553,""16"":15.6641660532,""17"":22.0054220646,""18"":8.934015362,""19"":21.8003798454,""20"":27.4641360371,""21"":6.3206072161,""22"":27.4779461675,""23"":6.4791414076,""24"":26.5975807196,""25"":6.1147926973,""26"":16.0703419118,""27"":5.1266338591,""28"":7.5455291546,""29"":13.4412195288,""30"":13.0048545604,""31"":13.5951599223,""32"":5.5379670322,""33"":5.8567707721,""34"":18.3614396275,""35"":12.5470800195,""36"":5.3458016113,""37"":9.4727208295,""38"":15.0664077217,""39"":16.6633495886,""40"":8.4450019682,""41"":8.5844280898,""42"":9.4758843238,""43"":10.0504898288,""44"":17.8021577679,""45"":6.1527940372,""46"":7.4415927362,""47"":13.6642170589,""48"":11.3895729452,""49"":12.8544155102,""50"":5.2076192817,""51"":8.1478215006,""52"":6.1200051685,""53"":6.6965014293,""54"":7.405723168,""55"":7.1930670949,""56"":8.4826458693,""57"":15.1860574624,""58"":6.1470803706,""59"":6.2712213401,""60"":10.7585696055,""61"":14.7295982453,""62"":5.3726917082,""63"":5.3125367275,""64"":5.5606065218,""65"":7.6055627325,""66"":8.8362979082,""67"":10.2590738419,""68"":10.0608816893,""69"":6.1063333333,""70"":5.1331869864,""71"":5.477705547,""72"":5.1073968449,""73"":5.7262711555,""74"":8.7493244651,""75"":11.3340782835,""76"":5.9807413049,""77"":6.1028191505,""78"":9.9817526338,""79"":6.9258065599,""80"":8.3396228349,""81"":5.2609425299,""82"":7.1554760022,""83"":7.5602493279,""84"":7.2247484361,""85"":8.4700786691,""86"":8.4661817567,""87"":5.5752036182,""88"":5.3261684508,""89"":5.6808178961,""90"":8.3883925488,""91"":8.2846677738,""92"":5.0424146771,""93"":6.2989725316,""94"":6.6423637694,""95"":6.1073808597,""96"":5.416233426,""97"":6.5593243603,""98"":5.7139053005,""99"":5.0192298672,""100"":5.5943135554,""101"":5.5943822378},""count"":{""0"":378,""1"":236,""2"":140,""3"":132,""4"":100,""5"":90,""6"":88,""7"":86,""8"":78,""9"":72,""10"":66,""11"":62,""12"":60,""13"":60,""14"":60,""15"":56,""16"":56,""17"":54,""18"":54,""19"":50,""20"":50,""21"":48,""22"":48,""23"":46,""24"":46,""25"":44,""26"":42,""27"":40,""28"":40,""29"":40,""30"":36,""31"":34,""32"":34,""33"":34,""34"":34,""35"":30,""36"":28,""37"":28,""38"":28,""39"":28,""40"":26,""41"":26,""42"":24,""43"":24,""44"":24,""45"":24,""46"":24,""47"":24,""48"":22,""49"":22,""50"":20,""51"":20,""52"":20,""53"":20,""54"":20,""55"":20,""56"":18,""57"":18,""58"":18,""59"":18,""60"":18,""61"":18,""62"":18,""63"":18,""64"":18,""65"":18,""66"":18,""67"":18,""68"":18,""69"":16,""70"":16,""71"":16,""72"":16,""73"":16,""74"":16,""75"":16,""76"":14,""77"":14,""78"":14,""79"":12,""80"":12,""81"":12,""82"":12,""83"":12,""84"":10,""85"":10,""86"":10,""87"":10,""88"":10,""89"":10,""90"":10,""91"":10,""92"":10,""93"":8,""94"":8,""95"":8,""96"":8,""97"":8,""98"":8,""99"":8,""100"":8,""101"":8},""sigma_nor"":{""0"":2.496911462,""1"":1.7779084904,""2"":2.5432805386,""3"":1.6217842373,""4"":2.1293045864,""5"":1.7924461775,""6"":1.5111451379,""7"":1.6338059213,""8"":1.8662921401,""9"":1.6354822373,""10"":3.3251685181,""11"":1.6050248073,""12"":1.9292726034,""13"":3.4030168642,""14"":3.4394433401,""15"":2.0317987122,""16"":2.9009679268,""17"":3.7229407096,""18"":2.0892906825,""19"":3.7862474299,""20"":4.5177579499,""21"":1.7999794398,""22"":4.5802676627,""23"":1.8349107165,""24"":4.5264985882,""25"":1.8001075696,""26"":3.1982422939,""27"":1.6902857819,""28"":2.0332447776,""29"":2.8691553081,""30"":2.8841028187,""31"":3.0157891683,""32"":1.7957291972,""33"":1.8440040352,""34"":3.7375227991,""35"":2.9475412768,""36"":1.8215946303,""37"":2.495790246,""38"":3.4096048807,""39"":3.6704898528,""40"":2.3634108923,""41"":2.3868378837,""42"":2.5803487295,""43"":2.6798173783,""44"":4.0216909408,""45"":2.0050961469,""46"":2.2281971511,""47"":3.3053814595,""48"":2.9699029459,""49"":3.2316450594,""50"":1.8911081499,""51"":2.434552755,""52"":2.0597466146,""53"":2.1663017967,""54"":2.2973889461,""55"":2.2580832158,""56"":2.5468301049,""57"":3.8316008865,""58"":2.0991973929,""59"":2.122990157,""60"":2.983031922,""61"":3.7441162591,""62"":1.9507786493,""63"":1.9392493913,""64"":1.9867942599,""65"":2.3787290162,""66"":2.6146107865,""67"":2.8872989428,""68"":2.8493135851,""69"":2.1287037518,""70"":1.9347641612,""71"":2.0034237095,""72"":1.9296244106,""73"":2.0529606702,""74"":2.6554288634,""75"":3.1705477857,""76"":2.1433269314,""77"":2.1687055033,""78"":2.9750909026,""79"":2.3920062005,""80"":2.6997210709,""81"":2.0296511842,""82"":2.4419933904,""83"":2.5300916629,""84"":2.5166959831,""85"":2.8016339487,""86"":2.800742315,""87"":2.1392716405,""88"":2.0822911127,""89"":2.1634367307,""90"":2.782943744,""91"":2.7592109817,""92"":2.0173667891,""93"":2.3551153068,""94"":2.4380759155,""95"":2.3088282733,""96"":2.1418525165,""97"":2.4180142507,""98"":2.2137676884,""99"":2.0459395948,""100"":2.1848752682,""101"":2.1848918613},""vocab_index"":{""0"":0,""1"":1,""2"":3,""3"":4,""4"":7,""5"":8,""6"":9,""7"":10,""8"":12,""9"":13,""10"":16,""11"":19,""12"":23,""13"":24,""14"":25,""15"":27,""16"":28,""17"":29,""18"":30,""19"":31,""20"":36,""21"":39,""22"":40,""23"":42,""24"":44,""25"":46,""26"":47,""27"":49,""28"":56,""29"":57,""30"":61,""31"":63,""32"":65,""33"":69,""34"":70,""35"":72,""36"":81,""37"":82,""38"":83,""39"":84,""40"":86,""41"":87,""42"":88,""43"":94,""44"":96,""45"":97,""46"":98,""47"":99,""48"":102,""49"":104,""50"":113,""51"":115,""52"":116,""53"":118,""54"":119,""55"":120,""56"":125,""57"":126,""58"":127,""59"":128,""60"":139,""61"":140,""62"":142,""63"":143,""64"":149,""65"":150,""66"":151,""67"":152,""68"":153,""69"":154,""70"":155,""71"":159,""72"":171,""73"":176,""74"":177,""75"":178,""76"":204,""77"":209,""78"":210,""79"":233,""80"":238,""81"":243,""82"":253,""83"":254,""84"":262,""85"":273,""86"":274,""87"":280,""88"":302,""89"":322,""90"":327,""91"":329,""92"":330,""93"":356,""94"":357,""95"":392,""96"":394,""97"":426,""98"":427,""99"":443,""100"":444,""101"":446},""word"":{""0"":""dr"",""1"":""interaction"",""2"":""papers"",""3"":""visualization"",""4"":""analyst"",""5"":""scenarios"",""6"":""analysis"",""7"":""process"",""8"":""model"",""9"":""interactions"",""10"":""ieee"",""11"":""pipeline"",""12"":""s"",""13"":""computer"",""14"":""j"",""15"":""work"",""16"":""selection"",""17"":""a"",""18"":""methods"",""19"":""analytics"",""20"":""m"",""21"":""different"",""22"":""graphics"",""23"":""cluster"",""24"":""d"",""25"":""points"",""26"":""s4"",""27"":""algorithms"",""28"":""paper"",""29"":""emphasis"",""30"":""t"",""31"":""c"",""32"":""high"",""33"":""quality"",""34"":""trans"",""35"":""reduction"",""36"":""literature"",""37"":""s1"",""38"":""pages"",""39"":""p"",""40"":""manual"",""41"":""shown"",""42"":""dimensionality"",""43"":""coding"",""44"":""keyword"",""45"":""parameters"",""46"":""s2"",""47"":""conf"",""48"":""table"",""49"":""h"",""50"":""vast"",""51"":""found"",""52"":""s3"",""53"":""s5"",""54"":""s6"",""55"":""s7"",""56"":""university"",""57"":""mail"",""58"":""l"",""59"":""technology"",""60"":""\ufb01ltering"",""61"":""keywords"",""62"":""annotation"",""63"":""starspire"",""64"":""b"",""65"":""2013"",""66"":""2014"",""67"":""science"",""68"":""k"",""69"":""sedlmair"",""70"":""lee"",""71"":""f"",""72"":""labels"",""73"":""items"",""74"":""2010"",""75"":""forum"",""76"":""labeling"",""77"":""separation"",""78"":""v"",""79"":""sample"",""80"":""criteria"",""81"":""frequently"",""82"":""appear"",""83"":""appeared"",""84"":""daniel"",""85"":""xx"",""86"":""201x"",""87"":""theoretical"",""88"":""initial"",""89"":""de\ufb01ning"",""90"":""document"",""91"":""end"",""92"":""acm"",""93"":""konstanz"",""94"":""xxx"",""95"":""vis"",""96"":""occurrences"",""97"":""dots"",""98"":""upper"",""99"":""ability"",""100"":""7a"",""101"":""offers""},""vector"":{""0"":""[ 5.65461   -0.5433018  2.2061276  3.8305895  2.0342393 -1.8007226\n -1.2372174 -5.523957  -6.6651144 -1.868221 ]"",""1"":""[ 4.4883122 -1.5478951 -0.5121506  5.7696276  5.718359  -1.4672216\n -2.4064574 -7.2237787 -4.5424695 -2.3369224]"",""2"":""[ 4.674046   -1.9200631  -0.08422561  6.06912     5.620145   -0.88459903\n -3.0414062  -6.751376   -4.448074   -2.1568935 ]"",""3"":""[ 5.222968  -2.0266106 -0.7209619  5.7903895  5.033263  -1.1599315\n -2.0889845 -6.9930043 -4.634169  -2.3643785]"",""4"":""[ 5.060564  -2.033141  -0.9122343  5.8385835  5.3995967 -1.4542266\n -2.3257213 -6.8598    -4.551448  -2.2765834]"",""5"":""[ 4.525461  -1.5799757 -0.5424979  6.2070293  5.6278024 -1.2707907\n -2.3452024 -6.712232  -4.2039948 -1.6103826]"",""6"":""[ 4.9444985 -1.8356321 -0.5979621  5.909764   5.5496755 -1.7783566\n -2.3578353 -6.892848  -4.8244834 -2.405351 ]"",""7"":""[ 4.5179796  -1.5344095  -0.28829968  6.2787986   5.687184   -1.7458476\n -2.327003   -7.012412   -4.9300604  -1.7606786 ]"",""8"":""[ 4.404163   -1.5821785  -0.55732876  6.2362394   5.4734874  -1.5170143\n -2.373644   -6.880145   -4.662596   -1.7967561 ]"",""9"":""[ 4.4040833 -1.4940768 -0.5611535  5.942574   5.854619  -1.3929176\n -2.4023771 -7.053587  -4.270376  -1.9667245]"",""10"":""[ 4.9453316  -0.88842934  1.356219    4.0497375   2.5508864  -1.4587338\n -0.65619123 -5.6903934  -6.1875587  -1.8290961 ]"",""11"":""[ 4.6014066  -1.6946814  -0.57028383  6.0124254   5.5226407  -1.4973587\n -2.2084749  -7.22879    -4.844863   -1.698488  ]"",""12"":""[ 5.589356  -0.5951398  2.3846188  3.6774528  2.2134876 -1.8589822\n -1.7940702 -5.1792226 -6.6596413 -2.2479725]"",""13"":""[ 4.88387    -2.090207   -0.3554484   5.7070074   5.343591   -0.99123675\n -2.4996243  -7.372476   -4.841842   -2.4054568 ]"",""14"":""[ 5.31304    -0.46042803  2.0884373   3.58987     1.8787545  -1.5997262\n -1.1893749  -5.128594   -6.4704685  -2.0081465 ]"",""15"":""[ 4.557733   -1.8619283  -0.24037376  6.055641    5.857789   -1.5830543\n -2.7333403  -7.2857685  -5.0192914  -2.338626  ]"",""16"":""[ 4.61128    -1.4672283  -0.08382229  6.0364895   5.7415032  -1.8967394\n -2.1984987  -6.98742    -4.975842   -2.0155573 ]"",""17"":""[ 4.575705  -1.2928739  0.401281   5.684019   5.765583  -2.3404365\n -2.2934332 -6.991844  -5.3715224 -2.8958063]"",""18"":""[ 4.867285   -1.707309   -0.50043535  6.2190404   5.7668962  -1.3949069\n -2.335499   -6.889684   -4.394218   -1.7611187 ]"",""19"":""[ 5.139979  -2.0648105 -0.8704391  5.8022914  5.2567825 -1.2345344\n -2.2538955 -6.977511  -4.533806  -2.2824395]"",""20"":""[ 5.6876645 -0.4786019  2.2836473  3.687831   1.9291017 -1.8370432\n -1.6103835 -5.180201  -6.7351623 -2.088234 ]"",""21"":""[ 4.753257   -1.2667711   0.47439367  5.879809    5.7685556  -2.3047838\n -2.1623483  -6.969932   -5.271712   -2.8490856 ]"",""22"":""[ 5.0410514 -2.0161047 -0.5083932  5.8195095  5.316891  -1.0187902\n -2.1807885 -7.274979  -4.6081247 -2.2739825]"",""23"":""[ 4.787257   -1.8090327  -0.14626461  6.0076594   5.135978   -1.4093523\n -2.0888505  -6.544272   -4.6779985  -2.3500342 ]"",""24"":""[ 5.527528   -0.53264225  2.1028922   3.5385592   2.2079973  -2.0737705\n -1.688122   -5.200642   -6.606067   -2.0816724 ]"",""25"":""[ 4.677471  -1.6705451  0.1347546  6.211633   5.693822  -1.0477554\n -2.4158676 -6.462331  -4.117849  -1.9322855]"",""26"":""[ 4.294607   -1.3353838   1.2921383   3.4877076   2.8566191  -1.845625\n -0.32087442 -5.590256   -6.4800215  -2.2518702 ]"",""27"":""[ 5.037801  -1.933     -0.6609376  6.022376   5.3139186 -0.9635689\n -2.1789315 -7.063058  -4.364555  -1.956742 ]"",""28"":""[ 4.68255    -2.0017266  -0.15959293  6.0688047   5.5410876  -1.0728215\n -3.029296   -6.958041   -4.846611   -2.3176484 ]"",""29"":""[ 4.7450852  -1.781209   -0.40651247  5.9640346   5.8056436  -1.8779778\n -2.5672133  -7.070518   -4.9932804  -2.3772998 ]"",""30"":""[ 5.455673  -0.694013   2.1067605  3.4593928  2.1339347 -2.0330346\n -1.697694  -5.0973344 -6.7261386 -2.035253 ]"",""31"":""[ 5.4043455 -0.661798   1.7602596  3.5906851  2.235996  -2.0644932\n -1.4811218 -5.2562704 -6.6406794 -1.9443036]"",""32"":""[ 4.6444206 -1.2011373  0.5645477  5.688652   5.6199903 -2.420752\n -2.2623522 -6.962668  -5.5461264 -2.890901 ]"",""33"":""[ 4.5484843  -1.4900784   0.05981984  5.795311    5.7917113  -1.849594\n -2.1881614  -7.243041   -5.1270847  -2.0255847 ]"",""34"":""[ 5.433983   -0.62354344  1.9053173   3.9541354   2.6803193  -1.9307857\n -1.5714321  -5.6567736  -6.306418   -1.9355316 ]"",""35"":""[ 4.607745  -1.3600713  0.0165657  5.7060003  5.550855  -2.154109\n -2.3788748 -6.9172864 -5.197193  -2.8658051]"",""36"":""[ 4.675688   -1.999877   -0.20440607  5.57616     5.527459   -1.2085545\n -2.7720985  -7.3299904  -5.0335493  -2.4232695 ]"",""37"":""[ 4.2491555  -1.2628977   1.4136585   3.444181    3.016861   -1.8057162\n -0.34131944 -5.5188     -6.357058   -2.4046187 ]"",""38"":""[ 4.6470337  -1.7918297  -0.13855858  5.998381    5.5230975  -0.71189314\n -2.789331   -6.594352   -4.0763664  -1.9495782 ]"",""39"":""[ 5.454926   -0.52876544  1.7929327   3.8468802   2.4293547  -1.9258146\n -1.6951778  -5.396333   -6.3003163  -1.8839866 ]"",""40"":""[ 4.6101413  -1.8279148  -0.29865524  6.4296155   5.732026   -1.4829425\n -2.7027047  -7.134315   -4.931245   -2.0839148 ]"",""41"":""[ 4.296025   -1.0711656   0.75718516  5.706287    6.2730126  -2.0658805\n -1.7734163  -6.9415317  -4.7323055  -2.3476775 ]"",""42"":""[ 5.169567   -1.96402    -0.65881693  5.869315    4.99944    -0.9341511\n -2.0823824  -6.903266   -4.4523416  -2.012941  ]"",""43"":""[ 4.9658175  -1.8758438  -0.51002926  6.134433    5.445025   -1.1851193\n -2.153604   -7.26339    -4.579094   -2.273881  ]"",""44"":""[ 5.054366   -1.8705171  -0.47749278  6.0485773   5.0747952  -0.72315264\n -2.365958   -6.618367   -4.2151318  -1.802576  ]"",""45"":""[ 4.758521  -1.6442503 -0.3886723  6.2319     5.4924126 -1.1218389\n -2.225579  -6.701292  -4.220947  -1.6642866]"",""46"":""[ 4.303367   -1.2293977   1.3753376   3.4553425   3.070953   -1.8195802\n -0.40437332 -5.5134435  -6.2991605  -2.448728  ]"",""47"":""[ 5.193637  -0.7363088  1.6198022  4.121771   2.5146534 -1.579161\n -0.8453462 -5.7423472 -6.256603  -1.7758448]"",""48"":""[ 4.5046988  -1.5322174   0.29542324  6.1663384   5.5517826  -1.4409807\n -2.3917725  -6.3375945  -4.5007315  -2.1233666 ]"",""49"":""[ 5.5612006 -0.3829743  2.1459324  3.742095   1.97217   -1.8359656\n -1.362156  -5.304748  -6.621127  -1.9109024]"",""50"":""[ 4.7892075 -1.1678103  0.6548302  5.9144363  5.648693  -2.4524636\n -2.2050881 -6.8876114 -5.4561934 -2.882755 ]"",""51"":""[ 4.180965   -1.0706031   0.92210525  5.5897465   6.239628   -2.092314\n -1.5942059  -6.9014325  -4.6926274  -2.2723808 ]"",""52"":""[ 4.2945795  -1.2425294   1.3769867   3.5137317   3.0512674  -1.7952688\n -0.38624913 -5.5607867  -6.319634   -2.406666  ]"",""53"":""[ 4.464154   -1.1622162   1.3110064   3.6327782   2.997307   -1.7559677\n -0.57935685 -5.6222034  -6.2788653  -2.419709  ]"",""54"":""[ 4.542232   -1.0972681   1.1913509   3.678463    2.9071233  -1.6341207\n -0.53190094 -5.542724   -6.367895   -2.4032085 ]"",""55"":""[ 4.4103394 -1.2709663  1.2685161  3.6867986  2.9486485 -1.7624027\n -0.482849  -5.6707    -6.2986975 -2.2736847]"",""56"":""[ 4.7396636  -2.0096443  -0.093308    5.4147687   5.201654   -0.98215955\n -2.6736956  -7.252221   -5.036553   -2.4108412 ]"",""57"":""[ 4.6194882 -1.9691705 -0.1418054  6.136264   5.634601  -1.1472911\n -3.0652695 -6.952065  -4.7828274 -2.2906787]"",""58"":""[ 5.482816   -0.41010413  2.2208445   3.6924074   2.0640507  -1.7847757\n -1.5316241  -5.2169185  -6.534826   -2.0648718 ]"",""59"":""[ 4.729568   -1.9295177  -0.49211085  5.559861    5.4049187  -1.1958358\n -2.278031   -7.363641   -4.785701   -2.1998289 ]"",""60"":""[ 4.8513665  -1.3613185   0.09934597  6.10989     5.7461796  -1.9842436\n -2.0685794  -7.039854   -4.916462   -2.6347675 ]"",""61"":""[ 4.8664055 -1.8396999 -0.3549393  6.04049    5.3206425 -0.7234955\n -2.5211349 -6.631437  -4.1202507 -1.820007 ]"",""62"":""[ 5.192527  -1.7883134 -0.4299827  6.2741756  5.2599373 -1.1788417\n -2.1710913 -6.907122  -4.4565797 -2.4877698]"",""63"":""[ 5.181573   -1.7957941   0.09826135  5.217218    4.1904597  -1.0361454\n -1.8507617  -6.5431795  -5.1289444  -2.1580708 ]"",""64"":""[ 5.4805193  -0.44766733  1.9347807   3.6333318   2.2499688  -2.0523274\n -1.3426493  -5.3708653  -6.537098   -1.9613129 ]"",""65"":""[ 4.5976677  -1.5249327   0.31872347  5.1462064   4.2439976  -1.6813416\n -1.315524   -6.353496   -5.215171   -2.3289888 ]"",""66"":""[ 4.557661   -1.481266    0.34632358  5.204609    4.3007255  -1.58689\n -1.3965168  -6.4342327  -5.214699   -2.204441  ]"",""67"":""[ 4.7359366  -2.0115736  -0.23368388  5.5143976   5.414991   -1.1440804\n -2.65886    -7.3547974  -5.013684   -2.429128  ]"",""68"":""[ 5.3860345 -0.326537   1.9354708  3.7573853  2.0501945 -1.7309793\n -1.2861589 -5.265516  -6.398801  -1.8588684]"",""69"":""[ 5.0788054 -1.7590173  0.270917   5.0496135  4.1870584 -1.1254587\n -1.8868101 -6.6184025 -5.3132524 -2.2724602]"",""70"":""[ 5.3170652  -0.67920125  1.8000417   3.7137928   1.9075735  -1.6909658\n -1.0316184  -5.333252   -6.6439037  -1.7691612 ]"",""71"":""[ 5.4716864  -0.24873587  1.8994404   3.784373    2.221724   -1.9287647\n -1.4709516  -5.3156137  -6.363418   -1.909099  ]"",""72"":""[ 5.062166   -1.6151206  -0.01218046  6.259358    5.396326   -1.0135863\n -2.0779502  -6.7584767  -4.175787   -2.3617787 ]"",""73"":""[ 4.605064   -1.739803   -0.07279787  6.2102222   5.6476464  -0.9862611\n -2.7450984  -6.5197477  -4.206184   -1.908697  ]"",""74"":""[ 4.5987606  -1.4959997   0.40228894  5.0257816   4.1126494  -1.6150151\n -1.22609    -6.2921658  -5.3043423  -2.2621334 ]"",""75"":""[ 4.554148   -1.8274602  -0.23250727  5.5668263   5.4940805  -0.9208869\n -2.6994255  -7.1225934  -4.5324407  -2.2495584 ]"",""76"":""[ 5.086191   -1.5281198  -0.18262015  6.1825523   5.480579   -1.4530189\n -2.0289824  -6.9916763  -4.5074735  -2.6058776 ]"",""77"":""[ 4.6414485 -1.5053791 -0.2721279  5.7643275  5.5924864 -1.8697151\n -2.478027  -7.0341535 -4.9535937 -2.7541928]"",""78"":""[ 5.429503   -0.59890085  1.9979913   3.707938    2.3325102  -1.9219742\n -1.4526064  -5.351416   -6.5434904  -2.0364473 ]"",""79"":""[ 4.713153   -1.7150115  -0.12081717  6.1319256   5.430429   -1.7064463\n -2.2807677  -6.5534086  -4.800256   -2.3109186 ]"",""80"":""[ 4.792203   -1.6253222  -0.19652222  6.1535234   5.5743527  -1.2425627\n -2.230936   -6.696595   -4.4009223  -1.5363076 ]"",""81"":""[ 4.2432747 -1.2088579  0.6389935  5.5879045  6.0993886 -2.0692127\n -1.75206   -7.0614557 -4.8549438 -2.2517793]"",""82"":""[ 4.243454  -1.1131134  0.8745306  5.5477085  5.962017  -2.0928054\n -1.6161864 -6.818297  -4.8576107 -2.3320374]"",""83"":""[ 4.176285  -1.0964066  0.9171344  5.5798717  6.209798  -2.0782537\n -1.5759732 -6.906728  -4.6955557 -2.2422361]"",""84"":""[ 5.342405   -0.5737186   1.9437861   3.8265948   1.987794   -1.5938108\n -0.87802446 -5.4994216  -6.5170527  -1.774239  ]"",""85"":""[ 5.358418  -0.4714041  2.0808132  3.8992217  2.3346448 -1.7785087\n -1.0643544 -5.664161  -6.3766646 -1.8524889]"",""86"":""[ 4.63504    -1.4771858   0.46753573  4.942429    3.993418   -1.6035515\n -1.2179409  -6.2735376  -5.3737593  -2.266263  ]"",""87"":""[ 4.783141   -1.6143143   0.22067346  5.73002     5.629878   -1.9944981\n -2.5280802  -6.9938645  -5.3278184  -2.7620478 ]"",""88"":""[ 4.6244802  -1.361981    0.34530443  5.759129    5.6459556  -2.230217\n -2.3459468  -6.8872266  -5.373681   -2.726783  ]"",""89"":""[ 5.2360783 -0.76575    1.6196226  3.7573357  2.0226877 -1.7140313\n -1.0878134 -5.3383155 -6.590681  -1.7233205]"",""90"":""[ 4.586571   -1.8094217  -0.14466113  6.4286366   5.6025705  -1.3854294\n -2.7945056  -6.8798203  -4.8738966  -2.1508589 ]"",""91"":""[ 4.5378423  -1.1709075   0.65506184  5.6094933   5.4427843  -2.2304864\n -2.0619488  -6.7099137  -5.338516   -2.7814138 ]"",""92"":""[ 5.1002355  -0.78513306  1.5072256   4.0714726   2.4584749  -1.4794422\n -0.7447021  -5.6741934  -6.225091   -1.7573165 ]"",""93"":""[ 5.03211    -1.838016    0.21586144  5.0978236   4.4688754  -1.0721\n -2.1472101  -6.843254   -5.288924   -2.363243  ]"",""94"":""[ 5.2780986  -0.5731963   1.9549677   4.016808    2.3893628  -1.6580215\n -0.87657815 -5.7696414  -6.3174014  -1.7932976 ]"",""95"":""[ 5.374612   -0.71793854  1.8834364   3.719141    2.485767   -1.995641\n -1.3784732  -5.418861   -6.5829854  -2.0570548 ]"",""96"":""[ 4.575549  -1.6521744 -0.3582353  6.1628585  5.7024107 -1.0432247\n -2.5536573 -6.6124573 -4.0339346 -1.7663565]"",""97"":""[ 4.8594933  -1.6923838   0.10425808  6.164901    5.447626   -0.942907\n -2.193833   -6.5617437  -4.120141   -2.1835406 ]"",""98"":""[ 4.6180773  -1.2084551   0.58670783  5.624814    5.524649   -2.3090212\n -2.174744   -6.846927   -5.437074   -2.881354  ]"",""99"":""[ 4.383423   -1.4227136   0.03720729  5.652997    5.962358   -1.739533\n -2.0921135  -7.318851   -4.8484826  -2.015022  ]"",""100"":""[ 4.490011  -1.2076541  1.2676504  3.5489047  2.7830188 -1.778765\n -0.567996  -5.5709033 -6.3849444 -2.3404713]"",""101"":""[ 4.168293  -1.157868   0.8518542  5.631467   6.325771  -2.038525\n -1.5900704 -6.9970536 -4.6086316 -2.1434016]""},""topic"":{""0"":2,""1"":-1,""2"":6,""3"":4,""4"":-1,""5"":6,""6"":6,""7"":6,""8"":6,""9"":6,""10"":1,""11"":-1,""12"":2,""13"":4,""14"":2,""15"":-1,""16"":6,""17"":5,""18"":6,""19"":4,""20"":2,""21"":5,""22"":4,""23"":-1,""24"":2,""25"":6,""26"":1,""27"":4,""28"":4,""29"":6,""30"":2,""31"":2,""32"":5,""33"":-1,""34"":2,""35"":5,""36"":4,""37"":1,""38"":6,""39"":2,""40"":6,""41"":3,""42"":4,""43"":4,""44"":-1,""45"":6,""46"":1,""47"":2,""48"":-1,""49"":2,""50"":5,""51"":3,""52"":1,""53"":1,""54"":1,""55"":1,""56"":4,""57"":6,""58"":2,""59"":4,""60"":-1,""61"":6,""62"":4,""63"":0,""64"":2,""65"":0,""66"":0,""67"":4,""68"":2,""69"":0,""70"":2,""71"":2,""72"":-1,""73"":6,""74"":0,""75"":4,""76"":-1,""77"":5,""78"":2,""79"":-1,""80"":6,""81"":3,""82"":3,""83"":3,""84"":2,""85"":2,""86"":0,""87"":5,""88"":5,""89"":2,""90"":6,""91"":5,""92"":2,""93"":0,""94"":2,""95"":2,""96"":6,""97"":-1,""98"":5,""99"":3,""100"":1,""101"":3},""exemplar"":{""0"":null,""1"":null,""2"":""*"",""3"":""*"",""4"":null,""5"":""*"",""6"":null,""7"":null,""8"":null,""9"":null,""10"":null,""11"":null,""12"":null,""13"":""*"",""14"":null,""15"":null,""16"":null,""17"":""*"",""18"":null,""19"":""*"",""20"":null,""21"":""*"",""22"":""*"",""23"":null,""24"":""*"",""25"":null,""26"":""*"",""27"":""*"",""28"":null,""29"":null,""30"":null,""31"":""*"",""32"":""*"",""33"":null,""34"":null,""35"":""*"",""36"":null,""37"":""*"",""38"":""*"",""39"":null,""40"":null,""41"":""*"",""42"":""*"",""43"":null,""44"":null,""45"":""*"",""46"":""*"",""47"":null,""48"":null,""49"":""*"",""50"":""*"",""51"":""*"",""52"":""*"",""53"":""*"",""54"":null,""55"":""*"",""56"":null,""57"":null,""58"":""*"",""59"":null,""60"":null,""61"":""*"",""62"":null,""63"":""*"",""64"":""*"",""65"":""*"",""66"":""*"",""67"":""*"",""68"":null,""69"":""*"",""70"":null,""71"":""*"",""72"":null,""73"":""*"",""74"":""*"",""75"":null,""76"":null,""77"":null,""78"":""*"",""79"":null,""80"":null,""81"":""*"",""82"":""*"",""83"":""*"",""84"":null,""85"":null,""86"":""*"",""87"":null,""88"":""*"",""89"":null,""90"":null,""91"":null,""92"":null,""93"":""*"",""94"":null,""95"":null,""96"":""*"",""97"":null,""98"":""*"",""99"":""*"",""100"":""*"",""101"":""*""},""word*"":{""0"":""dr"",""1"":""interaction"",""2"":""papers*"",""3"":""visualization*"",""4"":""analyst"",""5"":""scenarios*"",""6"":""analysis"",""7"":""process"",""8"":""model"",""9"":""interactions"",""10"":""ieee"",""11"":""pipeline"",""12"":""s"",""13"":""computer*"",""14"":""j"",""15"":""work"",""16"":""selection"",""17"":""a*"",""18"":""methods"",""19"":""analytics*"",""20"":""m"",""21"":""different*"",""22"":""graphics*"",""23"":""cluster"",""24"":""d*"",""25"":""points"",""26"":""s4*"",""27"":""algorithms*"",""28"":""paper"",""29"":""emphasis"",""30"":""t"",""31"":""c*"",""32"":""high*"",""33"":""quality"",""34"":""trans"",""35"":""reduction*"",""36"":""literature"",""37"":""s1*"",""38"":""pages*"",""39"":""p"",""40"":""manual"",""41"":""shown*"",""42"":""dimensionality*"",""43"":""coding"",""44"":""keyword"",""45"":""parameters*"",""46"":""s2*"",""47"":""conf"",""48"":""table"",""49"":""h*"",""50"":""vast*"",""51"":""found*"",""52"":""s3*"",""53"":""s5*"",""54"":""s6"",""55"":""s7*"",""56"":""university"",""57"":""mail"",""58"":""l*"",""59"":""technology"",""60"":""\ufb01ltering"",""61"":""keywords*"",""62"":""annotation"",""63"":""starspire*"",""64"":""b*"",""65"":""2013*"",""66"":""2014*"",""67"":""science*"",""68"":""k"",""69"":""sedlmair*"",""70"":""lee"",""71"":""f*"",""72"":""labels"",""73"":""items*"",""74"":""2010*"",""75"":""forum"",""76"":""labeling"",""77"":""separation"",""78"":""v*"",""79"":""sample"",""80"":""criteria"",""81"":""frequently*"",""82"":""appear*"",""83"":""appeared*"",""84"":""daniel"",""85"":""xx"",""86"":""201x*"",""87"":""theoretical"",""88"":""initial*"",""89"":""de\ufb01ning"",""90"":""document"",""91"":""end"",""92"":""acm"",""93"":""konstanz*"",""94"":""xxx"",""95"":""vis"",""96"":""occurrences*"",""97"":""dots"",""98"":""upper*"",""99"":""ability*"",""100"":""7a*"",""101"":""offers*""},""pos"":{""0"":1,""1"":1,""2"":1,""3"":1,""4"":2,""5"":2,""6"":3,""7"":4,""8"":5,""9"":6,""10"":1,""11"":3,""12"":2,""13"":2,""14"":3,""15"":4,""16"":7,""17"":1,""18"":8,""19"":3,""20"":4,""21"":2,""22"":4,""23"":5,""24"":5,""25"":9,""26"":2,""27"":5,""28"":6,""29"":10,""30"":6,""31"":7,""32"":3,""33"":6,""34"":8,""35"":4,""36"":7,""37"":3,""38"":11,""39"":9,""40"":12,""41"":1,""42"":8,""43"":9,""44"":7,""45"":13,""46"":4,""47"":10,""48"":8,""49"":11,""50"":5,""51"":2,""52"":5,""53"":6,""54"":7,""55"":8,""56"":10,""57"":14,""58"":12,""59"":11,""60"":9,""61"":15,""62"":12,""63"":1,""64"":13,""65"":2,""66"":3,""67"":13,""68"":14,""69"":4,""70"":15,""71"":16,""72"":10,""73"":16,""74"":5,""75"":14,""76"":11,""77"":6,""78"":17,""79"":12,""80"":17,""81"":3,""82"":4,""83"":5,""84"":18,""85"":19,""86"":6,""87"":7,""88"":8,""89"":20,""90"":18,""91"":9,""92"":21,""93"":7,""94"":22,""95"":23,""96"":19,""97"":13,""98"":10,""99"":6,""100"":9,""101"":7},""x2D"":{""0"":10.8366117477,""1"":2.7992134094,""2"":1.8454233408,""3"":0.8798418045,""4"":1.3002142906,""5"":3.5801701546,""6"":2.1556565762,""7"":3.1427016258,""8"":3.2858483791,""9"":3.4591197968,""10"":11.8763284683,""11"":3.2004601955,""12"":10.1263122559,""13"":0.8275005817,""14"":10.9419269562,""15"":2.1961541176,""16"":3.0061023235,""17"":3.5931127071,""18"":3.5140311718,""19"":1.0610474348,""20"":10.2596111298,""21"":3.792787075,""22"":1.026160121,""23"":2.0135197639,""24"":9.9405384064,""25"":3.0544786453,""26"":14.1692066193,""27"":1.3183715343,""28"":1.522713542,""29"":2.5750508308,""30"":10.0966653824,""31"":9.9348688126,""32"":3.6903395653,""33"":3.2896173,""34"":10.5190134048,""35"":3.4867472649,""36"":0.9866490364,""37"":13.9506196976,""38"":3.1477954388,""39"":10.2867841721,""40"":2.3008048534,""41"":5.9403486252,""42"":1.0305844545,""43"":1.4857299328,""44"":2.7775549889,""45"":3.49990201,""46"":14.1368436813,""47"":11.6790323257,""48"":2.6837961674,""49"":10.6641016006,""50"":3.7585945129,""51"":5.6353731155,""52"":13.9267158508,""53"":13.8169870377,""54"":13.6854734421,""55"":13.9573822021,""56"":0.6395229101,""57"":1.7490031719,""58"":10.2955789566,""59"":0.8434132934,""60"":3.3899447918,""61"":3.0371336937,""62"":1.6487234831,""63"":-0.3456374705,""64"":10.1196832657,""65"":-0.6750991344,""66"":-0.8011239171,""67"":0.8145393729,""68"":10.8743543625,""69"":-0.3684749007,""70"":11.1323184967,""71"":10.5683879852,""72"":2.5623342991,""73"":3.0339212418,""74"":-0.6231010556,""75"":0.9636020064,""76"":1.9700826406,""77"":3.0883843899,""78"":10.1164627075,""79"":2.4015219212,""80"":3.5054326057,""81"":5.6585831642,""82"":5.8184213638,""83"":5.7100973129,""84"":11.3305921555,""85"":11.1757011414,""86"":-0.6371486783,""87"":3.4013390541,""88"":3.4644401073,""89"":11.3054857254,""90"":2.1441681385,""91"":3.9593977928,""92"":11.7675409317,""93"":-0.3769848049,""94"":11.4427232742,""95"":10.2908582687,""96"":3.3857431412,""97"":2.7757921219,""98"":3.7156538963,""99"":3.3026878834,""100"":14.0449533463,""101"":5.6528868675},""y2D"":{""0"":6.9116530418,""1"":0.822181344,""2"":1.1961191893,""3"":2.3213453293,""4"":2.3337886333,""5"":1.8838495016,""6"":1.4380153418,""7"":0.5100839734,""8"":1.0883374214,""9"":1.4210003614,""10"":6.2058348656,""11"":0.9239565134,""12"":7.3043260574,""13"":1.4994394779,""14"":6.9862675667,""15"":0.4755220115,""16"":0.1881621033,""17"":-1.7641911507,""18"":1.7218829393,""19"":2.2535881996,""20"":7.3084402084,""21"":-1.6724073887,""22"":1.9934321642,""23"":2.1845607758,""24"":6.9155840874,""25"":2.2162153721,""26"":5.0755391121,""27"":2.6715424061,""28"":0.8981733918,""29"":0.2091906816,""30"":7.0565156937,""31"":6.5376620293,""32"":-2.0760211945,""33"":-0.2022672892,""34"":6.3045063019,""35"":-1.562106967,""36"":1.0828225613,""37"":4.9730033875,""38"":2.7111635208,""39"":6.423263073,""40"":0.6776077747,""41"":-1.6162182093,""42"":2.4622905254,""43"":2.1901469231,""44"":2.9772148132,""45"":2.2393884659,""46"":5.2561473846,""47"":6.2949485779,""48"":2.076066494,""49"":7.0219097137,""50"":-2.0172421932,""51"":-1.3804637194,""52"":5.24304533,""53"":4.9134807587,""54"":4.9394669533,""55"":4.9892115593,""56"":1.2901835442,""57"":0.9587982893,""58"":7.1522912979,""59"":1.5472536087,""60"":-1.0174087286,""61"":2.8275215626,""62"":2.5895867348,""63"":2.9039356709,""64"":6.2710766792,""65"":3.179723978,""66"":3.0075390339,""67"":1.1877018213,""68"":6.8496923447,""69"":2.913517952,""70"":6.6119008064,""71"":6.4369874001,""72"":2.6210830212,""73"":2.3566789627,""74"":3.2542891502,""75"":1.1325497627,""76"":2.4540867805,""77"":-0.6788918376,""78"":6.6764140129,""79"":1.5647364855,""80"":2.1908659935,""81"":-1.7796905041,""82"":-1.4643563032,""83"":-1.4780951738,""84"":6.449256897,""85"":6.2093410492,""86"":3.2107174397,""87"":-1.4337915182,""88"":-1.6243863106,""89"":6.598221302,""90"":0.9237679243,""91"":-1.9195216894,""92"":6.285449028,""93"":2.9167659283,""94"":6.1511487961,""95"":6.5135111809,""96"":2.3588180542,""97"":2.4699501991,""98"":-1.8948634863,""99"":0.0023451298,""100"":4.8478221893,""101"":-1.6686105728}}",False,False,False,http://ieeexplore.ieee.org/document/7536217/,,Visual Interaction with Dimensionality Reduction: A Structured Literature Analysis,PN7N37WR,False,False
CJAT82Y9,IN4SMR4K,"See	discussions,	stats,	and	author	profiles	for	this	publication	at:	https://www.researchgate.net/publication/6451414

Value	and	Relation	Display:	Interactive	Visual
Exploration	of	Large	Data	Sets	with	Hundreds	of
Dimensions

Article		in		IEEE	Transactions	on	Visualization	and	Computer	Graphics	·	May	2007

DOI:	10.1109/TVCG.2007.1010	·	Source:	PubMed

CITATIONS
37

5	authors,	including:

READS
78

Matthew	Ward
Worcester	Polytechnic	Institute

133	PUBLICATIONS			3,082	CITATIONS			

Elke	Rundensteiner
Worcester	Polytechnic	Institute

567	PUBLICATIONS			7,531	CITATIONS			

SEE	PROFILE

SEE	PROFILE

All	content	following	this	page	was	uploaded	by	Matthew	Ward	on	12	March	2014.

The	user	has	requested	enhancement	of	the	downloaded	file.

Value and Relation Display: Interactive Visual
Exploration of Large Datasets with Hundreds of

Dimensions

1

Jing Yang

Dept of Computer Science

UNC Charlotte

jyang13@uncc.edu

Daniel Hubball
Dept of Computer Science
University of Wales Swansea

csdan@swansea.ac.uk

Matthew Ward
Dept of Computer Science

Worcester Polytechnic Institute

matt@cs.wpi.edu

Elke Rundensteiner
Dept of Computer Science

Worcester Polytechnic Institute

rundenst@cs.wpi.edu

William Ribarsky
Dept of Computer Science

UNC Charlotte

ribarsky@uncc.edu

Abstract— Few existing visualization systems can handle large
datasets with hundreds of dimensions, since high dimensional
datasets cause clutter on the display and large response time in
interactive exploration. In this paper, we present a signiﬁcantly
improved multi-dimensional visualization approach named Value
and Relation (VaR) display that allows users to effectively and
efﬁciently explore large datasets with several hundred dimen-
sions. In the VaR display, data values and dimension relationships
are explicitly visualized in the same display by using dimension
glyphs to explicitly represent values in dimensions and glyph
layout to explicitly convey dimension relationships. In particular,
pixel-oriented techniques and density-based scatterplots are used
to create dimension glyphs to convey values. Multi-dimensional
scaling, Jigsaw map hierarchy visualization techniques, and
an animation metaphor named Rainfall are used to convey
relationships among dimensions. A rich set of interaction tools
have been provided to allow users to interactively detect patterns
of interest in the VaR display. A prototype of the VaR display
has been fully implemented. The case studies presented in this
paper show how the prototype supports interactive exploration of
datasets of several hundred dimensions. A user study evaluating
the prototype is also reported in this paper.

Index Terms— Multi-dimensional visualization, high dimen-

sional datasets, visual analytics.

datasets in the Information Visualization ﬁeld. They include:
(cid:129) Using condensed displays to provide as much information
as possible to users. Typical approaches include pixel-
oriented techniques [12], [13] and density-based displays
[9], [24]. For example, in pixel-oriented techniques, infor-
mation is so condensed that each pixel presents a single
data value.

(cid:129) Examining relationships among dimensions to discover
lower dimensional spaces with signiﬁcant features. Ex-
ample approaches include ranking low dimensional pro-
jections by their features such as linear relationships [19],
and placing dimensions in a layout revealing their rela-
tionships to help users construct meaningful subspaces
[28].

(cid:129) Providing a rich set of interactions to allow users to
explore datasets from multiple coordinated views. In
these views, different subsets of dimensions and/or data
items can be examined at different levels of detail us-
ing different visualization techniques. Examples of such
approaches include the Hierarchical Parallel Coordinates
[10] and the VIS-5D system [11].

I. INTRODUCTION

Large datasets with hundreds of dimensions are common
in applications such as image analysis, ﬁnance, bioinformatics
and anti-terrorism. For example, in order to detect the semantic
contents of large image collections, it is common to analyze
hundreds of low level visual attributes of the images. It is
a challenge to make decisions based on these datasets, since
they are hard to analyze due to the dimensionality curse [5],
i.e., the lack of data separation in high dimensional space.
Using multi-dimensional visualization techniques to present
this data to analysts and allowing them to interactively explore
and understand the datasets are an important approach to
addressing this challenge. However, most traditional multi-
dimensional visualization techniques suffer from visual clutter
and only scale up to tens of dimensions. Up to now, few multi-
dimensional visualization systems have claimed to be scalable
to datasets with hundreds of dimensions. In this paper, we
present such a system, called the Value and Relation (VaR)
display, which is an improved version of a technique reported
in an earlier paper [27].

Our work is based on multiple concepts proposed and
explored in prior efforts toward visual exploration of large

The concepts above are signiﬁcant features of the VaR
display since its initial version [27]. In the ﬁrst version (see
ﬁgures 1a and b), pixel-oriented displays were used to show
data values and group them into dimension glyphs representing
individual dimensions. The dimension glyphs were then po-
sitioned on the screen using a fast Multi-dimensional scaling
(MDS) algorithm [4] according to dimension correlations to
reveal their inter-relationships (dimension correlation is used
since it is a typical measure of dimension relationships, but
other relationship measures can also be used). A rich set
of interactions were provided to facilitate navigation in the
display and generate lower dimensional spaces of interest. To
differentiate the ﬁrst version from the improved version, we
call it the Pixel MDS VaR display.

In the improved version of VaR presented in this paper,
these features are signiﬁcantly strengthened. A density-based
scatterplot [9], [24] has been added to the system as an alter-
nate approach to generating dimension glyphs. A Jigsaw map
layout [23] and the Rainfall metaphor have been added into the
system as alternate dimension glyph layout approaches. The
new version also supports a broader range of interaction tools
than the original version, including a new data item selection

2

Fig. 1.
(a) Illustration of the VaR display. On the left is the spreadsheet of a 4-dimensional dataset with each column representing a dimension. On the
bottom is a matrix that records the pair-wise relationships (such as correlations) among the dimensions. In the middle is the glyph of the fourth dimension.
On the right is the VaR display of the dataset. (b) The Pixel MDS VaR display of the Image-89 dataset (89 dimensions, 10,417 data itmes). (c) The X-Ray
scatterplot MDS VaR display of the same dataset.

and highlighting tool. The labeling issue, which was ignored in
the initial version, is addressed in this version. A case study is
included in this paper involving the visual analysis of a dataset
with 838 dimensions. A user study comparing the VaR display
with the rank-by-feature framework [19], [20] is also reported.
This paper is organized as follows. Section II reviews
related work. Section III brieﬂy introduces the original Pixel
MDS VaR display. Section IV presents the approach of us-
ing density-based scatterplots to generate dimension glyphs.
Section V describes the new Jigsaw and Rainfall dimension
glyph layout strategies. Section VI summarizes the correlation
calculation algorithm used in the VaR display. Section VII
presents the interaction tools. Section VIII addresses the
labeling issue. Section IX describes the implementation of
the VaR display and addresses the scalability issue.Section X
discusses visual exploration approaches with the VaR display.
Section XI presents a case study and Section XII presents
a user study for the VaR display. Section XIII presents our
conclusions and future work.

II. RELATED WORK

Many techniques exist for generating condensed displays
for large datasets. The work most related to our work is pixel-
oriented techniques and scatterplots. Pixel-oriented visualiza-
tion techniques [12], [13] are a family of multi-dimensional
display techniques that map each data value to a pixel on
the screen and arrange the pixels into subwindows to convey
relationships. The patterns of the subwindows may reveal
clusters, trends, and anomalies. Pixel-oriented techniques are
one among several options to create the dimension glyph in
the VaR display.

Scatterplots visualize 2-D datasets or 2-D projections of
multi-dimensional datasets. In a scatterplot, there is a hori-
zontal axis and a vertical axis, which are associated with two
dimensions (X and Y). The data items are plotted onto the
display according to their coordinates on X and Y. Scatterplots
are widely used since they provide rich information about the

relationship between two dimensions, such as strength, shape
(line, curve, etc), direction (positive or negative), and presence
of outliers [18]. Density-based scatterplots [24], [9] scale to
large datasets by using intensity of the spot in a scatterplot
to indicate the data density in that spot. We use the density-
based scatterplot as an option for generating the dimension
glyph and treat the areas with no data items in a scatterplot in
a different way from existing approaches due to the possible
overlaps among the scatterplots.

Scatterplots of multi-dimensional datasets are often orga-
nized together to show multiple 2D projections of the datasets.
Scatterplot matrices [7] organize the scatterplots of all N x (N-
1)/2 2-D projections of an N-dimensional dataset into a matrix.
Scatterplot matrices easily get cluttered when the number of
dimensions increases. Rather than displaying all 2D projec-
tions, we display N scatterplots between all dimensions and
a focus dimension and position them in a manner conveying
dimension relationships in our density-based scatterplot VaR
option.

There exist multiple visualization approaches to examining
relationships among dimensions to discover lower dimen-
sional spaces with signiﬁcant features. The rank-by-feature
framework [19] ranks 1D or 2D axis-parallel projections of
multi-dimensional datasets using statistical analysis to help
users detect 1D or 2D projections with desired features such
as linearly related dimensions. [16] visualizes correlations
between each pair of dimensions in a matrix and allows users
to interactively select dimensions from the matrix to con-
struct lower dimensional spaces. The interactive hierarchical
dimension reduction approach [28] visually conveys dimension
relationships using a dimension hierarchy to facilitate lower
dimensional space construction. The VaR display is different
from these approaches since it integrates data value visual-
ization with dimension relationship visualization in the same
display to use screen space more efﬁciently.

Multi-dimensional Scaling (MDS) [4], [15] is an itera-
tive non-linear optimization algorithm for projecting multi-

dimensional data down to a reduced number of dimensions.
It is often used to convey relationships among data items
of a multi-dimensional dataset. For example, IN-SPIRE [25]
uses MDS to map data items from a document dataset to
a 2D space. It generates a Galaxies display as a spatial
representation of relationships within the document collection.
In our approach, MDS is used in a different way, namely to
convey relationships among dimensions rather than data items.
The Jigsaw map [23] is a recent space ﬁlling hierarchy
layout method. By placing the leaf nodes of a hierarchy into
a 1D layout using a depth ﬁrst traversal and mapping the
1D layout
into a rectangular 2D mesh using space-ﬁlling
curves, this method creates hierarchy displays of nicely shaped
regions, good continuity and stability. When all leaf nodes are
of the same size, a Jigsaw map can draw all leaf nodes without
any distortion in shape, namely, they can be all equal-sized
squares. This property of the Jigsaw map makes it a perfect
option for us to lay out dimensions organized into a hierarchy
on a 2D mesh, with each dimension drawn as a square glyph.
The similarity based dimension arrangement proposed in
[1] also addressed the problem of arranging pixel oriented
subwindows (dimensions) on a 2D mesh. It aimed to place
similar dimensions close to each other on the 2D mesh. The
Jigsaw map dimension layout is different in that it aims to
use the dimension layout to convey the hierarchical structure
among the dimensions. As a consequence, not only similar
dimensions but also outlier dimensions are revealed.

[29] presents a multi-dimensional visualization technique
called Dust & Magnet. It represents dimensions as magnets
and data items as dust particles and attracts dust particles using
magnets to reveal data item values in the dimensions. The
Rainfall metaphor proposed in this paper was inspired by Dust
& Magnet. The difference is that the Rainfall metaphor attracts
dimensions using dimensions, while Dust & Magnet attracts
data items using dimensions.

III. PIXEL MDS VAR DISPLAY

Figure 1a illustrates the approach to generating a Pixel
MDS VaR display. First, a dimension glyph, called a glyph in
short, is generated to represent data values in each dimension,
i.e., values in the same column in the spreadsheet, using
pixel oriented techniques [13]. In particular, each value is
represented by a pixel whose color indicates a high or low
value, and pixels representing values from the same dimension
are grouped together to form a glyph. In a glyph, each pixel
occupies a unique position without overlap. In the original
version, a spiral pixel layout was used. Rows in the spreadsheet
are ordered according to their values in one dimension (Note:
actually any 1D order can be used). Data values in each
column are positioned into a spiral according to this order. In
all glyphs, pixels representing values in the same row occupy
the same position so that glyphs can be associated with each
other.

Second, the correlations among the dimensions are cal-
culated and recorded into an N x N matrix (where N is
the dimensionality of the dataset). In order to calculate the
correlations, different approaches can be used according to

3

different purposes. For example, if users are most interested
in linearly related dimensions, Pearson’s correlation coefﬁ-
cient can be used to capture the linear relationships among
dimensions. We proposed a scalable and ﬂexible correlation
calculation algorithm [27] and applied it in the VaR display.
We will brieﬂy introduce it in Section VI for the purpose of
completeness.

Third, the N x N relationship matrix is used to generate N
positions in a 2-D space, one position for each dimension. The
proximity among the positions reﬂects relationships among
the dimensions, i.e., closely related dimensions are spatially
close to each other, and unrelated dimensions are positioned
far way from each other. In particular, a multi-dimensional
scaling algorithm [4] is used to create the 2-D positions upon
the relationship matrix.

Finally, the dimension glyphs are placed in the 2-D space
in their corresponding positions to form the VaR display.
Figure 1b shows an example of the VaR display. It shows
the Image-89 dataset of 89 dimensions and 10,417 data items.
It is a real dataset containing 88 low level visual attributes
and classiﬁcation information for 10,417 image segments
generated by an image analysis approach [8]. In the ﬁgure,
each block is a dimension glyph and there are 89 glyphs.
In each glyph, data values of the dimension are mapped to
colors of pixels, and pixels are ordered in a spiral manner. The
closeness of the glyph positions reveals the correlations among
the dimensions calculated by the underlying algorithm. For
example, several clusters of closely correlated dimensions and
a few dimensions that are distinct from most other dimensions
can be detected from the glyph positions in Figure 1b.

The above approach can be summarized as dimension glyph
generation and layout. Glyphs explicitly convey data values
and their layout explicitly conveys dimension relationships.
Moreover, dimension relationships are also revealed by the
patterns of the glyphs. Similarity among glyph patterns in-
dicates dimension relationships, whether there is a linear or
non-linear relationship, or they are partially correlated (such
as dimensions for which a subset of the data items is closely
related). Since humans are good at pattern recognition, the
patterns of the glyphs provide straightforward and intuitive
comparison of the dimensions. On the one hand, the layout
approach brings related dimensions close to each other to make
the pattern comparison easier. On the other hand, the patterns
allow users to conﬁrm or refute the relationships suggested by
the layout using their eyes, and reveal how the dimensions are
related in detail.

Besides the techniques used in the original VaR display,
there are other approaches to creating glyphs and laying them
out, which will be introduced in the following sections. Since
glyph generation and layout are independent from each other,
they can be combined freely to form various VaR displays.

IV. DIMENSION GLYPH ALTERNATIVE: X-RAY

SCATTERPLOTS

The glyph generation approach used in the original VaR
display is not the only approach for creating dimension glyphs.
For example, different layouts of the pixels within a glyph

reveal different patterns. As an example, organizing pixels
into a calendar pattern according to the time stamps of the
data items can reveal time-dependant patterns among the data
items. Since these techniques have been widely studied in
pixel-oriented techniques [12] and they can be integrated
into the VaR display easily by replacing the original pixel-
oriented dimension glyph generation approach, they will not
be discussed in this paper. Instead, we present our work
on customizing a density-based scatterplot glyph (called an
X-Ray glyph) generation approach. This approach has been
introduced into the improved version (see Figure 1c for an
example VaR display using the scatterplot approach).

In the VaR display, a scatterplot

is generated for each
dimension. The Y dimension of a scatterplot dimension glyph
is the dimension it represents, while all of the glyphs have the
same X dimension. We choose to use the same X dimension
since it will be hard for users to associate different dimension
glyphs if both X and Y dimensions change from one glyph
to another. Although this causes information loss, users can
always interactively change the X dimension guided by the
semi-automatic selection tool (see Section VII) and their visual
exploration (see Section XI).

The VaR display is targeted at large datasets. It is time
consuming to draw the projection of each data item on each
of the N scatterplots. Also, the large number of projections
would clutter the glyph. In order to avoid clutter and increase
scalability, we store each glyph as an M X M pixel matrix,
where M is an adjustable integer, and divide the 2D space
within the value range of the dataset into M X M equal-
size bins. The number of projections falling into each bin
is recorded and translated into the color of its corresponding
pixel in the pixel matrix. In particular, the intensity of the pixel
is proportional to data density of the area it represents.

Fig. 2. X-Ray Scatterplots (a) The ﬁrst solution (b) The second solution (c)
The X-Ray scatterplot solution.

The ﬁrst image (Figure 2a) we generated is disappointing,
since it is hard to differentiate unoccupied area (areas with
zero data items) from areas with a few data items. In order
to solve this problem, we assign a different hue to the pixels
representing unoccupied areas. In the image generated (Figure
2b), there are no data items in the blue area. We then observed
that,
to glyphs generated using pixel-oriented
techniques where every pixel represents a data value, there
are often large contiguous unoccupied areas in a scatterplot
glyph, especially when the X and Y dimensions are closely
related. Recalling that some glyph layout approaches, such

in contrast

4

as MDS, could cause overlaps among different glyphs, we
made the unoccupied areas semi-transparent so that users can
see hidden glyphs through the unoccupied areas of the hiding
glyphs. Figure 2c shows this ﬁnal solution. Since in the ﬁgure
the glyphs look very much like X-Ray photos, we named
this VaR display the X-Ray scatterplot VaR display. To give
users more ﬂexibility, we allow them to interactively choose
the color and transparency of the unoccupied areas. If users
dislike the semi-transparent unoccupied areas, they are able to
set them to opaque.

V. DIMENSION LAYOUT ALTERNATIVES: JIGSAW MAP

LAYOUT AND RAINFALL

A. Jigsaw Map Glyph Layout

The MDS approach is effective in conveying dimension
relationships. However, using the MDS approach, the positions
of two glyphs could be very close to each other if they are
closely related. Glyphs might overlap in this case, which is
sometimes undesired by the users. Besides allowing the users
to reduce overlaps in the MDS layout using interactions (see
Section VII), we propose a Jigsaw Map dimension layout
based on the recently proposed Jigsaw map [23]. In this
approach, dimensions are grouped into a dimension hierarchy.
The Jigsaw map, which is a space-ﬁlling hierarchy visualiza-
tion method, is then used to lay the dimensions on a grid.
This approach not only prevents glyphs from overlapping, but
also conveys the hierarchical structure among the dimensions.
Figure 3 shows VaR displays with a Jigsaw layout.

The motivation of this approach is that grouping dimensions
of high dimensional datasets into dimension hierarchies makes
it easy to capture the relationships among the dimensions.
In a dimension hierarchy, dimensions are organized into a
hierarchy of clusters. Dimensions within a cluster have closer
relationships among each other than with dimensions outside
the cluster. Clusters in different levels of the hierarchy divide
the dimensions into groups of different granularity. With the
dimension relationship matrix, it is convenient to generate
a dimension hierarchy using existing hierarchical clustering
approaches. In the hierarchy, each leaf node is a dimension in
the high dimensional dataset.

In order to turn the dimension hierarchy into the dimension
layout, we examined existing hierarchy visualization tech-
niques. The basic requirements are 1) the layout should be
space efﬁcient since our target is high dimensional datasets
and 2) each dimension should be assigned a space of the
same size, shape and orientation since it is difﬁcult for users
to compare and associate glyphs with different sizes, shapes,
or orientations. Since node-linked diagrams do not use space
efﬁciently, we only considered the space-ﬁlling hierarchy
visualization techniques [3], [21], [23]. Among them, only
the Jigsaw map [23] and quantum treemaps [3] are capable
since all other techniques assign areas of different shapes or
orientations to leaf nodes. We chose the Jigsaw map since it
generates layouts of nicely shaped regions and is stable with
regards to changing tree structures and leaf nodes [23].

To generate the Jigsaw map layout, we ﬁrst hierarchically
cluster the N dimensions in a dataset based on their pair-
wise distances (a pair of more closely related dimensions

5

Fig. 3. The Image-838 dataset (838 dimensions, 11,413 data items). (a) The Pixel Jigsaw map VaR display with separated dimensions selected and labeled
(b) The X-Ray scatterplot Jigsaw map VaR display with dimension Coarseness as the X dimension. The X dimension is in a pink frame and labeled. (c)
The X-Ray scatterplot Jigsaw map VaR display with dimension angle 135 as the X dimension. The X dimension is at the left bottom corner of the map and
dimensions closely related to it are in red frames. (d) A zoomed in display of the selected dimensions with their labels shown.

has a smaller distance than a pair of less related dimensions)
using the minimum single linkage metrics [17]. Then, the N
dimensions are ordered into a 1-D sequence according to their
positions in the hierarchy using a depth-ﬁrst traversal of the
hierarchy, and then the sequence is mapped to a 2-D L x K (
L x K >= N) mesh by applying a space-ﬁlling curve called
an H curve (please refer to [23] for more details). Figure 3a
shows an example of the Jigsaw layout. In this ﬁgure, similar
dimensions are close to each other and signiﬁcant boundaries
of groups of closely related dimensions, such as the group of

dimensions in the left bottom part of the map, can be detected.
Outlier dimensions, such as the dimensions on the left top part
of the map, are also distinguishable since their textures look
different from their neighbors.

B. Rainfall Metaphor

When exploring a high dimensional dataset, users are often
interested in the relationships between a single dimension of
interest with all other dimensions. Beside the X-Ray scatter-
plot, which reveals the relationships using glyph textures, we

6

Fig. 4. The Rainfall Metaphor. (a) At the beginning of the rain. Dimensions more closely related to the dimension of interest in the bottom are falling in a
faster acceleration than less related dimensions. (b) The rain continues. The dimensions with different correlations to the dimension of interest are separated.
It can be seen that there are roughly three levels of association between the dimension of interest and other dimensions. (c) The Rain is close to its end.
Dimensions signiﬁcantly distinct from the dimension of interest are revealed. The dataset is the Image-89 dataset. The glyphs are pixel-oriented glyphs (pixels
are ordered in a line by line (horizontal lines) manner.

provide a simple animation approach to dynamically illustrate
the relationships by changing glyph positions. This approach is
named the Rainfall Metaphor since it imitates rain (see Figure
4 for an example).

In the beginning of the animation, the dimension of interest
is placed in the center bottom of the display (the ground) and
all other dimensions (raindrops) are placed in the top of the
display (the sky). The horizontal positions of the raindrops
are randomly generated. After the rain starts, a raindrop falls
toward the ground in an acceleration that is proportional to
its correlation with the dimension of interest. Thus, a raindrop
moves toward the ground faster than another raindrop if it has
a closer relationship to the dimension of interest. A raindrop
stops its movement after it hits the ground. There is a timer
that starts from the beginning of the rain and ends when
all raindrops hit the ground. Users can interactively play the
animation by moving the slider representing the timer. Users
can also interactively select the dimension of interest for the
animation.

Figure 4a-c shows some screen captures of the Rainfall
layout. Using this metaphor, users can focus on the relation-
ships between the dimension of interest and other dimensions,
without being distracted by relationships among the other
dimensions. In different moments of the rain, either similar
dimensions or distinct dimensions to the dimension on the
ground attract the users’ attention.

VI. CORRELATION CALCULATION

In the VaR display, a binning based correlation calculation
algorithm is used. We only brieﬂy introduce it here since
it has been presented in full detail in [27]. We claim that
any relationship calculation algorithm can be used in the VaR
display as long as it scales to large datasets. The layout of
the glyphs reﬂects the type of relationship calculated by the
underlying algorithm.

In our algorithm, distribution of the value differences (be-
tween the different dimensions for the same data item) is
recorded into bins. In particular, the possible range of value
differences between a pair of dimensions is divided into a
sequence of bins. The number of data items whose value
differences between these two dimensions fall into the bins is
recorded. For an N dimensional dataset, N x (N-1)/2 sequences
of bins (one sequence for each pair of dimensions) are created.
A pair of dimensions is considered to be closely related if
a large number of data items fall info a small number of
bins (K) in its sequence. With a given K, the correlations
can be calculated in this way: sort the bins in the sequence
according to their populations, and sum up the populations
of K bins with the highest populations. The sum divided by
the total population of the data items is proportional to the
correlation between the dimensions. K is selected to be the
number of bins that make the global variance of correlations
for all dimensions maximum. This algorithm scales to a large
number of data items. Except for the ﬁrst scan, which can
be done with minimal cost when inserting the dataset into
the database, its efﬁciency is only related to the number of
dimensions.

The above algorithm is a heuristic approach whose purpose
is to maximize the visibility of the structure of the MDS and
Jigsaw layout. There are many other optimization problems
in the VaR display, such as selecting a dimension ordering
the pixel-oriented display in the initial view to provide the
maximum information to users at a ﬁrst glance. A detailed
discussion of such problems is presented in [27] and not
repeated here.

VII. INTERACTIVE TOOLS IN THE VAR DISPLAY

A rich set of interaction tools has been developed for the
VaR display. Navigation tools help users reduce clutter in the
display and discover information about the dataset. Automatic
and manual dimension selection tools allow users to perform

human-driven dimension reduction by selecting subsets of
dimensions for further exploration in the VaR display as well
as other multi-dimensional visualizations. Data item selection
tools allow users to select subsets of data items for further
exploration. In addition, the data item masking tool allows
users to examine details of selected data items within the
context of unselected data items.

Most of the interactive tools make no special assumption
about the glyph positioning and generation strategies, i.e., they
can be applied to any realization of the VaR display. These
tools are called general tools. Unless speciﬁcally noted, an in-
teraction tool is a general tool in the following sections, where
details of each navigation and selection tool are presented.

A. Tools for Glyph Layout

The MDS dimension layout causes overlaps among the
glyphs. Overlaps emphasize close relationships among the
dimensions because glyphs overlap only if their dimensions
are closely related. However, overlaps can prevent a user
from seeing details of an overlapped glyph. We provide the
following operations to overcome this problem (see [27] for
more detail).

(cid:129) Showing Names: By putting the cursor on the VaR
display, the dimension names of all glyphs under the
cursor position are shown in a message bar. Thus a user
can be aware of the existence of glyphs hidden by other
glyphs.

(cid:129) Layer Reordering: With a mouse click, a user can force
a glyph to be displayed in front of the others. In this
way he/she can view details of a glyph that is originally
overlapped. Users can also randomly change the ordering
of all dimension glyphs by clicking a button in the control
frame. In addition, selected dimensions are automatically
brought to the front of the display.

(cid:129) Manual Relocation: By holding the control key, a user
can drag and drop a glyph to whatever position he/she
likes. In this way a user can separate overlapping glyphs.
(cid:129) Extent Scaling: Extent scaling allows a user to interac-
tively decrease the sizes of all the glyphs proportionally to
reduce overlaps, or to increase them to see larger glyphs.
(cid:129) Dynamic Masking: Dynamic masking allows users to
hide the glyphs of unselected dimensions from the VaR
display.

(cid:129) Automatic Shifting: This operation automatically re-
duces the overlaps among the glyphs by slightly shift-
ing the positions of the glyphs. There are many more
advanced overlap reducing algorithms that can be used,
such as those listed in [22].

(cid:129) Distortion: Users can interactively enlarge the size of
some glyphs while keeping the size of all other glyphs
ﬁxed. In this way users are allowed to examine details
of patterns in the enlarged glyphs within the context
provided by the other glyphs.

(cid:129) Zooming and Panning: Users can zoom in, zoom out
and pan the VaR display. For example, in order to reduce
overlaps, sometimes the size of the glyphs has to be set
very small when there are a large number of dimensions.

7

Zooming into the display will enlarge the glyphs so that
the user can have a clear view of the patterns in the
glyphs.

(cid:129) Reﬁning: A reﬁned VaR display can be generated for
a selected subset of dimensions and a selected subset
of data items. The selected dimensions and data items
are treated as a new dataset. The relationship calculation,
glyph generation and positioning are applied to the new
dataset.

B. Tools for Glyph Regeneration

In the Pixel-Oriented dimension glyphs, the dimension used
to sort the data items affects the glyph patterns signiﬁcantly.
Clusters in subspaces including this dimension can be easily
detected while clusters in other subspaces are not. Similarly, in
the X-Ray scatterplot dimension glyphs, relationships between
other dimensions and the X dimension are easier to detect
than relationships among other dimensions. We allow users to
interactively select the sorting dimension in the pixel-oriented
mode and the X dimension in the X-Ray scatterplot mode
by clicking the mouse button on the glyph of the desired
dimension or selecting from a combo-box.

In addition, a comparing mode can be used in the pixel-
oriented glyphs in order to compare the dimensions with a
dimension of interest. In this mode, except the glyph of the
base dimension, the pixels of all other glyphs will be colored
according to the differences between the values of the base
dimension and their dimensions. A ﬁgure of the comparing
mode can be found in [27].

C. Dimension Selection Tools

Dimension selection tools enable users to select dimen-
sions of interest for further exploration using other multi-
dimensional visualization techniques. They can also be used
as a ﬁlter to reduce the number of glyphs displayed in a VaR
display, since we allow users to hide glyphs of unselected
dimensions using dynamic masking (see Section VII-A). The
selection tools we provide to users include automatic selec-
tion tools for closely related dimensions and well separated
dimensions, in addition to manual selection.

The automatic selection tool for related dimensions
takes a user-assigned dimension and correlation threshold as
input. Here we assume that a pair of more closely related
dimensions has a larger correlation measure than a pair of
less related dimensions. Users pick the assigned dimension by
clicking its glyph and adjust the threshold through a slider. The
tool automatically selects all dimensions whose correlation
measures to the input dimension are larger than the threshold
by traversing the dimension relationship matrix. This tool
enables the users to select a set of closely related dimensions.
The automatic selection tool for separated dimensions
takes a user-assigned dimension and correlation threshold
as input and returns a set of dimensions that describe the
major features of the dataset. The assigned dimension will
be included in the returned set of dimensions. Between each
pair of dimensions in the result set, the correlation measure is
smaller than the threshold. For any dimension that is not in

8

Fig. 5. Masking of Unselected Data Items. Unselected data items are covered by a mask with adjustable color and transparency. (a) No mask or fully
transparent mask. (b) Opaque mask. (b) Semi-transparent mask. The dataset is the Image-89 dataset. The glyphs are pixel-oriented glyphs (pixels are ordered
in a line by line (vertical lines) manner.

the result set, there is at least one dimension in the result set
whose correlation measure with it is larger than the threshold.
Using this tool, a user is able to select a set of dimensions
to construct a lower dimensional subspace revealing the major
features of the dataset without much redundancy. In Figure 1b
separated dimensions selected automatically are labeled.

The following algorithm can be used for automatic selection

of separated dimensions:

1) Get the assigned dimension and the selection threshold.
2) Set the assigned dimension as “selected” and all other

dimensions as “unselected”.

3) Find all unselected dimensions whose correlation mea-
sures to all existing selected dimensions are smaller than
the threshold. Mark them as “candidates”.

4) If there is no candidate dimension, go to step 5. Else, set
one candidate dimension as “selected” and every other
candidates as “unselected”. Go back to step 3.

5) Return all dimensions marked as “selected”.
It is interesting that it is not deﬁned how to pick one dimen-
sion among the candidate dimensions in step 4. Thus it can
be customized according to the task of interest. For example,
in Section VIII, this approach is customized to reduce the
clutter among the labels of the selected dimensions for a good
labeling result. Here we present another customization.

When users start to explore an unknown dataset, it is often
desired to ﬁnd dimension groups containing large numbers of
closely related dimensions. Thus a heuristic approach can be
used in step 4: setting a threshold, for each candidate dimen-
sion counting the number of dimensions having correlation
measures to it that are larger than the threshold, and selecting
the dimension with the highest count. Using this approach
dimensions with a larger number of closely related dimensions
have higher priority to be selected.

Manual selection allows a user to manually select a dimen-
sion by clicking its corresponding glyph. The user can unselect
the dimension by clicking the glyph again. The combination of
manual and automatic selection makes the selection operation

both ﬂexible and easy to use.

D. Data Item Selection and Masking Tools

Rather than allowing a user to select data items directly from
the glyphs in the VaR display (which is hard when glyphs
are small), we allow the user to select data items from a
dialog. Firstly, the user selects a dimension name from a name
list in the dialog. Then a brief summary of the dimensions
will be provided to help the user set up the selection criteria
for the selected dimension. If the dimension is a categorical
dimension, the distinct values in that dimension as well as the
number of data items for each value will be provided. The user
can then select the desired distinct values. If the dimension is
a numeric dimension, a histogram of the dimension will be
provided. The user then set up a minimum value and maximum
value for the selection using two sliders. The user can set the
selection ranges for multiple dimensions.

After the user sets the selection criteria, he/she can click a
button in the dialog to trigger the selection. A problem here is
how to highlight the selected data items. In most visualization
systems, selected data items are highlighted using either a
special color, or a surrounding box around the selected items.
However, in the VaR display with pixel-oriented techniques,
color has been used to represent the values, and it is hard
to put a surrounding box in a condensed glyph, especially if
the selected data items are not adjacent to each other in the
glyphs.

A straightforward solution to this problem is to display only
the selected data items. This is a general solution suitable for
all realizations of the VaR display. However, a drawback of
this approach is that the context provided by unselected data
items is lost. Such a context is often useful. For example, the
users might want to compare the selected data items with the
unselected data items among the dimensions.

In order to overcome this drawback, we developed an
approach called data item masking. This approach is only
useful for VaR displays using pixel-oriented techniques. In

9

Fig. 6. Labeling Solutions (a) All dimensions are labeled with names (b) Dimensions selected by the labeling algorithm are labeled. Clutter is reduced. (c)
Angled text is used to label all dimensions in the Jigsaw map layout. The dataset is the Image-89 dataset.

according to the following two heuristic criteria: 1) they should
be distinct dimensions, i.e., two similar dimensions should
not be labeled at the same time. Dimensions distinct from all
other labeled dimensions should be labeled. 2). they should be
separated from each other as much as possible to avoid clutter
on the screen. In addition, we allow users to interactively
change the number of dimensions labeled to get a less cluttered
view or to see more labels.

Criterion 1 is exactly the criterion used for automatic se-
lection of separated dimensions (see Section VII-C). Criterion
2 adds more constraints to the selection. Recall that there is
some freedom in step 4 of the selection algorithm, i.e., any
dimensions in the candidate dimension set can be selected; we
modiﬁed the algorithm for labeling as follows:

1) Assign a dimension and a selection threshold.
2) Set the assigned dimension as “selected” and all other

dimensions as “unselected”.

3) Find all unselected dimensions whose correlations with
all existing selected dimensions are smaller than the
threshold. Mark them as “candidates”.

4) If there is no candidate dimension, go to step 5. Else, set
the candidate dimension which is the most far way on
the screen from its closest existing selected dimension
as “selected” and other candidates as “unselected”. Go
back to step 3.

5) Return all dimensions marked as “selected” and label

this approach, both selected and unselected data items are
drawn on the screen. Unselected data items are covered by
a mask. Users can interactively change the color of the mask,
and adjust the transparency of the mask though a slider. When
the mask is opaque, as shown in Figure 5b, unselected data
items are hidden. When the mask is fully transparent, as shown
in Figure 5a, the selected data items are not highlighted. When
the mask is semi-transparent, as show in Figure 5c, the selected
data items are highlighted within the context provided by
the unselected data items. Users can interactively change the
transparency of the mask to adjust the strength of the context.
The implementation of this masking operation is simple.
First, a mask is generated using an approach similar to the
generation of a normal dimension glyph. The only difference
is that the pixels are set to be transparent for selected data
items and with user assigned color and transparency for
unselected data items. Our mask generation mechanism has
no dependency on the order of the data items,
is
not necessary for the selected data items to be adjacent to
each other in the glyphs. Since the color and shape of the
masks are the same for all
the mask is only
generated once, stored as a texture object, and pasted in the
front of all the glyphs. Since the texture mapping operation is
efﬁcient in OpenGL, displaying masks has minimal effect on
the rendering of a VaR display.

the glyphs,

i.e.,

it

VIII. LABELING

them.

In the original version of the VaR display, dimension names
are labeled horizontally in the middle top region above the
dimension glyph for all dimensions shown on the screen (see
Figure 6a). The labels clutter the screen seriously for a high
dimensional dataset, thus we did not provide the labeling
option to users. Rather, when users moved the cursor over
a glyph, the glyph name showed in the message bar below
the display. However, users complained that ﬁnding dimension
names in this way was tiring. They argued that the VaR display
without dimension labels is much less meaningful than one
with names labeled. In order to solve this problem, we chose to
label a subset of dimensions on the screen for the MDS layout
(see Figure 6b). The dimensions to be labeled are selected

When calculating the screen distance between two dimen-
sions in step 4, we must consider the fact that horizontal labels
are used. Their lengths are much larger than their widths.
Assume that labels have 5 characters on average and the
characters have equal height and width, the screen distance
between two dimensions d1 and d2 D(d1, d2) = fabs((d1.x
- d1.x)) + 5 * fabs((d1.y - d2.y)), where x and y are the
screen coordinates of the dimensions. The equation means that
we prefer dimensions separated in the vertical direction than
the horizontal direction. Figure 6b shows the same display as
Figure 6a with selected dimensions labeled using the above
algorithm.

The same labeling approach can be applied to the Jigsaw

map layout. In addition, since the glyphs are placed in a regular
mesh in the Jigsaw map, applying an angle on all the labels
greatly reduces the clutter on the screen even when all labels
are shown. Figure6c shows the Image-89 datasets in the Jigsaw
map layout with all dimension names displayed at a 20 degree
angle. Almost all of the dimension names can be distinguished
from this display.

In our prototype we bind labeling with selections,

i.e.,
users have the option to show labels of selected dimensions
only. When a user chooses this option and uses the automatic
selection tool for separated dimensions, it is exactly the above
clutter-reducing labeling approach. When a user uses the
selection tool for related dimensions, the dimensions closely
related to the user-assigned dimensions are labeled (see Figure
3d for an example).

IX. IMPLEMENTATION AND SCALABILITY ISSUE

When there are several hundred dimensions, the datasets
can easily contain millions of data values even if they only
contain thousands of data items. Datasets often have a higher
number of data items. Such large datasets not only cause large
response time during interactions and problems in storing the
data structures in a visualization system, but also cause clutter
on the display. Scalability is a critical issue for visualization
systems aimed at high dimensional datasets.

We have implemented a fully working prototype of the VaR
display. The biggest dataset that has been successfully loaded
into the VaR display so far is an image classiﬁcation dataset
containing 838 dimensions and 11413 data items, which means
over 9 million data values (see Figure 3 for its VaR display).
Most interactions can be processed within a few seconds on a
typical PC for this dataset. This dataset is the biggest dataset
we currently have. In the future, we will test larger datasets
on the prototype.

The critical techniques we used in the prototype for increas-
ing scalability are texture mapping, binning, and sampling
techniques. Using the texture mapping techniques provided by
OpenGL, our prototype stores all dimension glyphs (including
the mask in the masking operation) as texture objects and
pastes them on the screen as needed. As long as the glyph
textures do not change,
the dataset does not need to be
rescanned, which is time consuming for large datasets. By
keeping the texture objects small (such as hundreds of pixels),
which is reasonable since each dimension glyph will not be
too big on the screen in order to reduce clutter, the system can
draw hundreds of dimension glyph textures on the screen in
almost real time. This approach greatly reduces the response
time for most interactions because, except for reordering for
pixel-oriented glyphs and resetting the X dimension for X-Ray
scatterplot glyphs, almost all other interactions do not change
the glyph textures. Rather, they refresh, resize, reposition, or
reorder the glyphs.

According to our experience, drawing fonts in OpenGL is
a time consuming task. Our prototype stores all dimension
name labels as texture objects. These texture labels are created
one time, and can be quickly pasted on the screen until users
change the contents or colors of the labels. The texture labels
can be scaled and rotated easily on the screen.

10

Binning, i.e., using buckets to stored statistic information
about groups of values rather than recording them individually,
is an approach widely used in data mining techniques for large
datasets. We use binning techniques to increase the speed of
the correlation calculation algorithm (see section VI) and the
X-Ray scatterplot glyph generation (see section IV).

The prototype stores datasets in an Oracle database server.
It dynamically requests data from the server when needed,
making use of the sorting and query functions provided by
the database server. When generating a VaR display for a
dataset containing a large number of data items, we use a
random sampling approach to reduce the response time for
fetching data items from the server, as well as the number
of values to be processed. In particular, the system keeps a
default maximum number. When the number of data items
contained in a dataset exceeds it, a uniform random sampling
is performed on the dataset to only fetch the maximum number
of data items. Users are allowed to interactively adjust the
maximum number in order to trade between the response time
and visualization accuracy.

Random sampling is easy to implement. However, it has
the big drawback that a large sampling rate is needed in order
to reduce small group loss in the samples [6]. In order to
overcome this problem, many solutions have been proposed,
such as biased sampling [14] or dynamic sample selection
[2]. It has been shown in the literatures that these approaches
successfully reduce small group loss. We will explore these
approaches in the future.

X. DISCUSSION

The VaR display can serve as an overview tool for a high
dimensional dataset. Starting from the VaR display, other
visualization techniques can be used for more detailed visual
analysis. For example, the VaR display is coordinated with
parallel coordinates, star glyphs, and scatterplot matrix views
in our prototype. Although these techniques could not handle
hundreds of dimensions, they work well in examining data
items and dimensions selected by the VaR display. Recently,
we completed an interesting project in coordinating the VaR
display with an image exploration interface. The VaR display
was used to show the high dimensional image content anno-
tations. Users were allowed to select images by contents from
the VaR display. The images were then examined in detail in
an image exploration interface. This work is described in [26].
The MDS and Jigsaw map glyph layout approaches have
their advantages and disadvantages. From its nature, MDS
is better in capturing high dimensional relationships than the
hierarchical approach. However, the non-overlap feature of the
Jigsaw map layout makes it a popular approach for users of
the VaR display thus far.

Although the pixel-oriented glyphs are mentioned less than
the X-Ray scatterplot glyphs in this paper, this is only because
the usage of the pixel-oriented techniques has been widely
studied and their effectiveness has been shown in many papers.
Compared to scatterplots, the pixel-oriented glyphs are more
effective in pixel usage since they make use of each pixel.
However, it is easier to compare the relationship between a

11

Fig. 7.
(a) The Pixel MDS VaR display of the Image-838 dataset with separated dimensions selected and labeled. (b)(c) The X-Ray scatterplot Jigsaw map
VaR display of the Image-89 dataset. The dimension in a yellow frame is non-linearly related to the X dimension. (c) The X-Ray scatterplot Jigsaw map VaR
display with another X dimension (the dimension highlighted by the yellow frame in (b)).

dimension of interest and all other dimensions using the scat-
terplot glyphs. Users ﬁnd it difﬁcult to compare the patterns
of pixel-oriented glyphs if they are far from each other.

Compared to scatterplot matrices, the X-Ray scatterplot VaR
display has its advantages and disadvantages. For datasets with
a small number of dimensions, scatterplot matrices might be
preferred since all possible axis-parallel 2-D projections are
provided in them. However, for datasets with tens, hundreds
or thousands of dimensions, the X-Ray scatterplot VaR display
might be preferred since it causes less clutter. Its disadvantage
that only part of possible 2-D projections are displayed is
leveraged by two facts: ﬁrst, dimension relationships conveyed
by the VaR display give strong hints on the shapes of the
undisplayed 2-D projections; second, users can interactively
access 2-D projections of interest through interactions.

Compared to approaches that rank the 1D or 2-D projections
according to their features and allow users to examine detail
of a projection by selecting it from diagrams or lists conveying
the ranking (such as the rank-by-feature framework [19]),
the VaR display also has its advantages and disadvantages.
Obviously for tasks such as ﬁnding the most linearly corre-
lated dimensions the ranking approaches are better choices.
However, the VaR display is better in helping users grasp the
global relationships among the dimensions.

XI. CASE STUDY

We have explored several real datasets using the VaR dis-
play, including the Image-838 dataset [8] with 838 dimensions
and 11,413 data items and the Image-89 dataset [8] with 89
dimensions and 10,471 data items. They all contain low level
visual attributes for image classiﬁcation. Image analysts are
interested in ﬁnding outlier dimensions that are uncorrelated to
most other dimensions, and dimensions representing a group of
correlated dimensions (a dimension cluster) in order to reduce
the number of low level visual attributes used in the image
classiﬁcation process.

For both datasets, we selected a Pixel MDS VaR display
with all dimensions displayed as the initial view, since the

pixel-oriented glyphs have a higher pixel usage efﬁciency
and the MDS display conveys dimension relationships more
accurately than the Jigsaw map layout. Figure 7a and Figure 1b
show the Pixel MDS VaR displays of the Image-838 dataset
and the Image-89 dataset respectively. From the ﬁgures, we
found that there are dimension outliers and clusters in both
datasets. We then applied automatic selections for separated
dimensions. Both outlier dimensions and dimensions repre-
senting dimension clusters were selected.

Then, we switched to the Jigsaw map layout. Figure 3a
shows the Pixel Jigsaw map VaR display of the Image-838
dataset. There are several distinguishable regions that can be
seen in the map where adjacent glyphs in the regions have
similar patterns. For example, there is a distinguishable region
composed of bright blue glyphs at the left bottom of the
map. If only one dimension is selected in such a region, it
means that the neighbors of the selected dimension are closely
related to it, since selection for separated dimensions was used.
Thus they are a dimension cluster and the selected dimension
can represent the cluster. The selected and labeled dimension
angle 135 at the left bottom corner is such a representative
dimension. Meanwhile, selected dimensions crowded together,
such as the selected dimensions in the left top of the map,
are potential outliers since they are distinct from their closest
neighbors. The selected and labeled dimension Coarseness at
the left top corner is such suspicious outlier.

In order to examine if dimension Coarseness is an outlier,
an X-Ray scatterplot VaR display was created using it as
the X dimension (see Figure 3b). From scatterplots in Figure
3b it can be seen that no other dimensions show strong
correlations with dimension Coarseness. Thus it is conﬁrmed
that dimension Coarseness is an outlier dimension.

Figure 3c examines if dimension angle 135 is a repre-
sentative dimension. The X dimension of the scatterplots is
dimension angle 135 and dimensions closely correlated to
dimension anagle 135 are selected and highlighted. It can be
seen that a large number of dimensions are selected and they
all contain a clear diagonal pattern which indicates a strong

linear correlation. Figure 3d shows a zoomed in display of the
selected dimensions in which their labels are shown.

A similar exploration approach was conducted for the
Image-89 dataset. An interesting pattern in this dataset was
found when we were examining dimension Channel Energy 5
using the X-Ray scatteplot Jigsaw map VaR display (Figure
7b): there was a glyph with a curved band (the glyph with a
yellow frame, the frame was manually added into the ﬁgure
for highlighting). It seemed that
this dimension was non-
linearly related to the target dimension. It raised our interest
and became our next target.

We clicked this dimension to set it as the X dimension in
the X-Ray scatterplots and got Figure 7c. It is labeled in
Figure 7c as Texture Brightness DC. Figure 7c shows that
dimension Texture Brightness DC is non-linearly related to
most dimensions in this dataset. The curved bands are fairly
thin in some dimensions, which means strong non-linear
relationships.

XII. USER STUDY

A user study has been conducted to evaluate the VaR display
by comparing it to the Rank-by-Feature feature of HCE [19].
To form a comparable study, we considered the X-Ray scat-
terplot glyph style of VaR and the scatterplot prism from the
HCE system, namely its 2D projection ranking, selection and
visualization feature. In HCE, 2D projections are ranked by
features such as strength of linear relationship or least square
error for curvilinear regression. The ranking is visualized in
both a matrix and a list. A window beside the ranking windows
shows the scatterplot of the 2D projection selected by the user.
Our assumption was that the VaR display would better help
users grasp global relationships among the dimensions in a
high dimensional dataset. The reason is that VaR provides a
detailed view of all dimensions at the same time while users
of HCE need to take efforts to associate multiple dimensions
since they can only examine a few detailed views at the same
time.

Eight subjects participated in the user study. The subjects
vary in educational backgrounds: one was a psychology grad-
uate student, two were computer science undergraduate stu-
dents, three were graduate students in the ﬁeld of visualization,
and two were researchers/post-doctorates in visualization. The
subjects completed the user study one by one on the same
computer with the same instructor. Each subject tested both
systems. The order of using VaR and HCE was alternated for
the subjects.

The study began with a 10 minute training session using
both VaR and HCE and a further 10 minutes to allow subjects
to explore the tools and ask the instructor questions. A set of
tasks were then completed by the subjects using both tools. A
post-test survey to ﬁnd user preferences and a discussion were
conducted immediately following the completion of the tasks.
We used the Image-89 dataset of 89 dimensions and 10,471
data items. As shown in the case study (Section XI), there
are some strong linearly related dimensions and some strong
non-linearly related dimensions in the Image-89 dataset.

The ﬁrst

task was to describe relationships between a
given dimension and each of the other dimensions using the

12

scatterplot displays by approximating the numbers of different
scatterplot shapes involved with the given dimension. Samples
of typical shapes, such as diagonal thin straight bands for lin-
ear relations, curved bands for non-linear relations, and evenly
distributed scatterplot indicating unrelated dimensions were
provided to users. The second task required users to describe
relationships among ﬁve randomly assigned dimensions using
their scatterplot shapes.

The majority of users performed the ﬁrst task quicker and
evaluated the task to be easier using the VaR display. The
average time was 3.2 minutes and the standard deviation was
0.5 minutes for VaR, and the average time was 4.7 minutes
and the standard deviation was 3.2 minutes for HCE. On a
scale of 0 (hard) to 5 (easy), the mean scores of 3.5 and 2.1
were given to VaR and HCE respectively. A similar trend was
identiﬁed in the second task: the average time was 3.5 minutes
and the standard deviation was 0.4 minutes for VaR, and the
average time was 8.5 minutes and the standard deviation was
2.9 minutes for HCE. The scores are 3.6 for VaR and 1.0 for
HCE. Results from these tasks highlighted the advantage of
the VaR display in providing a global view of the dimension
relationships.

Qualitative results and qualitative feedback from the post-
test survey were also encouraging. Users typically preferred
using VaR over HCE for the given tasks. The reasons given
by each user were generally similar and can be summarized by
the ability to examine details of multiple relations on a single
display. One user in the study preferred HCE over VaR due to
the more detailed and visible scatterplots in the HCE system.
Users were also asked if they agreed with the statement “this
tool is useful for exploring high dimensional data”. On a scale
of 0 (disagree) to 5 (agree), users responded with a mean score
of 4.3 and 3.5 for VaR and HCE respectively.

A number of comments and suggestions were made by the
users regarding both systems. Positive feedback from VaR
included an intuitive interface, the instantaneous global view
and ability to quickly select the X dimension of all scatterplots.
Improvements suggested by the users involved ranking the
dimensions by features, and using color and best-ﬁt-lines to
enhance the scatterplot displays which were considered too
dense. In addition, users suggested ordering the dimension
glyphs according to the shapes of the scatterplot using au-
tomatic image analysis techniques. For the HCE system, users
preferred the ranking features and the scatterplot display with
rich features and interactions. Users suggested that the global
view provided by the prism in HCE lacked details compared
to the VaR display. Future work may beneﬁt by combining the
best features of these two systems.

XIII. CONCLUSION

In this paper, the VaR display, which allows users to inter-
actively explore large datasets with hundreds of dimensions,
was presented. The essential
idea of the VaR display is
to represent each dimension in a high dimensional dataset
using an information-rich glyph, and arranging the glyphs to
reveal the relationships among the dimensions. By integrating
existing techniques such as MDS, Jigsaw map, pixel-oriented

13

[12] D.A. Keim. Designing pixel-oriented visualization techniques: Theory
IEEE Transactions on Visualization and Computer

and applications.
Graphics, 6(1):1–20, January-March 2000.

[13] D.A. Keim, H.-P. Kriegel, and M. Ankerst. Recursive pattern: a
technique for visualizing very large amounts of data. Proc. IEEE
Visualization ’95, pages 279–286, 1995.

[14] G. Kollios, D. Gunopulos, N. Koudas, and S. Berchtold. Efﬁcient
biased sampling for approximate clustering and outlier detection in large
IEEE Transactions on Knowledge and Data Engineering,
data sets.
15(5):1170–1187, 2003.

[15] J.B. Kruskal and M. Wish. Multidimensional Scaling. Sage Publications,

1978.

[16] A. MacEachren, X. Dai, F. Hardisty, D. Guo, and G. Lengerich. Explor-
ing high-d spaces with multiform matrices and small multiples. Proc.
IEEE Symposium on Information Visualization, pages 31–38, 2003.

[17] F. Murtagh. A survey of recent advances in hierarchical clustering

algorithms. Computer Journal, 26(4):354–359, 1983.

[18] NetMBA.

http://www.netmba.com/statistics/plot/scatter/.

[19] J. Seo and B. Shneiderman. A rank-by-feature framework for un-
supervised multidimensional data exploration using low dimensional
projections. Proc. IEEE Symposium on Information Visualization, pages
65–72, 2004.

[20] J. Seo and B. Shneiderman. A rank-by-feature framework for inter-
active exploration of multidimensional data. Information Visualization,
4(2):96–113, 2005.

[21] B. Shneiderman. Tree visualization with tree-maps: A 2d space-ﬁlling

approach. ACM Transactions on Graphics, 11(1):92–99, Jan. 1992.

[22] M.O. Ward. A taxonomy of glyph placement strategies for multidi-
mensional data visualization. Information Visualization, 1(3-4):194–210,
2002.

[23] M. Wattenberg. A note on space-ﬁlling visualizations and space-ﬁlling
curves. Proc. IEEE Symposium on Information Visualization, pages 181–
186, 2005.

[24] E.J. Wegman and Q. Luo. High dimensional clustering using parallel
coordinates and the grand tour. Computing Science and Statistics,
28:361–368, 1997.

[25] J.A. Wise, J.J. Thomas, K. Pennock, D. Lantrip, M. Pottier, A. Schur,
and V. Crow. Visualizing the non-visual: Spatial analysis and interaction
with information from text documents. Proc. IEEE Symposium on
Information Visualization, pages 51–58, 1995.

[26] J. Yang, J. Fan, D. Hubball, Y. Gao, H. Luo, W. Ribarsky, and
M. Ward. Semantic image browser: Bridging information visualization
with automated intelligent image analysis. Proc. IEEE Symposium on
Visual Analytics Science and Technology, pages 191–198, 2006.

[27] J. Yang, A. Patro, S. Huang, N. Mehta, M. Ward, and E. Rundensteiner.
Value and relation display for interactive exploration of high dimensional
datasets. Proc. IEEE Symposium on Information Visualization, pages
73–80, 2004.

[28] J. Yang, M.O. Ward, E.A. Rundensteiner, and S. Huang. Visual
hierarchical dimension reduction for exploration of high dimensional
datasets. Eurographics/IEEE TCVG Symposium on Visualization, pages
19–28, 2003.

[29] J. Yi, R. Melton, J. Stasko, and J. Jacko. Dust & magnet: Multivariate
information visualization using a magnet metaphor. Information Visual-
ization, 4:239–256, 2005.

techniques, and scatterplots, and allowing users to interactively
explore large datasets according to their interests, the VaR
display provides a rich metaphor for interactive exploration
of high dimensional datasets. The case studies and user study
conducted proved that the VaR display is an effective approach
with high scalability.

Although work presented in this paper has greatly extended
the functionality of the original VaR display [27], we believe
that
the VaR display still has much potential for further
development. Time-dependant dimension glyph generation or
layout, the ability to convey spatial information, and the ability
to visualize dynamically changing data streams, are future
directions we want to explore in the VaR display. In addition,
detecting features by analyzing and comparing textures of
dimension glyphs using automatic image analysis techniques
is also an appealing future work. Another important future
work is to conduct user studies to evaluate different options
provided by the VaR display.

ACKNOWLEDGMENT

We gratefully thank Dr. Daniel A. Keim for giving many
valuable suggestions for this work, Dr. Jianping Fan, Yuli Gao,
and Hangzai Luo for providing us the datasets, and the users
who participated in the user study.

This work was performed with partial support from NSF
grant IIS-0119276 and the National Visualization and Ana-
lytics Center (NVAC(tm)), a U.S. Department of Homeland
Security Program, under the auspices of the Southeastern Re-
gional Visualization and Analytics Center. NVAC is operated
by the Paciﬁc Northwest National Laboratory (PNNL), a U.S.
Department of Energy Ofﬁce of Science laboratory.

REFERENCES

[1] M. Ankerst, S. Berchtold, and D.A. Keim. Similarity clustering of
dimensions for an enhanced visualization of multidimensional data.
Proc. IEEE Symposium on Information Visualization, pages 52–60,
1998.

[2] B. Babcock, S. Chaudhuri, and G. Das. Dynamic sample selection
for approximate query processing. Proc. ACM SIGMOD International
Conference on Management of Data, pages 539–550, 2003.

[3] B. Bederson, B. Shneiderman, and M. Wattenberg. Ordered and quantum
treemaps: Making effective use of 2d space to display hierarchies. ACM
Transactions on Graphics, 21(4):833–854, 2002.

[4] C.L. Bentley and M.O. Ward. Animating multidimensional scaling
to visualize n- dimensional data sets. Proc. IEEE Symposium on
Information Visualization, pages 72–73, 1996.

[5] K. Beyer, J. Goldstein, R. Ramakrishnan, and U. Shaft. When is “nearest
neighbor” meaningful? Lecture Notes in Computer Science, 1540:217–
235, 1999.

[6] S. Chaudhuri, R. Motwani, and V. Narasayya. Random sampling for
histogram construction: how much is enough? Proc. ACM SIGMOD
International Conference on Management of Data, pages 436–447, 1998.
[7] W.S. Cleveland and M.E. McGill. Dynamic Graphics for Statistics.

Wadsworth, Inc., 1988.

[8] J. Fan, Y. Gao, and H. Luo. Multi-level annotation of natural scenes
using dominant image components and semantic image concepts. Proc.
ACM international conference on Multimedia, pages 540 – 547, 2004.
Interactive information visualization of
a million items. Proc. IEEE Symposium on Information Visualization,
pages 117–124, 2002.

[9] J.-D. Fekete and C. Plaisant.

[10] Y. Fua, M.O. Ward, and E.A. Rundensteiner. Hierarchical parallel
coordinates for exploration of large datasets. Proc. IEEE Visualization,
pages 43–50, Oct. 1999.

[11] B. Hibbard and D. Santek. The vis-5d system for easy interactive

visualization. Proc. IEEE Visualization, pages 28–35, 1990.

View publication stats
View publication stats

","{""pos"":{""0"":1,""1"":2,""2"":3,""3"":4},""2"":{""0"":""var"",""1"":""ieee*"",""2"":""hce"",""3"":""proc*""},""6"":{""0"":""items*"",""1"":""user"",""2"":""pages*"",""3"":""positions""},""1"":{""0"":""figure*"",""1"":""screen"",""2"":""mask"",""3"":""version""},""3"":{""0"":""x*"",""1"":""n*"",""2"":""m*"",""3"":""j*""},""0"":{""0"":""selected*"",""1"":""different*"",""2"":""multi"",""3"":""labeled""},""5"":{""0"":""dimensions"",""1"":""dimension*"",""2"":""values"",""3"":""texture*""},""4"":{""0"":""glyphs*"",""1"":""visualization*"",""2"":""datasets*"",""3"":""tools*""}}",2007,{},False,False,journalArticle,False,CJAT82Y9,[],self.user,"{""Unnamed: 0"":{""0"":0,""1"":1,""2"":2,""3"":3,""4"":4,""5"":5,""6"":6,""7"":7,""8"":8,""9"":9,""10"":10,""11"":11,""12"":12,""13"":13,""14"":14,""15"":15,""16"":16,""17"":17,""18"":18,""19"":19,""20"":20,""21"":21,""22"":22,""23"":23,""24"":24,""25"":25,""26"":26,""27"":27,""28"":28,""29"":29,""30"":30,""31"":31,""32"":32,""33"":33,""34"":34,""35"":35,""36"":36,""37"":37,""38"":38,""39"":39,""40"":40,""41"":41,""42"":42,""43"":43,""44"":44,""45"":45,""46"":46,""47"":47,""48"":48,""49"":49,""50"":50,""51"":51,""52"":52,""53"":53,""54"":54,""55"":55,""56"":56,""57"":57,""58"":58,""59"":59,""60"":60,""61"":61,""62"":62,""63"":63,""64"":64,""65"":65,""66"":66,""67"":67,""68"":68,""69"":69,""70"":70,""71"":71,""72"":72,""73"":73,""74"":74,""75"":75,""76"":76,""77"":77,""78"":78},""C"":{""0"":16.8056686489,""1"":16.0379904008,""2"":6.4429595732,""3"":8.7058822885,""4"":8.6223357982,""5"":10.8893552729,""6"":29.9402387205,""7"":7.7098324881,""8"":8.816603319,""9"":7.4098142356,""10"":9.478251861,""11"":11.7469964043,""12"":7.6184037877,""13"":10.8706530408,""14"":9.2580306488,""15"":6.3902672737,""16"":6.892769299,""17"":7.1869709614,""18"":9.2769471585,""19"":8.5459267678,""20"":9.8465188367,""21"":7.3331129569,""22"":14.6788559857,""23"":13.3219552817,""24"":9.2824997855,""25"":21.1244581221,""26"":23.7565836538,""27"":15.1479403111,""28"":9.465555362,""29"":19.9886580871,""30"":24.488760516,""31"":21.5470436057,""32"":7.2338553671,""33"":7.9205651303,""34"":20.092479274,""35"":8.5912047765,""36"":6.5104857409,""37"":8.9355002184,""38"":8.9355002184,""39"":17.075501175,""40"":8.3050959502,""41"":7.5646586731,""42"":9.978471643,""43"":11.7735883866,""44"":7.3981512291,""45"":8.5628995494,""46"":10.6369574524,""47"":6.8228967991,""48"":13.5593668015,""49"":7.8003619335,""50"":11.2686753455,""51"":7.8223047273,""52"":14.9221573836,""53"":7.94407177,""54"":7.5860553611,""55"":10.7137562149,""56"":7.9853009899,""57"":11.7810321707,""58"":11.5066048076,""59"":10.2253437726,""60"":6.3177492857,""61"":8.8546783903,""62"":10.0687076118,""63"":7.7942533617,""64"":10.1873619022,""65"":8.3987123129,""66"":8.4154164353,""67"":8.5412277762,""68"":8.0776557208,""69"":6.3744134665,""70"":6.466547658,""71"":6.3948726377,""72"":6.3948726377,""73"":6.3948726377,""74"":6.5284336757,""75"":6.6317111488,""76"":6.574636718,""77"":6.5036746253,""78"":6.5036746253},""count"":{""0"":406,""1"":362,""2"":218,""3"":158,""4"":122,""5"":114,""6"":104,""7"":98,""8"":88,""9"":82,""10"":80,""11"":78,""12"":76,""13"":64,""14"":48,""15"":42,""16"":40,""17"":40,""18"":40,""19"":38,""20"":38,""21"":38,""22"":36,""23"":36,""24"":36,""25"":36,""26"":34,""27"":32,""28"":32,""29"":32,""30"":32,""31"":32,""32"":30,""33"":30,""34"":30,""35"":28,""36"":26,""37"":24,""38"":24,""39"":24,""40"":22,""41"":22,""42"":22,""43"":22,""44"":20,""45"":20,""46"":20,""47"":20,""48"":20,""49"":18,""50"":18,""51"":18,""52"":18,""53"":16,""54"":16,""55"":16,""56"":14,""57"":14,""58"":14,""59"":14,""60"":12,""61"":12,""62"":12,""63"":12,""64"":12,""65"":10,""66"":10,""67"":10,""68"":10,""69"":10,""70"":10,""71"":8,""72"":8,""73"":8,""74"":8,""75"":8,""76"":8,""77"":8,""78"":8},""sigma_nor"":{""0"":1.8176223199,""1"":1.8246056992,""2"":1.4182286074,""3"":1.6596821899,""4"":1.735606573,""5"":1.9614727225,""6"":3.7807295267,""7"":1.7244193326,""8"":1.871279134,""9"":1.7525041051,""10"":1.9781536733,""11"":2.2303423679,""12"":1.8002214395,""13"":2.238953209,""14"":2.185986574,""15"":1.853104361,""16"":1.9406943208,""17"":1.982407208,""18"":2.2787309633,""19"":2.1988875859,""20"":2.3871979355,""21"":2.0232864898,""22"":3.1318453606,""23"":2.9310318938,""24"":2.3332158122,""25"":4.0857572471,""26"":4.5544821737,""27"":3.30410904,""28"":2.4227268533,""29"":4.0549420893,""30"":4.7529430439,""31"":4.2966598272,""32"":2.1023393794,""33"":2.2115778237,""34"":4.1478266371,""35"":2.3517810646,""36"":2.0383649504,""37"":2.4868040691,""38"":2.4868040691,""39"":3.8959010748,""40"":2.4187600811,""41"":2.2864567043,""42"":2.7177634696,""43"":3.0385198851,""44"":2.2959894066,""45"":2.5112726231,""46"":2.8946257036,""47"":2.189663755,""48"":3.4347816101,""49"":2.4160640833,""50"":3.0807984012,""51"":2.4202696225,""52"":3.7810219975,""53"":2.4949490152,""54"":2.4235994633,""55"":3.0469230005,""56"":2.560051701,""57"":3.3491403041,""58"":3.2920900299,""59"":3.0257306825,""60"":2.2596634989,""61"":2.8118220958,""62"":3.0760536309,""63"":2.5810222698,""64"":3.101878549,""65"":2.7853049591,""66"":2.7891269483,""67"":2.8179132305,""68"":2.7118455587,""69"":2.3221349664,""70"":2.3432157435,""71"":2.3782840144,""72"":2.3782840144,""73"":2.3782840144,""74"":2.4105513055,""75"":2.4355023266,""76"":2.4217135953,""77"":2.4045697146,""78"":2.4045697146},""vocab_index"":{""0"":0,""1"":1,""2"":3,""3"":5,""4"":8,""5"":9,""6"":11,""7"":13,""8"":15,""9"":17,""10"":19,""11"":20,""12"":21,""13"":26,""14"":35,""15"":41,""16"":45,""17"":46,""18"":48,""19"":50,""20"":52,""21"":53,""22"":58,""23"":62,""24"":63,""25"":64,""26"":68,""27"":69,""28"":70,""29"":71,""30"":72,""31"":73,""32"":79,""33"":80,""34"":81,""35"":83,""36"":90,""37"":96,""38"":97,""39"":103,""40"":106,""41"":108,""42"":116,""43"":121,""44"":122,""45"":123,""46"":127,""47"":132,""48"":134,""49"":135,""50"":148,""51"":149,""52"":150,""53"":170,""54"":171,""55"":172,""56"":180,""57"":193,""58"":196,""59"":197,""60"":217,""61"":228,""62"":231,""63"":239,""64"":240,""65"":245,""66"":289,""67"":291,""68"":294,""69"":295,""70"":296,""71"":299,""72"":300,""73"":301,""74"":303,""75"":353,""76"":362,""77"":367,""78"":368},""word"":{""0"":""dimensions"",""1"":""dimension"",""2"":""var"",""3"":""glyphs"",""4"":""items"",""5"":""x"",""6"":""selected"",""7"":""visualization"",""8"":""datasets"",""9"":""relationships"",""10"":""scatterplot"",""11"":""user"",""12"":""map"",""13"":""figure"",""14"":""different"",""15"":""values"",""16"":""scatterplots"",""17"":""tools"",""18"":""n"",""19"":""multi"",""20"":""space"",""21"":""screen"",""22"":""hierarchy"",""23"":""m"",""24"":""labeled"",""25"":""unselected"",""26"":""j"",""27"":""ieee"",""28"":""study"",""29"":""mask"",""30"":""hce"",""31"":""pages"",""32"":""2d"",""33"":""labels"",""34"":""proc"",""35"":""based"",""36"":""version"",""37"":""cid"",""38"":""129"",""39"":""threshold"",""40"":""computer"",""41"":""prototype"",""42"":""positions"",""43"":""texture"",""44"":""science"",""45"":""density"",""46"":""areas"",""47"":""s"",""48"":""symposium"",""49"":""ward"",""50"":""bins"",""51"":""masking"",""52"":""minutes"",""53"":""names"",""54"":""larger"",""55"":""step"",""56"":""presents"",""57"":""unoccupied"",""58"":""rain"",""59"":""candidate"",""60"":""leaf"",""61"":""sequence"",""62"":""ground"",""63"":""strong"",""64"":""subjects"",""65"":""dept"",""66"":""mode"",""67"":""d1"",""68"":""0"",""69"":""multidimensional"",""70"":""acm"",""71"":""worcester"",""72"":""polytechnic"",""73"":""institute"",""74"":""edu"",""75"":""raindrop"",""76"":""server"",""77"":""standard"",""78"":""deviation""},""vector"":{""0"":""[-1.2307066   2.6251771   3.296736    4.3487277  11.689719   -3.2463615\n -1.6862954  -3.6775155  -1.6499304  -0.28236347]"",""1"":""[-1.404483   2.8320992  3.4479547  4.390655  11.598217  -3.5320096\n -1.8352466 -3.533579  -1.3224148 -0.5936163]"",""2"":""[-1.0525311   1.8657277   4.289864    4.7324204   9.902872   -4.0838957\n -0.8386626  -2.7004259  -0.8279208   0.33783054]"",""3"":""[-0.90535975  1.7794542   3.0300968   4.6490526  11.341751   -3.047112\n -1.3484205  -3.6760333  -1.6499152  -0.4576088 ]"",""4"":""[-1.45423     2.1232998   3.140279    4.649444   11.2320595  -2.3125668\n -1.1386797  -4.187687   -1.5555285  -0.11699431]"",""5"":""[-1.0699636   2.5669565   4.047846    4.4736986  10.686314   -4.2479386\n -1.3639379  -2.9247596  -0.48424506 -0.46358415]"",""6"":""[-2.3064797  2.0529265  3.3953736  4.5551972 10.323666  -3.7488687\n -1.9033885 -3.3467784 -1.5147448 -1.0030411]"",""7"":""[-0.7447324   2.0478623   3.0176523   4.8305287  11.100165   -3.1003158\n -1.4578439  -3.4451177  -1.6394594  -0.19858953]"",""8"":""[-0.9837488   1.9877677   3.0781264   4.6969724  11.009438   -3.0644789\n -1.3146471  -3.5344956  -1.803334    0.12278887]"",""9"":""[-1.7400903   2.408728    2.896715    4.6344056  11.823782   -3.0108004\n -1.335119   -3.8362947  -1.8534694  -0.01369156]"",""10"":""[-1.0137696   2.0126386   3.0489075   4.5942965  10.983539   -3.5186207\n -1.5365677  -3.2394235  -1.699319   -0.10041877]"",""11"":""[-1.04719     1.7271483   3.3846362   4.7872443  11.132905   -2.6201622\n -0.97008085 -4.0592866  -1.0581639  -0.77315825]"",""12"":""[-1.1701773   1.809322    3.1139894   4.777357   11.298984   -3.2150428\n -1.4385306  -3.7444897  -1.4267125  -0.89329404]"",""13"":""[-1.6918024  2.4481442  3.166673   5.0460587 11.40635   -3.0690258\n -1.575727  -3.7821627 -0.773739  -1.3641286]"",""14"":""[-2.1804943  2.2280903  3.4696019  4.2389603 10.764915  -3.9170825\n -2.0689044 -3.4907675 -1.6574123 -0.9426539]"",""15"":""[-1.7459458   2.4976504   3.1028905   4.508693   11.780235   -3.1560402\n -1.4445873  -3.8524563  -1.641752   -0.23916605]"",""16"":""[-0.9915693   1.9510692   3.1849258   4.6070085  10.811141   -3.4710393\n -1.4150046  -3.2330363  -1.7174844   0.06672291]"",""17"":""[-0.9681587   2.075732    3.0217924   4.8783116  11.159799   -2.6991346\n -1.2619606  -3.7613018  -1.6139815  -0.12068348]"",""18"":""[-1.2966135  2.3917701  4.1841493  4.4781947 10.647437  -4.316246\n -1.3017818 -3.034265  -0.6934847 -0.4649552]"",""19"":""[-1.8330562  2.4509337  3.6276534  4.329009  10.975208  -4.07393\n -2.0615175 -3.31328   -1.6552627 -0.767843 ]"",""20"":""[-1.1874366   2.8931792   3.4311197   4.5416765  11.462174   -2.8229494\n -1.6130395  -3.8231668  -1.1024222  -0.32499817]"",""21"":""[-1.0051497   2.2548792   3.3600335   5.0126348  11.143349   -3.093652\n -1.408203   -3.599041   -0.62589324 -1.1602253 ]"",""22"":""[-1.8151811  2.4860935  2.9327834  4.6373944 11.8934145 -2.9006596\n -1.4195466 -4.0104733 -1.680164  -0.2633695]"",""23"":""[-1.1749562   2.6311905   4.0867863   4.3963714  10.923417   -4.1077423\n -1.2213935  -3.1227908  -0.60731614 -0.26456362]"",""24"":""[-2.270948   2.0397718  3.0998526  4.569132  10.570151  -3.4081252\n -1.9101443 -3.5164974 -1.5949606 -1.0962807]"",""25"":""[-1.8973914  1.9856807  3.3523576  4.559404  10.333124  -3.6466708\n -1.7221798 -3.2885454 -1.5799674 -0.5654663]"",""26"":""[-1.1394504   2.3978453   4.2118464   4.5107684  10.551106   -4.1886888\n -1.0960835  -2.9431856  -0.56453186 -0.15669976]"",""27"":""[-1.0113809   1.8627642   4.266966    5.021934    9.974788   -3.8233435\n -0.60167325 -2.886706   -0.6464479   0.18156649]"",""28"":""[-1.600971    2.0301452   3.381859    5.395774   10.538042   -2.49359\n -0.8764427  -3.7522464  -0.88183486 -0.3590259 ]"",""29"":""[-1.4491776  2.284824   3.0729907  4.903829  11.159978  -3.2626364\n -1.7485319 -3.4531176 -0.946836  -1.4279763]"",""30"":""[-1.1208663   1.8380843   4.173561    5.1116915  10.115755   -3.8209264\n -0.6047061  -3.0810623  -0.65657437 -0.11792721]"",""31"":""[-1.2538568   1.8370212   3.2238579   4.749929   11.14811    -2.3580873\n -0.9680285  -4.1266794  -1.3213747  -0.35499886]"",""32"":""[-1.4115613  2.2713506  4.034842   4.525226  10.734881  -4.213973\n -1.4453502 -3.193011  -0.8834841 -0.7289397]"",""33"":""[-1.6703972   1.9988261   2.8644323   4.5356336  11.225211   -2.659434\n -1.4333577  -3.9867609  -1.8410048  -0.32330602]"",""34"":""[-0.9633663  1.8695282  4.2012286  4.8372383 10.0105295 -3.9529757\n -0.7145756 -2.7514622 -0.7265622  0.2899715]"",""35"":""[-2.377304   2.0968683  3.333616   4.4674926 10.553717  -3.775132\n -2.0556664 -3.471111  -1.5999422 -1.2221093]"",""36"":""[-1.3212206  1.8988957  3.6520922  4.7144747 11.3194275 -3.4733937\n -1.4099089 -3.9194937 -1.0124196 -1.3967202]"",""37"":""[-1.2178932   2.0157578   4.427688    4.718159    9.893828   -3.9127572\n -0.9829498  -2.819488   -0.89592123  0.37263632]"",""38"":""[-1.8190838   2.1369064   3.9113564   4.4548535  10.446195   -4.1555543\n -1.6432968  -3.2017488  -1.1747872  -0.76938367]"",""39"":""[-1.9275272   2.6357388   3.4980042   4.769948   11.342675   -3.155562\n -1.6797187  -3.930912   -0.82027483 -1.2614034 ]"",""40"":""[-0.89053917  1.9778717   3.508033    5.1181545  10.880568   -2.7617583\n -0.9928166  -3.7188618  -0.77849483 -0.6533424 ]"",""41"":""[-1.2464763   1.9777769   3.5687733   4.965905   11.143408   -3.1936402\n -1.3713037  -3.8646727  -0.88415146 -1.3354397 ]"",""42"":""[-1.9204232   2.4696455   3.0682452   4.7534533  11.588214   -2.5861955\n -1.2844952  -4.1575036  -1.4053776  -0.32996032]"",""43"":""[-1.1227516  2.8477695  3.0926692  4.6829348 11.671778  -3.319671\n -1.8612232 -3.4396203 -1.1949979 -0.5295074]"",""44"":""[-1.1529467   2.2711608   3.4274514   5.317129   10.701014   -2.5321922\n -0.97165036 -3.6332855  -0.84336555 -0.16002432]"",""45"":""[-1.3032959  2.7304802  3.072049   4.6697755 11.7045    -3.2545269\n -1.7256247 -3.6267617 -1.267049  -0.4288165]"",""46"":""[-1.5878235   2.3548567   3.1511326   4.8934164  11.277799   -2.3734128\n -1.1740735  -4.083759   -1.3328217  -0.16688573]"",""47"":""[-1.2986133   2.6466413   3.9784884   4.4323215  11.0688715  -3.9206264\n -1.2512367  -3.3098307  -0.67678386 -0.38096106]"",""48"":""[-1.3927852   2.1435966   3.4542584   5.4791374  10.455757   -2.5575545\n -0.8987793  -3.5716429  -0.8345023  -0.18132181]"",""49"":""[-1.9652603  2.3776143  3.247954   5.0420966 11.174791  -2.648168\n -1.2052904 -4.0939965 -0.8972487 -0.7263032]"",""50"":""[-1.5131998   2.372798    3.058807    4.5241194  11.270678   -2.5171292\n -1.4160049  -4.042597   -1.5998306  -0.08459035]"",""51"":""[-1.7271792  2.2524345  2.9743035  4.82817   10.954088  -3.341499\n -1.8968824 -3.3560479 -1.1813619 -1.3856351]"",""52"":""[-1.3059512   2.0903084   3.3123527   4.630959   11.223947   -2.282989\n -1.0175756  -4.2199807  -1.187324   -0.31419605]"",""53"":""[-1.7117761  1.9232777  3.0127575  4.6753407 11.366312  -2.60564\n -1.1902386 -4.137003  -1.5731903 -0.4926393]"",""54"":""[-1.959306   2.2951212  3.721657   4.449238  10.919138  -3.956221\n -2.036844  -3.502601  -1.5738003 -1.0610399]"",""55"":""[-1.7329036  2.7119296  3.3790002  4.9065557 11.250916  -3.084272\n -1.6214516 -3.7257106 -0.5992641 -1.1990033]"",""56"":""[-2.3491018  2.0690923  3.168013   4.596952  10.530896  -3.514042\n -1.9569384 -3.4823246 -1.4898373 -1.2484267]"",""57"":""[-1.4960996   2.8335807   3.3125257   4.528869   11.234373   -2.6736095\n -1.691123   -3.9065828  -1.2051783  -0.32628497]"",""58"":""[-0.98611903  2.9346194   3.17387     5.048476   11.301058   -2.9073982\n -1.6681473  -3.4398708  -0.6834241  -0.49189222]"",""59"":""[-2.0691772   2.4426925   3.3132737   4.943547   11.238465   -2.784336\n -1.304225   -4.07846    -0.89501613 -0.8764292 ]"",""60"":""[-1.1025052   2.9018164   3.0995042   4.8963532  11.593081   -3.171964\n -1.8165568  -3.452561   -0.84325624 -0.7368649 ]"",""61"":""[-1.401201   2.506107   3.507322   4.8516703 11.23769   -3.2632313\n -1.5032479 -3.640179  -0.5429889 -1.2059839]"",""62"":""[-1.2708927   2.9640937   3.2974699   4.8965483  11.329541   -2.7599013\n -1.6405262  -3.7054434  -0.7671316  -0.52540994]"",""63"":""[-2.1525726  2.2732456  3.5583522  4.4024396 10.778067  -4.01769\n -2.1058686 -3.3954468 -1.6391331 -1.0897634]"",""64"":""[-1.6379803   2.0866208   3.174387    5.026638   10.946618   -2.3341172\n -1.0090663  -4.0010686  -1.3422647  -0.12265165]"",""65"":""[-1.1165258  1.8941388  4.057631   5.2912893 10.039191  -3.1456785\n -0.587399  -3.1216042 -0.6163397  0.0995476]"",""66"":""[-1.350402    2.1922486   3.757228    4.6813416  11.235322   -3.5328338\n -1.487337   -3.7691891  -0.80300856 -1.3085593 ]"",""67"":""[-1.1422689   2.02902     4.1434016   4.7534575  10.080649   -3.8635747\n -0.8702328  -2.8320122  -0.68357104  0.20278737]"",""68"":""[-1.3389162   2.1142464   4.1915913   4.537624   10.220019   -4.2015862\n -1.1899445  -2.9117758  -0.84120613 -0.15257846]"",""69"":""[-1.4393487  2.544289   3.3609414  4.3816037 11.278879  -3.7370157\n -1.9661409 -3.358205  -1.7017856 -0.5063743]"",""70"":""[-1.1813394   1.9704224   4.272127    4.9246864   9.879628   -3.6590636\n -0.78282386 -2.8253145  -0.65928686  0.31475574]"",""71"":""[-1.1118596   1.921752    4.2029986   5.1399236   9.882224   -3.4822962\n -0.63013667 -2.8928416  -0.5582134   0.27731895]"",""72"":""[-1.1891912   1.9628154   3.8898883   5.354801   10.20393    -2.9675384\n -0.6429292  -3.3333216  -0.63598627 -0.05630336]"",""73"":""[-1.3153749   2.0864942   3.6428971   5.4495964  10.389697   -2.67109\n -0.7634332  -3.5350306  -0.7085427  -0.15966742]"",""74"":""[-1.1146975   1.853405    4.1841645   5.2088456   9.92693    -3.3680718\n -0.5577309  -2.9960675  -0.62022686  0.16335182]"",""75"":""[-0.90044177  2.8516412   3.0820446   5.001096   11.452402   -3.1201797\n -1.745528   -3.346      -0.811142   -0.56611115]"",""76"":""[-0.8642691   1.7301191   3.5274227   4.906373   10.97114    -2.8226142\n -0.9113903  -3.8317907  -0.9822565  -0.63486034]"",""77"":""[-1.8048538  2.1972964  3.7184944  4.608069  11.164619  -3.6093829\n -1.686284  -3.8515053 -1.0905236 -1.3772717]"",""78"":""[-1.8449038  2.3472307  3.6155941  4.640447  11.358621  -3.44601\n -1.6896261 -3.9398267 -1.0879592 -1.3090793]""},""topic"":{""0"":5,""1"":5,""2"":2,""3"":4,""4"":6,""5"":3,""6"":0,""7"":4,""8"":4,""9"":-1,""10"":-1,""11"":6,""12"":-1,""13"":1,""14"":0,""15"":5,""16"":-1,""17"":4,""18"":3,""19"":0,""20"":-1,""21"":1,""22"":-1,""23"":3,""24"":0,""25"":-1,""26"":3,""27"":2,""28"":-1,""29"":1,""30"":2,""31"":6,""32"":3,""33"":-1,""34"":2,""35"":0,""36"":1,""37"":2,""38"":-1,""39"":1,""40"":-1,""41"":1,""42"":6,""43"":5,""44"":-1,""45"":5,""46"":6,""47"":3,""48"":-1,""49"":-1,""50"":6,""51"":-1,""52"":6,""53"":6,""54"":0,""55"":1,""56"":0,""57"":-1,""58"":-1,""59"":1,""60"":5,""61"":1,""62"":5,""63"":0,""64"":6,""65"":2,""66"":1,""67"":2,""68"":2,""69"":-1,""70"":2,""71"":2,""72"":-1,""73"":-1,""74"":2,""75"":5,""76"":-1,""77"":1,""78"":1},""exemplar"":{""0"":null,""1"":""*"",""2"":null,""3"":""*"",""4"":""*"",""5"":""*"",""6"":""*"",""7"":""*"",""8"":""*"",""9"":null,""10"":null,""11"":null,""12"":null,""13"":""*"",""14"":""*"",""15"":null,""16"":null,""17"":""*"",""18"":""*"",""19"":null,""20"":null,""21"":null,""22"":null,""23"":""*"",""24"":null,""25"":null,""26"":""*"",""27"":""*"",""28"":null,""29"":null,""30"":null,""31"":""*"",""32"":null,""33"":null,""34"":""*"",""35"":""*"",""36"":null,""37"":null,""38"":null,""39"":""*"",""40"":null,""41"":null,""42"":null,""43"":""*"",""44"":null,""45"":""*"",""46"":""*"",""47"":null,""48"":null,""49"":null,""50"":""*"",""51"":null,""52"":null,""53"":null,""54"":null,""55"":null,""56"":null,""57"":null,""58"":null,""59"":null,""60"":""*"",""61"":""*"",""62"":null,""63"":""*"",""64"":null,""65"":null,""66"":""*"",""67"":""*"",""68"":null,""69"":null,""70"":""*"",""71"":null,""72"":null,""73"":null,""74"":null,""75"":null,""76"":null,""77"":null,""78"":null},""word*"":{""0"":""dimensions"",""1"":""dimension*"",""2"":""var"",""3"":""glyphs*"",""4"":""items*"",""5"":""x*"",""6"":""selected*"",""7"":""visualization*"",""8"":""datasets*"",""9"":""relationships"",""10"":""scatterplot"",""11"":""user"",""12"":""map"",""13"":""figure*"",""14"":""different*"",""15"":""values"",""16"":""scatterplots"",""17"":""tools*"",""18"":""n*"",""19"":""multi"",""20"":""space"",""21"":""screen"",""22"":""hierarchy"",""23"":""m*"",""24"":""labeled"",""25"":""unselected"",""26"":""j*"",""27"":""ieee*"",""28"":""study"",""29"":""mask"",""30"":""hce"",""31"":""pages*"",""32"":""2d"",""33"":""labels"",""34"":""proc*"",""35"":""based*"",""36"":""version"",""37"":""cid"",""38"":""129"",""39"":""threshold*"",""40"":""computer"",""41"":""prototype"",""42"":""positions"",""43"":""texture*"",""44"":""science"",""45"":""density*"",""46"":""areas*"",""47"":""s"",""48"":""symposium"",""49"":""ward"",""50"":""bins*"",""51"":""masking"",""52"":""minutes"",""53"":""names"",""54"":""larger"",""55"":""step"",""56"":""presents"",""57"":""unoccupied"",""58"":""rain"",""59"":""candidate"",""60"":""leaf*"",""61"":""sequence*"",""62"":""ground"",""63"":""strong*"",""64"":""subjects"",""65"":""dept"",""66"":""mode*"",""67"":""d1*"",""68"":""0"",""69"":""multidimensional"",""70"":""acm*"",""71"":""worcester"",""72"":""polytechnic"",""73"":""institute"",""74"":""edu"",""75"":""raindrop"",""76"":""server"",""77"":""standard"",""78"":""deviation""},""pos"":{""0"":1,""1"":2,""2"":1,""3"":1,""4"":1,""5"":1,""6"":1,""7"":2,""8"":3,""9"":1,""10"":2,""11"":2,""12"":3,""13"":1,""14"":2,""15"":3,""16"":4,""17"":4,""18"":2,""19"":3,""20"":5,""21"":2,""22"":6,""23"":3,""24"":4,""25"":7,""26"":4,""27"":2,""28"":8,""29"":3,""30"":3,""31"":3,""32"":5,""33"":9,""34"":4,""35"":5,""36"":4,""37"":5,""38"":10,""39"":5,""40"":11,""41"":6,""42"":4,""43"":4,""44"":12,""45"":5,""46"":5,""47"":6,""48"":13,""49"":14,""50"":6,""51"":15,""52"":7,""53"":8,""54"":6,""55"":7,""56"":7,""57"":16,""58"":17,""59"":8,""60"":6,""61"":9,""62"":7,""63"":8,""64"":9,""65"":6,""66"":10,""67"":7,""68"":8,""69"":18,""70"":9,""71"":10,""72"":19,""73"":20,""74"":11,""75"":8,""76"":21,""77"":11,""78"":12},""x2D"":{""0"":1.0519770384,""1"":1.4825043678,""2"":2.1771748066,""3"":0.7023778558,""4"":-0.6110131145,""5"":3.5388016701,""6"":5.2723937035,""7"":0.811758697,""8"":0.5691592693,""9"":0.2027633786,""10"":1.0276679993,""11"":-0.021238165,""12"":1.1956769228,""13"":3.8605189323,""14"":5.1085057259,""15"":0.4939480424,""16"":0.8654354811,""17"":0.2791504264,""18"":3.5853531361,""19"":5.0140681267,""20"":1.5864790678,""21"":4.3805041313,""22"":0.1492318362,""23"":3.6455993652,""24"":5.3311076164,""25"":5.3378658295,""26"":3.3644604683,""27"":1.5352647305,""28"":0.3667845726,""29"":3.8430943489,""30"":1.27815485,""31"":-0.4234854579,""32"":3.866489172,""33"":-0.2011992484,""34"":1.8573758602,""35"":5.3935670853,""36"":4.4832777977,""37"":2.0115308762,""38"":4.7416954041,""39"":3.6761152744,""40"":0.2552843094,""41"":4.5607438087,""42"":-0.0123585202,""43"":1.6673182249,""44"":0.5220668316,""45"":1.2144616842,""46"":-0.3186795115,""47"":3.7623679638,""48"":0.4121341705,""49"":2.2844686508,""50"":-0.4045055807,""51"":4.0830593109,""52"":-0.5105486512,""53"":-0.2320062816,""54"":4.8737535477,""55"":3.888330698,""56"":5.2737016678,""57"":1.3820301294,""58"":2.1147871017,""59"":2.8497161865,""60"":1.975156188,""61"":4.1493301392,""62"":1.9970822334,""63"":4.9905982018,""64"":-0.2899733186,""65"":1.172350049,""66"":4.3966846466,""67"":1.9216046333,""68"":3.047980547,""69"":1.2738002539,""70"":1.740175128,""71"":1.489821434,""72"":0.9377911687,""73"":0.5863878727,""74"":1.3786735535,""75"":2.0854380131,""76"":0.2915405631,""77"":4.5122289658,""78"":4.121696949},""y2D"":{""0"":0.8203950524,""1"":1.0803328753,""2"":-5.4023532867,""3"":-1.3727167845,""4"":-0.700312376,""5"":-5.3281517029,""6"":-2.6528975964,""7"":-1.041280508,""8"":-1.2460535765,""9"":0.3075637221,""10"":-0.8311516643,""11"":-1.9296201468,""12"":-1.4746210575,""13"":-0.1413394064,""14"":-3.0014483929,""15"":0.486597985,""16"":-0.9837513566,""17"":-1.0784652233,""18"":-5.3848981857,""19"":-3.1282606125,""20"":0.4789750874,""21"":0.2662377656,""22"":0.2093656212,""23"":-5.0490717888,""24"":-2.7501027584,""25"":-3.0401742458,""26"":-5.106730938,""27"":-5.7521109581,""28"":-3.2837400436,""29"":-0.2930743992,""30"":-5.6327648163,""31"":-1.1922826767,""32"":-4.8707895279,""33"":-0.4902103543,""34"":-5.8138184547,""35"":-2.7475972176,""36"":-0.3588169217,""37"":-5.5946364403,""38"":-3.6963968277,""39"":0.0696535781,""40"":-2.5698931217,""41"":-0.1980213672,""42"":-0.1651140302,""43"":0.9585773945,""44"":-3.1254308224,""45"":0.7338367105,""46"":-0.9369589686,""47"":-4.9727954865,""48"":-3.3473012447,""49"":-0.3948594034,""50"":-0.2777399719,""51"":-0.7116648555,""52"":-1.2929700613,""53"":-0.5191013217,""54"":-2.9733383656,""55"":-0.0346399769,""56"":-2.4825587273,""57"":0.2905203402,""58"":0.7759212852,""59"":-0.2201745361,""60"":0.8898679614,""61"":0.2042695582,""62"":0.4964304268,""63"":-2.838881731,""64"":-1.0230979919,""65"":-4.8965511322,""66"":-0.478643775,""67"":-5.7500190735,""68"":-5.3692626953,""69"":1.2908699512,""70"":-5.5626497269,""71"":-5.3302898407,""72"":-4.3846402168,""73"":-3.5565114021,""74"":-5.2637991905,""75"":0.7954748273,""76"":-2.3081459999,""77"":-0.6439478993,""78"":-0.5034071803}}",False,False,False,http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4135655,,Value and Relation Display: Interactive Visual Exploration of Large Data Sets with Hundreds of Dimensions,CJAT82Y9,False,False
5UJ67Q46,LPICXL99,"Towards a Systematic Combination of Dimension Reduction

and Clustering in Visual Analytics

John Wenskovitch, Student Member, IEEE, Ian Crandell, Naren Ramakrishnan, Member, IEEE,

Leanna House, Scotland Leman, Chris North

Abstract— Dimension reduction algorithms and clustering algorithms are both frequently used techniques in visual analytics. Both
families of algorithms assist analysts in performing related tasks regarding the similarity of observations and ﬁnding groups in datasets.
Though initially used independently, recent works have incorporated algorithms from each family into the same visualization systems.
However, these algorithmic combinations are often ad hoc or disconnected, working independently and in parallel rather than integrating
some degree of interdependence. A number of design decisions must be addressed when employing dimension reduction and
clustering algorithms concurrently in a visualization system, including the selection of each algorithm, the order in which they are
processed, and how to present and interact with the resulting projection. This paper contributes an overview of combining dimension
reduction and clustering into a visualization system, discussing the challenges inherent in developing a visualization system that makes
use of both families of algorithms.
Index Terms—Dimension reduction, clustering, algorithms, visual analytics.

1 INTRODUCTION
Visual metaphors for exploring high-dimensional datasets come in a
variety of forms, each with their own strengths and weaknesses in both
visualization and interaction [37, 69]. In particular, datasets with high
dimensionality present tractability challenges for computation, design,
and interaction [29]. One frequently used method of visual abstraction
is to reduce a high-dimensional dataset into a low-dimensional space
while preserving properties of the high-dimensional structure (e.g., re-
tain or respect pairwise relationships from the higher dimensions in
the lower dimensional projection). Such dimension reduction algo-
rithms are useful abstractions because some of the dimensions in the
dataset may not be essential to understanding the underlying patterns
in the dataset [38]. Instead, a subset of the dimensions can be selected
or learned (or new dimensions introduced) to deﬁne the important
characteristics of the dataset. The visualization tasks associated with
dimension reduction algorithms have been well studied [14, 15].
Many dimension reduction algorithms employ a “proximity ≈ simi-
larity” metaphor, in which a distance function measures the similarity
of pairs of observations1 at the high-dimensional level and attempts to
preserve those distance relationships in the low-dimensional projection
by minimizing a stress function. Due to this “proximity ≈ similarity”
relationship, observations with high similarity or an underlying rela-
tionship can form implicit clusters in the low-dimensional projection.
Indeed, clustering can even be thought of as extremely low-resolution
dimension reduction, where knowledge about the various attributes
of the observations leads to a one-dimensional bin assignment (or a
set of probabilities for bin assignments). This relationship between
dimension reduction and clustering is also supported mathematically
in speciﬁc instances. For example, Ding and He [27] proved that prin-
cipal components are the continuous solutions to the discrete cluster
membership indicators for k-means clustering, indicating that Principal

• John Wenskovitch, Naren Ramakrishnan, and Chris North are with the

Virginia Tech Department of Computer Science. E-mails: {jw87 | naren |
north}@cs.vt.edu.
Department of Statistics. E-mails: {ian85 | lhouse | leman}@vt.edu.

• Ian Crandell, Leanna House, and Scotland Leman are with the Virginia Tech

Component Analysis (PCA) dimension reduction implicitly performs
data clustering as well.

Indications from previous studies [8, 33] have shown that analysts
use a complex combination of both developing clusters and organizing
observations in space in the sensemaking process [76] as they explore
a dataset. These explorations generate clusters created by the analyst
during exploratory interactions to spatially organize information on
the display, as well as clusters that naturally develop due to expressive
interactions updating the underlying layout (these interaction types are
deﬁned by Endert et al [34]). Other studies have also linked dimension
reduction algorithms to clustered data; for example, Choo et al. dis-
cusses dimension reduction methods for two-dimensional visualization
of high-dimensional clustered data, proposing a two-stage framework
for visualizing such data based on dimension reduction methods [21].
While dimension reduction algorithms and clustering algorithms
have been implemented together in a number of visualization systems,
these algorithms often operate independently and in parallel. In other
words, each algorithm supports some analysis component in the system
without the inﬂuence of the other algorithm: perhaps a collection
of observations are clustered, but the output of that clustering has
limited or no effect on the dimension-reduced layout of the observations.
Alternatively, a change to the spatialization may perceptually imply
the need for a change to the cluster assignment, but no update to
the cluster assignment may occur. The second case can be seen in
the iVisClustering system [57]. This tool clusters documents into a
collection of topics and uses a force-directed layout in the Cluster
Relation View to present the documents spatially. However, making a
change to the layout of the projection (see Fig. 1) has no effect on the
clustering assignments of the documents.

Exploring the connections between dimension reduction and clus-

Manuscript received xx xxx. 201x; accepted xx xxx. 201x. Date of Publication
xx xxx. 201x; date of current version xx xxx. 201x. For information on
obtaining reprints of this article, please send e-mail to: reprints@ieee.org.
Digital Object Identiﬁer: xx.xxxx/TVCG.201x.xxxxxxx

1In this work, we employ the convention of referring to the features of a
dataset as dimensions, individual data items as observations, and the features of
those observations as attributes.

Fig. 1. The iVisClustering system [57] incorporates dimension reduction
and clustering algorithms in the same system; however, making a change
to the layout has no effect on the clustering assignment.

Table 1. A selection of dimension reduction algorithms, organized by
the complexity of manifold each can learn: linear manifolds, nonlinear
manifolds, and algorithms that have implementations of both types.

Linear

Both

Nonlinear

Selected Dimension Reduction Algorithms
Factor Analysis [43]
Principal Component Analysis (PCA) [74]
Probabilistic PCA (PPCA) [84]
Projection Pursuit [40]
Feature Selection [42]
Independent Component Analysis (ICA) [49]
Multidimensional Scaling (MDS) [85]
Weighted MDS (WMDS) [18]
Glimmer [50]
Isomap [82]
Latent Dirichlet Allocation (LDA) [11]
t-Distributed Stochastic Neighbor Embedding
(t-SNE) [65]

tering algorithms leads to several natural research questions. If the
data separates into implicit clusters, and the analyst sees advantages
in the creation of these implicit clusters, can we appropriately sup-
port explicit cluster deﬁnitions so that the dimension reduction and
clustering algorithms support each other rather than conﬂict with each
other (or simply do not interact with each other)? If so, how should we
deﬁne, visualize, and interact with both observations and clusters in
a dimension-reduced projection? And ﬁnally, is there a difference be-
tween how analysts interpret and interact with low-dimensional clusters
as opposed to high-dimensional clusters?

Our research explores initial steps to address these questions. In

particular, this work includes the following contributions:

1. An overview of combining dimension reduction and clustering
techniques into a visualization system, including a discussion of
algorithms, tasks, visualizations, and interactions.

2. A discussion of the design decisions that must be addressed when
creating a visualization system that combines dimension reduction
and clustering algorithms.

The remainder of this paper discusses these contributions through the
exploratory data analysis process. We begin by providing an overview
of existing dimension reduction and clustering algorithms in Sect. 2.
From there, we discuss common high-dimensional data analysis tasks
is Sect. 3, visualizations to support those tasks in Sect. 4, and interac-
tions on those visualizations in Sect. 5. We close with a discussion of
further challenges and lessons learned in Sect. 6 and conclude in Sect. 7
with a summary of design questions that should be considered when
developing a tool combining these algorithm families.

2 ALGORITHMS
In this section, we summarize the variety of algorithms that address
dimension reduction and clustering tasks in visualization systems.

2.1 Dimension Reduction Algorithms
The goal of dimension reduction algorithms is to represent high-
dimensional data in a low-dimensional space while preserving high-
dimensional structures, including outliers and clusters [58]. Dimension
reduction has a scalability advantage over other methods for visualizing
high-dimension data such as parallel coordinate plots and heatmaps, but
with the disadvantage of information loss when transforming the data
into the low-dimensional projection [37, 61, 69]. Here, we summarize
many of the common dimension reduction algorithms in the Visualiza-
tion ﬁeld; more detailed surveys of dimension reduction algorithms can
be found in the literature [38, 39, 58, 91]. In addition, several tools have
been implemented that allow analysts to switch between and compare
dimension reduction algorithms [62, 77].

Dimension reduction algorithms can be divided into linear and non-
linear classes, referring to the structure of the underlying manifolds or
topological spaces that each class can learn. Linear dimension reduction
algorithms are limited to learning linear manifolds, while nonlinear di-
mension reduction algorithms can learn more complex manifolds. Still
other dimension reduction algorithms have been implemented in both
linear and nonlinear variants. Table 1 provides a set of commonly used
dimension reduction algorithms in the visualization literature, divided
into whether they are linear, nonlinear, or have implementations of both
levels of manifold complexity. Principal Component Analysis (PCA) is
perhaps the most frequently-used linear dimension reduction algorithm,
which works by determining the axes of maximum variance in the col-
lection of observations [74]. Another often-used dimension reduction
technique is Multidimensional Scaling (MDS), which computes pair-
wise distances between observations in the high-dimensional space and
attempts to preserve those distances in a low-dimensional projection.
MDS implementations exist in both linear and nonlinear forms.

Many of these dimension reduction algorithms require a distance
function as input, which provides the method for calculating the simi-
larity of each pair of observations. Much like the breadth of algorithms
discussed, a number of distance functions are used in Visualization
systems. The most popular metrics are those derived from p-norms,
which give distance functions of the form

(cid:12)(cid:12)xi,k − x j,k

(cid:12)(cid:12)p(cid:19)1/p

.

(cid:18)

∑

k

dp(xi,x j) =

Such a distance is deﬁned for any positive p. The most familiar ex-
amples are p = 1, which is known as Manhattan distance (due to the
city’s regular grid structure), and p = 2, which is Euclidean distance.
Aggarwal et al. [2] showed that Manhattan distances are preferable
to Euclidean distances for high-dimensional data, as Euclidean dis-
tance (and p-norms of p > 1 in general) tends to compress the space
as more dimensions are added, resulting in high-dimensional distances
that are less distinguishable. In determining the appropriate distance
function, it is also worth considering that some distance functions are
computationally more difﬁcult when optimizing a stress function.

Large datasets present performance difﬁculties with some dimen-
sion reduction algorithms. For example, MDS requires a distance to
be computed between each pair of observations, resulting in ∼ n2/2
distances computed for n observations. However, tools do exist to
visualize such large datasets. ASK-GraphView supports the interactive
visualization of graphs with up to 200,000 nodes and 16,000,000 edges
by using clustering algorithms to construct a hierarchical graph, thus
visualizing only internal subsections of the graph at any time [1]. A
related solution that combines these algorithm families is to initially
cluster the data and then apply a dimension reduction algorithm such
as MDS on the cluster centroids, followed by subsequent dimension
reduction executions on each individual cluster. This minimizes the
amount of memory required to store pairwise distances at the expense
of no longer having a single global distance measure.

2.2 Clustering Algorithms
Hundreds of clustering algorithms have been implemented, each with
inherent strengths and weaknesses. The broad collection of approaches
in this class of algorithms stems from the notion that a “cluster” is in-
herently a subjective structure, and as such cannot be precisely deﬁned.
Therefore, new algorithms or improvements on existing algorithms are
often created to solve a single problem, though these new solutions
may be applied to future problems where appropriate. As a result, there
is no globally optimal clustering algorithm; the best clustering algo-
rithm is problem-speciﬁc and often determined experimentally [36].
Surveys of clustering algorithms exist in the literature, which include
clustering from the perspectives of machine learning, human-computer
interaction, visualization, and statistics [23, 92].

Clustering algorithms come in two primary forms: hierarchical and
partitioning. Hierarchical algorithms in turn can be divisive (top-down)
or agglomerative (bottom-up). The divisive strategy approaches the
identiﬁcation of clusters through iterative partitioning, beginning with a

Table 2. Sample exploratory data analysis tasks, organized by stage in the data analysis process (rows) and algorithm family (columns).

See the Result

Dimension Reduction
See distribution of observations

Both
See relative positions of observations

Understand the Result Measure distances between observations

Identify attribute values of observations

Affect the Result

Change distance metric
Select different dimensions

Reposition observations in the full space
Enhance an existing pattern in the projection

Clustering
Identify clusters of observations
Label clusters
Determine cluster structure
Change cluster membership of observations
Create/remove clusters

single group and breaking it down into smaller portions according to an
algorithm-speciﬁc differencing measure [4]. In contrast, agglomerative
algorithms approach clustering through iterating aggregation, beginning
with every item in its own group and joining groups together through
an algorithm-speciﬁc similarity measure [78].

Perhaps the most common clustering algorithm is k-means [64],
which partitions a dataset into k clusters according to a distance between
each observation and the nearest cluster centroid. Finding an optimal k-
means solution is an NP-Hard problem; therefore, heuristic algorithms
exist to converge quickly to a local solution. The k-means algorithm
has been extended to support a variety of tasks, including weighted
clustering [48], hierarchical clustering [75], textual data [26], and
constrained clustering [89]. A number of k-means variants are discussed
in detail by Cordeiro de Amorim and Mirkin [25]. A major limitation
of k-means is that it can only ﬁnd clusters with convex shapes. The
algorithm also requires input parameter k for the number of clusters to
create, presenting an additional complication in generating the best set
of clusters with its heuristic approach. Several solutions to determine
the most appropriate k value are used, such as the elbow method [83].
Many of the distance functions that are applied to dimension reduc-
tion algorithms are also useful when considering cluster computations.
Cosine distance, for example, can be used to measure cohesion within
clusters [81]. The Jaccard similarity coefﬁcient is used for measuring
diversity and dissimilarity between clusters or sets of observations [60].
In selecting a clustering algorithm, an additional consideration
should be whether an observation can be assigned to only one cluster
(“hard” clustering) or can belong to multiple clusters (“fuzzy” or “soft”
clustering). The Fuzzy C-means Clustering algorithm [9, 30] is a fuzzy
extension of the k-means algorithm, in which the centroid of a cluster
is now computed as the mean of all observations weighted by their
probability of belonging to the cluster. Fuzzy C-means has found use
in the ﬁelds of bioinformatics [87] and image analysis [3].

A common clustering tool used in statistics is the Dirichlet process
mixture model (DPMM) [10]. This is a probabilistic method, and rather
than return a hard clustering assignment, it gives each observation a
probability of belonging to any given cluster. Additionally, and unlike
k-means, DPMMs learn the number of clusters dynamically, creating
new clusters and closing old ones as the algorithm proceeds. It is not
without drawbacks, however. The DPMM requires speciﬁcation of a
probability model for the observations in each cluster, which in turn
introduces its own difﬁculties. The algorithm also scales more poorly
than k-means with additional data, especially if the model parameters
are estimated with Markov chain Monte Carlo.

Much like with dimension reduction algorithms, large datasets can
present performance issues with clustering algorithms. Consider again
the k-means algorithm, for which the common Lloyd’s algorithm heuris-
tic implementation has a running time of O(nkdi) for a dataset with n
observations of d dimensions each, k clusters, and i iterations before
convergence [64]. The runtime of this algorithm is thus linear in terms
of both the number of observations and the number of dimensions;
however, performance can be greatly improved by reducing the number
of dimensions. Assuming that n and k are ﬁxed, the execution time
of the k-means algorithm can hence be improved substantially with
dimension reduction, potentially dropping the value of d from hundreds
to two (which may simultaneously reduce i as well). Several clustering
algorithms are designed to use on large datasets. For one example,
the Bradley-Fayyad-Reina (B-F-R) clustering algorithm is a variant
of k-means that works by internally maintaining summaries of large
collections of observations [13].

3 TASKS
This section presents an overview of tasks commonly seen in visu-
alization systems that implement dimension reduction and clustering
algorithms for exploratory data analysis. We discuss the implications
of the order in which these algorithms are executed, along with related
design decisions and considerations.

3.1 Dimension Reduction and Clustering Tasks
Our discussion of tasks for dimension reduction and clustering algo-
rithms focuses on exploratory data analysis tasks. When exploring a
high-dimensional dataset with dimension-reduced projections, there
are an immense number of possible 2D- or 3D-projections that can be
generated from the dataset. An analyst should be afforded the ability to
explore these alternate projections, as well as the related clusterings in
those projections, in order to gain insight from the data.

One method for enabling this exploration is by applying weights to
the dimensions in the dataset. Biasing the algorithms towards combina-
tions of dimensions in the dataset enables the creation of projections
that are similarly biased towards those dimension combinations. Thus,
an analyst can explore clusters and patterns in a projection that is biased
towards dimensions X, Y , and Z, and contrast that result with clusters
and patterns in a projection biased towards only dimensions U and V ,
both from the same initial high-dimensional dataset.

When interactively exploring a dataset, dimension reduction tasks
(the left columns of Table 2) typically relate to position, while cluster-
ing tasks (the right columns of Table 2) typically relate to grouping. For
example, identifying a similarity relationship between two observations
based on their separation distance in a projection is a dimension reduc-
tion task, while positioning two similar observations close together is
a clustering task. However, there exists obvious ambiguity even with
such basic interactions. When positioning two objects close together to
form a cluster, the analyst is also communicating a distance relationship
between those observations. Thus, space is overloaded for both group-
ing and layout interactions, further suggesting a relationship between
the dimension reduction and clustering algorithm families. As seen in
the selected tasks breakdown in Table 2, tasks can often be addressed by
only using a dimension reduction algorithm or a clustering algorithm,
but there do exist many cases where the interplay between algorithms
affects both when a task is performed.

This relationship can be further seen in Brehmer et al. [15], in which
ten analysts from six application domains were interviewed with the
goal of understanding how analysts explore dimension-reduced data.
The end result of this study was a set of ﬁve task sequences. Although
the authors were focused on analyst interpretations of dimension-
reduced data, three of the ﬁve resulting task sequences were related
to clusters of items revealed in the low-dimensional data projection.
Indeed, the “Verify Clusters” task sequence was performed by all ten
of their analysts and the “Name Clusters” sequence was performed by
eight of the ten analysts. In contrast, the tasks sequences that were
not cluster-based were only performed by two (“Name Synthesized
Dimensions”) and four (“Map Synthesized to Original Dimensions”)
of the ten analysts. These ﬁndings suggest that analysts are discretizing
these clusters of observations in dimension-reduced projections. In
other words, the dimension reduction algorithm is creating a continuous
visual distribution that analysts interpret in discrete segments. More-
over, investigating these clusters within the projection are common
goals of user exploration and interaction with datasets.

In addition to investigating clusters in an existing projection, studies
have shown that analysts create their own clusters of observations. For

example, the “Space to Think” study by Andrews et al. [8] investigated
how analysts use large displays to navigate and lay out documents in
the sensemaking process [76], and that these clusters occasionally have
spatial relationships, both to develop a timeline and to keep similar clus-
ters of documents near to each other spatially. When interviewed about
their sensemaking process later, analysts spoke of their documents and
clusters both in terms of proximity and in terms of groups, implying
that these are similar cognitive processes. The ForceSPIRE [33] and
StarSPIRE [12] systems were designed in part from these ﬁndings.

Similar behavior was seen in the “Be the Data” system reported by
Chen et al. [20], which allows participants to explore a dataset by taking
on the role of the observations in a deﬁned physical space. By moving
about the space, participants update a dimension-reduced projection.
The system is thereby able to learn which dimensions of the dataset are
most important to the current “projection” of people. Presented with
a collection of animals and their attributes, a group of seventh grade
students were posed the question “What makes some animals good to
eat?” The students began their exploration of the data by clustering
animals into discrete Edible and Inedible clusters. However, the student
who embodied the Rat observation did not consider herself a part of
either group, noting that rats are normally not edible but are consumed
in some cultures. She then positioned herself between the two clusters.
This caused the rest of the students to reconsider their distribution,
turning the discrete clusters into a continuous distribution of Edibility.
Cluster investigation tasks (the right columns of Table 2) come in a
number of forms, each of which have some meaning in a dimension-
reduced projection. For example, analysts may wish to understand the
overall layout of clusters in a projection, explore the proximity of one
cluster to another, investigate clusters of clusters and similar structures,
the shape of a cluster, and describe outlying clusters versus central clus-
ters. In addition, analysts may be interested in the relationship between
clusters and the individual observations in the projection, exploring to
which cluster(s) an observation belongs, understanding the properties
of observations that are outliers to all clusters, and investigating the
properties of a set of observations that form a cluster. There is a mix
of distribution and group questions that can be addressed through the
combination of both dimension reduction and clustering algorithms.

Adding clusters and clustering interactions to dimension-reduced
data can also improve scalability as datasets continue to grow in
size [32]. Having the ability to abstract collections of observations
into a single cluster that acts as an interaction target enables the abil-
ity to place more objects into virtual spaces, useful both for standard
monitors and for large display systems.

While the outputs of dimension reduction and clustering algorithms
are useful to locate patterns in a dataset, we also beneﬁt from enabling
these algorithms to learn from user interactions [34, 46, 59]. By in-
terpreting the semantic meaning of user interactions, each of these
algorithms can better enable exploratory data analysis. For example,
an analyst may wish to know what model parameters are necessary to
create a cluster from observations A, B, and C. By manipulating the pro-
jection to form such a cluster and initiating a semi-supervised machine
learning routine, the dimension reduction and clustering algorithms
can be trained to learn such model parameters and to update the entire
projection in response to those new parameters. The new projection
may create a new cluster from observations D, E, and F in addition to
the analyst-created cluster, a new insight into the dataset. Therefore,
the dimension reduction and clustering algorithms can help both at
the beginning of the exploration process by providing a na¨ıve starting
point, as well as throughout the exploration process by responding to
the interactions of an analyst.

3.2 Coordinating the Algorithms
Another consideration in selecting dimension reduction and clustering
algorithms is determining what parameters should be learned and used
by each algorithm, as well as what information should be learned by the
analyst. Beginning with the analyst, we discussed in the previous sub-
section that dimension reduction algorithms and clustering algorithms
serve similar purposes. However, dimension reduction algorithms are
more suited to tasks for pairwise comparisons and similarities between

observations, while clustering algorithms are better suited for compar-
isons involving the recognition and description of groups.

For the algorithms, one obvious design decision is to determine
whether or not the dimension reduction algorithm and clustering algo-
rithm should be using the same distance function, or even if they should
be using the same set of weights on the dimensions. It is possible for
the dimension reduction algorithm and the clustering algorithm to store
separate sets of weights, or to use different distance functions entirely.
When considering the semantics of the order of dimension reduction
and clustering algorithms, using clustering in high-dimensional space as
the ﬁrst operation makes uncovering clusters the primary semantic role
of the system, and hence results in a system designed to support locating
and understanding groups in the input data. In contrast, clustering as
the second operation in the low-dimensional space after executing a
dimensional reduction algorithm results in a clustering algorithm that
is merely a secondary aid to the dimension reduction algorithm.

An open question is determining whether analysts are cognitively
clustering in high-dimensional or low-dimensional space. Given that
analysts typically form clusters of text documents directly from the text
instead of ﬁrst converting those documents into another form [8], it
appears that clustering is performed in the high-dimensional space, at
least for textual data. Understanding the clustering process of analysts
will lead to better semantic interactions in this dimension reduction and
clustering design space, leading to further system interactions such as
enabling humans to provide corrections to clustering assignments and
hence update dimension reduction algorithm weights and projections.
Naturally, it is not possible to coordinate all pairs of dimension
reduction and clustering algorithms. For example, some dimension
reduction algorithms such as PCA do not rely on distances between
observations. Therefore, using the same distance measure between
PCA and a clustering algorithm is not possible.

3.3 Dimension Reduction and Clustering Combinations
When developing a system that includes both dimension reduction and
clustering algorithms, it is important to consider the order in which
these algorithms are performed on the data, as the order of these al-
gorithms will generate projections with different semantic meanings.
Fig. 2 includes six different pipelines that display execution orders
and data ﬂows between these algorithms. Each of these pipelines is
discussed in the following paragraphs. As the analyst progressively
explores the dataset, they may select a different pipeline for each round
of exploration, continuing to explore new projections (Fig. 3).

Independent Algorithms: As discussed previously, many visual-
ization systems incorporate both dimension reduction and clustering
algorithms, but these algorithms often execute independently and in
parallel so that the output of one algorithm has no effect on the other.
This pipeline is highlighted ﬁrst in Fig. 2 and was discussed in the
iVisClustering [57] example in the Introduction. In this system, topics
are computed and assigned as clusters, and a force-directed compu-
tation performs the node layout in the spatialization. However, an
update to the layout has no effect on the clustering assignments. In
addition, computing both algorithms on the high-dimensional data
will be more computationally expensive than performing only a single
high-dimensional computation.

Dimension Reduction Preprocessing for Clustering: Another
possibility is to execute a dimension reduction algorithm on the high-
dimensional data, and then pass the low-dimensional projection to the
clustering algorithm to determine groups, clustering on the reduced
data rather than the source data. This decision may be advantageous
because the clustering algorithm can execute faster on a dataset with
fewer dimensions, but the outcome may be misleading because the
low-dimensional positions of each observation are an approximation of
the high-dimensional relationships. Rather than generating clusters of
the input data, we generate clusters using data with less information,
resulting in potentially misleading cluster assignments. This risk is dis-
cussed by Joia et al. [52], noting that distances in the low-dimensional
space may be misleading due to projection errors. As a result, what
appear to be distinct clusters must be conﬁrmed, as there is no guaran-
tee that these clusters do contain unique content. An example of this

Fig. 2. Six different options for pipelines depicting combinations of dimension reduction algorithms and clustering algorithms. In each of these
pipelines examples, it is implied that each algorithm could use an independent distance function, resulting in more than just these six pipelines.
Further, these pipelines represent a single analysis iteration.

pipeline can be seen in Zha et al. [94], in which a technique similar
to PCA is performed ﬁrst and followed by k-means on that output.
Likewise, Ng et al. [71] propose an algorithm in which the observations
are embedded in low-dimensional space such as the eigenspace of the
graph Laplacian, and then k-means is applied to that low-dimensional
projection. Be The Data also creates clusters dynamically based on the
current projection [20].

Clustering Preprocessing for Dimension Reduction: The reverse
of the previous behavior occurs when the clustering algorithm is the
ﬁrst to execute, and then some information from the clustering output
(the cluster assignments, or the locations of the centroids) is used by the
dimension reduction algorithm for layout. Now, the clusters represent
relationships that exist in the initial data in high-dimensional space.
However, the clustering algorithm will take longer to execute due to
the additional number of dimensions processed. While less common,
some systems do operate in this way. For example, Ding and Li ﬁrst
use k-means clustering to initially generate class labels, followed by
LDA dimension reduction for subspace selection [28]. Fuzzy clustering
introduces a new complexity to this pipeline, as cluster assignments
are now a probability distribution rather than a ﬁxed bin assignment.
A pipeline of this form can also improve scalability, as the time and
space complexity of many dimension reduction algorithms make them
infeasible to execute on very large datasets. Clustering observations
and then performing a dimension reduction algorithm on those clusters
is one solution to this challenge.

One Algorithm Implicitly Includes the Other: Another alterna-
tive is to only execute one of the algorithms, either dimension reduction
or clustering, and then convert or interpret the output of the executed
algorithm as the output for the other algorithm as well. In these cases,
the results from one algorithm are structured to ﬁt the objective of the
other algorithm, exploiting the mathematical equivalence between these
algorithm families discussed brieﬂy in the Introduction. For example,
we can codify soft k-means clustering as assigning n observations to
k features with some associated weight or probability. Likewise, we
can formulate dimension reduction as reducing m features to p features

Fig. 3.
Interactions from the analyst will drive additional executions
through the pipeline during the data exploration process. The analyst
does not need to select the same pipeline on every iteration of the
analysis.

with some associated weight or probability. Therefore, the outcome of
soft k-means clustering can be interpreted in terms of dimension reduc-
tion by making the k clustering features also represent the p dimension
reduction features. A similar argument exists to map the outcome
of a dimension reduction algorithm directly to a cluster encoding by
executing a dimension reduction algorithm like PCA and binning the
output along one of the axes. Perhaps a more straightforward example
of this pipeline is the self-organizing map [55], a dimension reduction
technique which can be directly interpreted as a set of clusters without
any feature transformation. Kriegal et al. [56] present a survey of clus-
tering techniques for high-dimensional data, and include a discussion
on subspace clustering algorithms. Such algorithms simultaneously
reduce both the number of observations and the number of dimensions
in a dataset, in contrast with having a dimension reduction algorithm
that reduces the number of dimensions computing separately from a
clustering algorithm that reduces the number of observations.

Global and Local Algorithm Combinations: Because dimension
reduction algorithms typically take a global view of the overall space
while clustering algorithms take a local view [26], another option is
to implement a pipeline in which the overall structure of the space
is informed by the dimension reduction algorithm while local struc-
tures are governed by the clustering algorithm. These algorithms can
communicate with each other to converge towards an optimal layout,
but each is responsible for its own aspect of the structure. To further
clarify the difference between this pipeline and some of those discussed
previously, consider organizing a large collection of documents in a
display. One possibility is to place related documents into folders, and
then organize the folders in the space. This example reﬂects the “Clus-
tering Preprocessing” pipeline, as we organize the clusters rather than
individual documents. In contrast, the analyst could organize groups of
documents in the space, and then select and move those groups with
respect to one another. This example affords some additional fuzzy
clustering capabilities, as a document that may belong to two or more
clusters can be placed between those clusters. Here, the overall layout
of the documents can be handled by dimension reduction, while some
local structures of similar documents are supported by clustering.

Iterative, Alternating Algorithms: The ﬁnal pipeline represents a
structure where both dimension reduction and clustering are working
together in the same overarching algorithm. As k-means is an algo-
rithm that alternates between updating cluster assignments and centroid
positions, a third stage can be added for dimension reduction. Ideally,
this iterative alternating process will enable dimension reduction and
clustering to work in harmony to converge towards a best layout, trying
to ﬁnd the right set of dimensions and a good set of clusters simultane-
ously while also communicating between the algorithms. This pipeline
differs from “One Algorithm Implicitly Includes the Other” in that both
algorithms process the data cooperatively, rather than only executing
one of the algorithms and using its outcome to present both a projection

Fig. 4. Three options for encoding group membership as studied by
Saket et al [79]. In (a), nodes are free-ﬂoating and colored based on
cluster membership. In (b), the cluster coloring remains, and links are
drawn as necessary between some of the nodes. In (c), the nodes are
replaced by colored space-ﬁlling regions to indicate cluster membership.

and a clustering. Since both the dimension reduction algorithm and
the clustering algorithm will begin on the high-dimensional data, this
pipeline will be among the slowest to converge. Niu et al. [72] provides
an example of this pipeline.

This collection of pipelines and examples demonstrates methods
for combining dimension reduction and clustering algorithms, but are
not without limitations. Even extending these pipelines with a looping
structure to iterate through the dimension reduction and clustering
stages is insufﬁcient. To better model this and other similar cognitive
processes, we must extend this discussion of algorithms into the realm
of visualization and interaction; algorithms alone are insufﬁcient for
complex cognition [35].

4 VISUAL REPRESENTATION
After the algorithms have been selected, the next step is determining
how to present the results of the computations to the analyst. In this
section, we ﬁrst discuss common visual representations for dimension-
reduced data and clustered data. This is followed by a discussion of
potential visual outcomes of the pipelines introduced in Sect. 3.3.

4.1 Known Visualization Issues
As the sample interfaces in the bottom row of Fig. 6 show, most dimen-
sion reduction algorithm outputs are shown in scatterplots or node-link
diagrams. These scatterplots come with inherent issues in some cases,
such as difﬁculties in displaying and interpreting the dimensions that
result from an MDS projection. When dealing with large datasets,
the scatterplot or node-link representation of the dimension reduction
output runs a high risk of overplotting, especially if the spatialization
exhibits clear clustering in the layout. One solution for overplotting is
to abstract a cluster of observations into a single glyph to represent a
collection of observations, such as suggested by the Splatterplots im-
plementation [67]. An alternative is to ﬁlter the number of observations
visible in an overdrawn region, keeping a representative ratio of each
cluster in the overdrawn region [19].

While the natural representation of the dimension reduction output
uses a spatial projection like a scatterplot or node-link diagram, the
possibilities for representing cluster membership are much more diverse.
In addition to demonstrating clusters using a collection of nodes in close
spatial proximity, cluster membership can be encoded with colors or
glyphs. Even then, a number of design decisions can be made for how
best to express these memberships by color and shape.

Saket et al. [79] evaluate several encodings of cluster information
(see Fig. 4 for a visual representation of each of these encodings),
relating each to node-based tasks (for example, “Given node X, what
is its background color?”) and group-based tasks (“Given nodes X
and Y, determine if they belong to the same group”). They found that
the addition of group encodings does not negatively impact time and
accuracy on node-based tasks. As would be expected, group-based
tasks were best solved by node-link-group encodings. This outcome
suggests that the visual representation used to encode the clusters in
the projection depends on the tasks that the system addresses.

Fig. 5. Four options for displaying cluster membership as studied by
Jianu et al [51]. In addition to a node-link representation similar to that
included by Saket et al., this study included Linesets [5], GMap [41], and
BubbleSets [24].

Jianu et al. [51] perform a similar evaluation on four visual represen-
tations, including a node-link diagram similar to that studied by Saket
et al. as well as three other visual representations that are shown in
Fig. 5. Linesets [5] include link colors that match the node colors rep-
resenting cluster membership, highlighting connections between nodes
that are in the same cluster or group (top-right of Fig. 5). GMap [41]
is a space-ﬁlling representation that renders a geographic-like map for
clusters, containing all of the nodes in a colored region similar to the
node-link-graph representation studied by Saket et al. (bottom-left
of Fig. 5). Finally, BubbleSets [24] draws isocontours around clus-
ters, effectively balancing the Linesets and GMap representations by
using the isocontours to highlight links connecting members of the
same cluster but becoming space-ﬁlling in regions with high node den-
sity (bottom-right of Fig. 5). This study found that BubbleSets was
the superior representation for group-based tasks, but that encoding
group information onto node-link diagrams adds a 25% time penalty
onto network-based tasks, a conﬂict with the conclusion of Saket et al.
Clearly, more research is needed in this area to resolve such conﬂicts.
In addition to the above, another method for visualizing clusters
in a scatterplot or node-link diagram is to enclose nodes from indi-
vidual clusters in a convex hull [90]. Because k-means solves for
convex clusters based on a distance from an observation to the nearest
cluster centroid, a convex hull visualization may be the most natural
visualization representation for a k-means clustering output.

Moving away from scatterplot and node-link representations, an
alternative representation for clusters is to encode topics into a stream-
graph. For example, Liu et al. use streamgraphs to encode related text
keywords into topical collections, using the streamgraph to show how
the importance of those topics and keywords changes over time [63].

4.2 Algorithm Order Visualizations
Designers have an additional choice regarding which features are em-
phasized in the visual representation. For example, should the spatial
layout of the dimension reduction be emphasized over the cluster as-
signments? Alternatively, should the cluster assignments inform the
layout of the observations? Should we attempt to balance the two
outputs? How much of an impact should the algorithm order play in the
ﬁnal layout? The order in which we execute the dimension reduction
and clustering algorithms should have some impact on the outcome
of the visualization, but the degree to which this execution order is

emphasized can vary by system goals. Here, we describe potential
visualization properties for each of the pipelines described in Sect. 3.3.
Independent Algorithms: Consider the ﬁrst pipeline from Fig. 2,
in which both algorithms execute independently and in parallel. One
potential outcome of this pipeline is to represent clusters using convex
hulls. Here, the dimension reduction algorithm operates to ﬁnd an ideal
layout, while the clustering algorithm separately ﬁnds an ideal cluster
set. When combining the outputs, a potential result is a cluttered visual-
ization that is somewhat ambiguous in the cluster assignments of some
observations due to intersections between the clusters. A potentially
better solution, used by iVisClustering [57], is to use nodes colored by
class in cases of cluster occlusion such as these. Another solution that
allows the convex hulls to remain is to implement layout constraints
(such as those in IPSep-CoLa [31]) so that objects that clearly belong
to different clusters are visibly separated in the spatialization. However,
this requires prior knowledge of key cluster-deﬁning objects, or an
initial clustering computation that precedes the main clustering process.
This also defeats the goal of the pipeline by removing the separation
between dimension reduction and clustering algorithm execution.

Dimension Reduction Preprocessing for Clustering:

In this
pipeline, the output of the dimension reduction algorithm is fed into
the clustering algorithm, enabling clustering on the low-dimensional
reduced data rather than on the initial high-dimensional data. Because
clusters are drawn based on the proximity of observations in the projec-
tion, it is unlikely that these clusters will intersect. As noted previously,
executing the clustering algorithm on the dimension-reduced data may
not produce an optimal clustering on the high-dimensional data, which
could affect the analyst’s comprehension of the projection.

Clustering Preprocessing for Dimension Reduction: In the re-
verse of this process, we now cluster in the initial high-dimensional
data, and use some of that information such as the cluster assignments
to inform the dimension reduction. Such a visualization will likely re-
sult in visibly separated clusters as in the previous case, though perhaps
even more separated because space can be artiﬁcially added between
the clusters. Again, because we execute the dimension reduction algo-
rithm on the cluster assignment information (or other cluster algorithm
output) rather than on the initial high-dimensional data, the dimension
reduction projection may not be optimal and could also affect the ana-
lyst’s comprehension of the projection. More clearly stated, two points
that the dimension reduction algorithm judges to be somewhat similar
(but not similar enough to belong to the same cluster) may have an
artiﬁcially large distance applied between them in this projection.

One Algorithm Implicitly Includes the Other: A pipeline in
which only one algorithm is executed to perform both the dimension
reduction and clustering functions has inherent limitations depending
on which algorithm is performed. For example, if the dimension reduc-
tion algorithm is executed and clustering is applied only on the result
of the dimension-reduced spatialization, the clustering will likely be
far from optimal but the dimension reduction will be ideal. This could
result in a visualization in which, for example, the clusters are simply
assigned based on x-position in the projection.

Global and Local Algorithm Combinations: The global and local
pipeline describes the dimension reduction algorithm as responsible for
the global layout, while the clustering algorithm is responsible for local
reﬁnements and layout. These algorithms work together to create an
overall layout in which the dimension reduction algorithm effectively
lays out the clusters in a meaningful manner while the internal structure
of each cluster is maintained by the clustering algorithm. As such,
the ﬁne details of the projection will not be as accurate spatially as
the dimension reduction outcomes in the Independent Algorithms and
Dimension Reduction Preprocessing for Clustering pipelines, and the
clustering is still executing in part on the low-dimensional projection.
However, the layout should be relatively clean and understandable, and
the overall structure of the projection (e.g., the relative positions of the
clusters) will be meaningful.

Iterative, Alternating Algorithms: The ﬁnal pipeline in Fig. 2
includes both the dimension reduction algorithm and the clustering
algorithm working simultaneously and collaboratively to structure a
projection that is near-optimal for both representations. As such, this

Fig. 6. A selection of interfaces and tools that support Parametric In-
teraction or Observation-Level Interaction. The upper row shows PI
interfaces that include slider bars from Andromeda (PI view) [80], Star
Coordinates [53], and SpinBox widgets from STREAMIT [6]. The lower
row shows OLI interfaces from StarSPIRE [12], Paulovich et al. [73], and
Mamani et al. [66].

structure may produce the best visualizations with respect to the mean-
ing of the data, albeit at the cost of runtime.

A number of further design decisions can be incorporated into the
visualization. We have the option to emphasize the relative distance
between clusters more than the relative distance between pairs of ob-
servations. The visualization space is thus clusters of observations that
are obviously separated from each other in the space, possibly with
another iteration of the dimension reduction algorithm performed on
each individual cluster to generate a local layout. As yet another alter-
native, if the analyst is most interested in the clusters in the projection,
the emphasis could also be placed on the distance between each obser-
vation and the centroid of the cluster that it belongs to. Clusters could
also be artiﬁcially separated by a secondary execution of the dimension
reduction algorithm, but the superior layout determination is dependent
on the distance between each observation and a centroid.

We noted in Sect. 3.2 that it is not possible to combine all pairs
of dimension reduction and clustering algorithms. Likewise, it is not
possible to include all visual representations of dimension reduction
and clustering in the same visualization. For example, dendrograms are
often used to show hierarchical clustering; however, dendrograms are
not a useful visual encoding for dimension reduction algorithms.

5 INTERACTING WITH PROJECTIONS AND CLUSTERS
After displaying a visualization of dimension-reduced and clustered
data, the next step is to provide interactions to afford user exploration
through the dataset. Many studies have been performed and taxonomies
generated for interacting with high-dimensional data in a data analytics
context [7, 17, 88, 93].

In the context of exploring dimension-reduced data projections, two
primary methods exist for modifying an underlying distance function:
Parametric Interaction and Observation-Level Interaction. Surface-
level interactions are also often incorporated into visualization systems,
though these do not modify the underlying model. We begin this sec-
tion by discussing these interaction techniques and some representative
tools, as well as discussing interaction techniques that address cluster-
ing challenges. We follow this with a discussion of potential interaction
techniques that can support interaction with both dimension reduction
and clustering algorithms simultaneously.

5.1 Current Interaction Techniques
Parametric Interaction (PI) refers to manipulating parameters directly
in order to create a new projection and/or clustering assignment. This
presents a difﬁculty to novice or non-mathematically-inclined ana-
lysts, who may not understand how to update a set of weights to cre-
ate the dimension-reduced projection that they desire.
In contrast,
Observation-Level Interaction (OLI) refers to direct manipulation of
the observations, which in turn triggers a backsolving routine to learn
new parameters [34, 46, 59]. In this way, OLI hides the manipulation

Table 3. Sample interactions, organized by type of interaction (rows) and by the type of algorithm affected by the interaction (columns).

PI

OLI

Dimension Reduction

Rotate the projection

Reposition an observation external to clusters
or within a single cluster

Both
Modify the weight on a dimension
Select a different distance function
Reposition an observation into a
different cluster

Surface Measure a distance between observations

Details-on-demand to obtain attribute values

Clustering
Modify the max/min radius of a cluster
Change the number of clusters sought
Change cluster membership
Merge several clusters or split a cluster
Count the size of a cluster
Annotate a cluster

of the model from the analyst, allowing the analyst to perform more
natural direct manipulation interactions with the observations them-
selves. In Andromeda [80], PI allows analysts to modify weights on the
dimensions to modify the distance function directly by interacting with
sliders, while OLI uses an inverse MDS computation to interpret the
semantic meaning of the interaction in order to solve for those weights.
The upper row of Fig. 6 shows sample examples of PI from recent
visualization systems, complemented by some representative interac-
tions in the upper row of Table 3. Horizontal and vertical slider bars are
frequently utilized to enable analysts to interact with model parameters,
despite the fact that these model parameters have a variety of contexts.
Some of these sliders, such as those in Andromeda [80], include addi-
tional glyphs on the sliders to show the values of selected observations
on each dimension. In addition to slider bars, other techniques have
been utilized to support the manipulation of model parameters, such as
the SpinBox widgets of STREAMIT [6] and the transforming axes of
Star Coordinates [53]. PI techniques can also be extended to interact
with dimensions as well as observations, as shown by Turkay et al [86].
As seen in the lower row of Fig. 6 and discussed in Sect. 4, scatter
plots and node-link diagrams are the overwhelming favorite for display-
ing dimension-reduced projections, including those that support OLI.
Despite the ubiquity of these visual representations, individual OLI sys-
tems do display unique features and properties, such as supplementing
the scatterplot with additional views for context [16], supporting PI
in addition to OLI on the scatterplot [80], including local transforma-
tions [66], and focusing exclusively on textual data [12].

An additional consideration for OLI is the “With Respect to What”
problem detailed by Self et al. [80], which is the fundamental challenge
of using rigid algorithms to interpret the ambiguous meaning of an
interaction that involves dragging a node from one part of the display
to another. Andromeda solves this challenge by deﬁning a radius at
both the starting and ending point of the interaction, implying that
the analyst is moving an observation away from all other observations
within x pixels of the source and towards all other observations within
x pixels of the destination of the interaction, though the analyst is
afforded the ability to deselect observations that do not apply to the
interaction [80]. Points contained within this radius are highlighted in
the visual representation, allowing analysts to clearly see the interaction
targets that they are expressing within the projection [47].

In addition to Parametric and Observation-Level Interactions, the
introduction of clusters affords a variety of cluster-based interactions
that can support sensemaking. To begin, OLI can be applied to clusters,
including such interactions as moving clusters together and further
apart to reﬂect similarities and differences between clusters, as well as
transferring that information either to the weights on the clusters or the
weights on the nodes. We can also apply parameter tuning to clusters
at a global level, changing the number of clusters or the radius of all
clusters, or we can tune the parameters of individual clusters, creating
a collection of clusters with a variety of radii. The Vizster system, for
example, includes a PI-style slider bar to change the number of clusters
displayed in the X-ray view [44].

Clusters also introduce new cluster-speciﬁc interactions, such as clus-
ter merging, splitting, and creation [22,45], cluster annotation [54], and
hierarchies of clusters [70]. Performing any of these interactions can
communicate semantic information back to the system, re-executing the
pipeline that may or may not also include re-executing the dimension
reduction algorithm as a result of this user interaction.

5.2 Combined Interaction Techniques
The pipelines discussed in Sect. 3.3 naturally support the Parametric,
Observation-Level, surface-level, and clustering interactions discussed
in the previous subsection. Interactions in general can be designed for
each of these pipelines individually, but it is also useful to consider
interactions that can have meaning to both the dimension reduction
algorithm and the clustering algorithm simultaneously. To do so means
facing similar ambiguity that is addressed by the “With Respect to
What” problem and the issue of overloaded space.

For example, consider an analyst who is interacting with the clus-
tering assignment in a projection. Regardless of whether the analyst is
interacting with high-dimensional or low-dimensional clusters, drag-
ging an observation from one cluster to another is a natural interaction
to correct a misclassiﬁcation. However, the cause of that misclassiﬁca-
tion may be unknown to the analyst. Perhaps the analyst is interacting
with a system that implements the dimension reduction preprocess-
ing pipeline. If that is the case, then the analyst may be correcting
a misclassiﬁcation that results from the clustering operating on the
projected low-dimensional data. Thus, the goal of the system should
be to learn from that interaction, with the goal of getting closer to the
ideal high-dimensional clustering.

Alternatively, if the analyst is interacting with a system that imple-
ments clustering on the high-dimensional data, then performing the
same interaction is correcting for a case where the heuristic clustering
algorithm did not ﬁnd the optimal solution. The system can still learn
from this interaction to correct future clusterings, but the different cause
of the misclassiﬁcation should result in a different model update. These
two misclassiﬁcation corrections may be semantically identical to the
analyst who seeks to correct an error, but the underlying mechanics that
caused and must correct the misclassiﬁcation are different.

The same is true of an analyst interacting with observations in a
dimension-reduced projection. If an analyst drags an observation, it
may simply be that the analyst wishes to adjust the strength of the
relationship between two observations. However, adjusting the strength
of a relationship calculated on the high-dimensional data is inherently
different than adjusting the strength of a relationship calculated on clus-
ter algorithm output. And does the semantic meaning of the interaction
change if that drag interaction crosses a cluster boundary?

The introduction of explicitly-deﬁned clusters allows for a formal
target against which to judge interactions. When explicit clusters are
deﬁned, the analyst has four clearly deﬁned “with respect to what”
operations: (1) moving an observation into a cluster, (2) moving an
observation out of a cluster, (3) moving an observation from one cluster
into another, and (4) moving an observation without changing cluster
membership [90]. Each of these interactions can be designed to have
an effect on both the dimension reduction algorithm and the clustering
algorithm. Keeping an observation within a cluster, or dragging it from
one cluster into another, provides information to the clustering algo-
rithm that the classiﬁcation is either correct or incorrect. At the same
time, relocating an observation to a different position communicates
suggested distance information between the moved observation and
one or more additional observations in the projection. Each of these
algorithms can thus work to update the weight vector that then leads to
a projection and clustering update with this new information.

When mapping interactions to the pipelines summarized in Fig. 2,
choosing the primary target of the interaction is important even when
an interaction affects both algorithms. In the previous example, the

pipeline is implemented with the interaction primarily occurring on the
clusters, changing the cluster assignment of observations in order to up-
date the dimension reduction projection [90]. In contrast, “Be the Data”
also implements the same pipeline but with an interaction primarily
on the observation layout, using the dimension reduction algorithm to
update the clusters [20]. These two systems are both implementations
of the same pipeline, but place the interaction on different algorithms
to answer different questions about the high-dimensional data. Thus,
interactions can be considered independent of the pipelines.

A further open question to be addressed regards interactions on the
clusters themselves. If an analyst drags a cluster or interacts with it in
another manner, what adjustments should be made to the observations
and relationships within that cluster, as well as the relationships that
cross that cluster boundary?

6 DISCUSSION
Combining dimension reduction and clustering algorithms into the
same visualization system provides a number of opportunities for visu-
alization and interaction design. A system in which the two algorithm
classes cooperate for exploratory data analysis results in a relationship
in which the projection space (the outcome of the dimension reduction
algorithm) helps to explain the meaning of the clusters in the space,
while the clusters themselves help to explain the meaning of the space.
Including a machine learning aspect into a visualization system to
permit the dimension reduction and clustering algorithms to learn from
the actions of the analyst presents a number of additional challenges
for interaction design. In particular, the overloaded space metaphor
discussed in Sect. 3.1 causes challenges, as interactions within the
system must be mapped to at least one algorithm and may ambiguously
be mapped to both. For example, if an analyst drags and drops a
datapoint to reposition it in space, but the new coordinates did not
result in a cluster reassignment, should the clustering algorithm learn
nothing, or did the analyst provide some “fuzzy” clustering feedback
to the algorithm? A notion of iterative reﬁnement, in which the analyst
gradually trains the algorithms and offers corrections to mistakes at
each iteration is necessary in these cases. Such an iterative reﬁnement
process mimics Pirolli and Card’s Sensemaking Process [76].

Maintaining an analyst’s mental map during layout adjustments is a
well-studied problem [68], and is another factor that should be consid-
ered in visualization and interaction design for dimension reduction and
clustering systems. ForceSPIRE and Andromeda approach this mental
map challenge in different ways. ForceSPIRE, using a force-directed
layout, maintains the positions of nearly all observations during an
interaction, only altering the positions of observations near the interac-
tion [33]. In Andromeda, on the other hand, it is possible that all ob-
servations could move the entire distance across the space. The system
cognitively aids the analyst to understand such broad changes with an
animation slider, affording the analyst with the ability to incrementally
follow the post-interaction transition, as well as a layout stabilization
module to suppress the rotation invariant property of the Weighted
Multidimensional Scaling dimension reduction algorithm [80].

This work focuses on exploring the breadth of design options avail-
able to visualization researchers when combining dimension reduction
and clustering algorithms. Our goal with this work is to highlight
many of the decisions that exist in this design space, spurring further
exploration of this space with new tools. While we present a number of
design questions that must be addressed in creating such a visualiza-
tion system, we do not claim to answer any of these questions, as the
answers to many of them depend on the tasks and goals of the system.

7 CONCLUSION
The combination of dimension reduction and clustering algorithms rep-
resents an immense design space, including considerations of algorithm
selection and order, tasks, visualization, and interaction. In this paper,
we have provided a survey of each of these considerations, describing
existing research and discussing relevant design decisions applicable to
current and future systems (summarized in Table 4).

Returning to our discussion of the “Be the Data” interaction ﬁrst
addressed in Sect 3, we saw a smooth transition from discrete to con-

Table 4. A summary of the design challenges and questions discussed
throughout the paper regarding the combination of dimension reduction
and clustering algorithms.

Section

2.1 & 2.2

3.2

3.3

4.1

4.2

5.2

Design Decision
In general, clustering places an emphasis on re-
lationships within and between clusters.
In con-
trast, dimension reduction emphasizes observation-
to-observation relationships. Which of these tasks is
the primary goal of the analyst?
What properties of the data is the visualization seek-
ing to highlight? Which properties of the data are
the system and analyst trying to discover? Should
the primary goal of the visualization system be em-
phasizing observation relationships, clusters of ob-
servations, or both? Should the dimension reduction
and clustering algorithms use the same distance func-
tion (if possible), or should each algorithm use an
independent method of measuring similarity?
Which order and interaction of dimension reduction
and clustering algorithms best models the task that
the visualization system is addressing?
How can we encode distances and cluster member-
ship information when both algorithms are present?
As the dimension reduction and clustering algo-
rithms are competing in the same visualization, what
features should be emphasized in the visualization
to best address the problem?
Should interactions be designed independently for
the dimension reduction and clustering algorithms,
or should a given interaction affect both algorithms?

tinuous thinking. The students initially formed the clusters of Edible
and Inedible animals and then positioned those clusters in space, ini-
tially mimicking the cluster preprocessing pipeline. The transition from
this projection into a spectrum of Edibility amounts to iterative and
interactive reﬁnement of those initial clusters into a broader projection.
Without the interaction component, the pipelines could not successfully
model this student behavior.

A useful future direction for research would be a cognitive study,
further attempting to understand how analysts cognitively combine
the ideas of dimension reduction and clustering in both virtual and
non-virtual spaces. Such a study can further inform the pipelines,
visualizations, and interactions presented in this work.

ACKNOWLEDGMENTS
This research was supported by NSF Grants IIS-1447416, IIS-1633363,
and DGE-1545362, as well as by a grant from General Dynamics
Mission Systems. The authors would like to recognize the role of
comments from reviewers and discussions with InfoVis Lab @ VT
research group members in improving this work.

REFERENCES
[1] J. Abello, F. V. Ham, and N. Krishnan. Ask-graphview: A large scale graph
visualization system. IEEE Transactions on Visualization and Computer
Graphics, 12(5):669–676, Sept 2006. doi: 10.1109/TVCG.2006.120

[2] C. C. Aggarwal, A. Hinneburg, and D. A. Keim. On the Surprising
Behavior of Distance Metrics in High Dimensional Space, pp. 420–434.
Springer Berlin Heidelberg, Berlin, Heidelberg, 2001. doi: 10.1007/3-540
-44503-X 27

[3] M. N. Ahmed, S. M. Yamany, N. Mohamed, A. A. Farag, and T. Moriarty.
A modiﬁed fuzzy c-means algorithm for bias ﬁeld estimation and segmen-
tation of mri data. IEEE Transactions on Medical Imaging, 21(3):193–199,
March 2002. doi: 10.1109/42.996338

[4] M. S. Aldenderfer and R. K. Blashﬁeld. Cluster analysis. SAGE publica-

tions, Beverly Hills, USA, 1984.

[5] B. Alper, N. Riche, G. Ramos, and M. Czerwinski. Design study of linesets,
a novel set visualization technique. IEEE Transactions on Visualization

and Computer Graphics, 17(12):2259–2267, Dec 2011. doi: 10.1109/
TVCG.2011.186

[6] J. Alsakran, Y. Chen, Y. Zhao, J. Yang, and D. Luo. Streamit: Dynamic
visualization and interactive exploration of text streams. In 2011 IEEE
Paciﬁc Visualization Symposium, pp. 131–138, March 2011. doi: 10.1109/
PACIFICVIS.2011.5742382

[7] R. Amar, J. Eagan, and J. Stasko. Low-level components of analytic
activity in information visualization. In IEEE Symposium on Information
Visualization, 2005. INFOVIS 2005., pp. 111–117, Oct 2005. doi: 10.
1109/INFVIS.2005.1532136

[8] C. Andrews, A. Endert, and C. North. Space to think: Large high-
resolution displays for sensemaking. In Proceedings of the SIGCHI Con-
ference on Human Factors in Computing Systems, CHI ’10, pp. 55–64.
ACM, New York, NY, USA, 2010. doi: 10.1145/1753326.1753336

[9] J. C. Bezdek. Pattern Recognition with Fuzzy Objective Function Algo-

rithms. Kluwer Academic Publishers, Norwell, MA, USA, 1981.

[10] D. M. Blei and M. I. Jordan. Variational inference for dirichlet process

mixtures. Bayesian Analysis, 1:121–144, 2005.

[11] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. Journal

of machine Learning research, 3(Jan):993–1022, 2003.

[12] L. Bradel, C. North, L. House, and S. Leman. Multi-model semantic
interaction for text analytics. In 2014 IEEE Conference on Visual Analytics
Science and Technology (VAST), pp. 163–172, Oct 2014. doi: 10.1109/
VAST.2014.7042492

[13] P. S. Bradley, U. Fayyad, and C. Reina. Scaling clustering algorithms to
large databases. In Proceedings of the Fourth International Conference on
Knowledge Discovery and Data Mining, KDD’98, pp. 9–15. AAAI Press,
1998.

[14] M. Brehmer and T. Munzner. A multi-level typology of abstract visualiza-
tion tasks. IEEE Transactions on Visualization and Computer Graphics,
19(12):2376–2385, Dec 2013. doi: 10.1109/TVCG.2013.124

[15] M. Brehmer, M. Sedlmair, S. Ingram, and T. Munzner. Visualizing
dimensionally-reduced data: Interviews with analysts and a character-
ization of task sequences. In Proceedings of the Fifth Workshop on Beyond
Time and Errors: Novel Evaluation Methods for Visualization, BELIV
’14, pp. 1–8. ACM, New York, NY, USA, 2014. doi: 10.1145/2669557.
2669559

[16] E. T. Brown, J. Liu, C. E. Brodley, and R. Chang. Dis-function: Learning
In 2012 IEEE Conference on Visual
distance functions interactively.
Analytics Science and Technology (VAST), pp. 83–92, Oct 2012. doi: 10.
1109/VAST.2012.6400486

[17] A. Buja, D. Cook, and D. F. Swayne. Interactive high-dimensional data
visualization. Journal of Computational and Graphical Statistics, 5(1):78–
99, 1996. doi: 10.1080/10618600.1996.10474696

[18] J. D. Carroll and J.-J. Chang. Analysis of individual differences in mul-
tidimensional scaling via an n-way generalization of “eckart-young” de-
composition. Psychometrika, 35(3):283–319, 1970.

[19] H. Chen, W. Chen, H. Mei, Z. Liu, K. Zhou, W. Chen, W. Gu, and K. L.
Ma. Visual abstraction and exploration of multi-class scatterplots. IEEE
Transactions on Visualization and Computer Graphics, 20(12):1683–1692,
Dec 2014. doi: 10.1109/TVCG.2014.2346594

[20] X. Chen, J. Z. Self, L. House, and C. North. Be the data: A new approach
In IEEE Virtual Reality 2016 Workshop on

for immersive analytics.
Immersive Analytics, 03/2016.

[21] J. Choo, S. Bohn, and H. Park. Two-stage framework for visualization
of clustered high dimensional data. In 2009 IEEE Symposium on Visual
Analytics Science and Technology, pp. 67–74, Oct 2009. doi: 10.1109/
VAST.2009.5332629

[22] J. Choo, C. Lee, C. K. Reddy, and H. Park. Utopian: User-driven topic
modeling based on interactive nonnegative matrix factorization. IEEE
Transactions on Visualization and Computer Graphics, 19(12):1992–2001,
Dec 2013. doi: 10.1109/TVCG.2013.212

[23] J. Chuang and D. J. Hsu. Human-centered interactive clustering for data
analysis. Conference on Neural Information Processing Systems (NIPS).
Workshop on Human-Propelled Machine Learning, 2014.

[24] C. Collins, G. Penn, and S. Carpendale. Bubble sets: Revealing set
relations with isocontours over existing visualizations. IEEE Transactions
on Visualization and Computer Graphics, 15(6):1009–1016, Nov 2009.
doi: 10.1109/TVCG.2009.122

[25] R. Cordeiro de Amorim and P. Komisarczuk. On Initializations for the
Minkowski Weighted K-Means, pp. 45–55. Springer Berlin Heidelberg,
Berlin, Heidelberg, 2012. doi: 10.1007/978-3-642-34156-4 6

[26] I. S. Dhillon and D. S. Modha. Concept decompositions for large sparse

text data using clustering. Machine Learning, 42(1):143–175, 2001. doi:
10.1023/A:1007612920971

[27] C. Ding and X. He. K-means clustering via principal component analysis.
In Proceedings of the Twenty-ﬁrst International Conference on Machine
Learning, ICML ’04, pp. 29–. ACM, New York, NY, USA, 2004. doi: 10.
1145/1015330.1015408

[28] C. Ding and T. Li. Adaptive dimension reduction using discriminant
analysis and k-means clustering. In Proceedings of the 24th International
Conference on Machine Learning, ICML ’07, pp. 521–528. ACM, New
York, NY, USA, 2007. doi: 10.1145/1273496.1273562

[29] D. L. Donoho. High-dimensional data analysis: The curses and blessings
of dimensionality. In AMS Conference on Math Challenges of the 21st
Century, 2000.

[30] J. C. Dunn. A fuzzy relative of the isodata process and its use in detecting
compact well-separated clusters. Journal of Cybernetics, 3(3):32–57, 1973.
doi: 10.1080/01969727308546046

[31] T. Dwyer, Y. Koren, and K. Marriott. Ipsep-cola: An incremental pro-
cedure for separation constraint layout of graphs. IEEE Transactions on
Visualization and Computer Graphics, 12(5):821–828, Sept 2006. doi: 10.
1109/TVCG.2006.156

[32] C. F. Eick, N. Zeidat, and Z. Zhao. Supervised clustering - algorithms and
beneﬁts. In 16th IEEE International Conference on Tools with Artiﬁcial
Intelligence, pp. 774–776, Nov 2004. doi: 10.1109/ICTAI.2004.111

[33] A. Endert, S. Fox, D. Maiti, S. Leman, and C. North. The semantics of
clustering: Analysis of user-generated spatializations of text documents.
In Proceedings of the International Working Conference on Advanced
Visual Interfaces, AVI ’12, pp. 555–562. ACM, New York, NY, USA,
2012. doi: 10.1145/2254556.2254660

[34] A. Endert, C. Han, D. Maiti, L. House, S. Leman, and C. North.
Observation-level interaction with statistical models for visual analyt-
ics. In 2011 IEEE Conference on Visual Analytics Science and Technology
(VAST), pp. 121–130, Oct 2011. doi: 10.1109/VAST.2011.6102449

[35] A. Endert, M. S. Hossain, N. Ramakrishnan, C. North, P. Fiaux, and
C. Andrews. The human is the loop: new directions for visual analytics.
Journal of Intelligent Information Systems, 43(3):411–435, 2014. doi: 10.
1007/s10844-014-0304-9

[36] V. Estivill-Castro. Why so many clustering algorithms: A position paper.
SIGKDD Explor. Newsl., 4(1):65–75, June 2002. doi: 10.1145/568574.
568575

[37] U. M. Fayyad, A. Wierse, and G. G. Grinstein. Information visualization

in data mining and knowledge discovery. Morgan Kaufmann, 2002.

[38] I. K. Fodor. A Survey of Dimension Reduction Techniques. May 2002. doi:

10.2172/15002155

[39] S. L. France and J. D. Carroll. Two-way multidimensional scaling: A
review. IEEE Transactions on Systems, Man, and Cybernetics, Part C
(Applications and Reviews), 41(5):644–661, Sept 2011. doi: 10.1109/
TSMCC.2010.2078502

[40] J. H. Friedman and J. W. Tukey. A projection pursuit algorithm for
exploratory data analysis. IEEE Transactions on Computers, C-23(9):881–
890, Sept 1974. doi: 10.1109/T-C.1974.224051

[41] E. R. Gansner, Y. Hu, and S. Kobourov. Gmap: Visualizing graphs
and clusters as maps. In 2010 IEEE Paciﬁc Visualization Symposium
(PaciﬁcVis), pp. 201–208, March 2010. doi: 10.1109/PACIFICVIS.2010.
5429590

[42] I. Guyon and A. Elisseeff. An introduction to variable and feature selection.

J. Mach. Learn. Res., 3:1157–1182, Mar. 2003.
[43] H. H. Harman. Modern factor analysis. 1960.
[44] J. Heer and D. Boyd. Vizster: visualizing online social networks. In
IEEE Symposium on Information Visualization, 2005. INFOVIS 2005., pp.
32–39, Oct 2005. doi: 10.1109/INFVIS.2005.1532126

[45] C. Heine and G. Scheuermann. Manual clustering reﬁnement using inter-
action with blobs. In Proceedings of the 9th Joint Eurographics / IEEE
VGTC Conference on Visualization, EUROVIS’07, pp. 59–66. Eurograph-
ics Association, Aire-la-Ville, Switzerland, Switzerland, 2007. doi: 10.
2312/VisSym/EuroVis07/059-066

[46] L. House, S. Leman, and C. Han. Bayesian visual analytics: Bava. Sta-
tistical Analysis and Data Mining, 8(1):1–13, 2015. doi: 10.1002/sam.
11253

[47] X. Hu, L. Bradel, D. Maiti, L. House, C. North, and S. Leman. Semantics
of directly manipulating spatializations. IEEE Transactions on Visual-
ization and Computer Graphics, 19(12):2052–2059, Dec 2013. doi: 10.
1109/TVCG.2013.188

[48] J. Z. Huang, M. K. Ng, H. Rong, and Z. Li. Automated variable weighting

in k-means type clustering. IEEE Transactions on Pattern Analysis and
Machine Intelligence, 27(5):657–668, May 2005. doi: 10.1109/TPAMI.
2005.95

[49] A. Hyv¨arinen, J. Karhunen, and E. Oja. Independent component analysis,

vol. 46. John Wiley & Sons, 2004.

[50] S. Ingram, T. Munzner, and M. Olano. Glimmer: Multilevel mds on
the gpu. IEEE Transactions on Visualization and Computer Graphics,
15(2):249–261, March 2009. doi: 10.1109/TVCG.2008.85

[51] R. Jianu, A. Rusu, Y. Hu, and D. Taggart. How to display group infor-
mation on node-link diagrams: An evaluation. IEEE Transactions on
Visualization and Computer Graphics, 20(11):1530–1541, Nov 2014. doi:
10.1109/TVCG.2014.2315995

[52] P. Joia, F. Petronetto, and L. G. Nonato. Uncovering representative groups
in multidimensional projections. In Proceedings of the 2015 Eurographics
Conference on Visualization, EuroVis ’15, pp. 281–290. Eurographics
Association, Aire-la-Ville, Switzerland, Switzerland, 2015. doi: 10.1111/
cgf.12640

[53] E. Kandogan. Star coordinate: A multi-dimensional visualization tech-
nique with uniform treatment of dimensions. In Proceedings of the IEEE
Information Visualization Symposium, vol. 650, p. 22.

[54] E. Kandogan. Just-in-time annotation of clusters, outliers, and trends
in point-based data visualizations. In 2012 IEEE Conference on Visual
Analytics Science and Technology (VAST), pp. 73–82, Oct 2012. doi: 10.
1109/VAST.2012.6400487

[55] T. Kohonen. The self-organizing map. Proceedings of the IEEE,

78(9):1464–1480, Sep 1990. doi: 10.1109/5.58325

[56] H.-P. Kriegel, P. Kr¨oger, and A. Zimek. Clustering high-dimensional data:
A survey on subspace clustering, pattern-based clustering, and correlation
clustering. ACM Trans. Knowl. Discov. Data, 3(1):1:1–1:58, Mar. 2009.
doi: 10.1145/1497577.1497578

[57] H. Lee, J. Kihm, J. Choo, J. Stasko, and H. Park.

ivisclustering: An
interactive visual document clustering via topic modeling. Computer
Graphics Forum, 31(3pt3):1155–1164, 2012. doi: 10.1111/j.1467-8659.
2012.03108.x

[58] J. A. Lee and M. Verleysen. Nonlinear dimensionality reduction. Springer

Science & Business Media, 2007.

[59] S. C. Leman, L. House, D. Maiti, A. Endert, and C. North. Visual to

276, 1953. doi: 10.1007/BF02289263

[72] D. Niu, J. G. Dy, and M. I. Jordan. Dimensionality reduction for spectral
clustering. In Proceedings of the 14th International Conference Artiﬁcial
Intelligence and Statistics, AISTATS ’11, pp. 552–560. ACM, New York,
NY, USA, 2011.

[73] F. Paulovich, D. Eler, J. Poco, C. Botha, R. Minghim, and L. Nonato.
Piecewise laplacian-based projection for interactive data exploration and
organization. Computer Graphics Forum, 30(3):1091–1100, 2011. doi: 10
.1111/j.1467-8659.2011.01958.x

[74] K. Pearson. Principal components analysis. The London, Edinburgh and

Dublin Philosophical Magazine and Journal, 6(2):566, 1901.

[75] D. Pelleg, A. W. Moore, et al. X-means: Extending k-means with efﬁcient
estimation of the number of clusters. In ICML, vol. 1, pp. 727–734, 2000.
[76] P. Pirolli and S. Card. The sensemaking process and leverage points for an-
alyst technology as identiﬁed through cognitive task analysis. Proceedings
of International Conference on Intelligence Analysis, pp. 2–4, 2005.

[77] B. Rieck and H. Leitte. Persistent homology for the evaluation of dimen-
sionality reduction schemes. Computer Graphics Forum, 34(3):431–440,
2015. doi: 10.1111/cgf.12655

[78] D. Ro and H. Pe. Pattern classiﬁcation and scene analysis. John Wiley &

Sons, New York, USA, 1973.

[79] B. Saket, P. Simonetto, S. Kobourov, and K. Brner. Node, node-link,
and node-link-group diagrams: An evaluation. IEEE Transactions on
Visualization and Computer Graphics, 20(12):2231–2240, Dec 2014. doi:
10.1109/TVCG.2014.2346422

[80] J. Z. Self, R. K. Vinayagam, J. T. Fry, and C. North. Bridging the gap
between user intention and model parameters for human-in-the-loop data
analytics. In Proceedings of the Workshop on Human-In-the-Loop Data
Analytics, HILDA ’16, pp. 3:1–3:6. ACM, New York, NY, USA, 2016.
doi: 10.1145/2939502.2939505

[81] P.-N. Tan, M. Steinbach, and V. Kumar. Data mining cluster analysis:
basic concepts and algorithms. In Introduction to data mining, chap. 8.
Pearson Education India, 2013.

[82] J. B. Tenenbaum, V. d. Silva, and J. C. Langford. A global geometric frame-
work for nonlinear dimensionality reduction. Science, 290(5500):2319–
2323, 2000. doi: 10.1126/science.290.5500.2319

[83] R. L. Thorndike. Who belongs in the family? Psychometrika, 18(4):267–

[84] M. E. Tipping and C. M. Bishop. Probabilistic principal component
analysis. Journal of the Royal Statistical Society: Series B (Statistical
Methodology), 61(3):611–622, 1999.

[85] W. S. Torgerson. Theory and methods of scaling. 1958.
[86] C. Turkay, P. Filzmoser, and H. Hauser. Brushing dimensions - a dual
visual analysis model for high-dimensional data. IEEE Transactions on
Visualization and Computer Graphics, 17(12):2591–2599, Dec 2011. doi:
10.1109/TVCG.2011.178

[87] F. Valafar. Pattern recognition techniques in microarray data analysis.
Annals of the New York Academy of Sciences, 980(1):41–64, 2002. doi: 10
.1111/j.1749-6632.2002.tb04888.x

[88] T. von Landesberger, S. Fiebig, S. Bremm, A. Kuijper, and D. W. Fellner.
Interaction Taxonomy for Tracking of User Actions in Visual Analytics
Applications, pp. 653–670. Springer New York, New York, NY, 2014. doi:
10.1007/978-1-4614-7485-2 26

[89] K. Wagstaff, C. Cardie, S. Rogers, S. Schr¨odl, et al. Constrained k-means
clustering with background knowledge. In Proceedings of the Eighteenth
International Conference on Machine Learning, vol. 1, pp. 577–584, 2001.
[90] J. Wenskovitch and C. North. Observation-level interaction with clustering
and dimension reduction algorithms. In Proceedings of the 2nd Workshop
on Human-In-the-Loop Data Analytics, HILDA’17, pp. 14:1–14:6. ACM,
New York, NY, USA, 2017. doi: 10.1145/3077257.3077259

[91] A. Wism¨uller, M. Verleysen, M. Aupetit, and J. A. Lee. Recent advances
in nonlinear dimensionality reduction, manifold and topological learning.
In ESANN, 2010.

[92] R. Xu and D. Wunsch. Survey of clustering algorithms. IEEE Transactions
on Neural Networks, 16(3):645–678, May 2005. doi: 10.1109/TNN.2005.
845141

[93] J. S. Yi, Y. a. Kang, and J. Stasko. Toward a deeper understanding of the
role of interaction in information visualization. IEEE Transactions on
Visualization and Computer Graphics, 13(6):1224–1231, Nov 2007. doi:
10.1109/TVCG.2007.70515

[94] H. Zha, X. He, C. Ding, M. Gu, and H. D. Simon. Spectral relaxation
for k-means clustering. In Advances in Neural Information Processing
Systems, pp. 1057–1064, 2002.

parametric interaction (v2pi). PloS one, 8(3), 2013.

[60] M. Levandowsky and D. Winter. Distance between sets. Nature,

234(5323):34–35, 1971.

[61] S. Liu, D. Maljovec, B. Wang, P. T. Bremer, and V. Pascucci. Visualizing
high-dimensional data: Advances in the past decade. IEEE Transactions
on Visualization and Computer Graphics, 23(3):1249–1268, March 2017.
doi: 10.1109/TVCG.2016.2640960

[62] S. Liu, B. Wang, P.-T. Bremer, and V. Pascucci. Distortion-guided
structure-driven interactive exploration of high-dimensional data. Com-
puter Graphics Forum, 33(3):101–110, 2014. doi: 10.1111/cgf.12366

[63] S. Liu, M. X. Zhou, S. Pan, W. Qian, W. Cai, and X. Lian. Interactive,
topic-based visual text summarization and analysis. In Proceedings of
the 18th ACM Conference on Information and Knowledge Management,
CIKM ’09, pp. 543–552. ACM, New York, NY, USA, 2009. doi: 10.
1145/1645953.1646023

[64] S. Lloyd. Least squares quantization in pcm.

IEEE Transactions on
Information Theory, 28(2):129–137, Mar 1982. doi: 10.1109/TIT.1982.
1056489

[65] L. v. d. Maaten and G. Hinton. Visualizing data using t-sne. J. Mach.

Learn. Res., 9:2579–2605, Sept. 2008.

[66] G. M. H. Mamani, F. M. Fatore, L. G. Nonato, and F. V. Paulovich.
User-driven feature space transformation. Computer Graphics Forum,
32(3pt3):291–299, 2013. doi: 10.1111/cgf.12116

[67] A. Mayorga and M. Gleicher. Splatterplots: Overcoming overdraw in
scatter plots. IEEE Transactions on Visualization and Computer Graphics,
19(9):1526–1538, Sept 2013. doi: 10.1109/TVCG.2013.65

[68] K. Misue, P. Eades, W. Lai, and K. Sugiyama. Layout adjustment and the
mental map. Journal of Visual Languages & Computing, 6(2):183 – 210,
1995. doi: 10.1006/jvlc.1995.1010

[69] T. Munzner. Visualization Analysis and Design. CRC Press, 2014.
[70] E. J. Nam, Y. Han, K. Mueller, A. Zelenyuk, and D. Imre. Clustersculptor:
A visual analytics tool for high-dimensional data. In 2007 IEEE Sympo-
sium on Visual Analytics Science and Technology, pp. 75–82, Oct 2007.
doi: 10.1109/VAST.2007.4388999

[71] A. Y. Ng, M. I. Jordan, Y. Weiss, et al. On spectral clustering: Analysis

and an algorithm. In NIPS, vol. 14, pp. 849–856, 2001.

","{""pos"":{""0"":1,""1"":2,""2"":3,""3"":4,""4"":5,""5"":6,""6"":7},""3"":{""0"":""j"",""1"":""c*"",""2"":""d*"",""3"":""pp"",""4"":""m"",""5"":""al*"",""6"":""et*""},""2"":{""0"":""ieee*"",""1"":""tvcg*"",""2"":""york"",""3"":""usa*"",""4"":""acm*"",""5"":""oli*"",""6"":""ny""},""0"":{""0"":""1109"",""1"":""2014*"",""2"":""2011*"",""3"":""2005"",""4"":""2013*"",""5"":""1145"",""6"":""2012*""},""1"":{""0"":""10"",""1"":""a*"",""2"":""different*"",""3"":""similar*"",""4"":""local*"",""5"":""performed"",""6"":""execute""},""5"":{""0"":""observations"",""1"":""projection"",""2"":""interaction*"",""3"":""analyst"",""4"":""analysis*"",""5"":""visual"",""6"":""interactions*""},""6"":{""0"":""clustering*"",""1"":""algorithms"",""2"":""clusters*"",""3"":""algorithm"",""4"":""cluster*"",""5"":""dataset*"",""6"":""pipelines""},""4"":{""0"":""dimension*"",""1"":""dimensional*"",""2"":""space*"",""3"":""distance*"",""4"":""dimensions*"",""5"":""row*"",""6"":""manifolds*""}}",2018,{},False,False,journalArticle,False,5UJ67Q46,[],self.user,"{""Unnamed: 0"":{""0"":0,""1"":1,""2"":2,""3"":3,""4"":4,""5"":5,""6"":6,""7"":7,""8"":8,""9"":9,""10"":10,""11"":11,""12"":12,""13"":13,""14"":14,""15"":15,""16"":16,""17"":17,""18"":18,""19"":19,""20"":20,""21"":21,""22"":22,""23"":23,""24"":24,""25"":25,""26"":26,""27"":27,""28"":28,""29"":29,""30"":30,""31"":31,""32"":32,""33"":33,""34"":34,""35"":35,""36"":36,""37"":37,""38"":38,""39"":39,""40"":40,""41"":41,""42"":42,""43"":43,""44"":44,""45"":45,""46"":46,""47"":47,""48"":48,""49"":49,""50"":50,""51"":51,""52"":52,""53"":53,""54"":54,""55"":55,""56"":56,""57"":57,""58"":58,""59"":59,""60"":60,""61"":61,""62"":62,""63"":63,""64"":64,""65"":65,""66"":66,""67"":67,""68"":68,""69"":69,""70"":70,""71"":71,""72"":72,""73"":73,""74"":74,""75"":75,""76"":76,""77"":77,""78"":78,""79"":79,""80"":80,""81"":81,""82"":82,""83"":83,""84"":84,""85"":85,""86"":86,""87"":87,""88"":88,""89"":89,""90"":90,""91"":91,""92"":92,""93"":93,""94"":94,""95"":95,""96"":96,""97"":97,""98"":98,""99"":99,""100"":100,""101"":101,""102"":102,""103"":103,""104"":104,""105"":105,""106"":106,""107"":107,""108"":108,""109"":109,""110"":110,""111"":111,""112"":112,""113"":113,""114"":114,""115"":115,""116"":116},""C"":{""0"":10.7345538207,""1"":24.5363034803,""2"":15.1498615914,""3"":14.8261751356,""4"":15.0316371257,""5"":21.2694925291,""6"":20.4355930939,""7"":15.0054509007,""8"":19.9338360463,""9"":5.7545173652,""10"":43.3052745668,""11"":57.456490473,""12"":5.689821384,""13"":9.3923775262,""14"":12.3142127744,""15"":29.4773464175,""16"":8.4679015795,""17"":13.8714723871,""18"":15.0817254778,""19"":7.8430815665,""20"":6.568513114,""21"":26.7499467021,""22"":8.2403602945,""23"":5.9955944504,""24"":10.0096013941,""25"":28.2571261221,""26"":10.1653247259,""27"":14.296205642,""28"":8.1717475578,""29"":5.2953769809,""30"":26.2882841219,""31"":14.482967019,""32"":6.6052356583,""33"":6.9033394509,""34"":6.7362616904,""35"":19.8386387172,""36"":6.4358494932,""37"":21.646243618,""38"":6.1518010697,""39"":8.8748098557,""40"":9.7518416714,""41"":10.0957806024,""42"":10.3951978933,""43"":8.5105406538,""44"":17.3510928977,""45"":9.0854394373,""46"":16.3805547008,""47"":10.0846172823,""48"":7.3775352863,""49"":10.7516956836,""50"":10.5498700435,""51"":15.8549178203,""52"":16.7825671764,""53"":9.3901790546,""54"":14.2559189084,""55"":14.3518053487,""56"":6.3000173004,""57"":7.8505698467,""58"":12.9734969055,""59"":13.7901303964,""60"":13.2593050919,""61"":8.0026383038,""62"":15.0089561615,""63"":11.2677821992,""64"":9.6584344246,""65"":5.2115577999,""66"":5.1413260606,""67"":14.1157081058,""68"":5.5994220436,""69"":9.1159538896,""70"":9.4196620332,""71"":5.6286580289,""72"":5.2846745145,""73"":7.4198291686,""74"":11.2215510014,""75"":14.8430098746,""76"":8.1056538036,""77"":8.0443943937,""78"":8.0162993527,""79"":12.0356223922,""80"":8.8180803983,""81"":5.2202691393,""82"":6.6247747665,""83"":5.3291804552,""84"":12.9567416929,""85"":5.1918382321,""86"":11.1305830655,""87"":5.5125845492,""88"":7.2620162449,""89"":7.3022408986,""90"":7.3381624688,""91"":7.393057432,""92"":5.1767441377,""93"":5.7239324369,""94"":8.5285906124,""95"":10.4024412164,""96"":5.445167818,""97"":5.9946496603,""98"":6.3116231495,""99"":6.3045703815,""100"":6.5387940757,""101"":6.0944630603,""102"":8.4897457593,""103"":8.4865004038,""104"":7.5643571986,""105"":5.5228643268,""106"":8.0216437861,""107"":8.0056439615,""108"":8.3252074336,""109"":6.0537832929,""110"":6.6503145221,""111"":6.5591570337,""112"":6.2151681483,""113"":5.8914059336,""114"":5.1173495733,""115"":6.1158411609,""116"":5.3292744986},""count"":{""0"":346,""1"":332,""2"":300,""3"":252,""4"":232,""5"":216,""6"":182,""7"":142,""8"":136,""9"":134,""10"":132,""11"":126,""12"":110,""13"":108,""14"":102,""15"":88,""16"":86,""17"":86,""18"":84,""19"":82,""20"":78,""21"":78,""22"":78,""23"":76,""24"":70,""25"":66,""26"":64,""27"":64,""28"":62,""29"":62,""30"":62,""31"":60,""32"":56,""33"":56,""34"":56,""35"":56,""36"":54,""37"":52,""38"":48,""39"":48,""40"":44,""41"":44,""42"":42,""43"":42,""44"":42,""45"":40,""46"":40,""47"":34,""48"":34,""49"":34,""50"":34,""51"":34,""52"":34,""53"":32,""54"":32,""55"":32,""56"":30,""57"":30,""58"":30,""59"":28,""60"":28,""61"":26,""62"":26,""63"":26,""64"":24,""65"":22,""66"":22,""67"":22,""68"":22,""69"":22,""70"":22,""71"":20,""72"":20,""73"":20,""74"":20,""75"":20,""76"":20,""77"":20,""78"":20,""79"":20,""80"":20,""81"":18,""82"":18,""83"":18,""84"":18,""85"":16,""86"":16,""87"":16,""88"":16,""89"":16,""90"":16,""91"":14,""92"":14,""93"":14,""94"":14,""95"":12,""96"":12,""97"":12,""98"":12,""99"":12,""100"":12,""101"":12,""102"":10,""103"":10,""104"":10,""105"":10,""106"":10,""107"":10,""108"":10,""109"":10,""110"":8,""111"":8,""112"":8,""113"":8,""114"":8,""115"":8,""116"":8},""sigma_nor"":{""0"":1.5626678244,""1"":2.3176845078,""2"":1.852410896,""3"":1.9066422684,""4"":1.956200818,""5"":2.4025440649,""6"":2.4609587933,""7"":2.202060243,""8"":2.6326807569,""9"":1.4666643752,""10"":4.609484315,""11"":5.8972468176,""12"":1.5041360736,""13"":1.8479840795,""14"":2.1452802498,""15"":3.9525215877,""16"":1.8446745387,""17"":2.3946837293,""18"":2.5338439395,""19"":1.797561318,""20"":1.6795945169,""21"":3.8259529303,""22"":1.8574006795,""23"":1.6256153107,""24"":2.0959566231,""25"":4.2140962414,""26"":2.1570680101,""27"":2.6366432637,""28"":1.9381628439,""29"":1.5995585252,""30"":4.07082877,""31"":2.7048809891,""32"":1.7863775313,""33"":1.8230555506,""34"":1.8024986792,""35"":3.4145856427,""36"":1.777072661,""37"":3.7211118351,""38"":1.7777966057,""39"":2.1356274877,""40"":2.2958341675,""41"":2.3427127433,""42"":2.4096273525,""43"":2.1477364025,""44"":3.3762147578,""45"":2.2515783636,""46"":3.2859039952,""47"":2.4842054504,""48"":2.0742857145,""49"":2.5852177591,""50"":2.5546563231,""51"":3.3579728783,""52"":3.4984421288,""53"":2.4110354007,""54"":3.1657495692,""55"":3.1806223033,""56"":1.9537889684,""57"":2.2004433149,""58"":3.015373598,""59"":3.2011053847,""60"":3.1143869213,""61"":2.2890829999,""62"":3.4663154033,""63"":2.8377068668,""64"":2.6119495612,""65"":1.865998144,""66"":1.8534489429,""67"":3.4570163025,""68"":1.9353027979,""69"":2.5636464162,""70"":2.6179138258,""71"":1.9689297482,""72"":1.9053504528,""73"":2.2999961919,""74"":3.0026775268,""75"":3.672040428,""76"":2.4267587988,""77"":2.4154360756,""78"":2.410243202,""79"":3.1531442882,""80"":2.5584383094,""81"":1.9215654553,""82"":2.1907519385,""83"":1.9424393155,""84"":3.404331917,""85"":1.9464528436,""86"":3.1299929612,""87"":2.0103747908,""88"":2.3590212899,""89"":2.367037713,""90"":2.374196569,""91"":2.4369311165,""92"":1.9761852211,""93"":2.0899393386,""94"":2.6729953287,""95"":3.1486902207,""96"":2.0697475261,""97"":2.1893413778,""98"":2.2583301551,""99"":2.2567951313,""100"":2.3077735469,""101"":2.211065606,""102"":2.8061338801,""103"":2.805391326,""104"":2.5944002155,""105"":2.1272961413,""106"":2.6990297399,""107"":2.6953688976,""108"":2.7684866645,""109"":2.2487731328,""110"":2.4399967546,""111"":2.4179738259,""112"":2.3348688302,""113"":2.2566504384,""114"":2.0696445402,""115"":2.3108722152,""116"":2.120843927},""vocab_index"":{""0"":0,""1"":1,""2"":2,""3"":3,""4"":4,""5"":5,""6"":7,""7"":8,""8"":9,""9"":10,""10"":11,""11"":12,""12"":13,""13"":14,""14"":15,""15"":18,""16"":19,""17"":20,""18"":21,""19"":22,""20"":23,""21"":24,""22"":25,""23"":26,""24"":29,""25"":30,""26"":32,""27"":33,""28"":34,""29"":37,""30"":38,""31"":39,""32"":40,""33"":41,""34"":42,""35"":43,""36"":45,""37"":47,""38"":48,""39"":49,""40"":50,""41"":51,""42"":54,""43"":55,""44"":56,""45"":57,""46"":62,""47"":68,""48"":69,""49"":70,""50"":71,""51"":72,""52"":73,""53"":74,""54"":77,""55"":78,""56"":80,""57"":82,""58"":83,""59"":89,""60"":90,""61"":91,""62"":99,""63"":100,""64"":110,""65"":111,""66"":113,""67"":116,""68"":118,""69"":121,""70"":122,""71"":126,""72"":136,""73"":140,""74"":143,""75"":144,""76"":145,""77"":146,""78"":147,""79"":148,""80"":149,""81"":150,""82"":158,""83"":160,""84"":163,""85"":197,""86"":199,""87"":200,""88"":201,""89"":202,""90"":203,""91"":236,""92"":237,""93"":238,""94"":242,""95"":267,""96"":271,""97"":276,""98"":282,""99"":283,""100"":287,""101"":289,""102"":308,""103"":309,""104"":311,""105"":341,""106"":349,""107"":350,""108"":351,""109"":358,""110"":390,""111"":460,""112"":467,""113"":468,""114"":480,""115"":484,""116"":485},""word"":{""0"":""clustering"",""1"":""dimension"",""2"":""reduction"",""3"":""algorithms"",""4"":""clusters"",""5"":""algorithm"",""6"":""cluster"",""7"":""visualization"",""8"":""observations"",""9"":""dimensional"",""10"":""10"",""11"":""doi"",""12"":""projection"",""13"":""interaction"",""14"":""k"",""15"":""j"",""16"":""space"",""17"":""analyst"",""18"":""c"",""19"":""analysis"",""20"":""visual"",""21"":""ieee"",""22"":""s"",""23"":""distance"",""24"":""system"",""25"":""1109"",""26"":""interactions"",""27"":""d"",""28"":""tasks"",""29"":""observation"",""30"":""pp"",""31"":""m"",""32"":""dimensions"",""33"":""example"",""34"":""al"",""35"":""pipeline"",""36"":""et"",""37"":""a"",""38"":""analysts"",""39"":""p"",""40"":""dataset"",""41"":""node"",""42"":""computer"",""43"":""fig"",""44"":""transactions"",""45"":""analytics"",""46"":""graphics"",""47"":""t"",""48"":""different"",""49"":""similar"",""50"":""pipelines"",""51"":""conference"",""52"":""h"",""53"":""tvcg"",""54"":""proceedings"",""55"":""l"",""56"":""documents"",""57"":""link"",""58"":""2014"",""59"":""2011"",""60"":""2005"",""61"":""north"",""62"":""representation"",""63"":""york"",""64"":""usa"",""65"":""datasets"",""66"":""assignments"",""67"":""linear"",""68"":""nodes"",""69"":""acm"",""70"":""2013"",""71"":""science"",""72"":""local"",""73"":""performed"",""74"":""execute"",""75"":""oli"",""76"":""ny"",""77"":""1145"",""78"":""vast"",""79"":""2012"",""80"":""w"",""81"":""leman"",""82"":""nonlinear"",""83"":""weights"",""84"":""pi"",""85"":""outcome"",""86"":""interacting"",""87"":""oct"",""88"":""international"",""89"":""2009"",""90"":""2007"",""91"":""representations"",""92"":""2002"",""93"":""dec"",""94"":""1111"",""95"":""cid"",""96"":""distribution"",""97"":""probability"",""98"":""row"",""99"":""scatterplot"",""100"":""andromeda"",""101"":""symposium"",""102"":""xx"",""103"":""201x"",""104"":""manifolds"",""105"":""potential"",""106"":""modify"",""107"":""correct"",""108"":""misclassi\ufb01cation"",""109"":""forum"",""110"":""xxx"",""111"":""encodings"",""112"":""manipulation"",""113"":""radius"",""114"":""2004"",""115"":""switzerland"",""116"":""2015""},""vector"":{""0"":""[ 5.245301   -0.02698356  2.798057    1.5601519  -3.0362275   7.026695\n -1.4915427   4.4793005  -1.9205502   1.6924908 ]"",""1"":""[ 6.221679   -0.43709204  2.8003318   2.1061778  -3.221032    7.122268\n -1.9750454   4.005424   -2.916156    0.94667125]"",""2"":""[ 6.4951887  -0.67336386  3.3553572   1.9375716  -2.9061716   6.8557625\n -0.77581453  4.129995   -2.7394402   1.4069741 ]"",""3"":""[ 5.34232    -0.24875508  3.093347    1.5887836  -3.0264688   7.215262\n -1.5492368   4.418282   -2.7231064   2.1666265 ]"",""4"":""[ 5.3031735   0.07615329  2.6582384   1.3937243  -3.0779493   6.975999\n -1.5797408   4.335774   -1.8367054   1.5145665 ]"",""5"":""[ 5.3008943 -0.1536032  3.0350735  1.5921878 -2.9621193  7.1093965\n -1.4442419  4.3510513 -2.4618518  2.037704 ]"",""6"":""[ 5.3830419e+00 -7.4255234e-04  2.6904795e+00  1.5064073e+00\n -3.0075364e+00  6.8993893e+00 -1.4681884e+00  4.3470078e+00\n -1.7749894e+00  1.4161659e+00]"",""7"":""[ 5.755829   -0.25955436  3.1326287   2.0964727  -3.319363    7.021793\n -1.2512958   4.52738    -2.5971222   2.166272  ]"",""8"":""[ 6.3825145   0.13635385  3.4057949   1.551751   -3.48881     7.4254513\n -1.077939    4.290387   -2.828076    2.0190542 ]"",""9"":""[ 6.1159363 -0.4968221  2.870222   2.006102  -3.1450443  7.0304093\n -1.9692763  4.107865  -3.0070534  1.3218337]"",""10"":""[ 6.520422   -0.39127457  3.2690172   2.2903163  -2.524737    6.127824\n -0.61133134  3.974029   -2.3565378   0.6424122 ]"",""11"":""[ 5.2895255  -0.09611887  1.8751367   0.69649535 -2.6265032   5.6763473\n -0.3108402   3.4245636  -0.7450156  -0.3158262 ]"",""12"":""[ 6.2970333  -0.56697094  3.1950321   2.194123   -3.4049785   7.246575\n -1.216228    4.478063   -2.8176024   1.7072605 ]"",""13"":""[ 6.6100206  -0.23194629  3.4876554   1.8395407  -3.2825785   7.34902\n -1.0027995   4.352168   -3.127309    1.7817336 ]"",""14"":""[ 5.292759   -0.28496036  1.6672877   1.1037228  -2.4408884   5.235459\n -0.23811033  3.5043042  -0.27931204 -0.4399524 ]"",""15"":""[ 5.324251   -0.2198145   1.8463691   0.9790053  -2.4878423   5.172114\n -0.36253968  3.7049458  -0.09853588 -0.46202338]"",""16"":""[ 6.3212295  -0.42801204  3.0345495   2.0555723  -3.1872005   7.1705337\n -1.6811109   4.0761986  -3.013024    1.1585319 ]"",""17"":""[ 5.756512   -0.04581151  3.2853498   1.8218724  -3.2707896   7.483067\n -1.0740156   4.4746027  -2.7922068   2.3163419 ]"",""18"":""[ 5.3393617  -0.43697688  1.9246615   1.0208957  -2.1405814   5.010315\n  0.09301993  3.4795597  -0.4025189  -0.54307485]"",""19"":""[ 6.1146665  -0.09490561  3.3531492   1.7962672  -3.2851603   7.3512697\n -0.8499692   4.3984694  -2.6497416   1.9832629 ]"",""20"":""[ 6.269102   -0.49239802  3.320059    2.21652    -3.1668804   6.8970823\n -1.117474    4.366904   -2.9325542   1.8134546 ]"",""21"":""[ 5.3468165e+00  3.2626274e-03  2.1980932e+00  1.0085320e+00\n -2.7839520e+00  5.6576514e+00 -8.8763261e-01  4.1280718e+00\n -3.7382421e-01  1.2730484e-01]"",""22"":""[ 5.404908   -0.5879703   1.7481605   0.67784667 -2.157941    4.989551\n -0.08636869  3.1518712  -0.21229678 -0.91784424]"",""23"":""[ 6.3027983  -0.30491316  2.8860638   1.9699831  -3.0865443   6.867656\n -1.5953578   3.9593794  -2.5677164   0.8038195 ]"",""24"":""[ 5.7934074  -0.28745633  3.3955767   1.5978767  -2.7670448   7.2646422\n -1.0706443   4.210602   -2.837325    1.876477  ]"",""25"":""[ 5.515143   -0.36039045  2.696226    1.9590187  -1.748815    4.6363773\n  0.46346256  4.017156   -0.40691754  0.26767832]"",""26"":""[ 6.5474143  -0.10288666  3.485462    1.5991449  -3.3077152   7.4931684\n -1.1168071   4.326186   -3.1546402   1.9310724 ]"",""27"":""[ 5.362632   -0.42405108  1.7828268   0.7788128  -2.271036    5.086984\n -0.10463683  3.3043215  -0.24215366 -0.70683473]"",""28"":""[ 6.14017   -0.1228152  3.3379893  1.3585093 -3.2200656  7.5705976\n -1.5095035  4.2215815 -3.1353614  2.0628538]"",""29"":""[ 6.475173   -0.08499677  3.400546    1.8472271  -3.415931    7.222042\n -0.99736977  4.2937922  -2.8229027   1.8294214 ]"",""30"":""[ 5.272366   -0.11070796  1.970103    0.7634225  -2.5066397   5.5388455\n -0.0502809   3.4848907  -0.68570936 -0.24400249]"",""31"":""[ 5.335662   -0.3754644   1.6981034   0.8260279  -2.362773    5.0474534\n -0.2143614   3.403737   -0.03327566 -0.7559819 ]"",""32"":""[ 6.0492506 -0.3441009  2.8634763  1.8555859 -3.2475946  7.2544017\n -1.9079709  4.154721  -2.9045055  1.3490192]"",""33"":""[ 5.7283797  -0.42683625  2.874078    1.6168187  -2.1207132   5.5750895\n -0.16886044  3.884155   -1.3398807   0.5674408 ]"",""34"":""[ 5.3317537  -0.23429528  1.8824805   0.7002063  -2.4332464   5.3851333\n -0.11584071  3.3529177  -0.4716409  -0.45347762]"",""35"":""[ 5.5553827  -0.38405642  3.1987827   1.8011014  -2.8031247   7.0202565\n -1.6359754   4.0542874  -2.770516    1.9792893 ]"",""36"":""[ 5.3695226  -0.3548385   1.828358    0.7607071  -2.3355227   5.331518\n -0.0388977   3.2710028  -0.53716767 -0.555233  ]"",""37"":""[ 6.56987    -0.69749343  3.3585896   1.9717239  -2.6023257   6.476831\n -0.7387324   3.8834827  -2.6595078   0.9607587 ]"",""38"":""[ 5.650936    0.03174603  3.3180351   1.7427493  -3.1861756   7.518575\n -1.0505677   4.408919   -2.8811097   2.3263521 ]"",""39"":""[ 5.431624   -0.4210197   1.945856    0.9636921  -2.3714933   5.459034\n -0.28303543  3.4222713  -0.6935282  -0.34338877]"",""40"":""[ 5.3015475  0.127917   2.7980394  1.4955295 -3.289101   7.097543\n -1.5809262  4.4052567 -2.101293   2.0065413]"",""41"":""[ 5.3354373  -0.13438608  2.60769     1.4639826  -2.9632773   6.641764\n -1.5362052   4.131548   -1.8440453   1.2840508 ]"",""42"":""[ 5.6445665 -0.3343002  3.3261878  1.944643  -2.8501728  7.057151\n -1.2038504  4.3057027 -3.048637   2.0743587]"",""43"":""[ 5.3427267  -0.2911742   1.9989647   0.9111062  -2.4675515   5.64374\n -0.2365817   3.4853103  -0.8477578  -0.13772854]"",""44"":""[ 6.1669064 -0.0428201  3.4214551  1.4405063 -3.2877095  7.687667\n -1.2537905  4.3810253 -3.1238632  2.2275848]"",""45"":""[ 5.5778527  -0.06044001  3.1947544   1.8740857  -3.2753332   7.294282\n -1.1489687   4.5118375  -2.663354    2.341942  ]"",""46"":""[ 5.7786727  -0.32470152  3.2271018   2.0061598  -3.1590867   7.0732627\n -1.3084426   4.4480395  -2.9142365   2.1738129 ]"",""47"":""[ 5.370307   -0.48519662  1.8760664   0.8460029  -2.1564863   4.9752665\n -0.02989057  3.3540041  -0.27129877 -0.71740884]"",""48"":""[ 6.473691   -0.47306937  3.379095    1.9755611  -2.4088504   6.2982173\n -0.68685794  3.8969877  -2.558297    0.69944876]"",""49"":""[ 6.4111037  -0.6219009   3.3787656   1.800147   -2.3676867   6.327715\n -0.5789283   3.8061273  -2.4636917   0.78044826]"",""50"":""[ 5.5927467  -0.36281204  3.0741746   1.7947646  -2.9382906   7.0686088\n -1.8104169   4.128734   -2.825413    1.9659255 ]"",""51"":""[ 6.1307783  -0.15797319  3.650914    1.6369606  -2.9121022   7.815809\n -0.6941545   4.244059   -3.4425938   1.8973949 ]"",""52"":""[ 5.3599052  -0.28968114  1.9178667   0.91878045 -2.3225648   5.164075\n -0.05561404  3.4686592  -0.2974905  -0.4492863 ]"",""53"":""[ 5.4152102   0.04513767  2.084873    1.1663661  -2.7647412   5.47267\n -1.0344262   3.9122727  -0.23943825  0.066018  ]"",""54"":""[ 6.2079387  -0.11653553  3.6089573   1.5537436  -3.031207    7.866537\n -0.78935164  4.295764   -3.3762617   1.9486191 ]"",""55"":""[ 5.3574805  -0.32461265  1.8931838   0.7086855  -2.3396301   5.0844383\n -0.21332112  3.5404634  -0.14454854 -0.6864485 ]"",""56"":""[ 5.9597716  -0.03934163  3.299803    1.3379582  -3.2321992   7.687554\n -1.4366676   4.3016253  -3.0791478   2.1828566 ]"",""57"":""[ 5.726764   -0.3883648   2.791456    1.4411794  -2.2999794   5.831834\n -0.42001858  3.8135476  -1.4606483   0.5536675 ]"",""58"":""[ 5.5219316  -0.41861948  2.982746    2.283057   -1.385319    4.238325\n  0.8507937   4.1968985  -0.43055737  0.5403208 ]"",""59"":""[ 5.424918   -0.34955397  3.0875084   2.3667693  -1.5317388   4.3623977\n  0.7510825   4.1462984  -0.49664974  0.53472865]"",""60"":""[ 5.561634   -0.47789764  2.90791     2.1573884  -1.5646119   4.5991993\n  0.5415751   4.0876427  -0.5986635   0.4625523 ]"",""61"":""[ 6.3751826 -0.3404728  3.003414   2.0331097 -2.946556   6.726136\n -1.3948476  3.9057648 -2.5515428  0.7414921]"",""62"":""[ 6.26445    -0.50102115  3.2594016   1.9459544  -3.257189    7.360345\n -1.2906675   4.4249015  -2.996861    1.7623717 ]"",""63"":""[ 5.2917624   0.03712159  2.1971135   1.1147758  -2.6140025   5.2408237\n -0.43979913  4.23818    -0.0444261  -0.04938781]"",""64"":""[ 5.391425   -0.00783851  2.2955313   1.1786307  -2.595004    5.337323\n -0.48685104  4.257547   -0.2032279   0.03906088]"",""65"":""[ 5.4291034   0.02341688  2.9156253   1.5004243  -3.276488    7.253644\n -1.6425945   4.4230075  -2.4247851   2.1382892 ]"",""66"":""[ 5.9494324  -0.06248425  3.2047586   1.4602946  -3.3193815   7.5246806\n -1.5515685   4.2665854  -2.9502037   2.1006923 ]"",""67"":""[ 6.417116  -0.5378489  3.2747796  1.9722725 -2.8318193  6.7510014\n -1.2560968  4.09144   -2.9484625  1.3269689]"",""68"":""[ 5.3646507  -0.15713349  2.7007926   1.5358317  -3.0315862   6.807785\n -1.6734772   4.181681   -2.1221795   1.5327746 ]"",""69"":""[ 5.4047456  -0.07479838  2.0607681   1.0257671  -2.7240179   5.644628\n -0.9098712   3.8106883  -0.49218032  0.03204777]"",""70"":""[ 5.396555   -0.39832556  3.0405164   2.4627469  -1.4782592   4.279313\n  0.82743245  4.176494   -0.40713644  0.4793484 ]"",""71"":""[ 5.838052   -0.18134722  3.4205043   2.0246673  -2.8749554   7.0944643\n -0.9938444   4.1514854  -3.0203485   1.8931872 ]"",""72"":""[ 6.5641675  -0.3791685   3.3662493   2.1866498  -2.6520948   6.425973\n -0.7824201   3.9577231  -2.6132298   0.78185785]"",""73"":""[ 6.2753677  -0.67278564  3.3431637   1.4521965  -2.3247027   6.4254556\n -0.5608675   3.697265   -2.360441    0.88553095]"",""74"":""[ 6.170368   -0.68097943  3.2677398   1.3983344  -2.2222311   6.3361554\n -0.5562185   3.6079156  -2.2224343   0.7217934 ]"",""75"":""[ 5.346424   -0.13472506  2.0336428   0.9164821  -2.6807437   5.448411\n -0.8241228   3.998433   -0.15903084 -0.21813023]"",""76"":""[ 5.2516637e+00 -2.3763986e-02  2.0497384e+00  9.9747437e-01\n -2.5983872e+00  5.2030125e+00 -4.0530130e-01  4.0655999e+00\n  3.9893267e-04 -2.3044869e-01]"",""77"":""[ 5.503333   -0.34823805  2.6824348   1.9325258  -1.7582585   4.6240277\n  0.47889853  4.030328   -0.41255832  0.25897095]"",""78"":""[ 6.603999   -0.67522144  3.3755574   1.949628   -2.4976141   6.4147334\n -0.78947353  3.8070843  -2.6534462   0.81978655]"",""79"":""[ 5.424693   -0.40645215  2.986866    2.3268774  -1.4953346   4.2384257\n  0.87245685  4.2207847  -0.4957984   0.48588273]"",""80"":""[ 5.4561634  -0.4312056   2.168233    1.1992385  -2.074707    4.9208875\n  0.09539101  3.6084416  -0.38776088 -0.3997778 ]"",""81"":""[ 5.375993   -0.05697798  2.1237273   0.99973524 -2.7515337   5.553015\n -0.99402064  4.07197    -0.2367922  -0.02043922]"",""82"":""[ 6.2727475  -0.48113948  3.265239    1.9272039  -2.8536804   6.7819777\n -1.3865339   4.151173   -3.0382948   1.5645397 ]"",""83"":""[ 5.8889313  -0.20981541  2.9327242   1.687141   -3.1941772   7.440894\n -1.6526141   4.2416224  -2.7901125   1.4417974 ]"",""84"":""[ 5.3712564  -0.29729196  1.7652727   1.0808452  -2.5489035   5.4838486\n -0.4799914   3.4737554  -0.5090293  -0.29568624]"",""85"":""[ 6.2768073  -0.08816882  3.4530234   1.7069353  -3.1221755   7.6468034\n -0.792025    4.293898   -3.03202     1.706817  ]"",""86"":""[ 6.7040563  -0.26986384  3.488048    1.7772648  -3.1709874   7.1852875\n -1.0969408   4.2646866  -3.1622338   1.6776179 ]"",""87"":""[ 5.240536    0.09218848  2.235033    1.0515927  -2.6296291   5.446229\n -0.2586427   4.027298   -0.38285464  0.1500609 ]"",""88"":""[ 6.467206   -0.34374315  3.3865454   2.214284   -2.6457634   6.5590086\n -0.82065547  4.025432   -2.7379746   0.8959474 ]"",""89"":""[ 5.30661    -0.34697336  3.1653457   2.411306   -1.6118038   4.4563975\n  0.6491839   4.06564    -0.51029575  0.55225325]"",""90"":""[ 5.433432   -0.3423285   2.9391642   2.0971553  -1.6228122   4.4818516\n  0.631785    4.16994    -0.5673775   0.44247675]"",""91"":""[ 6.1796355  -0.39318922  3.2055824   1.7974468  -3.360994    7.4005322\n -1.4804258   4.456139   -3.0117297   1.9416122 ]"",""92"":""[ 5.4717317  -0.3688017   2.9734955   2.1208763  -1.6796601   4.6182427\n  0.5758148   4.1916285  -0.7316046   0.54722774]"",""93"":""[ 5.3094215  -0.00647652  2.183947    1.077099   -2.5439043   5.38003\n -0.19039904  3.9456918  -0.39555052  0.03662632]"",""94"":""[ 5.5055327  -0.3468382   2.561338    1.7969666  -1.8566823   4.7293334\n  0.35530233  3.979935   -0.3996708   0.15957914]"",""95"":""[ 5.428856   -0.14554398  1.9667096   0.9394587  -2.6372454   5.522488\n -0.8607259   3.616584   -0.42052087 -0.17580518]"",""96"":""[ 5.97965    -0.2932461   3.2780502   1.7414783  -2.8943744   7.276223\n -0.97337306  4.2896295  -2.5669234   1.5251194 ]"",""97"":""[ 5.9074397  -0.08315406  3.192509    1.7402068  -2.9852195   7.4678836\n -0.9767387   4.2396092  -2.6783965   1.4214464 ]"",""98"":""[ 6.3623962  -0.44007042  2.9026191   2.109246   -3.129827    6.997997\n -1.7486113   3.9356182  -2.8224838   0.7819887 ]"",""99"":""[ 5.432585    0.05660579  2.88027     1.6916741  -3.3262208   7.095829\n -1.4779625   4.517045   -2.1928678   2.0712075 ]"",""100"":""[ 5.3766308e+00 -1.6602221e-01  2.1859224e+00  8.9295006e-01\n -2.7474172e+00  5.7220149e+00 -1.0900893e+00  4.1226029e+00\n -3.6654431e-01 -1.7584305e-03]"",""101"":""[ 6.2206063  -0.20770772  3.748543    1.5870132  -2.8516955   7.8497148\n -0.5631588   4.2400312  -3.5098302   1.8697815 ]"",""102"":""[ 5.4884496  -0.25438884  2.1226554   1.3618188  -2.260642    5.0968533\n -0.03534187  3.8274093  -0.32774493 -0.18358602]"",""103"":""[ 5.582312   -0.47875684  2.876664    2.3646784  -1.3832259   4.369791\n  0.647225    4.175554   -0.19031945  0.5588187 ]"",""104"":""[ 5.8066645  -0.44213897  2.8548057   1.8556076  -3.0928116   6.9944143\n -2.013256    4.1688266  -2.887561    1.629771  ]"",""105"":""[ 6.6082497  -0.56994766  3.3178263   2.1007233  -2.6907022   6.555388\n -0.8237249   3.9270542  -2.689395    0.93272877]"",""106"":""[ 6.1864486  -0.5689967   3.235705    1.5363983  -2.2103138   6.1717796\n -0.4893801   3.702667   -2.1536274   0.63077724]"",""107"":""[ 6.2486978  -0.53801125  3.3036618   1.6436737  -2.2436285   6.2119665\n -0.55826324  3.778426   -2.258525    0.6311502 ]"",""108"":""[ 5.2748046   0.08647672  2.8221092   1.5842929  -3.1983473   7.0578604\n -1.4533174   4.520006   -1.9611037   1.9132662 ]"",""109"":""[ 6.1653905  -0.1993556   3.6711864   1.6368467  -2.8887827   7.8031473\n -0.67472756  4.2327995  -3.4629583   1.8438665 ]"",""110"":""[ 5.461543   -0.21768807  2.1929646   1.3177583  -2.321191    5.1030817\n -0.20561919  3.9858034  -0.2138144  -0.14079107]"",""111"":""[ 5.468656   -0.25092754  2.9605522   1.5687102  -3.12286     7.18573\n -1.7656951   4.3682976  -2.6516812   2.0525434 ]"",""112"":""[ 6.206205   -0.27308455  3.3556223   2.045037   -3.3279743   7.2029133\n -0.95623344  4.45798    -2.8054721   2.0093503 ]"",""113"":""[ 5.958781   -0.21224372  2.7752485   1.806231   -3.0909135   6.945905\n -1.6500362   4.054193   -2.3736482   0.9846326 ]"",""114"":""[ 5.5776963  -0.469455    2.918628    2.2195332  -1.6303436   4.675551\n  0.45926735  4.016758   -0.57364905  0.43494093]"",""115"":""[ 5.343211    0.02987473  2.1994426   1.0999885  -2.682862    5.3959064\n -0.6124649   4.1975236  -0.17893225  0.02659627]"",""116"":""[ 5.5955505  -0.3557178   2.9699235   2.4072256  -1.4900302   4.3769717\n  0.7212607   4.102309   -0.2848423   0.43872672]""},""topic"":{""0"":6,""1"":4,""2"":-1,""3"":6,""4"":6,""5"":6,""6"":6,""7"":-1,""8"":5,""9"":4,""10"":1,""11"":-1,""12"":5,""13"":5,""14"":-1,""15"":3,""16"":4,""17"":5,""18"":3,""19"":5,""20"":5,""21"":2,""22"":-1,""23"":4,""24"":-1,""25"":0,""26"":5,""27"":3,""28"":-1,""29"":5,""30"":3,""31"":3,""32"":4,""33"":-1,""34"":3,""35"":5,""36"":3,""37"":1,""38"":-1,""39"":3,""40"":6,""41"":-1,""42"":5,""43"":-1,""44"":5,""45"":5,""46"":5,""47"":3,""48"":1,""49"":1,""50"":6,""51"":5,""52"":3,""53"":2,""54"":5,""55"":3,""56"":-1,""57"":-1,""58"":0,""59"":0,""60"":0,""61"":-1,""62"":5,""63"":2,""64"":2,""65"":6,""66"":5,""67"":-1,""68"":6,""69"":2,""70"":0,""71"":-1,""72"":1,""73"":1,""74"":1,""75"":2,""76"":2,""77"":0,""78"":1,""79"":0,""80"":-1,""81"":2,""82"":-1,""83"":-1,""84"":-1,""85"":5,""86"":-1,""87"":2,""88"":1,""89"":0,""90"":0,""91"":-1,""92"":0,""93"":-1,""94"":0,""95"":-1,""96"":-1,""97"":-1,""98"":4,""99"":6,""100"":2,""101"":-1,""102"":-1,""103"":0,""104"":4,""105"":1,""106"":1,""107"":1,""108"":6,""109"":5,""110"":-1,""111"":6,""112"":5,""113"":-1,""114"":0,""115"":2,""116"":0},""exemplar"":{""0"":""*"",""1"":""*"",""2"":null,""3"":null,""4"":""*"",""5"":null,""6"":""*"",""7"":null,""8"":null,""9"":""*"",""10"":null,""11"":null,""12"":null,""13"":""*"",""14"":null,""15"":null,""16"":""*"",""17"":null,""18"":""*"",""19"":""*"",""20"":null,""21"":""*"",""22"":null,""23"":""*"",""24"":null,""25"":null,""26"":""*"",""27"":""*"",""28"":null,""29"":""*"",""30"":null,""31"":null,""32"":""*"",""33"":null,""34"":""*"",""35"":null,""36"":""*"",""37"":""*"",""38"":null,""39"":""*"",""40"":""*"",""41"":null,""42"":null,""43"":null,""44"":""*"",""45"":null,""46"":null,""47"":""*"",""48"":""*"",""49"":""*"",""50"":null,""51"":null,""52"":""*"",""53"":""*"",""54"":null,""55"":""*"",""56"":null,""57"":null,""58"":""*"",""59"":""*"",""60"":null,""61"":null,""62"":""*"",""63"":null,""64"":""*"",""65"":""*"",""66"":null,""67"":null,""68"":""*"",""69"":""*"",""70"":""*"",""71"":null,""72"":""*"",""73"":null,""74"":null,""75"":""*"",""76"":null,""77"":null,""78"":""*"",""79"":""*"",""80"":null,""81"":""*"",""82"":null,""83"":null,""84"":null,""85"":null,""86"":null,""87"":null,""88"":null,""89"":""*"",""90"":""*"",""91"":null,""92"":null,""93"":null,""94"":null,""95"":null,""96"":null,""97"":null,""98"":""*"",""99"":null,""100"":null,""101"":null,""102"":null,""103"":null,""104"":""*"",""105"":""*"",""106"":null,""107"":""*"",""108"":null,""109"":null,""110"":null,""111"":""*"",""112"":""*"",""113"":null,""114"":null,""115"":""*"",""116"":""*""},""word*"":{""0"":""clustering*"",""1"":""dimension*"",""2"":""reduction"",""3"":""algorithms"",""4"":""clusters*"",""5"":""algorithm"",""6"":""cluster*"",""7"":""visualization"",""8"":""observations"",""9"":""dimensional*"",""10"":""10"",""11"":""doi"",""12"":""projection"",""13"":""interaction*"",""14"":""k"",""15"":""j"",""16"":""space*"",""17"":""analyst"",""18"":""c*"",""19"":""analysis*"",""20"":""visual"",""21"":""ieee*"",""22"":""s"",""23"":""distance*"",""24"":""system"",""25"":""1109"",""26"":""interactions*"",""27"":""d*"",""28"":""tasks"",""29"":""observation*"",""30"":""pp"",""31"":""m"",""32"":""dimensions*"",""33"":""example"",""34"":""al*"",""35"":""pipeline"",""36"":""et*"",""37"":""a*"",""38"":""analysts"",""39"":""p*"",""40"":""dataset*"",""41"":""node"",""42"":""computer"",""43"":""fig"",""44"":""transactions*"",""45"":""analytics"",""46"":""graphics"",""47"":""t*"",""48"":""different*"",""49"":""similar*"",""50"":""pipelines"",""51"":""conference"",""52"":""h*"",""53"":""tvcg*"",""54"":""proceedings"",""55"":""l*"",""56"":""documents"",""57"":""link"",""58"":""2014*"",""59"":""2011*"",""60"":""2005"",""61"":""north"",""62"":""representation*"",""63"":""york"",""64"":""usa*"",""65"":""datasets*"",""66"":""assignments"",""67"":""linear"",""68"":""nodes*"",""69"":""acm*"",""70"":""2013*"",""71"":""science"",""72"":""local*"",""73"":""performed"",""74"":""execute"",""75"":""oli*"",""76"":""ny"",""77"":""1145"",""78"":""vast*"",""79"":""2012*"",""80"":""w"",""81"":""leman*"",""82"":""nonlinear"",""83"":""weights"",""84"":""pi"",""85"":""outcome"",""86"":""interacting"",""87"":""oct"",""88"":""international"",""89"":""2009*"",""90"":""2007*"",""91"":""representations"",""92"":""2002"",""93"":""dec"",""94"":""1111"",""95"":""cid"",""96"":""distribution"",""97"":""probability"",""98"":""row*"",""99"":""scatterplot"",""100"":""andromeda"",""101"":""symposium"",""102"":""xx"",""103"":""201x"",""104"":""manifolds*"",""105"":""potential*"",""106"":""modify"",""107"":""correct*"",""108"":""misclassi\ufb01cation"",""109"":""forum"",""110"":""xxx"",""111"":""encodings*"",""112"":""manipulation*"",""113"":""radius"",""114"":""2004"",""115"":""switzerland*"",""116"":""2015*""},""pos"":{""0"":1,""1"":1,""2"":1,""3"":2,""4"":3,""5"":4,""6"":5,""7"":2,""8"":1,""9"":2,""10"":1,""11"":3,""12"":2,""13"":3,""14"":4,""15"":1,""16"":3,""17"":4,""18"":2,""19"":5,""20"":6,""21"":1,""22"":5,""23"":4,""24"":6,""25"":1,""26"":7,""27"":3,""28"":7,""29"":8,""30"":4,""31"":5,""32"":5,""33"":8,""34"":6,""35"":9,""36"":7,""37"":2,""38"":9,""39"":8,""40"":6,""41"":10,""42"":10,""43"":11,""44"":11,""45"":12,""46"":13,""47"":9,""48"":3,""49"":4,""50"":7,""51"":14,""52"":10,""53"":2,""54"":15,""55"":11,""56"":12,""57"":13,""58"":2,""59"":3,""60"":4,""61"":14,""62"":16,""63"":3,""64"":4,""65"":8,""66"":17,""67"":15,""68"":9,""69"":5,""70"":5,""71"":16,""72"":5,""73"":6,""74"":7,""75"":6,""76"":7,""77"":6,""78"":8,""79"":7,""80"":17,""81"":8,""82"":18,""83"":19,""84"":20,""85"":18,""86"":21,""87"":9,""88"":9,""89"":8,""90"":9,""91"":22,""92"":10,""93"":23,""94"":11,""95"":24,""96"":25,""97"":26,""98"":6,""99"":10,""100"":10,""101"":27,""102"":28,""103"":12,""104"":7,""105"":10,""106"":11,""107"":12,""108"":11,""109"":19,""110"":29,""111"":12,""112"":20,""113"":30,""114"":13,""115"":11,""116"":14},""x2D"":{""0"":8.2134914398,""1"":6.3819565773,""2"":4.4383587837,""3"":6.9466347694,""4"":7.9851293564,""5"":7.2140960693,""6"":8.0684070587,""7"":6.2304282188,""8"":4.6011266708,""9"":6.487555027,""10"":3.8897354603,""11"":-8.3575267792,""12"":4.7774982452,""13"":4.2625966072,""14"":-9.0547513962,""15"":-8.9558639526,""16"":6.3458590508,""17"":5.8788208961,""18"":-9.2872180939,""19"":4.8487229347,""20"":4.7757649422,""21"":-7.2446894646,""22"":-9.712015152,""23"":5.9727611542,""24"":5.5857601166,""25"":-13.4832553864,""26"":4.342997551,""27"":-9.5605096817,""28"":5.1750526428,""29"":4.4914512634,""30"":-8.4008321762,""31"":-9.4990062714,""32"":6.3053812981,""33"":2.6229803562,""34"":-8.8863697052,""35"":6.6551976204,""36"":-9.0597991943,""37"":3.7151534557,""38"":5.8042469025,""39"":-8.5770645142,""40"":7.7392101288,""41"":8.1247549057,""42"":6.0480904579,""43"":-8.430147171,""44"":5.0097603798,""45"":6.0174894333,""46"":5.9918932915,""47"":-9.5182228088,""48"":3.6257517338,""49"":3.4777846336,""50"":6.6686177254,""51"":4.2866082191,""52"":-9.0951890945,""53"":-7.0537052155,""54"":4.3723726273,""55"":-9.347910881,""56"":5.2156143188,""57"":2.8196167946,""58"":-13.1855564117,""59"":-13.0913667679,""60"":-13.1374349594,""61"":5.7405295372,""62"":4.6870222092,""63"":-7.8476958275,""64"":-7.7196054459,""65"":7.4171919823,""66"":5.4117498398,""67"":4.857155323,""68"":8.1124572754,""69"":-7.0429005623,""70"":-13.2503442764,""71"":5.6460709572,""72"":3.9756062031,""73"":3.3820230961,""74"":3.1580104828,""75"":-7.4861402512,""76"":-7.9838094711,""77"":-13.3176898956,""78"":3.8236865997,""79"":-13.0808172226,""80"":-9.1578817368,""81"":-7.2414889336,""82"":5.0343050957,""83"":6.2595210075,""84"":-8.5359544754,""85"":4.3067646027,""86"":4.2347807884,""87"":-7.8079681396,""88"":4.0868067741,""89"":-13.1313657761,""90"":-12.8723974228,""91"":4.9606957436,""92"":-13.0175762177,""93"":-7.9520602226,""94"":-13.4184112549,""95"":-7.2351131439,""96"":5.2737159729,""97"":5.3721027374,""98"":6.1108927727,""99"":7.6213202477,""100"":-7.2919487953,""101"":4.3772320747,""102"":-8.624464035,""103"":-13.3780937195,""104"":6.4767775536,""105"":4.027970314,""106"":3.2036967278,""107"":3.2869095802,""108"":7.8782243729,""109"":4.3402695656,""110"":-8.3274641037,""111"":7.1009960175,""112"":4.8107662201,""113"":6.0821456909,""114"":-13.1604909897,""115"":-7.8441429138,""116"":-13.2895154953},""y2D"":{""0"":-5.71261549,""1"":-3.9906392097,""2"":-3.7284514904,""3"":-5.7288627625,""4"":-5.5420708656,""5"":-5.7831134796,""6"":-5.3748598099,""7"":-5.8396615982,""8"":-5.9268145561,""9"":-4.1303086281,""10"":-2.729029417,""11"":8.5153694153,""12"":-4.9019083977,""13"":-5.5782318115,""14"":8.1555204391,""15"":7.777276516,""16"":-3.9889411926,""17"":-6.0249147415,""18"":8.4300899506,""19"":-5.738296032,""20"":-4.8185214996,""21"":6.6745228767,""22"":8.3850488663,""23"":-3.6455144882,""24"":-5.4186067581,""25"":-17.2630691528,""26"":-5.9283528328,""27"":8.1825590134,""28"":-6.3285117149,""29"":-5.4973192215,""30"":8.371887207,""31"":8.0215673447,""32"":-4.4020876884,""33"":-2.5160899162,""34"":8.4853982925,""35"":-5.3255167007,""36"":8.454656601,""37"":-3.1743700504,""38"":-6.0710372925,""39"":8.4279031754,""40"":-5.8014278412,""41"":-5.4083385468,""42"":-5.314037323,""43"":8.3985214233,""44"":-6.2807445526,""45"":-6.0453262329,""46"":-5.5291361809,""47"":8.234913826,""48"":-2.8929629326,""49"":-2.7227244377,""50"":-5.1913151741,""51"":-6.708714962,""52"":8.4768972397,""53"":6.8635587692,""54"":-6.577600956,""55"":8.0735340118,""56"":-6.2840685844,""57"":-2.6024448872,""58"":-18.0571899414,""59"":-17.8858699799,""60"":-17.4268054962,""61"":-3.546756506,""62"":-5.0011258125,""63"":6.729924202,""64"":6.9292840958,""65"":-5.7416195869,""66"":-6.0586767197,""67"":-3.8299055099,""68"":-5.5495738983,""69"":6.953312397,""70"":-17.9799823761,""71"":-5.4239292145,""72"":-2.8916285038,""73"":-2.6265292168,""74"":-2.3807878494,""75"":6.7677984238,""76"":6.7920627594,""77"":-17.2240047455,""78"":-2.9715161324,""79"":-18.0537528992,""80"":7.9569482803,""81"":6.6246199608,""82"":-4.314593792,""83"":-4.5197958946,""84"":8.1994152069,""85"":-6.1979141235,""86"":-5.4691390991,""87"":7.0954546928,""88"":-3.0456185341,""89"":-17.7614173889,""90"":-17.337179184,""91"":-5.593644619,""92"":-17.4687652588,""93"":7.2265515327,""94"":-17.2432193756,""95"":7.0332283974,""96"":-5.246758461,""97"":-5.3529429436,""98"":-3.7066996098,""99"":-5.8099322319,""100"":6.6333966255,""101"":-6.6308240891,""102"":7.4828577042,""103"":-17.8270931244,""104"":-4.5320935249,""105"":-3.2081463337,""106"":-2.3288478851,""107"":-2.5366823673,""108"":-5.632733345,""109"":-6.5824532509,""110"":7.2730960846,""111"":-5.615585804,""112"":-5.356356144,""113"":-3.8348042965,""114"":-17.3469829559,""115"":6.7915487289,""116"":-17.8876419067}}",False,False,False,http://ieeexplore.ieee.org/document/8019882/,,Towards a Systematic Combination of Dimension Reduction and Clustering in Visual Analytics,5UJ67Q46,False,False
8KJJXFM6,VV6MIDHB,"Semantic Interaction for Visual Text Analytics 
Chris North 
Alex Endert 
Virginia Tech 
Virginia Tech 

Patrick Fiaux 
Virginia Tech 

Blacksburg, VA USA 

aendert@vt.edu 

Blacksburg, VA USA 

pfiaux@vt.edu 

 

Blacksburg, VA USA 

north@vt.edu 

by 

For 

through 

ABSTRACT 
Visual analytics emphasizes sensemaking of large, complex 
datasets 
interactively  exploring  visualizations 
generated 
example, 
statistical  models. 
dimensionality  reduction  methods  use  various  similarity 
metrics to visualize textual document collections in a spatial 
metaphor,  where  similarities  between  documents  are 
approximately  represented  through  their  relative  spatial 
distances  to  each  other  in  a  2D  layout.  This  metaphor  is 
designed to mimic analysts’ mental models of the document 
collection  and  support  their  analytic  processes,  such  as 
clustering similar documents together. However, in current 
methods, users must interact with such visualizations using 
controls  external  to  the  visual  metaphor,  such  as  sliders, 
menus, or text fields, to directly control underlying model 
parameters  that  they  do  not  understand  and  that  do  not 
relate  to  their  analytic  process  occurring  within  the  visual 
metaphor.  In  this  paper,  we  present  the  opportunity  for  a 
new  design  space  for  visual  analytic  interaction,  called 
semantic  interaction,  which  seeks  to  enable  analysts  to 
spatially interact with such models directly within the visual 
metaphor using interactions that derive from their analytic 
process,  such  as  searching,  highlighting,  annotating,  and 
repositioning  documents.  Further,  we  demonstrate  how 
semantic  interactions  can  be  implemented  using  machine 
learning 
tool,  called 
ForceSPIRE, for interactive analysis of textual data within 
a  spatial  visualization.    Analysts  can  express  their  expert 
domain knowledge about the documents by simply moving 
them,  which  guides  the  underlying  model  to  improve  the 
overall layout, taking the user’s feedback into account. 
Author Keywords 
Visualization; visual analytics; interaction 
ACM Classification Keywords 
H5.m.  Information  interfaces  and  presentation  (e.g.,  HCI): 
Miscellaneous.  
General Terms 
Design; Human Factors; Theory 

in  a  visual  analytic 

techniques 

 
Permission to  make digital or hard copies of all or part of this work for 
personal or classroom use is granted without fee provided that copies are 
not made or distributed for profit or commercial advantage and that copies 
bear this notice and the full citation on the first page. To copy otherwise, 
or  republish,  to  post  on  servers  or  to  redistribute  to  lists,  requires  prior 
specific permission and/or a fee. 
CHI’12, May 5–10, 2012, Austin, Texas, USA. 
Copyright 2012 ACM 978-1-4503-1015-4/12/05...$10.00. 
 

 

INTRODUCTION 
Visual analytics bases its success on combining the abilities 
of statistical models, visualization, and human intuition for 
users to gain insight into large, complex datasets [23]. This 
success often hinges on the ability for users to interact with 
the  information,  manipulating  the  visualization  based  on 
their  domain  expertise,  interactively  exploring  possible 
connections, and investigating hypotheses. It is through this 
interactive exploration that users are able to make sense of 
complex  datasets,  a  process  referred  to  as  sensemaking 
[19].  
The  two  primary  parts  of  sensemaking  are  foraging  and 
synthesis. Foraging refers to the stages of the process where 
users filter and gather collections of interesting or relevant 
information.  Then,  using  that  information,  users  advance 
through  the  synthesis  stages  of  the  process,  where  they 
construct  and  test  hypotheses  about  how  the  foraged 
information  may  relate  to  the  larger  plot.  Tools  exist  that 
support users for either foraging or synthesis – but not both. 
In  this  paper  we  present  semantic  interaction,  combining 
the  foraging  abilities  of  statistical  models  with  the  spatial 
synthesis abilities of analysts. Semantic interaction is based 
on the following principles: 
1. Visual  “near=similar”  metaphor  supports  analysts’ 
spatial  cognition,  and  is  generated  by  statistical  models 
and similarity metrics. [22] 

2. Use  semantic  interactions  within  the  visual  metaphor, 
based  on  common  interactions  occurring  in  spatial 
analytic  processes  [4]  such  as  searching,  highlighting, 
annotating, and repositioning documents.  

3. Interpret  and  map  the  semantic  interactions  to  the 
underlying parameters of the model, by updating weights 
and adding information. 

4. Shield  the  users  from  the  complexity  of  the  underlying 

mathematical models and parameters. 

5. Models  learn  incrementally  by  taking  into  account 
interaction during the entire analytic process, supporting 
analysts’ process of incremental formalism [10]. 

6. Provide  visual  feedback  of  the  updated  model  and 

learned parameters within the visual metaphor. 

7. Reuse  learned  model  parameters  in  future  or  streaming 

data within the visual metaphor. 

To  demonstrate  the  concept  of  semantic  interaction,  we 
present  a  prototype  visual  analytics  tool,  ForceSPIRE,  for 
spatial analysis of textual information. In ForceSPIRE, the 
user  interaction  takes on  a deeper,  more  integrated role in 

the  exploratory  spatial  analytic  process.  This  is  done 
through capturing the semantic interaction, interpreting the 
analytical  reasoning  associated  with  the  interaction,  and 
updating the statistical model, and ultimately updating the 
spatialization.  Hence,  users  are  able  to  leverage  semantic 
interaction  to  explore  and  analyze  the  data  interactively, 
while  the  system  is  responsible  for  properly  updating  the 
underlying statistical model.  
RELATED WORK 
Foraging Tools 

 

Figure  1.  A  model  of  interaction  with  foraging  tools.  Users 
interact  directly  with  the  statistical  model  (red),  then  gain 
insight  through  observing  the  change  in  the  visualization 
(blue). 
We  categorize  foraging  tools  by  their  ability  to  pass  data 
through  complex  statistical  models  and  visualize  the 
computed structure of the dataset for the user to gain insight 
(Figure  1).  Thus,  users  interact  with  these  tools  primarily 
through directly manipulating the parameters of the model 
used  for  computing  the  structure.  As  such,  users  are 
required  to  translate  their  domain  expertise  and  semantics 
about  the  information  to  determine  which  (and  by  how 
much) to adjust these parameters. The following examples 
further describe this category of tools. 
Visualizations such as IN-SPIRE’s “Galaxy View” (shown 
in  Figure  3)  present  users  with  a  spatial  layout  of  textual 
information where similar documents are proximally close 
to  one  another  [25].  An  algorithm  creates  the  layout  by 
mapping the high-dimensional collection of text documents 
down  to  a  two-dimensional  view.  In  these  spatializations, 
the  spatial  metaphor  is  one  from  which  users  can  infer 
meaning  of  the  documents  based  on  their  location.  The 
notion  of  distance  between  documents  represents  how 
similar the two documents are (i.e., more similar documents 
are  placed  closer  together).  For  instance,  a  cluster  of 
documents  represents  a  group  of  similar  documents,  and 
documents  placed  between  two  clusters  implies  those 
documents are connected to both clusters. These views are 
beneficial  as  they  allow  users  to  visually  gain  a  quick 
overview  of  the  information,  such  as  what  key  themes  or 
groups  exist  within  the  dataset.  The  complex  statistical 
models  that  compute  similarity  between  documents  are 
based on the structure within the data, such as term or entity 
frequency. In order to interactively change the view, users 
are  required  to  directly  adjust  keyword  weights,  add  or 
remove documents/keywords, or provide more information 
on how to parse the documents for keywords/entities upon 
import. 

 

to  a 

to  understand 

the 

[15].  Through  adjusting 

Similarly, an interactive visualization tool called iPCA uses 
Principal  Component  Analysis  (PCA)  to  reduce  high-
dimensional  data  down 
two-dimensional  plot, 
providing  users  with  sliders  and  other  visual  controls  for 
directly  adjusting  numerous  parameters  of  the  algorithm, 
such  as  individual  eigenvalues,  eigenvectors,  and  other 
components  of  PCA 
the 
parameters,  the  user  can  observe  how  the  visualization 
changes.  This  allows  users  to  gain  insight  into  a  dataset, 
given  they  have  a  thorough  understanding  of  PCA, 
necessary 
the 
changes they are making to the model parameters. 
Alsakran  et  al.  presented  a  visualization 
system, 
STREAMIT,  capable  of  spatially  arranging  text  streams 
based  on  keyword  similarity  [3].  Again,  users  can 
interactively  explore  and  adjust  the  spatial  layout  through 
directly  changing  the  weight  of  keywords  that  they  find 
important.  In  addition,  STREAMIT  allows  for  users  to 
conduct  a  temporal  investigation  of  how  clusters  change 
over time. 
Synthesis Tools 

implications  behind 

 

Figure  2.  A  model  of  interaction  with  synthesis  tools.  Users 
manually  create  a  spatial  layout  of  the  information  to 
maintain and organize their insights about the data. 
Synthesis  tools  focus  on  allowing  users  to  organize  and 
maintain their hypotheses and insight regarding the data in 
a  spatial  medium.  In  large  part,  this  is  done  through 
presenting users with a flexible spatial workspace in which 
they  can  organize  information  through  creating  spatial 
structures,  such  as  clusters,  timelines,  stories,  etc.  (Figure 
2). In doing so, users externalize their thought processes (as 
well  as  their  insights)  into  a  spatial  layout  of  the 
information. 
For example, Analyst’s Notebook [2] provides users with a 
spatial workspace where information can be organized, and 
connections  between  specific  pieces  of  information  (e.g., 
entities, documents, events, etc.) can be created. Similarly, 
The Sandbox [26] enables users to create a series of cases 
(collections  of 
information)  which  can  be  organized 
spatially within the workspace.  
From  previous  studies,  we  found  cognitive  advantages 
associated  with  the  manual  creation  of  a  spatial  layout  of 
the  information  [4].  By  providing  users  a  workspace  in 
which  to  manually  create  spatial  representations  of  the 
information, users were able to externalize their semantics 
of the information into the workspace. That is, they created 
spatial  structures  (e.g.,  clusters,  timelines,  etc.),  and  both 
the structures as well as the locations relative to remaining 
layout  carried  meaning  to  the  users  with  regards  to  their 
sensemaking process. Marshall et al. have pointed out that 

this 

interaction  (and 

From  the  sensemaking  loop  presented  by  Pirolli  and  Card 
[19],  we  learn  that  in  intelligence  analysis,  that  analytic 
process  consists  not  only  of  the  information  that  is 
explicitly  within  the  dataset  being  analyzed,  but  also  the 
domain knowledge of the analyst performing the analysis. It 
is through this domain knowledge that analysts interact and 
explore  the  dataset  to  “make  sense”  of  the  information. 
Thus,  we  believe 
the  domain 
knowledge  associated  with  it)  is  equally  important  as  the 
raw data, and must be incorporated into the visualization by 
tightly coupling the model with the interaction. 
From this body of work, we most notably come away with 
an understanding that 1) analysts fundamentally understand 
the spatial metaphor used in many spatial visualizations, 2) 
many  of  these  systems  are  constructed  using  complex 
mathematical  algorithms  to  transform  high-dimensional 
data  to  two  dimensions,  and  3)  in  most  cases  these 
algorithms  can  be  controlled  by  analysts  largely  through 
visual  controls  (e.g.,  sliders,  knobs,  etc.)  to  directly  adjust 
parameters of the algorithms, updating the spatial layout. 
SEMANTIC INTERACTION 

 

Figure 4. A model of semantic interaction. Users are able to 
interact directly in the spatial metaphor. The system updates 
the corresponding parameters of the statistical model based on 
the analytic reasoning of the users. Finally, the model updates 

the visualization based on the changes, thus unifying the 
synthesis and foraging stages of the sensemaking loop. 

In the purest sense, semantic interaction refers to interaction 
occurring  within  a  spatial  visualization,  with  the  added 
benefit that it is tightly coupled to the model calculating the 
spatial layout (Figure 4). Given the previous work of what 
interaction  in  visual  analytic  tools  is,  semantic  interaction 
occupies a new design space for interaction. It merges the 
ability to change the statistical model while maintaining the 
flexibility  and  familiar  methods  for  interacting  within  the 
metaphor  of  spatial  visualizations.  Users  can  benefit  from 
semantic  interactions  in  that  they  can  interact  within  a 
metaphor  which 
they  are  familiar  with,  performing 
interactions  which  are  part  of  the  spatial  analytic  process 
[4], without having to focus on formal updates to the model.  
Semantic  interaction  leverages  the  cognitive  connection 
formed  between  the  user  and  the  spatial  layout.  The 
following intelligence analysis scenario is representative of 
the strategies and interactions of analysts when performing 
an  intelligence  analysis  task  of  textual  documents  in  a 
spatial visualization, as previously found by Andrews et al. 
[4],  and  further  motivates  and  explains  the  concept  of 
semantic interaction: 

 
Figure  3.  The  IN-SPIRE  Galaxy  View  showing  a 
spatializtiation  of  documents  represented  as  dots.  Each 
cluster of dots represents a group of similar documents.  
 
allowing users to create such informal relationships within 
information  is  beneficial,  as  it  does  not  require  users  to 
formalize these relationships [17].  
From this related work, we believe a trend is emerging in 
how interaction is currently handled in many visual analytic 
systems where complex statistical models are used – users 
are  required  to  go  outside  of  the  metaphor.  That  is,  while 
the  visual  representation  given  to  users  is  spatial,  the 
methods of interaction require users to step outside of that 
metaphor  and  interact  directly  with  the  parameters  of  the 
statistical model using visual controls, toolbars, etc.  
There  has  been  some  work  in  providing  more  easy  to  use 
interactions  for  updating  statistical  models.  For  example, 
relevance feedback has been used for content-based image 
retrieval, where users are able to move images towards or 
away  from  a  single  image  in  order  to  portray  pair-wise 
similarity  or  dissimilarity  [24].  From  there,  an  image 
retrieval algorithm determines the features and dimensions 
shared between the images that the user has determined as 
being  similar.  We  view  this  as  one  example  where  the 
interaction stays in the spatial metaphor of the visualization.  
Also, spatializations of document sets exist that allow users 
to place “points of interest” into the spatial layout. In VIBE, 
users are allowed to define multiple points of interest in the 
spatial  layout  that  correspond  to  a  series  of  keywords 
describing  a  subject  matter  of  interest  to  the  user  [18]. 
Similarly,  Dust  &  Magnet  [27]  allows  users  to  place  a 
series  of  “magnets”  representing  keywords  into  the  space 
and observe how documents are attracted or repelled from 
the  locations  of  these  magnets.  Through  both  of  these 
systems, users can interact in the spatial metaphor through 
these  placements  of  “nodes”  representing  keywords. 
However, the focus of semantic interaction is on interacting 
with  data  (i.e.,  documents),  an 
important  distinction 
discussed in the following section. 

 

 

 
Figure  5.  (top)  The  basic  version  of  the  “visualization 
pipeline”.  Interaction  can  be  performed  on  directly  the 
Algorithm  (blue  arrow)  or  the  data  (red  arrow).  (bottom) 
Our  modified  version  of 
for  semantic 
interaction,  where  the  user  interacts  within  the  spatial 
metaphor (purple arrow). 

the  pipeline 

During her analysis, an intelligence analyst finds a 
suspicious  and 
interesting  phrase  within  a 
document. While reading through the document, she 
highlights  the  phrase  “suspicious  individuals  were 
spotted  at  the  airport”,  in  order  to  more  easily 
recall  this  information  later.  After  she  finishes 
reading the document, she moves the document into 
the  bottom  right  corner  of  her  workspace,  in  the 
proximity of other documents related to an event at 
an airport. To remind herself of her hypothesis, she 
annotates  the  document  with  “might  be  related  to 
Revolution  Now  terrorist  group”.  Now,  with  the 
goal  of 
the 
“airport”, she searches for the term, continuing her 
investigation. 

further  examining 

the  events  at 

investigating 

that  each  of 

instead  point  out 

the  analytic  process  of 

In addition to the three forms of semantic interaction in the 
scenario,  Table  1  provides  a  list  of  various  forms  of 
semantic  interaction,  including  how  each  can  be  used 
within 
textual 
information  spatially.  We  do  not  claim  that  this  list  is 
complete,  but 
these 
interactions  can  relate  to  a  user’s  reasoning  within  the 
analytic process.  
Designing for Semantic Interaction 
In order for analysts to interact with information in a spatial 
metaphor, it must first be created. Following the model of 
the visualization pipeline [13], this creation calls for a series 
of  mathematical  transformations,  turning  raw  data  into  a 
spatial  layout  –  much  the  way  many  of  the  visualizations 
mentioned  previously  are  constructed.  However,  these 
visualizations  fit  this  model,  as  their  user  interactions  are 
primarily  focused  on  directly  modifying  the  statistical 
model  (as  well  as  other  attributes  of  the  visualization  or 
data  transformation).  Designing  for  semantic  interaction 
requires  a  fundamentally  different  model  for  how  tools 
integrate  user  interaction  –  one  that  can  capture  the 
interaction,  interpret  the  associated  analytical  reasoning, 
and update the appropriate mathematical parameters.  
Figure  5  illustrates  this  model,  where  the  spatialization  is 
treated  a  medium  through  which  the  user  can  perceive 

 

Figure 6. Overview of how nodes and edges in ForceSPIRE’s 
force-directed layout are created from documents (Doc) and 
entities (Ent), respectively.  

 

 

it 

interaction, 

information  and  gain  insight,  as  well  as  interact  and 
perform  his  analysis.  Through  expanding  the  pipeline  to 
accommodate  for  semantic 
is  a  more 
appropriate match to the user’s sensemaking process. 
Capturing the Semantic Interaction 
A  non-trivial  first  step  in  the  model  is  capturing  the  user 
interaction.  Much  research  has  been  done  in  this  area, 
primarily  for  the  purpose  of  maintaining  process  history 
(e.g., [5], [21], [12], etc.). When considering how to capture 
interaction,  one  decision  to  be  made  is  at  what  “level”  to 
capture  it.  For  example,  GlassBox  [6]  captures  interaction 
at a rudimentary level (i.e. mouse clicks and key strokes), 
while  Graphical  History  [14]  keeps  track  of  a  series  of 
previous  visualizations  as  a  user  changes  the  visualization 
during the exploration of the data.  
Semantic  interaction  is  captured  at  a  data  level,  as  the 
interactions  occur  on  the  data,  and  within  the  spatial 
metaphor.  Using 
the 
interaction being captured would be: 

the  earlier  analytic  scenario, 

•  The highlighted phrase 
•  When the highlighting occurs (timestamp) 
•  The color chosen for the highlight 
•  The document in which the highlight occurs 
•  The new document location 
•  The text of the annotation 

By  capturing  (and  storing)  the  interaction  history,  we  can 
interpret the analytical reasoning of the user. Thus, we not 
only capture the interaction, but also use it. 
Interpreting the Associated Analytical Reasoning 
In interpreting the interaction, the goal is for the system to 
determine  the  analytical  reasoning  associated  with  the 
interactions  and  update  the  model  accordingly.  From 
previous findings [4], we can associate analytical reasoning 
with  forms  of  semantic  interaction  (see  Table  1).  It  is 
essentially the model’s task to determine  why, in terms of 
the data, the interaction occurred. To answer this question, 
we do not propose that this model can accurately gauge user 
intent.  Instead,  the  goal  is  to  calculate,  based  on  the  data, 

Figure 7. Using ForceSPIRE on a 32 megapixel large, 
high-resolution display. 

 

 
what information is consistent with the captured interaction. 
For  instance,  we  associate  text  highlighting  with  adding 
importance to the text being highlighted. We do not claim 
that we can associate the interaction of highlighting to the 
intuition that spurred the analyst to highlight the text, which 
is far more challenging, and arguably impossible. 
We refer to the captured and interpreted interactions as soft 
data, in comparison to the hard data that is extracted from 
the raw textual information (e.g., term or entity frequency, 
titles,  document  length,  etc.).  We  define  soft  data  as  the 
stored result of user interaction as interpreted by the system. 
In  representing  interaction  as  soft  data,  the  algorithm  can 
calculate  and  reconfigure  the  spatial  layout  accordingly. 
Figure  5  illustrates  how  our  approach  differs  from  the 
traditional visualization pipeline. 
There has been previous work in capturing and interpreting 
reasoning from user interaction. For instance, Dou et al. [7] 
performed  a  study  where  financial  analysts  were  asked 
analyze  a  dataset  using  WireVis,  an  interactive  financial 
transaction visualization. The tool developers then analyzed 
the captured interaction, and assumptions were made about 
the  reasoning  of  the  analysts  at  specific  points  in  the 
investigation. These results were compared to the analysts’ 
self-recorded  reasoning,  and  found  to  be  accurate  up  to 
82%. While our work has similar goals (i.e., interpreting the 
analytical reasoning associated with the analysts through an 
evaluation  of  the  interaction)  our  model  does  so  through 
tightly  integrating  the  interaction  with  the  underlying 
mathematical model. In doing so, the interpretation can be 
done algorithmically. 
Updating the Underlying Model 
Through  metric  learning  of  distance  weights,  the  layout 
uses  the  soft  data  to  update  the  underlying  model. 
Depending  on  the  algorithm  used  to  compute  the  spatial 
layout,  the  precise  parameters  being  updated  will  vary.  In 
general,  this  will  refer  to  weighting  of  a  combination  of 
dimensions  that  will  help  guide  the  model  as  to  which 
dimensions the user finds important.  
FORCESPIRE: SYSTEM OVERVIEW 
ForceSPIRE  is  a  visual  analytics  prototype  designed  for 
specific 
(document 
movement,  text  highlighting,  search,  and  annotation)  for 

forms  of 

interaction 

semantic 

 

Figure  8.  Moving  the  document  shown  by  the  arrow, 
ForceSPIRE  adapts  the  layout  accordingly.  Documents 
sharing entities with the document being moved follow. 

 

interactively exploring textual data. The system has a single 
spatial  view  (shown  in  Figure  12),  where  a  collection  of 
documents is represented spatially based on similarity (i.e., 
documents closer together are more similar).  
ForceSPIRE is designed for large, high-resolution displays 
(such  as  the  one  shown  in  Figure  7).  As  semantic 
interaction emphasizes the importance of context in which 
the  interaction  takes  place  (e.g.,  highlighting  text  in  the 
context  of  the  document),  having  the  full  detail  text 
available  in  the  context  of  the  spatial  layout  is  beneficial 
over having a single document viewer. Further, the physical 

Table  1.  Forms  of  semantic  interaction.  Each  interaction 
corresponds  to  reasoning  of  users  within  the  analytic 
process. 

Form of Semantic 

Interaction 

Document Movement 

Text Highlighting 

Pinning  Document 
Location 
Annotation, “Sticky Note” 

to 

Document Coloring 

Level of Visual Detail 

Query Terms 
 

Associated Analytic Reasoning 

• Similarity/Dissimilarity 
• Create 

spatial  construct 

timeline, list, story, etc) 

• Test 

hypothesis, 

see 
document “fits” in region 

(.e.g 

how 

• Mark 

importance  of  phrase 

(collection of entities) 

• Augment  visual  appearance  of 

document for reference 

to 

in 

• Give 

semantic  meaning 

space/layout 

• Put 

semantic 

information 

workspace, within context 
• Create visual group/cluster 
• Mark group membership 
• Change 

ease 

of 

visually 
referencing  information  (e.g.  full 
detail = more important = easy to 
reference) 

• Expressive search for entity 

(and 

to  match 

is  positioning 

Semantic Interaction in ForceSPIRE 
The  semantic  interactions  in  ForceSPIRE  are:  placing 
information  at  specific  locations,  highlighting,  searching, 
and annotating in order to incrementally change the spatial 
layout 
their  mental  model.  The  primary 
parameters  of  the  force-directed  model  that  are  being 
updated  through  this  learning  model  are  the  importance 
values of the entities.  
Document  Movement.  The  predominant  interaction  in  a 
spatial  workspace 
repositioning) 
documents.  In  previous  work,  we  have  demonstrated  how 
users can perform both exploratory and expressive forms of 
this type of interaction [9]. In ForceSPIRE, we allow for the 
following  exploratory  interaction  (i.e.,  interaction  that 
allows users to explore the structure of the current model, 
but  does  not  change  it).  Users  are  able  to  interactively 
explore the information by dragging a document within the 
workspace, pinning a document to a particular location (see 
Figure  8),  as  well  as  linking  two  documents.  When 
dragging a document, the force-directed system responds by 
finding the lowest energy state of the remaining documents 
given  the  current  location  of  the  dragged  document. 
Mathematically, this adds a constraint to the stress function 
being  optimized  (in  this  case  the  force-directed  model). 
This  allows  users  to  explore  the  relationship  of  that 
document in comparison to the remaining documents.  
In addition to the exploratory dragging of a document, users 
have the ability to pin a document. By pinning a document, 
users  are  able  to  incrementally  add  semantic  meaning  to 
locations in their workspace. By specifying key documents 
to  user-defined  locations,  the  layout  of  the  remaining 
documents will adapt to these constraints. Thus, users can 
explore  how  documents  are  positioned  based  on  their 
similarity  (or  dissimilarity)  to  the  pinned  documents.  For 
instance,  if  the  layout  places  a  document  between  two 
pinned  documents, 
the  particular 
document holds a link between the two pinned documents, 
sharing entities that occur in both. 
Finally,  users  can  perform  an  expressive  form  of  this 
interaction  by  linking  two  documents,  performed  by 
dragging  one  document  onto  another  pinned  document.  In 
doing so, ForceSPIRE calculates the similarity between the 
documents,  and  increases  the  importance  value  of  the 
entities  shared  between  both  documents.  As  a  result,  the 
layout will place more emphasis on the characteristics that 
make those two documents similar. 
Highlighting.  When  highlighting  a  term,  ForceSPIRE 
creates an entity from the term (if not already one), and the 
importance  value  of  that  term  is  increased.  Similarly, 
highlighting  a  phrase  results  in  the  phrase  being  first 
parsed for entities, then increasing the importance value of 
each  of  those  entities.  For  example,  Figure  11  shows  the 
effect of highlighting the terms “Colorado” and “missiles” 
in the document pointed to with the arrow. As a result, the 

it  may 

imply 

that 

 
Figure  9.  The  Effect  of  adding  an  annotation  (“these 
individuals  may  be  related  to  Revolution  Now”)  to  the 
document shown with an arrow. As  a result,  the document 
becomes 
linked  with  other  documents  mentioning  the 
terrorist organization “Revolution Now”.  

presence of these displays creates an environment in which 
the  virtual  information  (in  this  case  the  documents)  can 
occupy  persistent  physical  space.  As  a  result,  users  are 
further  immersed  into  the  spatial  metaphor,  as  they  can 
point and quickly refer to information based on the physical 
locations.  
Constructing the Spatial Metaphor 
The spatial layout of the text documents is determined by a 
modified  version  a  force-directed  graph  model  [11].  This 
model  functions  on  the  principle  of  nodes  with  a  mass 
connected  by  springs  with  varying  strengths.  Thus,  each 
node has attributes of attraction and repulsion: nodes repel 
other  nodes,  and  two  nodes  attract  each  other  only  when 
connected  by  a  spring  (edge).  The  optimal  layout  is  then 
computed  by  iteratively  calculating  these  forces  until  the 
lowest energy state of all the nodes is reached. A complete 
description of this algorithm can be found in [11].  
We  apply  this  model  to  textual  information  by  treating 
documents  as  nodes  (an  overview  is  shown  in  Figure  6). 
The entire textual content of each document is parsed into a 
collection  of  entities  (i.e.,  keywords).  The  number  of 
entities corresponds to the mass of each document (heavier 
nodes  do  not  move  as  fast  as  lighter  nodes).  A spring  (or 
edge) represents one or more matching entities between two 
nodes.  Therefore,  the  initial  distance  metric  is  a  based  on 
co-occurrence  of  terms  between  documents.  For  example, 
two  documents  containing  the  term  “airport”  will  be 
connected  by  a  spring.  The  strength  of  a  spring  (i.e.  how 
close together it tries to place two nodes) is based on two 
factors:  the  number  of  entities  two  documents  have  in 
common,  and  the  importance  value  associated  with  each 
shared entity (initially, importance values are created using 
a  standard  tfidf  method  [16]).  The  sum  of  all  importance 
values add up to 1. 
The resulting spatial layout is one where similarity between 
documents  is  represented  by  distance  relative  to  other 
documents.  Similarity  in  this  system  is  defined  by  the 
strength of the spring between two documents. A stronger 
spring  (and  therefore  a  larger  amount  of  shared  entities) 
will pull two documents closer together, and thus represent 
two similar documents. 

 

 
Figure  10.  Searching  for  the  term  ”Atlanta”,  documents 
containing the term highlight green within the context of the 
spatial  layout.  Additionally,  the  importance  value  of  entity 
“Atlanta” is increased. 

other  documents  containing  that  term  are  clustered  more 
tightly. 
Searching.  When  coming  across  a  term  of  particular 
interest, analysts usually search on that term in order to find 
other  occurrences.  In  a  spatial  workspace,  this  is  of 
particular  importance,  because  the  answer  to  “where  the 
term  is  also  found”  is  not  only  given  in  terms  of  what 
documents,  but  also  where  in  the  layout  those  documents 
occur. The positions of documents containing the term are 
shown in context of the entire dataset, from which users can 
infer the importance of that term (as shown in Figure 10).  
ForceSPIRE  first  creates  an  entity  from  the  search  term 
(unless  it  is  already  one),  then  increases  the  importance 
value  of  the  search  term.  Figure  10  gives  an  example  of 
how a search result appears in ForceSPIRE. Searching for 
the  term  “Atlanta”,  documents  that  contain  the  term  are 
highlighted  green,  and  links  are  drawn  to  show  where  the 
resulting documents are in relation to the current document.  
Annotation.  Annotations  (i.e.,  “sticky  notes”)  are  also 
viewed as a form of semantic interaction, occurring within 
the analytic process, from which analytic reasoning can be 
inferred. When a user creates a note regarding a document, 
that semantic information should be added to the document. 
For example, if Document A refers to “Revolution Now” (a 
suspicious  terrorist  group),  and  Document  B  refers  to  “a 
group of suspicious individuals”, and the user has reason to 
believe  these  individuals  are  related  to  Revolution  Now, 
adding a note to Document B stating “these individuals may 
be  related  to  Revolution  Now”  is  one  way  for  the  user  to 
add semantic meaning to the document.  
ForceSPIRE  handles  the  addition  of  the  note  (shown  in 
Figure 9) by 1) parsing the note for any currently existing 
entities,  then  2)  increasing  the  importance  value  of  each, 
and 3) creating any new springs between other documents 
sharing these entities. In the example in Figure 9, edges are 
created between Document B and Document A (as well as 
any  other  documents  that  mention  “Revolution  Now”). 
Additionally,  if  the  note  contains  any  new  entities  not 
currently in the model, they are created, with the intent that 

 

 
Figure 11. The effect of highlighting a phrase containing the 
entites  “Colorado”  and  “missiles”.  Documents  containing 
these  entities  move  closer,  as  the  increase  in  importance 
value increases the edge strength.  

the 

importance  values  of 

any future entities that may match to that note can be linked 
at that time. ForceSPIRE also handles cases where notes are 
edited,  with  text  added  or  removed  from  the  note,  by 
updating  the  entities  associated  with  the  document,  and 
adjusting 
these  entities 
accordingly. 
Model Updates 
Each  of  the  semantic  interactions  in  ForceSPIRE  impacts 
the  model  by  updating  the  importance  values  of  entities, 
and  the  mass  of  each  document.  The  calculation  for 
updating the importance value of an entity is the same for 
each interaction. If an entity was “hit” (i.e., it was included 
in  a  highlight,  it  was  searched,  it  was  in  a  note,  etc.), 
ForceSPIRE increases its importance value by 10%. As the 
sum  of  all  importance  values  of  entities  adds  up  to  1, 
ForceSPIRE  subtracts  an  equal  amount  from  all  other 
entities’ importance values. As a result, importance values 
decay over time, and entities that are rarely used during the 
analysis  have  less  impact  on  the  layout.  The  mass  of  a 
document  uses  a  similar  calculation,  in  that  each  time  a 
document  is  “hit”  (i.e.,  text  was  highlighted,  it  was  the 
result of a search hit, etc.), it increases by 10%.  
When  undoing  an 
standard 
the 
“Control+Z”  keyboard  shortcut,  a  linear  history  of  the 
interactions will be reversed, and the importance values of 
affected  entities  will  be  returned  to  their  prior  values  (as 
well  as  document  masses).  As  for  the  locations  of  the 
documents,  the  reverted  importance  values  and  document 
masses  will  be  responsible  for  updating 
layout. 
However, this does not guarantee that the layout will return 
to  the  exact  previous  view,  and  the  user  may  find  it 
necessary to perform small adjustments. 
The model updates used in ForceSPIRE serve as an initial 
approach at how to couple semantic interactions with model 
updates. Other, more complex methods may exist, and we 
encourage  further  research  in  this  area.  Sensemaking  is  a 
complex exploratory process. As such, semantic interaction 

interaction  using 

the 

through 

more  central  documents.  While  reading 
the 
documents, he highlighted phrases of interest. For example, 
he highlighted the phrase “Nizar A. is now known to have 
spent six months in Afghanistan”. In doing so, ForceSPIRE 
increased  the  importance  value  of  the  entities  within  the 
phrase,  particularly  “Afghanistan”  and  “Nizar  A”.  As  a 
result, the layout forms more tightly around those entities. 
Each change incrementally changes the layout. 
Continuing  with  his  investigation,  he  began  searching  for 
words  of  interest  (e.g.,  “weapons”,  “Colorado”,  “Atlanta”, 
etc.). ForceSPIRE provided him with quick visual feedback 
on where in the dataset each terms showed up (the search 
result  for  “Atlanta”  is  shown  in Figure  10).  In  addition  to 
gaining an overview of the distribution of the term within 
the  dataset  (by  highlighting  each  document  containing  the 
term  green),  ForceSPIRE  treats  performing  a  search  as 
either  creating  a  new  entity  from  the  search  term,  or 
increasing the importance value if an entity corresponding 
to the search term already exists. As a result of the multiple 
search terms and highlights corresponding to locations (e.g., 
“Atlanta”,  “Los  Angeles”,  “Missouri”,  etc.),  ForceSPIRE 
adapts  the  spatialization  by  creating  a  more  geographic-
oriented layout (shown in the “Mid Stage” layout in Figure 
12).  
During  further  investigation,  he  began  opening  more 
documents and adding annotations to documents where he 
found  information  missing  that  he  knew.  For  example, 
Figure  9  shows  how  he  opened  one  document  where 
“suspicious individuals” were mentioned. Earlier, he read a 
document  containing 
terrorist 
organization  named  “Revolution  Now”.  While  reading 
about  the  suspicious  individuals,  the  other  information  in 
the document triggered him to make a connection between 
these  individuals  and  Revolution  Now.  He  made  added  a 
note  to  the  document  about  the  suspicious  individuals 
stating  “these  individuals  may  be  related  to  Revolution 
Now”. As a result, ForceSPIRE parsed the note for entities, 
added  them  to  the  document,  and  pulled  the  document 
closer to other documents containing the entity “Revolution 
Now”.  
After  continuing  his  investigation  in  this  manner,  he 
ultimately  made  the  connections  within  the  dataset  to 
uncover  the  terrorist  plot.  The  progression  of  the  spatial 
layout,  shown  in Figure 12, shows the final layout, where 
he  was  able  to  pinpoint  regions  of  the  layout  as  being 
important  in  his  finding.  Some  of  the  spatial  locations  of 
clusters  are  a  result  of  him  pinning  documents  to  that 
region (e.g., “Atlanta”, “Los Angeles”, etc.). These pinned 
documents are shown in red. Perhaps more interestingly is 
not the regions that were created as a result of him pinning 
documents  to  that  location,  but  rather  how  the  remaining 
documents respond in the layout. For example, in the final 
state  shown  in  Figure  12,  a  group  of  documents  began  to 
emerge  in  the  middle  of  all  the  pinned  locations.  Upon 
examining  these  documents,  he  discovered  that  these 

information  about  a 

the 

layout 

 

interaction, 

instances  during 

 
Figure 12. The incremental change of the spatial layout (main 
view  of  ForceSPIRE)  from  the  initial  to  the  final  state. 
Through  semantic 
incrementally 
changed  based  on the  semantic  input of the user. We labeled 
the regions based on what the user told us the regions meant to 
him at each stage. 
can  enable  analysts  to  explore  their  hypothesis  in-situ, 
while  the  provenance  of  their  insights  is  captured  and 
stored. An open area of research is what analyzing the soft 
data might reveal about the analytic process. For instance, if 
the  importance  values  of  entities  converge  on  a  small 
number  of  entities,  specific  biases  might  be  revealed. 
Similarly, 
the  analysis  when  new 
hypotheses  are  being  explored  may  be  indicated  by 
diverging importance values. 
Use Case 
We  demonstrate  the  functionality  of  ForceSPIRE  through 
the  following  use  case.  In  this  scenario,  we  simulate  an 
intelligence  analysis  scenario  where  the  task  is  to  find  a 
hidden terrorist plot in a pre-constructed, ficticious textual 
dataset.  The  dataset  consists  of  50 
text  documents, 
containing  a  complex  terrorist  plot  (explosives  are  being 
transported to various cities in the U.S. using trucks). The 
combination of the task of finding the hidden terrorist plot 
and  the  textual  dataset  is  representative  of  daily  work 
performed  by  professional  intelligence  analysts  [8].  The 
analysis  described  below  lasted  70  minutes,  and  was 
performed  by  an  individual  computer  science  graduate 
student.  
The user began the investigation by loading the collection 
of  documents  into  ForceSPIRE.  The  documents  were 
automatically  parsed  for  entities  using 
the  LingPipe 
keyword  extraction  library  [1].  From  these  entities,  an 
initial layout was generated, shown in Figure 12(top). From 
this  layout,  he  began  investigation  by  reading  through  the 

 

interpreting 

leverage 

interactions 

DISCUSSION 
Unifying the Sensemaking Loop 
With the fundamentally different role occupied by semantic 
interaction, we explore a new design space for interaction in 
visual analytic tools. With the addition of soft data, and a 
model  capable  of 
the  user’s  analytical 
reasoning,  we 
that  are  already 
occurring in the spatial analytic process to further aid users 
in their sensemaking process.  
With  semantic  interaction,  the  amount  of  formalization 
between foraging and sensemaking (Figure 13) on the part 
of the user is reduced. For instance, in moving a document, 
users  can  formulate  a  hypothesis  based  on  that  document, 
expecting  similar  documents 
to  follow.  ForceSPIRE 
attempts to update the layout based on the interaction, and 
gives the user feedback. Thus, the foraging stage occurs as 
a  result  of  the  hypothesis  being  formed  through  semantic 
interaction.  By  not  forcing  users  to  over-formalize  their 
analytic  reasoning  too  early  in  order  to  forage  for  the 
relevant  information,  semantic  interaction  creates  a  more 
seamless 
transition  between 
foraging  and  synthesis, 
unifying the sensemaking loop.  
Future Work 
Semantic 
interaction,  as  a  concept,  opens  up  many 
possibilities for further research, such as: what interactions 
to  capture  and  store,  which  parameters  of  the  model  to 
update,  how  to  store  the  soft  data,  and  which  models 
present a metaphor that can be extended upon.  
In  order  to  make  more  concrete  claims  regarding  the 
usability  and  effectiveness  of  ForceSPIRE  (and  thus,  of 
semantic  interaction),  a  formal  user  study  is  needed.  Our 
plan is to introduce ForceSPIRE to professional intelligence 
analysts  and  have  them  solve  scenarios  that  model  their 
daily  task,  such  as  one  of  the  VAST  datasets  [2020].  The 
observations  and  feedback  from  these  users  will  provide 
ecological validity for semantic interaction. 
CONCLUSION 
In  this  paper  we  have  discussed  how  the  concept  of 
semantic  interaction  leads  to  a  new  design  space  for 
interaction 
information. 
Semantic  interactions  occur  directly  within  the  spatial 
metaphor,  support  spatial  cognition,  and  exploit  spatial 
analytic  interactions.  We  describe  semantic  interaction, 
discussing  the  three  components  required  –  capturing  the 
interaction, 
the  analytical  reasoning,  and 
updating  the  mathematical  model.  Further,  we  present 
ForceSPIRE, designed for semantic interaction with textual 
information, discussing its functionality and demonstrating 
how it can be used through a use case. Lastly, we discuss 
how  semantic  interaction  has  the  opportunity  to  unify  the 
sensemaking  loop,  creating  a  more  seamless  analytic 
process.  In  allowing  users  to  interact  within  the  spatial 
metaphor, they can remain more focused on their analysis 
of  the  data,  without  having  to  become  experts  in  the 
underlying mathematical models of the system.  

in  spatializations  of 

interpreting 

textual 

 

Figure  13.  The  sensemaking  loop,  illustrating  the  complex 
sequence  of  steps  used  by  intelligence  analysts  in  order  to 
gain insight into data.  
 
documents  are  about  the  terrorist  organization  using  “U-
Haul”  or  “Ryder”  trucks  for  transportation  between  these 
locations. ForceSPIRE placing these documents in between 
these  cities  in  the  layout  was  helpful,  as  these  documents 
contain  information  “connecting”  the  events  in  these 
locations.  Immediately  after  noticing  this  event,  he  also 
made use of the expressive form of interaction, performed 
by dragging two of these documents together to determine 
what  made  them  similar.  After  seeing  that  it  was  indeed 
terms  such  as  “Ryder”  and  “U-Haul”,  the  layout  formed 
more tightly around these terms. 
ForceSPIRE interpreted the analytical reasoning of the user 
through the creation of new entities that were not found by 
the  initial  keyword  extraction,  as  well  as  the  increase  of 
importance values of existing entities. This is evidenced by 
the  creation  of  39  new  entities  during  the  course  of  the 
analysis.  LingPipe  extracted  89  initial  entities  from  this 
dataset,  and  at  the  time  of  completing  our  investigation 
ForceSPIRE  included  128.  Examples  of  newly  created 
entities  are  “big  event”,  “grenades”,  “Fisher  Island”, 
“weapons”,  and  others.  The  ability  for  new  entities  to  be 
created  via  semantic  interaction  did  not  interfere  with  the 
fluid sensemaking process of the user. Instead, it aided the 
process  by  creating  new  entities,  which  in  turn  created 
semantically relevant connections within the dataset. 
In  addition  to  creating  new  entities,  existing  entities 
dynamically  changed  their  importance  value  based  on  the 
semantic 
interpreted 
reasoning 
interactions.  Examples  of  entities 
their 
importance  values  are  “Atlanta”,  “Revolution  Now”, 
“Colorado”,  “L.A.”,  and  others.  As  a 
the 
ForceSPIRE incrementally adapted the layout based on the 
user  input.  This  shows  that  adjusting  importance  values, 
creating entities, and changing locations of key documents 
helped  the  user  discover  the  structure  of  the  dataset,  and 
ultimately make out the hidden terrorist plot.  

of 
that  changed 

analytical 

result, 

the 

 

ACKNOWLEDGEMENTS 
This research was funded by the NSF grant CCF-0937071 
and the DHS center of excellence. 
REFERENCES 
1.  Alias-i. 2008. LingPipe 4.0.1. City, 2008. 
2.  i2 Analyst's Notebook. City. 
3.  Alsakran, J., Chen, Y., Zhao, Y., Yang, J. and Luo, D. 

STREAMIT: Dynamic visualization and interactive 
exploration of text streams. In Proceedings of the IEEE 
Pacific Visualization Symposium, 2011.  

4.  Andrews, C., Endert, A. and North, C. Space to Think: 
Large, High-Resolution Displays for Sensemaking. In 
Proceedings of the CHI '10, 2010.  

5.  Callahan, S. P., Freire, J., Santos, E., Scheidegger, C. E., 

C, Silva, u. T. and Vo, H. T. VisTrails: visualization 
meets data management. In Proceedings of the 
SIGMOD international conference on Management of 
data (Chicago, IL, USA, 2006). ACM.  

6.  Cowley, P., Haack, J., Littlefield, R. and Hampson, E. 

Glass box: capturing, archiving, and retrieving 
workstation activities. In Proceedings of the workshop 
on Continuous archival and retrival of personal 
experences (Santa Barbara, California, USA, 2006). 
ACM.  

7.  Dou, W., Jeong, D. H., Stukes, F., Ribarsky, W., 

Lipford, H. R. and Chang, R. Recovering Reasoning 
Processes from User Interactions. IEEE Computer 
Graphics and Applications, 2009. 

8.  Endert, A., Andrews, C., Fink, G. A. and North, C. 

Professional Analysts using a Large, High-Resolution 
Display. In Proceedings of the IEEE VAST Extended 
Abstract (2009).  

9.  Endert, A., Han, C., Maiti, D., House, L., Leman, S. C. 

and North, C. Observation-level Interaction with 
Statistical Models for Visual Analytics. IEEE VAST, 
2011. 

10. Frank M. Shipman, I. and Marshall, C. C. Formality 

Considered Harmful: Experiences, Emerging Themes, 
and Directions on the Use of Formal Representations 
inInteractive Systems. ACM CSCW, 8, 4, 1999, 333-352. 

11. Fruchterman, T. M. J. and Reingold, E. M. Graph 

drawing by force-directed placement. Software: Practice 
and Experience, 21, 11 1991, 1129-1164. 

12. Gotz, D. Interactive Visual Synthesis of Analytic 

Knowledge. IEEE VAST, 2006. 
13. Heer, J. prefuse manual, 2006. 
14. Heer, J., Mackinlay, J., Stolte, C. and Agrawala, M. 

Graphical Histories for Visualization: Supporting 
Analysis, Communication, and Evaluation. IEEE 
Transactions on Visualization and Computer Graphics, 
14, 6 , 2008, 1189-1196. 

 

15. Jeong, D. H., Ziemkiewicz, C., Fisher, B., Ribarsky, W. 

and Chang, R. iPCA: An Interactive System for PCA-
based Visual Analytics. Computer Graphics Forum, 28, 
2009, 767-774. 

16. Karen A Statistical Interpretation of Term Specificity 

and its Application in Retrieval. Journal of 
Documentation, 28, 1972, 11-21. 

17. Marshall, C. C., Frank M. Shipman, I. and Coombs, J. 

H. VIKI: spatial hypertext supporting emergent 
structure. In Proceedings of the European conference on 
Hypermedia technology (Edinburgh, Scotland, 1994). 
ACM.  

18. Olsen, K. A., Korfhage, R. R., Sochats, K. M., Spring, 
M. B. and Williams, J. G. Visualization of a document 
collection: the vibe system. Information Process 
Management, 29, 1 1993, 69-81. 

19. Pirolli, P. and Card, S. Sensemaking Processes of 

Intelligence Analysts and Possible Leverage Points as 
Identified Though Cognitive Task Analysis Proceedings 
of the International Conference on Intelligence 
Analysis,2005, 6. 

20. Plaisant, C., Grinstein, G., Scholtz, J., Whiting, M., 

O'Connell, T., Laskowski, S., Chien, L., Tat, A., Wright, 
W., Gorg, C., Zhicheng, L., Parekh, N., Singhal, K. and 
Stasko, J. Evaluating Visual Analytics at the 2007 
VAST Symposium Contest. Computer Graphics and 
Applications, IEEE, 28, 2 2008, 12-21. 

21. Shrinivasan, Y. B. and Wijk, J. J. v. Supporting the 

analytical reasoning process in information 
visualization. In Proceedings of the CHI '08 (Florence, 
Italy, 2008). ACM.  

22. Skupin, A. A Cartographic Approach to Visualizing 
Conference Abstracts. IEEE Computer Graphics and 
Applications, pp. 50-58, January/February, 2002. 

23. Thomas, J. J., Cook, K. A., National, V. and Analytics, 
C. Illuminating the path. IEEE Computer Society, 2005. 
24. Torres, R. S., Silva, C. G., Medeiros, C. B. and Rocha, 

H. V. Visual structures for image browsing. In 
Proceedings of the conference on Information and 
knowledge management (New Orleans, LA, USA, 
2003). ACM.  

25. Wise, J. A., Thomas, J. J., Pennock, K., Lantrip, D., 

Pottier, M., Schur, A. and Crow, V. Visualizing the non-
visual: spatial analysis and interaction with information 
for text documents. Morgan Kaufmann Publishers, 1999. 

26. Wright, W., Schroh, D., Proulx, P., Skaburskis, A. and 

Cort, B. The Sandbox for analysis: concepts and 
methods. In Proceedings of the CHI '06 (New York, 
NY, 2006). ACM.  

27. Yi, J. S., Melton, R., Stasko, J. and Jacko, J. A. Dust & 
magnet: multivariate information visualization using a 
magnet metaphor. Information Visualization, 4, 4, 2005, 
239-256. 

","{""pos"":{""0"":1,""1"":2,""2"":3,""3"":4},""0"":{""0"":""j"",""1"":""c*"",""2"":""m*"",""3"":""b""},""3"":{""0"":""spatial*"",""1"":""semantic"",""2"":""visual*"",""3"":""visualization*""},""1"":{""0"":""acm*"",""1"":""ieee*"",""2"":""atlanta*"",""3"":""virginia*""},""2"":{""0"":""model"",""1"":""figure"",""2"":""result"",""3"":""shown*""},""4"":{""0"":""users*"",""1"":""entities*"",""2"":""forcespire*"",""3"":""individuals""}}",2012,{},False,False,conferencePaper,False,8KJJXFM6,[],self.user,"{""Unnamed: 0"":{""0"":0,""1"":1,""2"":2,""3"":3,""4"":4,""5"":5,""6"":6,""7"":7,""8"":8,""9"":9,""10"":10,""11"":11,""12"":12,""13"":13,""14"":14,""15"":15,""16"":16,""17"":17,""18"":18,""19"":19,""20"":20,""21"":21,""22"":22,""23"":23,""24"":24,""25"":25,""26"":26,""27"":27,""28"":28,""29"":29,""30"":30,""31"":31,""32"":32,""33"":33,""34"":34,""35"":35,""36"":36,""37"":37,""38"":38,""39"":39,""40"":40,""41"":41,""42"":42,""43"":43,""44"":44,""45"":45,""46"":46,""47"":47,""48"":48,""49"":49,""50"":50,""51"":51,""52"":52,""53"":53,""54"":54,""55"":55,""56"":56,""57"":57,""58"":58,""59"":59,""60"":60,""61"":61,""62"":62,""63"":63},""C"":{""0"":8.4266472061,""1"":11.2896869022,""2"":20.1440855562,""3"":5.9718055352,""4"":7.0487790416,""5"":14.7837064376,""6"":7.1267305366,""7"":12.1121254103,""8"":7.9500130407,""9"":4.8974849172,""10"":5.3110256908,""11"":18.078332817,""12"":7.5682456791,""13"":10.8088348285,""14"":5.511061034,""15"":6.3740280947,""16"":29.1033319649,""17"":28.0128756912,""18"":8.4711840759,""19"":7.2706540282,""20"":10.2422514657,""21"":6.1074203174,""22"":4.7909956393,""23"":10.442184723,""24"":9.3334214408,""25"":10.9062732047,""26"":10.6768702293,""27"":5.7744811753,""28"":5.6706345749,""29"":10.0247219358,""30"":8.7807160348,""31"":5.651198606,""32"":10.5572880095,""33"":12.5448712135,""34"":6.9549925865,""35"":4.7037035622,""36"":11.7821753009,""37"":6.0135480384,""38"":4.7688877124,""39"":10.1144264323,""40"":4.7812199605,""41"":6.0536825246,""42"":8.3557215606,""43"":5.6415313773,""44"":4.8787214593,""45"":6.6525628838,""46"":5.4309345201,""47"":7.5229964972,""48"":6.3393032342,""49"":6.038552072,""50"":5.3938706788,""51"":6.4153499066,""52"":4.7147427449,""53"":5.923364503,""54"":6.0478015784,""55"":5.7843108461,""56"":6.0198175516,""57"":6.5889660473,""58"":7.429214174,""59"":6.2834932146,""60"":4.9709260215,""61"":6.1928146421,""62"":4.7177444158,""63"":4.7177444158},""count"":{""0"":186,""1"":174,""2"":128,""3"":124,""4"":116,""5"":116,""6"":102,""7"":90,""8"":76,""9"":70,""10"":66,""11"":66,""12"":64,""13"":56,""14"":54,""15"":48,""16"":44,""17"":40,""18"":34,""19"":32,""20"":32,""21"":30,""22"":30,""23"":28,""24"":26,""25"":24,""26"":24,""27"":22,""28"":22,""29"":22,""30"":20,""31"":20,""32"":20,""33"":20,""34"":18,""35"":18,""36"":18,""37"":16,""38"":16,""39"":16,""40"":14,""41"":14,""42"":14,""43"":12,""44"":12,""45"":12,""46"":12,""47"":12,""48"":10,""49"":10,""50"":10,""51"":10,""52"":10,""53"":10,""54"":10,""55"":10,""56"":10,""57"":10,""58"":10,""59"":8,""60"":8,""61"":8,""62"":6,""63"":6},""sigma_nor"":{""0"":1.5915740858,""1"":1.8205250827,""2"":2.6969215221,""3"":1.5020334735,""4"":1.612946636,""5"":2.2996277526,""6"":1.6566849233,""7"":2.1912677815,""8"":1.8359009285,""9"":1.525438363,""10"":1.5859204851,""11"":3.0482485684,""12"":1.8555597198,""13"":2.3035789069,""14"":1.6614936169,""15"":1.8069994833,""16"":4.9334253894,""17"":4.9351730364,""18"":2.2398914197,""19"":2.0822805523,""20"":2.5431984716,""21"":1.9231515785,""22"":1.7137411529,""23"":2.6541670573,""24"":2.5126870474,""25"":2.8279600872,""26"":2.7882486612,""27"":1.9665828468,""28"":1.9480272495,""29"":2.7260275996,""30"":2.5515321648,""31"":1.9730959769,""32"":2.87990021,""33"":3.2472699652,""34"":2.2540412355,""35"":1.8225608886,""36"":3.1792154132,""37"":2.1102124507,""38"":1.862162489,""39"":2.9274817951,""40"":1.8939603201,""41"":2.1584905672,""42"":2.6370578526,""43"":2.1124857434,""44"":1.9464613743,""45"":2.3325351476,""46"":2.0666496713,""47"":2.5219836434,""48"":2.3141015646,""49"":2.245288151,""50"":2.0977817309,""51"":2.3315014345,""52"":1.9423937649,""53"":2.2189326425,""54"":2.2474044857,""55"":2.1871164503,""56"":2.2410015963,""57"":2.3712257009,""58"":2.5634787961,""59"":2.3513756262,""60"":2.0342697675,""61"":2.3294683999,""62"":1.9937215647,""63"":1.9937215647},""vocab_index"":{""0"":0,""1"":1,""2"":2,""3"":3,""4"":4,""5"":5,""6"":6,""7"":9,""8"":10,""9"":12,""10"":13,""11"":14,""12"":15,""13"":16,""14"":17,""15"":22,""16"":26,""17"":28,""18"":31,""19"":37,""20"":38,""21"":39,""22"":43,""23"":46,""24"":53,""25"":59,""26"":61,""27"":67,""28"":68,""29"":70,""30"":73,""31"":78,""32"":80,""33"":81,""34"":84,""35"":89,""36"":90,""37"":99,""38"":100,""39"":101,""40"":102,""41"":128,""42"":129,""43"":132,""44"":150,""45"":155,""46"":157,""47"":159,""48"":169,""49"":184,""50"":198,""51"":199,""52"":200,""53"":201,""54"":202,""55"":203,""56"":204,""57"":205,""58"":206,""59"":260,""60"":264,""61"":266,""62"":267,""63"":268},""word"":{""0"":""interaction"",""1"":""documents"",""2"":""document"",""3"":""spatial"",""4"":""semantic"",""5"":""users"",""6"":""model"",""7"":""entities"",""8"":""forcespire"",""9"":""figure"",""10"":""visual"",""11"":""importance"",""12"":""data"",""13"":""visualization"",""14"":""metaphor"",""15"":""term"",""16"":""j"",""17"":""c"",""18"":""statistical"",""19"":""result"",""20"":""values"",""21"":""models"",""22"":""shown"",""23"":""a"",""24"":""value"",""25"":""nodes"",""26"":""search"",""27"":""foraging"",""28"":""workspace"",""29"":""note"",""30"":""m"",""31"":""individuals"",""32"":""containing"",""33"":""proceedings"",""34"":""acm"",""35"":""phrase"",""36"":""ieee"",""37"":""atlanta"",""38"":""b"",""39"":""r"",""40"":""usa"",""41"":""computer"",""42"":""d"",""43"":""domain"",""44"":""arrow"",""45"":""context"",""46"":""pinned"",""47"":""h"",""48"":""dimensional"",""49"":""pipeline"",""50"":""increases"",""51"":""began"",""52"":""vast"",""53"":""2008"",""54"":""conference"",""55"":""2006"",""56"":""w"",""57"":""graphics"",""58"":""k"",""59"":""regions"",""60"":""t"",""61"":""v"",""62"":""virginia"",""63"":""tech""},""vector"":{""0"":""[-1.0146911   0.45974797 -2.2006605  -0.32951418  0.38365647  5.805801\n -3.5028548  -2.2627747  -1.5441638  -6.0583253 ]"",""1"":""[-0.8149088  -0.05758966 -1.8061626  -0.54027086  0.525379    5.888296\n -3.0371895  -3.34467    -1.9669716  -6.060259  ]"",""2"":""[-0.9030161  -0.03263819 -2.1914217  -0.40165016  0.053866    5.818605\n -2.762541   -3.12432    -1.9432933  -5.7576094 ]"",""3"":""[-0.8736852   0.1921808  -2.530733   -0.03325944  0.66319495  5.847092\n -3.9834824  -2.3858178  -1.2019457  -5.716478  ]"",""4"":""[-0.99071175  0.09866843 -2.628436   -0.06703249  0.3834029   5.828568\n -3.7141192  -2.3803148  -1.3950622  -5.570219  ]"",""5"":""[-0.99775267 -0.12947395 -1.3001764  -0.7048167   1.1029902   5.965662\n -2.9643571  -3.1518767  -1.7317784  -6.1244516 ]"",""6"":""[-1.127103   0.1978366 -1.7879734 -0.6026337  0.3826592  5.844747\n -2.6573179 -2.427933  -1.6473299 -6.0177393]"",""7"":""[-0.9610707   0.07408552 -1.3486772  -0.6171226   0.8836041   5.974419\n -2.7748322  -3.1623187  -1.8417323  -6.204684  ]"",""8"":""[-1.0508912   0.01606372 -1.4398435  -0.8144081   0.7131056   6.000813\n -2.575953   -3.154801   -1.944377   -5.9780927 ]"",""9"":""[-1.2552164e+00  1.5215981e-01 -1.9685858e+00 -6.6352695e-01\n  1.0006794e-03  5.8391762e+00 -2.3441620e+00 -2.5312004e+00\n -2.0311334e+00 -5.8023448e+00]"",""10"":""[-1.1087849   0.20896624 -2.477523   -0.47998115  0.58292556  5.8337765\n -4.018372   -2.154887   -1.3443258  -5.6456795 ]"",""11"":""[-1.4066122  -0.09818583 -1.7890593  -0.94914305  0.253933    5.7732544\n -3.0586486  -2.642529   -2.6086948  -5.7314596 ]"",""12"":""[-1.0265995  -0.21003383 -1.8185092  -0.68778145  0.9379941   5.982647\n -3.6019228  -2.9071717  -1.7211559  -5.82493   ]"",""13"":""[-0.96654844  0.3693863  -2.140395   -0.583715    0.8404466   5.9536552\n -4.1130404  -2.2758942  -1.2846229  -5.9208055 ]"",""14"":""[-1.2354714   0.44991446 -2.1907592  -0.5641816   0.1090809   5.8286176\n -3.0929031  -2.147831   -1.8099613  -5.9341283 ]"",""15"":""[-1.0710083   0.316274   -2.4428792  -0.2823122  -0.16727236  5.8157377\n -2.8939352  -2.6008558  -2.0988967  -5.9678254 ]"",""16"":""[-2.1047335  -0.05568503 -0.8963235  -2.4145894   1.2473046   5.778081\n -4.0760436  -1.7970248  -2.8839126  -5.6023865 ]"",""17"":""[-2.264128  -0.2658352 -0.7289386 -2.6940534  1.1138971  5.6781883\n -3.7367487 -1.8873633 -3.2480633 -5.3497834]"",""18"":""[-0.96549165 -0.10803262 -2.3256664  -0.3519859   0.7250448   5.906088\n -3.8760173  -2.624317   -1.421497   -5.6320024 ]"",""19"":""[-1.2369485  -0.20932128 -2.6723263  -0.51875025 -0.23111872  5.921134\n -2.3401277  -2.7412348  -2.034661   -5.2430153 ]"",""20"":""[-1.3221291  -0.10508251 -1.3284093  -1.0144248   0.72035366  5.8377104\n -3.0026584  -2.6688275  -2.2755518  -5.97404   ]"",""21"":""[-1.0758206   0.10119182 -1.5450488  -0.71214736  0.7212778   5.870704\n -2.921237   -2.592609   -1.5915534  -6.0871034 ]"",""22"":""[-1.5055268  -0.38673186 -2.57742    -0.8144827  -0.2173147   5.771769\n -2.2070975  -2.630367   -2.104354   -4.844528  ]"",""23"":""[-1.3391224e+00 -4.2639664e-01 -2.7104325e+00 -5.0935012e-01\n -2.9676696e-04  5.8023891e+00 -2.6994171e+00 -2.6479847e+00\n -1.8030962e+00 -4.9036078e+00]"",""24"":""[-1.568642   -0.09927793 -1.5217427  -1.2841309   0.48502597  5.789509\n -3.106838   -2.402328   -2.5706003  -5.693751  ]"",""25"":""[-1.0288606   0.01659237 -1.3881894  -0.904711    1.1536257   6.0257554\n -3.2693908  -2.9338434  -1.62587    -6.046973  ]"",""26"":""[-0.97568035  0.15068218 -2.717022   -0.16136454 -0.08153129  5.81035\n -3.066863   -2.616971   -1.7200372  -5.5982475 ]"",""27"":""[-8.9166492e-01  2.8620744e-01 -2.6799955e+00  6.5695516e-05\n  3.0189598e-01  5.7910929e+00 -3.6303697e+00 -2.3573000e+00\n -1.3618282e+00 -5.6995268e+00]"",""28"":""[-1.0827209   0.18773751 -1.8908534  -0.81576115  1.0774477   5.9510903\n -4.1565986  -2.399035   -1.4892242  -5.998549  ]"",""29"":""[-1.2603474  -0.00879287 -2.384376   -0.60024595 -0.22857109  5.826298\n -2.419822   -2.6988342  -2.196652   -5.496713  ]"",""30"":""[-1.9272118  -0.12990838 -0.5790954  -2.7055824   1.2238735   5.6642303\n -3.9208665  -1.800853   -3.0657103  -5.575746  ]"",""31"":""[-1.0606776  -0.20645481 -1.2818921  -0.5916177   0.92513186  5.87177\n -2.735242   -3.1212835  -1.9700748  -6.169705  ]"",""32"":""[-1.3260951  -0.30487487 -2.67458    -0.62537026 -0.20564875  5.586755\n -2.3882658  -2.838941   -1.9546063  -4.8218966 ]"",""33"":""[-0.7869137   0.18587545 -2.049784   -0.68730664  0.43273005  5.8773866\n -3.4545624  -3.1618106  -2.0522563  -6.1650295 ]"",""34"":""[-1.9223336   0.03614163 -1.1523399  -2.0640364   1.2023559   5.917065\n -4.170124   -1.7783102  -2.4288197  -5.6756744 ]"",""35"":""[-1.1676401   0.24782343 -2.4086783  -0.38336906 -0.22130816  5.816956\n -2.680574   -2.5306458  -2.0020254  -5.745515  ]"",""36"":""[-1.7197127   0.12954092 -1.2146844  -1.9409626   1.1717702   5.9388595\n -4.2200966  -1.9810637  -2.2053719  -5.82586   ]"",""37"":""[-1.853723    0.08898474 -1.1746686  -1.8243093   1.3920233   5.8788896\n -4.4014473  -1.806556   -2.3207688  -5.7879257 ]"",""38"":""[-2.183162   -0.22800855 -0.58839846 -2.7039957   1.2327017   5.653518\n -3.6389053  -2.1185856  -3.2810915  -5.5084405 ]"",""39"":""[-2.238339    0.07618111 -0.83338076 -2.4299984   0.98283994  5.91917\n -3.732664   -1.6511885  -3.1341262  -5.6407704 ]"",""40"":""[-1.8286362   0.10899594 -1.2101971  -1.5852509   1.5704283   5.8811736\n -4.4404902  -1.8837135  -2.3681638  -5.8636007 ]"",""41"":""[-1.2238654  -0.01398859 -1.9752812  -0.8660783   0.9858791   5.840242\n -4.0465097  -2.4016538  -1.6154332  -5.9286966 ]"",""42"":""[-2.0470762  -0.19408125 -0.5046497  -2.7499652   1.2427082   5.662091\n -3.8633976  -1.962516   -3.0764074  -5.554111  ]"",""43"":""[-1.1802977   0.11664508 -1.7932541  -0.31037915  0.51177996  5.831658\n -3.0357475  -2.6159842  -1.941274   -6.1456714 ]"",""44"":""[-1.5184164   0.29629278 -1.9992477  -1.0064552   0.1079644   5.804814\n -2.8936322  -1.9883707  -2.0332627  -5.6470375 ]"",""45"":""[-1.1971502   0.18655655 -2.0019412  -0.43268278  0.14652692  5.823335\n -2.9414778  -2.6373594  -2.2032208  -6.0095477 ]"",""46"":""[-1.5019554  -0.2747346  -2.72266    -0.78721535 -0.3070272   5.737969\n -2.4220567  -2.450708   -2.0993502  -4.84428   ]"",""47"":""[-2.0600958  -0.02616582 -0.69695807 -2.5550802   1.1472898   5.8170776\n -3.8816683  -1.6396747  -3.0542965  -5.6257005 ]"",""48"":""[-0.9819449   0.13671093 -2.3455107  -0.21963282  0.8751115   5.824711\n -4.0981035  -2.2849975  -1.1683861  -5.785012  ]"",""49"":""[-0.98544294  0.03307873 -1.7855271  -0.77669203  0.92003417  5.9712896\n -3.6814198  -2.7346122  -1.6659731  -5.981419  ]"",""50"":""[-1.4483758  -0.59558976 -2.4733539  -0.71272117  0.06279489  5.875272\n -2.31394    -2.7792501  -1.9834659  -4.8816123 ]"",""51"":""[-1.5480081  -0.48134094 -2.49503    -0.8643058  -0.09468346  5.820538\n -2.295483   -2.616333   -2.1049623  -4.8294506 ]"",""52"":""[-1.2899603  -0.48938754 -2.5844564  -0.48755544  0.21803038  5.8579526\n -2.8660078  -2.6902833  -1.7054881  -4.9823365 ]"",""53"":""[-1.0339769   0.3023243  -2.4506416  -0.919194   -0.05898682  6.076795\n -2.6572044  -2.8422658  -2.4344752  -5.888468  ]"",""54"":""[-0.84007424  0.2731265  -2.2017155  -0.7559919   0.24980377  5.891508\n -3.350446   -3.0661235  -2.203073   -6.1238446 ]"",""55"":""[-1.0063754   0.16612898 -2.5016997  -0.8168898  -0.08263657  6.0296035\n -2.606325   -2.9016452  -2.3279557  -5.7748237 ]"",""56"":""[-2.3269308  -0.07785939 -0.607529   -2.771438    1.1432546   5.7736793\n -3.7635293  -1.7467067  -3.3988533  -5.5321426 ]"",""57"":""[-1.1257459   0.0728647  -2.1424468  -0.75964415  0.82094675  5.801223\n -3.9134564  -2.3774917  -1.4061497  -5.8999677 ]"",""58"":""[-1.9789577  -0.15315442 -0.87773013 -2.4456193   1.1003957   5.6586947\n -3.8451014  -1.9573534  -3.0241525  -5.5363374 ]"",""59"":""[-1.0091013  -0.01915083 -1.6011204  -0.9409501   0.9408217   6.0831485\n -3.075163   -3.081218   -1.9052716  -5.9802966 ]"",""60"":""[-2.2549355  -0.1163502  -0.43357018 -2.8814347   1.305257    5.719669\n -3.9903378  -1.8090675  -3.2375774  -5.591436  ]"",""61"":""[-2.2105103 -0.0460991 -0.7244313 -2.6748393  1.0512334  5.794876\n -3.7847195 -1.7277633 -3.247585  -5.537156 ]"",""62"":""[-1.8437417e+00  4.5388048e-03 -1.3055010e+00 -1.5646892e+00\n  1.4692740e+00  5.9063177e+00 -4.3463392e+00 -1.8591013e+00\n -2.3800545e+00 -5.7595186e+00]"",""63"":""[-1.4391633   0.05451877 -1.6642047  -1.2474096   1.1660062   5.8854504\n -4.2357297  -2.194768   -1.8898238  -5.879853  ]""},""topic"":{""0"":-1,""1"":-1,""2"":-1,""3"":3,""4"":3,""5"":4,""6"":2,""7"":4,""8"":4,""9"":2,""10"":3,""11"":-1,""12"":-1,""13"":3,""14"":-1,""15"":-1,""16"":0,""17"":0,""18"":3,""19"":2,""20"":-1,""21"":-1,""22"":2,""23"":2,""24"":-1,""25"":3,""26"":-1,""27"":-1,""28"":3,""29"":2,""30"":0,""31"":4,""32"":2,""33"":-1,""34"":1,""35"":2,""36"":1,""37"":1,""38"":0,""39"":0,""40"":-1,""41"":3,""42"":0,""43"":-1,""44"":-1,""45"":2,""46"":2,""47"":0,""48"":3,""49"":3,""50"":2,""51"":2,""52"":-1,""53"":-1,""54"":-1,""55"":-1,""56"":0,""57"":3,""58"":0,""59"":4,""60"":0,""61"":0,""62"":1,""63"":-1},""exemplar"":{""0"":null,""1"":null,""2"":null,""3"":""*"",""4"":null,""5"":""*"",""6"":null,""7"":""*"",""8"":""*"",""9"":null,""10"":""*"",""11"":null,""12"":null,""13"":""*"",""14"":null,""15"":null,""16"":null,""17"":""*"",""18"":null,""19"":null,""20"":null,""21"":null,""22"":""*"",""23"":null,""24"":null,""25"":null,""26"":null,""27"":null,""28"":null,""29"":null,""30"":""*"",""31"":null,""32"":""*"",""33"":null,""34"":""*"",""35"":null,""36"":""*"",""37"":""*"",""38"":null,""39"":null,""40"":null,""41"":null,""42"":""*"",""43"":null,""44"":null,""45"":null,""46"":null,""47"":""*"",""48"":""*"",""49"":null,""50"":""*"",""51"":""*"",""52"":null,""53"":null,""54"":null,""55"":null,""56"":null,""57"":""*"",""58"":null,""59"":""*"",""60"":null,""61"":""*"",""62"":""*"",""63"":null},""word*"":{""0"":""interaction"",""1"":""documents"",""2"":""document"",""3"":""spatial*"",""4"":""semantic"",""5"":""users*"",""6"":""model"",""7"":""entities*"",""8"":""forcespire*"",""9"":""figure"",""10"":""visual*"",""11"":""importance"",""12"":""data"",""13"":""visualization*"",""14"":""metaphor"",""15"":""term"",""16"":""j"",""17"":""c*"",""18"":""statistical"",""19"":""result"",""20"":""values"",""21"":""models"",""22"":""shown*"",""23"":""a"",""24"":""value"",""25"":""nodes"",""26"":""search"",""27"":""foraging"",""28"":""workspace"",""29"":""note"",""30"":""m*"",""31"":""individuals"",""32"":""containing*"",""33"":""proceedings"",""34"":""acm*"",""35"":""phrase"",""36"":""ieee*"",""37"":""atlanta*"",""38"":""b"",""39"":""r"",""40"":""usa"",""41"":""computer"",""42"":""d*"",""43"":""domain"",""44"":""arrow"",""45"":""context"",""46"":""pinned"",""47"":""h*"",""48"":""dimensional*"",""49"":""pipeline"",""50"":""increases*"",""51"":""began*"",""52"":""vast"",""53"":""2008"",""54"":""conference"",""55"":""2006"",""56"":""w"",""57"":""graphics*"",""58"":""k"",""59"":""regions*"",""60"":""t"",""61"":""v*"",""62"":""virginia*"",""63"":""tech""},""pos"":{""0"":1,""1"":2,""2"":3,""3"":1,""4"":2,""5"":1,""6"":1,""7"":2,""8"":3,""9"":2,""10"":3,""11"":4,""12"":5,""13"":4,""14"":6,""15"":7,""16"":1,""17"":2,""18"":5,""19"":3,""20"":8,""21"":9,""22"":4,""23"":5,""24"":10,""25"":6,""26"":11,""27"":12,""28"":7,""29"":6,""30"":3,""31"":4,""32"":7,""33"":13,""34"":1,""35"":8,""36"":2,""37"":3,""38"":4,""39"":5,""40"":14,""41"":8,""42"":6,""43"":15,""44"":16,""45"":9,""46"":10,""47"":7,""48"":9,""49"":10,""50"":11,""51"":12,""52"":17,""53"":18,""54"":19,""55"":20,""56"":8,""57"":11,""58"":9,""59"":5,""60"":10,""61"":11,""62"":4,""63"":21},""x2D"":{""0"":5.1053624153,""1"":2.2052004337,""2"":1.5555150509,""3"":5.5029296875,""4"":5.7455615997,""5"":3.0828664303,""6"":1.570779562,""7"":2.7757260799,""8"":2.9495048523,""9"":0.6821449399,""10"":5.7818508148,""11"":2.259806633,""12"":3.798885107,""13"":5.3684563637,""14"":1.2686476707,""15"":1.1818811893,""16"":-18.5178146362,""17"":-18.6294059753,""18"":5.2741160393,""19"":-0.3145881593,""20"":2.8261539936,""21"":2.6462287903,""22"":-0.8492141366,""23"":-0.3732075393,""24"":2.4580135345,""25"":3.3175239563,""26"":1.141073823,""27"":5.5207710266,""28"":4.7926182747,""29"":0.2627085447,""30"":-18.2495727539,""31"":3.1139543056,""32"":-0.5626488924,""33"":2.2994501591,""34"":-18.6289997101,""35"":0.6395167708,""36"":-18.8134975433,""37"":-18.9103717804,""38"":-18.0410919189,""39"":-18.6666412354,""40"":-18.7108764648,""41"":4.6521010399,""42"":-18.1908378601,""43"":2.0365352631,""44"":1.1899846792,""45"":1.5008049011,""46"":-0.7420284748,""47"":-18.6236877441,""48"":5.4653940201,""49"":4.1711001396,""50"":-0.7186219096,""51"":-0.8109298348,""52"":-0.3377493024,""53"":0.8615840673,""54"":1.8662140369,""55"":0.9256069064,""56"":-18.3871955872,""57"":5.0138816833,""58"":-18.388759613,""59"":3.2660636902,""60"":-18.1244163513,""61"":-18.6050281525,""62"":-18.9508304596,""63"":4.6230483055},""y2D"":{""0"":-0.1769365221,""1"":0.4568448365,""2"":-1.4108214378,""3"":0.3336576819,""4"":0.0458018184,""5"":0.6564816236,""6"":-0.174206242,""7"":0.690214932,""8"":0.2103714645,""9"":-0.9475626945,""10"":0.6120545268,""11"":-0.7565245628,""12"":0.5476783514,""13"":0.8785309792,""14"":-0.7235620618,""15"":-1.3630974293,""16"":13.6448221207,""17"":14.7387609482,""18"":0.5107907653,""19"":-2.3409283161,""20"":-0.2011116445,""21"":0.3986444771,""22"":-2.6352884769,""23"":-2.9402930737,""24"":-0.599865675,""25"":0.7345350981,""26"":-1.7853188515,""27"":0.0371928029,""28"":0.7964926958,""29"":-1.7255764008,""30"":14.1066799164,""31"":0.3413920999,""32"":-3.0135493279,""33"":0.1849061549,""34"":13.0443105698,""35"":-1.4213742018,""36"":12.8538789749,""37"":12.7313404083,""38"":14.5871772766,""39"":14.2765188217,""40"":12.6744174957,""41"":0.8735739589,""42"":14.2777528763,""43"":-0.1895020604,""44"":-0.5059697628,""45"":-1.0451809168,""46"":-2.9213895798,""47"":13.955745697,""48"":0.750187695,""49"":0.5921595097,""50"":-2.7114670277,""51"":-2.6085908413,""52"":-2.6484794617,""53"":-1.2079275846,""54"":-0.787878871,""55"":-1.5236403942,""56"":14.8017177582,""57"":0.5789060593,""58"":13.9764699936,""59"":0.4583012462,""60"":14.5150880814,""61"":14.5464162827,""62"":12.7000236511,""63"":1.2437583208}}",False,False,False,http://dl.acm.org/citation.cfm?doid=2207676.2207741,,Semantic interaction for visual text analytics,8KJJXFM6,False,False
ZMGBDR3L,T4TKQ4MM,"This is the author's version of an article that has been published in this journal. Changes were made to this version by the publisher prior to publication.

The final version of record is available at

 http://dx.doi.org/10.1109/TVCG.2017.2672987

The Subspace Voyager: Exploring High-Dimensional Data along 

a Continuum of Salient 3D Subspace 

 Bing Wang and Klaus Mueller, Senior Member, IEEE 

Abstract— Analyzing high-dimensional data and finding hidden patterns is a difficult problem and has attracted numerous research 
efforts. Automated methods can be useful to some extent but bringing the data analyst into the loop via interactive visual tools can 
help  the  discovery  process  tremendously.  An  inherent  problem  in  this  effort  is  that  humans  lack  the  mental  capacity  to  truly 
understand spaces exceeding three spatial dimensions. To keep within this limitation, we describe a framework that decomposes a 
high-dimensional  data  space  into  a  continuum  of  generalized  3D  subspaces.  Analysts  can  then  explore  these  3D  subspaces 
individually  via  the  familiar  trackball  interface  while  using  additional  facilities  to  smoothly  transition  to  adjacent  subspaces  for 
expanded  space  comprehension. Since the  number  of such  subspaces suffers  from  combinatorial  explosion,  we  provide  a  set  of 
data-driven  subspace  selection  and  navigation  tools  which  can  guide  users  to  interesting  subspaces  and  views.  A  subspace  trail 
map  allows  users  to  manage  the  explored  subspaces,  keep  their  bearings,  and  return  to  interesting  subspaces  and  views.  Both 
trackball and trail map are each embedded into a word cloud of attribute labels which aid in navigation. We demonstrate our system 
via several use cases in a diverse set of application areas – cluster analysis and refinement, information discovery, and supervised 
training of classifiers. We also report on a user study that evaluates the usability of the various interactions our system provides.  
Index Terms— High-dimensional data, subspace navigation, trackball, PCA, ant colony optimization

1.   IN T R OD UC T I ON 

to 

recognize 

tools 

D 

ATA  with  many  attributes  have  become  commonplace  in  a 
wide range of domains, such as science, business, medicine, 
etc.  In  these  data,  the  most  interesting  relations  are  often 
multivariate,  and  gaining  proper 
these 
relationships  reliably  is  still  an  active  area  of  research.  While 
automated  analysis  can  be  useful  in  finding  some  of  the  high-
dimensional patterns, adding the human into the loop can break ties 
and help discern patterns in confounding and noisy data settings that 
benefit  from  the  intricate  reasoning  faculties  of  human  domain 
experts.  However,  we  are  still  far  off  from  having  effective  visual 
tools  for  high-D  data  analytics  that  make  the  best  use  of  the  inborn 
capabilities  of  the  human  visual  system  and  at  the  same  time  also 
observe its limitations.   

High-D  space  is  generally  confusing  to  most  people  since 
humans  do  not  possess  the  innate  neural  network  to  recognize  and 
reason  with  high-D  objects.  Spatial  reasoning  skills  are  acquired  in 
early  childhood  where  often  haptic  and  visual  experiences  are 
combined to build 3D mental models of the real world. Since high-D 
objects are largely mathematical and do not occur in a tangible form, 
the associated cognitive reasoning chains are not developed in these 
critical  early  years.  This  lack  of  reasoning  faculties  represents  a 
barrier  for  most  people  when  dealing  with  high-D  data  later  in  life 
and so deprives them of the chance to find more insight in these data.  
We describe a framework and interface that eases this barrier by 
design, called the Subspace Voyager. It serializes the exploration of 
high-D  space  into  a  continuous  travel  along  a  string  of  generalized, 
but not necessarily dimension axis-aligned 3D subspaces, visualized 
as scatterplot projections of the data points. This serialization allows 
us  to  abolish  the  complex  interactions  and  representations  that  are 
often  typical  to  high-D  space  exploration  tools.  We  replace  them 
with  paradigms  familiar  to  most  people,  such  as  trackballs,  maps, 
and  word  clouds.  Our  interface  uses  these  to  help  users  explore  the 
generalized 3D subspaces, navigate the continuum of 3D subspaces, 
and assess the relevance of individual attributes for a given subspace.  
The  simplicity  gained  through  the  3D  subspace  decomposition 
comes at a price – the extent of the transformations defined on such a 
restricted  subspace  is  limited  and  may  not  reach  far  enough  to 
generate  a  projection  in  which  a  pattern  of  current  interest  is  well 

                               ———————————————— 

  Bing Wang and Klaus Mueller are with the Visual Analytics and Imaging 
Lab at the Computer Science Department, Stony Brook University, Stony 
Brook, NY. Email: {wang12, mueller}@cs.sunysb.edu. 

Manuscript received February 07. 2017. 

 

1 
 

expressed. To enable a reach beyond these limits we have augmented 
the 3D navigation interface with extra capabilities that allow users to 
“chase” the discovered patterns by moving to adjacent 3D subspaces 
via simple mouse interactions. In this way, patterns can be observed 
that are truly multivariate and not restricted to a single 3D subspace.  
In some sense, our approach is akin to that taken in an upcoming 
Indie  video  game,  Miegakure  [46]  (itself  inspired  by  the  classic 
novel Flatland [2]) which enables 4D space travel by swapping one 
of the three current dimensions. We go significantly further than this 
game:  (1)  our  spaces  are  much  greater  than  4D,  and  (2)  we  allow 
transitions  in  all  dimensions  simultaneously.  Yet,  it  is  encouraging 
that the entertainment industry sees fun in this type of space travel. It 
suggests that our interface might be fun and engaging as well, which 
will immensely benefit the analytics that is performed with it. 

The  3D  subspaces  our  system  supports  are  general  in  the  sense 
that they do not need to be constrained to three specific data axes but 
can be spanned by a basis of three arbitrary orthogonal vectors. This 
affords a better alignment with the high-D phenomenon under study 
and  effectively  allows  its  exploration  in  relation to  all  relevant  data 
dimensions. It, however, also brings about a huge number of possible 
subspaces.  To  manage  this  complexity  we  provide  a  variety  of 
objective-driven  search  and  clustering  facilities  that  assist  users  in 
locating subspaces with interesting structures. 

When  designing  our  interface  we  placed  great  emphasis  on 
making  the  interactions  direct,  intuitive,  and  responsive  [34].  Most 
exploration goals can be achieved by expressing them directly in the 
visualization,  via  simple  mouse  selections  and  transitions.  At  the 
same  time,  our  framework  is  quite  general  and  is  readily  applicable 
for  many  tasks  and  application  areas  that  involve  multivariate  data, 
such  as  cluster  sculpting  [30]  and  analysis,  information  discovery, 
and the supervised training of classifiers, just to name a few.  

In summary, the specific contributions of our work are: 

  A  serialization  of  high-D  space  exploration  into  a  journey 
within and across a string of adjacent generalized 3D subspaces 
  An  interactive  trackball  interface  for  3D  subspace  exploration 
augmented with direct controls for goal-directed transitioning to 
adjacent 3D subspaces – an activity we call cluster chasing 

  An illustrative, non-obtrusive labeling scheme that allows users 

to appreciate the influence of different variables on the display 

  Various  goal-directed  view  optimization  and  view  selection 
facilities  that  lower  the  subspace  navigation  overhead  and 
expand the search for interesting high-D phenomena 

  A  map-like  interface  organized  by  view  similarity  where  users 
can  store  interesting  scatterplot  views  and  construct  a  tour  for  
presentation within an animated scatter plot display 
Our  paper  is  organized  as  follows.  Section  2  reports  on  related 
research  motivating  our  work.  Section  3  focuses  specifically  on  the 

Copyright (c) 2017 IEEE. Personal use is permitted. For any other purposes, permission must be obtained from the IEEE by emailing pubs-permissions@ieee.org.

This is the author's version of an article that has been published in this journal. Changes were made to this version by the publisher prior to publication.

The final version of record is available at

 http://dx.doi.org/10.1109/TVCG.2017.2672987

TripAdvisorND  system  –  a  precursor  of  the  Subspace  Voyager. 
Section  4  provides  a  system  overview.  Section  5  describes  the 
trackball  based  subspace  explorer.  Section  6  presents  the  subspace 
trail map. Section 7 outlines three use scenarios. Section 8 describes 
our user study and its outcomes, and Section 9 offers conclusions. 

2.  RE L AT ED  W O RK   

Our principal visualization modality is  the scatterplot – a projection 
of the data into an orthogonal 2D basis.  In scatterplots, clusters and 
their  shapes  are  relatively  easy  to  recognize,  but  points  distant  in 
high-D space may project into similar  locations and this can lead to 
ambiguities. Helping users deal with these ambiguities is one of the 
major  aims  of  our  work.  Another  aim  is  to  aid  users  in  producing 
informative  projective  views  into  interesting  subspaces  of  the  data. 
In the following, we divide work related to ours into four aspects.      

Dealing with projection ambiguities  

One way to resolve projection ambiguities is to decompose the space 
into  a  matrix  of  axis-aligned  bivariate  scatterplots,  called  SPLOM 
[17]. While SPLOMs can help with disambiguation, users might find 
it  difficult  to  integrate  information  from  such  a  mosaic  of  plots, 
especially when the number of dimensions is even moderately large.  
Another approach is to use layout optimization schemes, such as 
Multidimensional Scaling (MDS) [24], Linear Discriminant Analysis 
(LDA)  [28],  and  Stochastic  Neighbor  Embedding  (t-SNE)  [42]. 
MDS,  for  example,  seeks  to  generate  a  layout  where  the  pairwise 
distances  of  points  in  2D  are  relatively  similar  to  those  in  high-D 
space.  But  even  with  layout  optimization,  trying  to  warp  high-D 
space  onto  a  2D  plane  is  inherently  ill-posed  since  it  cannot  fully 
capture multivariate data variations. Distortions are the consequence, 
making  it  difficult  to  correctly  recognize  the  true  shape  and 
appearance of clusters,  and also hampering the  assessment of point-
wise distances, both far and near. Hence, while ambiguities might be 
resolved, the risk of distortions has taken their place.   

A  third  alternative  is  to  enable  users  to  change  the  projection 
basis  in  a  continuous  fashion,  effectively  using  motion  parallax  to 
resolve  depth  and  relative  distance.  Several  systems  have  followed 
this  paradigm.  One  of  these  is  ScatterDice  [11].  It  restricts  the 
transitions  to  motions  between  two  bivariate  projections  at  a  time, 
giving  rise  to  a  dynamic  3D  point-cloud  projection  display.  More 
general  is  the  GGobi  system  [39],  itself  derived  from  the  seminal 
concept  of  the  ‘Grand  Tour’  [5],  as  well  as  the  TripAdvisorND 
framework  devised  by  one  of  the  co-authors  [31].  Both  allow  users 
to  transition  between  arbitrary  multivariate  projections.  Our  current 
framework  also  follows  this  general  paradigm  but  offers  interactive 
exploration  capabilities  that  greatly  exceed  those  provided  by  these 
earlier  systems.  For  example,  while  GGobi  also  uses  a  trackball,  it 
does  not  offer  the  advanced  subspace  exploration  facilities  our 
trackball interface provides.  

Defining a multivariate projection basis  

𝑁−1
𝑖=0

𝒗𝒊

Our layout is a generalized projection display where the 2D location 
p of a projected N-D data point x with coordinates xi, 0 ≤ i ≤ N-1, is 
given  by 𝒑 = ∑
𝑥𝑖.  Here,  the  vi  are  a  set  of  2D  basis  vectors 
with common origin O. We can use this formulation to compare our 
display  with  several  others  that  are  in  common  use.  In  Star 
Coordinates  [21]  all  basis  vectors  have  unit  length  and  by  ways  of 
changing  their  orientations,  users  can  interactively  increase  the 
spread  of  the  projected  data  points.  RadViz  [20]  is  similar  but 
includes a normalization by ∑
. Conversely, in biplots [14] the 
vector  basis  is  a  projection  of  the  axis  vectors  into  the  2D  frame 
spanned by the two major principal component (PC) axes. As a result, 
the vector v are typically not (all) unit length and their orientation is 
clearly defined. Projecting the data points into the PC-basis naturally 
maximizes their spread in the 2D display which removes the need for 
interaction. However, the projection ambiguity problems still remain.  
Our  display  is  similar  to  biplots  but  distinct  in  two  ways.  First, 
we  allow  users  to  change  the  biplot  projection  basis  interactively 

𝑁−1
𝑖=0

𝑥𝑖

which  helps  overcome  the  ambiguity  problems  via  motion  parallax. 
The transitions can affect many dimensions at once, and not just one 
at  a  time  like  in  Star  Coordinates  and  RadViz.  Second,  we  plot  the 
dimension  labels  at  the  display  periphery.  We  use  the  sizes  and 
opacities  of  the  dimension  labels  to  indicate  the  influences  of  the 
attributes on the projection. Conversely, biplots project the data axes 
as arrow-headed lines directly into the display leading to clutter.   

Selecting informative views 

The problem of projective view overload is not unique to SPLOMs. 
In many cases, it can be helpful to include proper quality criteria by 
which  the  most  informative  views  can  be  selected.  Research  in  this 
area has mainly addressed the selection of axis-aligned views in the 
presence of clustered or classified data. Sips et al. [37] define a class 
consistency measure which favors views based on the distance to the 
class center of gravity or on the entropies of the spatial distributions. 
Tatu et al. [40] assess quality by measures on density, histogram, and 
class  separation.  The  rank-by-feature  system  [36]  allows  users  to 
specify  certain  statistical  criteria,  such  as  correlation,  scatterplot 
uniformity,  etc.  Schäfer  et  al.  [35]  describe  a  quality  metric  that 
focuses  on  structural  preservation  and  visual  clutter  avoidance. 
GGobi  uses  projection  pursuit  [9][13]  to  generate  interesting 
multivariate projections. We use a popular evolutionary  algorithm – 
ant  colony  optimization  (ACO)  [10]  –  in  conjunction  with  view 
quality  metrics  such  as  stress,  class  density,  class  separation,  holes, 
and central mass.  

Finally,  a  problem  with  having many  projections  is  also how  to 
manage  and  organize  them.  Several  map-based  diagrams  have  been 
proposed [31][45].  We  provide  a  novel  map  that  is  dedicated  to  the 
management  of  generalized  subspaces.  In  addition,  our  map  also 
allows users to construct animated tours for presentation purposes. 

Managing interesting subspaces 

Subspace  clustering  has  been  an  active  research  area  in  the  data 
mining  community  [23]  but  the  focus  was  mostly  on  automated 
algorithms.  In  the  field  of  visualization,  one  may  distinguish  the 
contributions by how much they rely on automated subspace analysis 
methods. On one end are the works of Yuan et al. [44] and Kim et al. 
[22]  where  users  are  in  full  control.  The  former  proposes  a  visual 
subspace  exploration  approach  that  focuses  mainly  on  interactive 
dimension set selection and refinement. The latter suggests a system 
where  users  can  drop  data  points  into  two  different  groups  and  the 
projection  basis  vectors  are  updated  automatically.  Lehmann  et  al. 
[26] find minimal sets of projections, allowing  users to draw a path 
to  traverse  between  them.  In  our  system,  users  can  also  modify  the 
projection basis to favor certain dimensions, namely by emphasizing 
the influence of these dimensions directly in the interface.   

Other approaches first perform an automated subspace clustering 
step  and  then  visualize  the  results  as  small  multiples  of  scatterplot 
projections  [4],  as  MDS  layouts  [41],  or  use  animated  transitioning 
between them [27] akin to our map. We also first perform clustering 
but then use the results to provide guidance in the subsequent visual 
exploration  of  the  actual  subspaces,  focusing  on  cluster  appearance 
and relations. This can be helpful in the visual reasoning process.  

Related  in  some  respect  is  also  the  LineUp  system  by  Gratzl  et 
al.  [16].  LineUp  requires  users  to  manually  set  a  weight  for  each 
attribute to determine its influence on the rankings of the data items. 
However,  setting  weights  explicitly  might  not  be  intuitive  to 
mainstream  users  with  limited  quantitative  reasoning  abilities.  They 
may  simply  not  know  their  preferences  at  this  level  of  detail  but 
rather  discover  them  implicitly  during  data  exploration.  Our  system 
supports this type of exploratory discovery process.  

3.  REC AP: THE  T RI PADV IS O R N D F R AM EW O RK 

The  approach  we  have  taken  is  largely  motivated  by  our  earlier 
TripAdvisorND  framework  [31]  and  the  shortcomings  we  have 
observed in its use. One major improvement is the new trackball  

2 
 

Copyright (c) 2017 IEEE. Personal use is permitted. For any other purposes, permission must be obtained from the IEEE by emailing pubs-permissions@ieee.org.

This is the author's version of an article that has been published in this journal. Changes were made to this version by the publisher prior to publication.

The final version of record is available at

 http://dx.doi.org/10.1109/TVCG.2017.2672987

Shortcomings of TripAdvisorND motivating our work 

While the pad interface allows unprecedented control in the dynamic 
manipulation  of  the  view  onto  the  N-D  point  cloud,  the  need  to 
separately manipulate two pointers in sequence suffers from a certain 
lack of ergonomics. A further shortcoming is that users are required 
to keep track of two interfaces at the same time: (1) the visualization 
window  that  shows  the  moving  point  cloud  along  with  a  projected 
coordinate system, and (2) the pad that controls the orientation of the 
projection  plane.  In  practice,  a  user  may  observe  one  or  more 
dimensions  that  should  be  emphasized  in  the  display  as  they  might 
offer the potential to break up a cluster into two or more components. 
To do this, the user would need to looks at the pad to identify which 
pointer should be moved and in what direction, and then observe the 
effect in the display. In the present work,  we aimed for an interface 
that  makes  this  operation  more  straightforward  by  embedding  the 
navigation  controls  directly  into  the  display.  Enhancing  the  well-
known  trackball  interface  with  N-D  navigation  capabilities  seemed 
to be good choice toward this goal. We also added view optimization 
and  other  navigation  aids  to  support  the  manual  exploration, 
allowing users to arrive at meaningful projections faster. 

4.  S YS TEM  OV ERV IE W 

Fig.  2  shows  the  Subspace  Voyager  interface.  It  has  three  main 
components:  the  Subspace  Explorer  (SE),  the  Subspace  Trail  Map 
(STM),  and  the  control  panel.  The  latter  allows  users  to  set  the 
various parameters and modes in the system.  

The  exploration  pipeline  of  the  Subspace  Voyager  is  illustrated 
in Fig. 3. After loading the data, our system performs either Random 
Projection  or  Subspace  Clustering  and  Principal  Component 
Analysis  (PCA)  to  identify  an  initial  promising  3D  subspace.  More 
3D subspaces can be generated via the control panel at any time. 

The  data  is  then  projected  into  this  generated  subspace  and  is 
displayed  in  the  SE-embedded  trackball.  There  are  different 
interaction modes users can perform on the trackball. The first mode 

 

Fig.  1.  Pad-based  navigation  interface  of  TripAdvisorND.  In  the 
setting  shown,  the  PPA-x  vector  is  dominantly  a  combination  of 
dimension axis DA 4 and DA 5, while PPA-y is a combination of 
DA 6, DA 1, and DA 2. 

interface,  which  is  much  more  direct  than  the  spatially  disjoint 
navigation  pad  of  TripAdvisorND  (see  Fig.  1).  This  navigation  pad 
consists of a polygon with S vertices, where S is the cardinality of the 
subspaces.  Each  vertex  corresponds  to  a  native  dimension  –  hence 
the  subspaces  are  axis-aligned  (and  not  generalized).  It  should  also 
be noted that for S>3 different orderings of the vertices are required 
to allow users to access the full projection coverage of the subspace. 

The  interior  of  the  polygon  shows  two  disk-shaped  pointers. 
They represent the two (N-D) basis vectors into which the N-D point 
cloud  is  projected  for  display  using  the  vector  dot  product.  In  [31] 
these  two  vectors  are  called  Projection  Plane  Axis  (PPA)  vectors  – 
the  x-axis  is  PPA-x  and  the  y-axis  is  PPA-y.  The  vectors  are 
computed  from  their  positions  in  the  pad  polygon  via  generalized 
barycentric coordinate interpolation [29]. 

In  the  pad-based  interface,  users  can  control  the  influence  a 
dimension has on the display by moving either the PPA-x or PPA-y 
pointer  toward  that  dimension.  This  essentially  spreads  out  the 
projected  point  cloud  along  that  dimension  and  so  reveals  the 
dimension’s  ability  to  separate  the  data  points  into  different 
populations/clusters.  Then,  by  moving  the  other  pointer  toward 
another dimension, bivariate relationships can be visualized. Finally, 
when  moving  either  or  both  pointers  midway  between  a  set  of 
dimensions  users  can  appreciate  the  combined  effects  stemming 
from the multivariate relationships of these dimensions. 

Fig. 2. Subspace Voyager interface. It has three main components: the Subspace Explorer (SE), the Subspace Trail Map (STM) and the 
control panel. The SE is coupled with the trackball interface. It not only displays the data as a  scatterplot, but it also allows users to 
visualize the current directions of the projected dimension axis vectors as labels placed outside its circular boundary. The  labels are 
properly sized in terms of the corresponding attribute’s influence on the display. The SE offers various interactions for users to examine 
the data. The STM holds a set of views (and their parameters) that users may have found interesting during the exploration, embedding 
them into a word cloud of attributes. Finally, the control panel allows users to set the various parameters and modes in the system. 

3 
 

Copyright (c) 2017 IEEE. Personal use is permitted. For any other purposes, permission must be obtained from the IEEE by emailing pubs-permissions@ieee.org.

This is the author's version of an article that has been published in this journal. Changes were made to this version by the publisher prior to publication.

The final version of record is available at

 http://dx.doi.org/10.1109/TVCG.2017.2672987

 

Fig. 4. 3D trackball. Given the current and previous mouse clicks, 
both the axis of rotation and the rotation angle can be computed. 

indicate  to  what  extent  its  associated  attribute  is  expressed  in  the 
projection.  A  larger  and  bolder  font  means  that  the  scatterplot 
exhibits  more  of  the  attribute’s  variability.  The  label  placement,  on 
the  other  hand,  reveals  the  radial  direction  along  which  the 
variability  is  mostly  exposed.  The  simplest  form  of  trackball 
interaction  generates  scatterplot  projections  confined  to  the  current 
generalized  3D  subspace  projected  into  the  SE.  This  projected  3D 
subspace can be modified by:  
  Mouse-initiated  trackball  interaction:  users  can  transition  to 

adjacent 3D subspaces by augmented trackball interaction   

  Randomized  projections:  this  discovers  new  3D  subspaces  ready 

for trackball-based exploration    

  3D  Subspace  interpolation:  moving  a  slider  in  the  control  panel 
generates  a  continuous  set  of  3D  subspaces,  intermediate  to  two 
subspaces in the STM, which can be explored via the trackball 

  View  optimization:  the  3D  subspace  (as  well  as  the  current 
projection view within the current 3D subspace) can be optimized 
via projection pursuit driven by a user-defined set of criteria  

     The control panel provides several options for trackball  use. The 
checkbox  ‘TurnOff’  specifies  if  all  data  points  are  to  be  shown  or 
only those that are well described in the current subspace, i.e., belong 
to  that  subspace.  The  color  bar  on  the  bottom  right  is  the  brushing 
tool. It allows users to tag individual points or groups of points in a 
dedicated color to cluster them or mark them as inactive in gray.  

4.3 

The Subspace Trail Map (STM)  

The STM holds a set of views (and their parameters) that users may 
have  found  interesting  during  the  trackball  exploration.  The  view 
images  are  embedded  into  a  word  cloud  of  attributes.  Their 
placement  with  respect  to  each  word  indicates  the  influence  of  the 
corresponding  attribute  to  the  view.  We  treat  each  view  as  a  point 
and use PCA on all of them to spread them out. The circular shape of 
the  images  mimics  the  shape  of  the  trackballs.  A  smaller  diameter 
reduces overlap of similar views in the STM while a larger diameter 
provides  magnification.  Users  can  drag  any  view  back  into  the 
trackball  for  further  exploration,  or  they  can  connect  interesting 
views by lines to produce animated transitions for presentations.  

5.  THE  S UB SP ACE  E XP L OR ER   AND  TR AC K B AL L  I N TE R F ACE 

Users can tilt the trackball and watch the resulting scatterplot react to 
the motion. Fig. 4 sketches how a trackball works. Imagine a virtual 
sphere that encapsulates the current generalized 3D subspace. When 
clicked, the screen coordinate of the mouse is mapped to this sphere. 
Given  the  current  and  previous  mouse  clicks,  we  can  compute  the 
axis of rotation n and the rotation angle . From those two quantities, 
a 3×3 rotation matrix is derived, as described in [3].  

5.1 

Creating the Trackball Space Projection Matrix 

The trackball system only  works in 3D but our data points are N-D 
and so we need to project the ND points into 3D before rotating. We 
achieve this by post-multiplying the trackball rotation matrix T with 
the 3N projection matrix P. We have two options for the first two of 
the  vectors  in  P:  (1)  the  orthogonal  PPA  x-axis  and  y-axis  pair  we 
obtained  from  the  randomized  projection  procedure,  or  (2)  the  two 
most significant PCs we obtained when performing PCA for the 

Fig.  3.    Subspace  Voyager  workflow.  See  Section  4  for  a 
narration.  
is to rotate the trackball while pressing down  the left  mouse button. 
This enables an exploration of the current 3D subspace. The second 
mode allows users to transition to  adjacent subspaces where certain 
attributes  of  interest  have  a  higher  emphasis  than  in  the  current  3D 
subspace.  It  yields  data  projections  that  better  capture  the  cluster 
distributions  in  these  attributes.  In  this  cluster  chasing,  users  move 
the mouse – now with the right mouse button depressed – toward the 
respective attribute labels displayed on the trackball periphery. This 
increases the weight of these dimensions in the PPA vectors.  

As  mentioned,  in  our  system  there  is  no  need  for  manually 
optimizing  views  which  can  be  tedious.  Our  system  provides  Ant 
Colony  Optimization  (ACO)  [10]  to  generate  the  best  trackball 
configuration  automatically  according to  a  set  of  user-selected  view 
quality  criteria.  Users  can  also  tag  points  by  brushing  them  into 
different colors. This is helpful for cluster analysis or for editing out 
unwanted  structures.  Finally,  at  any  time  users  can  save  the  current 
trackball view to the STM to keep track of interesting findings. Any 
of these STM views can then be dragged back  into the trackball for 
further  exploration.  Multiple  small  views  can  also  be  linked  and 
traversed in order, providing a smooth transition between views.    

4.1  Generating a Set of Subspaces  

Choosing meaningful subspaces for exploration is a key challenge in 
multivariate data analysis and much work has been dedicated toward 
this goal (see Section 2). We have implemented two such strategies: 
(1)  random  view  generation  and  (2)  subspace  clustering.  Users  can 
generate new subspaces at any time via the control panel.   

For the former (1), we use the technique proposed by Anand et al. 
[1]  and  then  further  optimize  the  subspace  using  ACO  powered 
projection  pursuit  (see  Section  5.4).  For  the  latter  (2)  we  assume  – 
similar  to  Liu  et  al.  [27]  and  our  own  work  [43] –  that  each  cluster 
forms a subspace on its own. We characterize each such subspace by 
the three principal components obtained with PCA. Finally, for both 
of these methods, we use ACO view optimization to generate a high 
quality  (given  the  chosen  metric)  scatterplot  projection  in  the 
trackball display. 

We should also note that in a view that has the PC vectors as its 
basis  if  two  (or  more)  dimension  vectors  are  very  close,  it  means 
they are to some extent correlated. This is especially true when these 
dimensions  have  large  weightings  in  one  significant  PC  (i.e.  these 
dimensions  are  strongly  correlated  [47]).  We  will  make  use  of  this 
relationship in the use case described in Section 7.1. 

4.2 

The Subspace Explorer (SE) 

The  SE  is  coupled  with  the  trackball  interface.  It  not  only  displays 
the  data  as  a  scatterplot,  but  it  also  allows  users  to  visualize  the 
current  directions  of  the  projected  dimension  axis  vectors  as  labels 
placed outside its circular boundary. The size and opacity of a label 

4 
 

Copyright (c) 2017 IEEE. Personal use is permitted. For any other purposes, permission must be obtained from the IEEE by emailing pubs-permissions@ieee.org.

This is the author's version of an article that has been published in this journal. Changes were made to this version by the publisher prior to publication.

The final version of record is available at

 http://dx.doi.org/10.1109/TVCG.2017.2672987

 

Fig. 5. Updating the PPA x-axis and PPA y-axis vectors by moving 
the mouse towards one or more dimensions. The influence of each 
dimension is weighted by a Gaussian function. 
selected cluster. In both cases we require a third orthogonal axis, call 
it  the  PPA  z-axis.  Since  this  is  N-D  space  we  have  a  number  of 
choices. We can either (1) randomly generate an N-D vector, or (2) if 
the PPA x-and PPA y-axes are generated via PCA, use the third most 
significant axis for the PPA z-axis.  

Note that the resulting vector is not necessarily orthogonal to the 
PPA  x-axis  and  the  PPA  y-axis.  To  make  it  orthogonal  we  use  the 
Gram-Schmidt  orthonormalization  process  [7]  to  find  orthogonal 
basis  vectors.  The  Gram-Schmidt  process 
linearly 
independent  vectors  and  produces  N  orthonormal  vectors  spanning 
the same N-D space. In practice, we keep the PPA x-axis and PPA y-
axis  which  are  already  orthonormal  and  run  Gram-Schmidt  to 
orthonormalize the PPA z-axis from the initially chosen vector. Once 
P is configured in this way, T is reset to the identity matrix, ready to 
be manipulated in the 3D trackball interaction.  

takes  N 

5.2 

Processing the Points within the Trackball Space 

With P in place, the following sequence of operations is executed for 
every  trackball  move:  (1)  compute  the  3N  compound  projection 
matrix  M=S∙T∙P,  where  S  is  an  optional  scaling  matrix  that  allows 
zooming  into  the  display,  and  (2)  multiply  each  N-D  point  vector 
VND  by  M  to  obtain  the  3D  points  V3D=M∙VND.  But  ultimately  we 
are only interested in the projection of the points into the coordinate 
system  spanned  by  the  PPA-x  and PPA-y  vectors  manipulated  with 
the trackball. This yields a set of 2D points, V2D, which are the first 
two components of V3D since the projection is orthogonal.  

We have not observed a significant delay in the direct projection 
of  N-D  points  in  the  operation  of  the  trackball.  But  first  pre-
computing  a  3D  point  cloud  right  after  construction  of  the  3D 
coordinate system and rotating them directly for the lifetime of P can 
reduce  the  number  of  computations  to  roughly  N/3  of  the  original 
computations.  We  have  not  chosen  this  intermediate  step  because  it 
requires extra storage which can be significant for large point clouds.  

5.3  Mouse Interactions within the Trackball Interface 

We  provide  three  modes  of  mouse  interactions  within  the  trackball. 
All  are  controlled  with  different  mouse  buttons  depressed.  The  first 
is the basic mouse interaction when the trackball is rotated within the 
current  3D  subspace.  It  is  performed  when  the  left  mouse  button  is 
depressed  (see  Section  5.2).  The  other two  operations  are  described 
in more detail in the following.  

Chase clusters in adjacent 3D subspaces  

5.3.1 
When  using  the  basic  3D  subspace  exploration  mode  (Section  5.2) 
we  frequently  observed  that  interesting  patterns  were  starting  to 
evolve but their full exposure was out of reach since it occurred in a 
different,  albeit  nearby,  subspace  (i.e.  a  subspace  that  could  not  be 
reached simply by 3D rotation). In these situations, we often felt the 
need to “break out” of the current 3D subspace in the direction of the 
trackball  movement  such  that  these  patterns  could  be  reached.  To 
solve  this  shortcoming  we  added  the  capability  to  smoothly 
transition  from  one  subspace  to  an  adjacent  one.  It  allows  users  to 
interactively  change  the  influence  of  the  data  dimensions  whose 

5 
 

projections  align  with  the  current  trackball  motion,  progressively 
increasing  their  bias  in  the  projection  matrix  P.  This  gives  the 
exploring user access to the adjacent 3D subspace where the patterns 
of interest are better expressed. It lets him/her explore the data with a 
higher emphasis on one or more attributes of interest.  

To engage into this mode of exploration users would release the 
left mouse button and instead press the right button while moving the 
mouse  in  the  direction  of  the  desired  dimension’s  projection,  as 
indicated  by  the  corresponding  attribute’s  label  on  the  trackball’s 
periphery.  The  further  the  mouse  is  moved  the  more  the  projection 
plane is tilted into the dimension’s axis  vector. Conversely,  moving 
backward  along  that  direction,  towards  the  center  of  the  trackball, 
decreases the influence of this dimension.   

As  Fig.  5  illustrates,  ideally  we  would  accomplish  this  task  by 
adding  (or  subtracting) 
increments  x=ka∙d∙sin()  and  y= 
ka∙d∙cos() to the PPA-x and PPA-y vectors, respectively, where   
is the angle between the mouse movement vector and the trackball x-
axis (the PPA-x vector). Here d is the distance the mouse moved in 
the  direction  of  the  projected  dimension  axis  vector  (positive  when 
moving towards the periphery, negative otherwise), and ka is a user-
adjustable  speed  constant  (we  use  the  dot  products  instead  of  the 
trigonometric functions). Subsequently, Gram-Schmidt is used to re-
orthonormalize  P  (see  Section  5.1),  using  the  original  PPA  z-axis 
vector.  One  problem  here  is  that,  after  Gram-Schmidt,  the  direction 
of  this  data  dimension  would  change  and  thus  there  might  be  other 
dimensions taking the selected one’s direction. We overcome this by 
fixing the selected dimension until the user releases the mouse.  

This basic approach generalizes to more than one dimension. Fig. 
5  illustrates  the  practical  case  in  which  there  are  two  or  more 
projected  dimension  axis  vectors  in  close  range  of  the  exploration 
direction.  This  might  be  an  indication  of  multivariate  relationships. 
To properly scale the axes vector influences geometrically, we apply 
a Gaussian weighting in terms of their direction misalignment.  This 
is done via the following equation: wd=exp(-kd∙dot(vm, vd)) where wd 
is  the  weight  applied  to  this  axis  vector,  vm and vd are the  direction 
vectors  of  the  mouse  and  the  axis  vector,  respectively,  and  kd 
determines  the  reach  of  the  Gaussian.  The  remaining  steps  are 
similar to the single-vector case described in the previous paragraphs. 
Our  system  also  supports  the  case  in  which  a  user  would  first 
select  an  attribute  via  a  mouse  click  on  the  trackball  boundary  but 
then move the mouse in a direction not necessarily aligned with the 
attribute’s dimension vector. This will gradually align the dimension 
vector  with  the  mouse  motion  and  move  the  attribute  label 
accordingly.  Again,  the  selected  dimension’s  weighting  changes 
according to the direction and length of the mouse movement. 

5.3.2  Go “deeper” into high-dimensional space 
By clicking the middle mouse button, our system generates a PPA-z 
vector  according  to  the  two  options  described  in  Section  5.1  and  a 
new orthogonal vector is computed using Gram-Schmidt. Then with 
a  trackball  up  (down)  motion,  the  emphasis  of  the  dimensions 
projecting on the PPA z-axis is increased (decreased). The effect  of 
this  operation  will  only  be  visible  once  the  trackball  is  rotated 
regularly  and  the  new  3D  subspace  is  exposed.  We  call  this 
functionality “deep” since the axis that is changed is the PPA z-axis 
(i.e. the axis pointing into the depth of the display). 

5.4 

Display of Attribute Labels on the SE Boundary 

As  mentioned,  in  order  to  better  comprehend  the  relationships 
between a scatterplot projection and the data dimensions (attributes), 
we  display  the  attribute  names  as  labels  along  the  SE  trackball 
periphery (see Fig. 6). The extent of  which  a dimension contributes 
to  the  projected  point  cloud  is  indicated  by  label  size  and  opacity. 
The  larger  and bolder  the  label’s  font is,  the  stronger  the  attribute’s 
contribution  to  the  plot.  The  location  of  each  label  is  computed  by 
the attribute’s weighting in the PPA-x and PPA-y vectors. Let wx be 
the  PPA-x  weighting,  and  wy  be  the  PPA-y  weighting.  Then  the 
angle  between  this  dimension  vector  and  the  positive  x-axis  is 
computed as α = atan(wy/wx). 

Copyright (c) 2017 IEEE. Personal use is permitted. For any other purposes, permission must be obtained from the IEEE by emailing pubs-permissions@ieee.org.

This is the author's version of an article that has been published in this journal. Changes were made to this version by the publisher prior to publication.

The final version of record is available at

 http://dx.doi.org/10.1109/TVCG.2017.2672987

                            (a)                                                               (b)                                                              (c)                                                                  

Fig. 6. Dimension label overlap prevention. (a) Naïve implementation causing label overlap; (b) Using our angular spacing scheme to 
prevent  label overlap; (c) Illustration of our label overlap prevention scheme. 

Preventing Overlapping Attribute Labels 

5.4.1 
In practice, attribute labels may come to print on top of one another 
(Fig.  6(a)).  This  occurs  because  several  dimension  vectors  overlap. 
We solved this problem by forcing labels to locate at least β degrees 
apart  from  their  neighbors.  Fig.  6(c)  shows  this  for  the  upper  left 
quadrant.  Here, 𝑑1 is  the  location  of  label1  located  γ  degrees  away 
′ is  the  location  of  neighboring  label2,  spaced 
from  PPA-y  and 𝑑2
𝛽′ degrees  away.  We  see  that 𝛽′ is  too  small  causing  the  two  labels 
to  overlap.  Therefore  we  introduce  a  small  displacement  which 
places  label2  at 𝑑2 .  Now  label1  and  label2  are  spaced 𝛽  degrees 
apart and no longer overlap. 

In experiments, we found that the best choice for β is dependent 
on  the  orientation  of  the  dimension  vector.  The  more  vertical  it  is, 
the  larger  β  should  be,  while  for  a  more  horizontal  alignment,  a 
smaller β will suffice. The following equation relates β to the angle γ 
between the vertical axis and the dimension vector (for the upper left 
quadrant only – the other three quadrants are related by symmetry): 

𝜃𝑣 − (𝜃𝑣 − 𝜃ℎ) ∗

            0 ≤ 𝛾 <  45°

γ

        β =   { 

 
          𝜃ℎ                                      45° < 𝛾 ≤  90°    

45°

Here, 𝜃𝑣 and 𝜃ℎ  are  constants  we  determined  for  the  maximal  font 
size  of  the  labels  which  occur  when  the  corresponding  dimension 
vectors  are  fully  projected.  The  angle   𝜃ℎ =  4°  is  the  displacement 
needed  when  γ  is  greater  than  45°,  while  an  angle  of 𝜃𝑣 = 24° is 
needed  when  γ=0°.  When  γ  is  between  0°  and  45°  we  determine  β 
via linear interpolation. Fig. 6(b) shows the configuration of Fig. 6(a) 
with our label displacement scheme enabled. 

We  also  found  that  while  displacing  the  labels  provided  for 
better  readability,  it  was  distracting  in  interactive  mode  when  users 
were rotating the trackball since it could lead to sudden jumps of the 
labels.  Hence  we  only  apply  the  overlap  removal  method  when  the 
projection  is  fixed  (after  releasing  the  mouse).  Conversely,  when  a 
dataset  has  many  dimensions,  the  label  overlap  can  never  be 
prevented. For this reason, we added a slider to the control panel by 
which  users  can  set  the  maximum  number  of  displayed  attribute 
labels.  These  can  be  the  most  significant  attributes  or  attributes 
manually selected by clicking on their labels with <ctrl> depressed.    

5.5 

Point Brushing, Tagging, and De-Activation 

Our interface also provides the ability to label a point (or a group of 
points)  with  a  color  chosen  from  a  palette.  This  is  useful  when 
monitoring  a  certain  point’s  (or  point  group’s)  behavior  when  the 
trackball  rotates.  It  greatly  helps  in  distinguishing  different  clusters 
or seeing sub-clusters emerge during motion.  

Conversely,  by  painting  a  selected  group  of  points  in  gray  they 
will become invisible and will be excluded from all further analysis. 
This  helps,  for  example,  in  recognizing  other  structures  that  were 
hidden or ambiguous before this removal. 

6 
 

6.  THE  S UB SP ACE  T R AI L  M AP   AN D VI EW  GEN ER AT I O N 

The  subspace  trail  map  (STM)  is  a  spatial  layout  of  thumbnail 
representations  of  views.  It  serves  three  purposes.  First,  it  enables 
users to keep track of the subspaces explored so far. These subspaces 
can  be  revisited  for  further  exploration.  Second,  it  serves  as  a 
presentation  platform  for  the  system  to  suggest  new  subspaces  not 
yet  explored.  Third,  it  permits  users  to  define  routes  along  which 
they  can  transition  between  two  or  more  of  these  subspaces, 
essentially  using  them  as  keyframes.  In  the  STM,  users  can  double 
click any view thumbnail and add  it back into the SE. For clustered 
data, all subspaces can be inserted into the STM at once by clicking 
the ‘AllSubspace’ button in the control panel.  

6.1 

Populating the Subspace Trail Map (STM) 

Each  view  thumbnail  in  the  STM  holds  the  view’s  2D  scatterplot 
embedded  into  a  circle  to  mimic  its  appearance  in  the  SE.  PCA 
analysis  is  used  to  ensure  a  well-spread  layout  of  the  view 
thumbnails  with  a  minimum  of  overlap.  If  overlap  occurs  the 
‘SmallViewSize’  slider  can  be  employed  to  lower  the  circle  sizes 
uniformly  (see  Fig.  11(i)).  Alternatively,  clicking  on  a  partially 
hidden view will bring it to the foreground.  

To  illustrate  how  the  STM  layout  works,  suppose  there  are 𝑝 
subspace views stored in the STM and the dimensionality of the data 
set is 𝑁. The three orthogonal PPA vectors (the PPA x, y, and z-axes) 
spanning a subspace j can then be formally expressed as: 

𝑁−1

𝑃𝑃𝐴𝑖𝑗 = ∑ 𝑤𝑖𝑗𝑘𝑑𝑘

 

𝑘=0

where 𝑖 is either x, y, or z, 0 ≤ j ≤ 𝑝 − 1, 𝑤𝑖𝑗𝑘 is the weighting of the 
𝑘𝑡ℎ  data  dimension  on  𝑃𝑃𝐴𝑖𝑗  and  𝑑𝑘  is  the  𝑘𝑡ℎ  dimension  axis 
vector.  We then use the L2 norm to define the overall  weighting of 
the 𝑘𝑡ℎ data dimension for the 𝑗𝑡ℎ  subspace: 

𝑊𝑗𝑘 =   √𝑤𝑥𝑗𝑘

2 + 𝑤𝑦𝑗𝑘

2 + 𝑤𝑧𝑗𝑘

2    

These weights define an N-D vector for each subspace: 

𝑆𝑗 = [𝑊0𝑗, 𝑊1𝑗 , 𝑊2𝑗 … 𝑊𝑝−1,𝑗] 

This  allows  us  to  treat  each  subspace  as  an 𝑁-D  point.  We  perform 
PCA on this space of points. We keep the first two PCs and project 
all points (subspaces) into this basis. Since PCA automatically seeks 
to  find  the  directions  that  maximize  the  variance  of  the  data  points, 
the view thumbnails will be organized in a way that reduces overlaps.  

Finally,  the  view  thumbnails  are  embedded  in  a  word  cloud  of 
dimension labels (see Fig. 2). These labels are likewise placed based 
on  this  PC-basis,  using  the  projection  strength  of  their  dimension 
vectors to define their sizes and opacities. To prevent clutter we only 
keep the labels of the ten most significant dimensions.   

Copyright (c) 2017 IEEE. Personal use is permitted. For any other purposes, permission must be obtained from the IEEE by emailing pubs-permissions@ieee.org.

This is the author's version of an article that has been published in this journal. Changes were made to this version by the publisher prior to publication.

The final version of record is available at

 http://dx.doi.org/10.1109/TVCG.2017.2672987

6.2 

 Subspace and View Optimization  

We  perform  view  optimization  for  several  tasks.  One  is  to  produce 
an  optimized  3D  subspace  from  a  higher  dimensional  subspace 
generated  via  subspace  clustering.  Users  may  also  use  it  on  the  fly 
when  interacting  with  the  SE:  (1)  during  exploration  of  a  3D 
subspace, and (2) for chasing clusters into neighboring subspaces. In 
the latter case, the view optimization can be set to perform the search 
within  a  narrow  range  of  dimension  increments,  or  across  an 
expanded range. Both of these applications aid users in the trackball-
based  exploration.  They  help  accelerate 
tedious  manual 
exploration  needed  to  find  a  view  that  fits  a  certain  view  quality 
criterion, such as a cluster or a class separation.  

the 

View optimization via ant-colony optimization   

6.2.1 
A  popular  view  optimization  method  in  the  context  of  high-D  data 
visualization  is  projection  pursuit.  Starting  from  any  projection, 
projection  pursuit  returns  the  PPA  x-axis  and  PPA  y-axis  that 
optimizes  a  targeted  projection  pursuit  index  (PPI).  A  number  of 
methodologies  have  been  proposed  for  this  task,  such  as  hill 
climbing  [8],  random  search  [32],  or  simulated  annealing  [9].  We 
have  strived  for  a  sophisticated  yet  comparably  easy-to-implement 
algorithm – Ant Colony Optimization (ACO) [10]. To the best of our 
knowledge, ACO has not been used for projection pursuit so far.  

General description of ant colony optimization (ACO) 

ACO  simulates  the  behavior  of  ants  in  nature.  When  looking  for 
food, ants initially travel randomly until they find food. On their way 
back  they  leave  a  pheromone  trace  along  the  route.  Instinct 
prescribes  that  other  ants  most  likely  follow  this  pheromone  trace 
instead  of  wandering  randomly.  But  pheromone  also  evaporates 
gradually,  and  so  over  time,  shorter  (lower  cost)  paths  will  be 
traveled  more  frequently  and  become  more  attractive,  leading  to  a 
convergence  on  the  optimal  path.  Based  on  this  intuition,  the 
simplest  ACO  algorithm  consists  of  the  following  three  steps 
executed  iteratively:  (1)  construct  solutions,  (2)  evaluate  solutions, 
and  (3)  update  pheromone,  increasing  it  on  low-cost  paths  and 
evaporating  it  on  others.  It  has  been  shown  that  the  solution  so 
generated is typically quite close to the optimal solution.  

The  ACO  algorithm  requires  a  discrete  search  space.  Projection 
pursuit,  however,  is  typically  performed  in  the  continuous  domain. 
General  solutions  that  address  this  problem  have  been  proposed 
[6][38] – we opted for a grid-based approach. In addition, ACO also 
requires an objective function to judge the quality of the solutions. In 
our case, this can be any view quality metric, no matter how complex. 
This  freedom  of  choice  is  enabled  because  ACO  does  not  require  a 
mathematical  derivation  of  a  gradient  measure  which  would  be 
needed for an analytical optimization scheme.  

Specific application of ACO for subspace and view optimization  

In our case, the search space is the set of all possible PPA x-axes and 
PPA  y-axes  and  the  objective  function  is  a  chosen  view  quality 
metric  –  low  stress  [24],  high  class-consistency  [37],  or  others.  To 
explain  how  ACO  works  for  this  application,  suppose  (with no  loss 
of generality) the simple case of a 2D data set with two data axes, d1 
and  d2,  where  the  PPA  x-axis  and  y-axis  can  be  represented  as 
𝑃𝑃𝐴𝑥 =   𝛼1𝑑1 + 𝛽1𝑑2 ,  and 𝑃𝑃𝐴𝑦 =   𝛼2𝑑1 + 𝛽2𝑑2.  There  are  four 
unknowns – 𝛼1, 𝛽1, 𝛼2 and 𝛽2 (for an N-D dataset there would be 2N 
unknowns).  As  an  illustration,  these  unknown  parameters  are 
represented as the four vertical gridded bars in Fig. 7. 

Our  ACO  algorithm  differs  from  the  traditional  one  in  the 
selection  of  the  initial pheromone  distribution.  While  the  traditional 
ACO  typically  begins  with  an unbiased  distribution,  ours  cannot do 
this  since  we  begin  from  an  initial  PPA  x-axis  and  y-axis 
configuration,  e.g.,  a  randomized  view  or  the  PC-basis  of  a  cluster. 
To  account  for  this,  we  increase  the  pheromone  of  this  view’s 
parameter levels, giving rise to  the red path in Fig. 7, which sets its 
levels to the discretized 𝛼1, 𝛽1, 𝛼2 and 𝛽2 values of this initial view.    

7 
 

 
 
 
 
 
 
 

 

2

             𝛼2                   𝛽

                      𝛼1               𝛽
Fig.  7.  Illustration  of  the  ACO  algorithm  in  the  discrete  domain. 
Each  vertical  bar  grid  point  stands  for  a  level  of  the  parameter 
represented  by  the  bar.  The  red,  piecewise  linear  polyline  is  a 
possible solution with the levels indicated by the bar intersections. 

1

Next,  a  generation  of  ants  is  set  free,  moving  across  the 
parameter  space  (from  left  to  right  in  Fig,  7)  selecting  levels  via 
pheromone-weighted  randomization.  While  the  levels  of  the  initial 
view  are  more  likely,  the  randomization  ensures  a  more  diverse  set 
of choices. After the whole set of parameters has been traversed, the 
generated  views  are  evaluated  by  the  chosen  view  quality  metric. 
The pheromone of each parameter level is then updated according to 
the  quality  of  the  views  it  was  part  of.  The  algorithm  stops  after  a 
fixed  number  of  iterations  and  for  each  view  parameter, 𝛼1, 𝛽1, 𝛼2 
and 𝛽2, the level with the highest amount of pheromone is chosen. 

Fig. 7 resembles a parallel coordinate display. We observed that 
after  the  single  initial  polyline,  ACO  tends  to  generate  many 
polylines  which  eventually  narrow  down  to  a  single  slim  cluster  – 
the optimized view.  

 ACO  can  also  be  constrained  to  produce  views  in  a  preferred 
interval.  For  example,  one  can  constrain  the  search  range  on  each 
parameter to be close to the initial path. This can be done  by fixing 
the  two  ends  of  the  vertical  bars  to  be  close  to  the  initial  values. 
Likewise, one can also loosen this condition and do a global search. 
In this case, the resulting view would be a global optimum according 
to different criteria. Finally, we should also take into account that the 
ACO  needs  to  return PPA  vectors,  which  are  required  to  be  of  unit 
length  and  orthogonal.  We  therefore  always  normalize  the  returned 
PPA  x-axis  and  then  use  Gram-Schmidt  orthonormalization  to  find 
the corresponding PPA y-axis. 

6.2.2  Other optimization capabilities  
Our  system  also  allows  users  to  select  several  dimensions  and 
produce  a  view  in  which  those  dimensions  are  equally  expressed.  
This produces plots similar to Star Coordinates or RadViz and can be 
useful in cases where  one wishes to see the influence of a subset of 
attributes  on  the  data.  It  is  achieved  by  clicking  on  the  respective 
labels  along  the trackball  while  depressing  the  ctrl-  and  space  keys. 
Then,  when  releasing  the  mouse,  the  weightings  for  the  selected 
dimensions are set to the maximum. A Gram-Schmidt step follows to 
orthogonalizes the transformation matrix. Fig. 8 shows an example.  

Illustrative use case 

6.2.3 
Fig.  9  shows  results  that  can  be  obtained  with  our  ACO-based 
subspace and view optimization framework using the sales campaign 
dataset  described  in  Section  7.1.  We  first  apply  simple  k-means 
clustering  using  the  Structure-Based  Distance  Metric  of  Lee  et  al. 
[25] and obtain three subspace clusters. A subsequent PCA analysis 
for each cluster establishes three separate 3D subspaces. Clicking the 
‘AllSubspace’  button  adds  all three  subspaces  to  the  STM  (see  Fig. 
9(a)). We color the three subspace clusters blue, magenta, and green, 
and color the circumference of each thumbnail view by the subspace 
it  represents.  We  observe  that  for  the  magenta  and  green  subspace 
views, 
the  focus  cluster  (magenta  or  green, 
respectively)  still  overlap  with  points  of  other  (co-)  clusters  – 
especially  for  the  magenta  subspace.  Next,  we  optimize  the  three 
subspace  views  using  distribution  consistent  criteria  [37],  shown  in 
Fig. 9(b-d). We observe that the blue cluster’s subspace and  

the  points  of 

Copyright (c) 2017 IEEE. Personal use is permitted. For any other purposes, permission must be obtained from the IEEE by emailing pubs-permissions@ieee.org.

This is the author's version of an article that has been published in this journal. Changes were made to this version by the publisher prior to publication.

The final version of record is available at

 http://dx.doi.org/10.1109/TVCG.2017.2672987

(a) 

(b) 

 (c) 

(d) 

Fig.  9.  Using  the  ACO-powered  subspace  and  view  optimizer  to 
optimize  the  visual  separation  of  three  subspace  clusters,  colored 
blue,  magenta,  and  green.  (a)  The  STM  with  the  thumbnail  views  of 
each  subspace.  The  color  of  each  thumbnail  circle  indicates  the 
subspace  cluster  it  shares  its  basis  with.  We  observe  that  the 
subspace PCs alone cannot isolate the subspaces well  – there is still 
a significant amount of cluster overlap. (b-d) Optimized subspaces for 
the  blue,  magenta  and  green  cluster,  respectively,  using 
the 
distribution  consistent  view  quality  criteria.  All  subspace  clusters  are 
now well separated from the others in their respective subspaces. 

instead  of  using  the  slider.  The  animation  provides  a  smooth 
transition  between  findings  when  presenting  the  results,  as  opposed 
to abruptly changing the views or simply cross dissolving them.   

7.  APP L IC AT I O N  EX AM P L E S 

In the following, we demonstrate the versatility of our framework by 
ways of applying it to a diverse set of use scenarios involving high-D 
data.  We  show  our  framework’s  application  in  (1)  visual  cluster 
analysis,  (2)  visual  item  discovery  and  selection,  helping  users  to 
recognize and negotiate tradeoffs among items, and (3) visual cluster 
refinement,  allowing  users  to  partition  feature-driven  clusters  based 
on  the  visual  expression  of  the  aggregation  of  these  features.  A 
fourth  use  case  –  the  visual  setup  of  a  classifier  in  the  presence  of 
intermixing outliers – is presented in the paper’s supplement.    

7.1 

Use Scenario #1:  Visual Cluster Analysis  

To  illustrate  the  trackball  interactions,  we  chose  a  multivariate 
cluster  analysis  task  involving  an  interactive  study  of  a  sales  force 
working for a large company. The dataset consists of 900 points (one 
per salesperson) and 10 attributes parameterizing the basic corporate 
sales pipeline. Briefly, a sales campaign begins with a lead  

                             (a)                                            (b) 
Fig.  8.  Equally  expressing  several  dimensions.  (a)  The  original 
projection. 
(b)  The  optimized  projection  where  %Complete, 
#Opportunity, and #Leads are equally expressed.  

projection  are  almost  unchanged.  This  is  because  the  three  clusters 
are already well separated here. Since we only run optimization in a 
close range of the original PC projection this view might already be 
the best compared to its neighbors. (Better views could possibly be 
obtained by expanding this range.) Conversely, the subspaces of the 
magenta  and  green  clusters  have  significantly  improved.  In  each 
panel,  the  respective  subspace  clusters  are  now  clearly  separated 
from the others.  

6.3 

Transitioning Between Subspaces  

Self-initiated  and  controlled  animation  can  be  a  helpful  paradigm 
for humans to understand how two or more different representations 
of  the  same  information  relate  to  one  another  [18][33].  We  have 
employed  animation  to  help  users  understand  how  two  subspaces 
relate to one another, with the added aim that this might also instill a 
better  understanding  of  the  high-D  data  space  in  a  larger  context. 
Users  can  select  multiple  thumbnail  views  in  the  STM  and  connect 
them with a path. Moving the ‘TraverseBtw’ slider then changes the 
PPA axis vectors from one subspace to another.  

Simply  linearly  interpolating  between  bases  of  PPA  axes, 
however,  would  lead  to  nonlinear  intermediate  projections.  We, 
therefore,  adopted  the  algorithm  by  Cook  et  al.  [9]  to  transition 
between the two subspaces using singular value decomposition. Fig. 
10  shows  three  snapshots  of  a  sequence  of  frames  from  such  an 
animation,  along  with  the  path  connecting  the  two  corresponding 
nodes  in  the  STM.  All  keyframes  and  the  path  connecting  them  are 
shown in panel (d). Panels (a) to (c) show intermediate views along 
the path, and the yellow dot in panel (d) indicates the view’s location 
in  panel  (b).  Since  these  still  frames  can  only  provide  a  limited 
illustration,  the  reader  is  encouraged  to  view  the  provided  video  to 
appreciate the insightful visual effect of this animation. 

Alternatively,  we  also  include  a  ‘presentation  mode’  where  a 
narrator  would  click  the  ‘Next’  button  to  go  to  the  next  keyframe 

                 (a)                                                     (b)                                                      (c)                                                              (d) 

Fig. 10. Transitioning between two subspaces marked in the STM using the animation slider. (a)(b) and (c) are three intermediate views. (d) 
is the animation path in the STM. The yellow dot indicates the location of the view in (b). The provided video has a complete animation. 

8 
 

Copyright (c) 2017 IEEE. Personal use is permitted. For any other purposes, permission must be obtained from the IEEE by emailing pubs-permissions@ieee.org.

This is the author's version of an article that has been published in this journal. Changes were made to this version by the publisher prior to publication.

The final version of record is available at

 http://dx.doi.org/10.1109/TVCG.2017.2672987

(a) 

(b) 

(d) 

(e) 

(g) 

(h) 

(c) 

(f) 

(i) 

Fig. 11. Analyzing the sales force dataset. (a) The dataset projected onto the first two PCs. There are three visually separable clusters -- the three 
sales teams under study. (b) STM with view thumbnails of  the overall space and the extracted subspaces for each of the three teams  -- each 
optimized such that its focus cluster is maximally separated from the others. (c)  Subspace of the blue team (d) green team subspace, and (e) 
magenta team subspace. (f) Increasing the weighting of PipelineRevenue and ExpectedROI by moving the mouse towards the respective labels 
(with right mouse button depressed). Both the green and magenta team generates more revenue than the blue team. (g) Increasing the weighting 
of #Opportunity along the PPA-y axis. The green team generates the fewest opportunities. (h) Increasing the weighting of Cost/WonLead. The 
green team is the most frugal, but has the most revenue, while the blue team is the most wasteful with not much revenue. (h)  STM setup for the 
animated presentation of these findings.    

generator  who  produces  prospective  customers  that  a  salesperson 
might  be  able  to  close  a  deal  with.  If  these  leads  receive  positive 
responses, they become won leads and receive a sales pitch at a cost 
per  won  lead.  Upon  further  positive  response,  they  become 
opportunities  or  potential  customers.  Cost  is  involved  in  every  step 
and high pipeline revenue is the ultimate goal. Three are three sales 
teams in our dataset.  

Step 1: explore the PCA view 

7.1.1 
Let us assume a sales team analyst, Pat, is about to analyze the data. 
He begins with treating the entire dataset as one cluster and performs 
PCA  –  shown  in  Fig.  11(a).  He  immediately  notices  that  there  are 
three  visually  separable  clusters  representing  the  three  sales  teams. 
These distinct clusters suggest that the three sales teams indeed seem 
to  apply  different  strategies  for  possibly  different  outcomes.  Pat 
clicks  the  ‘Apply’  button  to  load  the  cluster  information  from  the 
original data. The result (the thumbnail view on the bottom right side 
of panel (a)) confirms that the three clusters are indeed real clusters.  

Next,  Pat  examines  the  SE  boundary  in  Fig.  11(a).  He  notices 
that there are two groups of closely mapped  attributes with strongly 
printed  labels:  (1)  Expected  ROI  and  Pipeline  Revenue,  and  (2) 
LeadsWon and #Leads. As explained in Section 4.1, this means that 
the  attributes  in  each  of  these  groups  are  strongly  correlated.  Pat 
finds this view informative and saves it to the STM. 

Step 2: explore the salient subspaces 

7.1.2 
Next,  Pat  wishes  to  examine  the  subspaces  of  each  cluster.  He 
performs  PCA  on  all  of  them  and  adds  them  to  the  STM.  Pat  then 
optimizes each subspace  such that its focus cluster is best separated 
from the others. In Fig. 11(b), the view thumbnails outlined in blue, 
magenta,  and  green  are  the  subspaces  for  the  correspondingly 
colored clusters. The neutral view is the subspace for the entire data. 
Pat  first  brings  the  blue  cluster’s  subspace  back  to  the  SE  for 
closer  examination  (Fig.  11(c)).  He  notices  that  Cost  has  the  most 
prominent  label  and  that  the  blue  cluster  varies  significantly  in  this 
direction  –  more  than  the  two  others.  This  suggests  that  there  is  a 
wide diversity in the cost incurred by members of the blue sales team.  

9 
 

Copyright (c) 2017 IEEE. Personal use is permitted. For any other purposes, permission must be obtained from the IEEE by emailing pubs-permissions@ieee.org.

This is the author's version of an article that has been published in this journal. Changes were made to this version by the publisher prior to publication.

The final version of record is available at

 http://dx.doi.org/10.1109/TVCG.2017.2672987

Next,  Pat  brings  the  subspace  of  the  green  cluster  into  the  SE 
(Fig.  11(d)).  He  notices  that  in  this  subspace  #Leads  and  Cost  are 
most widely expressed (i.e. these attributes best distinguish the green 
sales team  from the others). From the plot, Pat learns that the green 
team,  with  its  cluster  being  most  closely  located  to  the  #Leads 
attribute,  seems  to  generate  the  most  leads,  while  the  blue  team 
generates the fewest. He also confirms the finding from the last view 
that the blue team seems to incur the highest cost.  

Lastly, Pat brings the magenta subspace into the SE (Fig. 11(e)). 
He  confirms  some  of  the  findings  of  the  previous  plots  and  also 
learns that PlannedRev, Cost and ExpectedROI are the attributes that 
have  the  highest  variance  for  this  group  of  data.  Finally,  he  also 
learns that the magenta sales team is separated from the other two by 
a combination of PlannedRev, #Opportunity and ExpectedROI. 

Step 3: look for differences in sales strategy 

7.1.3 
Pat  knows  that  high  Pipeline  Revenue  and  Expected  ROI  are 
important  targets  for  any  business.  He  decides  that  it  would  be  a 
beneficial  undertaking  to  explore  how  the  company’s  sales  force 
relates to these two revenue parameters.  

He  uses  the  STM  to  bring  the  initial  PCA  view  (small  panel  in 
Fig.  11(a))  back  to  the  SE.  He  presses  the  right  mouse  button  and 
moves the mouse in the direction of the two revenue parameters. Fig. 
11(f) shows the outcome. Note that the font of the two revenue labels 
gets  stronger  which  means  that  the  corresponding  two  attributes 
receive more weight in the viewed 3D subspace. The plot shows that 
both the green and magenta sales teams generate more revenue than 
the  blue  one  and  that  the  green  team  is  slighter  better  than  the 
magenta one. Pat also notices the #Opportunity attribute near the top 
of the plot and that it seems to separate the clusters well. He figures 
that revenue probably has a lot to do with the generated opportunities 
and he decides to give this attribute more emphasis.  

He  uses  cluster  chasing  to  emphasize  #Opportunity,  clicking  on 
its  label  and  moving  the  mouse  upwards  with  the  right  button 
depressed. He similarly emphasizes pipeline revenue and arrives at a 
traditional bivariate scatterplot that has pipeline revenue along PPA-
x  and  #opportunity  along  PPA-y  (see  Fig.  11(g)).  He  observes  that 
while  the  green  and  magenta  teams  vary  in  the  number  of 
opportunities – magenta creates more – both groups have somewhat 
similar revenue but green has a slight advantage. On the other hand, 
the blue team also has high #Opportunity but its revenue is low. 

So  why  does  the  blue  team  lack  revenue  despite  its  similar 
amount of opportunities? Pat knows that sales teams typically spend 
money to turn won leads into opportunities. He decides to make Cost 
per  won  lead  the  new  PPA-x  axis  by  selecting  it  from  the  attribute 
list  in  the  control  panel  (since  it is  not  visible  currently).  Fig. 11(h) 
shows  the  outcome.  He  quickly  notices  that  the  blue  team  incurs 
much  higher  cost  than  the  other  teams  and  that  the  green  team  has 
the  highest  pipeline  revenue.  In  fact,  the  green  team  is  the  most 
frugal having the narrowest cluster. 

Based  on these  discoveries, Pat concludes  that  while  generating 
many  opportunities  sounds  like  a  winning  strategy,  it  is  associated 
with  high  cost  and  therefore  the generated  revenue  tends  to  be  low. 
This  is  the  lesson  taught  by  the  blue  team.  It  thus  seems  better  to 
replicate  the  green  team’s  strategy  –  spend  little  cost  on  each  won 
lead and, despite gaining fewer opportunities, obtain higher revenue.       

Step 3: use the STM for sharing the findings 

7.1.4 
Pat is excited about his findings and plans a presentation to his group. 
He  notices  that  the  STM  is  too  cluttered  and  so  he  uses  the 
“SmallViewSize”  slider  to  reduce  the  size  of  the  view  thumbnails. 
Then  he  connects  them  by  simple  mouse  clicks  and  builds  a  path 
(bottom  panel  in  Fig.  11(i)).  Clicking  the  ‘Next’  button,  all  his 
findings can now be displayed sequentially, in an animated fashion. 

Conclusions from this use case 

7.1.5 
We believe that this example convincingly demonstrates how our SE 
interface  enables  users  to  playfully  arrive  at  different  multivariate 
scatterplot projections, quickly respond to new explorations ideas on 

10 
 

a  whim,  make  casual  observations  in  the  process,  and  just  as  easily 
return  back  to  a  traditional  bivariate  scatterplot  visualization.  The 
interested reader may watch the video to see the complete process. 

7.2 

Use Scenario #2: Visual Item Discovery & Selection    

Selecting  the  best  college,  given  the  many  personal  constraints  and 
preferences  one  might  have,  is  arguably  one  of  the  most  difficult 
choices a person will make in life. It involves the task of discovering 
the  set  of  schools  that  best  meet  one’s  personal  requirements, 
comparing them by weighing their trade-offs, and then selecting the 
college that fits best. Here we use the mixed dataset initially created 
by Nam and Mueller [31]. It has multi-faceted data on 50 of the top 
US colleges, enabling the college-seeking student to look at schools 
not only  through  the  lens  of  academics  but  also  through  the  lens  of 
social  life  and  the  general  environment  the  school  resides  in. 
Academic  ranking  and  tuition  information  were  extracted  from  a 
leading source of such information – the US News & World Report 
[49].  The  College  Prowler  website  [48],  on  the  other  hand,  ranks 
colleges  on  a  multitude  of  social  and  environmental  factors.  We 
picked  8  of  the  20  the  site  offers:  athletics,  campus  housing,  local 
atmosphere,  nightlife,  safety,  transportation,  academic  environment, 
and  weather.  Each  score  is  available  letter-graded  ranging  from  A+ 
to D-. We mapped these equidistantly to values in the range 0 to 1.  

The  College Prowler  website  allows  users  to  navigate  the  space 
of  college  attributes  by  filtering,  using  slider  bars  and  menu 
selections for each parameter to narrow down the search. This can be 
rather tedious and it also makes it difficult to recognize tradeoffs. We 
believe that our SE provides a more playful and targeted experience, 
while the STM is a better platform to save any intermediate findings.  
In  the  following,  we  shall  follow  17-year  old  Tina  who  is  just 
about  to  finish  high  school  and  see  how  she  uses  our  subspace 
voyager to find the university she feels best about. 

Checking out the relationships of attributes 

7.2.1 
Tina starts out with a view onto the dataset as a single cluster using 
the primary PC axes as a basis (Fig. 12(a)). As mentioned in Section 
4.1,  in  such  a  view  the  dimension  vectors  of  strongly  positively 
correlated attributes tend to coincide and as a result, their labels map 
to  similar  locations  along  the  trackball  boundary.  Conversely, 
negatively  correlated  attributes  will  map  to  opposite  sides  of  the 
trackball  boundary.  The  only  condition  for  both  is  that  their 
projection into the PC-axes basis is sufficiently significant, which is 
visually expressed in our system  by a large and heavy label font. In 
the  initial  view  of  Fig.  12(a)  Tina  observes  two  sets  of  positively 
correlated  attributes: 
(2) 
LocalAtmosphere,  NightLife,  and  Transportation.  She  also  observes 
a  few  negatively  correlated  attributes,  among  them:  (1)  Academic 
with  Weather  and  Athletics,  and  (2)  LocalAtomosphere  and 
NightLife,  with  Safety.  From  these  constellations,  Tina  quickly 
recognizes  that  top  academic  universities  tend  to  charge  higher 
tuition, but at the same  time, their athletic teams are not necessarily 
among the best. She also learns that universities built in nice town or 
city  areas  usually  have  better  nightlife  and  transportation  systems, 
but  they  also  tend  to  be  less  safe.  All  this  is  good  to  know  before 
engaging in the actual selection process described next.    

(1)  Academics  and  Tuition,  and 

Finding the set of schools that fit the best 

7.2.2 
Tina  does  not  come  from  a  wealthy  family  and  so  her  immediate 
focus is tuition cost. Her first step is, therefore, to select Tuition and 
move  the  mouse  towards  that  label  (to  the  left).  Next,  she  wants  to 
see which of the schools have a good academic ranking. She selects 
USNewsScore  and  moves  the  mouse  downward  to  maximize  the 
spread.  This  leaves  her  with  the  axis-aligned  scatterplot  shown  in 
Fig.  12(b).  In  this  plot,  all  points  on  the  lower  right  side  are  the 
universities  with  high  rankings  but  low  tuition  –  these  are  the  ones 
Tina is interested in the most. She colors them in magenta and asks 
the system to label them – in this case with the university names. 

Tina  likes  the  outdoors  a  lot  which  requires  the  weather  to  be 

generally good. So she adds Weather as another requirement to 

Copyright (c) 2017 IEEE. Personal use is permitted. For any other purposes, permission must be obtained from the IEEE by emailing pubs-permissions@ieee.org.

This is the author's version of an article that has been published in this journal. Changes were made to this version by the publisher prior to publication.

The final version of record is available at

 http://dx.doi.org/10.1109/TVCG.2017.2672987

(a) 

(c) 

(c) 

axis 

(b).  Make  Tuition  the 
PPA-x 
and 
USnewsScore  the  PPA-y 
The  magenta-
axis. 
colored, 
labeled  points 
are  the  schools  with  high 
US  News  Score  and  low 
Tuition.  

(b) 

(a).  The  PCA  view  of  the  entire 
dataset.  It  reveals  a  strong  positive 
correlation  between  Academic  and 
between 
Tuition, 
LocalAtmosphere,  NightLife, 
and 
Transportation.  

as  well 

as 

(c). Increase  Weather along the 
PPA-y  axis.    Purdue  moves  up 
revealing 
weather, 
TexaxA&M  and  UMaryland  do  not 
move  much  but  are  low  in  both 
scores. 

bad 

its 

(f) 

(d) 

(e). Increase Nightlife along the 
PPA-y  axis.  USCViterbi  has  the 
best  overall  score, 
followed  by 
UCLA, Georgia Tech, UCSanDiego 
and UC Berkeley.  

(e) 

(f). The final setup. The dimension 
four  dimension 

reveals 

projection 
groups.  

(d). 

Increase  Athletic  along 

the 
PPA-x  axis.    UCSantaBabara  has  a 
very low athletic score. 

Fig. 12. Finding the best college in the college dataset. 

                       Table 1 
Rankings of the final five candidates 
 

College 

Acad. 

Athletics  House  Atmos.  Night Life 

Safety 

Trans.  Weather  US News 

Tuition 

10 

10 

10 
10 
9 

10 

2 

11 
9 
8 

5 

8 

5 
8 
6 

12 

11 

10 
9 
11 

10 

12 

9 
8 
9 

9 

7 

7 
7 
11 

4 

8 

7 
10 
6 

11 

11 

8 
11 
12 

69 

77 

86 
89 
72 

22428 

22734 

22188 
14998 
14694 

UCLA 

USC-Viterbi 

Georgia Tech 

UC Berkeley 

UC San Diego 

11 
 

Copyright (c) 2017 IEEE. Personal use is permitted. For any other purposes, permission must be obtained from the IEEE by emailing pubs-permissions@ieee.org.

This is the author's version of an article that has been published in this journal. Changes were made to this version by the publisher prior to publication.

The final version of record is available at

 http://dx.doi.org/10.1109/TVCG.2017.2672987

USNewsScore by selecting the Weather label and moving the mouse 
in  the  downward  direction  (Fig.  12(c)).  This  enables  her  to 
appreciate any tradeoffs that may exist in these two variables.  

After  making  this  choice,  she  sees  ‘Purdue’  moving  away 
significantly. This means that even though its USNewsScore is quite 
good, it is not good enough to make up for the unfavorable weather.  
Likewise,  ‘GeorgiaTech’  also  moves  away  but  not  as  much  and  so 
Tina  keeps  it  marked  and  labeled.  ‘UMaryland’  and  ‘TexasA&M’ 
did not  move  too  much  either,  but  both  of  their  scores  are  not  high 
from  the  onset.  It  means  that  none  of  these  two  schools  does  well 
enough  in  either  UsnewScore  or  Weather  to  make  up  for  the 
moderate performance in the other attribute. Tina removes these two 
schools as well, repainting them to neutral blue.  

Tina  enjoys  the  excitement  of  college  team  sports.  She  is  also 
quite  athletic  and  she  thinks  she  might  be  able  to  secure  an  athletic 
scholarship to pay for her tuition. So she puts the Athletics attribute 
near  the  tuition  using  the  aforementioned  mouse  interactions  (Fig. 
12(d)). She notices that ‘UCSantaBarbara’ has a rather poor athletic 
score  and  henceforth  she  eliminates  that  school.  On  the other  hand, 
‘USC-Viterbi’  has 
followed  by 
‘GeorgiaTech’,  ‘UCLA’,  ‘UCBerkely’  and  ‘UCSanDiego’.  She 
keeps all them magenta colored and labeled. 

the  highest  athletic  score, 

Of course, Tina wants to have some fun in college. She focuses 
on  NightLife  and  moves  it  to  the  bottom  (Fig.  12(e)).  ‘USCViterbi’ 
moves  down  confirming  that  it  has  a  good  nightlife.  ‘UCBerkeley’ 
and  ‘UCSanDiego’  move  up,  indicating  that  they  may  have  good 
weather  but  the  nightlife  is  limited.  Conversely,  ‘GeorgiaTech’  and 
‘UCLA’ stay put – they are more balanced in those two factors. 

The decision – selecting the #1 school 

7.2.3 
Looking at the plot shown in Fig. 12(e) Tina sees that ‘USC-Viterbi’ 
might  be  the  best  candidate.  It  is  somewhat  in  the  middle  between 
Athletics  and  Nightlife  and  it  is  closest  to  the  circle  boundary 
indicating  that  it  has  the  highest  values  there.  Yet,  ‘GeorgiaTech’ 
and ‘UCLA’ are both not far behind and could be close contenders. 
In  order  to  gain  an  overall  impression,  Tina  puts  all  attributes  of 
interest  into  one  view.  She  tilts  the  trackball  and  creates  the 
configuration shown in Fig. 12(f). Four dimension groups emerge (1) 
Athletic and faintly Academic, (2) Tuition, (3) LocalAtmosphere and 
Transportation  (both  with  small  weighting),  (4)  NightLife,  Weather 
and  faintly  USNewsScore,  Safety,  and  CampusHousing.  Among  all 
those groups of factors, Tina values Athletic and Academic the most, 
and  so  she  chooses  ‘GeorgiaTech’  as  her  #1  top  choice  school  to 
apply for. 

Comparison with TripAdvisorND  

7.2.4 
We  purposely  conducted  a  similar  selection  task  than  Nam  and 
Mueller  in  [31],  and  a  partial  goal  of  this  use  case  was  to  compare 
the two systems. We obtained rather similar, almost identical results 
than  these  authors,  except  that  their  final  candidate  list  did  not 
contain ‘UCLA’. We compared UCLA’s scores with that of the other 
candidates (see Table 1) and found that except for a lower rating in 
transportation  and  a  slightly  lower  rating  in  USNewsScore,  it  is  not 
worse  in  other  aspects  and  hence  should  be  included  in  the  final 
candidate set. Especially in the final dimension group Academic and 
Athletic, it has a better combination of values than the other schools 
in the set, except for ‘Georgia Tech’.  

We 

think 

that  the  omission  of  ‘UCLA’  occurs  because 
TripAdvisorND’s  motion  trail  makes  it  sometimes  difficult  to 
precisely  follow  each  point.  But  the  motion  trail  is  needed  there  to 
convey  the  dynamic  movement.  Conversely,  with  our  trackball, 
motion  trails  are  not  required  since  the  perception  of  the  motion  is 
much  more  tightly  linked  to  the interaction  that  is  causing  it – both 
occur in the same interface.  

Another  advantage  of  our  new  system  is  that  users  no  longer 
need to take their eyes off the visualization while they are interacting 
to  change  the  view.  TripAdvisorND’s  touchpad  required  this.  It  also 
required  that  two  points  are  moved  separately  –  the  one  due  to  the 
PPA-x  and  the  one  due  to  the  PPA-y  vector.  With  our  trackball 

12 
 

interface, users can express these goals much more directly. In fact, 
they do not even need to be aware of the existence of these axes and 
vectors which we believe makes our interface much more appealing 
to general users.  

7.3 

Use Scenario #3 – Visual Cluster Refinement 

Often  high-D  data  are  derived  from  feature  analysis  where  the 
features themselves are not overly meaningful in isolation. Rather, it 
is the synthesis of all features that allow users to describe a grouping 
of  the  data  points.  In  this  process,  the  feature-based  clustering 
provides  the  organization  in  which  the  boundaries  of  the  individual 
groups can be delineated. We now demonstrate how our system can 
be used to allow humans to assist in creating and refining these kinds 
of  groupings  in  data,  using  visualization  as  a  gateway.  We  call  this 
process visual cluster refinement.  

images.  It  provides  a 

  We have selected an image classification tasks for this use case. 
The  CLEF  Cross-Language  Image  Retrieval  Track  (ImageCLEF) 
[50], launched in 2003, is an evaluation forum for the cross-language 
annotation  and  retrieval  of 
language 
independent platform where visual information retrieval systems can 
be  evaluated  for  analysis,  classification  and  retrieval  tasks.  The 
ImageCLEF  data  [15][51]  entails  three  sets  of  images  –   training, 
testing, and development. Each set uses different feature descriptors 
to describe the images, such as SIFT, color histogram, and GIST. We 
use  the  GETLF  feature  vector  from  the  development  set  of 
ImageCLEF 2013 [52], which is a 256-dimensional histogram based 
feature.  For  the  exact  information  on  how  to  generate  these 
descriptors, the reader is referred to [15]. 

In the following, we employ our Subspace Voyager as a medium 
to bring users into the loop of assessing and assisting the process of 
top-down  clustering  of  this  dataset.  Since  the  cognitive  processes 
driving  image  recognition  and  assessment  are  still  much  better 
developed in humans (as opposed to machines) a visual interface that 
allows humans to participate in this task can be very valuable.  

We begin by setting the initial number of clusters to a value of 2 
and  run  k-means  clustering  with  the  structure-based  distance  metric 
[25]  on  the  collection  of  points.  Fig  13  (a)(b)  shows  the  two 
subspaces in which the two clusters reside. Since the attribute labels 
on  the  trackball  boundary  are  rather  cryptic,  a  visual  assessment  of 
cluster  quality  is  difficult  and  even  more  so  is  their  interactive 
refinement. This can only be done by visualizing the semantics of the 
data points themselves – in this case, the underlying images.  

To  facilitate  this,  we  examine  the  two  clusters  separately  inside 
their own subspaces by turning off the other cluster. Similar to Liu et 
al. [27] we randomly select a subset of the data points in each cluster 
and  display  the  corresponding  images  next  to  them  (Fig.  13(c)(d)). 
We  notice  that  the  images  in  the  magenta  cluster  (Fig.  13(c))  are 
overall more saturated than those in the blue cluster (Fig. 13(d)). For 
the magenta cluster in Fig. 13(c) a clear change from yellow to black 
can  be  observed  along  the  PPA-y  axis,  with  yellow  sunsets,  yellow 
flames,  and  yellow-leaved  trees  on  the  bottom  of  the  distribution, 
mixed  with  increasingly  more  black  towards  the  top.  For  the  blue 
cluster in Fig. 13(d), the images on the bottom left are a paler green 
mixed  with  gray  while  those  on  the  top  are  mostly  blue  toned.  The 
images on the right half have a background that is mostly white, with 
the  main  objects  being  low  saturated.  The  differences  between  the 
two  clusters  in  Fig.  13  (c,  d)  are  obvious  and  this  confirms  that  k-
means can separate the dataset well at this level of the hierarchy. 

We  now  continue  this  process  and  further  partition  the  clusters 
using  k-means.  We  choose  the  blue  cluster  (Fig.  13(d))  since  its 
diversity  is  much  greater  than  that  of  the  magenta  cluster.  As  there 
seem to be three main categories of images we pick k=3. Figs. 13(e-
g)  show  the  results.  We  observe  that  the  classification  has  become 
more  specific.  The  sub-cluster  in  Fig.  13(e)  has  the  blue  images, 
fading out towards the bottom left. The sub-cluster of Fig. 13(f) has 
the  green  images,  again  fading  out  towards  the bottom  left.  Finally, 
the  sub-cluster  in  Fig. 13(g)  has the  saturated  images  or  the  images 
with white background. While this 2-level tree could already suffice 
for some applications, one more level of sub-clustering might  

Copyright (c) 2017 IEEE. Personal use is permitted. For any other purposes, permission must be obtained from the IEEE by emailing pubs-permissions@ieee.org.

This is the author's version of an article that has been published in this journal. Changes were made to this version by the publisher prior to publication.

The final version of record is available at

 http://dx.doi.org/10.1109/TVCG.2017.2672987

Fig.13.  Exploring  the  ImageCLEF  dataset.  (a)  The  subspace  of  the  blue  cluster.  (b)  The  subspace  of  the  dark  magenta  cluster.  (c)  The 
images in the dark magenta cluster. (d) The images in the blue cluster. (e-g) The three sub-clusters of the cluster in (d). 
 

separate  the  fully  saturated  images  from  the  less  saturated  ones  in 
each of the clusters obtained so far. Here the visualizations can help 
to determine where and whether such a step is required or desirable. 

8.  USER  STUDY 

To evaluate the features of our interface, we conducted a user study 
with 10 graduate students – 3 females and 7 males of diverse cultural 
background (4 North Americans and 6 Asians). None had experience 
in visual analytics. We sought to test whether the participants could 
fulfill certain data analysis tasks using our system. 

8.1 

Setup 

We invited all participants to sit down with us individually. We first 
showed  them  a  3-minute  intro  video  which  covered  all  basic 
interactions 
trackball 
interactions, saving views to the STM and bringing them back to the 
SE, and traversing between STM views. We used the Iris dataset [53] 
as a walk-through example in this video. 

the  Subspace  Voyager  supports  – 

the 

After  the  video,  each  participant  could  ask  questions  to  resolve 
any doubts. This was the only time  we entertained questions. Three 
participants  were  unclear  on  how  to  interpret  the  dimension  labels 
along the trackball -- a brief explanation resolved these doubts. Next, 
each  participant  was  asked  to  perform  three  tasks.  With  their 
consent,  we  filmed  the  computer  screen  to  record  their  operations. 
We  asked  them  to  speak  out  their  thoughts  during  the  entire  time, 
which we also recorded. We used both recordings in our study. 

8.2 

Tasks 

Our  tasks  were  designed  to  measure  three  levels  of  understanding 
[19]  gained  from  the  visual  interactions  –  shape,  organization,  and 
relations.  For  the  first  task,  we  used  a  somewhat  contrived  3D  data 
set: a hollow tube with a stick in the middle that was not aligned with 
any of the data axes. We asked the participants to describe the shape 

13 
 

of  the  data,  first  using  the  SPLOM  (Fig.  14(a))  and  then  using  the 
Subspace Voyager (Fig. 14(b)). 

The  second  task  measured  visual  understanding.  We  did  not 
inform the participants about the nature of the dataset. We initialized 
the  STM  with  two  scatterplots  of  the  sales  force  data  (Fig.  15(a-b)) 
and  asked  the  participants  to  describe  what  they  saw  in  these  two 
plots.  Then  we  encouraged  them  to  transition  between  the  two 
scatterplots and again asked them to describe their impressions. 

For  the  data  understanding  task,  we  also  used  the  sales  force 
dataset  but  now  we  first  showed  the  participants  a  1-minute  video 
that  introduced  the  attributes  of  the  data.  The  initial  trackball 
configuration is shown in Fig. 16(a). In this view, the clusters for the 
three teams overlap. The participants were told that there were three 
sales teams, who used different sales strategies and that the task was 
to determine which of the strategies was best to reach high revenue. 

8.3 

Result   

The  following  results  also  include  a  comparative  study  with  the 
TripAdvisorND interface, using the same data and participants.  

Task 1 – Shape understanding 

8.3.1 
Not a single participant found the hidden stick in the SPLOM. This 
was to be expected since this structural feature can only be observed 
from  a  non-axis  aligned  angle.  Eight  participants  asked  for  pen  and 
paper  to  reconstruct  the  distribution  of  the  data  but  none  got  it 
completely right. Descriptions were ‘tilted cylinder’ or ‘oval prism’.   
On the other hand, using our trackball’s rotation functionality, all 
participants managed to find the hidden stick. They spent 48 seconds 
on  average  for  this  task.  Some  of  the  descriptions  given  were  ‘pipe 
with something in the middle’, ‘cylinder with some coaxial cable’, or 
‘two  concentric  cylinders’.  Fig.  14(c)  and  (d)  shows  two  typical 
views  the  participants  generated  and  which  helped  them  draw  their 
conclusions. This high success rate demonstrates that our trackball is 
able to help users understand the structure of data.  

Copyright (c) 2017 IEEE. Personal use is permitted. For any other purposes, permission must be obtained from the IEEE by emailing pubs-permissions@ieee.org.

This is the author's version of an article that has been published in this journal. Changes were made to this version by the publisher prior to publication.

The final version of record is available at

 http://dx.doi.org/10.1109/TVCG.2017.2672987

                      (a)                                             (b)                                                       (c)                                                   (d) 

Fig. 14. User study 1: shape understanding. We asked the participants to use both (a) SPLOM and (b-d) our system to examine the shape 
of the data. (b) The initial view in the SE. (c, d) Two typical views the participants generated to help them draw their conclusions. 

                 (a)                                                       (b)                                                  (c)                                                  (d) 

Fig. 15. User study 2: visual understanding. We showed the participants an STM composed of two views (a) and (b). We then asked them 
to traverse between these two views and describe what they saw along the path. This path included view (c) which was the most revealing 
– the motion parallax clarified that there were indeed three clusters. (d) The three clusters marked in different colors as a confirmation.     

                  (a)                                                     (b)                                                  (c)                                                   (d) 

Fig. 16. User study 3: data understanding. (a-d) Various views our participants generated. See Section 8.3.3 for a narration of these plots.  

Task 2 – Visual understanding 

8.3.2 
Starting out with the two view thumbnails (shown expanded in Fig. 
15(a-b)) eight of the participants stated that there were two clusters. 
On the other hand, two of the participants suspected that there might 
be  a  third  cluster,  mostly  based  on  the  view  in  Fig.  15(a).  Next,  all 
used the ‘TraverseBtw’ slider to go from one view to the other (nine 
users went  from the top view to the bottom one while one went the 
other  way).  Fig.  15(c)  has  the  most  revealing  view  they  generated 
(colored  in  Fig.  15(d)).  Everyone  spotted  the  third  cluster  while 
traveling. The average time for completing the task was 83s. Most of 
this time was spent on describing the observations while only 10–20s 
was spent on traversing between the two subspaces. 

The  transition  interface  seemed  very  effective  in  helping  the 
participants understand the high-D structures. Some of the comments 
were  ‘The  bigger  cluster  separates  into  two,  one  of  them  remains  a 
separate cluster, while the other one merges with the smaller cluster’ 
and  ‘The  upper  left  cluster  seems  to  be  moving  forward.  Another 
cluster  is  moving  upward,  and  the  third  one  is  moving  downward’. 
One person saved a couple of views in the STM and later mentioned 
that  ‘if  I  look  at  those  still  frames,  I  probably  still  cannot  tell  that 

there are three clusters, it’s really the motion by which you can tell.’ 
This  comment  nicely  verbalizes  the  power  of  motion  parallax.  It 
makes it easier to spot patterns than relying purely on still frames.   

8.3.3     Task 3 – Data understanding 
For  this  task,  we  colored  the  points  according  to  sales  team.  We 
observed  that  the  participants  often  used  the  ‘chase  cluster’ 
functionality but as a part of different exploration strategies. One of 
these  strategies  consisted  of  making  individual  data  dimensions  the 
dominant  factor  on  either  the  PPA-x  or  the  PPA-y  axis  and  then 
observing  the  distribution  of  the  three  sales  teams  along  these 
attributes.  Fig.  16(b)  shows  a  view  generated  by  a  participant  who 
wanted  to  examine  the  influence  of  #opportunities.  Later  on,  when 
using  the  STM  to  return  to  this  view  to  present  her  findings,  she 
stated that ‘the blue team has the lowest number of opportunities’.  

Another strategy was to keep PipelineRevenue as either the PPA-
x  or  PPA-y  axis  and  assign  another  attribute  to  the  other  axis.  By 
doing  this,  these  participants  managed  to  create  traditional  axis-
aligned  scatterplots  where  they  could  examine  the  relationships 
between two variables. One typical view of this method is shown in 
Fig.  16(c).  Here  the  participant  concluded:  ‘The  blue  and  magenta 

14 
 

Copyright (c) 2017 IEEE. Personal use is permitted. For any other purposes, permission must be obtained from the IEEE by emailing pubs-permissions@ieee.org.

This is the author's version of an article that has been published in this journal. Changes were made to this version by the publisher prior to publication.

The final version of record is available at

 http://dx.doi.org/10.1109/TVCG.2017.2672987

teams all have high revenue. The magenta and green teams all have a 
high number of opportunities.’ 

Yet another analysis strategy was to try to come up with certain 
views where some attributes, or all of them, were well expressed. A 
typical  view  for  this  strategy  is  shown  in  Fig.  16(d).  Based  on  this 
view, the participant generating it described his findings as ‘The blue 
and  magenta  teams  have  higher  revenues  than  the  green  one.  They 
both generate more leads and have a lower cost per won lead. Those 
two factors seem to be important.’ 

All participants used the STM to save important findings. When 
they reported these finding to us, six participants simply dragged and 
dropped  their  saved  views  back  to  the  trackball,  while  four 
participants  used  the  STM  to  traverse  between  these  key  frames 
when  telling  us  the  story  because  they  ‘liked  the  animation’.  When 
their  findings,  all  participants  arrived  at  similar 
presenting 
conclusions, viz. ‘The blue and the magenta teams have the highest 
revenue’, ‘The blue team has a high number of leads and this might 
lead to their high revenue’ and ‘Cost per won lead needs to be low’.  
The participants spent on average 17 minutes and 48 seconds on 
this task. There was a wide time spread. One of the participants spent 
almost  33  minutes  because  he  was  ‘having  fun’  and  just  wanted  to 
explore  the  dataset  more.  We  believe  this  proves  that  our  system  is 
very playful and nicely engages the users into the data analytics.  

8.3.4     Further finds from the voice recordings 
Analyzing  the  recordings  produced  further  interesting  comments. 
One participant said our system was ‘very intuitive’ and ‘helped me 
not  only  understand  the  distribution  of  the  data  on  one  specific 
dimension  but  multiple  dimensions  at  the  same  time’.  Other 
participants stated that our system made ‘exploring data fun’, that the 
trail map made ‘switching back and forth very fast’, and that this was 
the ‘first time seeing data exploration could be done in this way’.  

8.3.5     Comparative study with TripAdvisorND 
We  also  conducted  a  comparative  study  with  the  TripAdvisorND 
interface  to  test  if  our  system  could  outperform  its  ancestor.  Since 
TripAdvisorND does not have a trail map for the navigation between 
different subspaces, we only repeated the first and the third tasks. We 
engaged the same participants as in the Subspace Voyager study and 
we  used  the  same  data.  There  were,  however,  six  months  between 
the two studies. This greatly diminished learning effects with respect 
to  the data.  Our  goal  was  primarily  to  learn  about pros  and  cons of 
the two systems, and only get a rough estimate of the time needed to 
accomplish views comparable to those obtained before. 

that 

the  participants  were  mostly  moving 

For  the  first  task,  the  participants  expressed  that  the  subspace 
voyager  was  more  ‘direct’.  They  thought  that  the  pad  navigation 
interface  in  TripAdvisorND  ‘made  the  control  of  the  shape  difficult. 
We  observed 
the 
navigation  points  ‘arbitrarily’  until  they  found  out  what  was  going 
on. One participant mentioned that because of the ‘extra layer of the 
interface, how to control the points is less obvious and less intuitive’.  
We  asked  him  what  he  meant  by  ‘extra  layer’.  He  replied  ‘it’s  the 
separate navigation interface and also the switching between x and y 
control  points’.  On  average,  the  participants  spent  91  seconds  to 
finish  this  task  using  TripAdvisorND.  This  is  about  twice  the  time 
they needed with the Subspace Voyager.  

For  the  third  task,  the  one  participant  who  chose  to  make 
individual data dimensions the dominant factor on either the PPA-x 
or  PPA-y  axis  preferred  the  navigation  polygon  in  TripAdvisorND. 
He  thought  moving  the  red  and  blue  dots  onto  any  two  dimensions 
was  very  straightforward  in  TripAdvisorND  while  ‘it  required  a  bit 
more  adjustment  to  single  out  the  two  dimensions  I  want’  in 
Subspace  Voyager.  In  contrast,  the  other  participants  who  tried  to 
come  up  with  certain  views  where  some  attributes,  or  all  of  them, 
were well expressed all preferred Subspace Voyager. They all agreed 
that  it  was  much  easier  to  come  up  with  a  meaningful  multivariate 
projection  using  the  new  system.  One  participant  said  that  for 
TripAdvisorND,  ‘to  get  the  superposition  of  dimensions,  I  had  to 
move  the  vertices  of  the  dimensions  I  am  interested  in  next  to  each 

15 
 

other  in  the  polygon  and  it’s  tedious’  while  ‘In  the  Subspace 
Voyager,  moving  dimensions  to  desired  locations  and  controlling 
their weights was very straightforward’.  

We  believe 

these  (mostly  qualitative)  findings  and 
assessments make a conclusive argument for the Subspace Voyager.   

that 

9.  CO NC L US I ON S 

We  demonstrated  a  system  for  high-D  data  exploration  in  form  of 
scatterplot projections that decomposes the high-D data space into a 
continuum  of  generalized  3D  subspaces.  Using  3D  space  as  the 
immediate visual context affords a natural user interface  well suited 
for  mainstream  users.  The  interactive  tools  we  designed  do  not 
require  users  to  ever  think  of  data  in  their  native  high-D  context. 
Rather, users fluidly transition from one generalized 3D subspace to 
the next in a goal-directed manner, emphasizing and de-emphasizing 
the  weights  of  the  various  attributes  on  the  fly  during  the  visual 
interactions. Key elements of our system are an augmented trackball 
with  a  peripheral  weight-adaptive  attribute  label  display,  a  metric-
driven view and subspace optimizer, and a map that allows users to 
organize  the  scatterplots  of  key  findings  and  transition  between 
them.  We  also  provided  several  measures  that  help  scalability  for 
both  attributes  and  data  items.  Users  can  control  the  number  of 
attribute  labels  shown  and  they  can  hide  data  points  temporality  to 
improve  the  visibility  of  the  points  currently  deemed  relevant. 
Several  user  studies  confirmed  that  our  system  supports both  visual 
and data understanding. 

In  future  work,  we  would  like  to  add  depth  information  when 
displaying the data points in the trackball. This could be achieved by 
introducing  depth  of  field  effects  and  fog  and  converting  the  point 
clouds into shaded 3D shapes with drop and self-shadows, combined 
with occlusion and semi-transparent effects. All of these could allow 
users  to  better  appreciate  the  structure  of  the  data  and  discover 
patterns  that  would  otherwise  be  hard  to  notice  in  a  conventional 
scatter  plot  display.  The  end  goal  of  all  of  these  efforts  is  to  create 
intuitive  displays,  which  invite  discussion  of  personal  findings  with 
colleagues  in  business  planning  and  policy-making  scenarios,  etc. 
We also plan to refine our system via percept-oriented studies [12]. 

10.  AC KN OW L ED G EM EN T S 

This  research  was  partially  supported  by  NSF  grants  IIS  1527200 
and IIS 1117132, as well as the MSIP (Ministry of Science, ICT and 
Future  Planning),  Korea,  under  the  ""ITCCP  Program""  directed  by 
NIPA. We thank Eric Papenhausen for proofreading the manuscript.  

RE FE RE NC ES 

[1]  A.  Anand,  L.  Wilkinson,  T.  Dang.  ""Visual  pattern  discovery  using 

random projections."" Proc. VAST, pp. 43-52, 2012. 

[2]  E.  Abbot,  Flatland:  A  Romance  of  Many  Dimensions,  Dover  Thrift 

Edition, 1984. 

[3]  E. Angel, D. Shreiner, Interactive Computer Graphic with WebGL (7th 

[4] 

Edition), Addison-Wesley, 2014. 
I.  Assent,  R.  Krieger,  E.  Müller,  T.  Seidl,  “VISA:  visual  subspace 
clustering analysis,” ACM SIGKDD Explorations Newsletter, 9(2), 5-12, 
2007. 

[5]  D.  Asimov,  ""The  Grand  Tour:  A  tool  for  viewing  multidimensional 
data,"" SIAM J. Scientific and Statistical Computing, 6(1):128-143, 1985. 
[6]  G. Chen, J. Wang. C. Li, ""Solving the optimization of projection pursuit 
model  using  improved  ant  colony  algorithm,""  Conference  on  Natural 
Computation, pp. 521 – 525, 2008. 

[7]  W. Cheney, D. Kincaid, Linear Algebra: Theory and Applications, 2009. 
[8]  D.  Cook,  A.  Buja,  J.  Cabrera,  C.  Hurley,  ""Grand  Tour  and  Projection 

Pursuit,"" Computational and Graphical Statistics, 4(3): 155-172, 1995. 

[9]  D.  Cook,  E.  Lee,  A.  Buja,  H.  Wickham,  ""Grand  Tours,  Projection 
Pursuit  Guided  Tours  and  Manual  Controls,""  Handbook  of  Data 
Visualization, New York, Springer, 2006. 

[10]  M.  Dorigo,  ""Optimization,  Learning  and  Natural  Algorithms,""  Ph.D. 

Thesis, Politecnico di Milano, 1992. 

Copyright (c) 2017 IEEE. Personal use is permitted. For any other purposes, permission must be obtained from the IEEE by emailing pubs-permissions@ieee.org.

This is the author's version of an article that has been published in this journal. Changes were made to this version by the publisher prior to publication.

The final version of record is available at

 http://dx.doi.org/10.1109/TVCG.2017.2672987

[11]  N.  Elmqvist,  P.  Dragicevic,  J.-D.  Fekete,  ""Rolling  the  dice:  a  multi-
dimensional  visual  exploration  using  scatterplot  matrix  navigation,"" 
IEEE  Trans.  Visualization  and  Computer  Graphics,  14(6):1539-1148, 
2008. 

[12]  R.  Etemadpour,  R.  Motta,  J.  de  Paiva,  R.  Minghim  M.  de  Oliveira,  L. 
Linsen.  “Perception-based  evaluation  of  projection  methods  for 
multidimensional data visualization,” IEEE Trans. on Visualization and 
Computer Graphics, 21(1):81-94. 

[13]  J.  Friedman,  J.  Tukey,  ""A  projection  pursuit  algorithm  for  exploratory 

data analysis,"" IEEE Trans. on Computers, 23(9): 881-890, 1974. 

[14]  K.  Gabriel,  ""The  biplot  graphic display  of  matrices  with application  to 

reduction:  A  structured 
Visualization and Computer Graphics, 23(1), pp 241-250, 2017 

literature  analysis,” 

IEEE  Trans.  on 

[35]  M.  Schäfer,  L.  Zhang,  T.  Schreck,  A.  Tatu,  J.  Lee,  M.  Verleysen,  D. 
Keim,  ""Improving  projection-based  data  analysis  by  feature  space 
transformations,"" SPIE Electronic Imaging, pp. 86540H-86540H, 2013. 
[36]  J. Seo, B. Shneiderman, ""A rank-by-feature framework for unsupervised 
multidimensional  data  exploration  using  low  dimensional  projections,"" 
Proc. IEEE Info Vis, pp. 65-72, 2004. 

[37]  M.  Sips,  B.  Neubert,  J.  Lewis,  P.  Hanrahan,  ""Selecting  good  views  of 
high-dimensional  data  using  class  consistency,""  Computer  Graphics 
Forum, 28(3): 831-838, 2009. 

principal component analysis"". Biometrika. 58 (3): 453–467, 1971. 

[38]  K.  Socha,  M.  Dorigo,  ""Ant  colony  optimization  for  continuous 

[15]  A.  Gilbert,  et  al.  “Overview  of  the  ImageCLEF  2015  Scalable  Image 
Annotation,  Localization  and  Sentence  Generation  task,”  Proc.  CEUR 
Workshop, CEUR-WS.org, Toulouse, France, September 2015 

[16]  S. Gratzl, A. Lex, N. Gehlenborg, H. Pfister, M. Streit, ""Lineup: Visual 
analysis of multi-attribute rankings"", IEEE Trans. on Visualization and 
Computer Graphics,  19(12): 2277-2286, 2013  

[17]  J.  Hartigan,  ""Printer  graphics  for  clustering,""  Journal  of  Statistical 

Computation and Simulation, 4(3): 187-213, 1975. 

domains,"" European J. Operational Research 185: 1155-1173, 2008. 

[39]  D. Swayne, D. Lang, A. Buja, D. Cook, ""GGobi: evolving from XGobi 
into an extensible framework for interactive data visualization,"" Comp. 
Statistics & Data Analysis, 43(4):423-444, 2003. 

[40]  A. Tatu, G. Albuquerque, M. Eisemann, P. Bak, H. Theisel, M. Magnor, 
D.  Keim,  ""Automated  analytical  methods to  support  visual  exploration 
of high-dimensional data,"" IEEE Trans. on Visualization and Computer 
Graphics, 17(5): 584-597, 2011. 

[18]  J.  Heer,  G.  Robertson.  ""Animated  transitions  in  statistical  data 
graphics."" IEEE Trans. on Visualization and Computer Graphics, 13(6): 
1240-1247, 2007. 

[41]  A.  Tatu,  L.  Zhang,  E.  Bertini.,  T.  Schreck.  Keim,  S.  Bremm,  T.  von 
Landesberger,  “Clustnails:  Visual  analysis  of  subspace  clusters,” 
Tsinghua Science and Technology, 17(4), 419-428, 2012. 

[19]  N. Henry, J.-D. Fekete, “Evaluating Visual Table Data Understanding,” 

[42]  L. van der Maaten, G. Hinton, ""Visualizing data using t-SNE,"" Journal 

Proc. BELIV, p. 1, 2006. 

[20]  P.  Hoffman,  G.  Grinstein,  “A  survey  of  visualizations  for  high-
dimensional  data  mining.  Information  visualization  in  data  mining  and 
knowledge  discovery,”  Information  Visualization  in  Data  Mining  and 
Knowledge Discovery, pp. 47-82, 2012. 

[21]  E.  Kandogan,  ""Visualizing  multi-dimensional  clusters,  trends,  and 

outliers using star coordinates."" ACM SIGKDD, pp. 107-116, 2001 

[22]  H.  Kim,  J.  Choo,  H.  Park,  A.  Endert,  “InterAxis:  Steering  scatterplot 
axes  via  observation-level  interaction,”  IEEE  Trans.  Visualization  and 
Computer Graphics, 22(1):131-140, 2015. 

[23]  H. Kriegel, P. Kröger, A. Zimek, ""Clustering high-dimensional data: A 
survey on subspace clustering, pattern-based clustering, and correlation 
clustering,"" ACM Trans. Knowledge Discovery from Data, 3(1):1, 2009. 
[24]  J.  Kruskal,  M.  Wish,  ""Multidimensional  Scaling,""  Sage  Publications, 

1977. 

[25]  J.  Lee,  K.  T.  McDonnell,  A.  Zelenyuk,  D.  Imre  K.  Mueller,  “A 
structure-based  distance  metric  for  high-dimensional  space  exploration 
with  multi-dimensional  scaling”,  IEEE  Trans  on  Visualization  and 
Computer Graphics, 20(3): 351-364, 2014. 

[26]  DJ  Lehmann,  H  Theisel,  “Optimal  sets  of  projections  of  high-
dimensional  data,”  IEEE  Trans  on  Visualization  and  Computer 
Graphics, 2016, 22(1): 609-618. 

[27]  S.  Liu,  B.  Wang,  J.J.  Thiagarajan,  P.-T.  Bremer,  V.  Pascucci.  ""Visual 
exploration  of  high-dimensional  data  through  subspace  analysis  and 
dynamic projections."" Computer Graphics Forum. 34(3): 271-280, 2015. 
[28]  G.  McLachlan,  Discriminant  Analysis  and  Statistical  Pattern 

Recognition, Wiley, 2004. 

[29]  M.  Meyer,  H.  Lee,  A.  Barr,  M.  Desbrun,  ""Generalized  barycentric 
coordinates  on  irregular  polygons,""  Graphics  Tools,  7(1):1086-7651, 
2002. 

[30]  E. Nam, Y. Han, K. Mueller, A. Zelenyuk, D. Imre, ""ClusterSculptor: A 
visual analytics tool for high-dimensional data,"" IEEE VAST, pp. 75-82, 
2007. 

[31]  J.  Nam,  K.  Mueller,  ""TripAdvisorND:  A  tourism-inspired  high-
dimensional  space  exploration  framework  with  overview  and  detail,"" 
IEEE Trans. Visualization & Computer Graphics, 19(2):291-305, 2013. 
[32]  C.  Posse,  ""An  effective  two-dimensional  projection pursuit algorithm,"" 
Communications  in  Statistics:  Simulation  and  Computation  19:  1142-
1164, 1990. 

[33]  P.  Ruchikachorn,  K.  Mueller,  “Learning  visualizations  by  analogy: 
promoting visual literacy through visualization morphing,” IEEE Trans. 
on Visualization and Computer Graphics, 21(9):1028-1044, 2015. 

[34]  D. Sacha, L. Zhang, M. Sedlmair, J. A. Lee, J. Peltonen, D. Weiskopf, S. 
North,  and  D.  A.  Keim.  “Visual  interaction  with  dimensionality 

16 
 

of Machine Learning Research, 9(11): 2579-2605, 2008. 

[43]  B.  Wang.  K.  Mueller,  ""Does  3D  really  make  sense  for  visual  cluster 
analysis?  Yes!""  International  Workshop  on  3DVis:  Does  3D  Really 
Make Sense for Data Visualization?  Paris, France, November 2014. 

[44]  X.  Yuan,  D.  Ren,  Z.  Wang,  and  C.  Guo,  “Dimension  projection 
matrix/tree:  interactive  subspace  visual  exploration  and  analysis  of 
high-dimensional  data”,  IEEE  Trans.  on  Visualization  and  Computer 
Graphics, 19(12): 2625 – 2633, 2013. 

[45]  Z.  Zhang,  K.  McDonnell,  K.  Mueller,  ""A  network‐based  interface  for 
the  exploration  of  high‐dimensional  data  spaces,""  Proc.  IEEE  Pacific 
Vis, pp. 17-24, Songdo, Korea, March 2012. 

[46]  http://miegakure.com/ 
[47]  https://onlinecourses.science.psu.edu/stat505/node/54 
[48]  College Prowler (Accessed 9/09), http://collegeprowler.com, 2012. 
[49]  US  News  Best  Colleges  (Accessed  9/09),  http://colleges.usnews. 

rankingsandreviews.com, 2012. 

[50]  http://www.imageclef.org/ 
[51]  http://risenet.prhlt.upv.es/webupv-datasets/dwld/v2013/feats_visual/ 
[52]  http://risenet.prhlt.upv.es/webupv/datasets/agreement?dwld=dwld/v201

3/feats_visual/webupv13_devel_visual_getlf.feat.gz 

[53]  https://archive.ics.uci.edu/ml/datasets/Iris 

Bing  Wang  received  her  PhD  from  the 
Computer  Science  Department  at  Stony 
Brook University. Her research focus is high 
dimensional  data  visualization  and  visual 
analytics.  
 
 
 
 
 
Klaus  Mueller  received  a  PhD  in  computer 
 
science  from  The  Ohio  State  University  and 
 
is currently a professor of computer science 
at  Stony  Brook  University.  His  research 
interests  are  visual  analytics,  HCI,  and 
medical imaging. He won the NSF CAREER 
award  in  2001  and  the  SUNY  Chancellor 
Award  for  Excellence  in  Scholarship  and 
Creative  Activity  in  2011.  For more  info  see 
http://www.cs.sunysb.edu/~mueller/ 

Copyright (c) 2017 IEEE. Personal use is permitted. For any other purposes, permission must be obtained from the IEEE by emailing pubs-permissions@ieee.org.

","{""pos"":{""0"":1,""1"":2,""2"":3,""3"":4,""4"":5},""8"":{""0"":""exploration"",""1"":""revenue"",""2"":""teams"",""3"":""tuition*"",""4"":""college*""},""5"":{""0"":""fig"",""1"":""high"",""2"":""a*"",""3"":""blue"",""4"":""magenta""},""7"":{""0"":""data"",""1"":""cluster"",""2"":""visual*"",""3"":""visualization*"",""4"":""optimization*""},""1"":{""0"":""ieee*"",""1"":""ppa*"",""2"":""stm*"",""3"":""aco*"",""4"":""tina""},""2"":{""0"":""11*"",""1"":""8*"",""2"":""12*"",""3"":""13*"",""4"":""15*""},""0"":{""0"":""\ud835\udefd*"",""1"":""\ud835\udf03\ud835\udc63*"",""2"":""\ud835\udf03\u210e*"",""3"":""\ud835\udefc1*"",""4"":""\ud835\udefc2*""},""6"":{""0"":""b*"",""1"":""n"",""2"":""j*"",""3"":""m*"",""4"":""p""},""4"":{""0"":""view*"",""1"":""views"",""2"":""basis*"",""3"":""case*"",""4"":""understanding*""},""3"":{""0"":""subspace*"",""1"":""axis"",""2"":""subspaces*"",""3"":""dimension"",""4"":""vectors*""}}",2018,{},False,False,journalArticle,False,ZMGBDR3L,[],self.user,"{""Unnamed: 0"":{""0"":0,""1"":1,""2"":2,""3"":3,""4"":4,""5"":5,""6"":6,""7"":7,""8"":8,""9"":9,""10"":10,""11"":11,""12"":12,""13"":13,""14"":14,""15"":15,""16"":16,""17"":17,""18"":18,""19"":19,""20"":20,""21"":21,""22"":22,""23"":23,""24"":24,""25"":25,""26"":26,""27"":27,""28"":28,""29"":29,""30"":30,""31"":31,""32"":32,""33"":33,""34"":34,""35"":35,""36"":36,""37"":37,""38"":38,""39"":39,""40"":40,""41"":41,""42"":42,""43"":43,""44"":44,""45"":45,""46"":46,""47"":47,""48"":48,""49"":49,""50"":50,""51"":51,""52"":52,""53"":53,""54"":54,""55"":55,""56"":56,""57"":57,""58"":58,""59"":59,""60"":60,""61"":61,""62"":62,""63"":63,""64"":64,""65"":65,""66"":66,""67"":67,""68"":68,""69"":69,""70"":70,""71"":71,""72"":72,""73"":73,""74"":74,""75"":75,""76"":76,""77"":77,""78"":78,""79"":79,""80"":80,""81"":81,""82"":82,""83"":83,""84"":84,""85"":85,""86"":86,""87"":87,""88"":88,""89"":89,""90"":90,""91"":91,""92"":92,""93"":93,""94"":94,""95"":95,""96"":96,""97"":97,""98"":98,""99"":99,""100"":100,""101"":101,""102"":102,""103"":103,""104"":104,""105"":105,""106"":106,""107"":107,""108"":108,""109"":109,""110"":110,""111"":111,""112"":112,""113"":113,""114"":114,""115"":115,""116"":116,""117"":117,""118"":118,""119"":119,""120"":120,""121"":121,""122"":122,""123"":123,""124"":124,""125"":125,""126"":126},""C"":{""0"":6.4171537735,""1"":11.1384085557,""2"":14.6785424311,""3"":22.6960717192,""4"":8.4640298589,""5"":8.5071177495,""6"":8.1137049653,""7"":18.4226822683,""8"":11.9761596985,""9"":7.7057570649,""10"":10.0893321818,""11"":10.2250917329,""12"":6.0207176108,""13"":10.4236901371,""14"":9.602878767,""15"":14.5452380038,""16"":8.5289071268,""17"":12.8636255821,""18"":13.4090295051,""19"":11.4319711791,""20"":6.6313433803,""21"":8.1342295064,""22"":48.7706932906,""23"":7.5866276021,""24"":9.1424561026,""25"":22.9729776117,""26"":7.1992691838,""27"":13.4703218139,""28"":20.8173503733,""29"":10.609992433,""30"":24.48396648,""31"":9.3122257858,""32"":8.0258858701,""33"":19.295009953,""34"":7.3562719864,""35"":18.3752717182,""36"":19.3703630065,""37"":6.5659931471,""38"":20.9818163581,""39"":16.8280233033,""40"":5.9830438103,""41"":15.416425041,""42"":6.0531393345,""43"":8.8845291179,""44"":6.7018733725,""45"":8.442274989,""46"":16.4738319976,""47"":6.2668370169,""48"":14.296467463,""49"":12.8874155729,""50"":11.6138295976,""51"":6.6647917514,""52"":11.0965759209,""53"":8.9510854908,""54"":10.6732126069,""55"":14.1645104331,""56"":25.4850803775,""57"":7.2819010985,""58"":6.7553706042,""59"":7.331293613,""60"":7.7612560812,""61"":6.6217081977,""62"":23.7446219507,""63"":12.4935954172,""64"":8.5412323611,""65"":21.3396932872,""66"":6.3087239819,""67"":6.8658374511,""68"":19.3169830258,""69"":6.5714326943,""70"":7.1570945119,""71"":8.7141959893,""72"":17.8598647355,""73"":6.7785480257,""74"":6.6976403202,""75"":9.3030100773,""76"":16.2601851913,""77"":6.2922643168,""78"":7.316638869,""79"":15.0788196404,""80"":9.7899557871,""81"":13.7401665292,""82"":6.3804572648,""83"":6.5547942973,""84"":14.6688826839,""85"":6.8048616364,""86"":12.6818702823,""87"":12.6262354013,""88"":11.9435931104,""89"":5.9695579576,""90"":7.9987286854,""91"":7.9987286854,""92"":8.5633623971,""93"":9.6117344614,""94"":10.963022984,""95"":12.5342881793,""96"":6.4848717742,""97"":11.891798923,""98"":7.3947494211,""99"":9.6134624083,""100"":7.0537795778,""101"":10.1322229114,""102"":8.0787240655,""103"":7.5012358661,""104"":8.1577436641,""105"":8.5988861311,""106"":8.7711908073,""107"":8.4327782927,""108"":7.4229761006,""109"":8.2510820573,""110"":8.5595421743,""111"":6.3209664118,""112"":6.0841106098,""113"":6.6031841424,""114"":6.8017414696,""115"":8.0902307793,""116"":8.0287534887,""117"":6.0055636701,""118"":7.2242884304,""119"":6.5921103769,""120"":6.6063050929,""121"":6.6299338252,""122"":6.0398832608,""123"":6.5756390716,""124"":6.335628115,""125"":6.3356964697,""126"":6.6394055316},""count"":{""0"":234,""1"":230,""2"":162,""3"":160,""4"":148,""5"":138,""6"":130,""7"":130,""8"":128,""9"":128,""10"":116,""11"":116,""12"":110,""13"":108,""14"":94,""15"":92,""16"":84,""17"":78,""18"":76,""19"":76,""20"":70,""21"":68,""22"":66,""23"":64,""24"":64,""25"":64,""26"":56,""27"":56,""28"":56,""29"":54,""30"":54,""31"":50,""32"":50,""33"":50,""34"":48,""35"":48,""36"":48,""37"":46,""38"":46,""39"":44,""40"":42,""41"":40,""42"":40,""43"":38,""44"":38,""45"":38,""46"":36,""47"":36,""48"":36,""49"":36,""50"":34,""51"":34,""52"":34,""53"":34,""54"":34,""55"":34,""56"":34,""57"":32,""58"":32,""59"":30,""60"":30,""61"":30,""62"":30,""63"":30,""64"":28,""65"":28,""66"":26,""67"":26,""68"":26,""69"":24,""70"":24,""71"":24,""72"":24,""73"":22,""74"":22,""75"":22,""76"":22,""77"":20,""78"":20,""79"":20,""80"":20,""81"":20,""82"":18,""83"":18,""84"":18,""85"":18,""86"":18,""87"":18,""88"":18,""89"":16,""90"":16,""91"":16,""92"":16,""93"":16,""94"":16,""95"":16,""96"":14,""97"":14,""98"":14,""99"":14,""100"":12,""101"":12,""102"":12,""103"":12,""104"":12,""105"":12,""106"":12,""107"":12,""108"":12,""109"":10,""110"":10,""111"":10,""112"":10,""113"":10,""114"":10,""115"":10,""116"":10,""117"":10,""118"":10,""119"":8,""120"":8,""121"":8,""122"":8,""123"":8,""124"":8,""125"":8,""126"":8},""sigma_nor"":{""0"":1.4028912514,""1"":1.709781883,""2"":2.1057539335,""3"":2.7247562157,""4"":1.6607552323,""5"":1.6858911447,""6"":1.6717787488,""7"":2.5398647377,""8"":2.0041472077,""9"":1.6419469002,""10"":1.8828768265,""11"":1.8949291077,""12"":1.5342404097,""13"":1.9426064526,""14"":1.923031941,""15"":2.4198477862,""16"":1.8597407873,""17"":2.349099364,""18"":2.4232636641,""19"":2.2105421245,""20"":1.7189390232,""21"":1.8977562438,""22"":6.5636571208,""23"":1.857693772,""24"":2.0383179204,""25"":3.6439744363,""26"":1.8594660785,""27"":2.631042272,""28"":3.5350041208,""29"":2.2987524527,""30"":4.0327064635,""31"":2.1733220565,""32"":2.0071829876,""33"":3.4626628032,""34"":1.9360762604,""35"":3.3840842189,""36"":3.5148492738,""37"":1.8465303598,""38"":3.7751816987,""39"":3.2603115423,""40"":1.796516809,""41"":3.1492064952,""42"":1.8216488003,""43"":2.2479132015,""44"":1.9318904636,""45"":2.1838800342,""46"":3.3974914426,""47"":1.8869151409,""48"":3.0752540679,""49"":2.8667225268,""50"":2.7157663375,""51"":1.9663585657,""52"":2.6374412292,""53"":2.312560464,""54"":2.5733334637,""55"":3.1020030367,""56"":4.8162196909,""57"":2.0840250605,""58"":2.0023560778,""59"":2.117839381,""60"":2.1862357161,""61"":2.0049619895,""62"":4.7287917048,""63"":2.9390332068,""64"":2.3436173033,""65"":4.4344423927,""66"":2.0044640505,""67"":2.0980727108,""68"":4.1901690625,""69"":2.0775657303,""70"":2.1789483122,""71"":2.4484945986,""72"":4.0316804623,""73"":2.1459922836,""74"":2.1315354714,""75"":2.5970701323,""76"":3.8401973884,""77"":2.0915856848,""78"":2.2809232822,""79"":3.7156257107,""80"":2.738072361,""81"":3.468199256,""82"":2.1439262315,""83"":2.1773395349,""84"":3.7324795607,""85"":2.2252672514,""86"":3.3516502709,""87"":3.3409873318,""88"":3.2101526281,""89"":2.1014456108,""90"":2.5058416623,""91"":2.5058416623,""92"":2.618368243,""93"":2.8272996639,""94"":3.0965996964,""95"":3.4097391638,""96"":2.2481298242,""97"":3.3721674305,""98"":2.4372828614,""99"":2.8985276252,""100"":2.4198593249,""101"":3.0898776351,""102"":2.6429368674,""103"":2.5172474765,""104"":2.6601353578,""105"":2.7561493162,""106"":2.7936511558,""107"":2.7199962086,""108"":2.5002143626,""109"":2.751526397,""110"":2.822103659,""111"":2.3099060052,""112"":2.2557121789,""113"":2.3744788742,""114"":2.4199098124,""115"":2.7147227968,""116"":2.7006564764,""117"":2.2377402349,""118"":2.5165907314,""119"":2.4259350932,""120"":2.4293644243,""121"":2.4350729393,""122"":2.292521387,""123"":2.421955756,""124"":2.363971006,""125"":2.36398752,""126"":2.4373612287},""vocab_index"":{""0"":0,""1"":1,""2"":3,""3"":4,""4"":5,""5"":6,""6"":8,""7"":9,""8"":10,""9"":11,""10"":13,""11"":14,""12"":16,""13"":17,""14"":21,""15"":23,""16"":24,""17"":27,""18"":28,""19"":29,""20"":34,""21"":37,""22"":39,""23"":41,""24"":42,""25"":43,""26"":51,""27"":53,""28"":54,""29"":55,""30"":56,""31"":57,""32"":58,""33"":61,""34"":65,""35"":66,""36"":67,""37"":69,""38"":71,""39"":73,""40"":76,""41"":80,""42"":81,""43"":88,""44"":89,""45"":90,""46"":96,""47"":99,""48"":100,""49"":101,""50"":104,""51"":106,""52"":107,""53"":109,""54"":110,""55"":111,""56"":112,""57"":130,""58"":132,""59"":133,""60"":138,""61"":139,""62"":141,""63"":142,""64"":151,""65"":153,""66"":154,""67"":155,""68"":163,""69"":172,""70"":173,""71"":174,""72"":175,""73"":185,""74"":186,""75"":188,""76"":189,""77"":191,""78"":203,""79"":204,""80"":205,""81"":206,""82"":208,""83"":228,""84"":234,""85"":235,""86"":236,""87"":237,""88"":238,""89"":243,""90"":262,""91"":263,""92"":265,""93"":268,""94"":269,""95"":270,""96"":295,""97"":297,""98"":300,""99"":302,""100"":312,""101"":339,""102"":346,""103"":349,""104"":350,""105"":351,""106"":352,""107"":355,""108"":356,""109"":381,""110"":402,""111"":417,""112"":418,""113"":426,""114"":427,""115"":428,""116"":430,""117"":431,""118"":432,""119"":529,""120"":531,""121"":532,""122"":537,""123"":538,""124"":539,""125"":540,""126"":554},""word"":{""0"":""data"",""1"":""subspace"",""2"":""view"",""3"":""fig"",""4"":""users"",""5"":""trackball"",""6"":""ieee"",""7"":""ppa"",""8"":""cluster"",""9"":""axis"",""10"":""subspaces"",""11"":""projection"",""12"":""high"",""13"":""3d"",""14"":""dimension"",""15"":""visual"",""16"":""views"",""17"":""mouse"",""18"":""exploration"",""19"":""stm"",""20"":""b"",""21"":""dimensions"",""22"":""participants"",""23"":""vectors"",""24"":""a"",""25"":""blue"",""26"":""visualization"",""27"":""vector"",""28"":""magenta"",""29"":""n"",""30"":""team"",""31"":""dimensional"",""32"":""optimization"",""33"":""green"",""34"":""11"",""35"":""j"",""36"":""sales"",""37"":""8"",""38"":""revenue"",""39"":""aco"",""40"":""label"",""41"":""computer"",""42"":""basis"",""43"":""tripadvisornd"",""44"":""m"",""45"":""dataset"",""46"":""current"",""47"":""p"",""48"":""images"",""49"":""12"",""50"":""navigation"",""51"":""t"",""52"":""13"",""53"":""panel"",""54"":""cost"",""55"":""teams"",""56"":""graphics"",""57"":""direction"",""58"":""case"",""59"":""interesting"",""60"":""projected"",""61"":""overlap"",""62"":""pat"",""63"":""trans"",""64"":""button"",""65"":""tina"",""66"":""mueller"",""67"":""generalized"",""68"":""tuition"",""69"":""understanding"",""70"":""h"",""71"":""college"",""72"":""weather"",""73"":""z"",""74"":""weighting"",""75"":""opportunities"",""76"":""nightlife"",""77"":""research"",""78"":""leads"",""79"":""athletic"",""80"":""15"",""81"":""participant"",""82"":""adjacent"",""83"":""pad"",""84"":""pheromone"",""85"":""animation"",""86"":""academic"",""87"":""asked"",""88"":""pp"",""89"":""science"",""90"":""gram"",""91"":""schmidt"",""92"":""thumbnail"",""93"":""notices"",""94"":""schools"",""95"":""ucla"",""96"":""chosen"",""97"":""\u03b2"",""98"":""parameter"",""99"":""opportunity"",""100"":""reasoning"",""101"":""\u03b3"",""102"":""separated"",""103"":""moves"",""104"":""transportation"",""105"":""score"",""106"":""usnewsscore"",""107"":""spent"",""108"":""2012"",""109"":""ambiguities"",""110"":""da"",""111"":""\ud835\udefd"",""112"":""vertical"",""113"":""school"",""114"":""athletics"",""115"":""georgiatech"",""116"":""saturated"",""117"":""proc"",""118"":""2015"",""119"":""degrees"",""120"":""\ud835\udf03\ud835\udc63"",""121"":""\ud835\udf03\u210e"",""122"":""ants"",""123"":""solutions"",""124"":""\ud835\udefc1"",""125"":""\ud835\udefc2"",""126"":""retrieval""},""vector"":{""0"":""[ 4.9794273  5.133634   4.602479  -1.3968558 -2.7373888  0.7830719\n -2.8027885 -0.9649887 -2.6459215 -0.7979725]"",""1"":""[ 5.2404814   4.8870173   4.8454742  -1.4875705  -3.3404384   0.82025003\n -3.5617025  -0.11213639 -2.7875886  -0.39450482]"",""2"":""[ 5.452472    5.092327    4.307387   -1.6179779  -3.3265336   1.7486123\n -2.7668073  -0.73540664 -2.3763547  -0.60284805]"",""3"":""[ 4.84222     5.9253893   4.2043204  -0.20476954 -3.4558244   2.2754014\n -3.4951205   0.75487417 -3.701498   -0.5771189 ]"",""4"":""[ 5.1672225  5.5503387  3.8894916 -1.6248344 -2.349166   1.1198212\n -2.6568289 -0.7949091 -2.6310291 -0.8173777]"",""5"":""[ 4.7403526   5.389372    4.7758574  -1.2044482  -2.9648952   1.214515\n -3.015154    0.14976698 -3.5600235  -0.887338  ]"",""6"":""[ 5.0126457   6.509872    2.7284534   0.6634312  -2.9884162   2.093666\n -3.357044    1.8280532  -4.5094223   0.04886228]"",""7"":""[ 5.05459     6.444781    3.0040421   0.6486008  -3.126275    1.9695275\n -3.349292    1.9085035  -4.5571446   0.07250334]"",""8"":""[ 4.819598    5.1108265   4.9401803  -1.3305012  -2.9049568   0.5913025\n -2.8742254  -0.87857926 -2.8066206  -0.90248257]"",""9"":""[ 5.3177333   5.0351305   4.6731944  -1.3485053  -3.4630947   1.5043266\n -3.4893901  -0.04436978 -2.7874217  -0.40413758]"",""10"":""[ 5.2301264   4.852895    4.888323   -1.5164145  -3.3934207   0.9049999\n -3.538581   -0.08007356 -2.8092225  -0.3774621 ]"",""11"":""[ 5.016486   4.9454513  4.85247   -1.5914544 -2.980482   1.6113011\n -3.309493  -0.5786428 -2.7565675 -0.6110814]"",""12"":""[ 4.843691    5.427115    4.8769274  -0.9015324  -3.6146266   2.3441398\n -3.8412237  -0.16540442 -2.806937   -0.458113  ]"",""13"":""[ 4.896569    5.019374    4.956428   -1.6752026  -2.864898    0.92986023\n -3.0262725  -0.06642408 -3.3409688  -0.73233527]"",""14"":""[ 5.4364805   4.9853625   4.553649   -1.4602711  -3.4092886   1.2866381\n -3.3432395  -0.2443667  -2.5707793  -0.39768362]"",""15"":""[ 4.8081136   4.904047    5.11388    -1.7347522  -2.8194075   1.0864518\n -2.9893124  -0.54316396 -3.182655   -0.7832078 ]"",""16"":""[ 5.4061136   5.174074    4.171325   -1.745596   -2.9724922   1.5922092\n -2.6712677  -0.87557805 -2.4099777  -0.6054696 ]"",""17"":""[ 4.6764417   5.4618664   4.8758254  -1.0978781  -3.0505733   1.2513372\n -3.1443253   0.14600769 -3.5298934  -0.83292884]"",""18"":""[ 4.6846795  4.9792724  4.8531632 -1.6853983 -2.3247883  0.9691326\n -2.8223207 -1.1978228 -2.896579  -0.8036535]"",""19"":""[ 5.0005126   6.5261235   2.8698153   0.6527982  -3.0157886   2.005367\n -3.2735498   1.8612995  -4.5555153   0.05941469]"",""20"":""[ 4.9320035   6.102617    3.7438993   0.09872832 -3.4306145   2.4210308\n -3.448026    1.0084094  -3.8744793  -0.45484287]"",""21"":""[ 5.4061394   4.967758    4.4220834  -1.6975178  -3.0691044   1.0745739\n -3.2789276  -0.29964393 -2.6571991  -0.3805929 ]"",""22"":""[ 5.152704    5.6774144   3.8087704  -1.528704   -2.3675394   1.2346408\n -2.5893998  -0.84580994 -2.553011   -0.901653  ]"",""23"":""[ 5.136204    4.9882393   4.9358926  -1.4723351  -3.3160481   0.89288265\n -3.3805525  -0.15708716 -2.8994412  -0.53741634]"",""24"":""[ 4.936358    5.3971143   4.881636   -0.89850813 -3.7686496   2.3446662\n -3.7405062  -0.20611745 -2.7338612  -0.49148396]"",""25"":""[ 4.842239    5.627872    4.673861   -0.61562675 -3.733764    2.5021114\n -3.4430635   0.21018454 -3.2235951  -0.749811  ]"",""26"":""[ 4.818383    4.90934     5.073083   -1.6431885  -2.7914329   0.74754083\n -2.9511704  -0.6694607  -3.0559952  -0.7984151 ]"",""27"":""[ 5.0606856   5.0903606   4.9086657  -1.2956296  -3.366779    1.099765\n -3.4474     -0.03326943 -3.0084043  -0.509964  ]"",""28"":""[ 4.8341      5.598491    4.749053   -0.6395535  -3.5830362   2.1794019\n -3.501885    0.47100183 -3.506848   -0.70873934]"",""29"":""[ 4.8466454   6.179954    3.7309866   0.01939775 -3.4308045   2.4476123\n -3.3007953   0.8547215  -3.7829165  -0.58228284]"",""30"":""[ 4.7813206  5.737806   4.1817966 -1.2103121 -2.3094583  1.2589645\n -2.790318  -0.8425753 -2.7315497 -0.9689818]"",""31"":""[ 5.3143387   4.902446    4.729977   -1.6577271  -3.2421346   1.0421069\n -3.3770854  -0.11429711 -2.8140793  -0.4224151 ]"",""32"":""[ 4.991351    4.926093    4.821676   -1.5018543  -2.841005    0.7021385\n -3.1640842  -0.74415827 -2.772839   -0.6069886 ]"",""33"":""[ 4.835809    5.5491047   4.796202   -0.6908025  -3.6535015   2.3013601\n -3.5499706   0.25207028 -3.2700603  -0.66926825]"",""34"":""[ 4.8957043   5.897601    3.9665215  -0.47303882 -3.820609    3.189603\n -3.0226293  -0.49398607 -2.5819037  -0.9127127 ]"",""35"":""[ 4.9325414   6.2762337   3.4868598   0.23938186 -3.428158    2.3171048\n -3.3129797   1.133877   -4.003793   -0.38942164]"",""36"":""[ 4.7374926  5.1456447  4.492638  -1.6122804 -2.1725032  1.7707531\n -3.07539   -1.1622225 -2.7660406 -0.6445694]"",""37"":""[ 4.955132    5.9170265   3.9353175  -0.43278417 -3.858595    3.1633737\n -3.0487206  -0.388243   -2.6775126  -0.87790984]"",""38"":""[ 4.6331077  5.2445645  4.4054713 -1.5849752 -2.050634   1.9200581\n -3.0571954 -1.1961727 -2.8452747 -0.596111 ]"",""39"":""[ 5.0479736  6.303279   3.0583928  0.5030415 -2.98776    1.8627077\n -3.2485998  1.814225  -4.482373   0.1698267]"",""40"":""[ 5.2588873   5.3279085   4.388823   -1.0735134  -3.329228    1.6159201\n -3.2633984  -0.09861311 -2.7691917  -0.56985086]"",""41"":""[ 4.6421323   5.4043274   4.698562   -1.4696785  -2.363623    0.97247267\n -2.7795696  -0.53075343 -3.184312   -0.9427534 ]"",""42"":""[ 5.493946   5.1902914  4.2670245 -1.4540715 -3.4854438  1.8921238\n -2.7457707 -0.9400228 -2.1487117 -0.5762933]"",""43"":""[ 4.966363    5.3505216   3.8810184  -1.4771022  -2.2862716   1.2285634\n -2.6188617  -0.22947408 -3.5577245  -0.4838949 ]"",""44"":""[ 4.8724914   6.209973    3.6289034   0.10330462 -3.4664288   2.42513\n -3.3224616   0.9321262  -3.8453183  -0.5485411 ]"",""45"":""[ 5.1492505  5.105115   4.601448  -1.3730599 -3.0754282  0.6494821\n -2.849211  -0.6377173 -2.676851  -0.7336606]"",""46"":""[ 4.899202    5.4226513   4.809955   -0.9192733  -3.6514502   2.315748\n -3.6828237  -0.2517366  -2.7119389  -0.53697675]"",""47"":""[ 4.8796377   6.1746173   3.870848   -0.02081009 -3.3361828   2.3220136\n -3.5052686   0.78874207 -3.6906598  -0.4258993 ]"",""48"":""[ 5.212595   5.0261455  4.5631433 -1.8583254 -2.9017231  1.0470752\n -2.7897336 -0.4315391 -2.9415824 -0.6750764]"",""49"":""[ 4.8279243   5.8507943   4.1118307  -0.5588076  -3.7456145   3.191713\n -3.1412601  -0.41783977 -2.6550803  -0.9743659 ]"",""50"":""[ 4.6284447   4.8424807   5.0503473  -1.7774986  -2.3959053   1.0369186\n -2.8613684  -0.97030485 -3.1728263  -0.80988216]"",""51"":""[ 4.8109307  6.2525887  3.7102978  0.0070963 -3.380685   2.287378\n -3.2979507  1.0678326 -4.074784  -0.5624885]"",""52"":""[ 4.822734    5.927792    3.927236   -0.6168378  -3.7905893   3.0832255\n -3.0141516  -0.60126895 -2.488287   -0.9880929 ]"",""53"":""[ 5.002388    5.6533504   4.2294707  -1.1529346  -2.9022827   1.3642325\n -2.671762   -0.53448313 -2.7826715  -1.0036767 ]"",""54"":""[ 4.6242523  5.3157697  4.432     -1.4330229 -2.2043293  2.1176865\n -3.1403792 -1.1152626 -2.8427024 -0.6065921]"",""55"":""[ 4.9481187   5.642136    3.9618826  -1.4942086  -2.1311593   1.2797166\n -2.858189   -0.91967714 -2.6047711  -0.81816363]"",""56"":""[ 4.919416    5.0446053   4.806094   -1.7477776  -2.7083013   0.8726765\n -2.813437   -0.29878226 -3.270721   -0.76357085]"",""57"":""[ 5.3002925  5.1558146  4.57201   -1.3396972 -3.397597   1.8805106\n -3.291035  -0.3766306 -2.5866287 -0.4737495]"",""58"":""[ 5.4499927   5.3193197   4.2154694  -1.3153051  -3.5205922   1.9879417\n -2.8335092  -0.85910666 -2.1788282  -0.5785114 ]"",""59"":""[ 5.0082645   5.399749    4.730013   -1.0318929  -3.6529644   2.3883247\n -3.6776454  -0.4994807  -2.5098114  -0.42046767]"",""60"":""[ 4.95959    5.2998676  4.7084284 -1.0840937 -3.4590685  2.7427213\n -3.4843009 -0.4946054 -2.6891577 -0.5483191]"",""61"":""[ 5.216463    5.0609713   4.924871   -1.2808648  -3.5831568   2.502563\n -3.3007267  -0.3981653  -2.737445   -0.49536768]"",""62"":""[ 4.7592053   5.760166    4.2490964  -0.6198394  -3.207313    1.7863733\n -3.1695461   0.44070315 -3.6523895  -0.7858315 ]"",""63"":""[ 4.857422    5.7334857   4.5408096  -0.43784824 -3.593353    2.427167\n -3.7246997   0.44002023 -3.3465776  -0.45514438]"",""64"":""[ 4.7806377   5.5455656   4.6502614  -0.9649184  -3.1737576   1.4974743\n -3.0684574   0.22472176 -3.510268   -0.8843518 ]"",""65"":""[ 5.0196657   6.368335    3.027986    0.4452928  -3.1142054   1.9925517\n -3.2876434   1.62702    -4.348934    0.03111842]"",""66"":""[ 4.923654   6.468669   2.9567182  0.555852  -3.0757618  2.0989058\n -3.2249072  1.6341449 -4.404129  -0.0732953]"",""67"":""[ 4.979286    5.201936    5.022589   -1.0710994  -3.6674254   1.8103594\n -3.7044282  -0.09781006 -2.8746557  -0.47060427]"",""68"":""[ 4.5318594   5.471942    4.2502294  -1.5983015  -1.7207407   1.6314464\n -2.8416486  -1.1640452  -2.9595635  -0.69366986]"",""69"":""[ 5.29066    5.150285   4.45044   -1.4962618 -3.226409   1.9311733\n -2.8716252 -1.1069876 -2.251099  -0.541178 ]"",""70"":""[ 4.942888    6.1511602   3.6362538   0.1067304  -3.4650416   2.2828772\n -3.3493278   1.0661803  -4.0029707  -0.41644827]"",""71"":""[ 4.4735103   5.6160865   4.1679006  -1.6089804  -1.5211653   1.3998313\n -2.6919868  -1.0631468  -3.0924425  -0.65987825]"",""72"":""[ 4.722222    5.2273703   4.5362067  -1.698935   -2.1519365   0.9991158\n -2.6105504  -0.87607545 -3.0413704  -0.872912  ]"",""73"":""[ 4.979483    6.224686    3.466332    0.24203138 -3.4811687   2.2461405\n -3.2984786   1.1237129  -3.9727418  -0.33629844]"",""74"":""[ 4.9221396   5.2772226   4.562936   -1.1496254  -2.789314    1.2949517\n -3.1403887  -0.9232492  -2.5825028  -0.68806446]"",""75"":""[ 5.106462    5.195638    4.0639706  -1.8853043  -2.3175082   1.555654\n -2.8582046  -1.0382828  -2.5852144  -0.53663033]"",""76"":""[ 4.8380294   5.233632    4.2090487  -1.6887107  -2.1697748   1.189358\n -2.6636403  -0.50867605 -3.3957393  -0.61544967]"",""77"":""[ 4.7618413   5.1762524   4.6619225  -1.5532165  -2.3485074   0.96464217\n -2.7717268  -1.153565   -2.759123   -0.83627504]"",""78"":""[ 5.143466    5.3560786   4.616181   -1.1235657  -3.6373827   2.6238406\n -3.5170608  -0.57331616 -2.4526942  -0.4114963 ]"",""79"":""[ 4.6024866   5.625757    4.1261344  -1.5693266  -1.6932639   1.4089898\n -2.6988714  -0.99420327 -3.001739   -0.8563271 ]"",""80"":""[ 4.8800187   5.8487177   4.0396905  -0.54284024 -3.7648408   3.1394436\n -3.0520952  -0.5284319  -2.5529947  -0.89547855]"",""81"":""[ 5.088146    5.6627192   3.9358644  -1.4055605  -2.4638789   1.1696804\n -2.6240354  -0.8155789  -2.6125586  -0.94263303]"",""82"":""[ 5.051487    5.294997    4.8654838  -0.9705118  -3.7304628   2.6484165\n -3.4778898  -0.11844022 -2.8969297  -0.5624632 ]"",""83"":""[ 4.731743    5.5633545   4.595748   -0.9357656  -3.1054914   1.4699467\n -3.0751007   0.28146362 -3.5964224  -0.87309206]"",""84"":""[ 4.8657293   5.4662905   4.5824695  -1.3347839  -2.6181462   1.0249827\n -3.4362087  -0.31603482 -2.89991    -0.8028443 ]"",""85"":""[ 4.729638    5.1105576   4.9727716  -1.6398414  -2.618711    0.92876977\n -2.9237387  -0.416947   -3.258365   -0.8510653 ]"",""86"":""[ 4.5742517  5.5576086  4.257799  -1.6519611 -1.6698514  1.2319874\n -2.641065  -1.0620228 -2.9916654 -0.8468878]"",""87"":""[ 5.0749536   5.4111195   4.4613976  -1.0477037  -3.588129    3.0185554\n -3.337548   -0.68222624 -2.4617953  -0.548963  ]"",""88"":""[ 4.8467317   6.039478    4.046636   -0.11777329 -3.3338406   2.2699318\n -3.4139824   0.7990496  -3.7195659  -0.5838613 ]"",""89"":""[ 4.610103    5.460342    4.4608083  -1.5996932  -1.9518033   1.0361438\n -2.682933   -0.95455897 -2.9891603  -0.8931335 ]"",""90"":""[ 4.807294    5.714748    4.6058264  -0.50028753 -3.493358    2.2301588\n -3.615446    0.5327425  -3.5454996  -0.5811762 ]"",""91"":""[ 4.9860654   6.5332694   2.7950172   0.57178813 -2.9120178   1.9463925\n -3.2271302   1.7259436  -4.5224934   0.13455924]"",""92"":""[ 5.180676    5.1015854   4.564848   -1.636037   -3.0529263   0.9971615\n -2.758465   -0.29982996 -3.037644   -0.7203782 ]"",""93"":""[ 5.329678    5.191461    4.1945796  -1.8253776  -2.8653493   1.6253729\n -2.7022035  -0.7344997  -2.6384294  -0.60029316]"",""94"":""[ 4.808637    5.5387716   4.0002966  -1.6830198  -1.9038332   1.3547032\n -2.755056   -1.0497485  -2.7701926  -0.68618286]"",""95"":""[ 4.9665756   6.45145     2.8331983   0.47464314 -2.749672    1.7359596\n -3.0658016   1.6770892  -4.5175524   0.20142394]"",""96"":""[ 5.0027895   5.494353    4.4391503  -0.9103116  -3.6546988   2.965167\n -3.360521   -0.5388844  -2.57708    -0.61666745]"",""97"":""[ 4.9733443   6.068847    3.5389528   0.08928322 -3.2406354   2.083759\n -3.505154    1.2427727  -4.0463505  -0.23643012]"",""98"":""[ 5.1880436   5.0318923   4.597049   -1.3285835  -3.091109    0.65712476\n -3.0838122  -0.5710807  -2.6659482  -0.5857033 ]"",""99"":""[ 5.015777   5.411414   4.2486777 -1.2703775 -3.1185646  2.53736\n -3.1482532 -0.9126271 -2.4436703 -0.5760769]"",""100"":""[ 5.399692    5.2106247   4.3011975  -1.4932437  -3.2658124   1.7777704\n -2.769589   -1.0428023  -2.1950746  -0.57392067]"",""101"":""[ 4.946842    6.0721097   3.4843576   0.07160178 -3.1977654   2.106263\n -3.516498    1.3047806  -4.108958   -0.2582597 ]"",""102"":""[ 5.142269    5.2297626   4.7964077  -1.090343   -3.6846588   2.8155985\n -3.410389   -0.36736807 -2.7120607  -0.49695536]"",""103"":""[ 5.2861342   5.238249    4.517746   -1.3608068  -3.4344318   2.2759144\n -3.240796   -0.56883043 -2.4894576  -0.45851365]"",""104"":""[ 4.554388    5.1268644   4.615205   -1.6768523  -2.012658    1.4795868\n -2.8968043  -1.1901487  -3.0146081  -0.70981795]"",""105"":""[ 4.8076105   5.548716    4.343511   -1.0374427  -2.5832045   1.5411279\n -3.1202755  -0.90370166 -2.6320035  -0.75197613]"",""106"":""[ 5.0392194   6.3548665   2.9001648   0.4572256  -2.7323472   1.6581659\n -3.018742    1.7999333  -4.5637665   0.30149013]"",""107"":""[ 5.1464276   5.2877884   4.594675   -1.1445452  -3.4945803   2.9376655\n -3.3932939  -0.6081812  -2.555642   -0.43124282]"",""108"":""[ 5.0504823   5.7301664   3.940644   -0.72706413 -3.5797744   2.662294\n -2.7518342  -0.71479815 -2.3878508  -0.92396975]"",""109"":""[ 5.28379     5.04553     4.1308937  -1.9032363  -2.6172397   1.4857006\n -2.9670238  -0.9721319  -2.4468482  -0.43474528]"",""110"":""[ 4.894539    5.9775796   3.8748276  -0.22714062 -3.5192413   2.5839305\n -3.2475615   0.42553562 -3.4182723  -0.6819116 ]"",""111"":""[ 5.360941    5.670404    2.5751524  -0.40321288 -4.012982    3.3554769\n -3.218571   -0.03425257 -3.5342748  -0.5183291 ]"",""112"":""[ 5.0969687  5.1790876  4.8516054 -1.114209  -3.62904    1.9872135\n -3.5980537  0.0972447 -2.9965746 -0.4888811]"",""113"":""[ 4.502718   5.459949   4.3332286 -1.6459349 -1.855054   1.4140984\n -2.8248804 -1.1015382 -2.97163   -0.6717188]"",""114"":""[ 4.5457773   5.6253457   4.0912437  -1.4497495  -1.7151814   1.3883529\n -2.7894366  -1.0372477  -2.9805746  -0.75815874]"",""115"":""[ 4.9306765   6.4168115   2.836696    0.36978447 -2.6401892   1.6291595\n -2.9931936   1.5584972  -4.4653406   0.22424743]"",""116"":""[ 4.908666    5.4519377   4.8408594  -0.78381336 -3.705609    2.4558008\n -3.693988    0.06204681 -3.021163   -0.5241458 ]"",""117"":""[ 5.008062    6.6000237   2.930846    0.70787126 -3.1210668   2.061826\n -3.2932107   1.8994906  -4.582101   -0.02283932]"",""118"":""[ 5.0269113   5.802714    3.8487387  -0.61742336 -3.6457112   2.7536983\n -2.838254   -0.6056482  -2.4845002  -0.93453455]"",""119"":""[ 4.75269    5.5071707  4.131573  -1.7365268 -1.8151584  1.2077672\n -2.662162  -1.021333  -2.8699214 -0.7441366]"",""120"":""[ 5.272863    5.7195377   2.6959193  -0.47119913 -3.967932    3.3495283\n -3.1441     -0.13167872 -3.4303896  -0.6208689 ]"",""121"":""[ 5.3480096   5.7356625   2.615771   -0.4910173  -3.9269955   3.307897\n -3.1787775  -0.09050929 -3.495722   -0.57513696]"",""122"":""[ 4.8077035   5.6684365   4.3268437  -1.3408169  -2.3350637   1.0824094\n -3.1526442  -0.46576822 -2.8972483  -0.90482116]"",""123"":""[ 5.268334    5.165398    4.0992146  -1.8242776  -2.5238235   1.3016316\n -2.9271247  -0.9012996  -2.4784346  -0.53577447]"",""124"":""[ 5.2857456   5.603362    2.6601825  -0.33260977 -4.0888853   3.305063\n -3.221487   -0.02439349 -3.4974153  -0.54102206]"",""125"":""[ 5.427786    5.7784395   2.5336099  -0.49646366 -3.8970551   3.2725935\n -3.1566153  -0.07858519 -3.560391   -0.55342704]"",""126"":""[ 4.7508154   4.8744164   4.99232    -1.668422   -2.557004    0.8492207\n -2.8856027  -0.97330785 -2.990041   -0.7975407 ]""},""topic"":{""0"":7,""1"":3,""2"":4,""3"":5,""4"":-1,""5"":-1,""6"":1,""7"":1,""8"":7,""9"":3,""10"":3,""11"":-1,""12"":5,""13"":-1,""14"":3,""15"":7,""16"":4,""17"":-1,""18"":8,""19"":1,""20"":6,""21"":-1,""22"":-1,""23"":3,""24"":5,""25"":5,""26"":7,""27"":3,""28"":5,""29"":6,""30"":-1,""31"":3,""32"":7,""33"":5,""34"":2,""35"":6,""36"":-1,""37"":2,""38"":8,""39"":1,""40"":-1,""41"":-1,""42"":4,""43"":-1,""44"":6,""45"":7,""46"":5,""47"":6,""48"":-1,""49"":2,""50"":-1,""51"":6,""52"":2,""53"":-1,""54"":-1,""55"":8,""56"":7,""57"":3,""58"":4,""59"":5,""60"":5,""61"":5,""62"":-1,""63"":5,""64"":-1,""65"":1,""66"":1,""67"":-1,""68"":8,""69"":4,""70"":6,""71"":8,""72"":8,""73"":6,""74"":-1,""75"":-1,""76"":-1,""77"":8,""78"":5,""79"":8,""80"":2,""81"":8,""82"":5,""83"":-1,""84"":-1,""85"":7,""86"":8,""87"":5,""88"":6,""89"":8,""90"":5,""91"":1,""92"":-1,""93"":4,""94"":8,""95"":1,""96"":5,""97"":6,""98"":-1,""99"":-1,""100"":4,""101"":6,""102"":5,""103"":-1,""104"":-1,""105"":-1,""106"":1,""107"":5,""108"":2,""109"":4,""110"":-1,""111"":0,""112"":-1,""113"":8,""114"":8,""115"":1,""116"":5,""117"":1,""118"":2,""119"":8,""120"":0,""121"":0,""122"":-1,""123"":4,""124"":0,""125"":0,""126"":7},""exemplar"":{""0"":null,""1"":""*"",""2"":""*"",""3"":null,""4"":null,""5"":null,""6"":""*"",""7"":""*"",""8"":null,""9"":null,""10"":""*"",""11"":null,""12"":null,""13"":null,""14"":null,""15"":""*"",""16"":null,""17"":null,""18"":null,""19"":""*"",""20"":""*"",""21"":null,""22"":null,""23"":""*"",""24"":""*"",""25"":null,""26"":""*"",""27"":""*"",""28"":null,""29"":null,""30"":null,""31"":""*"",""32"":""*"",""33"":null,""34"":""*"",""35"":""*"",""36"":null,""37"":""*"",""38"":null,""39"":""*"",""40"":null,""41"":null,""42"":""*"",""43"":null,""44"":""*"",""45"":null,""46"":""*"",""47"":null,""48"":null,""49"":""*"",""50"":null,""51"":""*"",""52"":""*"",""53"":null,""54"":null,""55"":null,""56"":""*"",""57"":null,""58"":""*"",""59"":null,""60"":null,""61"":null,""62"":null,""63"":null,""64"":null,""65"":null,""66"":null,""67"":null,""68"":""*"",""69"":""*"",""70"":""*"",""71"":""*"",""72"":null,""73"":null,""74"":null,""75"":null,""76"":null,""77"":null,""78"":""*"",""79"":""*"",""80"":""*"",""81"":null,""82"":""*"",""83"":null,""84"":null,""85"":""*"",""86"":""*"",""87"":null,""88"":null,""89"":null,""90"":null,""91"":""*"",""92"":null,""93"":null,""94"":null,""95"":null,""96"":null,""97"":null,""98"":null,""99"":null,""100"":""*"",""101"":null,""102"":""*"",""103"":null,""104"":null,""105"":null,""106"":null,""107"":""*"",""108"":null,""109"":null,""110"":null,""111"":""*"",""112"":null,""113"":""*"",""114"":""*"",""115"":null,""116"":""*"",""117"":null,""118"":null,""119"":null,""120"":""*"",""121"":""*"",""122"":null,""123"":null,""124"":""*"",""125"":""*"",""126"":null},""word*"":{""0"":""data"",""1"":""subspace*"",""2"":""view*"",""3"":""fig"",""4"":""users"",""5"":""trackball"",""6"":""ieee*"",""7"":""ppa*"",""8"":""cluster"",""9"":""axis"",""10"":""subspaces*"",""11"":""projection"",""12"":""high"",""13"":""3d"",""14"":""dimension"",""15"":""visual*"",""16"":""views"",""17"":""mouse"",""18"":""exploration"",""19"":""stm*"",""20"":""b*"",""21"":""dimensions"",""22"":""participants"",""23"":""vectors*"",""24"":""a*"",""25"":""blue"",""26"":""visualization*"",""27"":""vector*"",""28"":""magenta"",""29"":""n"",""30"":""team"",""31"":""dimensional*"",""32"":""optimization*"",""33"":""green"",""34"":""11*"",""35"":""j*"",""36"":""sales"",""37"":""8*"",""38"":""revenue"",""39"":""aco*"",""40"":""label"",""41"":""computer"",""42"":""basis*"",""43"":""tripadvisornd"",""44"":""m*"",""45"":""dataset"",""46"":""current*"",""47"":""p"",""48"":""images"",""49"":""12*"",""50"":""navigation"",""51"":""t*"",""52"":""13*"",""53"":""panel"",""54"":""cost"",""55"":""teams"",""56"":""graphics*"",""57"":""direction"",""58"":""case*"",""59"":""interesting"",""60"":""projected"",""61"":""overlap"",""62"":""pat"",""63"":""trans"",""64"":""button"",""65"":""tina"",""66"":""mueller"",""67"":""generalized"",""68"":""tuition*"",""69"":""understanding*"",""70"":""h*"",""71"":""college*"",""72"":""weather"",""73"":""z"",""74"":""weighting"",""75"":""opportunities"",""76"":""nightlife"",""77"":""research"",""78"":""leads*"",""79"":""athletic*"",""80"":""15*"",""81"":""participant"",""82"":""adjacent*"",""83"":""pad"",""84"":""pheromone"",""85"":""animation*"",""86"":""academic*"",""87"":""asked"",""88"":""pp"",""89"":""science"",""90"":""gram"",""91"":""schmidt*"",""92"":""thumbnail"",""93"":""notices"",""94"":""schools"",""95"":""ucla"",""96"":""chosen"",""97"":""\u03b2"",""98"":""parameter"",""99"":""opportunity"",""100"":""reasoning*"",""101"":""\u03b3"",""102"":""separated*"",""103"":""moves"",""104"":""transportation"",""105"":""score"",""106"":""usnewsscore"",""107"":""spent*"",""108"":""2012"",""109"":""ambiguities"",""110"":""da"",""111"":""\ud835\udefd*"",""112"":""vertical"",""113"":""school*"",""114"":""athletics*"",""115"":""georgiatech"",""116"":""saturated*"",""117"":""proc"",""118"":""2015"",""119"":""degrees"",""120"":""\ud835\udf03\ud835\udc63*"",""121"":""\ud835\udf03\u210e*"",""122"":""ants"",""123"":""solutions"",""124"":""\ud835\udefc1*"",""125"":""\ud835\udefc2*"",""126"":""retrieval""},""pos"":{""0"":1,""1"":1,""2"":1,""3"":1,""4"":1,""5"":2,""6"":1,""7"":2,""8"":2,""9"":2,""10"":3,""11"":3,""12"":2,""13"":4,""14"":4,""15"":3,""16"":2,""17"":5,""18"":1,""19"":3,""20"":1,""21"":6,""22"":7,""23"":5,""24"":3,""25"":4,""26"":4,""27"":6,""28"":5,""29"":2,""30"":8,""31"":7,""32"":5,""33"":6,""34"":1,""35"":3,""36"":9,""37"":2,""38"":2,""39"":4,""40"":10,""41"":11,""42"":3,""43"":12,""44"":4,""45"":6,""46"":7,""47"":5,""48"":13,""49"":3,""50"":14,""51"":6,""52"":4,""53"":15,""54"":16,""55"":3,""56"":7,""57"":8,""58"":4,""59"":8,""60"":9,""61"":10,""62"":17,""63"":11,""64"":18,""65"":5,""66"":6,""67"":19,""68"":4,""69"":5,""70"":7,""71"":5,""72"":6,""73"":8,""74"":20,""75"":21,""76"":22,""77"":7,""78"":12,""79"":8,""80"":5,""81"":9,""82"":13,""83"":23,""84"":24,""85"":8,""86"":10,""87"":14,""88"":9,""89"":11,""90"":15,""91"":7,""92"":25,""93"":6,""94"":12,""95"":8,""96"":16,""97"":10,""98"":26,""99"":27,""100"":7,""101"":11,""102"":17,""103"":28,""104"":29,""105"":30,""106"":9,""107"":18,""108"":6,""109"":8,""110"":31,""111"":1,""112"":32,""113"":13,""114"":14,""115"":10,""116"":19,""117"":11,""118"":7,""119"":15,""120"":2,""121"":3,""122"":33,""123"":9,""124"":4,""125"":5,""126"":9},""x2D"":{""0"":-3.5787928104,""1"":-2.9313983917,""2"":-1.5206382275,""3"":-5.9138426781,""4"":-2.8947057724,""5"":-4.7314381599,""6"":-23.2558670044,""7"":-23.231672287,""8"":-3.6707875729,""9"":-2.9903604984,""10"":-2.947779417,""11"":-3.256503582,""12"":-3.3724946976,""13"":-4.4493050575,""14"":-3.1349058151,""15"":-4.3724226952,""16"":-1.6578221321,""17"":-4.8427991867,""18"":-4.4800729752,""19"":-23.5132637024,""20"":-6.5762643814,""21"":-3.2377934456,""22"":-3.0197138786,""23"":-3.0698559284,""24"":-3.3250677586,""25"":-4.1358623505,""26"":-4.1798591614,""27"":-2.8959574699,""28"":-4.4511785507,""29"":-6.3481960297,""30"":-3.3712773323,""31"":-3.0440194607,""32"":-3.6579496861,""33"":-4.1781096458,""34"":-1.4322896004,""35"":-6.8212628365,""36"":-4.9846577644,""37"":-1.6415971518,""38"":-4.9375162125,""39"":-23.6455421448,""40"":-3.0541660786,""41"":-4.5068650246,""42"":-1.3317182064,""43"":-4.0592398643,""44"":-6.4733829498,""45"":-3.5017066002,""46"":-3.1685023308,""47"":-6.2153291702,""48"":-4.0503706932,""49"":-1.6569026709,""50"":-4.3909444809,""51"":-6.5890583992,""52"":-1.572483182,""53"":-3.2149271965,""54"":-4.8142089844,""55"":-3.4177558422,""56"":-4.5788812637,""57"":-2.8670918941,""58"":-1.3755567074,""59"":-2.787863493,""60"":-2.4928905964,""61"":-2.734146595,""62"":-4.8226466179,""63"":-4.3235144615,""64"":-4.6976633072,""65"":-23.4962158203,""66"":-23.389289856,""67"":-3.2362632751,""68"":-4.493927002,""69"":-1.650326252,""70"":-6.744248867,""71"":-4.3227643967,""72"":-4.4396591187,""73"":-6.915825367,""74"":-3.3736915588,""75"":-2.264146328,""76"":-4.2259488106,""77"":-4.291238308,""78"":-2.3419737816,""79"":-4.2753009796,""80"":-1.4365022182,""81"":-3.1086654663,""82"":-3.078527689,""83"":-4.7889122963,""84"":-3.6974842548,""85"":-4.5196604729,""86"":-4.3173847198,""87"":-2.0509288311,""88"":-6.1843709946,""89"":-4.3457455635,""90"":-4.5986933708,""91"":-23.3810443878,""92"":-3.9958045483,""93"":-1.8543237448,""94"":-3.8451328278,""95"":-23.5482807159,""96"":-2.0781443119,""97"":-7.0149269104,""98"":-3.468487978,""99"":-1.9817599058,""100"":-1.4762818813,""101"":-6.9809045792,""102"":-2.5582692623,""103"":-2.2797019482,""104"":-4.9044699669,""105"":-3.4313693047,""106"":-23.4731082916,""107"":-2.2095944881,""108"":-1.5955150127,""109"":-1.9747128487,""110"":-6.0598773956,""111"":-1.3795200586,""112"":-3.3508591652,""113"":-4.5872879028,""114"":-4.2136268616,""115"":-23.3933258057,""116"":-3.6553940773,""117"":-23.1615276337,""118"":-1.4357736111,""119"":-4.1780204773,""120"":-1.2855068445,""121"":-1.2931647301,""122"":-3.6378264427,""123"":-2.1323125362,""124"":-1.4111979008,""125"":-1.3142018318,""126"":-4.244852066},""y2D"":{""0"":1.523142457,""1"":0.0674778074,""2"":1.9784010649,""3"":-3.2719271183,""4"":3.3028154373,""5"":-0.9928761125,""6"":-6.606359005,""7"":-6.7703046799,""8"":1.4269206524,""9"":-0.6116544604,""10"":-0.039051868,""11"":-0.3163610101,""12"":-2.361853838,""13"":0.8623192906,""14"":-0.3172619045,""15"":1.2452652454,""16"":2.2623701096,""17"":-1.1148860455,""18"":1.9484363794,""19"":-6.8111081123,""20"":-3.6361813545,""21"":0.094960399,""22"":3.1874966621,""23"":0.1138355136,""24"":-2.2480845451,""25"":-2.4451286793,""26"":1.3326386213,""27"":-0.2680882514,""28"":-2.464471817,""29"":-3.6227221489,""30"":3.059429884,""31"":-0.1561918855,""32"":1.179695487,""33"":-2.3968248367,""34"":-3.807230711,""35"":-3.4069719315,""36"":4.1057081223,""37"":-3.5750827789,""38"":4.0567364693,""39"":-6.7809000015,""40"":-0.8386169672,""41"":2.2980589867,""42"":1.9552385807,""43"":2.8491859436,""44"":-3.4143517017,""45"":1.0107798576,""46"":-2.3477892876,""47"":-3.2467763424,""48"":0.8600278497,""49"":-3.571598053,""50"":1.775616169,""51"":-3.4737315178,""52"":-3.6502654552,""53"":2.7710177898,""54"":4.1879968643,""55"":3.3729605675,""56"":1.2037190199,""57"":-1.0050753355,""58"":1.733676672,""59"":-2.3120911121,""60"":-2.6728978157,""61"":-2.3862011433,""62"":-1.8216392994,""63"":-2.6657686234,""64"":-1.4544939995,""65"":-6.5242476463,""66"":-6.6584420204,""67"":-1.9782035351,""68"":4.0817246437,""69"":1.7667379379,""70"":-3.7332010269,""71"":4.0138168335,""72"":2.6393537521,""73"":-3.5277650356,""74"":2.1394481659,""75"":2.8362495899,""76"":2.9015636444,""77"":2.1988232136,""78"":-2.499961853,""79"":3.8723621368,""80"":-3.7897901535,""81"":3.1142356396,""82"":-2.596555233,""83"":-1.3167680502,""84"":2.092867136,""85"":1.3068282604,""86"":3.7310204506,""87"":-2.7235980034,""88"":-3.3985629082,""89"":3.2844643593,""90"":-2.5181334019,""91"":-6.7759375572,""92"":0.792647481,""93"":2.3647153378,""94"":3.6527478695,""95"":-7.0177221298,""96"":-2.8835442066,""97"":-3.4210729599,""98"":0.8471879959,""99"":-2.2787265778,""100"":1.7815965414,""101"":-3.5857863426,""102"":-2.5863075256,""103"":-2.0079119205,""104"":3.8990137577,""105"":2.8092653751,""106"":-7.0500559807,""107"":-2.5650982857,""108"":-3.419711113,""109"":2.5461087227,""110"":-3.4334158897,""111"":-4.9437451363,""112"":-1.8913300037,""113"":3.8341023922,""114"":3.837649107,""115"":-7.1114430428,""116"":-2.4320530891,""117"":-6.7210493088,""118"":-3.6908071041,""119"":3.6996104717,""120"":-4.931224823,""121"":-4.7956700325,""122"":2.5856163502,""123"":2.6631519794,""124"":-4.8578701019,""125"":-4.8247199059,""126"":1.7039107084}}",False,False,False,http://ieeexplore.ieee.org/document/7862917/,,The Subspace Voyager: Exploring High-Dimensional Data along a Continuum of Salient 3D Subspaces,ZMGBDR3L,False,False
VA72NXDN,WCW4X466,"Voyagers and Voyeurs:  
Supporting Asynchronous 
Collaborative Visualization

Doi:10.1145/1435417.1435439

By Jeffrey Heer, Fernanda B. Viégas, and Martin Wattenberg

abstract
This article describes mechanisms for asynchronous collab-
oration in the context of information visualization, recasting 
visualizations  as  not  just  analytic  tools,  but  social  spaces. 
We contribute the design and implementation of sense.us, 
a Web site supporting asynchronous collaboration across a 
variety of visualization types. The site supports view sharing, 
discussion, graphical annotation, and social navigation and 
includes novel interaction elements. We report the results 
of user studies of the system, observing emergent patterns 
of social data analysis, including cycles of observation and 
hypothesis, and the complementary roles of social naviga-
tion and data-driven exploration.

1. intRoDuction
Visual  representations  of  information  often  lead  to  new 
insights by enabling viewers to see data in context, observe 
patterns, and make comparisons. In this way, visualizations 
leverage the human visual system to improve our ability to 
process  large  amounts  of  data.  Card  et  al.6  describe  how 
visualization supports the process of sensemaking, in which 
information  is  collected,  organized,  and  analyzed  to  form 
new knowledge and inform further action. They emphasize 
the ways visualization exploits an individual’s visual percep-
tion to facilitate cognition.

In practice, however, sensemaking is often also a social 
process. People may disagree on how to interpret the data 
and  may  contribute  contextual  knowledge  that  deepens 
understanding.  As  participants  build  consensus  or  make 
decisions  they  learn  from  their  peers.  Furthermore,  some 
data sets are so large that thorough exploration by a single 
person  is  unlikely.  This  suggests  that  to  fully  support  sen-
semaking,  visualizations  should  also  support  social  inter-
action. In this spirit, a recent report23 names the design of 
collaborative  visualization  tools  as  a  grand  challenge  for 
visualization research.

These  considerations  are  not  just  hypothetical.  For 
example, the manager of a business group in our company 
described  to  us  how  quarterly  reports  are  disseminated 
within  his  organization  via  e-mail.  Heated  discussion 
takes place around charts and graphs as the group debates 
the  causes  of  sales  trends  and  considers  possible  future 
actions. However, writing about particular trends or views 
is  difficult,  involving  awkward  references  to  attached 
spreadsheets from the e-mail text. Furthermore, the discus-
sion is scattered and disconnected from the visualizations, 

making it difficult for newcomers to catch up or others to 
review and summarize the discussion thus far. According to 
the manager of the group, the analysis process could ben-
efit from a system for sharing, annotating, and discussing 
the visualized data.

Similar  scenarios  appear  in  other  domains.  Moreover, 
experiences  with  deployments  of  visualizations  hint  at 
ways  that  social  phenomena  already  occur  around  visual-
izations.  Wattenberg  and  Kriss27  describe  the  response  to 
NameVoyager,  an  online  visualization  of  historical  baby 
name  trends.  Playful  yet  often  surprisingly  deep  analysis 
appeared on numerous blogs as participants discussed their 
insights  and  hypotheses.  Observing  the  use  of  a  physical 
installation of the Vizster social network visualization, Heer18 
noted that groups of users, spurred by storytelling of shared 
memories,  spent  more  time  exploring  and  asked  deeper 
analysis questions than individuals. Similarly, Viégas et al.24 
found that users of the PostHistory e-mail archive visualiza-
tion  immediately  wanted  to  share  views  with  friends  and 
family and engage in storytelling.

While  suggestive,  these  observations  provide  only  a  cir-
cumstantial  understanding  of  the  social  aspects  of  asyn-
chronous analysis around visualizations. In the case of the 
NameVoyager and PostHistory, the findings were essentially 
accidental. Vizster was designed for playful interaction, but 
in a synchronous and less analytic context. It would there-
fore  be  valuable  to  replicate  these  findings  to  deepen  our 
understanding of this type of interaction.

Furthermore, if social interaction is an important accom-
paniment to data visualization, it is natural to look for ways 
to  support  and  encourage  it.  To  address  both  these  goals, 
we designed and implemented a Web site, sense.us, aimed 
at group exploration of demographic data. The site provides 
a suite of interactive visualizations and facilitates collabora-
tion through view bookmarking, doubly linked discussions, 
graphical  annotation,  saved  bookmark  trails,  and  social 
navigation through comment listings and user profiles. We 
then conducted user studies to observe closely how people 
engage in social data analysis. The studies also allowed us 
to evaluate the new design elements in the site and suggest 
directions for future work.

A  previous  version  of  this  paper  was  published  in  the  
Proceedings of the SIGCHI Conference on Human Factors in 
Computing Systems, April 2007.

January 2009  |   V ol. 52  |   no. 1  |   communications of thE acm     87

research highlights 

2. PRioR WoRK
Collaboration has been well studied in contexts that are not 
directly  related  to  information  visualization.  The  study  of 
how computer systems can enable collaboration is referred 
to as computer-supported cooperative work, or CSCW. Because 
collaboration occurs in a variety of situations, CSCW schol-
ars often use a “time-space” matrix21 to outline the concep-
tual landscape. The time dimension represents whether or 
not  participants  interact  at  the  same  time  (synchronously 
or  asynchronously)—for  example,  instant  messaging  is  a 
largely synchronous communication medium, while e-mail 
is  asynchronous.  The  space  dimension  describes  whether 
users are collocated or geographically distributed.

Most work on collaborative visualization has been done 
in  the  context  of  synchronous  scenarios:  users  interact-
ing at the same time to analyze scientific results or discuss 
the  state  of  a  battlefield.  Collocated  collaboration  usually 
involves shared displays, including wall-sized, table-top, or 
virtual  reality  displays  (e.g.,  Dietz,14  General  Dynamics16). 
Systems  supporting  remote  collaboration  have  primar-
ily  focused  on  synchronous  interaction,1,4  such  as  shared 
virtual  workspaces8  and  augmented  reality  systems  that 
enable multiple users to interact concurrently with visual-
ized  data.3,9  In  addition,  the  availability  of  public  displays 
has  prompted  researchers  to  experiment  with  asynchro-
nous, collocated visualization (same place, different time), 
for  example,  in  the  form  of  ambient  displays  that  share 
activity information about collocated users.7

In  this  article,  we  focus  on  remote  asynchronous 
 collaboration—the kind of collaboration that is most com-
mon over the Web. One reason for our interest is that parti-
tioning work across both time and space holds the potential 
of greater scalability in group-oriented analysis. For exam-
ple,  one  decision-making  study  found  that  asynchronous 
collaboration resulted in higher-quality outcomes—broader 
discussions, more complete reports, and longer solutions—
than  face-to-face  collaboration.2  However,  as  noted  by 
Viégas and Wattenberg,25 little research attention has been 
dedicated  to  asynchronous  collaboration  around  interac-
tive visualization. Instead, users often rely on static imag-
ery when communicating about these interactive systems. 
Images of the visualization are transferred as printouts or 
screenshots,  or  included  in  word-processing  or  presenta-
tion documents.

A few commercial visualization systems introduced prior 
to  our  work  provide  asynchronous  collaboration  features. 
Online mapping systems (e.g., Google Maps) provide book-
marks (URLs) that users can send to others to share views. 
The  visualization  company  Spotfire  provides  DecisionSite 
Posters,  a  Web-based  system  that  allows  a  user  to  post  an 
interactive  visualization  view  that  other  users  can  explore 
and  comment  on.  The  Posters  apply  only  to  a  subset  of 
Spotfire’s full functionality and do not allow graphical anno-
tations, limiting their adoption.25

One  common  feature  of  these  systems  is  application 
bookmarks: URLs or URL-like objects that point back into a 
particular  state  of  the  application,  for  example,  a  location 
and zoom level in the case of Google Maps. This pattern is 
not surprising; for users to collaborate, they must be able to 

88    communications of thE acm   |   January 2009  |   V ol. 52  |   no. 1

 

share  what  they  are  seeing  to  establish  a  common  ground 
for conversation.12

One  of  the  primary  uses  of  bookmarks  is  in  discussion 
forums  surrounding  a  visualization.  Some  systems  use 
what  we  term  independent  discussion,  where  conversations 
are decoupled from the visualization. For example, Google 
Earth provides threaded discussion forums with messages 
that  include  bookmarks  into  the  visualized  globe.  In  such 
systems there are unidirectional links from the discussion 
to  the  visualization,  but  no  way  to  discover  related  com-
ments while navigating the visualization itself.

Another  stream  of  related  work  comes  from  wholly 
or  partly  visual  annotation  systems,  such  as  the  regional 
annotations in sites such as Flickr.com and Wikimapia.org 
and  in  Churchill  et  al.’s  anchored  conversations.10  Such 
systems enable embedded discussion that places conversa-
tional markers directly within a visualization or document. 
Discussion  of  a  specific  item  may  be  accessed  through  a 
linked  annotation  shown  within  the  visualization.  These 
systems may be seen as the converse of independent dis-
cussions, allowing unidirectional links from an artifact to 
commentary.

In this article, we extend the past work with a comprehen-
sive design for asynchronous collaboration around interac-
tive  data  visualizations,  addressing  issues  of  view  sharing, 
discussion, graphical annotation, and social navigation.

3. thE DEsiGn of sEnsE.us
To  explore  the  possibilities  for  asynchronous  collabora-
tive visualization, we designed and implemented sense.us, 
a prototype Web application for social visual data analysis. 
The  site  provides  a  suite  of  visualizations  of  United  States 
census  data  over  the  last  150  years  (see  Figures  1  and  2) 
and  was  designed  for  use  by  a  general  audience.  We  built 
sense. us to put our design hypotheses into a concrete form 
which we could then deploy and use to study collaborative 
data exploration.

The  primary  interface  for  sense.us  is  shown  in  Figure 
1. In the left panel is a Java applet containing a visualiza-
tion. The right panel provides a discussion area, display-
ing commentary associated with the current visualization 
view,  and  a  graphical  bookmark  trail,  providing  access 
to views bookmarked by the user. With a straightforward 
bookmarking  mechanism,  sense.us  supports  collabora-
tion with features described in detail below: doubly linked 
discussions,  graphical  annotations,  saved  bookmark 
trails, and social navigation via comment listings and user 
activity profiles.

3.1. View sharing
When  collaborating  around  visualizations,  participants 
must be able to see the same visual environment in order to 
ground12 each others’ actions and comments. To this aim, 
the  sense.us  site  provides  a  mechanism  for  bookmark-
ing  views.  The  system  makes  application  bookmarking 
transparent  by  tying  it  to  conventional  Web  bookmark-
ing. The browser’s location bar always displays a URL that 
links  to  the  current  state  of  the  visualization,  defined  by 
the  settings  of  filtering,  navigation,  and  visual  encoding 

figure 1: the sense.us collaborative visualization system. (a) an interactive visualization applet, with a graphical annotation for the  
currently selected comment. the visualization is a stacked time-series visualization of the u.s. labor force, broken down by gender. here  
the percentage of the work force in military jobs is shown. (b) a set of graphical annotation tools. (c) a bookmark trail of saved views.  
(d) text-entry field for adding comments. Bookmarks can be dragged onto the text field to add a link to that view in the comment.  
(e) threaded comments attached to the current view. (f) uRl for the current state of the application. the uRl is updated automatically  
as the visualization state changes.

 

figure 2: sample visualizations from sense.us. (a) interactive state map. the image shows the male/female ratio of the states in 2005.  
(b) stacked time series of immigration data, showing the birthplace of u.s. residents over the last 150 years. the image shows the number 
of u.s. residents born in European countries. (c) Population pyramid, showing population variation across gender and age groups. additional 
variables are encoded using stacked, colored bands. the image visualizes school attendance in 2000; an annotation highlights the  
prevalence of adult education.

parameters.  As  the  visualization  view  changes,  the  URL 
updates  to  reflect  the  current  state  (Figure  1f),  simplify-
ing  the  process  of  sharing  a  view  through  e-mail,  blogs, 
or instant messaging by enabling users to cut-and-paste a 

link  to  the  current  view  at  any  time.  To  conform  to  user 
expectations, the browser’s back and forward buttons are 
tied to the visualization state, allowing easy navigation to 
previously seen views.

January 2009  |   V ol. 52  |   no. 1  |   communications of thE acm     89

research highlights 

3.2. Doubly linked discussion
To situate conversation around the visualization, we created 
a  technique  called  doubly  linked  discussion.  The  method 
begins with an “independent” discussion interface in which 
users can attach comments to particular states (or views) of 
a  visualization.  Comments  are  shown  on  the  right  side  of 
the  Web  page  and  grouped  into  linear  discussion  threads 
(Figure  1e).  Each  comment  shows  the  thread  topic,  com-
ment text, the author’s full name, and the time at which the 
comment was authored. Clicking on a comment takes the 
visualization  to  a  bookmarked  state  representing  the  view 
seen by the comment’s author.

Users can add comments either by starting a new thread 
or  posting  a  reply  to  an  existing  thread.  When  a  “New 
Comment” or “Reply” link is clicked, a text editor appears at 
the site where the comment will be inserted and the graphi-
cal annotation tools (discussed next) become active. Upon 
submission, the comment text and any annotations are sent 
to the server and the comment listing is updated.

The interface described above is based on links from the 
commentary into the visualization. Our system also provides 
links in the other direction: from the visualization into the 
discussion. As a user changes parameters and views in the 
visualization, they may serendipitously happen upon a view 
that another person has already commented on. When this 
occurs,  the  relevant  comments  will  automatically  appear 
in the right-hand pane. Our intuition was that this “doubly 
linked”  discussion  interface,  which  combines  aspects  of 
independent  and  embedded  discussion,  would  facilitate 
grounding  and  enable  the  visualization  itself  to  become  a 
social place.

3.3. Pointing via graphical annotation
In  real-time  collocated  collaboration,  participants  com-
monly  use  both  speech  and  gesture,  particularly  point-
ing,11,20  to  refer  to  objects  and  direct  conversation.  For 
asynchronous  collaboration,  graphical  annotations  can 
play  a  similar  communicative  role.  We  hypothesized  that 
graphical annotations would be important both for point-
ing  behavior  and  playful  commentary.  To  add  a  pictorial 
element  to  a  comment  or  point  to  a  feature  of  interest, 
authors can use drawing tools (Figure 1b) to annotate the 
commented  view.  These  tools  allow  free-form  ink,  lines, 
arrows, shapes, and text to be drawn over the visualization 
view.  The  tools  are  similar  to  presentation  tools  such  as 
Microsoft  PowerPoint  and  are  intended  to  leverage  users’ 
familiarity with such systems.

Comments  with  annotations  are  indicated  by  the  pres-
ence of a small shape logo to the left of the author’s name in 
the comment listing (see Figure 1e). When the mouse hov-
ers over an annotated comment, the comment region high-
lights  in  yellow  and  a  hand  cursor  appears.  Subsequently 
clicking the region causes the annotation to be shown and 
the highlighting to darken and become permanent. Clicking 
the  comment  again  (or  clicking  a  different  comment)  will 
remove the current annotation and highlighting.

We refer to this approach as geometric annotation, which 
operates like an “acetate layer” over the visualization, in con-
trast to data-aware annotations directly associated with the 

90    communications of thE acm   |   January 2009  |   V ol. 52  |   no. 1

 

underlying data. We chose to implement a free-form annota-
tion mechanism so that we could first study pointing behav-
iors in an unconstrained medium. Aside from the freedom 
of  expression  it  affords,  geometric  annotation  also  has  a 
technical advantage: it allows reuse of the identical annota-
tion  system  across  visualizations,  easing  implementation 
and preserving a consistent user experience.

3.4. collecting and linking views
In  data  analysis  it  is  common  to  make  comparisons 
between  different  ways  of  looking  at  data.  Furthermore, 
storytelling has been suggested to play an important role 
in social usage of visualizations, as discussed by Viégas et 
al.24 Drawing comparisons and telling stories both require 
the ability to embed multiple view bookmarks into a single 
comment.

To support such multiview comments and narratives, we 
created a “bookmark trail” widget. The bookmark trail func-
tions  something  like  a  shopping  cart:  as  a  user  navigates 
through  the  site,  he  or  she  can  click  a  special  “Add  View” 
link to add the current view to a graphical list of bookmarks 
(Figure 1c). Bookmarks from any number of visualizations 
can be added to a trail. A trail may be named and saved, mak-
ing it accessible to others.

The bookmark trail widget also functions as a short-term 
storage mechanism when making a comment that includes 
links  to  multiple  views.  Dragging  a  thumbnail  from  the 
bookmark trail and dropping it onto the text area create a 
hyperlink to the bookmarked view; users can then directly 
edit or delete the link text within the text editor. When the 
mouse hovers over the link text, a tooltip thumbnail of the 
linked view is shown.

3.5. awareness and social navigation
Social navigation15 leverages usage history to provide addi-
tional navigation options within an information space. Our 
initial system supports social navigation through comment 
listings  and  user  profile  pages  that  display  recent  activity. 
Comment  listings  provide  a  searchable  and  sortable  col-
lection  of  all  comments  made  within  the  system,  and  can 
be filtered to focus on a single visualization (see Figure 3). 
Comment  listing  pages  include  the  text  and  a  thumbnail 
image of the visualization state for each comment. Hovering 
over  the  thumbnail  yields  a  tooltip  with  a  larger  image. 
Clicking a comment link takes the user to the state of the 
visualization  where  the  comment  was  made,  displaying 
any annotations included with the comment. The author’s 
name links to the author’s profile page, which includes their 
five  most  recent  comment  threads  and  five  most  recently 
saved bookmark trails. The view also notes the number of 
comments made on a thread since the user’s last comment, 
allowing users to monitor the activity of discussions to which 
they contribute.

Although more elaborate social navigation mechanisms 
are  possible,  we  wanted  to  observe  system  usage  with 
just  these  basic  options.  We  were  particularly  interested 
in  observing  the  potential  interplay  between  data-driven 
exploration and social navigation. By allowing discussions 
to be retrieved unobtrusively while a user explores the data, 

figure 3: the sense.us comment listing page. comment listings 
display all commentary on visualizations and provide links to the 
commented visualization views.

potentially relevant conversation can be introduced into the 
exploration process. Meanwhile, comment listings and indi-
cations of recent posts may help users find views of interest, 
making social activity a catalyst for data exploration.

3.6. unobtrusive collaboration
Finally,  while  designing  sense.us  we  also  wished  to  follow 
a  common  CSCW  design  guideline:  collaborative  features 
should  not  impede  individual  usage.17  Hence  we  did  not 
litter views with prior annotations or commentary. Rather, 
commentary  on  a  visualization  is  retrieved  and  displayed 
unobtrusively on the right side of the screen and graphical 
annotations are displayed “on demand” by the user.

4. imPlEmEntation notEs
While  many  aspects  of  sense.us  rely  on  well-known  tech-
niques, this section provides implementation details for the 
more  complex  features:  application  bookmarking,  doubly 
linked discussions, and graphical annotations.

4.1. application bookmarking
Bookmarks of visualization state are implemented as a set of 
name–value  pairs  of  visualization  parameters,  listed  using 
standard URL query syntax. Normally, changing the brows-
er’s URL will force a reload of the page to prevent security 
attacks.  Because  a  reload  would  cause  a  disruptive  restart 
of the visualization applet, the bookmark URL encodes the 
query  string  as  a  page  anchor—using  the  URL  ‘#’  delim-
iter  instead  of  the  standard  ‘?’  delimiter—so  that  the  URL 
updates in place. Furthermore, updated URLs are put into 
the browser’s history stack, so that the browser’s back and 
forward buttons have their usual behavior. When a visualiza-
tion URL is updated due to use of the back or forward but-
tons or manual typing, scripts send the updated URL to the 

 

applet, which is parsed and used to update the current visu-
alization state.

4.2. Doubly linked discussions
The  bookmarking  mechanisms  alone  are  not  sufficient  to 
support  doubly  linked  discussions.  To  see  the  challenge 
in  linking  from  a  view  state  back  to  all  comments  on  that 
view,  consider  the  visualization  in  Figure  1.  When  a  user 
types  “military”  into  the  top  search  box,  they  see  all  jobs 
whose  titles  begin  with  the  string  “military.”  On  the  other 
hand,  if  they  type  only  “mili,”  they  see  all  titles  beginning 
with  “mili”—but  this  turns  out  to  be  the  identical  set  of 
jobs. These different parameter settings result in different 
URLs,  and  yet  provide  exactly  the  same  visualization  view. 
More generally, parameter settings may not have a one-to-
one mapping to visualization states. To attach discussions 
to views we therefore need an indexing mechanism which 
identifies  visualization  states  that  are  equivalent  despite 
having different parametric representations.

We  solve  this  indexing  problem  by  distinguishing 
between  two  types  of  parameters:  filter  parameters  and 
view  parameters.  Filter  parameters  determine  which  data 
elements are visible in the display. Rather than index filter 
parameters directly, we instead index the filtered state of 
the application by noting which items are currently visible, 
thereby  capturing  the  case  when  different  filter  param-
eters give rise to the same filtered state. View parameters, 
on the other hand, adjust visual mappings, such as select-
ing a normalized or absolute axis scale. Our current system 
indexes  the  view  parameters  directly.  The  bookmarking 
mechanism  implements  this  two-part  index  by  comput-
ing a probabilistically unique hash value based on both the 
filtered state and view parameters. These hash values are 
used  as  keys  for  retrieving  the  comments  for  the  current 
visualization state.

4.3. annotation
The  graphical  annotations  take  the  form  of  vector  graph-
ics drawn above the visualization. When a new comment is 
submitted, the browser requests the current annotation (if 
any) from the visualization applet. The annotation is saved 
to an XML format, which is then compressed using gzip and 
encoded  in  a  base  64  string  representation  before  being 
passed to the browser. When comments are later retrieved 
from the server, the encoded annotations are stored in the 
browser as JavaScript variables. When the user requests that 
an  annotation  be  displayed,  the  encoded  annotations  are 
passed to the applet, decoded, and drawn.

5. EValuation
To gain a preliminary understanding of asynchronous col-
laboration  practices  around  visualizations,  we  ran  explor-
atory  user  studies  of  the  sense.us  system.  The  studies  had 
two specific goals: first, to better understand emergent usage 
patterns  in  social  data  analysis;  second,  to  learn  how  well 
the  various  features  of  the  sense.us  system  supported  this 
analysis. We ran the studies in two different parts: a pair of 
controlled lab studies and a 3-week live deployment on the 
IBM  corporate  intranet.  To  analyze  the  data,  we  employed 

January 2009  |   V ol. 52  |   no. 1  |   communications of thE acm     91

 

were the visualizations of Figures 1 and 2 and a scatterplot of 
demographic metrics (see Figure 4). We also introduced two 
visualizations specific to the company: stacked time series 
of  keyword  tagging  activity  and  individual  user  activity  on 
dogear, an internal social bookmarking service. The site was 
publicized through an e-mail newsletter, an intranet article, 
and individual e-mails.

5.3. findings
In the rest of this section, we report observations from these 
studies,  organized  by  commentary,  graphical  annotations, 
navigation patterns, and use of doubly linked discussion. As 
variation in content and tone differed little across studies, 
the discussion incorporates data aggregated from each. The 
data analyzed were drawn from 12.5 h of qualitative observa-
tion and from usage logs including 258 comments: 41 from 
the pilot, 85 from the first study, 60 from the second, and 72 
from the deployment.

5.4. comments
We  first  wanted  to  learn  how  comments  were  being  used 
to  conduct  social  data  analysis—was  there  a  recognizable 
structure  to  the  discussions?  To  find  out,  we  performed  a 
formal  content  analysis  on  the  collected  comments.  Each 
paper author independently devised a coding rubric based 
upon  a  reading  of  the  comments.  We  then  compared  our 
separate rubrics to synthesize a final rubric that each author 
used to independently code the comments. The final coding 
rubric categorized comments as including zero or more of 
the following: observations, questions, hypotheses, links or 
references to other views, usage tips, socializing or joking, 
affirmations of other comments, to-dos for future actions, 
and tests of system functionality. We also coded whether or 
not comments made reference to data naming or collection 
issues,  or  to  concerns  about  the  Web  site  or  visualization 
design.  The  coded  results  were  compared  using  Cohen’s 

figure 4: scatterplot of u.s. states showing median household 
 income (x-axis) vs. retail sales per capita (y-axis). new hampshire 
and Delaware have the highest retail sales.

research highlights 

a mixed-methods analysis approach combining qualitative 
and quantitative observations.

5.1. lab study
We first ran a pilot study with 6 subjects (2 females, 4 males), 
all of whom were members of our immediate research team. 
Comments  from  the  pilot  were  visible  in  a  subsequent  12 
subject (3 females, 9 males) study, with subjects drawn from 
our greater research lab. Subjects were at least peripherally 
familiar  with  each  other  and  many  were  coworkers.  Ages 
ranged  from  the  early-twenties  to  mid-fifties  and  educa-
tion  varied  from  the  undergraduate  to  the  doctoral  level, 
spanning backgrounds in computer science, design, social 
science, and psychology. Concerned that our lab’s focus in 
collaborative software might bias results, we replicated the 
lab  study  in  a  university  environment  with  additional  12 
subjects (5 females, 7 males). Subject variation in age, edu-
cation, and social familiarity remained similar.

Subjects  conducted  a  25 min  usage  session  of  the  
sense.us system. A single visualization was available in the 
study: a stacked time series of the U.S. labor force over time, 
divided by gender (Figure 1). Users could navigate the visu-
alization by typing in text queries (matched to job title pre-
fixes), filtering by gender, and setting the axis scale, either to 
total people count or percentage values.

This  data  set  was  chosen  for  several  reasons.  First,  job 
choice is a topic that most of our users should have no dif-
ficulty relating to. Second, like many other real-world data 
sets, there are data collection issues, including missing data 
and  unclear  or  antiquated  labels.  Third,  we  suspected  the 
data would be an interesting boundary case for annotations, 
as for many visualization views, text seemed sufficient when 
referencing spikes or valleys in the data.

After a brief tutorial of system features, participants were 
instructed to use the system however they liked—no specific 
tasks were given. However, users were told that if they felt at 
a loss for action, they could browse the data for trends they 
found interesting and share their findings. An observer was 
present taking notes and a think-aloud protocol was used. 
User actions were also logged by the software. Subjects were 
run  in  sequential  order,  such  that  later  participants  could 
view  the  contributions  of  previous  subjects  but  not  vice 
versa. The system was seeded with five comments, each with 
an observation of a particular data trend.

After the study, subjects completed a short exit question-
naire  about  their  experiences.  Participants  were  asked  to 
rate on a 5-point Likert scale to what degree (1) they enjoyed 
using the system, (2) they learned something interesting, (3) 
 others’ comments were helpful in exploring the data, and if 
they found annotations useful for (4) making their own com-
ments,  or  (5)  understanding  others’  comments.  Subjects 
were  also  asked  free  response  questions  about  what  they 
liked, disliked, and would change about the system.

5.2. live deployment
We also conducted a live deployment of the system on the 
IBM corporate intranet for 3 weeks. Any employee could log 
in to the system using their existing intranet account. Eight 
visualizations  were  available  in  the  system,  among  them 

92    communications of thE acm   |   January 2009  |   V ol. 52  |   no. 1

kappa  statistic.  The  lowest  pairwise  kappa  value  was  0.74, 
indicating a satisfactory inter-rater reliability.

Most  commentary  on  sense.us  involved  data  analysis. 
A  typical comment made note of an observed trend or outlier, 
often coupled with questions, explanatory hypotheses, or both. 
A  typical  reply  involved  discussing  hypotheses  or  answering 
questions. The results of coding the comments are shown in 
Figure 5. In total, 80.6% of comments involved an observation 
of visualized data, 35.5% provided an explanatory hypothesis, 
and 38.1% included a question about the data or a hypothesis. 
Most  questions  and  hypotheses  accompanied  an  observa-
tion (91.6% and 92.2%, respectively) and half the hypotheses 
were either phrased as or accompanied by a question (49.0%).
For example, participants in both lab studies discovered 
a  large  drop  in  bartenders  around  the  1930s  and  posted 
comments  attributing  the  drop  to  alcohol  prohibition.  In 
the live deployment, one user commented on a scatterplot 
view,  asking  why  New  Hampshire  has  such  a  high  level  of 
retail  sales  per  capita  (Figure  4).  Another  user  noted  that 
New  Hampshire  does  not  have  sales  tax,  and  neither  does 
Delaware, the second highest in retail sales. In this fashion, 
discussion regularly involved the introduction of contextual 
information not present in the visualization. For instance, 
Figure  1  includes  a  timeline  of  events  that  was  iteratively 
constructed by multiple users, while the graph of teachers in 
Figure 6 notes the introduction of compulsory education.

One  instance  of  social  data  analysis  occurred  around  a 
rise, fall, and slight resurgence in the percentage of dentists 
in the labor force. The first comment (one of the five seed 
comments)  noted  the  trends  and  asked  what  was  happen-
ing.  One  subject  responded  in  a  separate  thread,  “Maybe 
this has to do with fluoridation? But there’s a bump . . . but kids 
got spoiled and had a lot of candy??” To this another subject 
responded  “As  preventative dentistry  has  become  more  effec-
tive, dentists have continued to look for ways to continue working 
(e.g., most people see the dentist twice a year now v. once a year 
just a few decades ago).” Perhaps the most telling comment, 
however, included a link to a different view, showing both 
dentists and dental technicians. As dentists had declined in 
percentage, technicians had grown substantially, indicating 
specialization within the field. To this, another user asked 
“I wonder if school has become too expensive for people to think 
about dentistry, or at least their own practice when they can go 
to  technical  school  for  less?”  Visual  data  analysis,  historical 
knowledge,  and  personal  anecdote  all  played  a  role  in  the 
sensemaking  process,  explicating  various  factors  shaping 
the data.

Another  role  of  comments  was  to  aid  data  interpreta-
tion, especially in cases of unclear meaning or anomalies in 
data collection. Overall, 15.7% of comments referenced data 
naming,  categorization,  or  collection  issues.  One  promi-
nent  occupation  was  labeled  “Operative,”  a  general  cate-
gory consisting largely of skilled labor. This term had little 
meaning to subjects, one of whom asked “what the hell is an 
operative?” Others responded to reinforce the question or to 
suggest an explanation, e.g., “I bet they mean factory worker.” 
Another subject agreed, noting that the years of the rise and 
fall  of  operatives  seemed  consistent  with  factory  workers. 
Other examples include views missing data for a single year 

figure 5: content analysis categorization of sense.us comments. 
categories are not mutually exclusive.

 

38.1%

35.5%

80.6%

Observation
Question
Hypothesis
Data Integrity
Linking
Socializing
System Design
Testing
Tips
To-do
Affirmation

15.7%
14.2%

9.0%
9.0%

5.6%
4.1%
2.6%
1.5%

0%

20%

40%

60%

80%

100%

figure 6: Visualization of the number of teachers. annotations 
 indicate the start of compulsory education and the rise of teachers 
in the post-World War ii era.

(1940 was a common culprit), leading users to comment on 
the probable case of missing data.

Some  users  were  less  interested  in  specific  views  than 
in recurring patterns. One user was interested in exploring 
careers  that  were  historically  male-dominated,  but  have 
seen increasing numbers of females in the last half-century. 
The user systematically explored the data, saving views in a 
bookmark trail later shared in a comment named “Women’s 
Rise.” Similarly, a more mathematically minded participant 
was  interested  in  patterns  of  job  fluctuations,  creating  a 
trail showcasing recurring distributions. Another searched 
for jobs that had been usurped by technology, such as bank 
tellers and telephone operators. In each of these cases, the 
result was a tour or story winding through multiple views.

Overall,  14.2%  of  comments  referenced  an  additional 
view, either implicitly in the text or explicitly through drag-
and-drop bookmark links. Although 22 of the 24 lab study 
subjects  (87.5%)  saved  at  least  one  view  to  the  bookmark 
trail,  only  14  (58.3%)  created  one  or  more  drag-and-drop 
bookmark links. The amount of view linking varied by user, 
ranging from 0 to 19 links with an average of 2.17.

Comments served other purposes as well. A number were 
simple tests of system functionality (5.6%), often deleted by 

January 2009  |   V ol. 52  |   no. 1  |   communications of thE acm     93

research highlights 

the user. Some included tips for using the system (4.1%), not-
ing how to take advantage of specific features. Overall, 9.0% 
of comments referenced the site design, either in the form 
of usage tips or feature requests. A few comments included 
to-dos for future work (2.6%), such as later adding a link to 
a relevant wikipedia article. Others served solely as affirma-
tions to another comment (1.5%). For example, people stat-
ing “I agree with that” to support a hypothesis. In many cases, 
study participants would note out loud “that is interesting!” 
without posting a comment to the system.

Finally,  some  comments  were  social  in  nature  (9.0%). 
Most pointed out trends in the data, but did so in a joking 
manner.  One  user  built  a  view  comparing  female  lawyers 
and  bartenders,  writing  “Women  at  the  bar  and  behind  the 
bar.” In the pilot study, one of our lab members annotated a 
drop in stock brokers after 1930 with a picture of a person’s 
trajectory  off  a  skyscraper  (Figure  7).  This  elicited  smiles 
and laughter from subjects in the subsequent study, one of 
whom replied with an affirmation simply saying “Whoa!”

We  also  analyzed  the  structural  aspect  of  comments. 
Excluding  comments  from  the  pilot  study,  deleted  test 
comments,  and  those  written  by  the  paper  authors,  195 
 comments were collected. Of those, 140 (71.8%) started new 
discussion  threads  while  55  (28.2%)  were  replies  to  exist-
ing threads. The average thread length was 1.35 comments 
(SD 0.82), with a maximum of 5 comments. In some cases, 
discussion spanned multiple threads.

5.5. Graphical annotation
Next, we wanted to understand how graphical annotations 
were used and to what degree they contributed to social data 
analysis.  Of  the  195  nonpilot,  nondeleted  comments,  68 
(35.9%) included annotations. The vast majority (88.6%) of 
annotations involved pointing to items or trends of interest. 
The others (11.4%) involved more playful expression, such as 
drawn smiley faces and the visual commentary of Figure 7.

Across  these  annotations,  a  total  of  179  “shapes”  were 
drawn, with the options being free-form ink, lines, arrows, 

figure 7: annotated view of stock brokers. the attached comment 
reads “Great depression ‘killed’ a lot of brokers.”

94    communications of thE acm   |   January 2009  |   V ol. 52  |   no. 1

 

rectangles,  ovals,  and  text.  Arrows  were  the  most  popular 
shape  (25.1%  of  shapes),  and  were  used  to  point  to  items 
as well as to situate information provided by text captions 
(24.6%). Ovals (17.9%) were primarily used to enclose regions 
of interest. Free-form ink drawn with the pencil tool (16.2%) 
was used for pointing, enclosing irregularly shaped regions, 
and free-form drawing. Of the rest, lines made up 14.5% of 
all shapes and rectangles only 1.7% (Figure 8).

A few users, particularly those with experience in graphic 
design, noted that graphical annotations were their favorite 
feature.  Other  users  noted  that  the  annotations  were  often 
unnecessary  for  comments  where  text  could  describe  the 
trend(s) of interest. A few of these users added annotations to 
such views anyway, saying the annotations were “surprisingly 
satisfying,” enabling “personal expression.” Exit survey results 
somewhat reflected these views, as users ranked annotations 
more useful for writing their own comments (M = 3.5/5.0, SD 
= 0.85) than understanding others’ comments (M = 3.2/5.0, 
SD = 0.90). This difference, however, did not reach statistical 
significance (t(23) = −1.67, p < 0.108, two-tailed).

5.6. Visitation and navigation
Our next questions concerned how users navigated the visual-
izations. Most users began exploring the data directly, starting 
from  the  default  overview  and  drilling  down.  A  few  imme-
diately went to the comments listing to see what others had 
done. Many participants searched for their own occupations 
and  those  of  friends  and  family.  Other  strategies  included 
browsing for items of interest found in the overview (“Wow, 
look how the poor farmers died out”) and formulating queries 
based on an over-arching interest, such as gender balance.

Looking to the usage logs, navigation by interaction with 
the  visualization  or  attached  commentary  was  by  far  the 
most common navigation technique, accounting for 70.5% 
of state views. The second most popular was the back and 
forward buttons at 17.5%, validating our integration of the 
visualization  with  browser  history  mechanisms.  Following 
a link from the comment listings accounted for 8.7% of all 
views, while the final 3.3% were due to clicking a bookmark 
in the bookmark trail (Figure 9).

figure 8: usage of sense.us graphical annotation tools.

Arrows
Text
Ovals
Pencil
Lines
Rectangles

1.7%

25.1%
24.6%

17.9%

16.2%

14.5%

0%

5%

10%

15%

20%

25%

figure 9: usage of sense.us navigation mechanisms.

Visualization
Back/Forward
Comment Listings
Bookmark Trail

17.5%

8.7%

3.3%

70.5%

0%

10%

20%

30%

40%

50%

60%

70%

80%

At some point, every subject explored the comment list-
ings.  Some  felt  they  would  find  interesting  views  more 
quickly.  Remarks  to  this  effect  included  “I  bet  others  have 
found even more interesting things” and “You get to stand on 
the  shoulders  of  others.”  Other  subjects  were  interested  in 
specific people they knew or discovering what other people 
had investigated. Said one participant, “I feel like a data voy-
eur. I really like seeing what other people were searching for.” 
Switching between data-driven exploration and social navi-
gation was common. Views discovered via comment listings 
often sparked new interests and catalyzed more data-driven 
exploration. After some exploration, participants routinely 
returned to the listings for more inspiration. In the survey, 
the  question  “Did  you  find  other  people’s  comments  use-
ful for exploring the data?” received the highest marks (M = 
4.46/5.0, SD = 0.63).

5.7. Doubly linked discussions
We  also  wanted  to  investigate  participant  reaction  to  the 
doubly linked model of comments. All users understood the 
model  readily  and  no  problems  were  reported  when  users 
wanted to comment on a specific view. The model became 
more problematic when users wanted to comment on mul-
tiple views. In this case, the user had to choose one view as 
primary,  comment  on  that,  and  then  reference  the  other 
views, either indirectly in the text or by creating a link from 
the bookmark trail. Some users expressed the opinion that 
creating links was a workable solution, while others wanted 
to  be  able  to  simultaneously  compare  multiple  views  for 
purposes of both analysis and commentary. One important 
aspect of doubly linked discussions is the problem of deter-
mining identical views, despite potentially differing visual-
ization parameters. In this respect, we found our indexing 
scheme improved the odds of discovering existing commen-
tary while navigating the visualization. Across both lab stud-
ies, 28.2% of all unique visits to a visualization state were to 
a view that had been reached through two or more differing 
parameter settings. Without the view indexing, there would 
be a much higher potential for “cross talk,” where users post 
comments concerning similar observations on related views, 
unaware of each other. Nonetheless, cross talk was observed 
in a total of six cases, typically when both normalized and 
absolute axis scales led to similar views. In two cases, par-
ticipants added linking comments that bridged the related 
discussions.

5.8. user experience
Overall, users found using sense.us both enjoyable and infor-
mative. In the exit survey, the question “Did you enjoy using 
the system?” received a mean rating of 4.0/5.0 (SD = 0.52). 
The  question  “Did  you  learn  something  interesting  using 
the system?” received a mean rating of 4.2/5.0 (SD = 0.65). 
Users also provided usability remarks and suggested addi-
tional collaboration features. The next section addresses a 
number of these requests (Figure 10).

6. Discussion
The usage we observed echoed some of the earlier findings 
about social data analysis.27 In particular, we saw cascading 

 

conversation threads in which users asked questions, stated 
hypotheses, and proposed explanations, all in a social con-
text.  A  significant  number  of  comments  were  playful  or 
joking,  as  were  a  few  graphical  annotations.  It  has  been 
hypothesized that one of the spurs to social data analysis is 
a situation in which each user brought a unique perspective 
to bear.27 In the case of job data, this unique perspective was 
the set of professions of friends and family of the user. We 
did indeed see people exploring in this fashion, covering a 
broad set of the data.

On the other hand, we observed a somewhat more busi-
nesslike tone to analysis than was seen previously. This was 
likely in part due to the corporate and laboratory settings of 
use. The presence of an observer in the lab studies undoubt-
edly  also  influenced  results,  though  many  users  reported 
they had fun conducting social data analysis.

Further  research  is  clearly  needed  to  understand  the 
broad  principles  of  analytical  behavior  in  the  context  of 
visualizations. Since the original publication of this article, 
some  of  that  research  has  occurred.  In  the  next  sections, 
as we describe research directions suggested by reactions 
to  sense.us,  we  also  provide  brief  notes  on  how  recent 
work  has  shed  light  on  issues  of  collaboration  around 
visualizations.

6.1. mechanisms for social data analysis
The doubly linked discussion model was probably the most 
effective  and  well-liked  novel  feature  of  sense.us.  If  there 
was any frustration with this feature, it was that users had to 
navigate to a precise location to see related comments. This 
shortcoming,  coupled  with  the  high  rate  of  within-applet 
navigation (Figure 9), raises an intriguing question for future 
research: would it be helpful to embed social navigation cues 
in the visualization or interface widgets themselves?

For  example,  a  dynamic  query  widget  used  to  filter  the 
visualization might include visual cues of how many people 
have visited or commented on the views reachable using the 
widget, providing information scent by which the user can 
purposefully  navigate  toward  either  popular  or  unpopular 
views.  Such  widgets  could  aid  the  discovery  of  interesting 
trends  that  simply  had  not  yet  been  seen.  In  our  context, 
one might imagine a slider—controlling a view parameter—
with marks indicating the presence of comments at specific 
parameter  values.  Similar  techniques  can  be  devised  for 
other interface widgets. A recent system for such “scented 
widgets”28  provides  evidence  that  such  cues  can  result  in 
increased revisitation to popular views while also directing 
users’ attention to under-explored data regions.

figure 10: Results of poststudy survey. mean values are shown,  
error bars indicate standard deviation.

1 Enjoyed using system
2 Learned interesting things
3 Other’s comments useful
4 Own annotations useful
5 Other’s annotations useful

0

1

2

3

4

5

January 2009  |   V ol. 52  |   no. 1  |   communications of thE acm     95

research highlights 

A second approach, suggested by many users, would be 
to show commentary related, though not directly attached 
to,  the  current  view.  Requested  features  include  show-
ing comments from other views that contain links to the 
current  view  (“trackbacks”),  and  related  commentary  on 
“nearby”  or  “similar”  views.  The  latter  could  help  allevi-
ate cross talk. Along these lines, there are appealing pos-
sibilities  for  generalizing  the  notion  of  view  indexing, 
for  example,  suggesting  conversations  on  views  deemed 
semantically  similar  to  the  current  view.  This  would 
require  an  index  of  visualization  state  providing  not  just 
equality  comparisons,  but  distance  measures.  Such  a 
retrieval model might be used to provide additional ben-
efits,  such  as  general  searchability  and  data-aware  auto-
complete mechanisms.

Users  have  also  suggested  using  visitation  data  or 
explicit  ratings  of  “interestingness”  to  suggest  views  of 
potential  interest.  Others  suggested  supporting  keyword 
tagging of comments22 and mining usage data. For exam-
ple,  both  manual  and  automated  tagging  of  questions  or 
other action items could be used to help direct collabora-
tive effort.

The  scope  of  comment  visibility  is  a  larger  issue  that 
affects  all  discussion  models.  What  happens  when  the 
amount  of  discussion  becomes  untenably  large,  or  users 
don’t want their activity exposed to everyone? The ability to 
form  groups  and  limit  comment  visibility  to  group  mem-
bers  is  one  means  requested  by  users  to  support  privacy 
and  make  discussion-following  both  more  relevant  and 
tractable.

Although  individual  usage  varied  substantially,  most 
lab study users (87.5%) did use the bookmark trails, which 
proved  essential  for  comments  that  included  multiple 
views.  Multiple  users  remarked  on  the  usefulness  of  the 
bookmark trails and wanted to more easily share trails as 
first  class  objects.  At  times,  users  were  frustrated  when 
following  multiple  links  in  a  comment,  as  the  original 
comment  would  disappear  when  a  new  view  was  loaded, 
requiring  use  of  the  back  button  to  perform  “hub-and-
spoke”  browsing.  In  response,  users  suggested  adding 
a  dedicated  “presentation”  mode  to  facilitate  tours  and 
storytelling.

Finally, the graphical annotations saw significant usage, 
despite mixed reactions from users. Though they were used 
for pointing, many users did not find them necessary for dis-
ambiguation. We expect that the value of annotations varies 
significantly  depending  on  the  type  of  visualization  being 
referenced. Regardless, annotations were used regularly for 
pointing and sometimes for socializing.

If the free-form annotations prove helpful, a second chal-
lenge would be to extend them to cover dynamic or evolving 
data  sets.  The  decoupled  nature  of  geometric  annotations 
can  prove  problematic  when  the  underlying  data  changes. 
Similar  problems  have  been  investigated  in  the  context  of 
document  annotation.5  More  recent  work19  has  explored 
“data-aware”  annotations  that  translate  user  selections 
into declarative queries over the underlying data, allowing 
annotations to be applied to time-varying data and different 
visual encodings.

96    communications of thE acm   |   January 2009  |   V ol. 52  |   no. 1

 

6.2. communities and data
Since  the  original  sense.us  experiment,  there  have  been 
several new examples of systems that support conversation 
around  data.  Web  sites  such  as  Swivel.com  have  provided 
social-network-style  platforms  for  conversation  around 
data,  along  with  basic  charting  capabilities.  Tableau 
Software launched its Tableau Server product, which (much 
like Spotfire’s DecisionSite Posters) allows users to collabo-
rate asynchronously around intranet-based visualizations. 
Little  has  been  published  about  usage  of  these  systems, 
however.

One new system where results have been reported is the 
Many Eyes Web site.26 In contrast to sense.us, or tools like 
Tableau or Spotfire, Many Eyes is freely available on the pub-
lic internet and allows users to upload their own data. Unlike 
data-oriented  sites  like  Swivel,  Many  Eyes  lets  users  apply 
more than a dozen interactive visualization techniques. They 
may  then  have  discussions  around  visualizations,  though 
annotation capabilities are more basic than in sense.us. The 
experiences on the site26 lend support to the idea that visu-
alization  can  catalyze  discussion.  While  these  discussions 
can be analytical, they also can be purely social, partisan, or 
game-like. In addition, the move from a closed setting to the 
public internet has made clear that these discussions can be 
highly distributed,13 with a significant proportion of collabo-
ration occurring (via hyperlinks) off the site. Designing for 
this type of multisite conversation suggests a whole new set 
of challenges.

7. conclusion
In  this  article,  we  investigated  mechanisms  supporting 
asynchronous collaboration around interactive information 
visualization, seeking to more tightly tie the perceptual and 
cognitive benefits of visualization to social processes of sen-
semaking.  To  do  so,  we  implemented  a  collaborative  data 
visualization site, sense.us. We then observed usage of the 
site in order to better understand the social dynamics sur-
rounding collective use of visualizations as well as the effi-
cacy of the particular features.

The  features  of  the  site—doubly  linked  discussions, 
bookmark  trails,  geometric  annotations,  and  comment 
listings—were  all  exploited  by  users.  The  doubly  linked 
discussions  successfully  enabled  users  to  fluidly  transfer 
attention  between  visualization  and  commentary  and  we 
suggested  ways  to  further  improve  this  type  of  discussion. 
Bookmark trails and geometric annotations were also well 
used, enabling tours through multiple views and pointing to 
items of interest, respectively. Finally, users played the roles 
of both voyager and voyeur, alternating between data-driven 
exploration directly within the visualization and social navi-
gation  through  comment  listings  and  user  profiles  to  dis-
cover new views of interest.

Overall, we believe these results show the value of focus-
ing  on  the  social  aspects  of  visual  analysis.  Our  user  stud-
ies  indicate  that  combining  conversation  and  visual  data 
analysis can help people explore a data set both broadly and 
deeply.  From  a  design  perspective,  there  lies  a  promising 
opportunity for exploring new widgets and modes of inter-
action aimed at enhancing collaboration.

References

  1.  anupam, V., bajaj, c.l., schikore, D., 
and shikore, m. representations in 
distributed cognitive tasks. IEEE 
Computer 27, 7 (1994), 37–43.
  2.  benbunan-fich, r., hiltz, s.r., 
and turoff, m. a comparative 
content analysis of face-to-face vs. 
asynchronous group decision making. 
Decision Support Systems 34, 4 
(2003), 457–469.

  3.  benko, h., ishak, e.w., and feiner, s.  

collaborative mixed reality 
visualization of an archaeological 
excavation. in IEEE International 
Symposium on Mixed and Augmented 
Reality (ISMAR 2004) (arlington, Va, 
2004), 132–140.

  4.  brodlie, K.w., Duce, D.a., gallop, J.r.,  

walton, J.P.r.b., and wood, J.D. 
Distributed and collaborative 
visualization. Computer Graphics 
Forum 23, 2 (2004), 223–251.

  5.  brush, a., bargeron, D., gupta, a., and 
cadiz, J. robust annotation positioning 
in digital documents. in Proceedings 
of ACM Human Factors in Computing 
Systems (CHI 2001), 2001.

  6.  card, s.K., mackinlay, J.D., and 

shneiderman, b. Readings in 
Information Visualization: Using Vision 
to Think. morgan-Kaufmann, 1999.

Journal of Computer-Supported 
Cooperative Work 13, 3 (2004), 
305–327.

  8.  chuah, m.c. and roth, s.f. Visualizing 

common ground. in Proceedings of the 
Conference on Information Visualization 
(IV) (los alamitos, usa, 2003), ieee 
computer society, 365–372.

  9.  chui, y.-P. and heng, P.-a. enhancing 

view consistency in collaborative 
medical visualization systems using 
predictive-based attitude estimation. 
in First IEEE International Workshop 
on Medical Imaging and Augmented 
Reality (MIAR’01) (hong Kong, 
china), 2001.

 10.  churchill, e.f., trevor, J., bly, s., 

nelson, l., and cubranic, D. anchored 
conversations: chatting in the context of 
a document. in ACM CHI 2000, 2000.

 11.  clark, h.h. Pointing and placing. in 
Pointing. Where Language, Culture, 
and Cognition Meet. s. Kita, ed. 
erlbaum, 2003, 243–268.

 12.  clark, h.h. and brennan, s.e. 

grounding in communication. in 
Perspectives on Socially Shared 
Cognition (1991), american 
Psychological association, 127–149.

 13.  Danis, c.m., Viégas, f.b., 

website. accessed: november, 2007.
 17.  grudin, J. groupware and social 
dynamics: eight challenges for 
developers. Communications of the 
ACM 37, 1 (1994), 92–105.

 18.  heer, J. socializing visualization. in 
ACM CHI 2006 Workshop on Social 
Visualization, 2006.

 19.  heer, J., agrawala, m., and willett, w. 

generalized selection via interactive query 
relaxation. in ACM CHI 2008, 959–969.
 20.  hill, w.c. and hollan, J.D. Deixis and 
the future of visualization excellence. 
in Proceedings of IEEE Visualization 
(1991), 314–319.

 21.  Johansen, r. Groupware: Computer 

Support for Business Teams. the free 
Press, new york, 1988.

 22.  millen, D.r., feinberg, J., and Keer, b. 

Dogear: social bookmarking in the 
enterprise. in Proceedings of ACM 
CHI 2006, 111–120.

 23.  thomas, J. and cook, K. Illuminating the 

 
Jeffrey Heer (jheer@stanford.edu), 
computer science Department, stanford 
university, stanford, ca.

communication-minded visualization: 
a call to action. IBM Systems Journal 
45, 4 (2006), 801–812.

 26.  Viégas, f.b., wattenberg, m., van ham, 

f., Kriss, J., and mcKeon,  
m. many eyes: a site for visualization 
at internet scale. IEEE Transactions 
on Visualization and Computer 
Graphics 12, 5 (nov./Dec. 2007), 
1121–1128.

 27.  wattenberg, m. and Kriss, J. 

Designing for social data analysis. 
IEEE Transactions on Visualization 
and Computer Graphics 12, 4 
(July–august 2006), 549–557.

 28.  willett, w., heer, J., and agrawala, m. 

scented widgets: improving 
navigation cues with embedded 
visualizations. IEEE Transactions on 
Visualization and Computer Graphics 
13, 6 (nov./Dec. 2007), 1129–1136.

Martin Wattenberg (mwatten@us.ibm.
com), Visual communication lab,  
ibm t.J. watson research center, 
cambridge, ma.

© acm 0001-0782/09/0001 $5.00

acknowledgments
We  thank  Jesse  Kriss,  Frank  van  Ham,  Doug  Fritz,  Kate 
Hollenbach,  Steve  Whittaker,  David  Millen,  and  Maneesh 
Agrawala  for  insightful  discussions.  We  also  would  like  to 
thank all the study participants and users of our system. 

 

(CHI 2008), 2008.

 14.  Dietz, P.h. and leigh, D.l. 

Diamondtouch: a multi-user touch 
technology. in Proceedings of ACM 
Symposium on User Interface Software 
and Technology, 2001, 219–226.

 15.  Dourish, P. and chalmers, m. running 

out of space: models of information 
navigation. in Human Computer 
Interaction (HCI’94), 1994.

Path: The Research and Development 
Agenda for Visual Analytics. ieee 
computer society, 2005.

 24.  Viégas, f.b., danah boyd, nguyen, D.h., 

Potter, J., and Donath, J. Digital artifacts 
for remembering and storytelling: 
Posthistory and social network 
fragments. in Proceedings of Hawaii 
International Conference on System 
Sciences (HICCSS) (2004), 105–111.

 16.  Dynamics, g. command post of the future. 

 25.  Viégas, f.b. and wattenberg, m. 

CACM lifetime mem half page ad:Layout 1  9/4/08  4:04 PM  Page 1
  7.  carter, s., mankoff, J., and goddi, P. 
building connections among loosely 
coupled groups: hebb’s rule at work. 

wattenberg, m., and Kriss, J. your place 
or mine? Visualization as a community 
component. in Proceedings of ACM 
Human Factors in Computing Systems 

Fernanda B. Viégas (viegasf@us.ibm.
com),Visual communication lab  
ibm t.J. watson research center, 
cambridge, ma.

Take Advantage of 
ACM’s Lifetime Membership Plan!

◆ ACM Professional Members can enjoy the convenience of making a single payment for their

entire tenure as an ACM Member, and also be protected from future price increases by
taking advantage of ACM's Lifetime Membership option.

◆ ACM Lifetime Membership dues may be tax deductible under certain circumstances, so

becoming a Lifetime Member can have additional advantages if you act before the end of
2008. (Please consult with your tax advisor.)

◆ Lifetime Members receive a certiﬁcate of recognition suitable for framing, and enjoy all of

the beneﬁts of ACM Professional Membership.

Learn more and apply at:

http://www.acm.org/life

January 2009  |   V ol. 52  |   no. 1  |   communications of thE acm     97

","{""pos"":{""0"":1,""1"":2,""2"":3,""3"":4},""2"":{""0"":""2004*"",""1"":""2006*"",""2"":""2001*"",""3"":""2008*""},""1"":{""0"":""comments"",""1"":""state*"",""2"":""current"",""3"":""trail*""},""3"":{""0"":""0"",""1"":""j"",""2"":""m*"",""3"":""b*""},""6"":{""0"":""add*"",""1"":""rise"",""2"":""drop*"",""3"":""live*""},""8"":{""0"":""annotations"",""1"":""bookmark"",""2"":""bookmarks*"",""3"":""widgets*""},""7"":{""0"":""data"",""1"":""users*"",""2"":""systems"",""3"":""usage""},""4"":{""0"":""5*"",""1"":""8*"",""2"":""35*"",""3"":""13*""},""5"":{""0"":""drawn*"",""1"":""updated*"",""2"":""responded*"",""3"":""received*""},""0"":{""0"":""visualization"",""1"":""asynchronous"",""2"":""vi\u00e9gas*"",""3"":""google*""}}",2009,{},False,False,journalArticle,False,VA72NXDN,[],self.user,"{""Unnamed: 0"":{""0"":0,""1"":1,""2"":2,""3"":3,""4"":4,""5"":5,""6"":6,""7"":7,""8"":8,""9"":9,""10"":10,""11"":11,""12"":12,""13"":13,""14"":14,""15"":15,""16"":16,""17"":17,""18"":18,""19"":19,""20"":20,""21"":21,""22"":22,""23"":23,""24"":24,""25"":25,""26"":26,""27"":27,""28"":28,""29"":29,""30"":30,""31"":31,""32"":32,""33"":33,""34"":34,""35"":35,""36"":36,""37"":37,""38"":38,""39"":39,""40"":40,""41"":41,""42"":42,""43"":43,""44"":44,""45"":45,""46"":46,""47"":47,""48"":48,""49"":49,""50"":50,""51"":51,""52"":52,""53"":53,""54"":54,""55"":55,""56"":56,""57"":57,""58"":58,""59"":59,""60"":60,""61"":61,""62"":62,""63"":63,""64"":64,""65"":65,""66"":66,""67"":67,""68"":68,""69"":69,""70"":70,""71"":71,""72"":72,""73"":73,""74"":74,""75"":75,""76"":76,""77"":77,""78"":78,""79"":79,""80"":80,""81"":81,""82"":82,""83"":83,""84"":84,""85"":85,""86"":86,""87"":87,""88"":88,""89"":89,""90"":90,""91"":91,""92"":92,""93"":93,""94"":94,""95"":95,""96"":96,""97"":97,""98"":98,""99"":99,""100"":100,""101"":101,""102"":102},""C"":{""0"":5.0263598265,""1"":5.0606095708,""2"":18.8828400526,""3"":6.4282259833,""4"":9.1190364797,""5"":11.6462177632,""6"":7.0784694921,""7"":7.9704427101,""8"":4.2195795352,""9"":21.8084466009,""10"":4.1173961472,""11"":11.6680746874,""12"":5.9823078213,""13"":29.9353141093,""14"":6.1914846276,""15"":4.6285426564,""16"":4.8407494587,""17"":7.0818487453,""18"":10.8012396704,""19"":4.5668552794,""20"":6.2485327069,""21"":6.0936423439,""22"":12.1792388416,""23"":11.962806611,""24"":6.2613380443,""25"":6.5150452867,""26"":7.8502033726,""27"":3.9351317222,""28"":6.1351590562,""29"":6.9517683878,""30"":12.1734413742,""31"":5.776098397,""32"":6.0699000671,""33"":6.7593152449,""34"":7.4646108978,""35"":5.3336888172,""36"":4.0212516344,""37"":4.0148208164,""38"":6.6329730311,""39"":4.6276076467,""40"":4.1231477211,""41"":5.1781164202,""42"":4.6881130561,""43"":7.1374691356,""44"":5.8275874855,""45"":7.3172054374,""46"":5.3123041962,""47"":8.7596483512,""48"":8.3990762601,""49"":9.873706987,""50"":3.9867992644,""51"":5.0940654022,""52"":6.4142874689,""53"":6.2489221624,""54"":5.004123836,""55"":5.9735797086,""56"":4.3151720575,""57"":5.9265522151,""58"":4.4803797764,""59"":6.3004893902,""60"":6.2669701229,""61"":6.8055822074,""62"":6.2882589292,""63"":7.9001202667,""64"":4.5815079102,""65"":5.8599352214,""66"":4.5150098164,""67"":6.3569839683,""68"":5.1135332675,""69"":4.4442866583,""70"":4.4185096721,""71"":5.0354647333,""72"":4.1945708078,""73"":4.3173068611,""74"":6.4651323107,""75"":4.0535352503,""76"":4.3958549292,""77"":4.3449038292,""78"":5.2850106327,""79"":5.102390481,""80"":5.1395379281,""81"":5.7294074088,""82"":6.4731719722,""83"":4.4863844947,""84"":4.4172131824,""85"":4.2593676869,""86"":3.9943630911,""87"":4.6901310121,""88"":4.5295974718,""89"":3.9698188572,""90"":4.3433020825,""91"":4.3504437828,""92"":4.2953813621,""93"":3.9901268583,""94"":4.0054015811,""95"":4.4344162631,""96"":4.1426157379,""97"":4.622970857,""98"":4.0917187391,""99"":4.6464023962,""100"":4.0638733619,""101"":4.7205659566,""102"":4.5860281484},""count"":{""0"":186,""1"":168,""2"":120,""3"":114,""4"":110,""5"":90,""6"":78,""7"":60,""8"":48,""9"":48,""10"":42,""11"":42,""12"":42,""13"":42,""14"":40,""15"":36,""16"":32,""17"":30,""18"":30,""19"":28,""20"":28,""21"":28,""22"":26,""23"":24,""24"":24,""25"":22,""26"":22,""27"":18,""28"":18,""29"":18,""30"":18,""31"":16,""32"":16,""33"":16,""34"":16,""35"":16,""36"":16,""37"":16,""38"":14,""39"":14,""40"":14,""41"":12,""42"":12,""43"":12,""44"":12,""45"":12,""46"":12,""47"":12,""48"":12,""49"":12,""50"":10,""51"":10,""52"":10,""53"":10,""54"":10,""55"":10,""56"":10,""57"":10,""58"":10,""59"":10,""60"":10,""61"":10,""62"":10,""63"":10,""64"":8,""65"":8,""66"":8,""67"":8,""68"":8,""69"":8,""70"":8,""71"":8,""72"":8,""73"":8,""74"":8,""75"":8,""76"":8,""77"":8,""78"":8,""79"":8,""80"":8,""81"":8,""82"":8,""83"":6,""84"":6,""85"":6,""86"":6,""87"":6,""88"":6,""89"":6,""90"":6,""91"":6,""92"":6,""93"":6,""94"":6,""95"":6,""96"":6,""97"":6,""98"":6,""99"":6,""100"":6,""101"":6,""102"":6},""sigma_nor"":{""0"":1.3496276887,""1"":1.3689813029,""2"":2.6378740306,""3"":1.5622348744,""4"":1.8161198177,""5"":2.1448101578,""6"":1.7338299684,""7"":1.9271934538,""8"":1.5238831628,""9"":3.8352381053,""10"":1.5372674194,""11"":2.5865056229,""12"":1.7964145363,""13"":5.1249113268,""14"":1.8412638547,""15"":1.6444570383,""16"":1.705383418,""17"":2.0781589065,""18"":2.6698214979,""19"":1.6943417877,""20"":1.9690696146,""21"":1.9437658957,""22"":2.9908538286,""23"":3.0108541762,""24"":2.0238859525,""25"":2.0989088867,""26"":2.3374786195,""27"":1.6752569927,""28"":2.0969125629,""29"":2.253423288,""30"":3.254205172,""31"":2.0628908054,""32"":2.1214429192,""33"":2.2588373592,""34"":2.3993966395,""35"":1.9747224296,""36"":1.7131651307,""37"":1.7118835247,""38"":2.2789183622,""39"":1.8620260971,""40"":1.7571547142,""41"":2.0116242128,""42"":1.9049757576,""43"":2.4380742244,""44"":2.1529805603,""45"":2.4771935455,""46"":2.0408299695,""47"":2.7911389585,""48"":2.7126610146,""49"":3.0336120541,""50"":1.7758365507,""51"":2.0291847408,""52"":2.3312583433,""53"":2.2934219102,""54"":2.0086056477,""55"":2.2304221399,""56"":1.8509699355,""57"":2.2196620074,""58"":1.8887703117,""59"":2.3052207573,""60"":2.2975513765,""61"":2.420788593,""62"":2.3024223649,""63"":2.6712245333,""64"":1.94018943,""65"":2.249047363,""66"":1.9241240161,""67"":2.3691304114,""68"":2.0687225509,""69"":1.9070378602,""70"":1.9008103441,""71"":2.0498618101,""72"":1.8467084846,""73"":1.8763605449,""74"":2.3952581961,""75"":1.8126354087,""76"":1.8953371373,""77"":1.8830277542,""78"":2.1101501269,""79"":2.0660305418,""80"":2.0750050714,""81"":2.2175128753,""82"":2.3972005147,""83"":1.9344804435,""84"":1.9167687064,""85"":1.876351403,""86"":1.8084953573,""87"":1.986650984,""88"":1.9455453903,""89"":1.8022106563,""90"":1.8978433177,""91"":1.8996719937,""92"":1.8855729246,""93"":1.807410644,""94"":1.8113218301,""95"":1.9211736603,""96"":1.8464563532,""97"":1.969454216,""98"":1.8334238657,""99"":1.9754540048,""100"":1.8262938868,""101"":1.9944440375,""102"":1.9599948098},""vocab_index"":{""0"":0,""1"":1,""2"":2,""3"":3,""4"":4,""5"":7,""6"":11,""7"":15,""8"":24,""9"":25,""10"":30,""11"":31,""12"":32,""13"":33,""14"":34,""15"":40,""16"":43,""17"":51,""18"":52,""19"":53,""20"":55,""21"":57,""22"":65,""23"":70,""24"":71,""25"":73,""26"":84,""27"":92,""28"":104,""29"":105,""30"":106,""31"":107,""32"":116,""33"":120,""34"":121,""35"":125,""36"":127,""37"":129,""38"":150,""39"":154,""40"":155,""41"":171,""42"":177,""43"":178,""44"":179,""45"":180,""46"":181,""47"":182,""48"":183,""49"":184,""50"":187,""51"":205,""52"":206,""53"":218,""54"":219,""55"":220,""56"":237,""57"":239,""58"":241,""59"":244,""60"":246,""61"":247,""62"":248,""63"":249,""64"":263,""65"":264,""66"":281,""67"":299,""68"":300,""69"":311,""70"":316,""71"":317,""72"":319,""73"":325,""74"":327,""75"":334,""76"":338,""77"":339,""78"":340,""79"":341,""80"":342,""81"":343,""82"":344,""83"":387,""84"":393,""85"":418,""86"":450,""87"":462,""88"":467,""89"":485,""90"":486,""91"":487,""92"":492,""93"":493,""94"":494,""95"":498,""96"":500,""97"":508,""98"":513,""99"":516,""100"":517,""101"":518,""102"":519},""word"":{""0"":""visualization"",""1"":""data"",""2"":""comments"",""3"":""users"",""4"":""comment"",""5"":""5"",""6"":""annotations"",""7"":""figure"",""8"":""bookmark"",""9"":""0"",""10"":""text"",""11"":""systems"",""12"":""state"",""13"":""j"",""14"":""collaboration"",""15"":""usage"",""16"":""time"",""17"":""current"",""18"":""m"",""19"":""asynchronous"",""20"":""computer"",""21"":""trail"",""22"":""subjects"",""23"":""url"",""24"":""parameters"",""25"":""b"",""26"":""d"",""27"":""vi\u00e9gas"",""28"":""interesting"",""29"":""question"",""30"":""ieee"",""31"":""wattenberg"",""32"":""proceedings"",""33"":""application"",""34"":""bookmarks"",""35"":""f"",""36"":""drawn"",""37"":""h"",""38"":""author"",""39"":""8"",""40"":""p"",""41"":""mechanism"",""42"":""subject"",""43"":""involved"",""44"":""cases"",""45"":""sd"",""46"":""widgets"",""47"":""r"",""48"":""chi"",""49"":""lifetime"",""50"":""sharing"",""51"":""collocated"",""52"":""displays"",""53"":""add"",""54"":""updated"",""55"":""image"",""56"":""rise"",""57"":""deployment"",""58"":""pilot"",""59"":""drop"",""60"":""model"",""61"":""w"",""62"":""2004"",""63"":""2006"",""64"":""designed"",""65"":""synchronous"",""66"":""independent"",""67"":""thumbnail"",""68"":""filtered"",""69"":""live"",""70"":""collection"",""71"":""retail"",""72"":""females"",""73"":""35"",""74"":""dentists"",""75"":""survey"",""76"":""eyes"",""77"":""13"",""78"":""graphics"",""79"":""2001"",""80"":""2008"",""81"":""kriss"",""82"":""membership"",""83"":""interact"",""84"":""google"",""85"":""shows"",""86"":""string"",""87"":""rubric"",""88"":""males"",""89"":""teachers"",""90"":""responded"",""91"":""year"",""92"":""brokers"",""93"":""rectangles"",""94"":""ovals"",""95"":""70"",""96"":""received"",""97"":""tableau"",""98"":""2003"",""99"":""a"",""100"":""agrawala"",""101"":""stanford"",""102"":""transactions""},""vector"":{""0"":""[ 3.1647253   0.06658875 -3.4833703   1.184141   -3.2421055  -2.1857584\n  1.39195     2.493702   -4.237831    0.55359685]"",""1"":""[ 2.9482365  -0.14503855 -3.4969547   0.8075945  -3.045889   -2.0562685\n  1.2742277   3.0295658  -4.324502    0.33949587]"",""2"":""[ 2.6014512   0.41569948 -3.1851003   0.85665214 -2.0760262  -2.469484\n  1.5345986   3.2622063  -4.176284    0.8391298 ]"",""3"":""[ 2.9158325  -0.11943297 -3.3696666   0.44257882 -2.431944   -1.6462289\n  1.4458727   3.3492541  -4.3984575  -0.16529693]"",""4"":""[ 2.3561492   0.37065098 -2.9635444   0.8135957  -2.0918498  -2.5805862\n  1.4538058   3.1546729  -4.105006    1.2729546 ]"",""5"":""[ 2.3889973  -0.86182624 -1.9628747  -0.81628543 -1.5809814  -0.72584397\n  2.0530918   1.8915992  -3.9604683   0.8011075 ]"",""6"":""[ 3.1582973   0.52795863 -3.367203    1.5577612  -2.6733139  -2.377989\n  1.636814    2.7709143  -4.277104    0.6538486 ]"",""7"":""[ 2.5189703  -0.10149179 -2.61968     1.2817109  -2.5651944  -2.0231607\n  1.1742077   3.1087072  -4.017797    1.0486088 ]"",""8"":""[ 3.2396653   0.62871957 -3.190689    1.6624378  -2.691294   -2.0932312\n  1.7766234   2.4379961  -4.202311    0.76047   ]"",""9"":""[ 2.5970044  -0.6795946  -1.9778318  -0.69586354 -1.547906   -0.6552637\n  2.0936465   1.6751479  -4.0404487   0.6940649 ]"",""10"":""[ 3.024975   0.3039691 -3.0152943  1.4149158 -2.437359  -2.333353\n  1.7856473  2.7071059 -4.382908   0.8574511]"",""11"":""[ 2.9237807  -0.24071701 -3.107698    0.7067798  -2.6055665  -1.5507619\n  1.3140497   3.3051014  -4.348973    0.09690881]"",""12"":""[ 2.1458027e+00 -1.9385116e-01 -2.9563248e+00 -2.1811987e-03\n -2.1710503e+00 -2.0097666e+00  1.2346766e+00  3.0081036e+00\n -3.8573718e+00  1.0874978e+00]"",""13"":""[ 3.1352258  -0.3760268  -2.2705107  -0.32031074 -1.8311712  -0.80802065\n  2.5624545   1.0339783  -4.298064    0.65712786]"",""14"":""[ 2.7201881   0.06014678 -3.4393053   0.7808876  -3.1825588  -2.351848\n  1.0692382   2.6781635  -3.9796476   0.9595921 ]"",""15"":""[ 2.7778645  -0.27383566 -3.380583    0.46898958 -2.9746504  -1.8167098\n  1.1369681   3.0980022  -4.2706175   0.31544575]"",""16"":""[ 2.1694033  -0.25020877 -2.5819545  -0.0635277  -1.9230713  -1.7692193\n  1.3124758   2.8337033  -3.8335922   1.0265647 ]"",""17"":""[ 2.0258894  -0.24601804 -2.7633865   0.05494975 -2.3788354  -1.938922\n  1.0711592   2.7026248  -3.6304772   1.3924979 ]"",""18"":""[ 3.0586674  -0.54359233 -2.1722372  -0.8004149  -1.5893117  -0.6972934\n  2.764999    1.1646936  -4.3381386   0.5573837 ]"",""19"":""[ 3.1531613   0.06345726 -3.5623758   0.6395273  -3.2648141  -2.0724764\n  1.55497     1.9953078  -4.1093807   0.70363176]"",""20"":""[ 3.20807    -0.03448023 -3.4623582   0.97095877 -2.9917572  -1.9396354\n  1.5087279   2.685746   -4.3498077   0.19693458]"",""21"":""[ 2.1937983  -0.07010008 -2.969746    0.26719052 -2.2886624  -2.1582658\n  1.1982949   2.9655268  -3.8573883   0.9788276 ]"",""22"":""[ 2.5832448   0.04251631 -3.1814468   0.2778989  -2.0571597  -1.8774717\n  1.577093    3.3579879  -4.348051    0.37818313]"",""23"":""[ 3.1306207   0.21283151 -2.8086762   1.0783088  -2.4473915  -1.6227763\n  1.9294757   2.285663   -4.290908    0.7606594 ]"",""24"":""[ 2.99552   -0.0893591 -2.952426   0.8269015 -2.5585618 -1.5139561\n  1.5612178  2.9271653 -4.365562   0.3857203]"",""25"":""[ 3.0022461  -0.50171393 -2.1324809  -0.60402125 -1.6086024  -0.8067758\n  2.5464942   1.2651606  -4.136852    0.5912962 ]"",""26"":""[ 2.9518905 -0.5856703 -2.0872614 -0.7546447 -1.5802256 -0.6636711\n  2.5946717  1.2960364 -4.229546   0.5715545]"",""27"":""[ 3.3222415  -0.01756298 -3.2282941   0.7312894  -2.835192   -2.0278063\n  2.0377705   1.9074795  -4.634138    0.5587277 ]"",""28"":""[ 2.0833242   0.26716164 -3.0602148   0.4021389  -2.2560627  -2.5976098\n  1.2774225   3.1285138  -3.9067576   1.7117777 ]"",""29"":""[ 2.3427541   0.24440695 -3.0111496   0.58552337 -2.1478674  -2.3949964\n  1.3764623   3.1835985  -4.085646    1.2589366 ]"",""30"":""[ 3.247023   -0.05708084 -2.9659786   0.36344573 -2.615965   -1.5355406\n  2.1896553   1.5410227  -4.334058    0.67101157]"",""31"":""[ 3.1878355e+00 -2.4328835e-03 -3.1874766e+00  7.9930550e-01\n -2.7696745e+00 -2.1440051e+00  1.9353826e+00  2.0821567e+00\n -4.6139598e+00  6.6208208e-01]"",""32"":""[ 2.7419822  -0.04770805 -3.1860142   0.6672327  -2.2683506  -1.9357527\n  1.2133449   3.4783745  -4.061983    0.2950146 ]"",""33"":""[ 2.8993     -0.28525665 -3.493965    0.6253341  -3.0552156  -1.95219\n  1.0373697   2.9744966  -4.023504    0.2700759 ]"",""34"":""[ 3.2950804   0.56708837 -3.3331172   1.6788173  -2.7673934  -2.1828172\n  1.7276076   2.5612674  -4.2675567   0.58869976]"",""35"":""[ 2.8636613  -0.6267784  -2.3195899  -0.70593596 -1.8057624  -0.88312036\n  2.5846255   1.2493206  -4.248481    0.5577869 ]"",""36"":""[ 1.6781969   0.47298723 -2.9451559   0.7006357  -2.74578    -2.8609228\n  0.8531523   2.9770658  -3.5262222   2.2675784 ]"",""37"":""[ 3.0219436  -0.52136767 -2.2993824  -0.65933806 -1.7811625  -0.83098006\n  2.7019818   1.0941647  -4.3025994   0.5631614 ]"",""38"":""[ 2.8457878   0.27883208 -2.9244366   1.0739764  -2.2159514  -2.2456663\n  1.797103    2.7339914  -4.3300037   0.9827932 ]"",""39"":""[ 2.3890524  -0.7918569  -1.8871715  -0.78104305 -1.4754506  -0.651874\n  1.9008427   1.9576901  -3.9419894   0.73356664]"",""40"":""[ 3.0367508  -0.29941043 -2.294465   -0.5962876  -1.6683741  -1.0725213\n  2.65541     1.344308   -4.1870604   0.5736495 ]"",""41"":""[ 2.8709183  -0.23872086 -2.874002    0.9044076  -2.6062777  -1.5419259\n  1.2762456   3.2503667  -4.2753916   0.36991203]"",""42"":""[ 2.1634877   0.01059119 -2.9545574   0.31030586 -2.187044   -2.26458\n  1.3250085   3.0983505  -3.9705918   1.3665407 ]"",""43"":""[ 1.9369502   0.26971796 -3.0313094   0.47338694 -2.5198295  -2.6832283\n  1.0662632   3.084159   -3.7479377   1.9026016 ]"",""44"":""[ 2.7484388  -0.16787897 -3.0650861   0.4772728  -2.275368   -1.6662352\n  1.3350441   3.3816962  -4.230412    0.2441297 ]"",""45"":""[ 3.1101727 -0.3424878 -2.5596166 -0.3285233 -2.0980794 -1.1330279\n  2.5577202  1.2345514 -4.308854   0.6245108]"",""46"":""[ 3.3683643   0.3992004  -3.3674476   1.7727227  -2.9767025  -2.168482\n  1.6373069   2.5613344  -4.294005    0.45317736]"",""47"":""[ 2.8770278  -0.37845755 -2.1839907  -0.63594824 -1.7358065  -1.0030588\n  2.590151    1.0553384  -4.1496367   0.8387151 ]"",""48"":""[ 3.0964553  -0.3862457  -2.2740335  -0.59717166 -1.7084458  -0.9272178\n  2.7597978   1.0909731  -4.275227    0.6119456 ]"",""49"":""[ 2.2396789  -0.35829306 -2.6220965   0.03506134 -2.1199477  -1.6753656\n  1.1905985   2.785652   -3.76482     0.91326773]"",""50"":""[ 2.5020149   0.04928057 -3.306297    0.7379835  -3.1465216  -2.429475\n  0.9885742   2.6893067  -3.8787916   1.2033688 ]"",""51"":""[ 2.9270594   0.1011263  -3.5809476   0.58092415 -3.4448364  -2.2864943\n  1.3565503   1.9584647  -3.9215477   1.0116131 ]"",""52"":""[ 2.2204063   0.24156229 -3.0044942   1.1470828  -2.9502108  -2.537941\n  1.0392463   2.8689535  -3.7322319   1.6429267 ]"",""53"":""[ 1.9584093   0.15773007 -2.586793    0.8651829  -2.4020035  -2.6175888\n  1.111794    2.8358076  -3.8443062   1.8477398 ]"",""54"":""[ 1.773826    0.27818078 -2.8767474   0.62482244 -2.7028723  -2.619107\n  0.90863824  2.7404284  -3.4989665   2.1369343 ]"",""55"":""[ 2.8115296   0.12063361 -2.8881683   1.5463077  -2.7096164  -2.1985552\n  1.3951107   2.934244   -4.169686    0.94999665]"",""56"":""[ 1.8759212  -0.02005926 -2.4047048   0.7384895  -2.3004637  -2.4498193\n  1.0629787   2.8592467  -3.823521    1.6797032 ]"",""57"":""[ 2.8161478  -0.29887608 -3.314935    0.7647252  -3.1664958  -1.9598\n  0.96611583  2.9441636  -4.0195184   0.5269142 ]"",""58"":""[ 2.7517314  -0.29050225 -2.9043152   1.0211029  -2.851104   -1.7651366\n  1.0702705   3.1196811  -4.0733104   0.6023266 ]"",""59"":""[ 1.8963946   0.06348201 -2.4926462   0.7219426  -2.3010364  -2.4996328\n  1.0848006   2.8647714  -3.8406587   1.7059631 ]"",""60"":""[ 2.7347474  -0.20322195 -2.68554     1.2572346  -2.7066705  -1.72086\n  1.1551573   3.124375   -4.0757065   0.72517663]"",""61"":""[ 2.777285   -0.578833   -2.1292832  -0.64554334 -1.6645474  -0.8735142\n  2.4005654   1.317007   -4.077253    0.722941  ]"",""62"":""[ 2.1037178 -0.6291413 -2.2326093 -0.6346503 -1.6197381 -1.1911958\n  1.5388772  2.563825  -3.7612538  0.9082433]"",""63"":""[ 2.178975   -0.6517083  -2.0916753  -0.59544426 -1.502939   -1.0542141\n  1.5119684   2.4729412  -3.8285296   0.79176795]"",""64"":""[ 1.7992979  0.561103  -2.8579106  0.9550557 -2.7433803 -2.896805\n  0.9361521  3.0887198 -3.6662714  2.1049736]"",""65"":""[ 2.9897578   0.0111493  -3.5419457   0.51113147 -3.304255   -2.14124\n  1.4090804   2.0446608  -4.0074544   0.86361736]"",""66"":""[ 2.035902   -0.10382595 -2.9543056   0.05262764 -2.2833781  -2.218155\n  1.2242503   2.9029412  -3.8256612   1.4700621 ]"",""67"":""[ 2.974311    0.15090463 -2.978737    1.5904119  -2.8742237  -2.092264\n  1.4605683   2.7106874  -4.176765    0.85714096]"",""68"":""[ 1.686198    0.36014774 -3.0090714   0.44782037 -2.713017   -2.6873987\n  0.8685218   2.71879    -3.435161    2.2468832 ]"",""69"":""[ 1.9306931  -0.05270909 -2.5304966   0.82894343 -2.6194675  -2.4772594\n  0.9600444   2.836663   -3.6824594   1.78      ]"",""70"":""[ 2.67568     0.07426443 -3.2989495   1.1170299  -2.9662373  -2.356864\n  1.1649795   3.0053356  -4.082088    0.85854506]"",""71"":""[ 3.1427944  -0.09127425 -3.6568906   0.7130128  -2.8240097  -1.8273423\n  1.3201609   3.0943053  -4.1878304  -0.2165655 ]"",""72"":""[ 2.7267494  -0.15254335 -3.1273525  -0.0138311  -2.0357447  -1.5423186\n  1.7501128   3.0352733  -4.377106    0.00693925]"",""73"":""[ 2.3249435  -0.7938883  -1.8248016  -0.77907085 -1.4004141  -0.5949348\n  1.8125029   2.0446312  -3.887495    0.7062006 ]"",""74"":""[ 2.9290707  -0.03153767 -3.490385    0.35218236 -2.2467985  -1.6924335\n  1.4523238   3.3636172  -4.194145   -0.3296757 ]"",""75"":""[ 2.5785754  -0.07511898 -3.32196     0.67553663 -2.7812529  -2.261659\n  1.1412451   3.1618686  -4.1297116   0.73075426]"",""76"":""[ 2.524176    0.24538535 -3.1381197   0.5683162  -2.0128694  -2.1941073\n  1.5493649   3.3102624  -4.2163835   0.63981235]"",""77"":""[ 2.4134443  -0.74102116 -1.9345009  -0.7128133  -1.5105362  -0.6639535\n  1.8832409   1.9521098  -3.9756787   0.7597039 ]"",""78"":""[ 3.2494764   0.21174924 -3.333685    1.5174835  -2.9942923  -2.173933\n  1.5796179   2.581222   -4.3142533   0.50472444]"",""79"":""[ 2.2908437  -0.49096918 -2.2213533  -0.38044453 -1.6360697  -1.2287234\n  1.5480721   2.4971714  -3.8989894   0.8151471 ]"",""80"":""[ 2.2420185  -0.59227026 -2.1360765  -0.51393926 -1.5474229  -1.1184192\n  1.5558124   2.4999557  -3.8112788   0.7479407 ]"",""81"":""[ 3.0861874  -0.28496128 -2.302875   -0.11491352 -1.850675   -0.9322612\n  2.3662517   1.2375497  -4.2422996   0.7004558 ]"",""82"":""[ 2.5840595  -0.27496967 -3.3456147   0.36067176 -2.6188383  -1.9608537\n  0.99422354  3.1505094  -3.8198729   0.36089075]"",""83"":""[ 1.9200844   0.10018557 -2.6477685   0.85237944 -2.6143017  -2.6603897\n  0.99217224  2.9117985  -3.7214231   1.877628  ]"",""84"":""[ 3.1960027  0.2631474 -2.9626079  0.9807416 -2.5804946 -1.7648469\n  2.0129383  1.9930229 -4.3004637  0.8203397]"",""85"":""[ 2.1152864   0.11217261 -2.752952    1.0894134  -2.840433   -2.460688\n  1.001592    2.8840785  -3.6925216   1.7233127 ]"",""86"":""[ 2.9779859   0.03151895 -2.69922     0.73290604 -2.3452706  -1.4800323\n  1.8577932   2.3017578  -4.2296033   0.74979407]"",""87"":""[ 2.8065782   0.39236417 -3.3074076   0.94169354 -2.5201042  -2.2818754\n  1.3850917   3.0534558  -4.1661124   0.8963159 ]"",""88"":""[ 2.8094869  -0.05884312 -3.2506924   0.12833554 -2.0864382  -1.612048\n  1.7089056   3.1817417  -4.389382   -0.0822164 ]"",""89"":""[ 2.8269055  -0.01010589 -3.3557398   0.29832777 -2.164006   -1.6909806\n  1.5764892   3.3199937  -4.334221   -0.14984685]"",""90"":""[ 1.8657525   0.4749691  -3.0133977   0.7235889  -2.599737   -2.8538532\n  0.99103254  3.1791012  -3.6980143   1.9846565 ]"",""91"":""[ 2.2854338  -0.38774967 -2.449799   -0.11785053 -1.8582288  -1.4809366\n  1.4076003   2.7049901  -3.8689501   0.80373627]"",""92"":""[ 3.0385714  -0.10668794 -3.5413878   0.5753153  -2.5701716  -1.7218891\n  1.3323747   3.3122659  -4.222661   -0.2899417 ]"",""93"":""[ 3.2399259   0.36017722 -3.2725463   1.8013523  -2.9444401  -2.2035234\n  1.5336975   2.7099142  -4.2398696   0.55668   ]"",""94"":""[ 3.1829045   0.32787633 -3.3138235   1.7280649  -2.8778152  -2.1857276\n  1.4300876   2.8753693  -4.193786    0.40852913]"",""95"":""[ 2.387971   -0.6349591  -1.924154   -0.5770086  -1.454693   -0.7135645\n  1.7121894   2.065392   -3.8792925   0.70940745]"",""96"":""[ 1.7940032   0.50855744 -2.9678707   0.78821087 -2.792917   -2.8100705\n  0.91503924  2.9450705  -3.5925107   2.139467  ]"",""97"":""[ 2.7769957e+00 -9.3944295e-04 -2.8164566e+00  1.5321492e+00\n -2.7466106e+00 -2.0449886e+00  1.2270730e+00  3.0512946e+00\n -4.0705261e+00  8.5503072e-01]"",""98"":""[ 2.3257203  -0.52489793 -2.13832    -0.43619275 -1.6339229  -1.1259228\n  1.5190126   2.3687637  -3.8972611   0.7126647 ]"",""99"":""[ 2.0608993  -0.06819227 -2.7331228   0.2172506  -2.370291   -2.1777842\n  1.0831625   2.7770507  -3.7748094   1.498061  ]"",""100"":""[ 3.2891877  -0.03089364 -3.2614048   0.6533029  -2.9072657  -1.8713156\n  1.9165306   1.870987   -4.455298    0.5488254 ]"",""101"":""[ 3.2532642   0.04220314 -2.9471695   0.5831342  -2.585283   -1.5943991\n  2.12955     1.7131416  -4.3590164   0.68267655]"",""102"":""[ 3.0285974  -0.14837466 -3.509146    0.70991176 -2.7495875  -1.8269509\n  1.2103057   3.2488375  -4.1580963  -0.07113302]""},""topic"":{""0"":0,""1"":7,""2"":1,""3"":7,""4"":-1,""5"":4,""6"":8,""7"":-1,""8"":8,""9"":3,""10"":-1,""11"":7,""12"":1,""13"":3,""14"":-1,""15"":7,""16"":-1,""17"":1,""18"":3,""19"":0,""20"":-1,""21"":1,""22"":-1,""23"":-1,""24"":-1,""25"":3,""26"":3,""27"":0,""28"":-1,""29"":1,""30"":-1,""31"":-1,""32"":-1,""33"":7,""34"":8,""35"":3,""36"":5,""37"":3,""38"":-1,""39"":4,""40"":3,""41"":7,""42"":1,""43"":-1,""44"":7,""45"":-1,""46"":8,""47"":3,""48"":3,""49"":1,""50"":-1,""51"":-1,""52"":-1,""53"":6,""54"":5,""55"":-1,""56"":6,""57"":-1,""58"":-1,""59"":6,""60"":8,""61"":3,""62"":2,""63"":2,""64"":-1,""65"":-1,""66"":1,""67"":8,""68"":-1,""69"":6,""70"":-1,""71"":-1,""72"":-1,""73"":4,""74"":7,""75"":-1,""76"":-1,""77"":4,""78"":8,""79"":2,""80"":2,""81"":-1,""82"":-1,""83"":6,""84"":0,""85"":-1,""86"":-1,""87"":-1,""88"":7,""89"":7,""90"":5,""91"":-1,""92"":7,""93"":8,""94"":8,""95"":4,""96"":5,""97"":8,""98"":2,""99"":1,""100"":0,""101"":0,""102"":7},""exemplar"":{""0"":null,""1"":null,""2"":null,""3"":""*"",""4"":null,""5"":""*"",""6"":null,""7"":null,""8"":null,""9"":null,""10"":null,""11"":null,""12"":""*"",""13"":null,""14"":null,""15"":null,""16"":null,""17"":null,""18"":""*"",""19"":null,""20"":null,""21"":""*"",""22"":null,""23"":null,""24"":null,""25"":""*"",""26"":null,""27"":""*"",""28"":null,""29"":null,""30"":null,""31"":null,""32"":null,""33"":null,""34"":""*"",""35"":null,""36"":""*"",""37"":""*"",""38"":null,""39"":""*"",""40"":null,""41"":null,""42"":""*"",""43"":null,""44"":null,""45"":null,""46"":""*"",""47"":null,""48"":""*"",""49"":null,""50"":null,""51"":null,""52"":null,""53"":""*"",""54"":""*"",""55"":null,""56"":null,""57"":null,""58"":null,""59"":""*"",""60"":null,""61"":null,""62"":""*"",""63"":""*"",""64"":null,""65"":null,""66"":""*"",""67"":null,""68"":null,""69"":""*"",""70"":null,""71"":null,""72"":null,""73"":""*"",""74"":""*"",""75"":null,""76"":null,""77"":""*"",""78"":""*"",""79"":""*"",""80"":""*"",""81"":null,""82"":null,""83"":""*"",""84"":""*"",""85"":null,""86"":null,""87"":null,""88"":""*"",""89"":null,""90"":""*"",""91"":null,""92"":""*"",""93"":""*"",""94"":null,""95"":null,""96"":""*"",""97"":null,""98"":""*"",""99"":""*"",""100"":""*"",""101"":""*"",""102"":null},""word*"":{""0"":""visualization"",""1"":""data"",""2"":""comments"",""3"":""users*"",""4"":""comment"",""5"":""5*"",""6"":""annotations"",""7"":""figure"",""8"":""bookmark"",""9"":""0"",""10"":""text"",""11"":""systems"",""12"":""state*"",""13"":""j"",""14"":""collaboration"",""15"":""usage"",""16"":""time"",""17"":""current"",""18"":""m*"",""19"":""asynchronous"",""20"":""computer"",""21"":""trail*"",""22"":""subjects"",""23"":""url"",""24"":""parameters"",""25"":""b*"",""26"":""d"",""27"":""vi\u00e9gas*"",""28"":""interesting"",""29"":""question"",""30"":""ieee"",""31"":""wattenberg"",""32"":""proceedings"",""33"":""application"",""34"":""bookmarks*"",""35"":""f"",""36"":""drawn*"",""37"":""h*"",""38"":""author"",""39"":""8*"",""40"":""p"",""41"":""mechanism"",""42"":""subject*"",""43"":""involved"",""44"":""cases"",""45"":""sd"",""46"":""widgets*"",""47"":""r"",""48"":""chi*"",""49"":""lifetime"",""50"":""sharing"",""51"":""collocated"",""52"":""displays"",""53"":""add*"",""54"":""updated*"",""55"":""image"",""56"":""rise"",""57"":""deployment"",""58"":""pilot"",""59"":""drop*"",""60"":""model"",""61"":""w"",""62"":""2004*"",""63"":""2006*"",""64"":""designed"",""65"":""synchronous"",""66"":""independent*"",""67"":""thumbnail"",""68"":""filtered"",""69"":""live*"",""70"":""collection"",""71"":""retail"",""72"":""females"",""73"":""35*"",""74"":""dentists*"",""75"":""survey"",""76"":""eyes"",""77"":""13*"",""78"":""graphics*"",""79"":""2001*"",""80"":""2008*"",""81"":""kriss"",""82"":""membership"",""83"":""interact*"",""84"":""google*"",""85"":""shows"",""86"":""string"",""87"":""rubric"",""88"":""males*"",""89"":""teachers"",""90"":""responded*"",""91"":""year"",""92"":""brokers*"",""93"":""rectangles*"",""94"":""ovals"",""95"":""70"",""96"":""received*"",""97"":""tableau"",""98"":""2003*"",""99"":""a*"",""100"":""agrawala*"",""101"":""stanford*"",""102"":""transactions""},""pos"":{""0"":1,""1"":1,""2"":1,""3"":2,""4"":1,""5"":1,""6"":1,""7"":2,""8"":2,""9"":1,""10"":3,""11"":3,""12"":2,""13"":2,""14"":4,""15"":4,""16"":5,""17"":3,""18"":3,""19"":2,""20"":6,""21"":4,""22"":7,""23"":8,""24"":9,""25"":4,""26"":5,""27"":3,""28"":10,""29"":5,""30"":11,""31"":12,""32"":13,""33"":5,""34"":3,""35"":6,""36"":1,""37"":7,""38"":14,""39"":2,""40"":8,""41"":6,""42"":6,""43"":15,""44"":7,""45"":16,""46"":4,""47"":9,""48"":10,""49"":7,""50"":17,""51"":18,""52"":19,""53"":1,""54"":2,""55"":20,""56"":2,""57"":21,""58"":22,""59"":3,""60"":5,""61"":11,""62"":1,""63"":2,""64"":23,""65"":24,""66"":8,""67"":6,""68"":25,""69"":4,""70"":26,""71"":27,""72"":28,""73"":3,""74"":8,""75"":29,""76"":30,""77"":4,""78"":7,""79"":3,""80"":4,""81"":31,""82"":32,""83"":5,""84"":4,""85"":33,""86"":34,""87"":35,""88"":9,""89"":10,""90"":3,""91"":36,""92"":11,""93"":8,""94"":9,""95"":5,""96"":4,""97"":10,""98"":5,""99"":9,""100"":5,""101"":6,""102"":12},""x2D"":{""0"":5.5040755272,""1"":6.4924259186,""2"":6.3620414734,""3"":7.7628974915,""4"":6.4184584618,""5"":4.491191864,""6"":5.340174675,""7"":6.2763090134,""8"":5.2690062523,""9"":4.5361504555,""10"":5.1449594498,""11"":7.3809051514,""12"":5.98574543,""13"":-17.0053844452,""14"":5.6235089302,""15"":6.7415785789,""16"":5.5283999443,""17"":6.0117034912,""18"":-17.1652050018,""19"":4.8360915184,""20"":5.7980589867,""21"":6.0412187576,""22"":7.7444372177,""23"":4.3647789955,""24"":7.2802219391,""25"":-17.61236763,""26"":-17.3929481506,""27"":4.3285083771,""28"":6.798479557,""29"":6.4378914833,""30"":3.9825959206,""31"":4.4555215836,""32"":7.3940725327,""33"":6.5982937813,""34"":5.413544178,""35"":-17.0935344696,""36"":7.7654500008,""37"":-17.0736045837,""38"":4.9561982155,""39"":4.4649477005,""40"":-17.3752937317,""41"":7.1259298325,""42"":6.2585735321,""43"":7.7019252777,""44"":7.525200367,""45"":-17.0806350708,""46"":5.7651281357,""47"":-17.4585037231,""48"":-17.453918457,""49"":5.6721563339,""50"":5.6663093567,""51"":5.1416530609,""52"":7.2667217255,""53"":7.2379293442,""54"":7.7070274353,""55"":5.9615807533,""56"":7.0224499702,""57"":6.3192205429,""58"":6.6149873734,""59"":7.0902991295,""60"":6.5204744339,""61"":-17.4590702057,""62"":5.0050272942,""63"":4.8285803795,""64"":7.9446673393,""65"":5.0116782188,""66"":6.2977595329,""67"":5.6532354355,""68"":7.7515039444,""69"":7.2345457077,""70"":5.8460950851,""71"":7.1412220001,""72"":7.888130188,""73"":4.6085247993,""74"":7.9350218773,""75"":6.0466065407,""76"":6.7238783836,""77"":4.4105172157,""78"":5.722697258,""79"":5.1725802422,""80"":4.95763731,""81"":-16.903635025,""82"":6.8934998512,""83"":7.3590226173,""84"":4.1319947243,""85"":7.3319392204,""86"":4.3262338638,""87"":5.788143158,""88"":8.0258617401,""89"":7.9866609573,""90"":7.8721385002,""91"":5.3355665207,""92"":7.5544557571,""93"":5.6510109901,""94"":5.7039217949,""95"":4.6456170082,""96"":7.7038092613,""97"":6.0488343239,""98"":5.0067725182,""99"":6.4431438446,""100"":4.178706646,""101"":4.0787754059,""102"":7.2755608559},""y2D"":{""0"":4.3384222984,""1"":3.423504591,""2"":1.6623874903,""3"":3.3213448524,""4"":0.9820944667,""5"":-3.3507859707,""6"":5.4883956909,""7"":4.5799221992,""8"":5.6400446892,""9"":-3.5311746597,""10"":5.1795048714,""11"":3.3852365017,""12"":-0.021071624,""13"":1.5994656086,""14"":3.2350714207,""15"":3.2298767567,""16"":-0.8239025474,""17"":-0.1882131249,""18"":1.8185104132,""19"":3.7609887123,""20"":4.066204071,""21"":0.1038084403,""22"":2.6736493111,""23"":4.5822081566,""24"":3.9650416374,""25"":2.0317344666,""26"":2.0058982372,""27"":4.039700985,""28"":0.1088961735,""29"":0.7240078449,""30"":4.0877776146,""31"":4.0481982231,""32"":2.9483590126,""33"":3.2264375687,""34"":5.7857542038,""35"":1.955883503,""36"":-1.222304225,""37"":1.7628269196,""38"":4.7801413536,""39"":-3.2913250923,""40"":1.622487545,""41"":3.8878102303,""42"":0.2812705338,""43"":-0.6845470071,""44"":3.006780386,""45"":1.5568470955,""46"":5.6863012314,""47"":1.7760837078,""48"":1.6805057526,""49"":-0.6579918861,""50"":3.1546516418,""51"":3.5614991188,""52"":-0.8723660707,""53"":-0.5533900857,""54"":-0.9886659384,""55"":4.8364162445,""56"":-0.3434451818,""57"":3.3266265392,""58"":3.9509701729,""59"":-0.3651820123,""60"":4.3037829399,""61"":1.9684129953,""62"":-2.1238815784,""63"":-2.397418499,""64"":-1.0742480755,""65"":3.6077282429,""66"":-0.106289126,""67"":5.0922312737,""68"":-1.29798913,""69"":-0.680798173,""70"":3.2507395744,""71"":3.4639589787,""72"":3.1176905632,""73"":-3.0728514194,""74"":3.3835299015,""75"":2.9142770767,""76"":1.8343571424,""77"":-3.2259232998,""78"":5.3849215508,""79"":-1.9133572578,""80"":-2.1675758362,""81"":1.8264225721,""82"":2.9685742855,""83"":-0.7326034904,""84"":4.2343354225,""85"":-0.9503683448,""86"":4.4749073982,""87"":2.6758580208,""88"":3.1809923649,""89"":3.0037634373,""90"":-0.9589756727,""91"":-1.3844133615,""92"":3.4726223946,""93"":5.7417492867,""94"":5.5385079384,""95"":-3.0427055359,""96"":-1.2678492069,""97"":4.7229132652,""98"":-2.1377141476,""99"":-0.1829076558,""100"":3.9312841892,""101"":4.2846565247,""102"":3.5060505867}}",False,False,False,http://portal.acm.org/citation.cfm?doid=1435417.1435439,,Voyagers and voyeurs: Supporting asynchronous collaborative visualization,VA72NXDN,False,False
SGYL3UXY,T4Y4B36G,"1
1
0
2

 

v
o
N
4

 

 
 
]

C
H
.
s
c
[
 
 

2
v
0
0
2
6

.

0
1
1
1
:
v
i
X
r
a

TopicViz: Semantic Navigation of Document

Collections

Jacob Eisenstein, Duen Horng “Polo” Chau, Aniket Kittur and Eric Xing

School of Computer Science
Carnegie Mellon University
Pittsburgh, PA 15215 USA

November 7, 2011

Abstract

When people explore and manage information, they think in terms of topics and themes.
However, the software that supports information exploration sees text at only the surface level.
In this paper we show how topic modeling – a technique for identifying latent themes across
large collections of documents – can support semantic exploration. We present TopicViz, an
interactive environment for information exploration. TopicViz combines traditional search and
citation-graph functionality with a range of novel interactive visualizations, centered around a
force-directed layout that links documents to the latent themes discovered by the topic model.
We describe several use scenarios in which TopicViz supports rapid sensemaking on large doc-
ument collections.

Introduction

1
As information repositories continue to expand and diversify, there is an urgent need for sys-
tems that help people explore and make sense of large document collections. While researchers
in information-seeking and related areas have developed increasingly effective interaction tech-
niques for navigating document collections [1, 16], these methods are hampered by a view of
language that is generally restricted to the surface level; such techniques are oblivious to the
semantic meaning behind the text. Meanwhile, researchers in machine learning and natural
language processing have developed powerful statistical methods for recovering latent seman-
tics [2], but the output of these methods is difﬁcult to present to both domain expert and novice
users alike.

In this paper, we introduce TopicViz, a new tool for searching and navigating large docu-
ment collections (Figure 1). TopicViz infers a set of topics that summarize the latent high-level
semantic organization of a collection, and provides a novel interactive view that exposes this
semantic organization using a force-directed layout. This layout permits a range of interactive

1

affordances, allowing users to gradually reﬁne their understanding of the search results and
citations links, while focusing in on key semantic distinctions of interest.

The analytic engine of our approach is the topic model – a powerful statistical technique
for identifying latent themes in a document collection [2]. Without any annotation, topic mod-
els can extract topics – sets of semantically-related words – and describe each document as a
mixture of these topics. For example, a given research paper might be characterized as 70%
human-computer interaction, and 30% machine learning.1 Topic models have been success-
fully applied to a broad range of text, and the extracted topics have been shown to cohere with
readers’ semantic judgments [4]. But while topic models are often motivated as a technique
to support information seeking, there has been little investigation of how users can understand
and exploit them.

One of the principle strengths of topic models is their ﬂexibility: topics need not correspond
to any predeﬁned taxonomy, but rather represent the latent structure inherent to the document
collection. However, this means that the content of each topic must somehow be conveyed
to the user. In topic modeling research, this issue is almost invariably addressed by showing
ranked lists of words and documents that are closely associated with each topic. But such
lists have undesirable properties:
it is difﬁcult to show more than a few entries per topic,
the meaning of individual terms may be unknown to non-experts;2 in addition, the numerical
scores for each word and topic are hard to interpret.

While hundreds of papers address the mathematical methodology of topic modeling, rel-
atively few take up the question of how topic models can support information exploration.
Our approach is distinguished from prior work in its emphasis on interaction: the user is em-
powered to manipulate the visualization by adding, rearranging or removing topics, and by
controlling the set of documents to visualize. The motivation for this design stems from our
focus on local information exploration: we aim to provide a deep understanding of a local
area of the information landscape that is relevant to the user’s goals, rather than a surface-level
static view of thousands of documents. We provide affordances for users to quickly focus in
on the topical distinctions that are relate to their goals, allowing them to interactively manip-
ulate topics within this space to better understand document-document, document-topic, and
topic-topic relationships.

2 Background
Topic models of document collections A topic model is a hierarchical probabilistic
model of document content [2]. Each topic is a probability distribution over words, β; ev-
ery word in every document is assumed to be randomly generated from one topic. In a given
document the proportion of words generated from each topic is given by a latent vector θd.
Thus, the matrix θ provides a succinct summary of the semantics of each document.

Both the topics β and the document descriptions θ can be obtained through ofﬂine statistical
inference [2, 10], without any need for manual annotation. Thus, topics need not correspond to

1This distinguishes topic models from more coarse-grained techniques that treat each document as a member of a

single cluster [7].

2For example, “muc”, “muc-6” and “muc-7” are three of the four most relevant terms for one of the topics learned
by our model. These terms are well-known to experts in natural language processing (they are the names of shared
research tasks), but are incomprehensible to an outsider.

2

Figure 1: The TopicViz environment. The main panel shows the initial presentation for a selected set
of documents, which are arranged in a force-directed layout controlled by the seven best-matching
topics. The upper-left panel shows the search results in list form, and the lower-left panel describes
the selected topic, “multilingual”.

3

“Morphology”

“Multilingual”

morphemes
morpheme

afﬁxes
afﬁx
kanji
endings
inﬂections
sufﬁxes

inﬂectional
katakana

bilingual

english-chinese

bitext

english-french
monolingual

melamed
cognates
hansard

japanese-english

systran

“Parsing”
nonterminal
nonterminals

adjoining

cfgs
cfg

subtree

non-terminal

subtrees
adjunction

non-terminals

Figure 2: A textual display of the top ten automatically-identiﬁed keywords from three topics
obtained from a dataset of research papers on computational linguistics. The topic names were
assigned manually.

any predeﬁned categories; indeed, this is why they are useful for exploratory analysis. In the
research literature, topic models are often displayed through textual tables showing the most
relevant words and documents for each topic, as in Figure 2.

In typical scenarios, the number of topics ranges from 10-200, and the number of docu-
ments can range from a few hundred to hundreds of thousands. The number of topics can be
determined automatically [20], or set in advance through interactive exploration by a domain
expert. Note that TopicViz is not currently designed to support the user in training new topic
models or exploring alternative topic model parametrizations. Rather, we target the case where
a topic model is trained in advance, to be used by many novices who are interested in a given
domain, such as legal documents or research literature. We consider the problem of supporting
end users to train new topic models to be an important area of future work.

Visualizing large document collections Most prior work on visualizing large document
collections can be divided into two high-level streams: citation graphs and static projection. In
citation graph approaches, each document is a node, and edges are used to represent citation
links; clustering is then performed over the resulting graph [19, 3]. The clusters are displayed
using techniques such as triangulation [19] or force-directed layout [3]. Such approaches are
well-suited to discover connected disciplines in science at a high-level, but do not consider the
textual content of individual documents.

Projection-based methods apply topic models [12, 9, 21] or related techniques like Latent
Semantic Analysis [14]. The high-dimensional document descriptions (θd in our notation from
earlier in this section) are then projected into two-dimensional coordinates for visualization
(Landauer et al. user color as an additional dimension [14]). A related, recent approach to use
visualize topic models is the work of Liu et al., who emphasize the temporal dimension by
placing it on the the X-axis of a graph that shows the evolution of topic strength and content
over time [15].

We differ from this prior work in our emphasis on document search and interactive sense-

4

making [8, 13]. Rather than viewing the entire collection and topic model in a single static
view, the user manipulates an ever-shifting subset of documents and topics. This approach is
driven by the intuition – dating back to early work on Scatter/Gather [7] – that only a small
corner of the topic space will be relevant for any given information search. We allow docu-
ments to be easily added and removed from the view, either through additional search queries
or by exploring citation links; similarly, topics can be moved and manipulated to reveal subtle
semantic distinctions. The remainder of the paper describes these affordances in greater detail.

3 Scenarios
The key idea behind TopicViz is to integrate a force-directed layout for topic models with an
integrated environment for expanding and reﬁning a document list. As in conventional doc-
ument search, the entrance point is the search query; however, rather than simply listing the
search results, they are visualized in an interactive force-directed layout with a range of affor-
dances. As these capabilities are best described by example, this section is centered around a
detailed novice user scenario and two briefer expert scenarios.3 The mechanisms underlying
TopicViz are described in detail in the following section.

3.1 Novice scenario
Consider an individual given the task of searching an unfamiliar research literature, with the
goal of identifying whether a particular technology can be applied to a commercial problem. In
our scenario, the individual is tasked with determining whether it is possible to automatically
identify names on foreign language websites, using a collection of 15,032 research papers on
computational linguistics [18].

The user begins by devising a query; with current tools like Google Scholar and Lexis
Nexis, the response to the query would be an ordered list of results. Only some of the resulting
documents will be relevant, and almost surely there will be relevant documents that do not
match the query. The user may then vary the search terms or navigate the citation links to try
to get a complete sense of the research literature in this unfamiliar area.

Now consider the same task, performed with TopicViz. The ﬁrst step is the same: the user
supplies a search query. The results are shown in a list (the top-left part of Figure 1). The
user then drags as many documents as desired into the main area, which is called the Topic
Field: each document is displayed as a node, and these nodes are surrounded by a ring of
topic centers. The topic centers are “pinned,” while the position of each document is set by
a force-directed layout in which the topics each exert an attractive force proportional to the
document’s topical relevance. Thus, documents with similar content will be located near each
other.

The size of each topic center is determined by its relevance to the documents in the ﬁeld,
and only the most relevant topics are shown. The panel on the lower-left shows the most
relevant words for each topic (selected by mouseover). The user can also see the relevance
of each topic to the documents in the ﬁeld both statically (by the document’s position) and

3Video of many of these affordances can be found at http://www.cs.cmu.edu/˜dchau/topicviz/

topicviz.mp4.

5

Figure 3: Rearranging the topic centers to view topic-topic relationships

6

Figure 4: By arranging the topic centers into two points, the documents are shown linearly by
relevance.

dynamically (by dragging the topic center around to see how the document nodes are affected).
The topic names are speciﬁed in advance, either manually by a domain expert, or through
automatic methods [17]; the user is free to rename topics with more familiar terms.

In our scenario, the user recognizes the topic multilingual as especially relevant to the
search – but other topics like morphology and Bayesian are not familiar. To better understand
if these topics are relevant, the user rearranges the topics, with multilingual in the upper-left
corner and the unfamiliar topics in an arc across the screen (Figure 3). From this view, the user
sees that morphology is related to multilingual, as several documents have strong connections
with both topics.

The user inspects the set of terms associated with the topic morphology (Figure 2). While
terms like “morpheme” and “inﬂection” are confusing, the user recognizes the terms “afﬁx”
and “sufﬁx” as referring to parts of individual words. Based on this insight, the user renames
the topic from morphology to subwords. While this name is not typically used in the research
literature, it helps the user relate the topic model to her pre-existing ontology.

Having identiﬁed morphology and multilingual as key topics of interest, the user again
rearranges the topics, placing the relevant topics in one corner of the screen and the others
in another corner. This causes the document nodes to form a line, with location governed by
relevance to the topics of the interest (Figure 4). The user now removes documents that are not
close to the desired topics by selecting and deleting their nodes.

7

The user has now culled the original list of query hits to a set of documents that are closely
related to multiple topics of interest. But the coverage of this document set depends on the
quality of the original query. To make sure that important documents have not been missed, the
user selects a subset of particularly promising documents and adds documents that cite them.
These new documents may not match the search query by name, but may still be relevant. The
user can now investigate the topical characteristics of these new documents and further reﬁne
the search.

Ultimately, the user arrives at a set of documents that reﬂect the underlying semantics of
the information search. By investigating the topic structure, the user has pruned away “false
positives” that match the query but are in fact irrelevant; by walking the citation graph, the
user has identiﬁed “false negatives” that are relevant but did not match the original query.
Morever, by interatively exploring the documents, topics, and terms that relate to the initial
query, the user acquires a deeper, structured understanding of the relevant area of the document
collection. This elucidates the speciﬁc role played by each document in the relevant research
literature, and contextualizes previously unknown themes, such as the topic morphology. The
user is now prepared to summarize the desired content, having obtained both a comprehensive,
high-precision list of documents and a clearer understanding of this area of research.

3.2 Expert scenarios
Determining author expertise We brieﬂy consider a scenario involving a user who has
more expertise in the domain of the document collection. Here, the expert wants to identify
the topical interests of several authors – perhaps to distinguish the speciﬁc contributions of
multiple authors on a single paper. To do this, the user searches for papers by each author
and drags them into the ﬁeld. However, unlike the previous view, the documents are pinned in
place, and the topics ﬂoat between them (such non-default behavior can be easily set using the
toolbar at the topic of the window). The edges in the force-directed layout are bidirectional, and
work identically in this setting; the user need only pin sets of documents for each author, and
then add relevant topics to the view. Figure 5 shows such a view for the relationship between
the three authors of a heavily-cited paper in computational linguistics; this view reveals that
the author to the upper-left has focused more on the speech topic; the author to the upper-right
has focused more on syntax and lexical semantics; and the author on the bottom has focused
more on the Bayesian and applications topics.

Direct manipulation 2D projections Finally, we consider a scenario in which an expert
user has a detailed understanding of the topic model, and wants to select a set of documents
that ﬁt a very speciﬁc semantic proﬁle. The novice scenario explored an affordance in which
documents were arranged on a spectrum between two topics (Figure 4). In fact, much more ex-
pressive arrangements are possible, yielding a direct-manipulation inferface for creating two-
dimensional projections.

Suppose that the expert user wants documents that describe multilingual analysis and
translation, but avoid syntax and parsing; in fact, let us suppose that parsing is completely
inappropriate due to technical constraints. The user can arrange the topic centers on a line, with
parsing to the far left and syntax slightly left of center, while locating the multilingual and
translation topics to the far right. Such a conﬁguration can be viewed as a one-dimensional

8

Figure 5: To compare topical emphasis of different authors, the expert user creates and pins “piles”
of documents for each author; the unpinned topic centers are pulled between them.

9

Figure 6: The expert user arranges the topic centers on the X and Y-axes to create a custom two-
dimensional projection of the topic space.

projection that assigns a large negative weight to parsing, a smaller negative weight to syn-
tax, and a equal positive weights to multilingual and translation. Next, the user wants to
distinguish documents that focus on morphology from those that focus on semantics – this
time using the Y-axis. The ﬁnal conﬁguration is shown in Figure 6. The user can now select
the documents in the desired subspace for further viewing and reﬁnement, as described in the
novice scenario.

Overall, we see that in two dimensions, the location of each topic center deﬁnes a projection
matrix that reduces the high-dimensional topic proportion vector to an easily viewable two
dimensional representation. By dragging topics further from the center, their absolute weight
is increased, causing them to exert a greater inﬂuence on the position of each document. Thus,
TopicViz offers an intuitive direct manipulation interface for designing projections that isolate
the desired region of topic space.

4 The TopicViz System
We now describe in more detail the mechanisms and affordances underlying the TopicViz sys-
tem. The core idea of TopicViz is to provide affordances for interactively exploring the topical
afﬁliations of a set of documents, while facilitating reﬁnement and expansions of the docu-

10

ment set. Thus, the main entry point is the search query, which will be familiar to users from
traditional information search interfaces. However, from this point, we diverge from prior ap-
proaches, emphasizing the direct manipulation design of novel 2D projections and interactive
exploration of document-topic and topic-topic relationships. The previous section described
the envisioned use cases for such interactions; we now describe the underlying mechanisms.

4.1 Document positioning
As described in Section 2, a topic model is deﬁned by the topic-term relations and the topic-
document relations. Both objects are high-dimensional: the topic-term matrix contains a row
for each topic, and a column for each word in the vocabulary; the topic-document matrix con-
tains a row for each document and a column for each topic. The number of documents and
vocabulary size are each typically in the thousands;4, and the numerical values are not intu-
itively meaningful on their own; rather, the structure of the topic model is best understood in a
relational setting. Thus, we present a document ﬁeld view incorporating topics and documents.
In the document ﬁeld, we see the relationship between documents and topics. Inspired by
“dust-and-magnet” approaches to information visualization, (e.g., [22]), we initially arrange
a ring of topic nodes around the outside of the ﬁeld, which act as magnets. Documents are
represented as nodes within this ﬁeld; edge weights are based on Hooke’s law, with 1 − θdi as
the force of the spring between topic i and document d. A document that is a near 100% match
for a given topic will be placed almost directly on that topic’s magnet; a document that is a
50% match for each of two topics will be positioned halfway between them. Thus, documents
that have similar topic proportions are located near each other, reﬂecting semantic differences
directly in the spatial layout. Visualizing such a high-dimensional model in 2D inevitably
causes information to be lost, but the force-directed layout permits interactive manipulation of
document nodes, allowing users to more closely examine regions of particular interest.

4.2 Document set reﬁnement
As the number of documents in a collection is typically in the thousands, it is not helpful to
view all of the documents at the same time. Our interface includes two affordances for selecting
sets of documents to visualize. The ﬁrst affordance – which is the entry point to interaction
with our system – is the search query. Just as in traditional search interfaces, the user enters
a query and receives a list of results (in a separate panel). These results can be sorted by
traditional metadata: titles, author, year, and venue. The user can then drag documents into the
document ﬁeld, which provides an intuitive graphical visualization of the semantic structure of
the search results. The second affordance permits the user to walk to the citation graph, adding
citing or cited documents for any set of documents already in the view; the citation links are
made visible.

By default, the set of topic magnets is dynamically updated to show the topics that are most
relevant to the documents currently in the ﬁeld. This feature can be turned off, allowing topics
to be added and deleted manually.

4In the scenario, the number of topics is 25; the vocabulary size is 18,743 (after pruning infrequent words) the

number of documents is 15,032.

11

4.3 Implementation
TopicViz is implemented through Shiftr [5], a Java platform designed to support interactive ex-
ploration and querying of large graph data with millions of nodes and edges. Shiftr builds on
the Prefuse library for force-directed layouts [11], providing a collection of fundamental oper-
ations over graph data: querying nodes by arbitrary node attributes; visualizing user-speciﬁed
subgraphs; and ﬂexible spatial arrangement for nodes through pinning and unpinning. Top-
icViz uses these lower-level operations to provide a force-directed layout interface for exploring
topic models of document content.

5 Future work
A key target for future work is empirical validation. Indeed, beyond the necessary task of eval-
uating the speciﬁc design decisions taken in TopicViz, we also believe that this tool can serve as
a platform for in situ user studies of whether and how topic models can best support document
set exploration and sensemaking. Speciﬁcally, we plan to develop a battery of information-
exploration tasks (similar to the email exploration tasks of Liu et al. [15]) and compare the
efﬁcacy of TopicViz with traditional search interfaces, as well as textual and table-based repre-
sentations of topic models.

From a visualization standpoint, we see several intriguing directions for future work. While
TopicViz offers an innovative take on the document-topic relationship, the connection between
topics and terms is still expressed through traditional term lists. We plan to explore whether
a more spatial visualization for this relationship would be possible, or whether an alternative
approach such as DocuBurst [6] could be incorporated in the TopicViz environment. We also
believe that an integrated presentation of document metadata such as time, authorship, and
venue would substantially improve the practical usability of the system. Finally, we are eager
to investigate the use of color as a third dimension, either to visualize such metadata, or to
enable gestalt high-level comparisons between document sets [14].

6 Summary
Topic models can give powerful insights on document collections – but only if used in combi-
nation with a comprehensible presentation and an interaction design built around the informa-
tion exploration process. TopicViz presents an interactive visualization that places topic models
in the context of a search interface, ﬁlling the same role currently played by keyword search.
We see two main advantages of our approach: it accounts for latent document semantics, and
provides an interactive spatial visualization that allows the user to rapidly focus on key areas
of interest.

Acknowledgments
This work was supported by the following grants: AFOSR FA9550010247, ONR N0001140910758,
NSF OCI-0943148, NSF IIS-0968484, NSF IIS-0713379, NSF CAREER DBI-0546594, and
an Alfred P. Sloan Fellowship.

12

References
[1] M. Baldonado and T. Winograd. SenseMaker: an information-exploration interface sup-
porting the contextual evolution of a user’s interests. In Proceedings of CHI, pages 11–18,
1997.

[2] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent Dirichlet allocation. Journal of Machine

Learning Research, 3:993–1022, 2003.

[3] K. W. Boyack, R. Klavans, and K. B¨orner. Mapping the backbone of science. Sciento-

metrics, 64(3):351–374, 2005.

[4] J. Chang, J. Boyd-Graber, S. Gerrish, C. Wang, and D. M. Blei. Reading tea leaves: How

humans intepret topic models. In NIPS, 2009.

[5] D. H. Chau, A. Kittur, C. Faloutsos, and J. I. Hong. Shiftr: a user-directed, link-based
system for ad hoc sensemaking of large heterogeneous data collections. In Proceedings
of CHI, pages 3535–3536, 2009.

[6] C. Collins, S. Carpendale, and G. Penn. Docuburst: Visualizing document content using

language structure. Computer Graphics Forum, 28(3):1039–1046, 2009.

[7] D. Cutting, D. Karger, J. Pedersen, and J. Tukey. Scatter/gather: A cluster-based approach
to browsing large document collections. In Proceedings of SIGIR, pages 318–329, 1992.
[8] B. Dervin. An overview of sense-making research: concepts, methods, and results to

date. In Annual Meeting of the International Communication Association, 1983.

[9] H. et al. The NIH visual browser: An interactive visualization of biomedical research. In

Proceedings of IEEE Conference on Information Visualisation, 2009.

[10] T. Grifﬁths and M. Steyvers. Finding scientiﬁc topics, 2004.
[11] J. Heer, S. K. Card, and J. A. Landay. prefuse: a toolkit for interactive information

visualization. In Proceedings of CHI, pages 421–430, 2005.

[12] T. Iwata, T. Yamada, and N. Ueda. Probabilistic latent semantic visualization: Topic

model for visualizing documents. In Proceedings of KDD, 2008.

[13] C. C. Kuhlthau. Inside the search process: Information seeking from the users perspec-

tive. Journal of the American Society for Information Science, 42:361–371, 1991.

[14] T. K. Landauer, D. Laham, and M. Derr. From paragraph to graph: Latent semantic

analysis for information visualization. PNAS, 101:5214–5219, April 2004.

[15] S. Liu, M. X. Zhou, S. Pan, W. Qian, W. Cai, and X. Lian. Interactive, topic-based visual

text summarization and analysis. In Proceedings of CIKM, pages 543–552, 2009.

[16] G. Marchionini. Exploratory search: from ﬁnding to understanding. Communications of

the ACM, 49(4):46, 2006.

[17] Q. Mei, X. Shen, and C. Zhai. Automatic labeling of multinomial topic models.

In

Proceedings of KDD, pages 490–499, 2007.

[18] D. R. Radev, P. Muthukrishnan, and V. Qazvinian. The ACL anthology network corpus.
In Workshop on Text and Citation Analysis for Scholarly Digital Libraries, pages 54–61,
2009.

13

[19] H. Small. Visualizing science by citation mapping. Journal of the American Society for

Information Science, 50(9):799–813, 1999.

[20] Y. Teh, M. Jordan, M. Beal, and D. Blei. Hierarchical dirichlet processes. Journal of the

American Statistical Association, 101(576):1566–1581, 2006.

[21] L. van der Maaten and G. Hinton. Visualizing high-dimensional data using t-sne. Journal

of Machine Learning Research, 9:2579–2605, 2008.

[22] J. S. Yi, R. Melton, J. Stasko, and J. A. Jacko. Dust & magnet: multivariate information

visualization using a magnet metaphor. Information Visualization, 4:239–256, 2005.

14

","{""pos"":{""0"":1,""1"":2,""2"":3,""3"":4},""0"":{""0"":""j"",""1"":""d"",""2"":""m"",""3"":""c*""},""2"":{""0"":""documents*"",""1"":""models"",""2"":""collections"",""3"":""proceedings*""},""4"":{""0"":""relevant*"",""1"":""desired"",""2"":""like"",""3"":""wants*""},""3"":{""0"":""figure*"",""1"":""scenario*"",""2"":""2009*"",""3"":""fact*""},""1"":{""0"":""multilingual"",""1"":""morphology"",""2"":""interface*"",""3"":""syntax*""}}",2011,{},False,False,journalArticle,False,SGYL3UXY,[],self.user,"{""Unnamed: 0"":{""0"":0,""1"":1,""2"":2,""3"":3,""4"":4,""5"":5,""6"":6,""7"":7,""8"":8,""9"":9,""10"":10,""11"":11,""12"":12,""13"":13,""14"":14,""15"":15,""16"":16,""17"":17,""18"":18,""19"":19,""20"":20,""21"":21,""22"":22,""23"":23,""24"":24,""25"":25,""26"":26,""27"":27,""28"":28,""29"":29,""30"":30,""31"":31,""32"":32,""33"":33,""34"":34,""35"":35,""36"":36,""37"":37,""38"":38,""39"":39,""40"":40,""41"":41,""42"":42,""43"":43,""44"":44,""45"":45,""46"":46,""47"":47,""48"":48,""49"":49,""50"":50,""51"":51,""52"":52,""53"":53,""54"":54,""55"":55,""56"":56,""57"":57},""C"":{""0"":3.4358249396,""1"":3.3051050672,""2"":6.2563384487,""3"":7.727551784,""4"":6.6562841566,""5"":4.6577059085,""6"":4.6747967338,""7"":8.4850135879,""8"":5.0904012127,""9"":4.6367973636,""10"":5.7019099961,""11"":12.4565138562,""12"":4.7834172824,""13"":3.952757475,""14"":5.4929427419,""15"":6.4895937616,""16"":10.7723531675,""17"":6.5018289142,""18"":3.943803019,""19"":3.8549634544,""20"":7.694056978,""21"":10.1289806708,""22"":6.6448641627,""23"":8.4415551358,""24"":3.7089400481,""25"":3.3868201884,""26"":3.2651883544,""27"":6.4546456996,""28"":7.5934669096,""29"":3.2828782629,""30"":6.8111935701,""31"":3.8249750137,""32"":4.9872832791,""33"":3.5610421375,""34"":5.3216319303,""35"":6.5624928604,""36"":3.4872604906,""37"":3.810233162,""38"":4.9620378782,""39"":5.3447630916,""40"":4.7493955814,""41"":4.7342002317,""42"":3.9306006513,""43"":3.3228456125,""44"":6.6210296007,""45"":3.7213558734,""46"":4.9986913185,""47"":4.725547917,""48"":4.6769568717,""49"":4.2315646859,""50"":3.3598783771,""51"":4.6700243543,""52"":4.2051563812,""53"":4.1717128465,""54"":4.3384200062,""55"":3.2916828185,""56"":3.4445553017,""57"":3.8161177028},""count"":{""0"":184,""1"":110,""2"":102,""3"":96,""4"":38,""5"":34,""6"":30,""7"":28,""8"":24,""9"":24,""10"":20,""11"":20,""12"":18,""13"":18,""14"":18,""15"":18,""16"":18,""17"":16,""18"":16,""19"":16,""20"":16,""21"":16,""22"":14,""23"":14,""24"":12,""25"":12,""26"":12,""27"":12,""28"":12,""29"":10,""30"":10,""31"":10,""32"":10,""33"":10,""34"":10,""35"":8,""36"":8,""37"":8,""38"":8,""39"":8,""40"":8,""41"":8,""42"":8,""43"":8,""44"":8,""45"":8,""46"":8,""47"":6,""48"":6,""49"":6,""50"":6,""51"":6,""52"":6,""53"":6,""54"":6,""55"":6,""56"":6,""57"":6},""sigma_nor"":{""0"":1.2376237401,""1"":1.2871789262,""2"":1.5747049787,""3"":1.7328099709,""4"":1.9252896843,""5"":1.6624357071,""6"":1.695256797,""7"":2.3344331036,""8"":1.8211877474,""9"":1.7426654193,""10"":1.9824690844,""11"":3.2309386636,""12"":1.8378387598,""13"":1.6786351311,""14"":1.9738258712,""15"":2.1648432497,""16"":2.985673669,""17"":2.2075225762,""18"":1.6977302962,""19"":1.6800253448,""20"":2.4451232448,""21"":2.9303823281,""22"":2.2813903909,""23"":2.65490166,""24"":1.691860305,""25"":1.6217514283,""26"":1.5952784525,""27"":2.2894587863,""28"":2.5373214169,""29"":1.6147758033,""30"":2.4220725017,""31"":1.7388103294,""32"":2.0047524416,""33"":1.6784211292,""34"":2.0812531334,""35"":2.4187797353,""36"":1.6758279029,""37"":1.7538555473,""38"":2.0321224624,""39"":2.1245858487,""40"":1.9807497643,""41"":1.9770786879,""42"":1.7829353813,""43"":1.6361065679,""44"":2.432921749,""45"":1.7323834969,""46"":2.0409776438,""47"":1.9957196989,""48"":1.9832776649,""49"":1.8692322748,""50"":1.6460316701,""51"":1.9815025515,""52"":1.862470267,""53"":1.8539068456,""54"":1.8965932323,""55"":1.6285697807,""56"":1.667713714,""57"":1.7628545367},""vocab_index"":{""0"":0,""1"":1,""2"":2,""3"":3,""4"":8,""5"":11,""6"":16,""7"":22,""8"":25,""9"":27,""10"":37,""11"":38,""12"":42,""13"":43,""14"":44,""15"":45,""16"":46,""17"":47,""18"":53,""19"":54,""20"":56,""21"":57,""22"":64,""23"":65,""24"":80,""25"":81,""26"":82,""27"":84,""28"":85,""29"":113,""30"":114,""31"":115,""32"":116,""33"":117,""34"":118,""35"":119,""36"":150,""37"":154,""38"":159,""39"":160,""40"":162,""41"":163,""42"":168,""43"":169,""44"":171,""45"":172,""46"":173,""47"":198,""48"":203,""49"":233,""50"":234,""51"":235,""52"":236,""53"":239,""54"":240,""55"":244,""56"":247,""57"":251},""word"":{""0"":""topic"",""1"":""document"",""2"":""documents"",""3"":""user"",""4"":""models"",""5"":""relevant"",""6"":""figure"",""7"":""query"",""8"":""collections"",""9"":""latent"",""10"":""nodes"",""11"":""j"",""12"":""multilingual"",""13"":""scenario"",""14"":""\ufb01eld"",""15"":""d"",""16"":""m"",""17"":""c"",""18"":""left"",""19"":""morphology"",""20"":""author"",""21"":""proceedings"",""22"":""centers"",""23"":""pages"",""24"":""literature"",""25"":""consider"",""26"":""match"",""27"":""t"",""28"":""2009"",""29"":""desired"",""30"":""relevance"",""31"":""center"",""32"":""manipulation"",""33"":""interface"",""34"":""journal"",""35"":""0"",""36"":""like"",""37"":""corner"",""38"":""wants"",""39"":""authors"",""40"":""direct"",""41"":""projections"",""42"":""spatial"",""43"":""11"",""44"":""nsf"",""45"":""a"",""46"":""k"",""47"":""muc"",""48"":""english"",""49"":""original"",""50"":""fact"",""51"":""focused"",""52"":""syntax"",""53"":""translation"",""54"":""weight"",""55"":""vocabulary"",""56"":""chi"",""57"":""american""},""vector"":{""0"":""[-0.2362476   1.6387982  -1.2609516  -1.4431493  -0.02378864 -0.88858855\n  2.167625    2.5470567  -2.2126856  -0.85504484]"",""1"":""[-0.54063874  1.6377518  -1.5035044  -1.5669008  -0.23944807 -0.7501079\n  2.2683094   2.2138038  -1.7570393  -0.3958471 ]"",""2"":""[-0.5558689   1.7640924  -1.8979678  -1.7212846   0.03650542 -0.72236645\n  2.4005666   2.230907   -1.7546626  -0.513814  ]"",""3"":""[-6.7038602e-01  1.7626318e+00 -1.5797573e+00 -8.5402679e-01\n -2.4093476e-03 -7.0869225e-01  2.6056080e+00  2.0523784e+00\n -2.0280259e+00 -1.1301488e+00]"",""4"":""[-0.15245683  1.2874261  -1.9247235  -1.3988881  -0.44220635 -0.5727749\n  2.2392075   2.297143   -1.3087695  -1.0277364 ]"",""5"":""[-0.14463393  1.46184    -0.8258192  -1.6606747  -0.62946445 -1.8226976\n  1.7903436   2.0629892  -2.2114918  -0.6517205 ]"",""6"":""[-0.09352029  1.0554883  -1.5697519  -1.3805757  -0.9060944  -0.8237478\n  2.0191314   2.2260802  -1.2913011  -1.3332635 ]"",""7"":""[-0.5006008   1.8511752  -1.3429022  -0.89224714 -0.3976199  -0.8066208\n  2.2722332   2.3288398  -2.033677   -1.0749161 ]"",""8"":""[-0.22471721  1.686284   -2.013538   -1.5341793  -0.02326517 -0.5969659\n  2.242954    2.4778783  -1.6193997  -0.6829946 ]"",""9"":""[ 0.13101909  1.4402505  -0.9558121  -1.1796272  -0.61136824 -1.9204239\n  1.5201296   2.153004   -2.0756397  -0.59278923]"",""10"":""[-0.24788126  1.7403508  -2.2658603  -1.0948673  -0.15483312 -0.8609743\n  2.3677611   2.1230834  -1.5565839  -1.4090995 ]"",""11"":""[-0.23404323  0.49801138 -2.218879   -0.7020185  -0.59672433 -2.2232523\n  0.9619957   1.2358936  -1.4078466  -2.8565934 ]"",""12"":""[-0.45749202  1.7848411  -1.5495075  -0.5300532   0.24754255 -1.3853835\n  1.7079371   2.290646   -2.3302994  -0.5073697 ]"",""13"":""[-0.20655316  1.0386447  -1.4505001  -1.5128819  -0.8162417  -0.7257342\n  2.1720164   2.1578157  -1.3098143  -1.0120313 ]"",""14"":""[ 0.20189969  1.6503145  -2.0433235  -1.1935467   0.26946497 -1.0840304\n  1.8217723   2.6973007  -1.9361737  -1.0167174 ]"",""15"":""[-0.06346922  0.6171851  -2.300745   -1.186558   -0.68210906 -2.291364\n  1.409519    1.367297   -1.0268507  -2.5714667 ]"",""16"":""[-0.08780601  0.47736987 -2.367409   -0.9693939  -0.7433038  -2.2313352\n  1.2818182   1.3614187  -1.0515087  -2.8090475 ]"",""17"":""[ 0.09393504  0.5677988  -2.186388   -1.0203224  -0.94465333 -2.0512419\n  1.2844757   1.5441928  -1.0646701  -2.5878637 ]"",""18"":""[ 0.10156589  1.3564327  -1.0264304  -1.686935   -0.9058915  -2.5215874\n  1.6990646   1.6939874  -2.0827723  -1.0606399 ]"",""19"":""[ 0.12933077  1.9492091  -1.8963366  -0.6259564   0.01247153 -0.9811751\n  1.8008438   2.7749314  -1.9506236  -0.87727046]"",""20"":""[-0.52460593  1.4119791  -1.3977867  -1.5372994   0.17636693 -1.0585425\n  2.4191203   1.9881126  -2.1312878  -0.6817224 ]"",""21"":""[-0.45396152  1.7805899  -1.8224477  -1.6143888   0.3524435  -0.76269406\n  2.3058002   2.4281023  -1.9912585  -0.48177224]"",""22"":""[-0.08660893  1.6320932  -2.301529   -1.3760333  -0.17884785 -1.0293274\n  2.2704124   2.142646   -1.5099559  -1.3891026 ]"",""23"":""[-0.6003002  1.6710842 -1.7629019 -1.310754   0.1731397 -0.7302679\n  2.641575   2.0519915 -1.9453188 -0.9724433]"",""24"":""[-0.05222469  1.5030874  -1.8028249  -1.1927215   0.39066097 -0.86949587\n  2.0110424   2.5628238  -2.0341563  -0.76543134]"",""25"":""[-0.15837929  1.0838398  -0.85169774 -1.7977202  -1.077317   -1.7160968\n  1.8734971   1.8687888  -1.7962077  -0.9625087 ]"",""26"":""[-0.09154388  1.1989781  -1.593443   -1.1886957  -0.92841256 -1.2104344\n  1.9329401   2.0812564  -1.4395233  -1.583026  ]"",""27"":""[-0.08732195  0.34428343 -2.1373432  -0.85231626 -0.91987246 -2.3038802\n  1.2580856   1.4342582  -1.0685247  -2.7151775 ]"",""28"":""[-0.18298188  0.83459055 -1.3720928  -1.5880954  -0.9935533  -1.113021\n  1.999753    1.9520543  -1.280283   -1.2495722 ]"",""29"":""[-0.13084538  1.2527484  -0.7738167  -1.610802   -0.8591539  -2.3362353\n  1.6933621   1.7218882  -2.1692808  -0.9409363 ]"",""30"":""[-0.18554467  1.667161   -1.0461501  -1.5301081  -0.51623255 -1.2367146\n  1.8704334   2.503386   -2.1600168  -0.84690523]"",""31"":""[ 0.14866102  1.4156996  -2.176803   -1.4256109  -0.46518216 -1.4872005\n  1.954877    2.070457   -1.4631702  -1.5664954 ]"",""32"":""[ 0.14902066  1.8259243  -1.2814786  -0.6142339  -0.40800226 -1.4081885\n  1.6118085   2.5319438  -2.0559719  -0.65087056]"",""33"":""[-0.35943455  1.8921033  -1.5901103  -0.529224   -0.09268138 -0.7784284\n  2.2098694   2.4034762  -2.0280588  -1.0138212 ]"",""34"":""[-0.3600044   1.66269    -1.7673023  -1.4416664   0.45722473 -0.83243686\n  2.246912    2.4118936  -2.0737364  -0.55185866]"",""35"":""[-0.13861147  0.5670185  -1.9965289  -0.99619657 -0.7656358  -2.2003028\n  1.2976267   1.4292481  -1.3069531  -2.4268093 ]"",""36"":""[-0.18098088  0.9798295  -0.89473647 -1.7414013  -1.0813109  -1.9845293\n  1.778418    1.7087321  -1.8095068  -1.1084954 ]"",""37"":""[ 0.07823353  1.179028   -1.9784495  -1.394578   -0.7642718  -1.4731829\n  1.899291    1.9659463  -1.3286731  -1.6665591 ]"",""38"":""[-0.10759237  1.1947813  -0.8445715  -1.734252   -0.9935338  -2.355759\n  1.7529722   1.6558373  -2.0676117  -1.0955746 ]"",""39"":""[-0.4053569   1.3600452  -1.7477367  -1.3826281   0.27346098 -0.8629859\n  2.4185643   2.046608   -1.904406   -0.79288554]"",""40"":""[ 0.02952125  1.3835546  -0.8829582  -1.460467   -0.59991044 -2.052957\n  1.6563956   1.9592723  -2.1265702  -0.54522943]"",""41"":""[-0.06023459  1.1348832  -1.7532196  -1.4019316  -0.7287832  -0.63813317\n  2.0832677   2.3271034  -1.2056257  -1.0278331 ]"",""42"":""[ 0.15418959  1.7970746  -1.4558187  -0.77560705 -0.33772007 -1.3877096\n  1.5527172   2.6437218  -2.05044    -0.8300461 ]"",""43"":""[-0.10784442  0.69409543 -1.6099856  -1.2248158  -0.83872485 -2.2052493\n  1.4790416   1.5720537  -1.425485   -1.8972037 ]"",""44"":""[-0.24460834  0.6170693  -2.021666   -0.8220912  -0.5930042  -2.0639267\n  1.1221193   1.384303   -1.5289518  -2.491785  ]"",""45"":""[-0.00499815  1.0792795  -0.993027   -1.3672794  -0.75918084 -1.9258205\n  1.5508006   1.9247282  -1.8578606  -0.83784294]"",""46"":""[-0.11349365  0.43362445 -2.0595775  -0.91270864 -0.83376056 -2.058187\n  1.0044448   1.3145612  -1.3794926  -2.810812  ]"",""47"":""[-0.26116106  0.4248978  -2.310038   -0.5569725  -0.6367272  -2.103227\n  0.8165766   1.2380173  -1.2841067  -3.0118763 ]"",""48"":""[-0.5868482   1.590449   -1.7185516  -0.5293116   0.46615005 -1.304524\n  1.8127142   2.1028392  -2.2712789  -0.6793658 ]"",""49"":""[-0.29328865  1.3968498  -1.1171467  -1.3838146  -0.22655138 -1.8011565\n  1.8247737   1.9297314  -2.2162967  -0.6338159 ]"",""50"":""[-0.21390915  1.0269705  -1.0840179  -1.6577243  -0.8316096  -1.40151\n  1.8639144   1.9985175  -1.687248   -0.96657777]"",""51"":""[ 0.00604285  1.4329692  -0.8671801  -1.7619184  -0.8120426  -2.1946142\n  1.771387    1.8692086  -2.1707616  -0.80793494]"",""52"":""[-0.22114286  1.9780174  -1.7882054  -0.36516252  0.13528612 -0.95985574\n  1.9777102   2.4849753  -2.0660195  -0.7380166 ]"",""53"":""[-0.47695804  1.7439523  -1.6283886  -0.75668854  0.359814   -1.1588745\n  1.9383758   2.2786295  -2.2387674  -0.47007295]"",""54"":""[-0.15925196  1.436426   -1.1348891  -1.3684485  -0.6314539  -1.2318739\n  1.7323728   2.4628634  -1.987974   -1.1736056 ]"",""55"":""[-0.19606093  1.8724129  -1.6891675  -0.5640034   0.0805076  -0.94887817\n  1.8270583   2.6261346  -2.0976746  -0.7591255 ]"",""56"":""[-0.12595527  0.38404685 -2.2543728  -0.69380623 -0.7866608  -2.078063\n  0.90566665  1.3261746  -1.254331   -2.9887815 ]"",""57"":""[-0.5767962   1.376902   -1.6371536  -0.6175147   0.2794028  -1.4977397\n  1.7262241   1.9366677  -2.2099164  -0.88461494]""},""topic"":{""0"":-1,""1"":-1,""2"":2,""3"":-1,""4"":2,""5"":4,""6"":3,""7"":-1,""8"":2,""9"":-1,""10"":-1,""11"":0,""12"":1,""13"":3,""14"":-1,""15"":0,""16"":0,""17"":0,""18"":-1,""19"":1,""20"":-1,""21"":2,""22"":-1,""23"":2,""24"":-1,""25"":-1,""26"":-1,""27"":0,""28"":3,""29"":4,""30"":-1,""31"":-1,""32"":-1,""33"":1,""34"":2,""35"":0,""36"":4,""37"":-1,""38"":4,""39"":2,""40"":4,""41"":-1,""42"":-1,""43"":0,""44"":0,""45"":4,""46"":0,""47"":0,""48"":-1,""49"":-1,""50"":3,""51"":4,""52"":1,""53"":1,""54"":-1,""55"":1,""56"":0,""57"":-1},""exemplar"":{""0"":null,""1"":null,""2"":""*"",""3"":null,""4"":null,""5"":""*"",""6"":""*"",""7"":null,""8"":null,""9"":null,""10"":null,""11"":null,""12"":null,""13"":""*"",""14"":null,""15"":null,""16"":null,""17"":""*"",""18"":null,""19"":null,""20"":null,""21"":""*"",""22"":null,""23"":null,""24"":null,""25"":null,""26"":null,""27"":""*"",""28"":""*"",""29"":null,""30"":null,""31"":null,""32"":null,""33"":""*"",""34"":""*"",""35"":""*"",""36"":null,""37"":null,""38"":""*"",""39"":""*"",""40"":""*"",""41"":null,""42"":null,""43"":null,""44"":null,""45"":null,""46"":""*"",""47"":null,""48"":null,""49"":null,""50"":""*"",""51"":""*"",""52"":""*"",""53"":""*"",""54"":null,""55"":""*"",""56"":null,""57"":null},""word*"":{""0"":""topic"",""1"":""document"",""2"":""documents*"",""3"":""user"",""4"":""models"",""5"":""relevant*"",""6"":""figure*"",""7"":""query"",""8"":""collections"",""9"":""latent"",""10"":""nodes"",""11"":""j"",""12"":""multilingual"",""13"":""scenario*"",""14"":""\ufb01eld"",""15"":""d"",""16"":""m"",""17"":""c*"",""18"":""left"",""19"":""morphology"",""20"":""author"",""21"":""proceedings*"",""22"":""centers"",""23"":""pages"",""24"":""literature"",""25"":""consider"",""26"":""match"",""27"":""t*"",""28"":""2009*"",""29"":""desired"",""30"":""relevance"",""31"":""center"",""32"":""manipulation"",""33"":""interface*"",""34"":""journal*"",""35"":""0*"",""36"":""like"",""37"":""corner"",""38"":""wants*"",""39"":""authors*"",""40"":""direct*"",""41"":""projections"",""42"":""spatial"",""43"":""11"",""44"":""nsf"",""45"":""a"",""46"":""k*"",""47"":""muc"",""48"":""english"",""49"":""original"",""50"":""fact*"",""51"":""focused*"",""52"":""syntax*"",""53"":""translation*"",""54"":""weight"",""55"":""vocabulary*"",""56"":""chi"",""57"":""american""},""pos"":{""0"":1,""1"":2,""2"":1,""3"":3,""4"":2,""5"":1,""6"":1,""7"":4,""8"":3,""9"":5,""10"":6,""11"":1,""12"":1,""13"":2,""14"":7,""15"":2,""16"":3,""17"":4,""18"":8,""19"":2,""20"":9,""21"":4,""22"":10,""23"":5,""24"":11,""25"":12,""26"":13,""27"":5,""28"":3,""29"":2,""30"":14,""31"":15,""32"":16,""33"":3,""34"":6,""35"":6,""36"":3,""37"":17,""38"":4,""39"":7,""40"":5,""41"":18,""42"":19,""43"":7,""44"":8,""45"":6,""46"":9,""47"":10,""48"":20,""49"":21,""50"":4,""51"":7,""52"":4,""53"":5,""54"":22,""55"":6,""56"":11,""57"":23},""x2D"":{""0"":1.5288242102,""1"":0.6362017989,""2"":0.9501055479,""3"":1.640811801,""4"":1.08056283,""5"":4.4089512825,""6"":1.5540401936,""7"":2.1719813347,""8"":0.9667916894,""9"":3.9993560314,""10"":1.2686649561,""11"":-9.3054475784,""12"":3.2037417889,""13"":1.4966666698,""14"":2.0461027622,""15"":-8.6170711517,""16"":-8.7111673355,""17"":-8.5526275635,""18"":4.3871011734,""19"":2.3227365017,""20"":0.8724307418,""21"":1.118662715,""22"":1.2239148617,""23"":0.7172090411,""24"":1.6557711363,""25"":3.5541899204,""26"":2.0331671238,""27"":-8.8479337692,""28"":1.976416111,""29"":4.4523558617,""30"":3.3047835827,""31"":1.4753379822,""32"":3.1359398365,""33"":2.4305026531,""34"":1.2747428417,""35"":-8.950843811,""36"":3.9462759495,""37"":1.7259156704,""38"":4.4438500404,""39"":0.7399587631,""40"":4.0857696533,""41"":1.2322747707,""42"":3.0826048851,""43"":-9.144282341,""44"":-9.3784217834,""45"":3.9553112984,""46"":-9.0461206436,""47"":-8.8910398483,""48"":2.9528889656,""49"":3.943372488,""50"":3.1540408134,""51"":4.3994226456,""52"":2.6456193924,""53"":2.8395068645,""54"":3.095341444,""55"":2.7082254887,""56"":-8.8714408875,""57"":2.806592226},""y2D"":{""0"":2.9349119663,""1"":2.9861972332,""2"":2.5037140846,""3"":2.4127411842,""4"":0.610933125,""5"":0.7715921402,""6"":-0.1415003985,""7"":2.6094069481,""8"":2.3056323528,""9"":0.7816765308,""10"":1.5078907013,""11"":3.1867558956,""12"":3.6590096951,""13"":0.2173985243,""14"":3.5351173878,""15"":3.4606106281,""16"":3.3925762177,""17"":3.6565241814,""18"":0.0372241214,""19"":3.270513773,""20"":2.8140816689,""21"":2.9446985722,""22"":1.2696888447,""23"":2.5165519714,""24"":3.4666335583,""25"":0.0692022592,""26"":0.0577047579,""27"":3.6509633064,""28"":0.2069220692,""29"":0.3435247242,""30"":1.5648601055,""31"":0.7560870051,""32"":2.6235542297,""33"":2.9989953041,""34"":3.2452018261,""35"":3.9290783405,""36"":-0.1622086763,""37"":0.6355237365,""38"":-0.0737067536,""39"":2.9939239025,""40"":0.4456706345,""41"":0.0680386052,""42"":2.9574635029,""43"":3.791084528,""44"":3.4179503918,""45"":0.2236226201,""46"":3.2379956245,""47"":2.980530262,""48"":3.9930260181,""49"":1.0791488886,""50"":0.3417475224,""51"":0.2793027759,""52"":3.3479278088,""53"":3.6501102448,""54"":1.1152501106,""55"":3.2391805649,""56"":3.0555136204,""57"":3.953701973}}",False,False,False,http://arxiv.org/abs/1110.6200,,TopicViz: Semantic Navigation of Document Collections,SGYL3UXY,False,False
PRCPUX25,7JQEDWA7,"Observation-Level Interaction with Statistical Models for Visual Analytics 

Alex Endert+      Chao Han*      Dipayan Maiti *     Leanna House*      Scotland Leman*      Chris North+ 

+ Department of Computer Science  

* Department of Statistics 

Virginia Tech 

 

 

ABSTRACT 

specifically  designed  for  visualizations  of  this  purpose.  Thus, 
many  visual  analytic  systems  are  fundamentally  based  on 
interaction  with  statistical  models  and  algorithms,  using 
visualization as the medium for the communication (i.e. where the 
interaction occurs). This communication is performed via direct 
interaction  with  the  parameters  of  the  model.  For  example, 
Interactive  Principal  Component  Analysis,  iPCA [3],  allows  the 
user to change the weight for each dimension in calculating the 
direction  of  projection  using  multiple  sliders  (one  slider  per 
dimension). Also, in an interactive visualization using MDS [4], 
the  user  can  weight  the  dissimilarities  in  the  calculation  of  the 
stress function through similar visual controls.  
In both instances, the model is made aware of the user input 
through  a  formal  and  direct  modification  of  a  parameter  (i.e. 
parameter  level  interaction).  The  drawback  of  this  type  of 
interaction  is  that  users  are  expected  to  be  experts  in  the 
underlying  model  that  generates  the  visualization.  Moreover,  as 
datasets continue to increase in size and dimensionality, directly 
adjusting dimensions or parameters creates an issue of scalability. 
Both interactive MDS [4] and object-centered MDS [5] also allow 
interactions such as “anchoring” points to provide the algorithm 
with user specified starting positions, either to test the sensitivity 
of the current visualization or to obtain an alternate spatial layout 
based  on  the  anchored  observations.  In  both  cases,  the  visual 
analytic system does not leverage the observation level interaction 
to obtain information about the parameters of the model. 
In  this  paper,  we  reevaluate  interaction  with  such  models, 
moving  away  from  parameter  level  interactions,  and  propose  to 
focus on interacting with data (i.e. observation level interaction). 
In contrast to parameter level interactions, users are familiar and 
comfortable  interacting  directly  with  the  data  in  a  spatial 
visualization, freely organizing and relocating observations as an 
integral  part  of  their  sensemaking  process  [6].  Thus,  it  is 
necessary for us to design models that are more tightly integrated 
with interaction at the observation level, rather than through visual 
controls of parameters. 
Our  framework  shields  users  from  the  technicalities  of  the 
model  and  allows  them  to  interact  freely  with  the  data  in  the 
visual  space. The  typical  steps  in  a  discovery  process  based  on 
such a framework will be as follows: 1) the visual analytic system 
provides  a  visualization  based  on  initial  values  of  model 
parameters,  2)  users 
inject 
understanding  and  semantic  reasoning  of  the  data,  3)  under  a 
certain  predefined  mapping  of 
the  user's  observation-level 
interaction to analytic reasoning, the parameters of the model are 
tuned  or  re-weighted  to  reflect  the  user's  understanding  of  the 
data,  and  finally  4) 
the  system  regenerates  an  updated 
visualization  based  on  the  new  parameter  values  of  the  model. 
The  process  continues  iteratively,  as  does  sensemaking,  for  the 
duration of the analytic process.  
We  show  examples  that  such  a  framework  can  be  applied  to 
dimension  reduction  algorithms  for  visual  analysis  of  high-
dimensional data. Our framework of incorporating user interaction 
can be applied to either deterministic or probabilistic methods. We 
demonstrate  this  on:  PPCA  (a  probabilistic  projection-based 

interact  with  observations 

to 

is 

facilitated 

In  visual  analytics,  sensemaking 

through 
interactive  visual  exploration  of  data.  Throughout  this  dynamic 
process, users combine their domain knowledge with the dataset 
to  create  insight.  Therefore,  visual  analytic  tools  exist  that  aid 
sensemaking  by  providing  various  interaction  techniques  that 
focus  on  allowing  users  to  change  the  visual  representation 
through adjusting parameters of the underlying statistical model. 
However,  we  postulate  that  the  process  of  sensemaking  is  not 
focused on a series of parameter adjustments, but instead, a series 
of perceived connections and patterns within the data.  Thus, how 
can models for visual analytic tools be designed, so that users can 
express  their  reasoning  on  observations  (the  data),  instead  of 
directly  on  the  model  or  tunable  parameters?  Observation  level 
(and  thus  “observation”)  in  this  paper  refers  to  the  data  points 
within  a  visualization.  In  this  paper,  we  explore  two  possible 
observation-level interactions, namely exploratory and expressive, 
within  the  context  of  three  statistical  methods,  Probabilistic 
Principal Component Analysis (PPCA), Multidimensional Scaling 
(MDS),  and  Generative  Topographic  Mapping  (GTM).  We 
discuss  the  importance  of  these  two  types  of  observation  level 
interactions, in terms of how they occur within the sensemaking 
process.  Further,  we  present  use  cases  for  GTM,  MDS,  and 
PPCA,  illustrating  how  observation  level  interaction  can  be 
incorporated into visual analytic tools. 
 
KEYWORDS:  observation-level 
statistical models. 
 
INDEX TERMS: H.5.0 [Human-Computer Interaction] 
1 

interaction,  visual  analytics, 

INTRODUCTION 
Visual  analytics 

is  “the  science  of  analytical  reasoning 
facilitated by interactive visual interfaces” [1]. The goal of visual 
analytics  (VA)  is  to  extract  information,  perform  exploratory 
analyses,  and  validate  hypotheses 
interactive 
exploration  process  known  as  sensemaking 
this 
sensemaking loop, users proceed through a complex combination 
of proposing and evaluating hypotheses and schemas about their 
data, with the ultimate goal of gaining insight (i.e. “making sense 
of”  the  data).  A  wide  variety  of  statistical  models  have  been 

through  an 

[2]. 

In 

{aendert, chaohan, dipayanm, lhouse, leman, north}@vt.edu 
 Blacksburg, VA 24061 

model),  MDS  (a  deterministic  stress  minimization  model),  and 
GTM  (a  probabilistic  manifold  learning  model).  However,  the 
fundamental framework can be applied to numerous other models. 
Finally,  we  discuss  the  tradeoffs  between  these  models  for 
observation-level interaction. 
2 

RELATED WORK 

these  algorithms. 

The three methods in this paper were chosen either because of 
their  wide  usage  or  flexibility  in  modelling  non-linear  data.  A 
large and growing body of literature has shown their successful 
applications in visualization. For example, PCA has gained a lot 
of  success  in  the  area  of  image  classification,  with  applications 
such  as  face  recognition  [7-10].  MDS  has  been  used  in  graph 
layout for network visualization [11-13] due to its rich distance 
information.  GTM  is  good  at  visualizing  unstructured  data  like 
newsgroup  text  collections,  web  navigation  datasets  [14],  and 
datasets  which  have  complicated  structure,  for  instance,  protein 
sequences [15] and the standard Swiss-Roll dataset [16].   
Research  has  gone  into  creating  systems  that  allow  for 
interaction  with 
iPCA  [3]  allows  direct 
interaction with the parameters of PCA, through the use of visual 
controls.  In  adjusting  these  parameters,  users  can  observe  the 
corresponding change in the visualization. Buja et al. demonstrate 
an  interactive  version  of  MDS  in  which  users  can  define  static 
locations of a number of observations, and the algorithm positions 
the remaining observations into the layout [4]. We would consider 
this an example of an observation-level interaction, as users can 
“test” the location of specific observations, and see how the layout 
(and  thus  the  algorithm)  responds.  However,  the  interaction  is 
directly on pairwise dissimilarities, instead of updating of global 
dimension  weights  based  on  the  user’s  positioning  of  the 
observations. 
interactive  MDS 
algorithm  using  “object-centric  interaction”,  where  users  can 
explore  alternative  positions  of  observations  by  moving  them 
within  the  spatialization  [5].  This  is  similar  to  our  concept  of 
observation-level interaction, in that the interaction is occurring in 
the spatialization. However, the movement of an observation is to 
discover the proportional error contribution, and not to adjust the 
parameters  of  MDS.  Another  example  of  interacting  directly  in 
the spatialization is “Dust & Magnet”, an interactive visualization 
allowing users to understand large, multivariate datasets [17]. It is 
based on the metaphor of magnets, which can attract observations 
that share the attributes of the magnet. Thus, in placing multiple 
magnets into specific locations in the space, users can gain insight 
into  the  structure  of  the  data  through  seeing  how  observations 
respond to the attractors. Therefore, the interaction is performed 
on attractors (i.e., parameters), not on the observations. 
From  this  work,  we  learn  that  statistical  methods  are  widely 
used in visual analytics, and approaches to making these methods 
interactive  have  been  proposed.  However,  interactivity  in  these 
cases mainly refers to direct manipulation of model parameters. 
With observation-level interaction, we focus on interacting with 
the  observations  within  the  spatial  metaphor,  and  handle  the 
corresponding parameter updates through our methods. 
3 

Similarly,  Broekens  et  al.  describe  an 

OBSERVATION-LEVEL INTERACTION 

In  general,  observation-level  interaction  refers  to  interactions, 
occurring  within  a  spatialization,  that  enable  users  to  interact 
directly  with  data  points  (i.e.,  observations).  A  spatialization  in 
this  context  refers  to  a  two-dimensional  layout  calculated  from 
high-dimensional  data  where  the  metaphor  of  relative  spatial 
proximity represents similarity between documents. That is, data 
points placed closer together are more similar. Observation-level 

in 

interaction 

interaction  may  exhibit 

the  algorithm  computes  similarity.  Thus,  when 

interactions  are  therefore  tightly  coupled  with  the  underlying 
mathematical  models  creating  the  layout,  thus  allowing  the 
models to update parameters based on the interaction occurring. 
While  numerous  forms  of 
these 
characteristics  (e.g.,  moving  clusters  of  documents,  marking 
regions of interest within the spatialization, etc.), in this paper we 
will  focus  on  one  –  movement  of  observations.  From  previous 
studies, we found that movement of observations (in those cases 
documents) closer together is one way for the user to externalize 
the  analytical  reasoning  that  those  documents  are  somehow 
similar [6]. In this study, the spatial rearrangement of documents 
was  an  integral  part  of  each  intelligence  analysts’  sensemaking 
process.  Further,  this  study  points  out  that  users  perform 
observation-level 
two  ways,  exploratory  or 
expressive, based on the particular analytical reasoning associated 
with the interaction, and also how the system responds.  
During an exploratory interaction, users utilize the algorithm to 
explore the data and the space. For example, through dragging one 
observation within the layout, users gain insight into the structure 
of  the  data  by  observing  how  other  data  reacts  given  the 
algorithm. While an observation is dragged through the layout, the 
algorithm  adjusts  the  layout  of  the  remaining  data  according  to 
how 
the 
observation  is  dragged  towards  a  cluster  of  data,  similar  data 
points attract, while dissimilar ones repel. Additional information 
such  as  a  list  of  similar  and  dissimilar  parameters  can  also  be 
displayed.  Through  this  process,  users  learn  about  a  single 
observation,  and  how  it  relates  to  the  other  observations  in  the 
dataset.  
An expressive interaction is different, in that it allows users to 
“tell” the model that the criteria (i.e. the parameters, weights) used 
for  calculating  the  similarity  need  to  be  adjusted  globally.  For 
example,  as  a  user  reads  two  documents,  she  denotes  they  are 
similar by dragging them close together. If this were exploratory, 
the two documents would repel again. However, in an expressive 
form of this interaction, it is the responsibility of the underlying 
mathematical  model  to  calculate  and  determine  why  these 
documents  are  similar,  and  update  the  model  generating  the 
spatial layout accordingly. Using the methods below, we illustrate 
how both expressive and exploratory forms of observation-level 
interaction  are  enabled  through  modifications  made  to  three 
common statistical methods (PPCA, MDS, and GTM).  
4  METHODS INTEGRATING OBSERVATION-LEVEL INTERACTION 
A probabilistic model assumes a sampling distribution for the 
observed data and an uncertainty over the model parameters (e.g. 
PPCA and GTM discussed in Section 4.1 and 4.3 respectively). A 
deterministic method makes no such assumptions about the data 
or the parameters (e.g. Weighted MDS, discussed in Section 4.2). 
House  et  al.  describe  in  detail  the  underpinnings  of  the 
probabilistic framework, termed as “Bayesian Visual Analytics” 
(BaVA) [18]. The BaVA process begins with an initial display of 
the data. In turn the user may assess the display and decide if it 
matches her mental model of the data. If it does not, the user may 
convey  her  cognitive  feedback  f(c)  by  adjusting  the  locations  of 
two  observations  to  convey  her  mental  model  about  the  two 
observations.  The  user  might  also  explore  an  alternative  spatial 
location  of  an  observation  and  see  how  the  other  observation 
responds  to  such  an  interaction.  In  short,  iterations  of  user 
interaction  and  subsequent  regeneration  of  the  visualization  are 
modelled  as  sequential  updating  of  maximum  a  posteriori 
estimates  of  parameters.  The  deterministic  version  of 
the 
framework, termed as “Visual to Parametric Interaction” (V2PI), 
also  starts  with  an  initial  display  and  upon  obtaining  a  user 
feedback  sequentially  updates  the  parameters,  but  the  updated 

values  of  the  parameters  are  such  that  they  minimize  some 
measure of discrepancy between the expected configuration of the 
data under the user’s reasoning and the original data [19].  
For each of the models discussed in this paper, we present an 
overview of the model, describe the modifications made to allow 
observation-level interaction, and show a use case demonstrating 
how an end-user can interact with each model. Given that each of 
these models is designed for different types of data (varying  in 
structure,  size,  and  nature  of  the  data),  the  example  use  cases 
below each use different datasets to match the intended use of the 
models  with  the  use  case.  The  use  cases  are  performed  in 
prototype visualizations to show a proof of concept, and we are 
actively  working  to  incorporate  these  models  into  more  fully 
featured tools.  
PPCA 
4.1 

4.1.1  Overview 

Principal  Component  Analysis  (PCA)  [20-22]  is  a  common, 
deterministic  method  used  to  summarize  data  in  a  reduced 
dimensional  form.  The  summary  is  a  projection  of  a  high-
dimensional  dataset  in  the  directions  with  the  largest  variance. 
When only two directions are chosen, PCA may produce a spatial 
representation or map of the data that is easy to visualize. One 
problem with PCA is that important structures (e.g., clusters) in 
data may not correlate with variance. Thus, PCA spatializations 
may mask information in the data that analysts may find useful.    
Probabilistic PCA [23] is, simply, a probabilistic form of PCA. 
This  means  that  PPCA  is  not  a  deterministic  algorithm,  but  a 
statistical  modeling  approach  (specifically,  a  factor  modeling 
approach) that estimates low-dimensional representations of high-
dimensional  data.  Let  d=[d1,…,dn]  represents  a  p×n  high-
dimensional  data  matrix,  where  n  represents  the  number  of 
observations, p represents the number of columns, and di (for i∈ 
{1,…,n})  represents  a  p×1  vector  for  observation  i.  Also,  let 
r=[r1,…,rn] represent a low-dimensional analogy of d, such that r 
is q×n and q<p.  For our purposes, we set q=2.  PPCA models d as 
a function of r,  

d W r
,
i
i

,

,
µσ

2

=

 
No Wr
i

(

I
µ σ
+
p

,

 

2

)

  
where, No(.,.) represents the Multivariate Normal Distribution; µ 
represents  a  p×1  mean-vector  of  d;  W  is  a  p×q  transformation 
matrix  known  as  the  factor  loadings  of  d;  Ip  is  a  p×p  identity 
matrix; and σ2 represents the variance of each dimension in d.  By 
convention,  PPCA  models  each  ri  with  a  Multivariate  Normal 
distribution centered at zero and with unit variance: ri~No(02, I2).  
In  turn,  the  conditional  posterior  distribution  for  ri  is  No(η,Σr), 
where 
 

η
=

2

W W I
W d
(
)
1
(
σµ−
ʹ′
+
−
2
r W W
Iσ
2
2
−
ʹ′
Σ=
σ
+
2

ʹ′

i

(

−

) 1

)
                               (1) 

 
A spatialization of data d that relies on PPCA plots the posterior 
expectation  η.  Similar  to  PCA,  the  coordinates  η  rely  on  the 
variability observed in d. To see this, let Σd represent the marginal 
variance of di, (Σd=V[di |W,µ,σ2]). Since Σd=W´W+I2σ2, we can 
-1W(di  -µ)  which  shows  that  the  relationship 
rewrite  η  as  η=Σd
between Σd and η is well defined.   
The  final  step  in  PPCA  is  to  estimate  the  model  parameters, 
{W, µ, σ2, Σd}. We take a Bayesian approach. We specify either 

 

 

 

reference or flat priors for each unknown (as suggested by [23] 
and use Maximum A Posteriori (MAP) estimators to assess (and 
plot)  η.  For  example,  when  we  assign  π(Σd)  ∝1,  the  posterior 
distribution for Σd  is an Inverse Wishart (IW) distribution,  

d

d

,

,

)

d

∝

1)

IW(

(
π Σ

nS p n p

− −                             (2) 
 
Where  Sd  represents  the  empirical  variance  of  d.  The  MAP 
estimate of Σd is Sd.   
4.1.2 

User Guided PPCA 

To enable analysts to guide PPCA via the data visualization, we 
take  advantage  of  the  relationship  between  Σd  and  η.  Namely, 
changes in Σd will effect η, and changes in η will effect Σd, when 
we invert Equation (1).   
After  obtaining  an  initial  PPCA  display,  the  user  adjusts  the 
locations of two observations; i.e., adjusts two columns in η. If 
the two observations are moved close to one another, the analyst 
is conveying that in her mental map, the observations are more 
similar  than  what  they  appear  in  the  display;  and,  if  the 
observations are dragged apart, the analyst is conveying that the 
observations differ more than what they appear.    
The  challenge  in  BaVA  is  to  parameterize  the  cognitive 
feedback  and  update  the  visualization  [18].  First,  we  determine 
the dimensions of the data d for which the adjusted observations 
are similar and different. Second, we transform the adjustments to 
η into a hypothetical p×p variance matrix. We denote this matrix 
by f(p), as it is a quantified version of f(c). In f(p), the dimensions for 
which the adjusted observations are similar have small variances 
and  the  dimensions  for  which  adjusted  observations  differ  have 
large variances. Third, we consider the hypothetical variance f(p) to 
be a realization of a Wishart distribution that has an expectation 
equal to Σd. Finally, we apply Bayesian sequential updating [24, 
25] to adjust Equation (2) by the parametric feedback f(p),  
 

(

π Σ=
d

d f
,

(

p

)

)

IW(
+

pS
− −
d

vf
+

(

p

)

,

p n v p
,

 

1)

where, υ is solved from a specification κ(κ ∈ [0,1]) made by the 
analyst  that  states  how  much  weight  to  place  on  the  feedback 
relative to the data. Namely, the updated MAP estimate for Σd is a 
weighted average of the empirical variance Sd and feedback f(p) 
 

MAP

(

)
Σ=
d

f

)

p
(
+

v
v n
+
 

 

S

d

n
v n
+

thus υ= nκ/(1-κ). Now, the PPCA projection of the data d that is 
based on MAP(Σd) will portray both information in the data and 
expert feedback. 
4.1.3 

Example 

A sensitive issue for taxpayers, parents, children, educators, and 
policy  makers  is  whether  an  increase  in  money  devoted  to 
education  will  increase  education  quality.  Money  provides  a 
means  to  buy  modern  textbooks,  employ  experienced  teachers, 
and provide a variety of classes and/or extra curricular activities. 
Although,  do  the  students  who  benefit  from  these  high-priced 
resources actually improve academically? 
In 1999, Dr. Deborah Guber compiled a dataset for pedagogical 
purposes  to  address  this  question  [26].  Based  on  the  following 
variables, 
the  academic  success, 
educational expenses, and other related variables in 1997 for each 
U.S. state: the average exam score on the Standard Aptitude Test 

the  dataset  summarizes 

from 

the  National  Center 

(SAT);  the  average  expenditure  per  pupil  (EXP);  the  average 
number of faculty per pupil (FAC); the average salary for teachers 
(SAL); and the percentage of students taking the SAT (PER). To 
increase  the  complexity  of  the  dataset  slightly,  we  added  two 
variables 
for  Education 
Statistics(www.http:nces.ed.gov):  the  number  of  high  school 
graduates  (HSG)  and  the  average  household  income  (INC). We 
hypothesize that states that spend more on education will cluster 
with states with high SAT averages.   
To assess the hypothesis and explore the data, we implement 
the  BaVA  process  using  PPCA.  Figure  1a),  displays  our  initial 
view of the data. Notice that the visualization does not present any 
structure in the data.  Analysts in the field of education, notice that 
two  states  with  different  expectations  for  SAT  scores  are 
displayed  close  to  one  another.  Thus,  we  select  the  appropriate 
observations and drag them apart as an expressive interaction to 
obtain an updated view that is displayed in Figure 1b). There are 
two clusters in 1b). These clusters correspond with SAT scores 
above and below the national median.  
Based  on  our  hypothesis,  we  suspect  that  the  clustering 
structure in SAT relates to EXP. However, when we re-plot 1b) 
and label the upper and lower EXP 50% quantiles in Figure 1c), 
EXP  does  not  explain  the  clusters.  Thus,  we  used  a  bi-plot  to 
identify  which  variables  explain  the  structure  we  see  in  Figure 
1b).  When  we  mark  the  observations  above  and  below  the 
empirical PER median in Figure 1d), we see that PER and SAT 
clearly  relate  to  the  formation  of  clusters  in  the  dataset.  Thus, 

(a)  Initial                            (b) SAT Scores 

 

 

              (c) EXP                                  (d) PER      

 
Figure  1.  After  injecting  expert  feedback  into  Figure  1a),  we 
obtain  Figures  b)-c).  For  frame  of  reference,  we  marked  the 
two  points  moved  to  inject  feedback  by  `x'  in  Figure  b).  The 
configuration  of  points  in  each  graph  are  identical,  but  the 
observations  are  labeled  differently.  In  Figure  b),  symbols  `●’ 
and  `○’  mark  the  upper  and  lower  50%  quantiles  for  SAT 
scores respectively; in Figure c), symbols `●’ and `○’ mark the 
upper  and  lower  50%  quantiles  for  EXP  scores  respectively; 
and in Figure d), symbols `●’ and `○’ mark the upper and lower 
50%  quantiles  for  the  percentage  of  students  taking  the  SAT 
the  clusters 
(PER) 
in  each  graph 
correspond with SAT and PER, but not EXP. 

respectively.  Notice 

further analyses of SAT and EXP must control for PER.   

 

4.2  MDS 

We  extend  our  framework  to  another  deterministic  method, 
which  forms  the  basis  for  a  large  number  of  visualization 
techniques: Multi-Dimensional Scaling (MDS).  
4.2.1  Overview 

All complex data visualizations are based on high-dimensional 
datasets, which contain features corresponding to dimensions, and 
the relative importance of such features through a set of weights 
(wi).  Classically  weighted  multidimensional  scaling  deals  with 
mapping  a  high  dimensional  dataset  d=[d1,…,dn]  into  a  low 
dimensional (in our case two-dimensional) space r, by preserving 
pairwise distances between observations in the low dimensional 
representation.  Let  w  represent  the  p-vector  of  feature  weights:  
w={w1,…,wp}. Given a set of feature weights, the low dimensional 
spatial coordinates are found by solving:  

 

where 

min
r
r i
,...,
1

n

, 

r
i

−

r δ
w
(
i j
j
,

−

)

∑

j n

<≤

)

w
(
δ
i j
,

w
k

dist(

d

ik

d

)

jk

 

p

=−∑

k

1
=

such  that  ∑k  wk=1.  dist()  represents  any  distance  function  for 
measuring  individual  features  in  the  high  dimensional  space. 
Because  it  is  not  possible  to  estimate  weights  and  the  set  r 
simultaneously,  we  provide  a  uniform  weighting  of  the  space 
wi=1/p for our first iteration. 
User Guided MDS 
4.2.2 

the  display  and 

learn  from  certain  aspects  of 

Once  a  visualization  is  generated,  the  user  may  either  agree 
with 
the 
visualization, or disagree, based on their domain expertise. Hence, 
the  user  may  wish  to  interact  and  rearrange  a  few  of  the 
observations in the visualization. Given a spatial interaction in the 
form  of  adjusting  the  relative  position  of  a  set  of  points,  we 
compute a set of feature weights, which are consistent with both, 
the  users  adjustment  and  the  underlying  mathematical  model. 
These are computed by inverting the optimization, by fixing the 
locations  of  the  adjusted  points  and  finding  an  optimal  set  of 
weights,  which  are  consistent  with  the  visualization.  Explicitly, 
we solve for w such that  

Figure  2.  Visualization  of  the  1990  census  dataset  using 
classical MDS. 
 
 

 

%  

r
( )
δ
−
i j
,

w
k

dist

d

(

i k
( )

−

r
j k
( )

)

min
w
w i
,...,
1

p

j

p

∑ ∑

l k
<≤ =

1

 
and  ∑k  wk=1,  where  d(i)k  represents  the  kth  element  in  the 
observation of d that maps to ri in the adjusted visualization and l 
is  the  total  number  of  manipulated  observations.  It  should  be 
noted  that  computing  the  new  weights  is  extremely  fast,  and  is 
then followed by a full MDS step. Thus, the entire generation of a 
new view can be performed in real time, depending on the size of 
the dataset and the specific hardware used. 
4.2.3 

Example 

inconsistencies  with 

their  mental  model 

Consider  for  example  a  visualization  produced  by  a  standard 
MDS  technique.  In  this  example  we  focus  on  the  1990  census 
dataset [27] under a Classical Metric Scaling (CMS) [28], using a 
Hamming distance (due to the categorical nature of the dataset) 
for  measuring  features  in  the  high  dimensional  space.  Figure  2 
illustrates  results  obtained  under  a  Classical  Metric  Scaling 
(CMS).  
Given  this  visualization,  a  user  may  distinguish  3-5  main 
clusters, and inquire what they mean. We see two major ways a 
user  can  interact  with  the  visualization,  in  order  to  explore  the 
space, and learn about the underlying dataset. The first of these is 
by highlighting a subset of the data, based on some question the 
user seeks to answer, and then rearranging the visualization based 
on 
(expressive 
interactions). 
The second approach is to hone in on visual structure, and move 
points  in  the  visual  space  in  order  to  learn  what  the  structure 
relates to in terms of the feature space (exploratory interactions). 
Both  of  these  interactions  are  nearly  identical,  however  the 
motivation for the interactions will differ. We will illustrate both 
types of visual reasoning through an example based on the 1990 
census dataset. 
The user may wish to interact expressively and identify points 
in the space that pertain to high and low income groups. The user 
highlights individuals with incomes below 15K and over 60K, as 
shown  by 
  in  leftmost  panel  of  Figure  3,  respectively. 
Because of the close proximity of the highlighted groups in the 
main clusters, the user drags (denoted by ⊗) a few representative 
low and high-income individuals into sets of groups in each of the 
3  main  sub-clusters.  The  system  reports  back  a  set  of  weights, 
which  explain  how  much  a  particular  feature  explains  the 
arrangement of points suggested by the user. High weights relate 
to 
their 

low  weights  suggest 

features,  while 

important 

and 

 

Figure 4. A user performing an exploratory interaction to learn 

to 

this 

information, 

the  system  updates 

    what distinguishes two clusters. 
corresponding  features  do  not  relate 
the  user's  visual 
rearrangement. For our example, we learn not only that income 
level  (29%),  but  also  by  their  means  of  transportation  to  work 
(20%), whether or not they worked the full year (25%), and their 
level of education (10%) are related to the user's repositioning of 
points.  Given 
the 
visualization, as shown in center panel of Figure 3. We notice that 
in  the  resulting  visualization,  the  income  groups  are  clearly 
separated.  The  resulting  visualization  displays  a  much  richer 
spatialization than simply showing clusters relating to the income 
groups.  For  example,  we  highlight  individuals  that  actually 
worked  in  the  right  most  panel  of  Figure  3,  and  notice  these 
individuals are shown in distinct sub-clusters. 2 of the 4 clusters in 
which  individuals  work  pertain  to  low-income  groups,  and  the 
other 2 pertain to high-income groups (as illustrated by the 
 and 
 symbols).  
Figure  4  shows  how  the  user  might  perform  an  exploratory 
interaction in order to learn what explains the clustering structure 
between the working/low income groups. To suggest the clusters 
could be moved further away from each other than they appear in 
the  current  visualization,  the  system  reports  back  the  weights, 
which explains the differences in the groups. For this example, the 
user learns that one of these clusters contains individuals that have 
a reliable mode of transportation to work (93% explained). The 
visualization could be updated based on this information, or the 
user could simply document this fact and proceed by explaining 
other areas of the spatialization. As always, there are an endless 

 
Figure 3. A sequence of visualizations derived through observation-level interaction with a modified MDS method. (Left) The user moves a 
set of points into new locations, communicating his intuition that there may be additional structure within each cluster. (Middle) The updated 
visualization showing new clusters. (Right) Highlighting showing the separation of income groups in the updated visualization. 
 

 

 

number  of  possibilities  for  learning  about  a  high  dimensional 
dataset via visual expression/exploration. Another example of an 
exploratory interaction with MDS is demonstrated by Buja et al. 
in  which  users  can  constrain  observations  to  specific  spatial 
locations [4]. 
GTM 
4.3 

4.3.1  Overview 

Introduced  by  Bishop  et  al,  [29]  Generative  Topographic 
Mapping (GTM) is a nonlinear latent variable modeling approach 
for  high-dimensional  data  clustering  and  visualization.  It  is 
considered  to  be  a  probabilistic  alternative  for  both  the  Self-
Organizing  Map  (SOM)  algorithm  [30]  and  Nonlinear  PCA. 
Similar  to  PPCA,  GTM  estimates  a  latent  variable  r=[r1,…,rn] 
(q×n  matrix)  that  is  a  low-dimensional  representation  of  high-
dimensional  data  d=[d1,…,dn]  (p×n  matrix  such  that  p>q). 
However, unlike PPCA, the q-dimensional coordinates r in GTM 
map  nonlinearly  to  a  complex  manifold  m=[m1,…,mn]  that  is 
embedded in the high-dimensional space.  This manifold, ideally, 
in  data  d  and  represents 
characterizes 
geometrically the expected value for d in the Gaussian model,   
                               (3) 

important  structure 

    

d N W r
( ),
i
i

Φ

(

I β−
1
p

)

:

 

j

2

)

=Φ

    

exp(

r
( )
Φ=−
i

µ
−
j
2
2
σ

m W r
( )
i
i
r
i

To estimate a coordinate mi, GTM takes a weighted average of J 
radial  basis  functions  {Φ1(),…,ΦJ()}  (Φj()  represents  a  radially 
symmetric Gaussian kernel) given ri and parameters there in,  
 

,                                      (4) 
,                            (5) 
 
where  W  is  a  p×J  transformation  matrix;  Φ(ri)  is  a  J×1  vector 
such that Φ(ri)=[Φ1(ri),Φ2(ri)…,ΦJ(ri)]ʹ′; and µj is a q×1vector that 
centers  the  basis  functions.  The  center  coordinates  µ=[µ1,…,µJ] 
cover the q-dimensional latent space uniformly. Model parameters 
are estimated using the EM algorithm [31]. 
One  advantage  of  GTM  is  that,  by  construction,  it  lacks 
sensitivity to outliers.  For tractability, the coordinates of each ri 
are  limited  a  priori  to  a  finite  set  g  of  K  possibilities,  ri 
∈g={g1,…,gK} 
latent  space 
uniformly.    To  decide  which  value  for  ri  generates  di,  GTM 
estimates the posterior probability, i.e., responsibility, that ri=gk. 
Given a prior probability that ri=gk is 1/K for all k ∈{1,…,K}, let 
Rik  represent  the  posterior  responsibility  that  latent  variable  ri 
generates di, when ri=gk, 
 

the  q-dimensional 

that  covers 

 ,                            (6) 

R
ik

=

d r
(
π
=Φ
i
i
K
d r
(
∑
π=
i
i
l
1

g W
,
,
k
g W
,
=Φ
l

())
,

())

 
In  turn,  GTM  plots  the  posterior  mode,  expectation,  or  any 
quantile of ri given specifications g and estimates for {Ri1,…RiK}.    
4.3.2 

User Guided GTM 

GTM  is  a  complex  modeling  approach  that  relies  on  many 
tunable parameters that are hard to interpret. User Guided GTM 
(ugGTM)  will  allow  analysts  to  both  take  advantage  of  the 
benefits  of  GTM 
complicated  GTM 
parameterization.  Specifically,  analysts  may 
tag 
clusters,  tag  regions  of  the  visualization  space,  and  query 
differences in documents.  

and  guide 

label,  i.e., 

the 

Here, we illustrate ugGTM within the context of an example. 
We have a collection of 54 abstracts from proposals funded by the 
National Institute for Health (NIH). After standard preprocessing, 
we apply a ranking system that we will call an Importance Index 
(ImpI),  which  is  based  on  the  Gini  coefficient.  ImpI  considers 
both the frequency and uniqueness of words that are shared across 
documents and assigns a metric between 0 and 1.  Entities that 
occur  equally  frequently  in  all  the  documents  have  ImpI=0  and 
entities that occur in only one document has ImpI=1.  We selected 
the 1000 entities with the highest ImpI. One advantage of ImpI is 
that we can measure document similarity using Euclidean distance 
between  proposals.  Pairs  of  documents  with  small  Euclidean 
distances have comparable terms with similar frequency; and pairs 
of  documents  with  large  Euclidean  distances  have  few,  if  any, 
words in common. 
We apply GTM for J=16 and K=400 to obtain an initial display 
of the proposals, shown in Figure 5. Notice four clusters appear in 
Figure 5 that we labeled A, B, C, and D.   
Tagging  the  Clusters  and  the  Space.  To  understand  the 
meaning of the clusters, we determine the words that both overlap 
the  least  within  each  cluster  and  have  the  highest  ImpI’s.  
Specifically, we apply k-means [32] to the low-dimensional data 
coordinates to determine cluster memberships.  For each cluster 
we  sum  the  ImpI  vectors  across  the  documents  and  rank  the 
entities based on the ImpI sum. Entities ranked highest are those 
that 1) have importance in the corpus (as determined by the ImpI) 
and 2) have occurred most frequently.  Given top rankings from 
each cluster, we delete those shared by all four clusters. Table 1 
lists  the  unique  key  words  that  describe  each  cluster.  Group  A 
represents proposals that include brain related cancer studies and 
their clinical applications. Group B represents proposals related to 
human neural systems. Group C represents proposals that address 
genomic  and  transcriptomic  research  problems. 
  Group  D 
represents  proposals  about 
such  as 
infectious  diseases, 
tuberculosis, and immunity.  

 
Table 1. Cluster tags (top 10 keywords) for NIH abstract groups. 
 

    
As  described  previously  in  Equation  (3),  GTM  characterizes 
high-dimensional  data  as  random  perturbations  from  a  complex 
manifold m; E[di] = mi for all i ∈ [1,…,n]. To tag the visualization 
space, we select any spot, r+, in the visualization and use Equation 
(4) to estimate its corresponding location on the manifold, m+. The 
estimate m+ will be a 1000×1 vector of ImpI’s that we may use to 
rank  the  entities.  We  report  the  top  ranked  entities  to  tag  the 
space. For example, in Figure 5, we pick up a spot r+ (represented 

Group A 

Group B 

Group C 

Group D 

Shared by All 

Groups 

tumors, brains, stem, treatments, patients, 
generations, drugs, ordering, controlling, 
therapeutics 
stem, neuronal, brains, proteins, deliveries, 
regulations, neural, patients, differentiation, 
expression, treatments 
stem, genetically, regulations, drugs, 
structurally, proteins, genomics, epigenetics, 
RNAs, complexities 
Infections, treatments, tuberculosis, 
expression, patients, drugs, strains, 
resistance, vaccination, immunity 
cells, functionalization, diseases, 
developments, genes, cancerous , studying, 
researchers, proposing, mechanisms, 
specification 

by a pink circle) that locates roughly at the center of cluster D.  
Several  of  the  tagged  top  keywords  overlap  with  the  words 
describing cluster D. 
    
Document-Based  Query  and  Cluster  Reorganization.  It  is 
common for users to assess documents by searching for keywords. 
However,  keyword  searching  may  be  a  tedious  task  and  fail  to 
reveal  document  clusters  of  interest.  For  example,  keyword 
searches may identify documents with similar keywords, but used 
in different contexts; miss documents that contain combinations of 
the  keywords;  or  prioritize  words  that  have  little  relative 
importance for the user.  In response to the challenges of keyword 
searching,  many  analysts  rely  on  document  matching.  For 
document  matching,  entire  documents  can  be  used  to  identify 
which of the remaining documents in the corpus are most similar 
(to the chosen document). Hence such a matching algorithm is a 
document-based query of a corpus. 
In our ugGTM, users may query documents in the corpus by 
dragging a document of interest directly in the visualization and 
watching  how  the  remaining  documents  respond;  e.g.,  similar 
documents will follow the document being dragged and dissimilar 
documents will repel. The behaviour of the documents is similar 
in spirit to Dust and Magnets (DnM) [17]. In DnM, analysts may 
drag or shake magnets that represent variables in the dataset and 
watch  as  relevant  documents  follow  the  magnets.  However,  a 
major  difference  between  DnM  and  ugGTM  is  that  when  users 
drag  documents  (not  variables)  and  watch  how  the  remaining 
react, they are comparing documents based on all of the variables 
in  the  dataset  simultaneously.  In  turn,  users  may  learn  which 
variables are important for comparisons, based on tags within the 
visualization space. 
The interaction is possible because ugGTM gives control to the 
users of some parameters in the model via the visualization.  Let 
r* represent the low-dimensional coordinates for a document that 
an  analyst  has  chosen  to  drag.  Given  r*,  we  add  to  the  model 
described in Equations (3)-(6) by expanding sets g and Φ so that 
g={g1,…,  gK,  g*}  and  Φ={Φ1,…,ΦJ,Φ*},  where  Φ*  =  exp{-||ri-
µ*||2/2σ2}  and  g*=µ*=r*.  In 
the  posterior 
responsibility (Equation 6) that r* generates d* via m* to 1 (where, 
m* is defined by Equation (4) so that the mapping between the 
low-  and  high-  dimensional  coordinates 
the  moving 
observations is deterministic. 
To  propagate  the  effect  of  moving  r*  to  the  remaining 
visualization,  we  take  a  local  regression  approach  [33]  to 
characterize high-dimensional data di |{ ri=g*,m*} in that we scale 
di-m* by the square-root of function V given scaled distance Δi = 
||d*-di||/c so that,  

turn,  we  assign 

for 

(
π

d r
=Φ=
i
i

g W
*

,

,
−

)

⎛
⎜
⎝

β
2
π

⎞
⎟
⎠

exp{

V
β

)

i

(
Δ
2

d m
i

*

 
}

2

p
/2
−
−
 

 

 

2 and c=0.5. In turn, both 
where c is user-defined; e.g., V(Δi)=Δi
posterior responsibility estimates (Equation 6) and estimates for m 
(Equation 4) change.  Let mi
(c) and mi
(u) represent the current and 
user-adjusted manifold estimates for observation i.  We define the 
BaVA-GTM estimate for the manifold, mi
 

(c+1), by 

 

m
(
i

c

1)
+ =

δ
i

m
c
( )
+−
i

(1

δ
i

)

m
u
( )
i

, 

where δi=||ri-r*||/b and b=max{||r1-r*||,…,||rn-r*||} so that δi∈ [0,1].  
(c+1) controls the visualization so that only the 
This definition for mi

regions  of  interest  respond  to  user  interactions;  areas  that  are 
distant from the dragged observations do not change.   
Parameters g*, Φ*, V(Δi), δ  and m(c+1) in ugGTM work together 
in the following way. When a data point di is far from d*, V(Δi) 
will  be  large  and  thus  decrease  the  posterior    responsibility 
(Equation 6) that ri=g* generates di. Similarly, when di is near d*, 
the  corresponding  responsibility  will  increase.  Increases  in  the 
responsibility  for  ri=g*  will  cause  the  coordinates  for  ri  to 
gravitate toward r*. Thus, analysts may specify constant c in our 
definition Δi, depending upon how many document matches they 
seek  for  the  moving  document.  Also,  the  degree  to  which  the 
observations  gravitate  toward  r*  is  determined  by  δ  and  m(c+1). 
When the manifold shifts from m(c) to m(c+1), the meaning of the 
visualization space changes, as we demonstrate in our example.  
4.3.3 

Example 

For our NIH example, we apply ugGTM. We display an initial 
GTM view of the documents (the 54×1000 dataset) in Figure 5. 
Suppose a user identifies a specific document of interest, e.g., Doc 
7 (highlighted in yellow in Figure 5) to investigate. A preliminary 
investigation might involve a sequence of non-spatial interactions, 
such as, searching of multiple keywords, reading all or part of the 
document  etc.  However,  a  comprehensive  assessment  of  the 
document may require spatial interactions as well. The user might 
explore  space  tags  across  the  screen  and  determine  a  more 
appropriate location for the document of interest. In this case, Doc 
7 is closer to Group A, and is about developing new brain tumor 
therapies  and  tumor  stem  cell  quiescence.  The  keywords  this 
document shares with group A include tumors, brains, cancerous, 
therapeutics and chemotherapy. However, since Doc 7 relates to 
therapy developments for disease, it shares some keywords with 
Group  D;  e.g.,  treatments,  strategies,  patients,  drugs,  resistance, 
clinically.   
As an exploratory spatial interaction, the user drags Doc 7 to 
the  lower  left  corner  of  the  display  and  watches  how  the 
remaining  documents  react.  By  repositioning  Doc  7,  the  user 
redefines the spatialization of the screen, i.e., modifies the space 
tag  corresponding  to  a  location.  For  example,  when  we  tag  the 
same  coordinates  r+  in  Figure  6  (r+  are  the  coordinates  of  the 
space tagged in Figure 5), we learn that the top keywords include 
treatments  and  tumors  as  well  as  those  that  were  there  earlier. 
Recall that ugGTM uses every variable in the dataset to compare 
documents.  For  this  reason,  documents  that  mention  stem  cells 
and  other  important  keywords  in  Doc  7  follow  Doc  7.  As 
expected, many documents in Group D gravitate toward Doc 7. 
However,  a  few  documents  in  Group  B  also  followed.  Future 
work will allow users to weight the keywords in Doc 7, if desired. 
Also  Documents  with  ID  20,  22,  32  and  39  change  locations. 
Important  keywords  for  these  documents  include  the  following: 
Doc 20 discusses diagnosis of HIV infection in patients who live 
with  limited  access  to  therapeutic  treatments;  Doc  22  discusses 
expression characteristics of a drug-resistant gene; Docs 32 relates 
to  varying  yeast  strains;  and  Doc  39  relates  to  Lymphocyte 
Homing.  Docs  20  and  22  repelled  against  Doc  7  because  the 
redefined-manifold down-weighted their important entities in the 
lower left corner and up-weighted the entity tumor. Thus, Doc 20 
and Doc 22 shifted to Groups A and C respectively. Docs 32 and 
39  are  separated  slightly  from  Group  D  and  gravitated  toward 
Group C because they have a few words in common with each 
group, but not enough to place them in either corner. 
An interesting note about the updated manifold is the change in 
shape or magnification factor [34]. The colour in the background 
is  plotted  based  on  the  logarithm  of  the  magnification  factor 

Figure  5.  GTM  display  of  the  NIH  abstracts.  Black  dots  mark 
documents and labeled by their document ID. 
 
evaluated on a fine grid that covers the visualization space. Due to 
the  nonlinear  mapping  from  ri  to  mi,  equal  distances  in  the 
visualization do not necessarily imply equal distances in the high-
dimensional space. The magnification factor describes the rate of 
change  between  distance  or  area  in  the  latent  space  and  the 
corresponding  distance  or  area  on  the  manifold  and  can  be 
interpreted  as  a  description  of  how  wiggly  the  manifold  is. 
Overall,  the  magnification  factor  is  lower  in  Figure  6  than  in 
Figure 5 and the clusters formed in Figure 6 are mainly in low 
magnification  areas.  This  means  the  clusters  in  Figure  6  are  in 
flat, stable regions of the estimated manifold. Thus, observations 
in these clusters are closer to one another than observations shown 
in clusters within Figure 5. 
5 

DISCUSSION 

We present a comparison of key characteristics of the methods 
used in this paper in Table 2. Again, the purpose of this work is 
not to make a direct comparison of these three methods, but rather 
to  present  how  to  apply  observation-level  interaction  to  each 
method, and summarise our findings in the table.  
Mappings. The three methods discussed in the paper provide 
us  with  a  spatialization  of  the  data  within  the  bounds  of  their 

 

 

 

Figure 6. The updated view after moving doc 7 from top left to 
bottom left. 
algorithmic  complexity.  Points  that  are  close  in  the  higher 
dimensional space remain close to each other in the visualization 
in  all  the  algorithms  although  the  concept  of  proximity  varies 
depending on the algorithm. As an artifact of the algorithms, in 
both PPCA and MDS, the high dimensional data is assumed to be 
a linear mapping of the visualized representation while GTM is a 
non-linear mapping of the same. Hence, the same dataset might 
provide  widely  disparate  visualizations  for  different  algorithms. 
Spatially  this  might  translate  to  the  fact  that  based  on  the 
algorithm, the user’s spatial interaction might target different sets 
of observations. Each algorithm can potentially have its own set 
of diagnostics overlaid with the visualization that might aid the 
user  in  understanding  the  proximity  of  the  data  in  the  higher 
dimensions;  e.g.  visualizing  the  magnification  factor  along  with 
the data in GTM indicates the level of distortion. The goal of the 
user is to obtain a view in multiple steps that matches with his 
mental model irrespective of the algorithm used to visualize the 
data.  The  specific  steps  that  the  user  goes  through  should  be 
immaterial in so far as the final visualization is concerned and all 
the algorithms discussed here have the flexibility to provide that.  
PPCA relies on the assumption that a single linear projection 
exists  that  can  reveal  useful  structure.  MDS  provides  a  two- 
dimensional representation of the observations via penalization of 
any  distance  distortion  that  happens  in  the  two-dimensional 

Table 2. Comparison of the methods used in this paper.  

  
Mapping Type 
Method Characterisation  
Distribution Assumption 
Scalability (Observations) 
Scalability (Dimensions) 
Conceptual Clarity 
Running Time 
Outlier Robustness 

PPCA 
Linear 
Variance 
Probabilistic 

(cid:174)(cid:174)(cid:174)(cid:1)

(cid:174)(cid:1)

(cid:174)(cid:174)(cid:174)(cid:1)

(cid:174)(cid:174)(cid:1)

(cid:174)(cid:174)(cid:1)

(cid:174)(cid:174)(cid:174) = Good(cid:1) (cid:174)(cid:174) = Average(cid:1)

MDS 
Linear 
Similarity 
Deterministic 

(cid:174)(cid:1)

(cid:174)(cid:174)(cid:174)(cid:1)

(cid:174)(cid:174)(cid:174)(cid:1)

(cid:174)(cid:174)(cid:174)(cid:1)

(cid:174)(cid:174)(cid:1)

(cid:174) = Poor 

GTM 

Non-linear 
Manifold 
Probabilistic 

(cid:174)(cid:1)

(cid:174)(cid:174)(cid:1)

(cid:174)(cid:1)

(cid:174)(cid:1)

(cid:174)(cid:174)(cid:174)(cid:1)

representation  using  a  stress  function.  However,  the  linear 
projection assumption may not hold for complex datasets or, the 
visualization based on minimizing stress in MDS might not reveal 
all the information in the data. In PPCA, using variance to select 
the  direction  in  which  to  project  data  makes  sense  for  datasets 
with a global linear structure [23]; the projection will minimize 
the number of observations that overlap so that they are as visible 
as possible.  
However,  variance  estimates  and  hence  PPCA  visualizations 
are  sensitive  to  outliers  and  it  is  not  uncommon  for  PPCA  to 
display one or two outliers and a cloud of occluded points. Under 
Euclidean  distance,  MDS  is  algorithmically  the  same  as  PPCA 
and  will  suffer  from  the  same  sensitivity  to  outliers.  Assessing 
such  a  visualization  and  making  appropriate  adjustments  would 
be,  at  best,  challenging.  Thus,  a  more  complex  methodology  is 
often needed to summarize datasets, e.g., mixture PPCA or GTM. 
GTM being a topographic mapping places the outliers at one end 
of the screen or at a position that is distant from the region that 
has more structure. In our interactive framework, outliers can be 
brought closer to existing user defined clusters through redefining 
the principal components in PPCA, reweighting of the dimensions 
in MDS and constraining responsibilities in GTM; in all the cases 
the  user’s  observation-level  interaction  initiates  the  parameter 
update. 
Scalability. In terms of time complexity, GTM is O(KND) (K 
number  of  latent  points,  N  number  of  observations,  D  data 
dimensionality),  PPCA  is  O(qND)  (q  is  the  dimension  of  the 
latent space, usually equals 2) and MDS varies from O(qND) to 
O(N3).  The  effect  of  high  dimensionality  (i.e.  the  number  of 
columns for every observation) on the run-time will be similar for 
all three algorithms. The challenge in scalability (large N) is also 
of  the  same  order  for  the  three  algorithms  when  Euclidean 
distance is used.  
However  in  the  design  of  a  visual  analytic  system  that 
incorporates user interaction in the framework, the choice of the 
algorithm  should  be  based  not  only  on  the  run-time  of  the 
algorithm  but  also  on  the  cost  incurred  in  converting  the 
observation-level interaction or feedback to updated values of the 
parameters for the method.  In PPCA, it is the cost of evaluating 
the feedback matrix f(p); in MDS it is the cost of obtaining optimal 
feature weights w based on pair-wise distances of the observations 
that the user has moved; and in GTM, it is the cost of computing 
distances between data points and reference vectors. Under such 
considerations, we think MDS provides the quickest and easiest 
two-dimensional visualization of the data, followed by PPCA and 
GTM.  
We  maintain  a  probabilistic  framework  in  PPCA  and  GTM. 
Specifically  for  PPCA,  computation  is  quick  since  the  primary 
parameter  of  interest  Σd  has  a  posterior  distribution  and  a 
conjugate feedback distribution, and MAP(Σd) can be computed 
without MCMC.  Thus, analysts can explore the data in real time.  
GTM (although being most flexible in handling more complicated 
data occlusion issues that challenge MDS or PPCA) is based on 
an expectation-maximization algorithm and hence needs more run 
time to converge to the optimal parameter value. 
Sensitivity. The methods described in this paper will respond 
based on the interaction performed (i.e., number of observations 
moved, distance the observations were moved, etc.). For example, 
moving a single observation will generally result in a less drastic 
change in the layout compared to a similar interaction performed 
on a cluster of observations. Thus, the sensitivity of the models in 
terms of responding to the user’s intuition is dependent on how 
large the change or update is provided by the user’s interaction, 

the size of the dataset, as well as if the data supports the suggested 
updated  layout.  The  methods  will  attempt  to  find  the  “best  fit” 
given the user feedback, but will maintain mathematical validity 
(i.e., users cannot force the layout if the data does not support it). 
The  result  is  such  that  the  system  balances  the  user’s  intuition 
with  the  structure of  the  data  to  reduce  bias.  The  goal  of  these 
techniques is not to converge on a single structure or layout, but 
rather to allow exploration of many possible structures. 
Interaction. The examples of how observation-level interaction 
can occur within spatializations in this paper show only one form 
of interaction available to users within spatializations – movement 
of individual observations. The methods are expandable to allow 
more  complex 
interactions,  such  as  moving  clusters  of 
observations, annotating a region of the spatialization, and other 
interactions used for communicating the intuition of the user to 
the system. In a fully implemented visual analytics system, these 
interactions  may 
include  queries,  highlighting,  and  other 
interactions  from  which  analytical  reasoning  of  users  can  be 
interpreted.  
Implementation.  The  prototype  visualizations  shown  in  this 
paper are intended to provide working examples of the modified 
methods. Through the use cases, we highlighted how an end-user 
might  interact  with  such  systems.  We  plan  to  integrate  these 
methods  into  more  fully  functional  visual  analytics  tools.  That 
will allow us to perform a series of user studies to evaluate the 
usability  and  effectiveness  of  observation-level  interaction  in 
terms  of  providing 
the 
sensemaking process.  
6 

to  users,  and  supporting 

insight 

CONCLUSION 

In  this  paper,  we  described  how  modifications  of  powerful 
statistical methods allow user interaction at the observation-level. 
By  interacting  within  the  visualization  through  movement  of 
observations, users are able to perform exploratory and expressive 
interactions. Thus, users are able to perform sensemaking tasks, 
such as hypothesis validation, directly within the spatial metaphor. 
By keeping the interaction at the observation level, users are not 
required  to  transform  their  sensemaking  into  a  combination  of 
statistical parameter updates.  
In particular, we modified PPCA, MDS, and GTM using BaVA 
[18] and V2PI [19] approaches, so that users can focus on their 
spatial  analysis  of  data  rather  than  directly  updating  statistical 
parameters of models. We present three examples (one for each 
modified  method)  that  illustrate  the  effectiveness  of  these  new 
models. Based on the positive results in this paper, as well as the 
lessons  learned,  coupling  interaction  with  statistical  models 
provides  an  opportunity  to  explore  additional  forms  of  spatial 
interaction for visual analytic applications. 
ACKNOWLEDGEMENTS 
This research was funded by the National Science Foundation, 
Computer and Communications Foundations, grant #0937071. 
REFERENCES 
[1]  Thomas,  J.  J.,  Cook,  K.  A.,  National,  V.  and  Analytics,  C. 
Illuminating the path. IEEE Computer Society, 2005. 
[2] Pirolli, P. and Card, S. Sensemaking Processes of Intelligence 
Analysts  and  Possible  Leverage  Points  as  Identified  Though 
Cognitive  Task  Analysis  Proceedings  of  the  2005  International 
Conference on Intelligence Analysis, McLean, Virginia, 2005. 
[3] Jeong, D. H., Ziemkiewicz, C., Fisher, B., Ribarsky, W. and 
Chang,  R.  iPCA:  An  Interactive  System  for  PCA-based  Visual 
Analytics. Computer Graphics Forum, 28, 2009. 

[24]  Spiegelhalter,  D.  and  Lauritzen,  S.  Sequential  updating  of 
conditional  probabilities  on  directed  graphical 
structures. 
Networks, 20, 1990, 275-605. 
[25]  West,  M.  and  Harrison,  J.  Bayesian  Forecasting  and 
Dynamic Models (Springer Series in Statistics). Springer, 1997. 
[26]  Guber,  D.  Getting  What  You  Pay  For:  The  Debate  Over 
Equity  in  Public  School  Expenditures.  Journal  of  Statistics 
Education, 7, 2, 1999. 
[27]  Blake,  C.  and  Merz,  C.  J.  {UCI}  Repository  of  machine 
learning databases. 1998. 
[28] Schiffman, S., Reynolds, L. and Young, F. Introduction to 
Multidimensional  Scaling:  Theory,  Methods,  and  Applications. 
Academic Press, 1981. 
[29]  Christopher,  M.  B.  GTM:  The  generative  topographic 
mapping. 1998. 
[30] Kohonen, T., Kaski, S., Lagus, K., Salojarvi, J., Honkela, J., 
Paatero,  V.  and  Saarela,  A.  Self  Organization  of  a  Massive 
Document  Collection.  Transactions  on  Neural  Networks,  11,  3 
2000. 
[31] Dempster, A. P., Laird, N. M. and Rubin, D. B. Maximum 
likelihood from incomplete data via the EM algorithm. City, 1977. 
[32] MacQueen, J. Some methods for classification and analysis 
of  multivariate  observations.  Proceedings  of 
the  Berkeley 
Symposium  on  Mathematical  Statistics  and  Probability,  1,  281-
297, 1967, 14. 
[33] Hastie, T., Tibshirani, R. and Friedman, J. H. The Elements 
of Statistical Learning. Springer, 2003. 
[34]  Svensen,  J.  F.  M.  GTM:  the  generative  topographical 
mapping. Aston University, Birmingham, 1998. 
 

 

L. 

the  expert. 

in  Face  Verification.  In  Proceedings  of 

[4] Buja, A., Swayne, D. F., Littman, M., Dean, N., Hofmann, H. 
and  Chen, 
Interactive  Data  Visualization  with 
Multidimensional  Scaling.  Journal  of  Computational  and 
Graphical Statistics, 17, 2, 2008. 
[5]  Broekens,  J.,  Cocx,  T.  and  Kosters,  W.  A.  Object-centered 
interactive  multi-dimensional  scaling:  Ask 
In 
Proceedings  of  the  Eighteenth  Belgium-Netherlands  Conference 
on Artificial Intelligence, 2006. 
[6] Andrews, C., Endert, A. and North, C. Space to Think: Large, 
High-Resolution Displays for Sensemaking. In Proceedings of the 
CHI, 2010.  
[7] Conde, C., Ruiz, A. and Cabello, E. PCA vs Low Resolution 
Images 
the  12th 
International  Conference  on  Image  Analysis  and  Processing 
(2003). IEEE Computer Society.  
[8]  Gottumukkal,  R.  and  Asari,  V.  K.  An  improved  face 
recognition technique based on modular PCA approach. Pattern 
Recogn. Lett., 25, 4, 2004. 
[9]  Imran,  S.,  Bajwa,  S.  and  Hyder,  I.  PCA  based  Image 
Classification of Single-layered Cloud Types. Journal of Market 
Forces, 1, 2, 2005. 
[10]  Du,  Q.  and  Fowler,  J.  E.  Low-Complexity  Principal 
Component Analysis for Hyperspectral Image Compression. Int. 
J. High Perform. Comput. Appl., 22, 4, 2008. 
[11] Battista, D., Eades, P., Tamassia, R. and Tollis, I. Algorithms 
for Drawing Graphs: An Annotated Bibliography. Computational 
Geometry, 1994. 
[12] Zigelman, G., Kimmel, R. and Kiryati, N. Texture Mapping 
Using  Surface  Flattening  via  Multidimensional  Scaling.  IEEE 
Transactions  on  Visualization  and  Computer  Graphics,  8,  2, 
2002. 
[13]  Chen,  L.  Local  multidimensional  scaling  for  nonlinear 
dimension  reduction,  graph  layout  and  proximity  analysis. 
ScholarlyCommons@Penn, 2006. 
[14] Kaban, A. A Scalable Generative Topographic Mapping for 
Sparse Data Sequences. 2005. 
[15]  Olier,  I.,  Vellido,  A.  and  Giraldo,  J.  Kernel  generative 
topographic mapping. In Proceedings of the European Symposium 
on Artificial Neural Networks – Computational Intelligence and 
Machine Learning, 2010.  
[16] Cruz-Barbosa, R. and Vellido, A. Unfolding the Manifold in 
Generative  Topographic  Mapping.  In  Proceedings  of  the  3rd 
international workshop on Hybrid Artificial Intelligence Systems 
(Burgos, Spain, 2008). Springer-Verlag.  
[17]  Yi,  J.  S.,  Melton,  R.,  Stasko,  J.  and  Jacko,  J.  A.  Dust  & 
magnet:  multivariate  information  visualization  using  a  magnet 
metaphor. Information Visualization, 4, 4, 2005. 
[18]  House,  L.,  Leman,  S.  C.  and  Han,  C.  Bayesian  Visual 
Analytics  (BaVA).  In  revision,  Technical  Report:  FODAVA-10-
02, http://fodava.gatech.edu/node/342010). 
[19] Leman, S. C., House, L., Maiti, D., Endert, A. and North, C. 
A  Bi-directional  Visualization  Pipeline  that  Enables  Visual  to 
Parametric  Interation  (V2PI). NFS FODAVA Technical Report 
(FODAVA-10-41),  2011.  
[20] Pearson, K. On Lines and Planes of Closest Fit to Systems of 
Points in Space. City, 1901. 
[21]  Jolliffe,  I.  Principal  Component  Analysis.  John  Wiley  and 
Sons, Ltd, 2002. 
[22]  Torokhti,  A.  and  Friedland,  S.  Towards  theory  of  generic 
Principal Component Analysis. 
[23]  Tipping,  M.  E.  and  Bishop,  C.  M.  Probabilistic  Principal 
Component  Analysis.  Journal  of  the  Royal  Statistical  Society, 
SeriesB: Statistical Methodology, 61, 1999. 

","{""pos"":{""0"":1,""1"":2,""2"":3,""3"":4,""4"":5,""5"":6},""1"":{""0"":""1*"",""1"":""174*"",""2"":""7*"",""3"":""2005*"",""4"":""1b*"",""5"":""50*""},""5"":{""0"":""users*"",""1"":""keywords*"",""2"":""groups*"",""3"":""entities*"",""4"":""words*"",""5"":""individuals*""},""4"":{""0"":""documents*"",""1"":""models*"",""2"":""methods*"",""3"":""document"",""4"":""paper*"",""5"":""process*""},""3"":{""0"":""interaction*"",""1"":""observation"",""2"":""visual*"",""3"":""statistical*"",""4"":""interactive*"",""5"":""analysis*""},""0"":{""0"":""gtm*"",""1"":""ppca*"",""2"":""mds*"",""3"":""\u03c6"",""4"":""impi*"",""5"":""uggtm*""},""2"":{""0"":""d"",""1"":""r*"",""2"":""p"",""3"":""c*"",""4"":""w"",""5"":""j""}}",2011,{},False,False,conferencePaper,False,PRCPUX25,[],self.user,"{""Unnamed: 0"":{""0"":0,""1"":1,""2"":2,""3"":3,""4"":4,""5"":5,""6"":6,""7"":7,""8"":8,""9"":9,""10"":10,""11"":11,""12"":12,""13"":13,""14"":14,""15"":15,""16"":16,""17"":17,""18"":18,""19"":19,""20"":20,""21"":21,""22"":22,""23"":23,""24"":24,""25"":25,""26"":26,""27"":27,""28"":28,""29"":29,""30"":30,""31"":31,""32"":32,""33"":33,""34"":34,""35"":35,""36"":36,""37"":37,""38"":38,""39"":39,""40"":40,""41"":41,""42"":42,""43"":43,""44"":44,""45"":45,""46"":46,""47"":47,""48"":48,""49"":49,""50"":50,""51"":51,""52"":52,""53"":53,""54"":54,""55"":55,""56"":56,""57"":57,""58"":58,""59"":59,""60"":60,""61"":61,""62"":62,""63"":63,""64"":64,""65"":65,""66"":66,""67"":67,""68"":68,""69"":69,""70"":70,""71"":71,""72"":72,""73"":73,""74"":74,""75"":75,""76"":76,""77"":77,""78"":78,""79"":79,""80"":80},""C"":{""0"":9.9699263096,""1"":10.8602832474,""2"":7.3516179998,""3"":10.680749275,""4"":97.3558729214,""5"":12.5384107816,""6"":7.9811755867,""7"":9.8097423938,""8"":10.3298099994,""9"":66.0027145314,""10"":8.2541530465,""11"":22.3052179143,""12"":10.6323684596,""13"":8.3610902583,""14"":11.6398621357,""15"":8.8316318593,""16"":21.6854130803,""17"":5.8854536284,""18"":7.3898645567,""19"":8.1968610046,""20"":15.7282147131,""21"":6.5818406161,""22"":13.5050161426,""23"":13.3141985735,""24"":13.4262638684,""25"":8.3561086903,""26"":11.6457315141,""27"":11.8456357478,""28"":9.2117689793,""29"":13.1973027245,""30"":9.2151832476,""31"":19.8206072583,""32"":24.5886366798,""33"":9.5727312213,""34"":8.8643294887,""35"":8.367108357,""36"":6.1168544467,""37"":10.0575909849,""38"":7.7415250288,""39"":6.102788046,""40"":7.7459788119,""41"":6.7043013254,""42"":6.7324451857,""43"":7.4874576917,""44"":21.4164561724,""45"":10.876356282,""46"":15.4916219038,""47"":17.7567773985,""48"":6.7575135366,""49"":7.1191945299,""50"":19.5919238342,""51"":6.8677368979,""52"":8.0261435839,""53"":17.851718807,""54"":7.1498723239,""55"":12.1162380133,""56"":6.2942766899,""57"":6.2963413514,""58"":6.2677975766,""59"":8.5987068891,""60"":8.6507498364,""61"":13.1138203602,""62"":11.2270336948,""63"":7.1194311196,""64"":9.6432883867,""65"":8.2556300388,""66"":9.494725205,""67"":6.2330544057,""68"":7.0694292703,""69"":9.3755591979,""70"":7.8551072852,""71"":8.0153088072,""72"":5.9474358486,""73"":5.9029399335,""74"":6.53955179,""75"":6.3195520121,""76"":6.3235741646,""77"":6.3235741646,""78"":6.5850023911,""79"":6.5560205368,""80"":6.5520151702},""count"":{""0"":144,""1"":130,""2"":124,""3"":118,""4"":108,""5"":88,""6"":84,""7"":76,""8"":74,""9"":74,""10"":72,""11"":72,""12"":70,""13"":70,""14"":68,""15"":68,""16"":66,""17"":62,""18"":62,""19"":58,""20"":58,""21"":50,""22"":50,""23"":50,""24"":44,""25"":44,""26"":42,""27"":42,""28"":34,""29"":34,""30"":32,""31"":32,""32"":32,""33"":30,""34"":28,""35"":28,""36"":28,""37"":28,""38"":28,""39"":26,""40"":26,""41"":26,""42"":26,""43"":26,""44"":26,""45"":26,""46"":26,""47"":26,""48"":24,""49"":24,""50"":24,""51"":22,""52"":22,""53"":22,""54"":20,""55"":20,""56"":18,""57"":16,""58"":16,""59"":16,""60"":16,""61"":16,""62"":14,""63"":14,""64"":14,""65"":12,""66"":12,""67"":12,""68"":12,""69"":12,""70"":12,""71"":10,""72"":10,""73"":8,""74"":8,""75"":8,""76"":8,""77"":8,""78"":8,""79"":8,""80"":8},""sigma_nor"":{""0"":1.790040342,""1"":1.9030593166,""2"":1.6208032141,""3"":1.9281318201,""4"":9.9185871061,""5"":2.2461922558,""6"":1.8033944127,""7"":2.0359984602,""8"":2.1047273745,""9"":8.1664884088,""10"":1.8891926528,""11"":3.4378462921,""12"":2.165458166,""13"":1.9119808257,""14"":2.2940338488,""15"":1.9765907834,""16"":3.4613924456,""17"":1.6690219326,""18"":1.8461201276,""19"":1.9679129275,""20"":2.8806000776,""21"":1.8206752604,""22"":2.7148478833,""23"":2.6902025676,""24"":2.796654703,""25"":2.1055969814,""26"":2.5834008276,""27"":2.6111794118,""28"":2.3520344463,""29"":2.9555436649,""30"":2.3838921873,""31"":4.0288760961,""32"":4.7684346152,""33"":2.4743963578,""34"":2.3964001797,""35"":2.3151714739,""36"":1.9475579491,""37"":2.5913377655,""38"":2.2129728325,""39"":1.969861787,""40"":2.245957941,""41"":2.070930699,""42"":2.0756595545,""43"":2.2025200831,""44"":4.542931793,""45"":2.7719377591,""46"":3.5474150284,""47"":3.9280164372,""48"":2.1097777606,""49"":2.1723875327,""50"":4.3315132637,""51"":2.1619287975,""52"":2.3689161022,""53"":4.1245770086,""54"":2.250099423,""55"":3.1680446661,""56"":2.1274089279,""57"":2.1665706948,""58"":2.1608821691,""59"":2.6254120924,""60"":2.6357837985,""61"":3.5252348796,""62"":3.2339704297,""63"":2.3800473714,""64"":2.904728101,""65"":2.681440172,""66"":2.9511272702,""67"":2.2412297926,""68"":2.4232654556,""69"":2.9251909777,""70"":2.5942670298,""71"":2.6975802641,""72"":2.2244402902,""73"":2.2594369616,""74"":2.413237354,""75"":2.3600871467,""76"":2.3610588669,""77"":2.3610588669,""78"":2.42421786,""79"":2.4172160731,""80"":2.4162484082},""vocab_index"":{""0"":1,""1"":2,""2"":3,""3"":4,""4"":6,""5"":8,""6"":10,""7"":12,""8"":13,""9"":14,""10"":16,""11"":17,""12"":18,""13"":19,""14"":20,""15"":21,""16"":23,""17"":24,""18"":25,""19"":29,""20"":30,""21"":35,""22"":36,""23"":37,""24"":39,""25"":42,""26"":44,""27"":45,""28"":53,""29"":55,""30"":56,""31"":58,""32"":59,""33"":60,""34"":62,""35"":63,""36"":64,""37"":65,""38"":68,""39"":71,""40"":73,""41"":77,""42"":78,""43"":79,""44"":80,""45"":83,""46"":84,""47"":85,""48"":86,""49"":90,""50"":92,""51"":93,""52"":102,""53"":103,""54"":104,""55"":112,""56"":120,""57"":144,""58"":145,""59"":147,""60"":148,""61"":149,""62"":180,""63"":181,""64"":182,""65"":204,""66"":206,""67"":208,""68"":209,""69"":210,""70"":211,""71"":253,""72"":256,""73"":311,""74"":315,""75"":316,""76"":317,""77"":318,""78"":336,""79"":337,""80"":340},""word"":{""0"":""1"",""1"":""interaction"",""2"":""user"",""3"":""d"",""4"":""cid"",""5"":""r"",""6"":""observation"",""7"":""gtm"",""8"":""p"",""9"":""174"",""10"":""users"",""11"":""documents"",""12"":""level"",""13"":""c"",""14"":""visual"",""15"":""ppca"",""16"":""figure"",""17"":""model"",""18"":""mds"",""19"":""w"",""20"":""j"",""21"":""g"",""22"":""ri"",""23"":""m"",""24"":""models"",""25"":""k"",""26"":""methods"",""27"":""document"",""28"":""represents"",""29"":""\u03c3d"",""30"":""statistical"",""31"":""group"",""32"":""doc"",""33"":""layout"",""34"":""interactive"",""35"":""analysis"",""36"":""paper"",""37"":""sensemaking"",""38"":""7"",""39"":""process"",""40"":""keywords"",""41"":""feedback"",""42"":""f"",""43"":""di"",""44"":""\u03b7"",""45"":""groups"",""46"":""\u03c6"",""47"":""a"",""48"":""analytics"",""49"":""variance"",""50"":""sat"",""51"":""parameter"",""52"":""exp"",""53"":""impi"",""54"":""analytic"",""55"":""income"",""56"":""linear"",""57"":""variables"",""58"":""\u03b4"",""59"":""uggtm"",""60"":""entities"",""61"":""\u03b4i"",""62"":""proposals"",""63"":""words"",""64"":""proceedings"",""65"":""features"",""66"":""individuals"",""67"":""tag"",""68"":""treatments"",""69"":""magnification"",""70"":""2005"",""71"":""scores"",""72"":""gk"",""73"":""states"",""74"":""1b"",""75"":""upper"",""76"":""50"",""77"":""quantiles"",""78"":""o"",""79"":""cost"",""80"":""fodava""},""vector"":{""0"":""[-0.4373649  -0.9824084  -2.5706658  -0.37745488  0.22427553 -0.47780344\n -1.5875137  -2.4298089   0.83580506  1.9139477 ]"",""1"":""[ 0.24979551 -1.2184464  -2.5199492  -0.6807545   1.5312382  -0.5355266\n -1.9871715  -2.5012689  -1.7959198   3.4668477 ]"",""2"":""[ 1.1991677  -1.8085966  -3.2485397   0.1918882   1.1623255  -0.36305273\n -2.4495673  -2.069114   -0.84440327  3.4091704 ]"",""3"":""[-0.7107459  -1.3137887  -3.0034437  -0.4999703   0.5901887  -0.22754672\n -1.5550922  -2.5364954   1.3338587   1.2389281 ]"",""4"":""[-0.7050667  -1.7692937  -3.0058913  -0.15407442  0.71982574 -0.44044426\n -1.7165654  -2.401539    1.2324662   1.4428499 ]"",""5"":""[-0.65462863 -1.6582047  -2.9164035  -0.493086    0.59359586 -0.43191326\n -1.1639366  -2.2549956   1.3514692   1.5450273 ]"",""6"":""[ 0.44459036 -1.1243492  -2.3975337  -0.72543764  1.3045771  -0.77408904\n -2.2125418  -2.5075486  -1.7160093   3.4719372 ]"",""7"":""[-0.3085919  -2.0142643  -2.5889678  -0.35967073  1.4133347  -0.5833371\n -1.4815587  -2.2735426  -0.18139605  2.696274  ]"",""8"":""[-0.7337892  -1.5327882  -3.0083747  -0.485297    0.8431663  -0.29351094\n -1.6239358  -2.3561897   1.0379502   1.4623234 ]"",""9"":""[-0.17119625 -0.96273196 -2.6187408  -0.56672466  0.12034151 -0.503687\n -1.5350498  -2.3783133   0.6908967   1.9223112 ]"",""10"":""[ 1.3885974 -1.6337878 -3.0724423  0.3832742  1.1650956 -0.3854268\n -2.5043163 -1.9428276 -0.9691336  3.424174 ]"",""11"":""[ 1.4140388  -2.042506   -2.8141751  -0.09912198  1.321576   -0.8229493\n -2.7132876  -1.962458   -1.4900666   3.6339478 ]"",""12"":""[ 0.4534208  -1.0688343  -2.2941966  -0.42335877  0.6288508  -0.72935075\n -2.3406618  -2.2313163  -0.7484261   2.960344  ]"",""13"":""[-0.7400214  -1.4447076  -2.8126862  -0.32089493  0.4570627  -0.42410216\n -1.4915422  -2.2896073   1.3511211   1.506254  ]"",""14"":""[-0.03469533 -1.0977888  -2.5700908  -0.8120333   1.3490984  -0.5065592\n -1.9815089  -2.802212   -1.4119956   3.2679906 ]"",""15"":""[-0.43150946 -2.06393    -2.5685186  -0.40395677  1.4182051  -0.81470317\n -1.6128881  -2.341933    0.04630278  2.6792226 ]"",""16"":""[ 0.85766506 -0.95080996 -2.7077212  -0.30993155  0.6684816  -0.5066442\n -2.331166   -2.0784802  -1.2518852   3.0509908 ]"",""17"":""[ 0.9788933  -1.0583953  -2.7488372  -0.40002418  1.1060724  -0.67390436\n -2.3160226  -2.2255754  -1.6976805   3.4386137 ]"",""18"":""[-0.5578823  -1.9076538  -2.6830122  -0.34279263  1.1823744  -0.64727515\n -1.6193174  -2.3399293   0.48826203  2.2865942 ]"",""19"":""[-0.43255395 -1.3635225  -2.7996416  -0.55865717  0.38760954 -0.4086524\n -1.2282645  -2.333326    1.2613137   1.5470375 ]"",""20"":""[-0.74310064 -1.9159464  -3.067095   -0.55082583  0.9674932  -0.30146575\n -1.0456649  -2.3100102   1.5509937   1.3143494 ]"",""21"":""[-0.63231784 -1.5594417  -2.9981623  -0.60759497  0.6556429  -0.195346\n -1.217851   -2.505192    1.5400605   1.1740364 ]"",""22"":""[-0.7389196  -1.8139721  -3.0804603  -0.6073231   1.0214392  -0.56569797\n -1.4104168  -2.1842244   1.192522    1.3160226 ]"",""23"":""[-0.84703314 -1.5471213  -3.0611825  -0.6391674   0.80692434 -0.29058012\n -1.2991439  -2.4750032   1.5074955   1.1415025 ]"",""24"":""[ 1.2005534  -1.202204   -2.7296162  -0.08736748  1.2187955  -0.75610566\n -2.4003537  -2.1927588  -1.3418877   3.5381453 ]"",""25"":""[-0.6574215  -1.7897065  -3.0893574  -0.6167085   0.940322   -0.35590366\n -1.2451819  -2.4164836   1.350464    1.2858615 ]"",""26"":""[ 1.1662897  -1.3880209  -2.4836607  -0.28608608  1.286027   -1.1162258\n -2.4456873  -2.1777363  -1.2548703   3.7163427 ]"",""27"":""[ 1.2882383  -1.8130448  -2.8651388  -0.2989121   1.2080854  -0.66086215\n -2.6943731  -2.0340445  -1.8680438   3.594826  ]"",""28"":""[ 0.72369134 -0.9554023  -2.8585536  -0.20890857  0.48730773 -0.25330478\n -2.2614977  -2.0421138  -0.89801586  2.753235  ]"",""29"":""[ 0.16964844 -2.328001   -2.610845   -0.23003098  1.8400174  -0.65139204\n -1.8640257  -2.1785593  -0.80719346  2.9703004 ]"",""30"":""[ 0.08327781 -1.5802333  -2.2652879  -0.8041276   1.2756647  -1.1071689\n -2.159693   -2.6294076  -0.96405756  3.3571515 ]"",""31"":""[ 0.65980566 -1.3606424  -2.7792351   0.07835969  0.9065642  -0.30750972\n -2.1442115  -2.051822   -0.6185816   3.0528598 ]"",""32"":""[ 1.2606999  -2.1295345  -3.1191325  -0.27829123  1.1866492  -0.6205723\n -2.7208016  -2.0409212  -1.5756226   3.4617727 ]"",""33"":""[ 0.8736694  -1.2188228  -2.8933165  -0.36628085  1.2029563  -0.39004916\n -2.4176288  -2.4288259  -1.6699872   3.4280891 ]"",""34"":""[ 0.01866779 -1.2402164  -2.509893   -0.75356174  1.409644   -0.58678675\n -1.9684404  -2.6714537  -1.4064589   3.3013766 ]"",""35"":""[ 0.39655885 -1.4833494  -2.242305   -0.71857     1.2518042  -1.0390558\n -2.2642443  -2.4175887  -1.3609515   3.447784  ]"",""36"":""[ 1.1835366  -1.8308696  -2.7059295  -0.40601835  1.2303207  -0.8243736\n -2.6660814  -2.0728462  -1.8458456   3.6322994 ]"",""37"":""[-0.2400235 -1.7349344 -2.374715  -0.7082598  1.6197243 -0.7666198\n -1.7042973 -2.47716   -1.0736458  3.142738 ]"",""38"":""[-0.15543473 -0.8893553  -2.488255   -0.48974854  0.2608688  -0.56369704\n -1.5525182  -2.456622    0.52725106  2.0864892 ]"",""39"":""[ 0.9800098  -1.5177819  -2.43642    -0.46397445  1.3417317  -0.9417141\n -2.399397   -2.091294   -1.728539    3.593072  ]"",""40"":""[ 1.2243577  -2.105264   -3.1629224  -0.15212755  1.3599108  -0.8552371\n -2.6076384  -2.3263845  -0.8852068   3.6334949 ]"",""41"":""[ 0.4389426  -1.2768077  -2.6020303  -0.5963034   1.4734172  -0.56809103\n -2.1211703  -2.466758   -1.7444302   3.484267  ]"",""42"":""[-0.43584725 -1.7013804  -2.9504921  -0.5187175   0.79116005 -0.18154845\n -1.2593925  -2.4312718   1.2337587   1.540912  ]"",""43"":""[-0.61291194 -1.4062212  -2.9897046  -0.39647183  0.4739547  -0.24951048\n -1.4259971  -2.560606    1.4605219   1.2912332 ]"",""44"":""[-0.5466467 -2.1770694 -3.251395  -0.3309761  1.2181277 -0.2991704\n -1.4820751 -2.0979538  0.7319004  1.758826 ]"",""45"":""[ 1.1962911  -1.6205251  -2.660923    0.25749955  0.9153071  -0.6070542\n -2.531601   -1.8894631  -0.72605234  3.267031  ]"",""46"":""[-0.62519825 -2.0026147  -3.1784012  -0.44247043  1.2737811  -0.26083565\n -1.5474348  -2.078972    0.71697253  1.8725917 ]"",""47"":""[ 0.05887245 -0.99760866 -2.6419482  -0.46957707  0.74853957 -0.36082706\n -1.9517878  -2.4465868  -0.5515661   2.748314  ]"",""48"":""[ 0.03633048 -1.7640672  -2.3255062  -0.7370655   1.560226   -0.9739315\n -1.989945   -2.5377414  -1.2020465   3.3952937 ]"",""49"":""[ 0.27845702 -1.676715   -2.406653   -0.66731346  1.1582853  -1.1344913\n -2.2978523  -2.533934   -0.68375385  3.248331  ]"",""50"":""[ 0.48461974 -0.97248214 -2.8282206  -0.3078435   0.39261398 -0.26359665\n -2.148076   -2.0969615  -0.5733193   2.5289207 ]"",""51"":""[ 0.86920947 -1.8862283  -3.3094523  -0.2768438   1.2795027  -0.75180405\n -2.3533232  -2.402513   -0.68175536  3.386727  ]"",""52"":""[-0.7387441  -1.8098557  -2.9674726  -0.448281    1.1089554  -0.39751887\n -1.5184078  -2.2854898   0.9262025   1.7469296 ]"",""53"":""[-0.54835474 -2.229948   -2.7410717  -0.3623623   1.5069796  -0.65962666\n -1.367566   -2.205519    0.26277512  2.4298837 ]"",""54"":""[-0.03985991 -1.5978707  -2.2626264  -0.80850166  1.4526227  -0.9404374\n -1.9616327  -2.5577385  -1.2097569   3.308026  ]"",""55"":""[ 0.5616083  -1.2194089  -2.291132   -0.58364576  0.7553168  -0.9618761\n -2.4218726  -2.2451053  -1.0285707   3.1179216 ]"",""56"":""[-0.06741744 -1.129527   -2.5369523  -0.74599326  1.142011   -0.5722764\n -1.9885734  -2.7064018  -1.0010816   3.0699337 ]"",""57"":""[ 0.9244397 -1.7286823 -2.9006872 -0.2300613  1.2467545 -0.9368348\n -2.4369433 -2.394789  -0.7048849  3.4587102]"",""58"":""[-0.53584707 -2.1344135  -3.215208   -0.3157948   1.1896774  -0.25113526\n -1.5369848  -2.0390456   0.66696364  1.8076487 ]"",""59"":""[-0.48177812 -2.10575    -2.728902   -0.401747    1.4330847  -0.57906497\n -1.3790783  -2.259826    0.12289643  2.4488926 ]"",""60"":""[ 1.3244885  -1.7551397  -2.7935529   0.40377936  1.1387984  -0.56790483\n -2.5151794  -1.7965248  -0.97231317  3.402678  ]"",""61"":""[ 0.41250038 -2.303409   -2.6657546  -0.19546294  1.7648178  -0.7272017\n -2.0306752  -2.1181204  -0.9397816   3.1014223 ]"",""62"":""[ 1.245325   -1.7047194  -2.5113018  -0.27768123  1.245763   -0.99882054\n -2.6033957  -2.0291069  -1.4669839   3.6093524 ]"",""63"":""[ 1.4097983  -1.9531205  -2.8885915  -0.02267332  1.1937131  -0.84122545\n -2.7049963  -2.077934   -1.0182854   3.5773044 ]"",""64"":""[ 1.0897574 -1.8493502 -2.4537625 -0.3850749  1.3900595 -1.0299276\n -2.5263424 -1.9958392 -1.6195135  3.5929358]"",""65"":""[ 1.0555038  -1.2785527  -2.8985953  -0.16111936  1.074352   -0.42604336\n -2.500883   -2.336128   -1.3051846   3.379119  ]"",""66"":""[ 1.2655066  -1.6942303  -2.7378051   0.410654    0.9839837  -0.54222417\n -2.5281174  -1.7718885  -0.79070646  3.279066  ]"",""67"":""[ 1.1679218  -2.0391364  -3.313238   -0.12715332  1.250815   -0.6134574\n -2.5012238  -2.220676   -0.89229196  3.5382931 ]"",""68"":""[ 1.2229574  -1.5001885  -2.5271094  -0.20522708  1.1197786  -1.0044817\n -2.5997627  -2.1787574  -1.1435773   3.5173068 ]"",""69"":""[ 0.13056381 -1.0141364  -2.6622238  -0.7516441   1.1656692  -0.48602438\n -2.1364765  -2.7346532  -1.3011026   3.1030757 ]"",""70"":""[-0.02464239 -0.9230525  -2.594487   -0.6105422   0.08823191 -0.56892157\n -1.4918326  -2.376979    0.5797902   1.9915324 ]"",""71"":""[ 0.96524197 -1.4925163  -2.4722712  -0.15550712  0.84092265 -0.84547955\n -2.5384138  -2.1360729  -0.72656465  3.219006  ]"",""72"":""[-0.750905  -1.9828612 -3.0350358 -0.5937531  1.2002591 -0.3747351\n -1.0919033 -2.4043517  1.2499602  1.5256658]"",""73"":""[ 1.3704172  -1.5518098  -2.747102    0.38845     0.95676535 -0.49972156\n -2.5465717  -1.7871898  -0.98687935  3.2838964 ]"",""74"":""[-0.5366764  -1.1335955  -2.6855817  -0.36806813  0.26707911 -0.43888655\n -1.5847706  -2.3752775   1.0275886   1.7437547 ]"",""75"":""[ 0.0860091  -0.9941689  -2.4545665  -0.4486474   0.47306684 -0.5551736\n -2.0408406  -2.3303747  -0.17080368  2.5194056 ]"",""76"":""[-0.27235436 -0.89692163 -2.5543127  -0.49017623  0.11486408 -0.36444694\n -1.7345906  -2.313007    0.53576994  2.0720897 ]"",""77"":""[ 0.13130714 -1.7641859  -2.5080745  -0.63869566  1.2428192  -1.0818694\n -2.1663194  -2.5749235  -0.50504696  3.1820636 ]"",""78"":""[-0.51964223 -1.5423808  -2.9570699  -0.45900938  0.47015333 -0.33512706\n -1.2391031  -2.3940685   1.5286995   1.3124677 ]"",""79"":""[ 0.7450865  -1.2138491  -2.3044267  -0.5795054   0.81259006 -1.0060617\n -2.486154   -2.1713107  -1.198222    3.1940768 ]"",""80"":""[-0.4960248  -2.1941552  -2.9133909  -0.4411542   1.4608692  -0.4991543\n -1.4010385  -2.2130487   0.26421666  2.2611673 ]""},""topic"":{""0"":1,""1"":3,""2"":-1,""3"":2,""4"":-1,""5"":2,""6"":3,""7"":0,""8"":2,""9"":1,""10"":5,""11"":4,""12"":-1,""13"":2,""14"":3,""15"":0,""16"":-1,""17"":-1,""18"":0,""19"":2,""20"":2,""21"":2,""22"":2,""23"":2,""24"":4,""25"":2,""26"":4,""27"":4,""28"":-1,""29"":-1,""30"":3,""31"":-1,""32"":-1,""33"":-1,""34"":3,""35"":3,""36"":4,""37"":-1,""38"":1,""39"":4,""40"":5,""41"":-1,""42"":2,""43"":2,""44"":-1,""45"":5,""46"":0,""47"":-1,""48"":3,""49"":-1,""50"":-1,""51"":-1,""52"":2,""53"":0,""54"":3,""55"":-1,""56"":-1,""57"":-1,""58"":-1,""59"":0,""60"":5,""61"":-1,""62"":4,""63"":5,""64"":4,""65"":-1,""66"":5,""67"":5,""68"":4,""69"":-1,""70"":1,""71"":-1,""72"":-1,""73"":5,""74"":1,""75"":-1,""76"":1,""77"":-1,""78"":2,""79"":-1,""80"":0},""exemplar"":{""0"":""*"",""1"":""*"",""2"":null,""3"":null,""4"":null,""5"":""*"",""6"":null,""7"":""*"",""8"":null,""9"":""*"",""10"":""*"",""11"":""*"",""12"":null,""13"":""*"",""14"":""*"",""15"":""*"",""16"":null,""17"":null,""18"":""*"",""19"":null,""20"":null,""21"":""*"",""22"":null,""23"":null,""24"":""*"",""25"":""*"",""26"":""*"",""27"":null,""28"":null,""29"":null,""30"":""*"",""31"":null,""32"":null,""33"":null,""34"":""*"",""35"":""*"",""36"":""*"",""37"":null,""38"":""*"",""39"":""*"",""40"":""*"",""41"":null,""42"":null,""43"":""*"",""44"":null,""45"":""*"",""46"":null,""47"":null,""48"":""*"",""49"":null,""50"":null,""51"":null,""52"":null,""53"":""*"",""54"":""*"",""55"":null,""56"":null,""57"":null,""58"":null,""59"":""*"",""60"":""*"",""61"":null,""62"":""*"",""63"":""*"",""64"":null,""65"":null,""66"":""*"",""67"":""*"",""68"":null,""69"":null,""70"":""*"",""71"":null,""72"":null,""73"":""*"",""74"":""*"",""75"":null,""76"":""*"",""77"":null,""78"":""*"",""79"":null,""80"":""*""},""word*"":{""0"":""1*"",""1"":""interaction*"",""2"":""user"",""3"":""d"",""4"":""cid"",""5"":""r*"",""6"":""observation"",""7"":""gtm*"",""8"":""p"",""9"":""174*"",""10"":""users*"",""11"":""documents*"",""12"":""level"",""13"":""c*"",""14"":""visual*"",""15"":""ppca*"",""16"":""figure"",""17"":""model"",""18"":""mds*"",""19"":""w"",""20"":""j"",""21"":""g*"",""22"":""ri"",""23"":""m"",""24"":""models*"",""25"":""k*"",""26"":""methods*"",""27"":""document"",""28"":""represents"",""29"":""\u03c3d"",""30"":""statistical*"",""31"":""group"",""32"":""doc"",""33"":""layout"",""34"":""interactive*"",""35"":""analysis*"",""36"":""paper*"",""37"":""sensemaking"",""38"":""7*"",""39"":""process*"",""40"":""keywords*"",""41"":""feedback"",""42"":""f"",""43"":""di*"",""44"":""\u03b7"",""45"":""groups*"",""46"":""\u03c6"",""47"":""a"",""48"":""analytics*"",""49"":""variance"",""50"":""sat"",""51"":""parameter"",""52"":""exp"",""53"":""impi*"",""54"":""analytic*"",""55"":""income"",""56"":""linear"",""57"":""variables"",""58"":""\u03b4"",""59"":""uggtm*"",""60"":""entities*"",""61"":""\u03b4i"",""62"":""proposals*"",""63"":""words*"",""64"":""proceedings"",""65"":""features"",""66"":""individuals*"",""67"":""tag*"",""68"":""treatments"",""69"":""magnification"",""70"":""2005*"",""71"":""scores"",""72"":""gk"",""73"":""states*"",""74"":""1b*"",""75"":""upper"",""76"":""50*"",""77"":""quantiles"",""78"":""o*"",""79"":""cost"",""80"":""fodava*""},""pos"":{""0"":1,""1"":1,""2"":1,""3"":1,""4"":2,""5"":2,""6"":2,""7"":1,""8"":3,""9"":2,""10"":1,""11"":1,""12"":3,""13"":4,""14"":3,""15"":2,""16"":4,""17"":5,""18"":3,""19"":5,""20"":6,""21"":7,""22"":8,""23"":9,""24"":2,""25"":10,""26"":3,""27"":4,""28"":6,""29"":7,""30"":4,""31"":8,""32"":9,""33"":10,""34"":5,""35"":6,""36"":5,""37"":11,""38"":3,""39"":6,""40"":2,""41"":12,""42"":11,""43"":12,""44"":13,""45"":3,""46"":4,""47"":14,""48"":7,""49"":15,""50"":16,""51"":17,""52"":13,""53"":5,""54"":8,""55"":18,""56"":19,""57"":20,""58"":21,""59"":6,""60"":4,""61"":22,""62"":7,""63"":5,""64"":8,""65"":23,""66"":6,""67"":7,""68"":9,""69"":24,""70"":4,""71"":25,""72"":26,""73"":8,""74"":5,""75"":27,""76"":6,""77"":28,""78"":14,""79"":29,""80"":7},""x2D"":{""0"":-11.8468580246,""1"":8.0914316177,""2"":6.0490884781,""3"":-12.0751972198,""4"":-11.4290218353,""5"":-12.1548595428,""6"":7.9529356956,""7"":-9.2729568481,""8"":-11.0589284897,""9"":-11.8709115982,""10"":5.9095473289,""11"":7.2121620178,""12"":7.3607683182,""13"":-12.1335840225,""14"":7.7143507004,""15"":-9.3983430862,""16"":7.7576565742,""17"":8.2047128677,""18"":-9.5558261871,""19"":-11.8704690933,""20"":-11.5852050781,""21"":-11.9998674393,""22"":-11.3623323441,""23"":-11.9374475479,""24"":7.8090844154,""25"":-11.6127138138,""26"":7.764213562,""27"":7.5725779533,""28"":7.4842934608,""29"":6.1155853271,""30"":6.5664587021,""31"":6.8498888016,""32"":7.1572589874,""33"":8.2315206528,""34"":7.5798602104,""35"":7.1322054863,""36"":7.6516265869,""37"":6.9485807419,""38"":-11.7497205734,""39"":8.0923652649,""40"":6.5350747108,""41"":8.142373085,""42"":-11.6586751938,""43"":-12.1554832458,""44"":-10.444814682,""45"":6.2471284866,""46"":-10.3045864105,""47"":6.9253945351,""48"":6.8617739677,""49"":6.7277135849,""50"":7.1650519371,""51"":6.6201777458,""52"":-10.6970300674,""53"":-9.4030399323,""54"":6.8126864433,""55"":7.6724839211,""56"":7.4237327576,""57"":6.7802152634,""58"":-10.1191978455,""59"":-9.5709657669,""60"":5.8610768318,""61"":6.21301651,""62"":7.5057835579,""63"":6.7196927071,""64"":7.8085341454,""65"":7.916510582,""66"":5.7986044884,""67"":6.3420786858,""68"":7.4234347343,""69"":7.6250629425,""70"":-12.0096588135,""71"":7.1621785164,""72"":-11.173579216,""73"":5.9133234024,""74"":-11.8872070312,""75"":6.9108681679,""76"":-11.824464798,""77"":6.6243600845,""78"":-12.1959323883,""79"":7.8375496864,""80"":-9.4365358353},""y2D"":{""0"":-4.3525738716,""1"":-3.9500005245,""2"":-7.4040417671,""3"":-2.7418208122,""4"":-2.716912508,""5"":-2.3981790543,""6"":-4.1666250229,""7"":-1.902479887,""8"":-2.5465641022,""9"":-4.2193846703,""10"":-7.3013906479,""11"":-8.0235462189,""12"":-5.4539990425,""13"":-2.7769808769,""14"":-3.9176046848,""15"":-1.9261592627,""16"":-6.1250243187,""17"":-6.7891097069,""18"":-1.7609713078,""19"":-2.996733427,""20"":-2.1484026909,""21"":-2.0662353039,""22"":-1.9799593687,""23"":-2.1730217934,""24"":-7.0208673477,""25"":-2.0051145554,""26"":-7.3989019394,""27"":-8.1406602859,""28"":-6.0014967918,""29"":-4.2528676987,""30"":-4.0454249382,""31"":-6.2381215096,""32"":-8.1090536118,""33"":-6.5561571121,""34"":-4.10019207,""35"":-4.2164478302,""36"":-7.9706521034,""37"":-3.9098258018,""38"":-4.3224859238,""39"":-7.5372276306,""40"":-7.6270985603,""41"":-4.2194504738,""42"":-2.4281196594,""43"":-2.5774621964,""44"":-2.0551564693,""45"":-6.7478399277,""46"":-1.9547592402,""47"":-5.4412884712,""48"":-3.940513134,""49"":-4.4231591225,""50"":-5.7897119522,""51"":-7.1754865646,""52"":-2.1789813042,""53"":-2.0312054157,""54"":-3.9289264679,""55"":-5.3390440941,""56"":-4.5012750626,""57"":-7.1154203415,""58"":-1.7917119265,""59"":-1.6000124216,""60"":-7.0811090469,""61"":-4.40284729,""62"":-7.6247091293,""63"":-7.7250704765,""64"":-7.7758083344,""65"":-6.7284197807,""66"":-6.9490656853,""67"":-7.4454407692,""68"":-7.2879590988,""69"":-4.3743247986,""70"":-4.4240169525,""71"":-6.5936675072,""72"":-2.1131033897,""73"":-6.8556580544,""74"":-3.86951828,""75"":-5.5756163597,""76"":-4.5660910606,""77"":-4.3688650131,""78"":-2.3909635544,""79"":-5.6300697327,""80"":-1.6502684355}}",False,False,False,http://ieeexplore.ieee.org/document/6102449/,,Observation-level interaction with statistical models for visual analytics,PRCPUX25,False,False
4DVV4NXW,WD6HIX8D,"Wang XM, Zhang TY, Ma YX et al. A survey of visual analytic pipelines. JOURNAL OF COMPUTER SCIENCE AND
TECHNOLOGY 31(4): 787–804 July 2016. DOI 10.1007/s11390-016-1663-1

A Survey of Visual Analytic Pipelines

Xu-Meng Wang, Tian-Ye Zhang, Yu-Xin Ma, Jing Xia, and Wei Chen ∗, Senior Member, IEEE

State Key Laboratory of Computer Aided Design and Computer Graphics, Zhejiang University, Hangzhou 310058, China

Innovation Joint Research Center for Cyber-Physical-Society System, Zhejiang University, Hangzhou 310058, China

E-mail: {wangxumeng, zhangtianye1026, mayuxin}@zju.edu.cn; jjane.summer@gmail.com
E-mail: chenwei@cad.zju.edu.cn

Received April 17, 2016; revised May 31, 2016.

Visual analytics has been widely studied in the past decade. One key to make visual analytics practical for
Abstract
both research and industrial applications is the appropriate deﬁnition and implementation of the visual analytics pipeline
which provides eﬀective abstractions for designing and implementing visual analytics systems. In this paper we review the
previous work on visual analytics pipelines and individual modules from multiple perspectives: data, visualization, model
and knowledge.
In each module we discuss various representations and descriptions of pipelines inside the module, and
compare the commonalities and the diﬀerences among them.

Keywords

visual analytics, pipeline, visualization, model, knowledge

1 Introduction

Nowadays the increasing availability of massive
datasets has raised a revolution of data gathering, sto-
rage and analysis. It becomes diﬃcult and gradually in-
feasible to apply standard tools for data analysis, which
are widely utilized during the past decades by business
analysts, scientists and government employees for in-
sight gaining and decision making.

In many ﬁelds such as biological computation, busi-
ness intelligence and online transaction analysis, auto-
mated data analysis approaches such as machine learn-
ing and data mining are commonly deployed to extract
patterns from existing data. The patterns are repre-
sented as the high-level abstraction of insights from the
data and then transformed into knowledge[1]. Visuali-
zation, from the perspective of human vision, provides
another scheme for analysts to enhance the ability of
understanding and exploring datasets. Usually visuali-
zation methods employ visual channels to represent
and transform raw datasets into various visual rep-

resentation forms, and thereby human intelligence is
incorporated into the data analysis process via intui-
tive interactive interface. In the past decade, the the-
ory of “visual analytics” (or visual analysis) has been
widely studied by combining automated data mining
techniques and visualization methods. Visual analytics
“integrates the capability of computer and the abilities
of the human analyst”[2] to empower the control of the
entire analysis and decision-making process.
In fact,
pioneers provide a few valuable literatures. Keim et
al.[2-3] gave a general introduction of visual analytics.
In addition, some scholars summarize the state-of-the-
art part in the ﬁeld of visual analytics, for instance,
Zhang et al.[4] focused on advanced commercial sys-
tems and Sun et al.[5] generalized cutting-edge research
and future challenges from the perspective of analytics
space.

The purpose of this paper is to bring visual analy-
tics into the limelight. We review a set of literatures on
visual analytics and propose a summarization of visual
analytics pipelines that cover automated data process-

Survey
The work was supported by the National Basic Research 973 Program of China under Grant No. 2015CB352503, the Major
Program of National Natural Science Foundation of China under Grant No. 61232012, the National Natural Science Foundation of
China under Grant Nos. 61422211, u1536118, and u1536119, Zhejiang Provincial Natural Science Foundation of China under Grant
No. LR13F020001, and Fundamental Research Funds for the Central Universities of China.

∗Corresponding Author
©2016 Springer Science + Business Media, LLC & Science Press, China

Wang XM, Zhang TY, Ma YX et al. A survey of visual analytic pipelines. JOURNAL OF COMPUTER SCIENCE AND
TECHNOLOGY 31(4): 787–804 July 2016. DOI 10.1007/s11390-016-1663-1

A Survey of Visual Analytic Pipelines

Xu-Meng Wang, Tian-Ye Zhang, Yu-Xin Ma, Jing Xia, and Wei Chen ∗, Senior Member, IEEE

State Key Laboratory of Computer Aided Design and Computer Graphics, Zhejiang University, Hangzhou 310058, China

Innovation Joint Research Center for Cyber-Physical-Society System, Zhejiang University, Hangzhou 310058, China

E-mail: {wangxumeng, zhangtianye1026, mayuxin}@zju.edu.cn; jjane.summer@gmail.com
E-mail: chenwei@cad.zju.edu.cn

Received April 17, 2016; revised May 31, 2016.

Visual analytics has been widely studied in the past decade. One key to make visual analytics practical for
Abstract
both research and industrial applications is the appropriate deﬁnition and implementation of the visual analytics pipeline
which provides eﬀective abstractions for designing and implementing visual analytics systems. In this paper we review the
previous work on visual analytics pipelines and individual modules from multiple perspectives: data, visualization, model
and knowledge.
In each module we discuss various representations and descriptions of pipelines inside the module, and
compare the commonalities and the diﬀerences among them.

Keywords

visual analytics, pipeline, visualization, model, knowledge

1 Introduction

Nowadays the increasing availability of massive
datasets has raised a revolution of data gathering, sto-
rage and analysis. It becomes diﬃcult and gradually in-
feasible to apply standard tools for data analysis, which
are widely utilized during the past decades by business
analysts, scientists and government employees for in-
sight gaining and decision making.

In many ﬁelds such as biological computation, busi-
ness intelligence and online transaction analysis, auto-
mated data analysis approaches such as machine learn-
ing and data mining are commonly deployed to extract
patterns from existing data. The patterns are repre-
sented as the high-level abstraction of insights from the
data and then transformed into knowledge[1]. Visuali-
zation, from the perspective of human vision, provides
another scheme for analysts to enhance the ability of
understanding and exploring datasets. Usually visuali-
zation methods employ visual channels to represent
and transform raw datasets into various visual rep-

resentation forms, and thereby human intelligence is
incorporated into the data analysis process via intui-
tive interactive interface. In the past decade, the the-
ory of “visual analytics” (or visual analysis) has been
widely studied by combining automated data mining
techniques and visualization methods. Visual analytics
“integrates the capability of computer and the abilities
of the human analyst”[2] to empower the control of the
entire analysis and decision-making process.
In fact,
pioneers provide a few valuable literatures. Keim et
al.[2-3] gave a general introduction of visual analytics.
In addition, some scholars summarize the state-of-the-
art part in the ﬁeld of visual analytics, for instance,
Zhang et al.[4] focused on advanced commercial sys-
tems and Sun et al.[5] generalized cutting-edge research
and future challenges from the perspective of analytics
space.

The purpose of this paper is to bring visual analy-
tics into the limelight. We review a set of literatures on
visual analytics and propose a summarization of visual
analytics pipelines that cover automated data process-

Survey
The work was supported by the National Basic Research 973 Program of China under Grant No. 2015CB352503, the Major
Program of National Natural Science Foundation of China under Grant No. 61232012, the National Natural Science Foundation of
China under Grant Nos. 61422211, u1536118, and u1536119, Zhejiang Provincial Natural Science Foundation of China under Grant
No. LR13F020001, and Fundamental Research Funds for the Central Universities of China.

∗Corresponding Author
©2016 Springer Science + Business Media, LLC & Science Press, China

","{""index"":{""0"":0},""abstract"":{""0"":false},""author"":{""0"":false},""citationArticles"":{""0"":false},""citations"":{""0"":false},""citationsList"":{""0"":false},""clusterID"":{""0"":false},""globalID"":{""0"":false},""notes"":{""0"":false},""organization"":{""0"":false},""pages"":{""0"":false},""parent_item"":{""0"":false},""pdf_file"":{""0"":false},""tags"":{""0"":false},""text"":{""0"":""\f\f\f\f\f\f\f\fWang XM, Zhang TY, Ma YX et al. A survey of visual analytic pipelines. JOURNAL OF COMPUTER SCIENCE AND\nTECHNOLOGY 31(4): 787\u2013804 July 2016. DOI 10.1007\/s11390-016-1663-1\n\nA Survey of Visual Analytic Pipelines\n\nXu-Meng Wang, Tian-Ye Zhang, Yu-Xin Ma, Jing Xia, and Wei Chen \u2217, Senior Member, IEEE\n\nState Key Laboratory of Computer Aided Design and Computer Graphics, Zhejiang University, Hangzhou 310058, China\n\nInnovation Joint Research Center for Cyber-Physical-Society System, Zhejiang University, Hangzhou 310058, China\n\nE-mail: {wangxumeng, zhangtianye1026, mayuxin}@zju.edu.cn; jjane.summer@gmail.com\nE-mail: chenwei@cad.zju.edu.cn\n\nReceived April 17, 2016; revised May 31, 2016.\n\nVisual analytics has been widely studied in the past decade. One key to make visual analytics practical for\nAbstract\nboth research and industrial applications is the appropriate de\ufb01nition and implementation of the visual analytics pipeline\nwhich provides e\ufb00ective abstractions for designing and implementing visual analytics systems. In this paper we review the\nprevious work on visual analytics pipelines and individual modules from multiple perspectives: data, visualization, model\nand knowledge.\nIn each module we discuss various representations and descriptions of pipelines inside the module, and\ncompare the commonalities and the di\ufb00erences among them.\n\nKeywords\n\nvisual analytics, pipeline, visualization, model, knowledge\n\n1 Introduction\n\nNowadays the increasing availability of massive\ndatasets has raised a revolution of data gathering, sto-\nrage and analysis. It becomes di\ufb03cult and gradually in-\nfeasible to apply standard tools for data analysis, which\nare widely utilized during the past decades by business\nanalysts, scientists and government employees for in-\nsight gaining and decision making.\n\nIn many \ufb01elds such as biological computation, busi-\nness intelligence and online transaction analysis, auto-\nmated data analysis approaches such as machine learn-\ning and data mining are commonly deployed to extract\npatterns from existing data. The patterns are repre-\nsented as the high-level abstraction of insights from the\ndata and then transformed into knowledge[1]. Visuali-\nzation, from the perspective of human vision, provides\nanother scheme for analysts to enhance the ability of\nunderstanding and exploring datasets. Usually visuali-\nzation methods employ visual channels to represent\nand transform raw datasets into various visual rep-\n\nresentation forms, and thereby human intelligence is\nincorporated into the data analysis process via intui-\ntive interactive interface. In the past decade, the the-\nory of \u201cvisual analytics\u201d (or visual analysis) has been\nwidely studied by combining automated data mining\ntechniques and visualization methods. Visual analytics\n\u201cintegrates the capability of computer and the abilities\nof the human analyst\u201d[2] to empower the control of the\nentire analysis and decision-making process.\nIn fact,\npioneers provide a few valuable literatures. Keim et\nal.[2-3] gave a general introduction of visual analytics.\nIn addition, some scholars summarize the state-of-the-\nart part in the \ufb01eld of visual analytics, for instance,\nZhang et al.[4] focused on advanced commercial sys-\ntems and Sun et al.[5] generalized cutting-edge research\nand future challenges from the perspective of analytics\nspace.\n\nThe purpose of this paper is to bring visual analy-\ntics into the limelight. We review a set of literatures on\nvisual analytics and propose a summarization of visual\nanalytics pipelines that cover automated data process-\n\nSurvey\nThe work was supported by the National Basic Research 973 Program of China under Grant No. 2015CB352503, the Major\nProgram of National Natural Science Foundation of China under Grant No. 61232012, the National Natural Science Foundation of\nChina under Grant Nos. 61422211, u1536118, and u1536119, Zhejiang Provincial Natural Science Foundation of China under Grant\nNo. LR13F020001, and Fundamental Research Funds for the Central Universities of China.\n\n\u2217Corresponding Author\n\u00a92016 Springer Science + Business Media, LLC & Science Press, China\n\n\fWang XM, Zhang TY, Ma YX et al. A survey of visual analytic pipelines. JOURNAL OF COMPUTER SCIENCE AND\nTECHNOLOGY 31(4): 787\u2013804 July 2016. DOI 10.1007\/s11390-016-1663-1\n\nA Survey of Visual Analytic Pipelines\n\nXu-Meng Wang, Tian-Ye Zhang, Yu-Xin Ma, Jing Xia, and Wei Chen \u2217, Senior Member, IEEE\n\nState Key Laboratory of Computer Aided Design and Computer Graphics, Zhejiang University, Hangzhou 310058, China\n\nInnovation Joint Research Center for Cyber-Physical-Society System, Zhejiang University, Hangzhou 310058, China\n\nE-mail: {wangxumeng, zhangtianye1026, mayuxin}@zju.edu.cn; jjane.summer@gmail.com\nE-mail: chenwei@cad.zju.edu.cn\n\nReceived April 17, 2016; revised May 31, 2016.\n\nVisual analytics has been widely studied in the past decade. One key to make visual analytics practical for\nAbstract\nboth research and industrial applications is the appropriate de\ufb01nition and implementation of the visual analytics pipeline\nwhich provides e\ufb00ective abstractions for designing and implementing visual analytics systems. In this paper we review the\nprevious work on visual analytics pipelines and individual modules from multiple perspectives: data, visualization, model\nand knowledge.\nIn each module we discuss various representations and descriptions of pipelines inside the module, and\ncompare the commonalities and the di\ufb00erences among them.\n\nKeywords\n\nvisual analytics, pipeline, visualization, model, knowledge\n\n1 Introduction\n\nNowadays the increasing availability of massive\ndatasets has raised a revolution of data gathering, sto-\nrage and analysis. It becomes di\ufb03cult and gradually in-\nfeasible to apply standard tools for data analysis, which\nare widely utilized during the past decades by business\nanalysts, scientists and government employees for in-\nsight gaining and decision making.\n\nIn many \ufb01elds such as biological computation, busi-\nness intelligence and online transaction analysis, auto-\nmated data analysis approaches such as machine learn-\ning and data mining are commonly deployed to extract\npatterns from existing data. The patterns are repre-\nsented as the high-level abstraction of insights from the\ndata and then transformed into knowledge[1]. Visuali-\nzation, from the perspective of human vision, provides\nanother scheme for analysts to enhance the ability of\nunderstanding and exploring datasets. Usually visuali-\nzation methods employ visual channels to represent\nand transform raw datasets into various visual rep-\n\nresentation forms, and thereby human intelligence is\nincorporated into the data analysis process via intui-\ntive interactive interface. In the past decade, the the-\nory of \u201cvisual analytics\u201d (or visual analysis) has been\nwidely studied by combining automated data mining\ntechniques and visualization methods. Visual analytics\n\u201cintegrates the capability of computer and the abilities\nof the human analyst\u201d[2] to empower the control of the\nentire analysis and decision-making process.\nIn fact,\npioneers provide a few valuable literatures. Keim et\nal.[2-3] gave a general introduction of visual analytics.\nIn addition, some scholars summarize the state-of-the-\nart part in the \ufb01eld of visual analytics, for instance,\nZhang et al.[4] focused on advanced commercial sys-\ntems and Sun et al.[5] generalized cutting-edge research\nand future challenges from the perspective of analytics\nspace.\n\nThe purpose of this paper is to bring visual analy-\ntics into the limelight. We review a set of literatures on\nvisual analytics and propose a summarization of visual\nanalytics pipelines that cover automated data process-\n\nSurvey\nThe work was supported by the National Basic Research 973 Program of China under Grant No. 2015CB352503, the Major\nProgram of National Natural Science Foundation of China under Grant No. 61232012, the National Natural Science Foundation of\nChina under Grant Nos. 61422211, u1536118, and u1536119, Zhejiang Provincial Natural Science Foundation of China under Grant\nNo. LR13F020001, and Fundamental Research Funds for the Central Universities of China.\n\n\u2217Corresponding Author\n\u00a92016 Springer Science + Business Media, LLC & Science Press, China\n\n\f""},""title"":{""0"":false},""topics"":{""0"":false},""type"":{""0"":false},""url"":{""0"":false},""user"":{""0"":""self.user""},""versions"":{""0"":false},""words"":{""0"":false},""year"":{""0"":false}}",2016,{},False,False,journalArticle,False,4DVV4NXW,[],self.user,"{""Unnamed: 0"":{""0"":0,""1"":1,""2"":2,""3"":3,""4"":4,""5"":5,""6"":6,""7"":7,""8"":8,""9"":9,""10"":10,""11"":11,""12"":12,""13"":13,""14"":14,""15"":15,""16"":16,""17"":17,""18"":18,""19"":19,""20"":20,""21"":21,""22"":22,""23"":23,""24"":24,""25"":25,""26"":26,""27"":27,""28"":28,""29"":29,""30"":30,""31"":31,""32"":32,""33"":33,""34"":34,""35"":35,""36"":36,""37"":37,""38"":38,""39"":39,""40"":40,""41"":41,""42"":42,""43"":43,""44"":44,""45"":45,""46"":46,""47"":47,""48"":48,""49"":49,""50"":50,""51"":51,""52"":52,""53"":53,""54"":54,""55"":55,""56"":56,""57"":57,""58"":58,""59"":59,""60"":60,""61"":61,""62"":62,""63"":63,""64"":64,""65"":65,""66"":66,""67"":67,""68"":68,""69"":69,""70"":70,""71"":71,""72"":72,""73"":73,""74"":74,""75"":75,""76"":76,""77"":77,""78"":78,""79"":79,""80"":80},""C"":{""0"":9.9699263096,""1"":10.8602832474,""2"":7.3516179998,""3"":10.680749275,""4"":97.3558729214,""5"":12.5384107816,""6"":7.9811755867,""7"":9.8097423938,""8"":10.3298099994,""9"":66.0027145314,""10"":8.2541530465,""11"":22.3052179143,""12"":10.6323684596,""13"":8.3610902583,""14"":11.6398621357,""15"":8.8316318593,""16"":21.6854130803,""17"":5.8854536284,""18"":7.3898645567,""19"":8.1968610046,""20"":15.7282147131,""21"":6.5818406161,""22"":13.5050161426,""23"":13.3141985735,""24"":13.4262638684,""25"":8.3561086903,""26"":11.6457315141,""27"":11.8456357478,""28"":9.2117689793,""29"":13.1973027245,""30"":9.2151832476,""31"":19.8206072583,""32"":24.5886366798,""33"":9.5727312213,""34"":8.8643294887,""35"":8.367108357,""36"":6.1168544467,""37"":10.0575909849,""38"":7.7415250288,""39"":6.102788046,""40"":7.7459788119,""41"":6.7043013254,""42"":6.7324451857,""43"":7.4874576917,""44"":21.4164561724,""45"":10.876356282,""46"":15.4916219038,""47"":17.7567773985,""48"":6.7575135366,""49"":7.1191945299,""50"":19.5919238342,""51"":6.8677368979,""52"":8.0261435839,""53"":17.851718807,""54"":7.1498723239,""55"":12.1162380133,""56"":6.2942766899,""57"":6.2963413514,""58"":6.2677975766,""59"":8.5987068891,""60"":8.6507498364,""61"":13.1138203602,""62"":11.2270336948,""63"":7.1194311196,""64"":9.6432883867,""65"":8.2556300388,""66"":9.494725205,""67"":6.2330544057,""68"":7.0694292703,""69"":9.3755591979,""70"":7.8551072852,""71"":8.0153088072,""72"":5.9474358486,""73"":5.9029399335,""74"":6.53955179,""75"":6.3195520121,""76"":6.3235741646,""77"":6.3235741646,""78"":6.5850023911,""79"":6.5560205368,""80"":6.5520151702},""count"":{""0"":144,""1"":130,""2"":124,""3"":118,""4"":108,""5"":88,""6"":84,""7"":76,""8"":74,""9"":74,""10"":72,""11"":72,""12"":70,""13"":70,""14"":68,""15"":68,""16"":66,""17"":62,""18"":62,""19"":58,""20"":58,""21"":50,""22"":50,""23"":50,""24"":44,""25"":44,""26"":42,""27"":42,""28"":34,""29"":34,""30"":32,""31"":32,""32"":32,""33"":30,""34"":28,""35"":28,""36"":28,""37"":28,""38"":28,""39"":26,""40"":26,""41"":26,""42"":26,""43"":26,""44"":26,""45"":26,""46"":26,""47"":26,""48"":24,""49"":24,""50"":24,""51"":22,""52"":22,""53"":22,""54"":20,""55"":20,""56"":18,""57"":16,""58"":16,""59"":16,""60"":16,""61"":16,""62"":14,""63"":14,""64"":14,""65"":12,""66"":12,""67"":12,""68"":12,""69"":12,""70"":12,""71"":10,""72"":10,""73"":8,""74"":8,""75"":8,""76"":8,""77"":8,""78"":8,""79"":8,""80"":8},""sigma_nor"":{""0"":1.790040342,""1"":1.9030593166,""2"":1.6208032141,""3"":1.9281318201,""4"":9.9185871061,""5"":2.2461922558,""6"":1.8033944127,""7"":2.0359984602,""8"":2.1047273745,""9"":8.1664884088,""10"":1.8891926528,""11"":3.4378462921,""12"":2.165458166,""13"":1.9119808257,""14"":2.2940338488,""15"":1.9765907834,""16"":3.4613924456,""17"":1.6690219326,""18"":1.8461201276,""19"":1.9679129275,""20"":2.8806000776,""21"":1.8206752604,""22"":2.7148478833,""23"":2.6902025676,""24"":2.796654703,""25"":2.1055969814,""26"":2.5834008276,""27"":2.6111794118,""28"":2.3520344463,""29"":2.9555436649,""30"":2.3838921873,""31"":4.0288760961,""32"":4.7684346152,""33"":2.4743963578,""34"":2.3964001797,""35"":2.3151714739,""36"":1.9475579491,""37"":2.5913377655,""38"":2.2129728325,""39"":1.969861787,""40"":2.245957941,""41"":2.070930699,""42"":2.0756595545,""43"":2.2025200831,""44"":4.542931793,""45"":2.7719377591,""46"":3.5474150284,""47"":3.9280164372,""48"":2.1097777606,""49"":2.1723875327,""50"":4.3315132637,""51"":2.1619287975,""52"":2.3689161022,""53"":4.1245770086,""54"":2.250099423,""55"":3.1680446661,""56"":2.1274089279,""57"":2.1665706948,""58"":2.1608821691,""59"":2.6254120924,""60"":2.6357837985,""61"":3.5252348796,""62"":3.2339704297,""63"":2.3800473714,""64"":2.904728101,""65"":2.681440172,""66"":2.9511272702,""67"":2.2412297926,""68"":2.4232654556,""69"":2.9251909777,""70"":2.5942670298,""71"":2.6975802641,""72"":2.2244402902,""73"":2.2594369616,""74"":2.413237354,""75"":2.3600871467,""76"":2.3610588669,""77"":2.3610588669,""78"":2.42421786,""79"":2.4172160731,""80"":2.4162484082},""vocab_index"":{""0"":1,""1"":2,""2"":3,""3"":4,""4"":6,""5"":8,""6"":10,""7"":12,""8"":13,""9"":14,""10"":16,""11"":17,""12"":18,""13"":19,""14"":20,""15"":21,""16"":23,""17"":24,""18"":25,""19"":29,""20"":30,""21"":35,""22"":36,""23"":37,""24"":39,""25"":42,""26"":44,""27"":45,""28"":53,""29"":55,""30"":56,""31"":58,""32"":59,""33"":60,""34"":62,""35"":63,""36"":64,""37"":65,""38"":68,""39"":71,""40"":73,""41"":77,""42"":78,""43"":79,""44"":80,""45"":83,""46"":84,""47"":85,""48"":86,""49"":90,""50"":92,""51"":93,""52"":102,""53"":103,""54"":104,""55"":112,""56"":120,""57"":144,""58"":145,""59"":147,""60"":148,""61"":149,""62"":180,""63"":181,""64"":182,""65"":204,""66"":206,""67"":208,""68"":209,""69"":210,""70"":211,""71"":253,""72"":256,""73"":311,""74"":315,""75"":316,""76"":317,""77"":318,""78"":336,""79"":337,""80"":340},""word"":{""0"":""1"",""1"":""interaction"",""2"":""user"",""3"":""d"",""4"":""cid"",""5"":""r"",""6"":""observation"",""7"":""gtm"",""8"":""p"",""9"":""174"",""10"":""users"",""11"":""documents"",""12"":""level"",""13"":""c"",""14"":""visual"",""15"":""ppca"",""16"":""figure"",""17"":""model"",""18"":""mds"",""19"":""w"",""20"":""j"",""21"":""g"",""22"":""ri"",""23"":""m"",""24"":""models"",""25"":""k"",""26"":""methods"",""27"":""document"",""28"":""represents"",""29"":""\u03c3d"",""30"":""statistical"",""31"":""group"",""32"":""doc"",""33"":""layout"",""34"":""interactive"",""35"":""analysis"",""36"":""paper"",""37"":""sensemaking"",""38"":""7"",""39"":""process"",""40"":""keywords"",""41"":""feedback"",""42"":""f"",""43"":""di"",""44"":""\u03b7"",""45"":""groups"",""46"":""\u03c6"",""47"":""a"",""48"":""analytics"",""49"":""variance"",""50"":""sat"",""51"":""parameter"",""52"":""exp"",""53"":""impi"",""54"":""analytic"",""55"":""income"",""56"":""linear"",""57"":""variables"",""58"":""\u03b4"",""59"":""uggtm"",""60"":""entities"",""61"":""\u03b4i"",""62"":""proposals"",""63"":""words"",""64"":""proceedings"",""65"":""features"",""66"":""individuals"",""67"":""tag"",""68"":""treatments"",""69"":""magnification"",""70"":""2005"",""71"":""scores"",""72"":""gk"",""73"":""states"",""74"":""1b"",""75"":""upper"",""76"":""50"",""77"":""quantiles"",""78"":""o"",""79"":""cost"",""80"":""fodava""},""vector"":{""0"":""[-0.4373649  -0.9824084  -2.5706658  -0.37745488  0.22427553 -0.47780344\n -1.5875137  -2.4298089   0.83580506  1.9139477 ]"",""1"":""[ 0.24979551 -1.2184464  -2.5199492  -0.6807545   1.5312382  -0.5355266\n -1.9871715  -2.5012689  -1.7959198   3.4668477 ]"",""2"":""[ 1.1991677  -1.8085966  -3.2485397   0.1918882   1.1623255  -0.36305273\n -2.4495673  -2.069114   -0.84440327  3.4091704 ]"",""3"":""[-0.7107459  -1.3137887  -3.0034437  -0.4999703   0.5901887  -0.22754672\n -1.5550922  -2.5364954   1.3338587   1.2389281 ]"",""4"":""[-0.7050667  -1.7692937  -3.0058913  -0.15407442  0.71982574 -0.44044426\n -1.7165654  -2.401539    1.2324662   1.4428499 ]"",""5"":""[-0.65462863 -1.6582047  -2.9164035  -0.493086    0.59359586 -0.43191326\n -1.1639366  -2.2549956   1.3514692   1.5450273 ]"",""6"":""[ 0.44459036 -1.1243492  -2.3975337  -0.72543764  1.3045771  -0.77408904\n -2.2125418  -2.5075486  -1.7160093   3.4719372 ]"",""7"":""[-0.3085919  -2.0142643  -2.5889678  -0.35967073  1.4133347  -0.5833371\n -1.4815587  -2.2735426  -0.18139605  2.696274  ]"",""8"":""[-0.7337892  -1.5327882  -3.0083747  -0.485297    0.8431663  -0.29351094\n -1.6239358  -2.3561897   1.0379502   1.4623234 ]"",""9"":""[-0.17119625 -0.96273196 -2.6187408  -0.56672466  0.12034151 -0.503687\n -1.5350498  -2.3783133   0.6908967   1.9223112 ]"",""10"":""[ 1.3885974 -1.6337878 -3.0724423  0.3832742  1.1650956 -0.3854268\n -2.5043163 -1.9428276 -0.9691336  3.424174 ]"",""11"":""[ 1.4140388  -2.042506   -2.8141751  -0.09912198  1.321576   -0.8229493\n -2.7132876  -1.962458   -1.4900666   3.6339478 ]"",""12"":""[ 0.4534208  -1.0688343  -2.2941966  -0.42335877  0.6288508  -0.72935075\n -2.3406618  -2.2313163  -0.7484261   2.960344  ]"",""13"":""[-0.7400214  -1.4447076  -2.8126862  -0.32089493  0.4570627  -0.42410216\n -1.4915422  -2.2896073   1.3511211   1.506254  ]"",""14"":""[-0.03469533 -1.0977888  -2.5700908  -0.8120333   1.3490984  -0.5065592\n -1.9815089  -2.802212   -1.4119956   3.2679906 ]"",""15"":""[-0.43150946 -2.06393    -2.5685186  -0.40395677  1.4182051  -0.81470317\n -1.6128881  -2.341933    0.04630278  2.6792226 ]"",""16"":""[ 0.85766506 -0.95080996 -2.7077212  -0.30993155  0.6684816  -0.5066442\n -2.331166   -2.0784802  -1.2518852   3.0509908 ]"",""17"":""[ 0.9788933  -1.0583953  -2.7488372  -0.40002418  1.1060724  -0.67390436\n -2.3160226  -2.2255754  -1.6976805   3.4386137 ]"",""18"":""[-0.5578823  -1.9076538  -2.6830122  -0.34279263  1.1823744  -0.64727515\n -1.6193174  -2.3399293   0.48826203  2.2865942 ]"",""19"":""[-0.43255395 -1.3635225  -2.7996416  -0.55865717  0.38760954 -0.4086524\n -1.2282645  -2.333326    1.2613137   1.5470375 ]"",""20"":""[-0.74310064 -1.9159464  -3.067095   -0.55082583  0.9674932  -0.30146575\n -1.0456649  -2.3100102   1.5509937   1.3143494 ]"",""21"":""[-0.63231784 -1.5594417  -2.9981623  -0.60759497  0.6556429  -0.195346\n -1.217851   -2.505192    1.5400605   1.1740364 ]"",""22"":""[-0.7389196  -1.8139721  -3.0804603  -0.6073231   1.0214392  -0.56569797\n -1.4104168  -2.1842244   1.192522    1.3160226 ]"",""23"":""[-0.84703314 -1.5471213  -3.0611825  -0.6391674   0.80692434 -0.29058012\n -1.2991439  -2.4750032   1.5074955   1.1415025 ]"",""24"":""[ 1.2005534  -1.202204   -2.7296162  -0.08736748  1.2187955  -0.75610566\n -2.4003537  -2.1927588  -1.3418877   3.5381453 ]"",""25"":""[-0.6574215  -1.7897065  -3.0893574  -0.6167085   0.940322   -0.35590366\n -1.2451819  -2.4164836   1.350464    1.2858615 ]"",""26"":""[ 1.1662897  -1.3880209  -2.4836607  -0.28608608  1.286027   -1.1162258\n -2.4456873  -2.1777363  -1.2548703   3.7163427 ]"",""27"":""[ 1.2882383  -1.8130448  -2.8651388  -0.2989121   1.2080854  -0.66086215\n -2.6943731  -2.0340445  -1.8680438   3.594826  ]"",""28"":""[ 0.72369134 -0.9554023  -2.8585536  -0.20890857  0.48730773 -0.25330478\n -2.2614977  -2.0421138  -0.89801586  2.753235  ]"",""29"":""[ 0.16964844 -2.328001   -2.610845   -0.23003098  1.8400174  -0.65139204\n -1.8640257  -2.1785593  -0.80719346  2.9703004 ]"",""30"":""[ 0.08327781 -1.5802333  -2.2652879  -0.8041276   1.2756647  -1.1071689\n -2.159693   -2.6294076  -0.96405756  3.3571515 ]"",""31"":""[ 0.65980566 -1.3606424  -2.7792351   0.07835969  0.9065642  -0.30750972\n -2.1442115  -2.051822   -0.6185816   3.0528598 ]"",""32"":""[ 1.2606999  -2.1295345  -3.1191325  -0.27829123  1.1866492  -0.6205723\n -2.7208016  -2.0409212  -1.5756226   3.4617727 ]"",""33"":""[ 0.8736694  -1.2188228  -2.8933165  -0.36628085  1.2029563  -0.39004916\n -2.4176288  -2.4288259  -1.6699872   3.4280891 ]"",""34"":""[ 0.01866779 -1.2402164  -2.509893   -0.75356174  1.409644   -0.58678675\n -1.9684404  -2.6714537  -1.4064589   3.3013766 ]"",""35"":""[ 0.39655885 -1.4833494  -2.242305   -0.71857     1.2518042  -1.0390558\n -2.2642443  -2.4175887  -1.3609515   3.447784  ]"",""36"":""[ 1.1835366  -1.8308696  -2.7059295  -0.40601835  1.2303207  -0.8243736\n -2.6660814  -2.0728462  -1.8458456   3.6322994 ]"",""37"":""[-0.2400235 -1.7349344 -2.374715  -0.7082598  1.6197243 -0.7666198\n -1.7042973 -2.47716   -1.0736458  3.142738 ]"",""38"":""[-0.15543473 -0.8893553  -2.488255   -0.48974854  0.2608688  -0.56369704\n -1.5525182  -2.456622    0.52725106  2.0864892 ]"",""39"":""[ 0.9800098  -1.5177819  -2.43642    -0.46397445  1.3417317  -0.9417141\n -2.399397   -2.091294   -1.728539    3.593072  ]"",""40"":""[ 1.2243577  -2.105264   -3.1629224  -0.15212755  1.3599108  -0.8552371\n -2.6076384  -2.3263845  -0.8852068   3.6334949 ]"",""41"":""[ 0.4389426  -1.2768077  -2.6020303  -0.5963034   1.4734172  -0.56809103\n -2.1211703  -2.466758   -1.7444302   3.484267  ]"",""42"":""[-0.43584725 -1.7013804  -2.9504921  -0.5187175   0.79116005 -0.18154845\n -1.2593925  -2.4312718   1.2337587   1.540912  ]"",""43"":""[-0.61291194 -1.4062212  -2.9897046  -0.39647183  0.4739547  -0.24951048\n -1.4259971  -2.560606    1.4605219   1.2912332 ]"",""44"":""[-0.5466467 -2.1770694 -3.251395  -0.3309761  1.2181277 -0.2991704\n -1.4820751 -2.0979538  0.7319004  1.758826 ]"",""45"":""[ 1.1962911  -1.6205251  -2.660923    0.25749955  0.9153071  -0.6070542\n -2.531601   -1.8894631  -0.72605234  3.267031  ]"",""46"":""[-0.62519825 -2.0026147  -3.1784012  -0.44247043  1.2737811  -0.26083565\n -1.5474348  -2.078972    0.71697253  1.8725917 ]"",""47"":""[ 0.05887245 -0.99760866 -2.6419482  -0.46957707  0.74853957 -0.36082706\n -1.9517878  -2.4465868  -0.5515661   2.748314  ]"",""48"":""[ 0.03633048 -1.7640672  -2.3255062  -0.7370655   1.560226   -0.9739315\n -1.989945   -2.5377414  -1.2020465   3.3952937 ]"",""49"":""[ 0.27845702 -1.676715   -2.406653   -0.66731346  1.1582853  -1.1344913\n -2.2978523  -2.533934   -0.68375385  3.248331  ]"",""50"":""[ 0.48461974 -0.97248214 -2.8282206  -0.3078435   0.39261398 -0.26359665\n -2.148076   -2.0969615  -0.5733193   2.5289207 ]"",""51"":""[ 0.86920947 -1.8862283  -3.3094523  -0.2768438   1.2795027  -0.75180405\n -2.3533232  -2.402513   -0.68175536  3.386727  ]"",""52"":""[-0.7387441  -1.8098557  -2.9674726  -0.448281    1.1089554  -0.39751887\n -1.5184078  -2.2854898   0.9262025   1.7469296 ]"",""53"":""[-0.54835474 -2.229948   -2.7410717  -0.3623623   1.5069796  -0.65962666\n -1.367566   -2.205519    0.26277512  2.4298837 ]"",""54"":""[-0.03985991 -1.5978707  -2.2626264  -0.80850166  1.4526227  -0.9404374\n -1.9616327  -2.5577385  -1.2097569   3.308026  ]"",""55"":""[ 0.5616083  -1.2194089  -2.291132   -0.58364576  0.7553168  -0.9618761\n -2.4218726  -2.2451053  -1.0285707   3.1179216 ]"",""56"":""[-0.06741744 -1.129527   -2.5369523  -0.74599326  1.142011   -0.5722764\n -1.9885734  -2.7064018  -1.0010816   3.0699337 ]"",""57"":""[ 0.9244397 -1.7286823 -2.9006872 -0.2300613  1.2467545 -0.9368348\n -2.4369433 -2.394789  -0.7048849  3.4587102]"",""58"":""[-0.53584707 -2.1344135  -3.215208   -0.3157948   1.1896774  -0.25113526\n -1.5369848  -2.0390456   0.66696364  1.8076487 ]"",""59"":""[-0.48177812 -2.10575    -2.728902   -0.401747    1.4330847  -0.57906497\n -1.3790783  -2.259826    0.12289643  2.4488926 ]"",""60"":""[ 1.3244885  -1.7551397  -2.7935529   0.40377936  1.1387984  -0.56790483\n -2.5151794  -1.7965248  -0.97231317  3.402678  ]"",""61"":""[ 0.41250038 -2.303409   -2.6657546  -0.19546294  1.7648178  -0.7272017\n -2.0306752  -2.1181204  -0.9397816   3.1014223 ]"",""62"":""[ 1.245325   -1.7047194  -2.5113018  -0.27768123  1.245763   -0.99882054\n -2.6033957  -2.0291069  -1.4669839   3.6093524 ]"",""63"":""[ 1.4097983  -1.9531205  -2.8885915  -0.02267332  1.1937131  -0.84122545\n -2.7049963  -2.077934   -1.0182854   3.5773044 ]"",""64"":""[ 1.0897574 -1.8493502 -2.4537625 -0.3850749  1.3900595 -1.0299276\n -2.5263424 -1.9958392 -1.6195135  3.5929358]"",""65"":""[ 1.0555038  -1.2785527  -2.8985953  -0.16111936  1.074352   -0.42604336\n -2.500883   -2.336128   -1.3051846   3.379119  ]"",""66"":""[ 1.2655066  -1.6942303  -2.7378051   0.410654    0.9839837  -0.54222417\n -2.5281174  -1.7718885  -0.79070646  3.279066  ]"",""67"":""[ 1.1679218  -2.0391364  -3.313238   -0.12715332  1.250815   -0.6134574\n -2.5012238  -2.220676   -0.89229196  3.5382931 ]"",""68"":""[ 1.2229574  -1.5001885  -2.5271094  -0.20522708  1.1197786  -1.0044817\n -2.5997627  -2.1787574  -1.1435773   3.5173068 ]"",""69"":""[ 0.13056381 -1.0141364  -2.6622238  -0.7516441   1.1656692  -0.48602438\n -2.1364765  -2.7346532  -1.3011026   3.1030757 ]"",""70"":""[-0.02464239 -0.9230525  -2.594487   -0.6105422   0.08823191 -0.56892157\n -1.4918326  -2.376979    0.5797902   1.9915324 ]"",""71"":""[ 0.96524197 -1.4925163  -2.4722712  -0.15550712  0.84092265 -0.84547955\n -2.5384138  -2.1360729  -0.72656465  3.219006  ]"",""72"":""[-0.750905  -1.9828612 -3.0350358 -0.5937531  1.2002591 -0.3747351\n -1.0919033 -2.4043517  1.2499602  1.5256658]"",""73"":""[ 1.3704172  -1.5518098  -2.747102    0.38845     0.95676535 -0.49972156\n -2.5465717  -1.7871898  -0.98687935  3.2838964 ]"",""74"":""[-0.5366764  -1.1335955  -2.6855817  -0.36806813  0.26707911 -0.43888655\n -1.5847706  -2.3752775   1.0275886   1.7437547 ]"",""75"":""[ 0.0860091  -0.9941689  -2.4545665  -0.4486474   0.47306684 -0.5551736\n -2.0408406  -2.3303747  -0.17080368  2.5194056 ]"",""76"":""[-0.27235436 -0.89692163 -2.5543127  -0.49017623  0.11486408 -0.36444694\n -1.7345906  -2.313007    0.53576994  2.0720897 ]"",""77"":""[ 0.13130714 -1.7641859  -2.5080745  -0.63869566  1.2428192  -1.0818694\n -2.1663194  -2.5749235  -0.50504696  3.1820636 ]"",""78"":""[-0.51964223 -1.5423808  -2.9570699  -0.45900938  0.47015333 -0.33512706\n -1.2391031  -2.3940685   1.5286995   1.3124677 ]"",""79"":""[ 0.7450865  -1.2138491  -2.3044267  -0.5795054   0.81259006 -1.0060617\n -2.486154   -2.1713107  -1.198222    3.1940768 ]"",""80"":""[-0.4960248  -2.1941552  -2.9133909  -0.4411542   1.4608692  -0.4991543\n -1.4010385  -2.2130487   0.26421666  2.2611673 ]""},""topic"":{""0"":1,""1"":3,""2"":-1,""3"":2,""4"":-1,""5"":2,""6"":3,""7"":0,""8"":2,""9"":1,""10"":5,""11"":4,""12"":-1,""13"":2,""14"":3,""15"":0,""16"":-1,""17"":-1,""18"":0,""19"":2,""20"":2,""21"":2,""22"":2,""23"":2,""24"":4,""25"":2,""26"":4,""27"":4,""28"":-1,""29"":-1,""30"":3,""31"":-1,""32"":-1,""33"":-1,""34"":3,""35"":3,""36"":4,""37"":-1,""38"":1,""39"":4,""40"":5,""41"":-1,""42"":2,""43"":2,""44"":-1,""45"":5,""46"":0,""47"":-1,""48"":3,""49"":-1,""50"":-1,""51"":-1,""52"":2,""53"":0,""54"":3,""55"":-1,""56"":-1,""57"":-1,""58"":-1,""59"":0,""60"":5,""61"":-1,""62"":4,""63"":5,""64"":4,""65"":-1,""66"":5,""67"":5,""68"":4,""69"":-1,""70"":1,""71"":-1,""72"":-1,""73"":5,""74"":1,""75"":-1,""76"":1,""77"":-1,""78"":2,""79"":-1,""80"":0},""exemplar"":{""0"":""*"",""1"":""*"",""2"":null,""3"":null,""4"":null,""5"":""*"",""6"":null,""7"":""*"",""8"":null,""9"":""*"",""10"":""*"",""11"":""*"",""12"":null,""13"":""*"",""14"":""*"",""15"":""*"",""16"":null,""17"":null,""18"":""*"",""19"":null,""20"":null,""21"":""*"",""22"":null,""23"":null,""24"":""*"",""25"":""*"",""26"":""*"",""27"":null,""28"":null,""29"":null,""30"":""*"",""31"":null,""32"":null,""33"":null,""34"":""*"",""35"":""*"",""36"":""*"",""37"":null,""38"":""*"",""39"":""*"",""40"":""*"",""41"":null,""42"":null,""43"":""*"",""44"":null,""45"":""*"",""46"":null,""47"":null,""48"":""*"",""49"":null,""50"":null,""51"":null,""52"":null,""53"":""*"",""54"":""*"",""55"":null,""56"":null,""57"":null,""58"":null,""59"":""*"",""60"":""*"",""61"":null,""62"":""*"",""63"":""*"",""64"":null,""65"":null,""66"":""*"",""67"":""*"",""68"":null,""69"":null,""70"":""*"",""71"":null,""72"":null,""73"":""*"",""74"":""*"",""75"":null,""76"":""*"",""77"":null,""78"":""*"",""79"":null,""80"":""*""},""word*"":{""0"":""1*"",""1"":""interaction*"",""2"":""user"",""3"":""d"",""4"":""cid"",""5"":""r*"",""6"":""observation"",""7"":""gtm*"",""8"":""p"",""9"":""174*"",""10"":""users*"",""11"":""documents*"",""12"":""level"",""13"":""c*"",""14"":""visual*"",""15"":""ppca*"",""16"":""figure"",""17"":""model"",""18"":""mds*"",""19"":""w"",""20"":""j"",""21"":""g*"",""22"":""ri"",""23"":""m"",""24"":""models*"",""25"":""k*"",""26"":""methods*"",""27"":""document"",""28"":""represents"",""29"":""\u03c3d"",""30"":""statistical*"",""31"":""group"",""32"":""doc"",""33"":""layout"",""34"":""interactive*"",""35"":""analysis*"",""36"":""paper*"",""37"":""sensemaking"",""38"":""7*"",""39"":""process*"",""40"":""keywords*"",""41"":""feedback"",""42"":""f"",""43"":""di*"",""44"":""\u03b7"",""45"":""groups*"",""46"":""\u03c6"",""47"":""a"",""48"":""analytics*"",""49"":""variance"",""50"":""sat"",""51"":""parameter"",""52"":""exp"",""53"":""impi*"",""54"":""analytic*"",""55"":""income"",""56"":""linear"",""57"":""variables"",""58"":""\u03b4"",""59"":""uggtm*"",""60"":""entities*"",""61"":""\u03b4i"",""62"":""proposals*"",""63"":""words*"",""64"":""proceedings"",""65"":""features"",""66"":""individuals*"",""67"":""tag*"",""68"":""treatments"",""69"":""magnification"",""70"":""2005*"",""71"":""scores"",""72"":""gk"",""73"":""states*"",""74"":""1b*"",""75"":""upper"",""76"":""50*"",""77"":""quantiles"",""78"":""o*"",""79"":""cost"",""80"":""fodava*""},""pos"":{""0"":1,""1"":1,""2"":1,""3"":1,""4"":2,""5"":2,""6"":2,""7"":1,""8"":3,""9"":2,""10"":1,""11"":1,""12"":3,""13"":4,""14"":3,""15"":2,""16"":4,""17"":5,""18"":3,""19"":5,""20"":6,""21"":7,""22"":8,""23"":9,""24"":2,""25"":10,""26"":3,""27"":4,""28"":6,""29"":7,""30"":4,""31"":8,""32"":9,""33"":10,""34"":5,""35"":6,""36"":5,""37"":11,""38"":3,""39"":6,""40"":2,""41"":12,""42"":11,""43"":12,""44"":13,""45"":3,""46"":4,""47"":14,""48"":7,""49"":15,""50"":16,""51"":17,""52"":13,""53"":5,""54"":8,""55"":18,""56"":19,""57"":20,""58"":21,""59"":6,""60"":4,""61"":22,""62"":7,""63"":5,""64"":8,""65"":23,""66"":6,""67"":7,""68"":9,""69"":24,""70"":4,""71"":25,""72"":26,""73"":8,""74"":5,""75"":27,""76"":6,""77"":28,""78"":14,""79"":29,""80"":7},""x2D"":{""0"":-11.8468580246,""1"":8.0914316177,""2"":6.0490884781,""3"":-12.0751972198,""4"":-11.4290218353,""5"":-12.1548595428,""6"":7.9529356956,""7"":-9.2729568481,""8"":-11.0589284897,""9"":-11.8709115982,""10"":5.9095473289,""11"":7.2121620178,""12"":7.3607683182,""13"":-12.1335840225,""14"":7.7143507004,""15"":-9.3983430862,""16"":7.7576565742,""17"":8.2047128677,""18"":-9.5558261871,""19"":-11.8704690933,""20"":-11.5852050781,""21"":-11.9998674393,""22"":-11.3623323441,""23"":-11.9374475479,""24"":7.8090844154,""25"":-11.6127138138,""26"":7.764213562,""27"":7.5725779533,""28"":7.4842934608,""29"":6.1155853271,""30"":6.5664587021,""31"":6.8498888016,""32"":7.1572589874,""33"":8.2315206528,""34"":7.5798602104,""35"":7.1322054863,""36"":7.6516265869,""37"":6.9485807419,""38"":-11.7497205734,""39"":8.0923652649,""40"":6.5350747108,""41"":8.142373085,""42"":-11.6586751938,""43"":-12.1554832458,""44"":-10.444814682,""45"":6.2471284866,""46"":-10.3045864105,""47"":6.9253945351,""48"":6.8617739677,""49"":6.7277135849,""50"":7.1650519371,""51"":6.6201777458,""52"":-10.6970300674,""53"":-9.4030399323,""54"":6.8126864433,""55"":7.6724839211,""56"":7.4237327576,""57"":6.7802152634,""58"":-10.1191978455,""59"":-9.5709657669,""60"":5.8610768318,""61"":6.21301651,""62"":7.5057835579,""63"":6.7196927071,""64"":7.8085341454,""65"":7.916510582,""66"":5.7986044884,""67"":6.3420786858,""68"":7.4234347343,""69"":7.6250629425,""70"":-12.0096588135,""71"":7.1621785164,""72"":-11.173579216,""73"":5.9133234024,""74"":-11.8872070312,""75"":6.9108681679,""76"":-11.824464798,""77"":6.6243600845,""78"":-12.1959323883,""79"":7.8375496864,""80"":-9.4365358353},""y2D"":{""0"":-4.3525738716,""1"":-3.9500005245,""2"":-7.4040417671,""3"":-2.7418208122,""4"":-2.716912508,""5"":-2.3981790543,""6"":-4.1666250229,""7"":-1.902479887,""8"":-2.5465641022,""9"":-4.2193846703,""10"":-7.3013906479,""11"":-8.0235462189,""12"":-5.4539990425,""13"":-2.7769808769,""14"":-3.9176046848,""15"":-1.9261592627,""16"":-6.1250243187,""17"":-6.7891097069,""18"":-1.7609713078,""19"":-2.996733427,""20"":-2.1484026909,""21"":-2.0662353039,""22"":-1.9799593687,""23"":-2.1730217934,""24"":-7.0208673477,""25"":-2.0051145554,""26"":-7.3989019394,""27"":-8.1406602859,""28"":-6.0014967918,""29"":-4.2528676987,""30"":-4.0454249382,""31"":-6.2381215096,""32"":-8.1090536118,""33"":-6.5561571121,""34"":-4.10019207,""35"":-4.2164478302,""36"":-7.9706521034,""37"":-3.9098258018,""38"":-4.3224859238,""39"":-7.5372276306,""40"":-7.6270985603,""41"":-4.2194504738,""42"":-2.4281196594,""43"":-2.5774621964,""44"":-2.0551564693,""45"":-6.7478399277,""46"":-1.9547592402,""47"":-5.4412884712,""48"":-3.940513134,""49"":-4.4231591225,""50"":-5.7897119522,""51"":-7.1754865646,""52"":-2.1789813042,""53"":-2.0312054157,""54"":-3.9289264679,""55"":-5.3390440941,""56"":-4.5012750626,""57"":-7.1154203415,""58"":-1.7917119265,""59"":-1.6000124216,""60"":-7.0811090469,""61"":-4.40284729,""62"":-7.6247091293,""63"":-7.7250704765,""64"":-7.7758083344,""65"":-6.7284197807,""66"":-6.9490656853,""67"":-7.4454407692,""68"":-7.2879590988,""69"":-4.3743247986,""70"":-4.4240169525,""71"":-6.5936675072,""72"":-2.1131033897,""73"":-6.8556580544,""74"":-3.86951828,""75"":-5.5756163597,""76"":-4.5660910606,""77"":-4.3688650131,""78"":-2.3909635544,""79"":-5.6300697327,""80"":-1.6502684355}}",False,False,False,http://link.springer.com/10.1007/s11390-016-1663-1,,A Survey of Visual Analytic Pipelines,4DVV4NXW,False,False
7DLBYPHS,QF8T8QRU,"Visual Analytics: Definition, Process and Challenges
Daniel Keim, Gennady Andrienko, Jean-Daniel Fekete, Carsten Görg, Jörn

Kohlhammer, Guy Melançon

To cite this version:
Daniel Keim, Gennady Andrienko, Jean-Daniel Fekete, Carsten Görg, Jörn Kohlhammer, et al.. Vi-
sual Analytics: Definition, Process and Challenges. Andreas Kerren and John T. Stasko and Jean-
Daniel Fekete and Chris North. Information Visualization - Human-Centered Issues and Perspectives,
Springer, pp.154-175, 2008, LNCS. <lirmm-00272779>

HAL Id: lirmm-00272779

https://hal-lirmm.ccsd.cnrs.fr/lirmm-00272779

Submitted on 11 Apr 2008

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Visual Analytics:

Deﬁnition, Process, and Challenges

Daniel Keim1, Gennady Andrienko2, Jean-Daniel Fekete3, Carsten G¨org4,

J¨orn Kohlhammer5, and Guy Melan¸con6

1 Department of Computer and Information Science, University of Konstanz,

78457 Konstanz, Germany,

2 Fraunhofer Institute for Intelligent Analysis and Information Systems(IAIS),

keim@informatik.uni-konstanz.de

Schloss Birlinghoven 53754 Sankt Augustin, Germany,

gennady.andrienko@iais.fraunhofer.de
3 Universit´e Paris-Sud, INRIA, Bˆat 490,

4 School of Interactive Computing & GVU Center, Georgia Institute of Technology,

F-91405 Orsay Cedex, France,
Jean-Daniel.Fekete@inria.fr

85 5th St., NW, Atlanta, GA 30332-0760, USA,

5 Fraunhofer Institute for Computer Graphics Research,

goerg@cc.gatech.edu

Fraunhoferstraße 5, D-64283 Darmstadt, Germany,

joern.kohlhammer@igd.fraunhofer.de

6 INRIA Bordeaux – Sud-Ouest, CNRS UMR 5800 LaBRI,

Campus Universit´e Bordeaux I,

351 Cours de la lib´eration, 33405 Talence Cedex, France,

Guy.Melancon@labri.fr

1 Introduction and Motivation

We are living in a world which faces a rapidly increasing amount of data to be
dealt with on a daily basis. In the last decade, the steady improvement of data
storage devices and means to create and collect data along the way inﬂuenced our
way of dealing with information: Most of the time, data is stored without ﬁltering
and reﬁnement for later use. Virtually every branch of industry or business,
and any political or personal activity nowadays generate vast amounts of data.
Making matters worse, the possibilities to collect and store data increase at a
faster rate than our ability to use it for making decisions. However, in most
applications, raw data has no value in itself; instead we want to extract the
information contained in it.

The information overload problem refers to the danger of getting lost in

data which may be

– irrelevant to the current task at hand
– processed in an inappropriate way
– presented in an inappropriate way

A. Kerren et al. (Eds.): Information Visualization, LNCS 4950, pp. 154–175, 2008.
c(cid:1) Springer-Verlag Berlin Heidelberg 2008

Visual Analytics: Deﬁnition, Process, and Challenges

155

Due to information overload, time and money are wasted, scientiﬁc and in-
dustrial opportunities are lost because we still lack the ability to deal with the
enormous data volumes properly. People in both their business and private lives,
decision-makers, analysts, engineers, emergency response teams alike, are often
confronted with massive amounts of disparate, conﬂicting and dynamic infor-
mation, which are available from multiple heterogeneous sources. We want to
simply and eﬀectively exploit and use the hidden opportunities and knowledge
resting in unexplored data sources.

In many application areas success depends on the right information being
available at the right time. Nowadays, the acquisition of raw data is no longer
the driving problem: It is the ability to identify methods and models, which can
turn the data into reliable and provable knowledge. Any technology, that claims
to overcome the information overload problem, has to provide answers for the
following problems:

– Who or what deﬁnes the “relevance of information” for a given task?
– How can appropriate procedures in a complex decision making process be

identiﬁed?

way?

ing?

– How can the resulting information be presented in a decision- or task-oriented

– What kinds of interaction can facilitate problem solving and decision mak-

With every new “real-life” application, procedures are put to the test possibly
under circumstances completely diﬀerent from the ones under which they have
been established. The awareness of the problem how to understand and analyse
our data has been greatly increased in the last decade. Even as we implement
more powerful tools for automated data analysis, we still face the problem of un-
derstanding and “analysing our analyses” in the future: Fully-automated search,
ﬁlter and analysis only work reliably for well-deﬁned and well-understood prob-
lems. The path from data to decision is typically quite complex. Even as fully-
automated data processing methods represent the knowledge of their creators,
they lack the ability to communicate their knowledge. This ability is crucial: If
decisions that emerge from the results of these methods turn out to be wrong,
it is especially important to examine the procedures.

The overarching driving vision of visual analytics is to turn the information
overload into an opportunity: Just as information visualization has changed our
view on databases, the goal of Visual Analytics is to make our way of processing
data and information transparent for an analytic discourse. The visualization of
these processes will provide the means of communicating about them, instead
of being left with the results. Visual Analytics will foster the constructive eval-
uation, correction and rapid improvement of our processes and models and -
ultimately - the improvement of our knowledge and our decisions (see Figure 1).
On a grand scale, visual analytics solutions provide technology that combines
the strengths of human and electronic data processing. Visualization becomes
the medium of a semi-automated analytical process, where humans and machines
cooperate using their respective distinct capabilities for the most eﬀective results.

156

D. Keim et al.

Fig. 1. Tight integration of visual and automatic data analysis methods with database
technology for a scalable interactive decision support.

The user has to be the ultimate authority in giving the direction of the analysis
along his or her speciﬁc task. At the same time, the system has to provide
eﬀective means of interaction to concentrate on this speciﬁc task. On top of
that, in many applications diﬀerent people work along the path from data to
decision. A visual representation will sketch this path and provide a reference
for their collaboration across diﬀerent tasks and abstraction levels.

The diversity of these tasks can not be tackled with a single theory. Visual
analytics research is highly interdisciplinary and combines various related re-
search areas such as visualization, data mining, data management, data fusion,
statistics and cognition science (among others). Visualization has to continuously
challenge the perception by many of the applying sciences that visualization is
not a scientiﬁc discipline in its own right. Even if the awareness exists, that
scientiﬁc analysis and results must be visualized in one way or the other, this
often results in ad hoc solutions by application scientists, which rarely match
the state of the art in interactive visualization science, much less the full com-
plexity of the problems. In fact, all related research areas in the context of visual
analytics research conduct rigorous, serious science each in a vibrant research
community. To increase the awareness of their work and their implications for
visual analytics research clearly emerges as one main goal of the international
visual analytics community (see Figure 2).

Because visual analytics research can be regarded as an integrating discipline,
application speciﬁc research areas should contribute with their existing proce-
dures and models. Emerging from highly application-oriented research, dispersed
research communities worked on speciﬁc solutions using the repertoire and stan-
dards of their speciﬁc ﬁelds. The requirements of visual analytics introduce new
dependencies between these ﬁelds.

Visual Analytics: Deﬁnition, Process, and Challenges

157

Fig. 2. Visual analytics integrates scientiﬁc disciplines to improve the division of labor
between human and machine.

2 Deﬁnition of Visual Analytics

In “Illuminating the Path” [39], Thomas and Cook deﬁne visual analytics as the
science of analytical reasoning facilitated by interactive visual interfaces. In this
chapter, however, we would like to give a more speciﬁc deﬁnition:

Visual analytics combines automated analysis techniques with interactive
visualizations for an eﬀective understanding, reasoning and decision making on
the basis of very large and complex data sets.

The goal of visual analytics is the creation of tools and techniques to enable

people to:

– Synthesize information and derive insight from massive, dynamic, ambigu-

ous, and often conﬂicting data.

– Detect the expected and discover the unexpected.
– Provide timely, defensible, and understandable assessments.
– Communicate assessment eﬀectively for action.

By integrating selected science and technology from the above discussed disci-
plines and as illustrated in Figure 2, there is the promising opportunity to form
the unique and productive ﬁeld of visual analytics. Work in each of the partici-
pating areas focuses on diﬀerent theoretical and practical aspects of users solving
real-world problems using Information Technology in an eﬀective and eﬃcient
way. These areas have in common similar scientiﬁc challenges and signiﬁcant sci-
entiﬁc added-value from establishing close collaboration can be identiﬁed. Beneﬁt
of collaboration between the ﬁelds is identiﬁed to be two-fold:

– Jointly tackling common problems will arrive at better results on the local

level of each discipline, in a more eﬃcient way.

– Integrating appropriate results from each of the disciplines will lay the fun-
dament for signiﬁcantly improved solutions in many important data analysis
applications.

158

D. Keim et al.

Visual Analytics versus Information Visualization

Many people are confused by the new term visual analytics and do not see a dif-
ference between the two areas. While there is certainly some overlay and some of
the information visualization work is certainly highly related to visual analytics,
traditional visualization work does not necessarily deal with an analysis tasks
nor does it always also use advanced data analysis algorithms.

Visual analytics is more than just visualization. It can rather be seen as an
integral approach to decision-making, combining visualization, human factors
and data analysis. The challenge is to identify the best automated algorithm for
the analysis task at hand, identify its limits which can not be further automated,
and then develop a tightly integrated solution with adequately integrates the best
automated analysis algorithms with appropriate visualization and interaction
techniques.

While some of such research has been done within the visualization commu-
nity in the past, the degree to which advanced knowledge discovery algorithms
have been employed is quite limited. The idea of visual analytics is to funda-
mentally change that. This will help to focus on the right part of the problem,
i.e. the parts that can not be solved automatically, and will provide solutions to
problems that we were not able to solve before.

One important remark should be made here. Most research eﬀorts in Infor-
mation Visualization have concentrated on the process of producing views and
creating valuable interaction techniques for a given class of data (social network,
multi-dimensional data, etc.). However, much less has been suggested as to how
user interactions on the data can be turned into intelligence to tune underlying
analytical processes. A system might for instance observe that most of the user’s
attention concern only a subpart of an ontology (through queries or by repeated
direct manipulations of the same graphical elements, for instance). Why not then
use this knowledge about the user’s interest and update various parameters by
the system (trying to systematically place elements or components of interest in
center view, even taking this fact into account when driving a clustering algo-
rithm with a modularity quality criteria, for instance).

This is one place where Visual Analytics maybe diﬀers most from Information
Visualization, giving higher priority to data analytics from the start and through
all iterations of the sense making loop. Creativity is then needed to understand
how perception issues can help bring more intelligence into the analytical process
by “learning” from users’ behavior and eﬀective use of the visualization.

3 Areas Related to Visual Analytics

Visual analytics builds on a variety of related scientiﬁc ﬁelds. At its heart, Visual
Analytics integrates Information and Scientiﬁc Visualization with Data Manage-
ment and Data Analysis Technology, as well as Human Perception and Cognition
research. For eﬀective research, Visual Analytics also requires an appropriate In-
frastructure in terms of software and data sets and related analytical problems
repositories, and to develop reliable Evaluation methodology (see Figure 3).

Visual Analytics: Deﬁnition, Process, and Challenges

159

Fig. 3. Visual Analytics integrates Scientiﬁc and Information Visualization with core
adjacent disciplines: Data management and analysis, spatio-temporal data, and human
perception and cognition. Successful Visual Analytics research also depends on the
availability of appropriate infrastructure and evaluation facilities.

An example for a common problem in several of the disciplines is that of scalabil-
ity with data size. The larger the data set to be handled gets, the more diﬃcult
it gets to manage, analyze, and visualize these data eﬀectively. Researching ap-
propriate forms to represent large data volumes by smaller volumes containing
the most relevant information beneﬁts each of the data management, analy-
sis, and visualization ﬁelds. On top of these individual progresses, a synergetic
collaboration of all these ﬁelds may lead to signiﬁcantly improved processing
results. Consider a very large data stream. Appropriate data management tech-
nology gives eﬃcient access to the stream, which is intelligently processed and
abstracted by an automatic analysis algorithm which has an interface to the
data management layer. On top of the analysis output, an interactive visual-
ization which is optimized for eﬃcient human perception of the relevant infor-
mation allows the analyst to consume the analysis results, and adapt relevant
parameters of the data aggregation an analysis engines as appropriate. The com-
bination of the individual data handling steps into a Visual Analytics pipeline
leads to improved results and makes data domains accessible which are not ef-
fectively accessible by any of the individual data handling disciplines. Similar
argumentations apply to other related ﬁelds and disciplines. In many ﬁelds, vi-
sualization is already used and developed independently as a means for analyzing
the problems at hand. However, a uniﬁed, interdisciplinary perspective on using
visualization for analytical problem-solving will show beneﬁcial for all involved
disciplines. As common principles, best practices, and theories will be developed,
these will become usable in the individual disciplines and application domains,
providing economies of scale, avoiding replication of work or application of only
sub-optimal techniques.

160

D. Keim et al.

3.1 Visualization

Visualization has emerged as a new research discipline during the last two dec-
ades. It can be broadly classiﬁed into Scientiﬁc and Information Visualization.
In Scientiﬁc Visualization, the data entities to be visualized are typically 3D
geometries or can be understood as scalar, vectorial, or tensorial ﬁelds with ex-
plicit references to time and space. A survey of current visualization techniques
can be found in [22,35,23]. Often, 3D scalar ﬁelds are visualized by isosurfaces or
semi-transparent point clouds (direct volume rendering) [15]. To this end, meth-
ods based on optical emission- or absorption models are used which visualize the
volume by ray-tracing or projection. Also, in the recent years signiﬁcant work
focused on the visualization of complex 3-dimensional ﬂow data relevant e.g.,
in aerospace engineering [40]. While current research has focused mainly on eﬃ-
ciency of the visualization techniques to enable interactive exploration, more and
more methods to automatically derive relevant visualization parameters come
into focus of research. Also, interaction techniques such as focus&context [28]
gain importance in scientiﬁc visualization.

Information Visualization during the last decade has developed methods
for the visualization of abstract data where no explicit spatial references are
given [38,8,24,41]. Typical examples include business data, demographics data,
network graphs and scientiﬁc data from e.g., molecular biology. The data con-
sidered often comprises hundreds of dimensions and does not have a natural
mapping to display space, and renders standard visualization techniques such as
(x, y) plots, line- and bar-charts ineﬀective. Therefore, novel visualization tech-
niques are being developed by employing e.g., Parallel Coordinates and their
numerous extensions [20], Treemaps [36], and Glyph [17]- and Pixel-based [25]
visual data representations. Data with inherent network structure may be visual-
ized using graph-based approaches. In many Visualization application areas, the
typically huge volumes of data require the appropriate usage of automatic data
analysis techniques such as clustering or classiﬁcation as preprocessing prior to
visualization. Research in this direction is just emerging.

3.2 Data Management

An eﬃcient management of data of various types and qualities is a key com-
ponent of Visual Analytics as this technology typically provides the input of
the data which are to be analyzed. Generally, a necessary precondition to per-
form any kind of data analysis is an integrated and consistent data basis [18,19].
Database research has until the last decade focused mainly on aspects of eﬃ-
ciency and scalability of exact queries on homogeneous, structured data. With
the advent of the Internet and the easy access it provides to all kinds of hetero-
geneous data sources, the database research focus has shifted toward integration
of heterogeneous data. Finding integrated representation of diﬀerent data types
such as numeric data, graphs, text, audio and video signals, semi-structured
data, semantic representations and so on is a key problem of modern database

Visual Analytics: Deﬁnition, Process, and Challenges

161

technology. But the availability of heterogeneous data not only requires the map-
ping of database schemata but includes also the cleaning and harmonization of
uncertainty and missing data in the volumes of heterogeneous data. Modern ap-
plications require such intelligent data fusion to be feasible in near real-time and
as automatically as possible [32]. New forms of information sources such as data
streams [11], sensor networks [30] or automatic extraction of information from
large document collections (e.g., text, HTML) result in a diﬃcult data analysis
problem which to support is currently in the focus of database research [43].
The relationship between Data Management, Data Analysis and Visualization
is characterized such that Data Management techniques developed increasingly
rely on intelligent data analysis techniques, and also interaction and visualiza-
tion to arrive at optimal results. On the other hand, modern database systems
provide the input data sources which are to be visually analyzed.

3.3 Data Analysis
Data Analysis (also known as Data Mining or Knowledge Discovery) researches
methods to automatically extract valuable information from raw data by means
of automatic analysis algorithms [29,16,31]. Approaches developed in this area
can be best described by the addressed analysis tasks. A prominent such task
is supervised learning from examples: Based on a set of training samples, deter-
ministic or probabilistic algorithms are used to learn models for the classiﬁcation
(or prediction) of previously unseen data samples [13]. A huge number of algo-
rithms have been developed to this end such as Decision Trees, Support Vector
Machines, Neuronal Networks, and so on. A second prominent analysis task is
that of cluster analysis [18,19], which aims to extract structure from data with-
out prior knowledge being available. Solutions in this class are employed to au-
tomatically group data instances into classes based on mutual similarity, and to
identify outliers in noisy data during data preprocessing for subsequent analysis
steps. Further data analysis tasks include tasks such as association rule mining
(analysis of co-occurrence of data items) and dimensionality reduction. While
data analysis initially was developed for structured data, recent research aims at
analyzing also semi-structured and complex data types such as web documents
or multimedia data [34].

It has recently been recognized that visualization and interaction are highly
beneﬁcial in arriving at optimal analysis results [9]. In almost all data analysis
algorithms a variety of parameters needs to be speciﬁed, a problem which is
usually not trivial and often needs supervision by a human expert. Visualization
is also a suitable means for appropriately communicating the results of the au-
tomatic analysis, which often is given in abstract representation, e.g., a decision
tree. Visual Data Mining methods [24] try to achieve exactly this.

3.4 Perception and Cognition
Eﬀective utilization of the powerful human perception system for visual analysis
tasks requires the careful design of appropriate human-computer interfaces. Psy-
chology, Sociology, Neurosciences and Design each contribute valuable results to

162

D. Keim et al.

the implementation of eﬀective visual information systems. Research in this area
focuses on user-centered analysis and modeling (Requirement Engineering), the
development of principles, methods and tools for design of perception-driven,
multimodal interaction techniques for visualization and exploration of large in-
formation spaces, as well as usability evaluation of such systems [21,12]. On the
technical side, research in this area is inﬂuenced by two main factors: (1.) The
availability of improved display resources (hardware), and (2.) Development of
novel interaction algorithms incorporating machine recognition of the actual user
intent and appropriate adaptation of main display parameters such as the level
of detail, data selection and aggregation, etc. by which the data is presented[44].
Important problems addressed in this area include the research of perceptual,
cognitive and graphical principles which in combination lead to improved visual
communication of data and analysis results; The development of perception-
theory-based solutions for the graphical representation of static and dynamic
structures; And development of visual representation of information at several
levels of abstraction, and optimization of existing focus-and-context techniques.

3.5 Human-Computer Interaction

Human-computer interaction is the research area that studies the interaction
between people and computers. It involves the design, implementation and eval-
uation of interactive systems in the context of the user’s task and work [12].
Like visual analytics itself, human-computer interaction is a multi-disciplinary
research area that draws on many other disciplines: computer science, system
design, and behavioral science are some of them. The basic underlying research
goal is to improve the interaction between users and computers: how to make
computers more receptive to the users’ intentions and needs. Thus, the research
areas discussed in the previous section about perception and cognition are also
much related to human-computer interaction [21].

As pointed out in the introduction, visual analytics aims to combine and
integrate the strengths of computers and humans into an interactive process to
extract knowledge from data. To eﬀectively switch back and forth between tasks
for the computer and tasks for the human it is crucial to develop an eﬀective
user interface that minimizes the barrier between the human’s cognitive model
of what they want to accomplish and the computer’s understanding of the hu-
man’s task. The design of user interfaces focuses on human factors of interactive
software, methods to develop and assess interfaces, interaction styles, and design
considerations such as eﬀective messages and appropriate color choice [37].

3.6 Infrastructure and Evaluation

The above described research disciplines require cross-discipline support regard-
ing the evaluation of the found solutions, and need certain infrastructure and
standardization grounding to build on eﬀectively. In the ﬁeld of information vi-
sualization, standardization and evaluation came into the focus of research only
recently. It has been realized that a general understanding of the taxonomies

Visual Analytics: Deﬁnition, Process, and Challenges

163

regarding the main data types and user tasks [2] to be supported are highly de-
sirable for shaping visual analytics research. A common understanding of data
and problem dimensions and structure, and acceptance of evaluation standards
will make research results better comparable, optimizing research productivity.
Also, there is an obvious need to build repositories of available analysis and vi-
sualization algorithms, which researchers can build upon in their work, without
having to re-implement already proven solutions.

How to assess the value of visualization is a topic of lively debate [42,33]. A
common ground that can be used to position and compare future developments
in the ﬁeld of data analysis is needed. The current diversiﬁcation and dispersion
of visual analytics research and development resulted from its focus onto speciﬁc
application areas. While this approach may suit the requirements of each of
these applications, a more rigorous and overall scientiﬁc perspective will lead to
a better understanding of the ﬁeld and a more eﬀective and eﬃcient development
of innovative methods and techniques.

3.7 Sub-communities

Spatio-Temporal Data: While many diﬀerent data types exist, one of the
most prominent and ubiquitous data types is data with references to time and
space. The importance of this data type has been recognized by a research
community which formed around spatio-temporal data management and anal-
ysis [14]. In geospatial data research, data with references in the real world
coming from e.g., geographic measurements, GPS position data, remote sensing
applications, and so on is considered. Finding spatial relationships and patterns
among this data is of special interest, requiring the development of appropriate
management, representation and analysis functions. E.g., developing eﬃcient
data structures or deﬁning distance and similarity functions is in the focus of re-
search. Visualization often plays a key role in the successful analysis of geospatial
data [6,26].

In temporal data, the data elements can be regarded as a function of time.
Important analysis tasks here include the identiﬁcation of patterns (either lin-
ear or periodical), trends and correlations of the data elements over time, and
application-dependent analysis functions and similarity metrics have been pro-
posed in ﬁelds such as ﬁnance, science, engineering, etc. Again, visualization of
time-related data is important to arrive at good analysis results [1].

The analysis of data with references both in space and in time is a chal-
lenging research topic. Major research challenges include [4]: scale, as it is often
necessary to consider spatio-temporal data at diﬀerent spatio-temporal scales;
the uncertainty of the data as data are often incomplete, interpolated, collected
at diﬀerent times, or based upon diﬀerent assumptions; complexity of geograph-
ical space and time, since in addition to metric properties of space and time
and topological/temporal relations between objects, it is necessary to take into
account the heterogeneity of the space and structure of time; and complexity of
spatial decision making processes, because a decision process may involve hetero-

164

D. Keim et al.

geneous actors with diﬀerent roles, interests, levels of knowledge of the problem
domain and the territory.

Network and Graph Data: Graphs appear as ﬂexible and powerful math-
ematical tools to model real-life situations. They naturally map to transporta-
tion networks, electric power grids, and they are also used as artifacts to study
complex data such as observed interactions between people, or induced interac-
tions between various biological entities. Graphs are successful at turning seman-
tic proximity into topological connectivity, making it possible to address issues
based on algorithmics and combinatorial analysis.

Graphs appear as essential modeling and analytical objects, and as eﬀective
visual analytics paradigms. Major research challenges are to produce scalable
analytical methods to identify key components both structurally and visually.
Eﬀorts are needed to design process capable of dealing with large datasets while
producing readable and usable graphical representations, allowing proper user
interaction. Special eﬀorts are required to deal with dynamically changing net-
works, in order to assess of structural changes at various scales.

4 The Visual Analytics Process

A number of systems for information visualization, as well as speciﬁc visual-
ization techniques, motivate their design choice from Shneiderman’s celebrated
mantra “Overview ﬁrst, Filter and zoom, Details on demand”. As is, the mantra
clearly emphasizes the role of visualization in the knowledge discovery process.
Recently, Keim adjusted the mantra to bring its focus toward Visual Analytics:
“Analyze ﬁrst, Show the Important, Zoom, ﬁlter and analyze further, Details
on demand”. In other words, this mantra is calling for astute combinations of
analytical approaches together with advanced visualization techniques.

The computation of any visual representation and/or geometrical embedding
of large and complex datasets requires some analysis to start with. Many scalable
graph drawing algorithms try to take advantage of any knowledge on topology
to optimize the drawing in terms of readability. Other approaches oﬀer repre-
sentations composed of visual abstractions of clusters to improve readability.
The challenge then is to try to come up with a representation that is as faithful
as possible to avoid introducing uncertainty. We must not fall into the na¨ıve
assumption that visualization can oﬀer a virgin view on the data: any represen-
tation will inevitably favor an interpretation over all possible ones. The solution
oﬀered by Visual Analytics is then to let the user enter into a loop where data
can be interactively manipulated to help gain insight both on the data and the
representation itself.

The sense-making loop structures the whole knowledge discovery process
supported through Visual Analytics. A generic scenario can be given following a
schema developed by van Wijk [42], which furthermore admits to be evaluated
and measured in terms of eﬃciency or knowledge gained. A choice for an initial
representation and adequate interactions can be made after applying diﬀerent

Visual Analytics: Deﬁnition, Process, and Challenges

165

statistical and mathematical techniques, such as spatio-temporal data analysis or
link mining depending on the nature of the dataset under study. The process then
enters a loop where the user can gain knowledge on the data, ideally driving the
system toward more focused and more adequate analytical techniques. Dually,
interacting on the visual representation, the user will gain a better understanding
of the visualization itself commanding for diﬀerent views helping him or her to
go beyond the visual and ultimately conﬁrm hypotheses built from previous
iterations (see Figure 4).

Fig. 4. The sense-making loop for Visual Analytics based on the simple model of
visualization by Wijk [42].

5 Application Challenges

Visual Analytics is a highly application oriented discipline driven by practical
requirements in important domains. Without attempting a complete survey over
all possible application areas, we sketch the potential applicability of Visual
Analytics technology in a few key domains.

In the Engineering domain, Visual Analytics can contribute to speed-up de-
velopment time for products, materials, tools and production methods by oﬀering
more eﬀective, intelligent access to the wealth of complex information resulting
from prototype development, experimental test series, customers’ feedback, and
many other performance metrics. One key goal of applied Visual Analytics in
the engineering domain will be the analysis of the complexity of the production
systems in correlation with the achieved output, for an eﬃcient and eﬀective
improvement of the production environments.

Financial Analysis is a prototypical promising application area for Visual
Analytics. Analysts in this domain are confronted with streams of heterogeneous
information from diﬀerent sources available at high update rates, and of varying

166

D. Keim et al.

reliability. Arriving at a unifying, task-centered view on diverse streams of data
is a central goal in ﬁnancial information systems. Integrated analysis and visu-
alization of heterogeneous data types such as news feeds, real-time trading data,
and fundamental economic indicators poses a challenge for developing advanced
analysis solutions in this area. Research based on results from Information Vi-
sualization is regarded as promising in this case.

Socio-economic considerations often form the basis of political decision
processes. A modern society can be regarded as a complex system of interre-
lationships between political decisions and economic, cultural and demographic
eﬀects. Analysis and Visualization of these interrelationships is promising in de-
veloping a better understanding of these phenomena, and to arrive at better
decisions. Successful Visual Analytics applications in this domain could start
being developed based on currently existing Geo-Spatial analysis frameworks.

Public Safety & Security is another important application area where Vi-
sual Analytics may contribute with advanced solutions. Analysts need to con-
stantly monitor huge amounts of heterogeneous information streams, correlating
information of varying degrees of abstraction and reliability, assessing the cur-
rent level of public safety, triggering alert in case of alarming situations being
detected. Data integration and correlation combined with appropriate analysis
and interactive visualization is promising to develop more eﬃcient tools for the
analysis in this area.

The study of Environment and Climate change often requires the ex-
amination of long term weather records and logs of various sensors, in a search
for patterns that can be related to observations such as changes in animal pop-
ulations, or in meteorological and climatic processes for instance. These require-
ments call for the development of systems allowing visual and graphical access
to historical monitoring data and predictions from various models in search for
or in order to validate patterns building over time.

These diverse ﬁelds of applications share many problems on an abstract level,
most of which are addressed by Visual Analytics. The actual (software) solution
must be adapted to the speciﬁc needs and terminologies of the application area
and consequently, many researchers currently focus on a speciﬁc customer seg-
ment. Much can be achieved, if the European research infrastructure in this ﬁeld
becomes strong enough to encourage the exchange of ideas on a broad scale, to
foster development of solutions applicable to multiple domains, achieving syn-
ergy eﬀects.

6 Technical Challenges

The primary goal of Visual Analytics is the analysis of vast amounts of data to
identify and visually distill the most valuable and relevant information content.
The visual representation should reveal structural patterns and relevant data
properties for easy perception by the analyst. A number of key requirements
need to be addressed by advanced Visual Analytics solutions. We next outline
important scientiﬁc challenges in this context.

Visual Analytics: Deﬁnition, Process, and Challenges

167

Scalability with Data Volumes and Data Dimensionality: Visual Ana-
lytics techniques need to be able to scale with the size and dimensionality of
the input data space. Techniques need to accommodate and graphically repre-
sent high-resolution input data as well as continuous input data streams of high
bandwidth. In many applications, data from multiple, heterogeneous sources
need to be integrated and processed jointly. In these cases, the methods need
to be able to scale with a range of diﬀerent data types, data sources, and levels
of quality. The visual representation algorithms need to be eﬃcient enough for
implementation in interactive systems.

Quality of Data and Graphical Representation: A central issue in Visual
Analytics is the avoidance of misinterpretations by the analyst. This may result
due to uncertainty and errors in the input data, or limitations of the chosen
analysis algorithm, and may produce misleading analysis results. To face this
problem, the notion of data quality, and the conﬁdence of the analysis algorithm
needs to be appropriately represented in the Visual Analytics solutions. The user
needs to be aware of these data and analysis quality properties at any stage in
the data analysis process.

Visual Representation and Level of Detail: To accommodate vast streams
of data, appropriate solutions need to intelligently combine visualizations of
selected analysis details on the one hand, and a global overview on the other
hand. The relevant data patterns and relationships need to be visualized on
several levels of detail, and with appropriate levels of data and visual abstraction.

User Interfaces, and Interaction Styles and Metaphors: Visual Analytics
systems need to be easily used and interacted with by the analyst. The analyst
needs to be able to fully focus on the task at hand, not on overly technical or
complex user interfaces, which potentially distract. To this end, novel interaction
techniques need to be developed which fully support the seamless, intuitive visual
communication with the system. User feedback should be taken as intelligently
as possible, requiring as little manual user input as possible, which guarantees
the full support of the user in navigating and analyzing the data, memorizing
insights and making informed decisions.

Display Devices: In addition to high-resolution desktop displays, advanced
display devices such as large-scale power walls and small portable personal assis-
tant, graphically-enabled devices need to be supported. Visual Analytics systems
should adapt to the characteristics of the available output devices, supporting
the Visual Analytics workﬂow on all levels of operation.

Evaluation: Due to the complex and heterogeneous problem domains addressed
by Visual Analytics, so far it has been diﬃcult to perform encompassing evalua-
tion work. A theoretically founded evaluation framework needs to be developed
which allows assessing the contribution of any Visual Analytics system toward
the level of eﬀectiveness and eﬃciency achieved regarding their requirements.

168

D. Keim et al.

Infrastructure: Managing large amounts of data for visualization or analysis
requires special data structures and mechanisms, both in memory and disks.
Achieving interactivity means refreshing the display in 100ms at worst whereas
analyzing data with standard techniques such as clustering can take hours to
complete. Achieving the smooth interaction required by the analysts to perform
their tasks while providing high-quality analytical algorithms need the combi-
nation of asynchronous computation with hybrid analytical algorithms that can
trade time with quality. Moreover, to fully support the analytical process, the
history of the analysis should also be recorded and interactively edited and an-
notated. Altogether, these requirements call for a novel software infrastructure,
built upon well understood technologies such as databases, software components
and visualization but augmented with asynchronous processing, history manage-
ments and annotations.

7 Examples for Visual Analytics Applications

7.1 Visual Analytics Tools for Analysis of Movement Data

With widespread availability of low cost GPS devices, it is becoming possible to
record data about the movement of people and objects at a large scale. While
these data hide important knowledge for the optimization of location and mobil-
ity oriented infrastructures and services, by themselves they lack the necessary
semantic embedding which would make fully automatic algorithmic analysis pos-
sible. At the same time, making the semantic link is easy for humans who however
cannot deal well with massive amounts of data. In [5] we argue that by using
the right visual analytics tools for the analysis of massive collections of move-
ment data, it is possible to eﬀectively support human analysts in understanding
movement behaviors and mobility patterns.

Figure 5 shows a subset of raw GPS measurements presented in so-called
space-time cube. The large amount of position records referring to the same
territory over a long time period makes it virtually impossible to do the analysis
by purely visual methods.

The paper [5] proposes a framework where interactive visual interfaces are
synergistically combined with database operations and computational process-
ing. The generic database techniques are used for basic data processing and ex-
traction of relevant objects and features. The computational techniques, which
are specially devised for movement data, aggregate and summarize these objects
and features and thereby enable the visualization of large amounts of informa-
tion. The visualization enables human cognition and reasoning, which, in turn,
direct and control the further analysis by means of the database, computational,
and visual techniques. Interactive visual interfaces embrace all the tools.

Thus, in order to detect and interpret signiﬁcant places visited by the mov-
ing entities, the positions of stops are extracted from the data by means of
appropriate database queries. Then, clustering methods are applied to detect
frequently visited places. Interactive visual displays put the results in the spa-
tial and temporal contexts. The spatial positions of the stops can be observed on

Visual Analytics: Deﬁnition, Process, and Challenges

169

Fig. 5. A visual display of a large amount of position records is unreadable and not
suitable for analysis.

Fig. 6. Positions of stops have been extracted from the database. By means of cluster-
ing, frequently visited places have been detected.

170

D. Keim et al.

Fig. 7. The temporal histograms show the distribution of the stops in the frequently
visited places (Figure 6) with respect to the weekly (left) and daily (right) cycles.

a map (Figure 6) or 3D spatial view. Temporal histograms (Figure 7) are used
to explore the temporal distribution of the stops throughout the time period and
within various temporal cycles (daily, weekly, etc.). These complementary views
allow a human analyst to understand the meanings or roles of the frequently
visited places.

In order to detect and interpret typical routes of the movement between the
signiﬁcant places, the analyst ﬁrst applies a database query to extract sequences
of position records between the stops, from which trajectories (time-referenced
lines) are constructed. Then, clustering is applied with the use of specially de-
vised similarity measures. The results are computationally generalized and sum-
marized and displayed in the spatial context (Figure 8).

7.2 Multilevel Visualization of the Worldwide Air

Transportation Network

The air transportation network has now become more dense and more complex
at all geographical levels. Its dynamic no more rests on simple territorial logics.
The challenge is to gain insightful understandings on how the routes carrying the
densest traﬃc organize themselves and impact the organization of the network
into sub-communities at lower levels. At the same time, subnetworks grow on
their own logic, involving tourism, economy or territorial control, and inﬂuence
or ﬁght against each other. Because of the network size and complexity, its study
can no more rely on traditional world map and requires novel visualization. A
careful analysis of the network structural properties, requiring recent results on
small world phenomenon, reveals its multilevel community structure.

The original network is organized into a top level network of communi-
ties (Figure 9(a)). Each component can then be further decomposed into sub-
communities. Capitals such as New York, Chicago, Paris or London (Figure 9(b))
clearly attract most of the international traﬃc and impose routes to ﬂy the world
around because of airline partnerships (economical logic). Asia (Figure 9(c))
clearly stands apart from these core hubs because of strong territorial ties en-
dorsed by national Asian airline companies (territorial logic). Visualization of
social networks such as the worldwide air transportation is challenged by the
necessity to scale with the growing size of network data while being able to oﬀer

Visual Analytics: Deﬁnition, Process, and Challenges

171

Fig. 8. A result of clustering and summarization of movement data: the routes between
the signiﬁcant places.

readable visual representations and ﬂuid interaction. Visualization today brings
the ﬁeld of social sciences close to the study of complex systems and promises
to deliver new knowledge across these disciplines [7,3,10].

8 Conclusions

The problems addressed by Visual Analytics are generic. Virtually all sciences
and many industries rely on the ability to identify methods and models, which
can turn data into reliable and provable knowledge. Ever since the dawn of mod-
ern science, researchers needed to ﬁnd methodologies to create new hypotheses,
to compare them with alternative hypotheses, and to validate their results. In
a collaborative environment this process includes a large number of specialized
people each having a diﬀerent educational background. The ability to commu-
nicate results to peers will become crucial for scientiﬁc discourse.

Currently, no technological approach can claim to give answers to all three

key questions that have been outlined in the ﬁrst section, regarding the

– relevance of a speciﬁc information
– adequacy of data processing methods and validity of results
– acceptability of the presentation of results for a given task

172

D. Keim et al.

(a) World air transportation network.

(b) USA and world hubs.

(c) Asia.

Fig. 9. Multilevel Visualization of the Worldwide Air Transportation Network

Visual Analytics: Deﬁnition, Process, and Challenges

173

Visual Analytics research does not focus on speciﬁc methods to address these
questions in a single “best-practice”. Each speciﬁc domain contributes a reper-
toire of approaches to initiate an interdisciplinary creation of solutions.

Visual Analytics literally maps the connection between diﬀerent alternative
solutions, leaving the opportunity for the human user to view these options in
the context of the complete knowledge generation process and to discuss these
options with peers on common ground.

References

1. Aigner, W., Miksch, S., M¨uller, W., Schumann, H., Tominski, C.: Visual meth-
ods for analyzing time-oriented data. IEEE Transactions on Visualization and
Computer Graphics 14(1), 47–60 (2008)

2. Amar, R.A., Eagan, J., Stasko, J.T.: Low-level components of analytic activity in

information visualization. In: INFOVIS, p. 15 (2005)

3. Amiel, M., Melan¸con, G., Rozenblat, C.: R´eseaux multi-niveaux: l’exemple des

´echanges a´eriens mondiaux. M@ppemonde 79(3) (2005)

4. Andrienko, G., Andrienko, N., Jankowski, P., Keim, D., Kraak, M.-J.,
MacEachren, A., Wrobel, S.: Geovisual analytics for spatial decision support:
Setting the research agenda. Special issue of the International Journal of Geo-
graphical Information Science 21(8), 839–857 (2007)

5. Andrienko, G., Andrienko, N., Wrobel, S.: Visual analytics tools for analysis of

movement data. ACM SIGKDD Explorations 9(2) (2007)

6. Andrienko, N., Andrienko, G.: Exploratory Analysis of Spatial and Temporal

Data. Springer, Heidelberg (2005)

7. Auber, D., Chiricota, Y., Jourdan, F., Melan¸con, G.: Multiscale visualization of

small world networks. In: INFOVIS (2003)

8. Card, S.K., Mackinlay, J., Shneiderman, B.: Readings in Information Visualiza-

tion: Using Vision to Think. Morgan Kaufmann, San Francisco (1999)

9. Ceglar, A., Roddick, J.F., Calder, P.: Guiding knowledge discovery through in-

teractive data mining, pp. 45–87. IGI Publishing, Hershey (2003)

10. Chiricota, Y., Melan¸con, G.: Visually mining relational data. International Review

on Computers and Software (2005)

11. Das, A.: Semantic approximation of data stream joins. IEEE Transactions on
Knowledge and Data Engineering 17(1), 44–59 (2005), Member-Johannes Gehrke
and Member-Mirek Riedewald

12. Dix, A., Finlay, J.E., Abowd, G.D., Beale, R.: Human-Computer Interaction (.),

3rd edn. Prentice-Hall, Inc., Upper Saddle River (2003)

13. Duda, R., Hart, P., Stock, D.: Pattern Classiﬁcation. John Wiley and Sons Inc,

Chichester (2000)

14. Dykes, J., MacEachren, A., Kraak, M.-J.: Exploring geovisualization. Elsevier

Science, Amsterdam (2005)

15. Engel, K., Hadwiger, M., Kniss, J.M., Rezk-salama, C., Weiskopf, D.: Real-time

Volume Graphics. A. K. Peters, Ltd., Natick (2006)

16. Ester, M., Sander, J.: Knowledge Discovery in Databases - Techniken und An-

wendungen. Springer, Heidelberg (2000)

17. Forsell, C., Seipel, S., Lind, M.: Simple 3d glyphs for spatial multivariate data.

In: INFOVIS, p. 16 (2005)

174

D. Keim et al.

18. Han, J., Kamber, M. (eds.): Data Mining: Concepts and Techniques. Morgan

Kaufmann, San Francisco (2000)

19. Hand, D., Mannila, H., Smyth, P. (eds.): Principles of Data Mining. MIT Press,

Cambridge (2001)

20. Inselberg, A., Dimsdale, B.: Parallel Coordinates: A Tool for Visualizing Multi-
variate Relations (chapter 9), pp. 199–233. Plenum Publishing Corporation, New
York (1991)

21. Jacko, J.A., Sears, A.: The Handbook for Human Computer Interaction. Lawrence

Erlbaum & Associates, Mahwah (2003)

22. Johnson, C., Hanson, C. (eds.): Visualization Handbook. Kolam Publishing (2004)
23. Keim, D., Ertl, T.: Scientiﬁc visualization (in german). Information Technol-

ogy 46(3), 148–153 (2004)

24. Keim, D., Ward, M.: Visual Data Mining Techniques (chapter 11). Springer, New

York (2003)

25. Keim, D.A., Ankerst, M., Kriegel, H.-P.: Recursive pattern: A technique for visu-
alizing very large amounts of data. In: VIS ’95: Proceedings of the 6th conference
on Visualization ’95, Washington, DC, USA, p. 279. IEEE Computer Society
Press, Los Alamitos (1995)

26. Keim, D.A., Panse, C., Sips, M., North, S.C.: Pixel based visual data mining of

geo-spatial data. Computers &Graphics 28(3), 327–344 (2004)

27. Kerren, A., Stasko, J.T., Fekete, J.-D., North, C.J. (eds.): Information Visualiza-

tion. LNCS, vol. 4950. Springer, Heidelberg (2008)

28. Kr´uger, J., Schneider, J., Westermann, R.: Clearview: An interactive context pre-
serving hotspot visualization technique. IEEE Transactions on Visualization and
Computer Graphics 12(5), 941–948 (2006)

29. Maimon, O., Rokach, L. (eds.): The Data Mining and Knowledge Discovery Hand-

book. Springer, Heidelberg (2005)

30. Meliou, A., Chu, D., Guestrin, C., Hellerstein, J., Hong, W.: Data gathering tours

in sensor networks. In: IPSN (2006)

31. Mitchell, T.M.: Machine Learning. McGraw-Hill, Berkeley (1997)
32. Naumann, F., Bilke, A., Bleiholder, J., Weis, M.: Data fusion in three steps:
Resolving schema, tuple, and value inconsistencies. IEEE Data Eng. Bull. 29(2),
21–31 (2006)

33. North, C.: Toward measuring visualization insight. IEEE Comput. Graph.

Appl. 26(3), 6–9 (2006)

34. Perner, P. (ed.): Data Mining on Multimedia Data. LNCS, vol. 2558. Springer,

Heidelberg (2002)

35. Schumann, H., M¨uller, W.: Visualisierung - Grundlagen und allgemeine Metho-

den. Springer, Heidelberg (2000)

36. Shneiderman, B.: Tree visualization with tree-maps: 2-d space-ﬁlling approach.

ACM Trans. Graph. 11(1), 92–99 (1992)

37. Shneiderman, B., Plaisant, C.: Designing the User Interface. Addison-Wesley,

Reading (2004)

38. Spence, R.: Information Visualization. ACM Press, New York (2001)
39. Thomas, J.J., Cook, K.A.: Illuminating the Path. IEEE Computer Society Press,

Los Alamitos (2005)

40. Tricoche, X., Scheuermann, G., Hagen, H.: Tensor topology tracking: A visual-
ization method for time-dependent 2d symmetric tensor ﬁelds. Comput. Graph.
Forum 20(3) (2001)

41. Unwin, A., Theus, M., Hofmann, H.: Graphics of Large Datasets: Visualizing a

Million (Statistics and Computing). Springer, New York (2006)

Visual Analytics: Deﬁnition, Process, and Challenges

175

42. van Wijk, J.J.: The value of visualization. In: IEEE Visualization, p. 11 (2005)
43. Widom, J.: Trio: A system for integrated management of data, accuracy, and

lineage. In: CIDR, pp. 262–276 (2005)

44. Yi, J.S., Kang, Y.a., Stasko, J.T., Jacko, J.A.: Toward a deeper understanding
of the role of interaction in information visualization. IEEE Trans. Vis. Comput.
Graph. 13(6), 1224–1231 (2007)

","{""pos"":{""0"":1,""1"":2,""2"":3,""3"":4},""2"":{""0"":""j*"",""1"":""m*"",""2"":""g*"",""3"":""c""},""1"":{""0"":""springer*"",""1"":""andrienko"",""2"":""ieee"",""3"":""daniel*""},""0"":{""0"":""3"",""1"":""2005*"",""2"":""2006*"",""3"":""2003""},""5"":{""0"":""research"",""1"":""management"",""2"":""development*"",""3"":""design*""},""4"":{""0"":""developed*"",""1"":""relevant"",""2"":""provide"",""3"":""needs""},""3"":{""0"":""types*"",""1"":""patterns*"",""2"":""places"",""3"":""parameters*""},""6"":{""0"":""data*"",""1"":""analytics*"",""2"":""analysis*"",""3"":""computer*""}}",2008,{},False,False,bookSection,False,7DLBYPHS,[],self.user,"{""Unnamed: 0"":{""0"":0,""1"":1,""2"":2,""3"":3,""4"":4,""5"":5,""6"":6,""7"":7,""8"":8,""9"":9,""10"":10,""11"":11,""12"":12,""13"":13,""14"":14,""15"":15,""16"":16,""17"":17,""18"":18,""19"":19,""20"":20,""21"":21,""22"":22,""23"":23,""24"":24,""25"":25,""26"":26,""27"":27,""28"":28,""29"":29,""30"":30,""31"":31,""32"":32,""33"":33,""34"":34,""35"":35,""36"":36,""37"":37,""38"":38,""39"":39,""40"":40,""41"":41,""42"":42,""43"":43,""44"":44,""45"":45,""46"":46,""47"":47,""48"":48,""49"":49,""50"":50,""51"":51,""52"":52,""53"":53,""54"":54,""55"":55,""56"":56,""57"":57,""58"":58,""59"":59,""60"":60,""61"":61,""62"":62,""63"":63,""64"":64,""65"":65,""66"":66,""67"":67,""68"":68,""69"":69,""70"":70,""71"":71,""72"":72,""73"":73,""74"":74,""75"":75,""76"":76,""77"":77,""78"":78,""79"":79,""80"":80,""81"":81,""82"":82,""83"":83,""84"":84,""85"":85,""86"":86,""87"":87,""88"":88,""89"":89,""90"":90,""91"":91,""92"":92,""93"":93,""94"":94,""95"":95,""96"":96,""97"":97},""C"":{""0"":10.4868371126,""1"":6.2452502856,""2"":7.58101733,""3"":8.032950108,""4"":8.7130334869,""5"":4.1290356029,""6"":26.7364534849,""7"":17.6159582396,""8"":4.368369665,""9"":21.4471456979,""10"":4.455246663,""11"":6.4533121922,""12"":4.8845768334,""13"":11.3874206977,""14"":5.0352074469,""15"":13.8510225649,""16"":5.7285415007,""17"":4.7821214262,""18"":3.9838524892,""19"":5.7135085688,""20"":4.6565294686,""21"":5.6956078279,""22"":9.2325251368,""23"":13.2248005758,""24"":7.3344035972,""25"":8.9418152769,""26"":11.9535123209,""27"":7.6135813052,""28"":10.9898918067,""29"":4.1429402531,""30"":4.457812137,""31"":10.8627292132,""32"":10.2141216837,""33"":12.6575453105,""34"":6.0849280262,""35"":10.4657498998,""36"":4.3862880367,""37"":5.3645325874,""38"":4.6194701619,""39"":4.8365676125,""40"":4.1811343881,""41"":5.3689843031,""42"":7.7991301289,""43"":10.3486081864,""44"":4.4407968672,""45"":9.7337446472,""46"":5.6657512762,""47"":6.5016951936,""48"":6.8495760494,""49"":7.8974868732,""50"":7.5398492966,""51"":4.2059559532,""52"":4.140511493,""53"":4.0047006157,""54"":5.7379357283,""55"":8.0199437111,""56"":7.2242235677,""57"":7.2242235677,""58"":4.204293434,""59"":7.1038221208,""60"":5.9015405471,""61"":6.640196022,""62"":6.4951904826,""63"":6.3518051782,""64"":5.6776348207,""65"":4.1309277431,""66"":4.875655098,""67"":6.2019376845,""68"":5.5442924882,""69"":6.5520315272,""70"":6.2786997683,""71"":5.8656105923,""72"":6.2238987148,""73"":4.1307255614,""74"":4.446727867,""75"":5.0342492011,""76"":5.2042488937,""77"":5.4937920073,""78"":4.2392282026,""79"":4.7005424011,""80"":4.0116120276,""81"":4.113228244,""82"":4.6859476896,""83"":4.6896098433,""84"":4.4698148841,""85"":4.5268272638,""86"":4.5519673686,""87"":4.4094503104,""88"":4.0651339214,""89"":4.5199878094,""90"":4.5700744892,""91"":4.6133466346,""92"":4.6168993605,""93"":4.5952253686,""94"":4.580756866,""95"":4.4272649239,""96"":4.5484112533,""97"":4.0613808536},""count"":{""0"":386,""1"":220,""2"":160,""3"":154,""4"":96,""5"":94,""6"":56,""7"":44,""8"":40,""9"":34,""10"":32,""11"":32,""12"":32,""13"":30,""14"":30,""15"":30,""16"":28,""17"":28,""18"":28,""19"":26,""20"":24,""21"":24,""22"":22,""23"":22,""24"":20,""25"":20,""26"":20,""27"":18,""28"":18,""29"":18,""30"":18,""31"":18,""32"":18,""33"":16,""34"":16,""35"":16,""36"":16,""37"":16,""38"":14,""39"":14,""40"":14,""41"":14,""42"":14,""43"":14,""44"":12,""45"":12,""46"":12,""47"":12,""48"":12,""49"":12,""50"":10,""51"":10,""52"":10,""53"":10,""54"":10,""55"":10,""56"":10,""57"":10,""58"":10,""59"":10,""60"":8,""61"":8,""62"":8,""63"":8,""64"":8,""65"":8,""66"":8,""67"":8,""68"":8,""69"":8,""70"":8,""71"":8,""72"":8,""73"":8,""74"":8,""75"":8,""76"":8,""77"":8,""78"":6,""79"":6,""80"":6,""81"":6,""82"":6,""83"":6,""84"":6,""85"":6,""86"":6,""87"":6,""88"":6,""89"":6,""90"":6,""91"":6,""92"":6,""93"":6,""94"":6,""95"":6,""96"":6,""97"":6},""sigma_nor"":{""0"":1.5213761011,""1"":1.4034529995,""2"":1.5699040536,""3"":1.615210014,""4"":1.8282360833,""5"":1.3878839601,""6"":4.2632772381,""7"":3.3677063858,""8"":1.5827765702,""9"":4.2047756638,""10"":1.6455889303,""11"":1.9555044642,""12"":1.7121813854,""13"":2.7630683205,""14"":1.7525891777,""15"":3.1549661055,""16"":1.8841210675,""17"":1.7295088178,""18"":1.599099331,""19"":1.9044533336,""20"":1.746081199,""21"":1.9259536846,""22"":2.5844756885,""23"":3.2978264855,""24"":2.2842067794,""25"":2.5813085229,""26"":3.1379676874,""27"":2.3802658498,""28"":3.0273669596,""29"":1.7150854181,""30"":1.7754335246,""31"":3.0029950734,""32"":2.8786834462,""33"":3.4343032365,""34"":2.1244378605,""35"":2.9974975021,""36"":1.7859137061,""37"":1.9808693244,""38"":1.8603344081,""39"":1.9054664567,""40"":1.7692094715,""41"":2.0161497277,""42"":2.5213489327,""43"":3.0513559282,""44"":1.8511477812,""45"":3.0031494727,""46"":2.117757166,""47"":2.2996990341,""48"":2.3754147507,""49"":2.6034908799,""50"":2.5887926814,""51"":1.8259807288,""52"":1.8110066996,""53"":1.779932472,""54"":2.1765055847,""55"":2.6986407539,""56"":2.5165758905,""57"":2.5165758905,""58"":1.8256003359,""59"":2.4890274199,""60"":2.2590988809,""61"":2.4375522049,""62"":2.4025200128,""63"":2.3678792566,""64"":2.2050050272,""65"":1.8313328232,""66"":2.0112530655,""67"":2.3316724548,""68"":2.1727905737,""69"":2.4162523599,""70"":2.3502175675,""71"":2.2504184878,""72"":2.3369780661,""73"":1.8312839777,""74"":1.9076276369,""75"":2.0495681472,""76"":2.0906387291,""77"":2.1605900567,""78"":1.871194565,""79"":1.9893168838,""80"":1.8129120529,""81"":1.8389315059,""82"":1.9855798187,""83"":1.9865175356,""84"":1.9302376935,""85"":1.9448360616,""86"":1.951273339,""87"":1.9147809756,""88"":1.8266166607,""89"":1.9430847775,""90"":1.9559097779,""91"":1.9669898751,""92"":1.9678995722,""93"":1.9623498142,""94"":1.9586450657,""95"":1.9193425162,""96"":1.950362774,""97"":1.8256556648},""vocab_index"":{""0"":0,""1"":1,""2"":2,""3"":3,""4"":5,""5"":6,""6"":8,""7"":16,""8"":19,""9"":23,""10"":24,""11"":25,""12"":29,""13"":33,""14"":35,""15"":36,""16"":39,""17"":40,""18"":42,""19"":50,""20"":61,""21"":63,""22"":72,""23"":73,""24"":74,""25"":85,""26"":86,""27"":87,""28"":89,""29"":99,""30"":100,""31"":102,""32"":103,""33"":104,""34"":108,""35"":109,""36"":113,""37"":115,""38"":119,""39"":120,""40"":135,""41"":136,""42"":137,""43"":138,""44"":146,""45"":177,""46"":178,""47"":179,""48"":180,""49"":181,""50"":182,""51"":202,""52"":206,""53"":207,""54"":216,""55"":217,""56"":218,""57"":219,""58"":220,""59"":221,""60"":222,""61"":226,""62"":227,""63"":230,""64"":237,""65"":247,""66"":257,""67"":273,""68"":283,""69"":300,""70"":303,""71"":304,""72"":305,""73"":306,""74"":307,""75"":308,""76"":309,""77"":310,""78"":311,""79"":318,""80"":319,""81"":321,""82"":325,""83"":327,""84"":328,""85"":329,""86"":330,""87"":344,""88"":362,""89"":435,""90"":441,""91"":453,""92"":456,""93"":461,""94"":462,""95"":465,""96"":468,""97"":473},""word"":{""0"":""data"",""1"":""visual"",""2"":""analytics"",""3"":""analysis"",""4"":""research"",""5"":""information"",""6"":""j"",""7"":""a"",""8"":""3"",""9"":""m"",""10"":""g"",""11"":""computer"",""12"":""application"",""13"":""c"",""14"":""representation"",""15"":""need"",""16"":""e\ufb00ective"",""17"":""network"",""18"":""temporal"",""19"":""database"",""20"":""management"",""21"":""developed"",""22"":""area"",""23"":""2005"",""24"":""springer"",""25"":""development"",""26"":""p"",""27"":""andrienko"",""28"":""way"",""29"":""relevant"",""30"":""possible"",""31"":""design"",""32"":""ieee"",""33"":""daniel"",""34"":""provide"",""35"":""automated"",""36"":""types"",""37"":""needs"",""38"":""ability"",""39"":""heidelberg"",""40"":""input"",""41"":""patterns"",""42"":""movement"",""43"":""places"",""44"":""eds"",""45"":""stops"",""46"":""b"",""47"":""h"",""48"":""r"",""49"":""2006"",""50"":""jean"",""51"":""parameters"",""52"":""include"",""53"":""graphs"",""54"":""high"",""55"":""visited"",""56"":""air"",""57"":""transportation"",""58"":""york"",""59"":""2003"",""60"":""gennady"",""61"":""lirmm"",""62"":""hal"",""63"":""fraunhofer"",""64"":""overload"",""65"":""collaboration"",""66"":""integrates"",""67"":""individual"",""68"":""structured"",""69"":""mantra"",""70"":""frequently"",""71"":""routes"",""72"":""territorial"",""73"":""w"",""74"":""k"",""75"":""2000"",""76"":""press"",""77"":""2004"",""78"":""carsten"",""79"":""00272779"",""80"":""fr"",""81"":""france"",""82"":""ou"",""83"":""konstanz"",""84"":""germany"",""85"":""institute"",""86"":""inria"",""87"":""procedures"",""88"":""integrating"",""89"":""build"",""90"":""functions"",""91"":""production"",""92"":""economic"",""93"":""computational"",""94"":""positions"",""95"":""logic"",""96"":""n"",""97"":""comput""},""vector"":{""0"":""[-2.0819597  -0.75361675 -0.33864376 -0.33474392  1.5378759   0.10763513\n -2.6578493   0.00610636 -0.16165939 -0.87975156]"",""1"":""[-1.3703648  -1.111229   -0.19565894  0.28242368  1.0743175   0.29973707\n -2.3945212   0.35513186 -0.39028046 -1.3247507 ]"",""2"":""[-1.8846114  -0.60893553 -0.39591652 -0.05152741  1.3880963  -0.05656401\n -2.4729223   0.13754627 -0.28971735 -1.0814308 ]"",""3"":""[-1.6572123  -0.55788517 -0.43546703  0.01354232  1.5695435   0.0300975\n -2.3817503   0.17520693 -0.08283444 -1.0758492 ]"",""4"":""[-1.5685451  -0.6923947  -0.1023174   0.24442533  1.477635   -0.19022202\n -2.3024423   0.17709643  0.2524029  -1.0327868 ]"",""5"":""[-1.689735   -0.75934994 -0.40372407 -0.31883708  1.6631587   0.08013445\n -2.6664572  -0.09693071  0.04938898 -0.9108339 ]"",""6"":""[-2.5147216  -4.0374603   2.852689    0.89891994 -1.6524383   0.39175695\n -1.8496996  -0.04099846 -0.13468482 -1.2839822 ]"",""7"":""[-0.80974156 -1.4676971  -0.44682872  0.42888442  1.765681    1.7050608\n -1.9320716   0.25023228 -0.319501   -1.3522947 ]"",""8"":""[-1.7321056  -2.7559104   1.1649452   0.13049124  0.06011627  1.3828757\n -1.8108933  -0.07944365 -0.51911026 -1.2343556 ]"",""9"":""[-2.4012723  -4.0766797   2.8245957   0.716888   -1.6880205   0.3850088\n -1.6854299  -0.3021318  -0.35326278 -1.4115266 ]"",""10"":""[-2.6970897  -4.0240498   2.8612802   0.76198524 -1.6018149   0.53520465\n -1.9996935  -0.27805313 -0.19320558 -1.2730165 ]"",""11"":""[-2.0291321  -1.0117543  -0.13578966 -0.12024914  1.2336943   0.16975148\n -2.4360678   0.13448198 -0.2508236  -0.9410323 ]"",""12"":""[-1.3150009  -0.67678386 -0.50286144  0.14363553  1.5846101   0.10801487\n -2.1376514   0.3238416   0.14777705 -0.94097763]"",""13"":""[-2.4419909 -4.159254   2.6254373  0.6716924 -1.7817363  0.7015246\n -1.5271071 -0.5294079 -0.3128871 -1.1926823]"",""14"":""[-1.2505156  -0.8991128  -0.5384767  -0.20619445  1.6976689   0.20227136\n -2.8054008   0.08905303  0.06999814 -0.96752274]"",""15"":""[-0.96132666 -1.1471235  -0.51105505  0.57966506  2.2529855   1.7774898\n -2.3132014   0.49229845 -0.07380274 -1.3284769 ]"",""16"":""[-2.227588   -3.4783964   2.091854    0.5180677  -1.2076447   0.39792103\n -1.6629595  -0.20950088 -0.2937391  -0.98554397]"",""17"":""[-2.0632029  -1.0386388   0.06040853  0.07341253  1.4866254   0.28759566\n -2.5847578   0.32162914  0.07839081 -0.8431317 ]"",""18"":""[-1.3935403  -1.1497492  -0.09626254  0.40592712  1.2046751   0.536203\n -2.3362658   0.36526492 -0.42844373 -1.4141766 ]"",""19"":""[-2.1065903  -0.899631   -0.17344785 -0.27147377  1.4243968   0.17992076\n -2.4665048   0.03328461 -0.12141388 -0.82969373]"",""20"":""[-1.2965004  -0.77046293 -0.2456583   0.42283925  1.6129689   0.12514004\n -2.6138492   0.4767136   0.19237053 -1.0477644 ]"",""21"":""[-0.47252214 -1.4305717  -0.91617584  0.31601104  1.9092458   1.5198709\n -1.9188037   0.38873476 -0.29824102 -0.8279151 ]"",""22"":""[-1.5887387  -1.180566    0.135432    0.27217662  2.1092865   0.88739496\n -2.5067446   0.32559586  0.42312035 -0.84183514]"",""23"":""[-1.7770821  -2.462117    0.8234194  -0.06855387  0.3990293   1.5577645\n -1.7557461   0.04005298 -0.734907   -1.2166244 ]"",""24"":""[-2.612801   -3.6072032   2.5445476   0.82184553 -1.2712599   0.09732143\n -2.1065567   0.2899504  -0.16309328 -1.0132501 ]"",""25"":""[-1.3088785  -0.84585756 -0.00791972  0.46487388  1.7978418   0.21287787\n -2.2774174   0.31383923  0.48317558 -1.0047089 ]"",""26"":""[-2.1169577  -3.900336    2.742234    0.6267618  -1.5336062   0.5810909\n -1.6687108  -0.25442788 -0.38715947 -1.4216838 ]"",""27"":""[-2.337394   -3.0666108   1.7101011   0.5703469  -0.6806803   0.3418124\n -1.9356569   0.10531261 -0.26729587 -0.8437577 ]"",""28"":""[-1.4664255  -1.0568938  -0.25613746  0.23771197  2.1933901   1.4975976\n -2.3399913   0.2776157  -0.17050882 -1.2182803 ]"",""29"":""[-0.9408791  -1.4287304  -0.4822035   0.3448876   1.8631468   1.6237823\n -2.105913    0.34592432 -0.40793538 -1.154297  ]"",""30"":""[-1.1205328  -1.4584622  -0.3578664   0.31405765  1.8779647   1.6344037\n -2.1679685   0.34874168 -0.3819889  -1.1117182 ]"",""31"":""[-1.1438559  -0.7973633  -0.37321353  0.2725623   1.5181398   0.15165895\n -2.2288082   0.44758642  0.3041573  -0.9338877 ]"",""32"":""[-2.5543787  -3.4611063   2.2878823   0.7437545  -1.137783    0.05646697\n -2.0111554   0.16713673 -0.19272655 -0.9234512 ]"",""33"":""[-2.6329122  -3.5591452   2.6002579   0.68569696 -1.2939378   0.17973667\n -2.3157895   0.56044626 -0.31955788 -1.0206645 ]"",""34"":""[-0.47872213 -1.2739692  -0.7825111   0.5146352   2.0543642   1.6176678\n -2.0264575   0.43252268 -0.03605759 -1.0470619 ]"",""35"":""[-1.4769032  -1.0782428  -0.5532325  -0.05664825  1.3410951   0.5387822\n -2.1907651   0.16874403 -0.49264663 -0.97965795]"",""36"":""[-1.9621181  -0.7186203  -0.6055939  -0.01734539  2.231411    0.90329856\n -2.8600059   0.41916326 -0.17698935 -0.7876839 ]"",""37"":""[-1.257229   -1.0317192  -0.43112507  0.45980045  2.3217275   1.5798422\n -2.4830153   0.4855337  -0.05014087 -1.2378222 ]"",""38"":""[-1.363506   -1.0603771  -0.2009922   0.50108504  2.238036    1.6612073\n -2.3605373   0.43734923 -0.11755411 -1.4178632 ]"",""39"":""[-2.272978   -2.8507245   1.6622244   0.634698   -0.47960117  0.06282686\n -1.9985787   0.19589016 -0.1694655  -0.8404645 ]"",""40"":""[-1.44875    -0.7860315  -0.57159215 -0.33817306  1.6355978   0.02255352\n -2.8803093   0.00883975  0.06181306 -0.8888665 ]"",""41"":""[-2.0157673  -0.591806   -0.5049372  -0.00472035  2.0932045   0.6227929\n -2.7198114   0.34416047 -0.13367002 -0.8652202 ]"",""42"":""[-1.6267946  -0.8602913   0.06179065  0.3614989   1.9510432   0.35952148\n -2.4918234   0.34043786  0.54940385 -0.8634112 ]"",""43"":""[-1.5834941  -1.1357466  -0.24292488  0.12904075  2.326579    1.38703\n -2.6574485   0.3401819   0.03079522 -0.92496854]"",""44"":""[-2.1123805  -3.595714    2.4170775   0.4829412  -1.294904    0.5063874\n -1.6659003  -0.26895025 -0.47985226 -1.1791296 ]"",""45"":""[-1.6486168  -1.0890048  -0.36518818  0.20961954  2.3371806   1.3524055\n -2.6818957   0.4919793   0.01952863 -0.78923374]"",""46"":""[-2.400788   -4.081625    2.6942782   0.66704535 -1.646348    0.7252871\n -1.6265944  -0.5114871  -0.30530092 -1.3337433 ]"",""47"":""[-2.6110277  -4.1724377   2.9240508   0.88026935 -1.7832255   0.48557025\n -1.7745332  -0.26002592 -0.16623078 -1.1683714 ]"",""48"":""[-2.3714545  -4.130491    2.9543805   0.67225456 -1.9057101   0.59192276\n -1.684687   -0.18066171 -0.3843071  -1.3732369 ]"",""49"":""[-1.7514372  -2.3738391   0.78852594 -0.12633274  0.4774063   1.5029339\n -1.826376    0.05142885 -0.6785138  -1.1949054 ]"",""50"":""[-2.4124115  -3.4560554   2.7257721   0.6066693  -1.3208534   0.1263162\n -2.324538    0.66345155 -0.36145863 -0.96230686]"",""51"":""[-1.923236   -0.7554818  -0.6901699  -0.2755956   2.0192418   0.61686116\n -2.9808574   0.22516094 -0.17994742 -0.75552535]"",""52"":""[-0.53077024 -1.253132   -0.73024976  0.5769749   2.1278405   1.7000058\n -2.081883    0.46034768  0.01986638 -1.108095  ]"",""53"":""[-2.1375113  -0.66040516 -0.52865064 -0.23437755  1.781186    0.31980035\n -2.7056594   0.19354884 -0.26601365 -0.8252486 ]"",""54"":""[-1.0401763  -1.6079917  -0.2546716   0.40076876  1.6312801   1.530428\n -2.038997    0.37063286 -0.35197172 -1.1326175 ]"",""55"":""[-0.6873613  -1.4107924  -0.7380894   0.35008347  2.0976198   1.7078576\n -2.0645206   0.42765766 -0.2152801  -0.88831204]"",""56"":""[-1.8743521  -1.112932    0.23157267  0.4312532   1.5267926   0.38496378\n -2.507685    0.56101555  0.25814292 -0.91238976]"",""57"":""[-1.6038398  -0.9632169   0.09352986  0.5266308   1.6839725   0.39461878\n -2.5064316   0.53044415  0.2516951  -1.0472214 ]"",""58"":""[-2.546067   -3.4469283   2.5750546   0.69507337 -1.1358225   0.15774101\n -2.3300796   0.57477045 -0.28694314 -1.0465834 ]"",""59"":""[-1.6678989  -2.322584    0.8168067  -0.19767246  0.53008616  1.5450944\n -1.883137    0.00620036 -0.67477906 -1.2503121 ]"",""60"":""[-2.184675   -2.5676694   1.281185    0.56634957 -0.11878426  0.29443705\n -2.0568757   0.24743576 -0.216615   -0.8698409 ]"",""61"":""[-2.4183218  -3.4186587   2.0124376   0.5959731  -1.0866367   0.3401861\n -1.7635616  -0.14425804 -0.25700796 -0.8736209 ]"",""62"":""[-2.750335   -3.8559904   2.7191718   0.84628475 -1.4748236   0.31560212\n -2.029021   -0.06556216 -0.14449811 -1.1126845 ]"",""63"":""[-2.4209101  -3.110975    1.9658113   0.7307464  -0.7729984  -0.04856905\n -2.0074496   0.2094153  -0.15644914 -0.8710735 ]"",""64"":""[-1.4089495  -0.9990943  -0.306477    0.26611078  1.2386441   0.25018424\n -2.7097335   0.44875956 -0.3074875  -1.1990936 ]"",""65"":""[-1.3498282  -0.7416173  -0.09276493  0.34825724  1.5296816  -0.20111865\n -2.341141    0.29444468  0.4617728  -0.95734835]"",""66"":""[-0.43295562 -1.3801886  -1.0271609   0.31798786  2.0642247   1.5169753\n -2.031288    0.4692739  -0.27778646 -0.7006775 ]"",""67"":""[-1.2909821  -1.2450925  -0.16805965  0.4744759   1.932953    1.4906484\n -2.2950573   0.41122448 -0.2721204  -1.3603308 ]"",""68"":""[-0.6950558  -1.4276545  -0.7835151   0.25149867  1.8035835   1.4678048\n -1.9678348   0.3403602  -0.4061742  -0.91283315]"",""69"":""[-1.6400814  -0.64071107 -0.40225565  0.16079322  2.021052    0.8255607\n -2.3949525   0.24919899 -0.21190766 -1.2204512 ]"",""70"":""[-0.96212894 -1.2525548  -0.42205334  0.53358924  2.3368638   1.9010764\n -2.241308    0.46503794  0.04915762 -1.2195803 ]"",""71"":""[-1.8795218  -1.0093607  -0.19441803  0.18324718  2.1931973   1.0173002\n -2.7446244   0.48044056  0.0971732  -0.7776989 ]"",""72"":""[-1.3286252  -1.1659797   0.05864779  0.57965845  1.4225558   0.6644165\n -2.339841    0.40184736 -0.23042937 -1.4443452 ]"",""73"":""[-2.4686544  -4.1892805   2.7887926   0.7449748  -1.8679204   0.7384079\n -1.5815518  -0.40222365 -0.25718963 -1.2349764 ]"",""74"":""[-2.6348846  -4.061043    2.7363727   0.89513844 -1.666793    0.37051347\n -1.7035162  -0.31700593 -0.16265088 -1.1812408 ]"",""75"":""[-1.8271868  -2.469683    0.7940399   0.04272882  0.3320248   1.3104041\n -1.8249613   0.0583019  -0.523157   -1.0877193 ]"",""76"":""[-1.53797    -1.1032255   0.18590318  0.4038544   1.9801003   0.59726137\n -2.6104372   0.3682079   0.5608499  -0.8703431 ]"",""77"":""[-1.6818855  -2.3803904   0.84997267 -0.10895649  0.4624214   1.4398068\n -1.8972888  -0.00929258 -0.60871583 -1.1595985 ]"",""78"":""[-2.2298255  -2.7491467   1.445016    0.58397853 -0.31561482  0.2793476\n -2.010225    0.20606901 -0.22830723 -0.85929024]"",""79"":""[-2.4216506  -3.5977488   2.1631083   0.5823909  -1.2453667   0.29570472\n -1.8254467  -0.08157788 -0.29674044 -0.9307511 ]"",""80"":""[-2.379226   -3.758061    2.778478    0.591755   -1.4941553   0.30105364\n -2.0287235   0.16994382 -0.42428362 -1.2276312 ]"",""81"":""[-2.4531538  -3.4575706   2.5316381   0.6350044  -1.1822824   0.11402893\n -2.2147598   0.45524633 -0.33237913 -1.0539553 ]"",""82"":""[-2.1233666  -3.8949838   2.7554946   0.48265293 -1.6148442   0.6221447\n -1.7102622  -0.2267504  -0.5340811  -1.3642839 ]"",""83"":""[-2.2953303  -2.9874656   1.7761632   0.6508311  -0.6504084  -0.03006167\n -1.9262762   0.10100124 -0.16128395 -0.8358871 ]"",""84"":""[-2.5358434  -3.3647406   2.4797313   0.7025674  -1.0263671   0.1661456\n -2.3259528   0.54759854 -0.25906387 -1.0129976 ]"",""85"":""[-1.6817932  -0.84424657  0.10900695  0.2200734   1.4424062  -0.12983057\n -2.3801925   0.1640798   0.43536234 -0.8729502 ]"",""86"":""[-2.4371634  -3.2499037   1.987447    0.7210058  -0.90997857 -0.00578822\n -1.8459448   0.01138246 -0.16988042 -0.84848464]"",""87"":""[-1.692431   -0.6330656  -0.7200588  -0.03483487  2.097271    0.6869736\n -2.7772593   0.3024218  -0.21786404 -0.9274086 ]"",""88"":""[-0.48984033 -1.3182724  -0.94218457  0.3267809   1.8845502   1.2132672\n -2.0634794   0.45142666 -0.28359035 -0.7696013 ]"",""89"":""[-0.4737136  -1.3010576  -0.80724245  0.3784998   1.9023887   1.3689524\n -1.9313582   0.38968277 -0.05869047 -0.8454318 ]"",""90"":""[-1.7841231  -0.77585787 -0.68719363 -0.1116565   2.154479    0.781473\n -2.915531    0.32859674 -0.15680681 -0.78509265]"",""91"":""[-1.3008752  -0.8335249  -0.06180497  0.4691209   1.560217    0.05280589\n -2.3484302   0.4866013   0.46027663 -0.9827318 ]"",""92"":""[-1.3916394  -1.0414842   0.04226745  0.55502385  1.4269674   0.43883416\n -2.342594    0.4195492  -0.05822849 -1.3267509 ]"",""93"":""[-1.7958825  -1.1067541  -0.0440478   0.13717291  1.0026762   0.14892894\n -2.3061697   0.19465242 -0.38821524 -1.1905522 ]"",""94"":""[-1.7411616  -0.9270898  -0.3524632   0.01791226  2.2608187   0.8753079\n -2.8703296   0.32202196  0.14906737 -0.7636927 ]"",""95"":""[-1.7438778  -0.6497111  -0.37440297  0.09430718  1.6756608   0.42368722\n -2.3632538   0.2265898  -0.2647708  -1.189056  ]"",""96"":""[-2.345958   -3.943739    2.766552    0.71329415 -1.5888271   0.5637941\n -1.7868121  -0.18779817 -0.2737531  -1.3740942 ]"",""97"":""[-2.4449449  -3.5183883   2.3004065   0.7450021  -1.2143682   0.2008806\n -1.706101   -0.22015853 -0.20396425 -1.0005761 ]""},""topic"":{""0"":6,""1"":-1,""2"":6,""3"":6,""4"":5,""5"":-1,""6"":2,""7"":-1,""8"":0,""9"":2,""10"":2,""11"":6,""12"":-1,""13"":2,""14"":-1,""15"":-1,""16"":-1,""17"":-1,""18"":-1,""19"":-1,""20"":5,""21"":4,""22"":-1,""23"":0,""24"":1,""25"":5,""26"":2,""27"":1,""28"":-1,""29"":4,""30"":-1,""31"":5,""32"":1,""33"":1,""34"":4,""35"":-1,""36"":3,""37"":4,""38"":4,""39"":-1,""40"":-1,""41"":3,""42"":-1,""43"":3,""44"":-1,""45"":-1,""46"":2,""47"":2,""48"":2,""49"":0,""50"":-1,""51"":3,""52"":4,""53"":-1,""54"":-1,""55"":4,""56"":-1,""57"":5,""58"":1,""59"":0,""60"":-1,""61"":-1,""62"":1,""63"":-1,""64"":-1,""65"":5,""66"":4,""67"":4,""68"":4,""69"":-1,""70"":-1,""71"":3,""72"":-1,""73"":2,""74"":2,""75"":0,""76"":-1,""77"":0,""78"":-1,""79"":-1,""80"":-1,""81"":1,""82"":2,""83"":-1,""84"":1,""85"":-1,""86"":1,""87"":3,""88"":4,""89"":4,""90"":3,""91"":5,""92"":-1,""93"":-1,""94"":3,""95"":-1,""96"":2,""97"":-1},""exemplar"":{""0"":""*"",""1"":null,""2"":""*"",""3"":""*"",""4"":null,""5"":null,""6"":""*"",""7"":null,""8"":null,""9"":""*"",""10"":""*"",""11"":""*"",""12"":null,""13"":null,""14"":null,""15"":null,""16"":null,""17"":null,""18"":null,""19"":null,""20"":null,""21"":""*"",""22"":null,""23"":""*"",""24"":""*"",""25"":""*"",""26"":null,""27"":null,""28"":null,""29"":null,""30"":null,""31"":""*"",""32"":null,""33"":""*"",""34"":null,""35"":null,""36"":""*"",""37"":null,""38"":null,""39"":null,""40"":null,""41"":""*"",""42"":null,""43"":null,""44"":null,""45"":null,""46"":null,""47"":null,""48"":null,""49"":""*"",""50"":null,""51"":""*"",""52"":null,""53"":null,""54"":null,""55"":""*"",""56"":null,""57"":""*"",""58"":""*"",""59"":null,""60"":null,""61"":null,""62"":null,""63"":null,""64"":null,""65"":""*"",""66"":null,""67"":null,""68"":""*"",""69"":null,""70"":null,""71"":null,""72"":null,""73"":null,""74"":null,""75"":""*"",""76"":null,""77"":""*"",""78"":null,""79"":null,""80"":null,""81"":""*"",""82"":null,""83"":null,""84"":""*"",""85"":null,""86"":null,""87"":null,""88"":null,""89"":""*"",""90"":""*"",""91"":null,""92"":null,""93"":null,""94"":null,""95"":null,""96"":""*"",""97"":null},""word*"":{""0"":""data*"",""1"":""visual"",""2"":""analytics*"",""3"":""analysis*"",""4"":""research"",""5"":""information"",""6"":""j*"",""7"":""a"",""8"":""3"",""9"":""m*"",""10"":""g*"",""11"":""computer*"",""12"":""application"",""13"":""c"",""14"":""representation"",""15"":""need"",""16"":""e\ufb00ective"",""17"":""network"",""18"":""temporal"",""19"":""database"",""20"":""management"",""21"":""developed*"",""22"":""area"",""23"":""2005*"",""24"":""springer*"",""25"":""development*"",""26"":""p"",""27"":""andrienko"",""28"":""way"",""29"":""relevant"",""30"":""possible"",""31"":""design*"",""32"":""ieee"",""33"":""daniel*"",""34"":""provide"",""35"":""automated"",""36"":""types*"",""37"":""needs"",""38"":""ability"",""39"":""heidelberg"",""40"":""input"",""41"":""patterns*"",""42"":""movement"",""43"":""places"",""44"":""eds"",""45"":""stops"",""46"":""b"",""47"":""h"",""48"":""r"",""49"":""2006*"",""50"":""jean"",""51"":""parameters*"",""52"":""include"",""53"":""graphs"",""54"":""high"",""55"":""visited*"",""56"":""air"",""57"":""transportation*"",""58"":""york*"",""59"":""2003"",""60"":""gennady"",""61"":""lirmm"",""62"":""hal"",""63"":""fraunhofer"",""64"":""overload"",""65"":""collaboration*"",""66"":""integrates"",""67"":""individual"",""68"":""structured*"",""69"":""mantra"",""70"":""frequently"",""71"":""routes"",""72"":""territorial"",""73"":""w"",""74"":""k"",""75"":""2000*"",""76"":""press"",""77"":""2004*"",""78"":""carsten"",""79"":""00272779"",""80"":""fr"",""81"":""france*"",""82"":""ou"",""83"":""konstanz"",""84"":""germany*"",""85"":""institute"",""86"":""inria"",""87"":""procedures"",""88"":""integrating"",""89"":""build*"",""90"":""functions*"",""91"":""production"",""92"":""economic"",""93"":""computational"",""94"":""positions"",""95"":""logic"",""96"":""n*"",""97"":""comput""},""pos"":{""0"":1,""1"":1,""2"":2,""3"":3,""4"":1,""5"":2,""6"":1,""7"":3,""8"":1,""9"":2,""10"":3,""11"":4,""12"":4,""13"":4,""14"":5,""15"":6,""16"":7,""17"":8,""18"":9,""19"":10,""20"":2,""21"":1,""22"":11,""23"":2,""24"":1,""25"":3,""26"":5,""27"":2,""28"":12,""29"":2,""30"":13,""31"":4,""32"":3,""33"":4,""34"":3,""35"":14,""36"":1,""37"":4,""38"":5,""39"":15,""40"":16,""41"":2,""42"":17,""43"":3,""44"":18,""45"":19,""46"":6,""47"":7,""48"":8,""49"":3,""50"":20,""51"":4,""52"":6,""53"":21,""54"":22,""55"":7,""56"":23,""57"":5,""58"":5,""59"":4,""60"":24,""61"":25,""62"":6,""63"":26,""64"":27,""65"":6,""66"":8,""67"":9,""68"":10,""69"":28,""70"":29,""71"":5,""72"":30,""73"":9,""74"":10,""75"":5,""76"":31,""77"":6,""78"":32,""79"":33,""80"":34,""81"":7,""82"":11,""83"":35,""84"":8,""85"":36,""86"":9,""87"":6,""88"":11,""89"":12,""90"":7,""91"":7,""92"":37,""93"":38,""94"":8,""95"":39,""96"":12,""97"":40},""x2D"":{""0"":1.5612076521,""1"":0.1190974861,""2"":1.1263689995,""3"":1.2521299124,""4"":1.041893363,""5"":1.4654458761,""6"":-10.9814004898,""7"":4.7483167648,""8"":-13.3044137955,""9"":-10.9163217545,""10"":-11.0492115021,""11"":0.8102645874,""12"":1.1400994062,""13"":-10.9270896912,""14"":1.6849424839,""15"":4.158721447,""16"":-12.6993656158,""17"":1.06084764,""18"":0.086942777,""19"":1.3153295517,""20"":0.3500847518,""21"":4.9147081375,""22"":1.8239508867,""23"":-13.1275157928,""24"":-11.874537468,""25"":0.766807735,""26"":-11.4917039871,""27"":-13.2662639618,""28"":4.0228385925,""29"":4.6363568306,""30"":4.6094179153,""31"":0.6380477548,""32"":-12.4157495499,""33"":-11.7228574753,""34"":4.8480801582,""35"":0.3270666599,""36"":2.9127829075,""37"":3.8916180134,""38"":4.1692562103,""39"":-13.2360067368,""40"":1.7650020123,""41"":2.7924704552,""42"":0.7933302522,""43"":3.2363762856,""44"":-12.2791576385,""45"":3.0364625454,""46"":-11.1509494781,""47"":-10.8288984299,""48"":-10.8158826828,""49"":-13.1127986908,""50"":-11.8297452927,""51"":2.5333878994,""52"":4.6201634407,""53"":2.2253468037,""54"":4.6326541901,""55"":4.7394914627,""56"":0.9500838518,""57"":0.5725226402,""58"":-12.0092191696,""59"":-12.9791631699,""60"":-13.1717681885,""61"":-12.7154846191,""62"":-11.1459331512,""63"":-12.9702959061,""64"":0.2730148733,""65"":0.9226151705,""66"":5.0961418152,""67"":4.1983318329,""68"":4.680311203,""69"":2.4209609032,""70"":4.1544342041,""71"":2.7248916626,""72"":0.2316660434,""73"":-10.9933567047,""74"":-10.8900413513,""75"":-13.0502586365,""76"":1.0268081427,""77"":-12.9347877502,""78"":-13.3705186844,""79"":-12.54591465,""80"":-11.3751506805,""81"":-11.8866844177,""82"":-11.3621902466,""83"":-13.0492401123,""84"":-11.9498796463,""85"":0.9917360544,""86"":-12.8845710754,""87"":2.6735789776,""88"":4.7899928093,""89"":4.963950634,""90"":2.722859621,""91"":0.5921399593,""92"":0.326787442,""93"":0.4891800582,""94"":2.9005055428,""95"":0.8935319185,""96"":-11.1357908249,""97"":-12.5900707245},""y2D"":{""0"":10.1058416367,""1"":9.4130125046,""2"":9.8165540695,""3"":9.3782777786,""4"":7.8022007942,""5"":9.793513298,""6"":6.8966288567,""7"":-10.7876110077,""8"":0.6452040076,""9"":7.4134159088,""10"":6.9126682281,""11"":9.8846902847,""12"":8.4227695465,""13"":7.7706036568,""14"":9.6168012619,""15"":-10.8188495636,""16"":6.196284771,""17"":9.2518777847,""18"":9.0863780975,""19"":10.0688619614,""20"":7.8263831139,""21"":-9.7818565369,""22"":8.2962827682,""23"":0.8085923791,""24"":5.6648564339,""25"":7.6837496758,""26"":7.2981843948,""27"":5.0682258606,""28"":-11.3684768677,""29"":-10.7714548111,""30"":-11.0529279709,""31"":7.5601081848,""32"":5.638753891,""33"":5.4227685928,""34"":-10.2462882996,""35"":9.6331338882,""36"":9.119058609,""37"":-11.1763248444,""38"":-11.1840009689,""39"":5.0167388916,""40"":9.7397584915,""41"":9.3438844681,""42"":8.0926704407,""43"":8.3230934143,""44"":6.4869775772,""45"":8.5718002319,""46"":7.6039075851,""47"":7.1950984001,""48"":7.348139286,""49"":0.8521497846,""50"":5.2635998726,""51"":9.3700866699,""52"":-10.4565849304,""53"":9.6724758148,""54"":-10.9518651962,""55"":-10.141910553,""56"":8.3950014114,""57"":8.2267971039,""58"":5.3031792641,""59"":0.9698141813,""60"":4.9009957314,""61"":5.8547921181,""62"":6.5476922989,""63"":5.3314223289,""64"":9.2547035217,""65"":7.5897402763,""66"":-9.785900116,""67"":-11.1925296783,""68"":-10.0600500107,""69"":9.0031147003,""70"":-10.8100862503,""71"":8.6148872375,""72"":8.8799762726,""73"":7.5552077293,""74"":7.0567874908,""75"":0.8802496791,""76"":8.2694549561,""77"":0.9421701431,""78"":4.8287248611,""79"":5.9174113274,""80"":6.5234260559,""81"":5.433382988,""82"":7.4227290154,""83"":5.2801699638,""84"":5.2163300514,""85"":7.8911042213,""86"":5.441880703,""87"":9.3811864853,""88"":-9.8399391174,""89"":-9.9687004089,""90"":9.2352561951,""91"":7.7664113045,""92"":8.6842136383,""93"":9.6159439087,""94"":8.8939743042,""95"":9.6336870193,""96"":7.4513735771,""97"":6.0815596581}}",False,False,False,http://link.springer.com/10.1007/978-3-540-70956-5_7,,"Visual Analytics: Definition, Process, and Challenges",7DLBYPHS,False,False
PPNESMHH,5RUCHG4U,"Organization Science
Vol. 16, No. 4, July–August 2005, pp. 409–421
issn 1047-7039(cid:1) eissn 1526-5455(cid:1) 05(cid:1) 1604(cid:1) 0409

informs ®

doi 10.1287/orsc.1050.0133
© 2005 INFORMS

Organizing and the Process of Sensemaking

Karl E. Weick, Kathleen M. Sutcliffe

Department of Management and Organizations, Ross School of Business, University of Michigan, 701 Tappan,

Ann Arbor, Michigan 48109-1234 {karlw@umich.edu, ksutclif@umich.edu}

Organization and Strategy, University of California, Irvine, Irvine, California 92697, dobstfel@uci.edu

David Obstfeld

Sensemaking involves turning circumstances into a situation that is comprehended explicitly in words and that serves as

a springboard into action. In this paper we take the position that the concept of sensemaking ﬁlls important gaps in
organizational theory. The seemingly transient nature of sensemaking belies its central role in the determination of human
behavior, whether people are acting in formal organizations or elsewhere. Sensemaking is central because it is the primary
site where meanings materialize that inform and constrain identity and action. The purpose of this paper is to take stock of
the concept of sensemaking. We do so by pinpointing central features of sensemaking, some of which have been explicated
but neglected, some of which have been assumed but not made explicit, some of which have changed in signiﬁcance over
time, and some of which have been missing all along or have gone awry. We sense joint enthusiasm to restate sensemaking
in ways that make it more future oriented, more action oriented, more macro, more closely tied to organizing, meshed
more boldly with identity, more visible, more behaviorally deﬁned, less sedentary and backward looking, more infused
with emotion and with issues of sensegiving and persuasion. These key enhancements provide a foundation upon which to
build future studies that can strengthen the sensemaking perspective.

Key words: sensemaking; interpreting; articulation; identity; power

Sensemaking involves

the ongoing retrospective
development of plausible images that rationalize what
people are doing. Viewed as a signiﬁcant process of
organizing, sensemaking unfolds as a sequence in which
people concerned with identity in the social context of
other actors engage ongoing circumstances from which
they extract cues and make plausible sense retrospec-
tively, while enacting more or less order into those ongo-
ing circumstances. Stated more compactly and more
colorfully, “[S]ensemaking is a way station on the road
to a consensually constructed, coordinated system of
action” (Taylor and Van Every 2000, p. 275). At that way
station, circumstances are “turned into a situation that is
comprehended explicitly in words and that serves as a
springboard to action” (p. 40). These images imply three
important points about the quest for meaning in orga-
nizational life. First, sensemaking occurs when a ﬂow
of organizational circumstances is turned into words and
salient categories. Second, organizing itself is embodied
in written and spoken texts. Third, reading, writing, con-
versing, and editing are crucial actions that serve as the
media through which the invisible hand of institutions
shapes conduct (Gioia et al. 1994, p. 365).

The emerging picture is one of sensemaking as a pro-
cess that is ongoing, instrumental, subtle, swift, social,
and easily taken for granted. The seemingly transient
nature of sensemaking (“a way station”) belies its cen-
tral role in the determination of human behavior. Sense-
making is central because it is the primary site where

meanings materialize that inform and constrain identity
and action (Mills 2003, p. 35). When we say that mean-
ings materialize, we mean that sensemaking is, impor-
tantly, an issue of language, talk, and communication.
Situations, organizations, and environments are talked
into existence.

Explicit efforts at sensemaking tend to occur when the
current state of the world is perceived to be different
from the expected state of the world, or when there is
no obvious way to engage the world. In such circum-
stances there is a shift from the experience of immersion
in projects to a sense that the ﬂow of action has become
unintelligible in some way. To make sense of the disrup-
tion, people look ﬁrst for reasons that will enable them to
resume the interrupted activity and stay in action. These
“reasons” are pulled from frameworks such as institu-
tional constraints, organizational premises, plans, expec-
tations, acceptable justiﬁcations, and traditions inherited
from predecessors. If resumption of the project is prob-
lematic, sensemaking is biased either toward identifying
substitute action or toward further deliberation.

Sensemaking is about

the interplay of action and
interpretation rather than the inﬂuence of evaluation
on choice. When action is the central focus, interpre-
tation, not choice, is the core phenomenon (Laroche
1995, p. 66; Lant 2002; Weick 1993, pp. 644–646).
Scott Snook (2001) makes this clear in his analysis of a
friendly ﬁre incident over Iraq in April 1994 when two
F-15 pilots shot down two friendly helicopters, killing

409

410

Weick, Sutcliffe, and Obstfeld: Organizing and the Process of Sensemaking
Organization Science 16(4), pp. 409–421, © 2005 INFORMS

26 people. As Snook says, this is not an incident where
F-15 pilots “decided” to pull the trigger.

I could have asked, “Why did they decide to shoot?”
However, such a framing puts us squarely on a path
that leads straight back to the individual decision maker,
away from potentially powerful contextual features and
right back into the jaws of the fundamental attribution
error. “Why did they decide to shoot?” quickly becomes
“Why did they make the wrong decision?” Hence, the
attribution falls squarely onto the shoulders of the deci-
sion maker and away from potent situation factors that
inﬂuence action. Framing the individual-level puzzle as
a question of meaning rather than deciding shifts the
emphasis away from individual decision makers toward a
point somewhere “out there” where context and individ-
ual action overlap (cid:1) (cid:1) (cid:1) (cid:1) Such a reframing—from decision
making to sensemaking—opened my eyes to the possibil-
ity that, given the circumstances, even I could have made
the same “dumb mistake.” This disturbing revelation,
one that I was in no way looking for, underscores the
importance of initially framing such senseless tragedies
as “good people struggling to make sense,” rather than
as “bad ones making poor decisions” (pp. 206–207).

To focus on sensemaking is to portray organizing
as the experience of being thrown into an ongoing,
unknowable, unpredictable streaming of experience in
search of answers to the question, “what’s the story?”
Plausible stories animate and gain their validity from
subsequent activity. The language of sensemaking cap-
tures the realities of agency, ﬂow, equivocality, tran-
sience, reaccomplishment, unfolding, and emergence,
realities that are often obscured by the language of
variables, nouns, quantities, and structures. Students of
sensemaking understand that the order in organizational
life comes just as much from the subtle, the small, the
relational, the oral, the particular, and the momentary as
it does from the conspicuous, the large, the substantive,
the written, the general, and the sustained. To work with
the idea of sensemaking is to appreciate that smallness
does not equate with insigniﬁcance. Small structures and
short moments can have large consequences.

We take the position that the concept of sensemaking
ﬁlls important gaps in organizational theory. We reaf-
ﬁrm this idea and take stock of the sensemaking concept
ﬁrst by highlighting its distinctive features descriptively,
using an extended example of pediatric nursing. Next
we summarize the distinctive features of sensemaking
conceptually and discuss intraorganizational evolution,
instigations, plausibility, and identity. Finally, we sum-
marize the distinctive features of sensemaking prospec-
tively and examine future lines of work that may develop
from ideas about institutions, distributed sensemaking,
power, and emotion. We conclude with a brief descrip-
tion of gaps in organizational theory that the concept of
sensemaking ﬁlls.

The Nature of Organized Sensemaking:
Viewed Descriptively
Organizational sensemaking is ﬁrst and foremost about
the question: How does something come to be an event
for organizational members? Second, sensemaking is
about the question: What does an event mean? In the
context of everyday life, when people confront some-
thing unintelligible and ask “what’s the story here?” their
question has the force of bringing an event into exis-
tence. When people then ask “now what should I do?”
this added question has the force of bringing meaning
into existence, meaning that they hope is stable enough
for them to act into the future, continue to act, and to
have the sense that they remain in touch with the con-
tinuing ﬂow of experience.

While these descriptions may help delimit sensemak-
ing, they say little about what is organizational in all of
this. The answer is that sensemaking and organization
constitute one another: “Organization is an attempt to
order the intrinsic ﬂux of human action, to channel it
toward certain ends, to give it a particular shape, through
generalizing and institutionalizing particular meanings
and rules” (Tsoukas and Chia 2002, p. 570). We need to
grasp each to understand the other. The operative image
of organization is one in which organization emerges
through sensemaking, not one in which organization pre-
cedes sensemaking or one in which sensemaking is pro-
duced by organization.

A central theme in both organizing and sensemak-
ing is that people organize to make sense of equivocal
inputs and enact this sense back into the world to make
that world more orderly. Basic moments in the process
of sensemaking are illustrated in the following account,
where a nurse describes what she did while caring for
a baby whose condition began to deteriorate (Benner
1994, pp. 139–140)1:

Nurse: I took care of a 900-gram baby who was about
26 or 27 weeks many years ago who had been doing
well for about two weeks. He had an open ductus that
day. The difference between the way he looked at 9 a.m.
and the way he looked at 11 a.m. was very dramatic.
I was at that point really concerned about what was going
to happen next. There are a lot of complications of the
patent ductus, not just in itself, but the fact that it causes
a lot of other things. I was really concerned that the baby
was starting to show symptoms of all of them.

Interviewer: Just in that two hours?

Nurse: You look at this kid because you know this kid,
and you know what he looked like two hours ago. It is a
dramatic difference to you, but it’s hard to describe that
to someone in words. You go to the resident and say:
“Look, I’m really worried about X, Y, Z,” and they go:
“OK.” Then you wait one half hour to 40 minutes, then
you go to the Fellow (the teaching physician supervising
the resident) and say: “You know, I am really worried
about X, Y, Z.” They say: “We’ll talk about it on rounds.”

Weick, Sutcliffe, and Obstfeld: Organizing and the Process of Sensemaking
Organization Science 16(4), pp. 409–421, © 2005 INFORMS

411

Interviewer: What is the X, Y, Z you are worried about?

Nurse: The fact that the kid is more lethargic, paler, his
stomach is bigger, that he is not tolerating his feedings,
that his chem strip (blood test) might be a little strange.
All these kinds of things. I can’t remember the exact
details of this case; there are clusters of things that go
wrong. The baby’s urine output goes down. They sound
like they are in failure. This kind of stuff. Their pulses
go bad, their blood pressure changes. There are a million
things that go on. At this time, I had been in the unit a
couple or three years.

Sensemaking Organizes Flux
Sensemaking starts with chaos. This nurse encounters
“a million things that go on” and the ongoing poten-
tial for “clusters of things that go wrong”—part of an
almost inﬁnite stream of events and inputs that surround
any organizational actor. As Chia (2000, p. 517) puts it,
we start with “an undifferentiated ﬂux of ﬂeeting sense-
impressions and it is out of this brute aboriginal ﬂux of
lived experience that attention carves out and concep-
tion names.” As the case illustrates, the nurse’s sense-
making does not begin de novo, but like all organizing
occurs amidst a stream of potential antecedents and con-
sequences. Presumably within the 24-hour period sur-
rounding the critical noticing, the nurse slept, awoke,
prepared for work, observed and tended to other babies,
completed paper work and charts, drank coffee, spoke
with doctors and fellow nurses, stared at an elevator
door as she moved between hospital ﬂoors, and per-
formed a variety of formal and impromptu observations.
All of these activities furnish a raw ﬂow of activity from
which she may or may not extract certain cues for closer
attention.

Sensemaking Starts with Noticing and Bracketing
During her routine activities, the nurse becomes aware
of vital signs that are at variance with the “normal”
demeanor of a recovering baby. In response to the
interruption, the nurse orients to the child and notices
and brackets possible signs of trouble for closer atten-
tion. This noticing and bracketing is an incipient state
of sensemaking. In this context sensemaking means
basically “inventing a new meaning (interpretation) for
something that has already occurred during the orga-
nizing process, but does not yet have a name (italics
in original), has never been recognized as a sepa-
rate autonomous process, object, event” (Magala 1997,
p. 324).

The nurse’s noticing and bracketing is guided by men-
tal models she has acquired during her work, training,
and life experience. Those mental models may help her
recognize and guide a response to an open ductus con-
dition or sickness more generally. Such mental models
might be primed by the patient’s conditions or a priori
permit her to notice and make sense of those conditions

(Klein et al., in press). Some combination of mental
models and salient cues calls her attention to this partic-
ular baby between the hours of 9 to 11 with respect to
a bounded set of symptoms.

The more general point is that in the early stages of
sensemaking, phenomena “have to be forcibly carved
out of the undifferentiated ﬂux of raw experience and
conceptually ﬁxed and labeled so that they can become
the common currency for communicational exchanges”
(Chia 2000, p. 517). Notice that once bracketing occurs,
the world is simpliﬁed.

Sensemaking Is About Labeling
Sensemaking is about labeling and categorizing to stabi-
lize the streaming of experience. Labeling works through
a strategy of “differentiation and simple-location, iden-
tiﬁcation and classiﬁcation, regularizing and routiniza-
tion [to translate] the intractable or obdurate into a
form that is more amenable to functional deployment”
(Chia 2000, p. 517). The key phrase here is “functional
deployment.” In medicine, functional deployment means
imposing diagnostic labels that suggest a plausible treat-
ment. In organizing in general, functional deployment
means imposing labels on interdependent events in ways
that suggest plausible acts of managing, coordinating,
and distributing. Thus, the ways in which events are ﬁrst
envisioned immediately begins the work of organizing
because events are bracketed and labeled in ways that
predispose people to ﬁnd common ground. To gener-
ate common ground, labeling ignores differences among
actors and deploys cognitive representations that are able
to generate recurring behaviors: “For an activity to be
said to be organized, it implies that types of behavior in
types of situation are systematically connected to types
of actors (cid:1) (cid:1) (cid:1) (cid:1) An organized activity provides actors with
a given set of cognitive categories and a typology of
actions” (Tsoukas and Chia 2002, p. 573).

A crucial feature of these types and categories is that
they have considerable plasticity. Categories have plas-
ticity because they are socially deﬁned, because they
have to be adapted to local circumstances, and because
they have a radial structure. By radial structure we mean
that there a few central instances of the category that
have all the features associated with the category, but
mostly the category contains peripheral instances that
have only a few of these features. This difference is
potentially crucial because if people act on the basis
of central prototypic cases within a category, then their
action is stable; but if they act on the basis of periph-
eral cases that are more equivocal in meaning, their
action is more variable, more indeterminate, more likely
to alter organizing, and more consequential for adapting
(Tsoukas and Chia 2002, p. 574).

Sensemaking Is Retrospective
The nurse uses retrospect to make sense of the puzzles
she observes at 11:00. She recalls “what he looked like

412

Weick, Sutcliffe, and Obstfeld: Organizing and the Process of Sensemaking
Organization Science 16(4), pp. 409–421, © 2005 INFORMS

two hours ago. It’s a dramatic difference.” Symptoms are
not discovered at 11:00. Instead, symptoms are created
at 11:00 by looking back over earlier observations and
seeing a pattern. The nurse alters the generic sensemak-
ing recipe, “how can I know what I think until I see what
I say,” into the medically more useful variant, “how can
I know what I’m seeing until I see what it was.”

Marianne Paget (1988, p. 56) has been especially sen-
sitive to the retrospective quality of medical work as
is evident in her description of mistakes in diagnosis:
“A mistake follows an act. It identiﬁes the character of
an act in its aftermath. It names it. An act, however, is
not mistaken; it becomes mistaken. There is a paradox
here, for seen from the inside of action, that is from the
point of view of an actor, an act becomes mistaken only
after it has already gone wrong. As it is unfolding, it
is not becoming mistaken at all; it is becoming.” When
people bracket a portion of streaming circumstances and
label them as a concern, a bad sign, a mistake, or an
opportunity, the event is at an advanced stage; the label
follows after and names a completed act, but the label-
ing itself fails to capture the dynamics of what is hap-
pening. Because mistakes and diagnoses are known in
the aftermath of activity, they are fruitfully described as
“complex cognitions of the experience of now and then.
They identify the too-lateness of human understanding”
(Paget 1988, pp. 96–97). So, “the now of mistakes col-
lides with the then of acting with uncertain knowledge.
Now represents the more exact science of hindsight, then
the unknown future coming into being” (Paget 1988,
p. 48).

Sensemaking Is About Presumption
To make sense is to connect the abstract with the con-
crete. In the case of medical action, “instances of illness
are concrete, idiosyncratic, and personal in their expres-
sion, and the stock of knowledge is abstract and ency-
clopedic. Interpretation and experimentation engage the
concrete, idiosyncratic, and personal with the abstract
and impersonal” (Paget 1988, p. 51). It is easy to miss
this linkage and to portray sensemaking as more cere-
bral, more passive, more abstract than it typically is.
Sensemaking starts with immediate actions, local con-
text, and concrete cues, as is true for the worried nurse.
She says to the resident, “Look, I’m really worried about
X, Y, Z.”

What is interesting about her concerns is that she is
acting as if something is the case, which means any fur-
ther action tests that hunch but may run a risk for the
baby. To test a hunch is to presume the character of
the illness and to update that presumptive understand-
ing through progressive approximations: “The [medical]
work process unfolds as a series of approximations
and attempts to discover an appropriate response. And
because it unfolds this way, as an error-ridden activity,
it requires continuous attention to the patient’s condition
and to reparation” (Paget 1988, p. 143).

Sensemaking Is Social and Systemic
The nurse’s sensemaking is inﬂuenced by a variety of
social factors. These social factors might include previ-
ous discussions with the other nurses on duty, an off-
hand remark about the infant that might have been made
by a parent, interaction with physicians—some of whom
encourage nurses to take initiative and some who do
not—or the mentoring she received yesterday.

However, it is not just the concerned nurse and her
contacts that matter in this unfolding incident. Medi-
cal sensemaking is distributed across the healthcare sys-
tem, and converges on the tiny patient as much through
scheduling that involves cross-covering of one nurse’s
patients by another nurse (and through multiple brands
of infusion pumps with conﬂicting setup protocols) as
it does through the occasional appearance of the attend-
ing physician at the bedside. If knowledge about the
correctness of treatment unfolds gradually, then knowl-
edge of this unfolding sense is not located just inside the
head of the nurse or physician. Instead, the locus is sys-
temwide and is realized in stronger or weaker coordina-
tion and information distribution among interdependent
healthcare workers.

Sensemaking Is About Action
If the ﬁrst question of sensemaking is “what’s going on
here?,” the second, equally important question is “what
do I do next?” This second question is directly about
action, as is illustrated in this case, where the nurse’s
emerging hunch is intertwined with the essential task of
enlisting a physician to take action on the case. The talk
that leads to a continual, iteratively developed, shared
understanding of the diagnosis and the persuasive talk
that leads to enlistment in action both illustrate the “say-
ing” that is so central to organizational action. In sense-
making, action and talk are treated as cycles rather than
as a linear sequence. Talk occurs both early and late,
as does action, and either one can be designated as the
“starting point to the destination.” Because acting is an
indistinguishable part of the swarm of ﬂux until talk
brackets it and gives it some meaning, action is not
inherently any more signiﬁcant than talk, but it factors
centrally into any understanding of sensemaking.

Medical sensemaking is as much a matter of thinking
that is acted out conversationally in the world as it is a
matter of knowledge and technique applied to the world.
Nurses (and physicians), like everyone else, make sense
by acting thinkingly, which means that they simultane-
ously interpret their knowledge with trusted frameworks,
yet mistrust
those very same frameworks by testing
new frameworks and new interpretations. The underlying
assumption in each case is that ignorance and knowl-
edge coexist, which means that adaptive sensemaking
both honors and rejects the past. What this means is that
in medical work, as in all work, people face evolving
disorder. There are truths of the moment that change,

Weick, Sutcliffe, and Obstfeld: Organizing and the Process of Sensemaking
Organization Science 16(4), pp. 409–421, © 2005 INFORMS

413

develop, and take shape through time. It is these changes
through time that progressively reveal that a seemingly
correct action “back then” is becoming an incorrect
action “now.” These changes also may signal a progres-
sion from worse to better.

Sensemaking Is About Organizing Through
Communication
Communication is a central component of sensemaking
and organizing: “We see communication as an ongo-
ing process of making sense of the circumstances in
which people collectively ﬁnd ourselves and of the
events that affect them. The sensemaking, to the extent
that it involves communication, takes place in interac-
tive talk and draws on the resources of language in order
to formulate and exchange through talk (cid:1) (cid:1) (cid:1) symbolically
encoded representations of these circumstances. As this
occurs, a situation is talked into existence and the basis
is laid for action to deal with it” (Taylor and Van Every
2000, p. 58). The image of sensemaking as activity that
talks events and organizations into existence suggests
that patterns of organizing are located in the actions and
conversations that occur on behalf of the presumed orga-
nization and in the texts of those activities that are pre-
served in social structures.

We see this in the present example. As the case illus-
trates, the nurse’s bracketed set of noticings coalesce
into an impression of the baby as urgently in need of
physician attention, but the nurse’s choice to articulate
her concerns ﬁrst to a resident and then to a Fellow pro-
duces little immediate result. Her individual sensemak-
ing has little inﬂuence on the organizing of care around
this patient as this passage shows (Benner 1994, p. 140):

(cid:1) (cid:1) (cid:1) At this time, I had been in the unit a couple or three
years. I was really starting to feel like I knew what was
going on but I wasn’t as good at throwing my weight
in a situation like that. And I talked to a nurse who had
more experience and I said, “Look at this kid,” and I told
her my story, and she goes: “OK.” Rounds started shortly
after that and she walks up to the Attending [Physician in
charge of patient] very quietly, sidles up and says: “You
know, this kid, Jane is really worried about this kid.”
She told him the story, and said: “He reminds me about
this kid, Jimmie, we had three weeks ago,” and he said:
“Oh.” Everything stops. He gets out the stethoscope and
listens to the kid, examines the kid and he says: “Call
the surgeons.” (Laughter) It’s that kind of thing where
we knew also what had to be done. There was no time
to be waiting around. He is the only one that can make
that decision. It was a case we had presented to other
physicians who should have made the case, but didn’t.
We are able in just two sentences to make that case to
the Attending because we knew exactly what we were
talking about. (cid:1) (cid:1) (cid:1) this particular nurse really knew exactly
what she was doing. [The Attending] knew she knew
what she was doing (cid:1) (cid:1) (cid:1) (cid:1) She knew exactly what button
to push with him and how to do it.

What we see here is articulation (Benner 1994, Winter
1987), which is deﬁned as “the social process by which
tacit knowledge is made more explicit or usable.” To
share understanding means to lift equivocal knowledge
out of the tacit, private, complex, random, and past to
make it explicit, public, simpler, ordered, and relevant
to the situation at hand (Obstfeld 2004). Taylor and Van
Every (2000, pp. 33–34) describe a process similar to
articulation: “A situation is talked into being through the
interactive exchanges of organizational members to pro-
duce a view of circumstances including the people, their
objects, their institutions and history, and their siting
[i.e., location as a site] in a ﬁnite time and place.” This
is what happens successively as the ﬁrst nurse trans-
lates her concerns for the second more powerful nurse,
who then rearticulates the case using terms relevant to
the Attending. The second nurse absorbs the complex-
ity of the situation (Boisot and Child 1999) by holding
both a nurse’s and doctor’s perspectives of the situation
while identifying an account of the situation that would
align the two. What is especially interesting is that she
tries to make sense of how other people make sense of
things, a complex determination that is routine in orga-
nizational life.

Summary
To summarize, this sequence highlights several distin-
guishing features of sensemaking, including its genesis
in disruptive ambiguity, its beginnings in acts of noticing
and bracketing, its mixture of retrospect and prospect,
its reliance on presumptions to guide action, its embed-
ding in interdependence, and its culmination in artic-
ulation that shades into acting thinkingly. Answers to
the question “what’s the story?” emerge from retrospect,
connections with past experience, and dialogue among
people who act on behalf of larger social units. Answers
to the question “now what?” emerge from presumptions
about the future, articulation concurrent with action, and
projects that become increasingly clear as they unfold.

The Nature of Organized Sensemaking:
Viewed Conceptually
Sensemaking as Intraorganizational Evolution
The preceding overview of early activities of sensemak-
ing and organizing that mobilize around moments of ﬂux
needs to be compressed if it is to guide research and
practice. One way to do that is to assume that “a sys-
tem can respond adaptively to its environment by mim-
icking inside itself the basic dynamics of evolutionary
processes” (Warglien 2002, p. 110). The basic evolution-
ary process assumed by sensemaking is one in which
retrospective interpretations are built during interdepen-
dent interaction. This framework is a variant of Donald

414

Weick, Sutcliffe, and Obstfeld: Organizing and the Process of Sensemaking
Organization Science 16(4), pp. 409–421, © 2005 INFORMS

Campbell’s application of evolutionary epistemology to
social
life (1965, 1997). It proposes that sensemak-
ing can be treated as reciprocal exchanges between
actors (Enactment) and their environments (Ecological
Change) that are made meaningful (Selection) and pre-
served (Retention). However, these exchanges will con-
tinue only if the preserved content
is both believed
(positive causal linkage) and doubted (negative causal
linkage) in future enacting and selecting. Only with
ambivalent use of previous knowledge are systems able
both to beneﬁt from lessons learned and to update either
their actions or meanings in ways that adapt to changes
in the system and its context. For shorthand we will
call this model “enactment theory,” as has become the
convention in organizational work (e.g., Jennings and
Greenwood 2003). Graphically, the ESR sequence looks
like Figure 1.

If we conceptualize organizing as a sequence of eco-
logical change-enactment-selection-retention with the
results of retention feeding back to all three prior pro-
cesses, then the speciﬁc activities of sensemaking ﬁt
neatly into this more general progression of organizing.
The reciprocal relationship between ecological change
and enactment includes sensemaking activities of sens-
ing anomalies, enacting order into ﬂux, and being shaped
by externalities. The organizing process of enactment
incorporates the sensemaking activities of noticing and
bracketing. These activities of noticing and bracketing,
triggered by discrepancies and equivocality in ongo-
ing projects, begin to change the ﬂux of circumstances
into the orderliness of situations. We emphasize “begin”
because noticing and bracketing are relatively crude acts
of categorization and the resulting data can mean sev-
eral different things. The number of possible meanings
gets reduced in the organizing process of selection. Here
a combination of retrospective attention, mental mod-
els, and articulation perform a narrative reduction of

the bracketed material and generate a locally plausi-
ble story. Though plausible, the story that is selected is
also tentative and provisional. It gains further solidity
in the organizing process of retention. When a plausi-
ble story is retained, it tends to become more substan-
tial because it is related to past experience, connected
to signiﬁcant identities, and used as a source of guid-
ance for further action and interpretation. The close ﬁt
between processes of organizing and processes of sense-
making illustrates the recurring argument (e.g., Weick
1969, pp. 40–42) that people organize to make sense of
equivocal inputs and enact this sense back into the world
to make that world more orderly. The beauty of mak-
ing ESR the microfoundation of organizing and sense-
making is that it makes it easier to work with other
meso- and macro-level formulations that are grounded in
Campbell’s work (e.g., Aldrich 1999, Baum and Singh
1994, Ocasio 2001).

Instigations to Sensemaking
The idea that sensemaking is focused on equivocality
gives primacy to the search for meaning as a way to
deal with uncertainty (e.g., Mills 2003, p. 44). Thus,
we expect to ﬁnd explicit efforts at sensemaking when-
ever the current state of the world is perceived to be
different from the expected state of the world. This
means that sensemaking is activated by the question,
“same or different?” When the situation feels “differ-
ent,” this circumstance is experienced as a situation of
discrepancy (Orlikowski and Gash 1994), breakdown
(Patriotta 2003), surprise (Louis 1980), disconﬁrmation
(Weick and Sutcliffe 2001), opportunity (Dutton 1993),
or interruption (Mandler 1984, pp. 180–189). Diverse
as these situations may seem, they share the proper-
ties that in every case an expectation of continuity is
breached, ongoing organized collective action becomes

Figure 1 The Relationship Among Enactment, Organizing, and Sensemaking

Ongoing updating

Retrospect

extracted cues

Identity

plausibility

Ecological

change

Enactment

Selection

Retention

Source. Jennings and Greenwood (2003; adapted from Weick 1979, p. 132).

Feedback of  identity on
selection and enactment

Weick, Sutcliffe, and Obstfeld: Organizing and the Process of Sensemaking
Organization Science 16(4), pp. 409–421, © 2005 INFORMS

415

disorganized, efforts are made to construct a plausible
sense of what is happening, and this sense of plausibil-
ity normalizes the breach, restores the expectation, and
enables projects to continue.

Questions of “same or different” tend to occur under
one of three conditions: situations involving the dramatic
loss of sense (e.g., Lanir 1989), situations where the loss
of sense is more mundane but no less troublesome (e.g.,
Westley 1990), and unfamiliar contexts where sense is
elusive (e.g., Orton 2000). Methodologically, it is hard
to ﬁnd people in the act of coping with disconﬁrmations
that catch them unawares (see Westrum 1982 for a clear
exception). Such outcroppings can be found, however, if
we examine how everyday situations sometimes present
us with either too many meanings or too few. For exam-
ple, managing any kind of process (e.g., a production
routine) with its interconnected processes of anticipation
and retrospection (Patriotta 2003) creates equivocality
of time (e.g., is this a fresh defect, or has it happened
for some time?) and equivocality of action (e.g., do I
have the resources to correct this defect?). Regardless
of whether there are too many meanings or too few, the
result is the same. Actors are faced with ﬂeeting sense
impressions that instigate sensemaking.

While scholars have a strong interest in conscious
sensemaking and in making the sensemaking process
more visible, they also agree with Gioia and Mehra
(1996, p. 1,228), who suggest that much of organiza-
tional life is routine and made up of situations that do
not demand our full attention. As they note, people’s
sense can be “modiﬁed in intricate ways out of aware-
ness via assimilation of subtle cues over time” (p. 1,229).
Acknowledgement of this facet of sensemaking is impor-
tant if only to avoid the impression that “routine organi-
zational life is devoid of sense” (Gioia and Mehra 1996,
p. 1,229).

Plausibility and Sensemaking
Sensemaking is not about
truth and getting it right.
Instead, it is about continued redrafting of an emerging
story so that it becomes more comprehensive, incorpo-
rates more of the observed data, and is more resilient
in the face of criticism. As the search for meanings
continues, people may describe their activities as the
pursuit of accuracy to get it right. However, that descrip-
tion is important mostly because it sustains motivation.
People may get better stories, but they will never get
the story. Furthermore, what is plausible for one group,
such as managers, often proves implausible for another
group, such as employees. In an important study of cul-
ture change, Mills (2003, pp. 169–173) found that sto-
ries tend to be seen as plausible when they tap into an
ongoing sense of current climate, are consistent with
other data, facilitate ongoing projects, reduce equivocal-
ity, provide an aura of accuracy (e.g., reﬂect the views

of a consultant with a strong track record), and offer a
potentially exciting future.

The idea that sensemaking is driven by plausibil-
ity rather than accuracy (Weick 1995, p. 55) conﬂicts
with academic theories and managerial practices that
assume that the accuracy of managers’ perceptions deter-
mine the effectiveness of outcomes. The assumption that
accuracy begets effectiveness builds on a long stream
of research on environmental scanning, strategic plan-
ning, rational choice, and organizational adaptation (e.g.,
Duncan 1972, Pfeffer and Salancik 1978) and persists,
for example, in current theorizing on search and adaptive
learning (e.g., Gavetti and Levinthal 2000) and strate-
gic decision making (e.g., Bukszar 1999).

However, studies assessing the accuracy of manager’s
perceptions are rare (see Sutcliffe 1994, Starbuck and
Mezias 1996 for exceptions), and those studies that
have been done suggest that managers’ perceptions are
highly inaccurate (Mezias and Starbuck 2003). This may
explain why some scholars propose that the key prob-
lem for an organization is not to accurately assess scarce
data, but to interpret an abundance of data into “action-
able knowledge” (Bettis and Prahalad 1995). These cri-
tiques have raised the question of the relative importance
and role of executives’ perceptual inputs relative to their
interpretations of these inputs. Kruglanski (1989) argues,
for example, that perceptual accuracy should be treated
as pragmatic utility, judged only by its usefulness for
beneﬁcial action.

A focus on perceptual accuracy is grounded in models
of rational decision making: A given problem is evalu-
ated in relation to stable goals and a course of action
chosen from a set of alternatives. In this model, accurate
information is important in evaluating the feasibility and
utility of alternative actions, and accurate perceptions
increase decision quality. However, actual organizations
do not ﬁt this conception. Problems must be brack-
eted from an amorphous stream of experience and be
labeled as relevant before ongoing action can be focused
on them. Furthermore, managers with limited attention
face many such issues at the same time, often eval-
uating several situations, interpretations, choices, and
actions simultaneously. Thus, inaccurate perceptions are
not necessarily a bad thing, as Mezias and Starbuck
(2003) conclude. People do not need to perceive the
current situation or problems accurately to solve them;
they can act effectively simply by making sense of cir-
cumstances in ways that appear to move toward gen-
eral long-term goals. Managerial misperceptions may
not curtail effective performance if agents have learning
mechanisms and operate in a context where there are
incentives to improve performance (Mezias and Starbuck
2003, p. 15; Winter 2003, p. 42).

The important message is that if plausible stories keep
things moving, they are salutary. Action-taking generates

416

Weick, Sutcliffe, and Obstfeld: Organizing and the Process of Sensemaking
Organization Science 16(4), pp. 409–421, © 2005 INFORMS

new data and creates opportunities for dialogue, bargain-
ing, negotiation, and persuasion that enriches the sense
of what is going on (Sutcliffe 2000). Actions enable peo-
ple to assess causal beliefs that subsequently lead to new
actions undertaken to test the newly asserted relation-
ships. Over time, as supporting evidence mounts, signif-
icant changes in beliefs and actions evolve.

Identity and Sensemaking
Identity construction is seen by many to be one of the
two basic properties that differentiate sensemaking from
basic cognitive psychology (Gililand and Day 2000,
p. 334). The other property is the use of plausibility as
the fundamental criterion of sensemaking. Mills (2003)
made a similar point when she organized her study of
culture change at Nova Scotia Power around identity
construction, which “is at the root of sensemaking and
inﬂuences how other aspects, or properties of the sense-
making process are understood” (Mills 2003, p. 55).

Discussions of organizational

identity tend to be
anchored by Albert and Whetten’s (1985) description of
identity as that which is core, distinctive, and enduring
about the character of the organization. From the per-
spective of sensemaking, who we think we are (identity)
as organizational actors shapes what we enact and how
we interpret, which affects what outsiders think we are
(image) and how they treat us, which stabilizes or desta-
bilizes our identity. Who we are lies importantly in the
hands of others, which means our categories for sense-
making lie in their hands. If their images of us change,
our identities may be destabilized and our receptiveness
to new meanings increase. Sensemaking, ﬁltered through
issues of identity, is shaped by the recipe “how can I
know who we are becoming until I see what they say
and do with our actions?”

The pathway from image change to identity change is
demonstrated in Gioia and Thomas (1996). Their work
suggests that if managers can change the images that
outsiders send back to the organization, and if insiders
use those images to make sense of what their actions
mean, then these changes in image will serve as a cat-
alyst for reﬂection and redrafting of how the organiza-
tion deﬁnes itself. The controversy implicit in Gioia and
Thomas’s ﬁndings is the suggestion that identity may not
be nearly as enduring as ﬁrst thought, and may be more
usefully conceptualized as a variable, mutable continuity
(Gioia et al. 2000). If this were found to be the case,
then identity would turn out to be an issue of plausibility
rather than accuracy, just as is the case for many issues
that involve organizing and sensemaking.

Gioia and Chittipeddi (1991) set the stage for many
of the current concerns with identity and image in their
early ﬁnding that sensemaking is incomplete unless there
is sensegiving, a sensemaking variant undertaken to cre-
ate meanings for a target audience. The reﬁnement of
this demonstration is the ﬁnding that
the content of

sensegiving (present versus future image) and the tar-
get (insider versus outsider) affect how people interpret
the actions they confront. Yet to be examined is the
effect of efforts at sensegiving on the sensemakers. In
the sensemaking recipe “how can I know what I think
until I see what I say?” sensegiving corresponds to the
saying. However, notice that the saying is problematic,
you do not really know what you think until you do say
it. When you hear yourself talk, you see more clearly
what matters and what you had hoped to say. Sensegiv-
ing therefore may affect the sensemaker as well as the
target. For example, in Gioia and Chittipeddi’s study,
those administrators trying to move a university’s iden-
tity and image into the category “top 10 university” may
themselves have thought differently about this issue as
they articulated their campaign to improve the univer-
sity’s reputation.

It is clear that the stakes in sensemaking are high
when issues of identity are involved. When people face
an unsettling difference, that difference often translates
into questions such as who are we, what are we doing,
what matters, and why does it matter? These are not
trivial questions. As Coopey et al. (1997, p. 312, cited
in Brown 2000) note,

Faced with events that disrupt normal expectations and,
hence, the efﬁcacy of established patterns of meaning and
associated behavior, individuals attempt to make sense
of ambiguous stimuli in ways that respond to their own
identity needs. They are able to draw creatively on their
memory—especially their personal experience—in com-
posing a story that begins to make sense of what is
happening while potentially enhancing their feelings of
self-esteem and self-efﬁcacy. The story is a sufﬁciently
plausible account of “what is happening out there?” that
it can serve as a landscape within which they and others
might be able to make commitments and to act in ways
that serve to establish new meanings and new patterns of
behavior.

The outcomes of such processes, however, are not
always sanguine. This was the case in Bristol Royal
Inﬁrmary’s (BRI) continuation of a pediatric cardiac
surgery program for almost 14 years in the face of
data showing a mortality rate roughly double the rate
of any other center in England (Weick and Sutcliffe
2003, p. 76). The board of inquiry that investigated this
incident concluded that there was a prevailing mindset
among people at BRI that enabled them to “wish away
their poor results” as a “run of bad luck” even though
“there was evidence sufﬁcient to put the Unit on notice
that there were questions to be answered as regards the
adequacy of the service” (Kennedy 2001, pp. 247–248).
That mindset prevailed partly because surgeons con-
structed their identity as that of people learning complex
surgical procedures in the context of unusually challeng-
ing cases. The dangerous omission in this identity was
that the resources they used for learning were minimal.

Weick, Sutcliffe, and Obstfeld: Organizing and the Process of Sensemaking
Organization Science 16(4), pp. 409–421, © 2005 INFORMS

They did not collect detailed data about their own prior
performance, solicit input from other members of the
surgical team, or observe the work of other surgeons
who were more skilled at this procedure until formal
complaints were ﬁled against pediatric surgeons.

The Nature of Organized Sensemaking:
Viewed Prospectively
Considering the modest amount of empirical work on
sensemaking that has accumulated so far, the question
of “future directions” pretty much takes care of itself.
Almost any kind of work is likely to enhance our under-
standing of a largely invisible, taken-for-granted social
process that is woven into communication and activ-
ity in ways that seem to mimic Darwinian evolution.
We brieﬂy discuss institutionalization, distributed sense-
making, power, and emotion to illustrate a few of the
many ways in which present thinking about sensemaking
might be enhanced.

Sensemaking and Institutional Theory
We have treated organizing as activity that provides a
more ordered social reality by reducing equivocality.
A crucial question is whether that reality gets renego-
tiated in every social interaction or whether, as Zucker
(1983) puts it, “institutionalization simply constructs the
way things are: alternatives may be literally unthinkable”
(p. 5). The tension inherent in these otherwise “cool”
positions is evident when Czarniawska (2003, p. 134)
observes that “Intentional action never leads to intended
results, simply because there is a lot of intentional action
directed at different aims in each time and place. Insti-
tutionalization, like power, is a post factum description
of the resultant of all those efforts combined with the
random events that accompanied them.”

Discussions of sensemaking often include words
like “construct,” “enact,” “generate,” “create,” “invent,”
“imagine,” “originate,” and “devise.” Less often do we
ﬁnd words like “react,” “discover,” “detect,” “become
aware of,” or “comply with.” This asymmetry suggests
that people who talk about sensemaking may exagger-
ate agency and may be reluctant to assume that peo-
ple internalize and adopt whatever is handed to them,
as Zucker suggests. An example of such exaggeration
might be the statement, “sensemaking is the feedstock
for institutionalization” (Weick 1995, p. 36). Institution-
alists might well argue that the causal arrow in this
assertion points in the wrong direction. The causal arrow
neglects evidence showing that organizational members
are socialized (indoctrinated) into expected sensemak-
ing activities and that ﬁrm behavior is shaped by broad
cognitive, normative, and regulatory forces that derive
from and are enforced by powerful actors such as mass
media, governmental agencies, professions, and interest
groups (Lounsbury and Glynn 2001). In other words,

417

“no organization can properly be understood apart from
its wider social and cultural context” (Scott 1995,
p. 151).

These diverse positions can begin to be reconciled
if we focus on mechanisms that link micro-macro lev-
els of analysis and if we pay as much attention to
structuring and conversing as we do to structures and
texts. One way to further such reconciliation is to fol-
low the lead of Hedstrom and Swedberg (1998), who
argue that when we want to explain change and vari-
ation at the macrolevel of analysis, we need to show
“how macro states at one point in time inﬂuence the
behavior of individual actors, and how these actions
generate new macro states at a later time” (p. 21).
Sensemaking can provide micromechanisms that link
macrostates across time through explication of cognitive
structures associated with mimetic processes, agency,
the mobilization of resistance, alternatives to confor-
mity such as independence, anticonformity, and unifor-
mity (Weick 1979, p. 115), and ways in which ongoing
interaction generates the taken for granted. Examples of
such mechanisms are found in Elsbach’s (2002) descrip-
tion of institutions within organizations and in descrip-
tions of “conventions” in the French Convention School
of institutionalists’ thought (Storpor and Salais 1997,
pp. 15–43).

this (see the important

The juxtaposition of sensemaking and institutional-
ism has been rare, but there are recent efforts to cor-
rect
integration proposed by
Jennings and Greenwood 2003). For example, Klaus
Weber’s (2003) study of globalization and convergence
speciﬁcally connects the sensemaking and macroinstitu-
tional perspectives. Weber focuses on the content rather
than the process of sensemaking. He argued that the
media provides corporate vocabularies, and that cor-
porate social structures direct the distribution of these
vocabularies among actors. His ﬁndings suggest
that
while institutions in the form of public discourse deﬁne
and impose the problems to which corporate actors
respond, those public institutions do not appear to direct
the solutions. Thus, public discourse appears to direct
corporate attention, set agendas, and frame issues, but it
is less critical for supplying response repertoires. Weber
concludes that the relationship between institutions and
corporate sensemaking is not linear; the use of corpo-
rate sensemaking vocabularies tends to be triggered by
institutions, but institutions have less inﬂuence over what
happens subsequent to triggering.

Distributed Sensemaking
The rhetoric of “shared understanding,” “common
sense,” and “consensus,” is commonplace in discussions
of organized sensemaking. However, the haunting ques-
tions remain: Are shared beliefs a necessary condition
for organized action (Lant 2002, p. 355), and is the con-
struct of collective belief theoretically meaningful (Porac

418

Weick, Sutcliffe, and Obstfeld: Organizing and the Process of Sensemaking
Organization Science 16(4), pp. 409–421, © 2005 INFORMS

et al. 2002, p. 593)? The drama associated with such
questions is demonstrated by Hughes et al. (1992) in
their study of reliability in the UK air trafﬁc control
system:

If one looks to see what constitutes this reliability, it can-
not be found in any single element of the system. It is
certainly not to be found in the equipment (cid:1) (cid:1) (cid:1) for a period
of several months during our ﬁeld work it was failing
regularly (cid:1) (cid:1) (cid:1) (cid:1) Nor is it to be found in the rules and proce-
dures, which are a resource for safe operation but which
can never cover every circumstance and condition. Nor is
it to be found in the personnel who, though very highly
skilled, motivated and dedicated, are as prone as peo-
ple everywhere to human error. Rather we believe it is
to be found in the cooperative activities of controllers
across the “totality” of the system, and in particular in the
way that it enforces the active engagement of controllers,
chiefs, and assistants with the material they are using and
with each other (cited in Woods and Cook 2000, p. 164).

Promising lines of development would seem to occur
if work on distributed cognition (Hutchins 1995), heed-
ful interrelating (Weick and Roberts 1993), and variable
disjunction of information2 (Turner 1978, p. 50) were
focused less on the assembling and diffusing of preex-
isting meaning and more on collective induction of new
meaning (see Laughlin and Hollingshead 1995 for labo-
ratory investigations of this issue). When information is
distributed among numerous parties, each with a differ-
ent impression of what is happening, the cost of recon-
ciling these disparate views is high, so discrepancies and
ambiguities in outlook persist. Thus, multiple theories
develop about what is happening and what needs to be
done, people learn to work interdependently despite cou-
plings loosened by the pursuit of diverse theories, and
inductions may be more clearly associated with effec-
tiveness when they provide equivalent rather than shared
meanings.

Sensemaking and Power
Sensemaking strikes some people as naïve with regard
to the red meat of power, politics, and critical theory.
People who are powerful, rich, and advantaged seem to
have unequal access to roles and positions that give them
an unequally strong position to inﬂuence the construc-
tion of social reality (Mills 2003, p. 153). Sensemaking
discussions do tend to assume that meanings survive as
a result of voting (e.g., Weick 1995, p. 6), with the pro-
viso that sometimes the votes are weighted equally and
sometimes they are not.

Enhancements of sensemaking that pay more attention
to power will tend to tackle questions such as how does
power get expressed, increase, decrease, and inﬂuence
others? Preliminary answers are that power is expressed
in acts that shape what people accept, take for granted,
and reject (Pfeffer 1981). How does such shaping occur?
Through things like control over cues, who talks to

whom, proffered identities, criteria for plausible stories,
actions permitted and disallowed, and histories and ret-
rospect that are singled out. To shape hearts and minds
is to inﬂuence at least seven dimensions of sensemak-
ing: the social relations that are encouraged and dis-
couraged, the identities that are valued or derogated, the
retrospective meanings that are accepted or discredited,
the cues that are highlighted or suppressed, the updat-
ing that is encouraged or discouraged, the standard of
accuracy or plausibility to which conjectures are held,
and the approval of proactive or reactive action as the
preferred mode of coping.

Sensemaking and Emotion
Magala (1997, p. 324) argued that perhaps the most
important lost opportunity in the 1995 book Sensemak-
ing in Organizations was fuller development of a theory
of organizational sentiments. Such a theory was “hinted
at but ignored.” The opening for further development of
emotional sensemaking was the property that projects
are ongoing, and when interrupted generate either neg-
ative emotions when resumption is thwarted or positive
emotions when resumption is facilitated. If emotion is
restricted to events that are accompanied by autonomic
nervous system arousal (Berscheid and Ammazzalorso
2003, p. 312; Schachter and Singer 1962), if the detec-
tion of discrepancy provides the occasion for arousal
(Mandler 1997), and if arousal combines with a posi-
tive or negative valenced cognitive evaluation of a sit-
uation (e.g., a threat to well-being or an opportunity to
enhance well-being), then sensemaking in organizations
will often occur amidst intense emotional experience.
Consider the case of high task interdependence. As the
interdependent partners “learn more about each other
and move toward closeness by becoming increasingly
dependent on each other’s activities for the performance
of their daily behavioral routines and the fulﬁllment of
their plans and goals, the number and strength of their
expectancies about each other increase. As a result, their
opportunities for expectancy violation, and for emotional
experience also increase” (Berscheid and Ammazzalorso
2003, p. 317). When an important expectancy is vio-
lated, the partner becomes less familiar, less safe, and
more of a stranger. In the face of an emotional outburst,
people often ask in disbelief “what did I do?!” That is
the wrong question. The better question is “what did you
expect” (Berscheid and Ammazzalorso 2003, p. 318)?
Expectations hold people hostage to their relationships
in the sense that each expectancy can be violated, and
generates a discrepancy, an emotion, and a valenced
interpretation. If I expect little, there is little chance
for discrepancy and little chance for emotion. However,
when “an outside event produces negative emotion for an
individual in a close relationship, the individual’s part-
ner may be less likely to remain tranquil and supportive
than a superﬁcial partner might be because the partner

Weick, Sutcliffe, and Obstfeld: Organizing and the Process of Sensemaking
Organization Science 16(4), pp. 409–421, © 2005 INFORMS

419

is likely to be experiencing emotion him or herself; the
partner’s emotional state, in turn, may interfere with the
partner’s ability to perform as the individual expects”
(Berscheid and Ammazzalorso 2003, p. 324).

Further exploration of emotion and sensemaking is
crucial to clear up questions such as whether intraorga-
nizational institutions are better portrayed as cold cog-
nitive scripts built around rules or as hot emotional
attitudes built around values (Elsbach 2002, p. 52).

Conclusions
To deal with ambiguity, interdependent people search
for meaning, settle for plausibility, and move on. These
are moments of sensemaking, and scholars stretch those
moments, scrutinize them, and name them in the belief
that they affect how action gets routinized, ﬂux gets
tamed, objects get enacted, and precedents get set. Work
to date suggests that the study of sensemaking is use-
ful for organizational studies because it ﬁlls several
gaps. Analyses of sensemaking provide (1) a micro-
mechanism that produces macro-change over
time;
(2) a reminder that action is always just a tiny bit ahead
of cognition, meaning that we act our way into belated
understanding; (3) explication of predecisional activities;
(4) description of one means by which agency alters
institutions and environments (enactment); (5) opportu-
nities to incorporate meaning and mind into organiza-
tional theory; (6) counterpoint to the sharp split between
thinking and action that often gets invoked in explana-
tions of organizational life (e.g., planners versus doers);
(7) background for an attention-based view of the ﬁrm;
(8) a balance between prospect in the form of anticipa-
tion and retrospect in the form of resilience; (9) reinter-
pretation of breakdowns as occasions for learning rather
than as threats to efﬁciency; and (10) grounds to treat
plausibility, incrementalism, improvisation, and bounded
rationality as sufﬁcient to guide goal-directed behavior.
Analyses of sensemaking also suggest important capa-
bilities and skills that warrant attention and development.
For example, the concept of enacted environments sug-
gests that constraints are partly of one’s own making and
not simply objects to which one reacts; the concept of
sensemaking suggests that plausibility rather than accu-
racy is the ongoing standard that guides learning; the
concept of action suggests that it is more important to
keep going than to pause, because the ﬂow of experience
in which action is embedded does not pause; and, the
concept of retrospect suggests that so-called stimuli for
action such as diagnoses, plans for implementation, and
strategies are as much the products of action as they are
prods to action.

Taken together, these properties suggest that increased
skill at sensemaking should occur when people are
socialized to make do, be resilient, treat constraints as
self-imposed, strive for plausibility, keep showing up,

use retrospect to get a sense of direction, and articulate
descriptions that energize. These are micro-level actions.
They are small actions, but they are small actions with
large consequences.

Acknowledgments
The authors thank two anonymous reviewers, Senior Editor
Alan Meyer, and Gary Klein for constructive comments on
previous versions of this paper.

Endnotes
1The terms “open ductus” and “complications of the patent
ductus” referenced by the nurse in her description refer to a
condition formally known as patent ductus arteriosus. Patent
ductus arteriosus is a condition where the ductus arteriosus,
a blood vessel that allows blood to bypass the baby’s lungs
before birth, fails to close after birth. The word “patent” means
open. If the patent ductus is not closed, the infant is at risk of
developing heart failure or a heart infection.
2“(cid:1) (cid:1) (cid:1) a complex situation in which a number of parties han-
dling a problem are unable to obtain precisely the same
information about the problem so that many differing interpre-
tations of the problem exist” (Turner 1978, p. 50).

References
Albert, S., D. Whetten. 1985. Organizational identity. L. L. Cummings,
B. M. Staw, eds. Research in Organizational Behavior, Vol. 7.
JAI Press, Greenwich, CT, 263–295.

Aldrich, H. 1999. Organizations Evolving. Sage, Thousand Oaks, CA.

Baum, J. A. C., J. V. Singh. 1994. Evolutionary Dynamics of Orga-

nizations. Oxford University Press, Oxford, UK.

Benner, P. 1994. The role of articulation in understanding practices
and experience as sources of knowledge in clinical nursing.
J. Tully, ed. Philosophy In An Age of Pluralism: The Philoso-
phy of Charles Taylor In Question. Cambridge University Press,
New York, 136–155.

Berscheid, E., H. Ammazzalorso. 2003. Emotional experience in close
relationships. G. J. Fletcher, M. S. Clark, eds. Blackwell Hand-
book of Social Psychology: Interpersonal Process. Blackwell,
Malden, MA, 308–330.

Bettis, R. A., C. K. Prahalad. 1995. The dominant logic: Retrospective

and extension. Strategic Management J. 16 5–14.

Boisot, M., J. Child. 1999. Organizations as adaptive systems in
complex environments: The case of China. Organ. Sci. 10(3)
237–252.

Brown, A. 2000. Making sense of inquiry sensemaking. J. Manage-

ment Stud. 37 45–75.

Bukszar, E., Jr. 1999. Strategic bias: The impact of cognitive biases

on strategy. Canadian J. Admin. Sci. 16 105–117.

Campbell, D. T. 1965. Variation and selective retention in socio-
cultural evolution. H. R. Barringer, G. I. Blanksten, R. Mack, eds.
Social Change in Developing Areas. Schenkman, Cambridge,
MA, 19–49.

Campbell, D. T. 1997. From evolutionary epistemology via selection
theory to a sociology of scientiﬁc validity. Evolution Cognition
3(1) 5–38.

Chia, R. 2000. Discourse analysis as organizational analysis. Organi-

zation 7(3) 513–518.

420

Weick, Sutcliffe, and Obstfeld: Organizing and the Process of Sensemaking
Organization Science 16(4), pp. 409–421, © 2005 INFORMS

Czarniawska, B. 2003. Constructionism and organization studies.
R. I. Westwood, S. Clegg, eds. Debating Organization: Point-
Counterpoint in Organization Studies. Blackwell, Malden, MA,
128–139.

Duncan, R. B. 1972. Characteristics of organizational environments

and perceived uncertainty. Admin. Sci. Quart. 17 313–327.

Dutton, J. E. 1993. The making of organizational opportunities: An
interpretive pathway to organizational change. L. L. Cummings,
B. M. Staw, eds. Research in Organizational Behavior, Vol. 15.
JAI Press, Greenwich, CT, 195–226.

Elsbach, K. D. 2002. Intraorganizational institutions. J. A. C. Baum,
ed. The Blackwell Companion to Organizations. Blackwell,
Malden, MA, 37–57.

Gavetti, G., D. Levinthal. 2000. Looking forward and looking back-
ward: Cognitive and experiential search. Admin. Sci. Quart. 45
113–137.

Gililand, S. W., D. V. Day. 2000. Business management. F. T.
Durso, ed. Handbook of Applied Cognition. Wiley, New York,
315–342.

Gioia, D. A., K. Chittipeddi. 1991. Sensemaking and sensegiv-
ing in strategic change initiation. Strategic Management J. 12
433–448.

Gioia, D. A., A. Mehra. 1996. Book review: Sensemaking in Organi-

zations. Acad. Management Rev. 21(4) 1226–1230.

Gioia, D. A., J. B. Thomas. 1996. Identity, image, and issue interpreta-
tion: Sensemaking during strategic change in academia. Admin.
Sci. Quart. 41 370–403.

Gioia, D. A., M. Schultz, K. Corley. 2000. Organizational

iden-
tity, image, and adaptive instability. Acad. Management Rev. 25
63–81.

Gioia, D. A., J. B. Thomas, S. M. Clark, K. Chittipeddi. 1994.
Symbolism and strategic change in academia: The dynamics of
sensemaking and inﬂuence. Organ. Sci. 5 363–383.

Hedström, P., R. Swedberg. 1998. Social mechanisms: An introduc-
tory essay. P. Hedström, R. Swedberg, eds. Social Mechanisms:
An Analytical Approach to Social Theory, Ch. 1. Cambridge
University Press, Cambridge, UK, 1–31.

Hughes, J., D. Randall, D. Shapiro. 1992. Faltering from ethnography
to design. Comput. Supported Cooperative Work (CSCW) Proc.,
Toronto, Ontario, Canada, 1–8.

Hutchins, E. 1995. Cognition in the Wild. MIT Press, Cambridge,

MA.

Jennings, P. D., R. Greenwood. 2003. Constructing the iron cage:
Institutional
theory and enactment. R. Westwood, S. Clegg,
eds. Debating Organization: Point-Counterpoint in Organization
Studies. Blackwell, Malden, MA, 195–207.

Kennedy, I. 2001. Learning from Bristol: The Report of the Public
Inquiry into Children’s Heart Surgery at Bristol Royal Inﬁrmary
1984–1995. Her Majesty’s Stationer, London, UK.

Klein, G., J. K. Phillips, E. L. Rall, D. A. Peluso. In press. A
data/frame theory of sensemaking. Unpublished manuscript.
R. R. Hoffman, ed. Expertise Out of Context: Proc. 6th Internat.
Conf. Naturalistic Decision Making. Erlbaum, Mahwah, NJ.

Kruglanski, A. W. 1989. The psychology of being “right”: The prob-
lem of accuracy in social perception and cognition. Psych. Bull.
106 395–409.

Lanir, Z. 1989. The reasonable choice of disaster—The shooting down
of the Libyan airliner on 21 February 1973. J. Strategic Stud.
12 479–493.

Lant, T. K. 2002. Organizational cognition and interpretation.
J. A. C. Baum, ed. The Blackwell Companion to Organizations.
Blackwell, Oxford, UK, 344–362.

Laroche, H. 1995. From decision to action in organizations: Decision-

making as a social representation. Organ. Sci. 6(1) 62–75.

Laughlin, P. R., A. B. Hollingshead. 1995. A theory of collec-
tive induction. Organ. Behavior Human Decision Processes 61
94–107.

Louis, M. R. 1980. Surprise and sensemaking: What newcomers expe-
rience in entering unfamiliar organizational settings. Admin. Sci.
Quart. 25 226–251.

Lounsbury, M., M. A. Glynn. 2001. Cultural entrepreneurship:
Stories, legitimacy, and the acquisition of resources. Strategic
Management J. 22(6) 545–564.

Magala, S. J. 1997. The making and unmaking of sense. Organ. Stud.

18(2) 317–338.

Mandler, G. 1984. Mind and Body. Free Press, New York.
Mandler, G. 1997. Human Nature Explored. Oxford, New York.
Mezias, J. M., W. H. Starbuck. 2003. Managers and their inaccurate
perceptions: Good, bad or inconsequential? British J. Manage-
ment 14(1) 3–19.

Mills,

J. H. 2003. Making Sense of Organizational Change.

Routledge, London, UK.

Obstfeld, D. 2004. Saying more and less of what we know: The
social processes of knowledge creation, innovation, and agency.
Unpublished manuscript, University of California-Irvine, Irvine,
CA.

Ocasio, W. 2001. How do organizations think? T. K. Lant, Z. Shapira,
eds. Organizational Cognition: Computation and Interpretation.
Erlbaum, Mahwah, NJ, 39–60.

Orlikowski, W. J., D. C. Gash. 1994. Technological frames: Making
sense of information technology in organizations. ACM Trans.
Inform. Systems 2 174–207.

Orton, J. D. 2000. Enactment, sensemaking, and decision making:
Redesign processes in the 1976 reorganization of US intelli-
gence. J. Management Stud. 37 213–234.

Paget, M. A. 1988. The Unity of Mistakes. Temple University Press,

Philadelphia, PA.

Patriotta, G. 2003. Sensemaking on the shop ﬂoor: Narratives
of knowledge in organizations. J. Management Stud. 40(2)
349–376.

Pfeffer, J. 1981. Power in Organizations. Pitman, Marshﬁeld, MA.
Pfeffer, J., G. R. Salancik. 1978. The External Control of Organi-
zations: A Resource Dependence Perspective. Harper and Row,
New York.

Porac, J. F., M. J. Ventresca, Y. Mishina. 2002. Interorganizational
cognition and interpretation. J. A. C. Baum, ed. The Black-
well Companion to Organizations. Blackwell, Malden, MA,
579–598.

Schachter, S., J. E. Singer. 1962. Cognitive, social, and physiological

determinants of emotional state. Psych. Rev. 69 379–399.

Scott, R. W. 1995. Institutions and Organizations. Sage, Thousand

Oaks, CA.

Snook, S. 2001. Friendly Fire. Princeton University, Princeton, NJ.
Starbuck, W. H., J. Mezias. 1996. Opening Pandora’s box: Studying
the accuracy of managers’ perceptions. J. Organ. Behavior 17
99–117.

Storpor, M., R. Salais. 1997. Worlds of Production: The Action

Frameworks of the Economy. Harvard, Cambridge, MA.

Sutcliffe, K. M. 1994. What executives notice: Accurate perceptions
in top management teams. Acad. Management J. 37 1360–1378.

Weick, Sutcliffe, and Obstfeld: Organizing and the Process of Sensemaking
Organization Science 16(4), pp. 409–421, © 2005 INFORMS

421

Sutcliffe, K. M. 2000. Organizational environments and organiza-
tional information processing. F. M. Jablin, L. L. Putnam, eds.
The New Handbook of Organizational Communication. Sage,
Thousand Oaks, CA, 197–230.

Taylor, J. R., E. J. Van Every. 2000. The Emergent Organization:
Communication as Its Site and Surface. Erlbaum, Mahwah, NJ.
Tsoukas, H., R. Chia. 2002. Organizational becoming: Rethinking

organizational change. Organ. Sci. 13(5) 567–582.

Turner, B. 1978. Man Made Disasters. Wykeham Press, London, UK.
Warglien, M. 2002. Intraorganizational evolution. J. A. C. Baum, ed.
The Blackwell Companion to Organizations. Blackwell, Malden,
MA, 98–118.

Weber, K. 2003. Does globalization lead to convergence? The evo-
lution of organizations’ cultural repertoires in the biomedical
industry. Unpublished dissertation, University of Michigan, Ann
Arbor, MI.

Weick, K. 1969. The Social Psychology of Organizing. Addison-

Wesley, Reading, MA.

Weick, K. E. 1979. The Social Psychology of Organizing, 2nd ed.

Addison-Wesley, Reading, MA.

Weick, K. E. 1993. The collapse of sensemaking in organizations:

The Mann Gulch disaster. Admin. Sci. Quart. 38 628–652.

Weick, K. E. 1995. Sensemaking in Organizations. Sage, Thousand

Oaks, CA.

Weick, K. E., K. H. Roberts. 1993. Collective mind in organiza-
tions: Heedful interrelating on ﬂight decks. Admin. Sci. Quart.
38 357–381.

Weick, K. E., K. M. Sutcliffe. 2001. Managing the Unexpected.

Jossey-Bass, San Francisco, CA.

Weick, K. E., K. M. Sutcliffe. 2003. Hospitals as cultures of entrap-
ment: A re-analysis of the Bristol Royal Inﬁrmary. California
Management Rev. 45(2) 73–84.

Westley, F. R. 1990. Middle managers and strategy: Microdynamics

of inclusion. Strategic Management J. 11 337–351.

Westrum, R. 1982. Social intelligence about hidden events. Knowl-

edge 3 381–400.

Winter, S. 1987. Knowledge and competence as strategic assets.
D. Teece, ed. The Competitive Challenge—Strategies for Indus-
Innovation and Renewal. Bollinger, Cambridge, MA,
trial
159–184.

Winter, S. 2003. Mistaken perceptions: Cases and consequences.

British J. Management 14 39–45.

Woods, D. D., R. I. Cook. 2000. Perspectives on human error: Hind-
sight biases and local rationality. F. T. Durso, ed. Handbook of
Applied Cognition. Wiley, New York, 141–172.

Zucker, L. G. 1983. Organizations as institutions. S. B. Bacharach, ed.
Research in the Sociology of Organizations, Vol. 2. JAI Press,
Greenwich, CT, 1–48.

","{""pos"":{""0"":1,""1"":2,""2"":3,""3"":4},""1"":{""0"":""j"",""1"":""cid"",""2"":""e"",""3"":""g""},""3"":{""0"":""nurse*"",""1"":""baby"",""2"":""kid"",""3"":""admin""},""6"":{""0"":""found*"",""1"":""noticing*"",""2"":""knew*"",""3"":""worried""},""7"":{""0"":""a*"",""1"":""increase*"",""2"":""exactly*"",""3"":""direct*""},""5"":{""0"":""sensemaking"",""1"":""social"",""2"":""strategic"",""3"":""emotion""},""2"":{""0"":""blackwell"",""1"":""sci"",""2"":""eds"",""3"":""uk*""},""4"":{""0"":""action"",""1"":""identity"",""2"":""organizations"",""3"":""decision""},""0"":{""0"":""1"",""1"":""2003"",""2"":""1995"",""3"":""2""}}",2011,{},False,False,bookSection,False,PPNESMHH,[],self.user,"{""Unnamed: 0"":{""0"":0,""1"":1,""2"":2,""3"":3,""4"":4,""5"":5,""6"":6,""7"":7,""8"":8,""9"":9,""10"":10,""11"":11,""12"":12,""13"":13,""14"":14,""15"":15,""16"":16,""17"":17,""18"":18,""19"":19,""20"":20,""21"":21,""22"":22,""23"":23,""24"":24,""25"":25,""26"":26,""27"":27,""28"":28,""29"":29,""30"":30,""31"":31,""32"":32,""33"":33,""34"":34,""35"":35,""36"":36,""37"":37,""38"":38,""39"":39,""40"":40,""41"":41,""42"":42,""43"":43,""44"":44,""45"":45,""46"":46,""47"":47,""48"":48,""49"":49,""50"":50,""51"":51,""52"":52,""53"":53,""54"":54,""55"":55,""56"":56,""57"":57,""58"":58,""59"":59,""60"":60,""61"":61,""62"":62,""63"":63,""64"":64,""65"":65,""66"":66,""67"":67,""68"":68,""69"":69,""70"":70,""71"":71,""72"":72,""73"":73,""74"":74,""75"":75,""76"":76,""77"":77,""78"":78,""79"":79,""80"":80,""81"":81,""82"":82,""83"":83,""84"":84,""85"":85,""86"":86,""87"":87,""88"":88,""89"":89,""90"":90,""91"":91,""92"":92,""93"":93,""94"":94,""95"":95,""96"":96,""97"":97,""98"":98,""99"":99,""100"":100,""101"":101,""102"":102,""103"":103,""104"":104,""105"":105,""106"":106,""107"":107,""108"":108,""109"":109,""110"":110,""111"":111,""112"":112,""113"":113,""114"":114,""115"":115,""116"":116,""117"":117,""118"":118,""119"":119,""120"":120,""121"":121,""122"":122,""123"":123,""124"":124,""125"":125,""126"":126,""127"":127,""128"":128,""129"":129,""130"":130,""131"":131,""132"":132,""133"":133},""C"":{""0"":3.9882295194,""1"":5.2756070928,""2"":9.294263611,""3"":47.2904167175,""4"":14.387429047,""5"":10.2242800854,""6"":7.3081936924,""7"":4.7283271776,""8"":16.6229002048,""9"":8.8072910362,""10"":8.6418398595,""11"":13.1110994514,""12"":4.6151308595,""13"":25.4892868581,""14"":3.4057206412,""15"":23.3185206529,""16"":25.107654845,""17"":15.1780425593,""18"":4.0892631682,""19"":11.4571837799,""20"":4.983589784,""21"":4.0162352824,""22"":14.3065722163,""23"":6.4911241057,""24"":3.8372759665,""25"":7.2432700012,""26"":4.883487143,""27"":6.8894048205,""28"":4.8603813097,""29"":4.4599517531,""30"":4.4336655976,""31"":5.1049697369,""32"":11.2817709262,""33"":12.7556887785,""34"":12.4899949802,""35"":7.3541940034,""36"":4.1078617706,""37"":6.3736416885,""38"":5.8355017449,""39"":3.5783423828,""40"":5.9347733223,""41"":9.5372152692,""42"":3.4898421892,""43"":7.9968386542,""44"":4.6071683923,""45"":8.6619367142,""46"":9.9955172607,""47"":9.4332635426,""48"":3.4409773255,""49"":4.5344574096,""50"":3.9988325847,""51"":3.4624460508,""52"":7.2004610147,""53"":7.2959872808,""54"":7.0734505685,""55"":7.5354480345,""56"":4.3893597139,""57"":11.8326375768,""58"":4.086346546,""59"":4.2866450677,""60"":5.3735108953,""61"":7.2528384655,""62"":6.7562753548,""63"":7.7648668506,""64"":7.4553744694,""65"":9.1774479254,""66"":3.2643882115,""67"":3.6127373418,""68"":3.7087934165,""69"":5.5913339982,""70"":5.692695969,""71"":3.5325522911,""72"":3.5339801985,""73"":3.4496327009,""74"":4.5353477504,""75"":5.3746272041,""76"":6.1888224298,""77"":6.5433200208,""78"":5.1561689202,""79"":6.9230411629,""80"":3.4921997591,""81"":3.6417380965,""82"":6.3360140934,""83"":6.3293766165,""84"":8.2433362677,""85"":5.8031282058,""86"":4.8140828346,""87"":4.7674344833,""88"":4.8016228788,""89"":4.3672027663,""90"":4.1606693189,""91"":6.4035357875,""92"":6.6115717347,""93"":6.6115717347,""94"":4.2127453556,""95"":6.5765842936,""96"":6.5589872048,""97"":4.3755561523,""98"":6.1542536043,""99"":6.5345317916,""100"":3.2733294972,""101"":3.2733294972,""102"":3.2733294972,""103"":4.4229986507,""104"":3.9337669054,""105"":3.2702685584,""106"":4.1264669868,""107"":4.0223383205,""108"":5.0888489775,""109"":4.703235631,""110"":4.118461138,""111"":4.4936903129,""112"":4.5046772508,""113"":4.0225325427,""114"":3.3589506107,""115"":4.1375723503,""116"":4.6482038446,""117"":4.7032303887,""118"":4.630834582,""119"":4.2985542084,""120"":3.5248357241,""121"":4.6741993459,""122"":3.8079348566,""123"":4.6887030668,""124"":4.3861074442,""125"":4.5963987839,""126"":4.6742203309,""127"":4.69452385,""128"":4.6279662333,""129"":3.5131509618,""130"":4.7265148569,""131"":3.2737904646,""132"":3.4188434722,""133"":3.4188434722},""count"":{""0"":288,""1"":108,""2"":98,""3"":80,""4"":70,""5"":64,""6"":62,""7"":56,""8"":56,""9"":52,""10"":52,""11"":50,""12"":50,""13"":44,""14"":42,""15"":42,""16"":42,""17"":40,""18"":32,""19"":28,""20"":26,""21"":26,""22"":26,""23"":24,""24"":24,""25"":24,""26"":24,""27"":24,""28"":24,""29"":22,""30"":22,""31"":22,""32"":22,""33"":22,""34"":22,""35"":20,""36"":20,""37"":20,""38"":18,""39"":18,""40"":18,""41"":18,""42"":18,""43"":18,""44"":18,""45"":18,""46"":18,""47"":18,""48"":16,""49"":16,""50"":16,""51"":16,""52"":16,""53"":16,""54"":16,""55"":16,""56"":14,""57"":14,""58"":14,""59"":14,""60"":14,""61"":14,""62"":14,""63"":14,""64"":14,""65"":14,""66"":12,""67"":12,""68"":12,""69"":12,""70"":12,""71"":12,""72"":12,""73"":12,""74"":12,""75"":12,""76"":12,""77"":12,""78"":10,""79"":10,""80"":10,""81"":10,""82"":10,""83"":10,""84"":10,""85"":10,""86"":8,""87"":8,""88"":8,""89"":8,""90"":8,""91"":8,""92"":8,""93"":8,""94"":8,""95"":8,""96"":8,""97"":8,""98"":8,""99"":8,""100"":8,""101"":8,""102"":8,""103"":8,""104"":8,""105"":8,""106"":8,""107"":8,""108"":8,""109"":6,""110"":6,""111"":6,""112"":6,""113"":6,""114"":6,""115"":6,""116"":6,""117"":6,""118"":6,""119"":6,""120"":6,""121"":6,""122"":6,""123"":6,""124"":6,""125"":6,""126"":6,""127"":6,""128"":6,""129"":6,""130"":6,""131"":6,""132"":6,""133"":6},""sigma_nor"":{""0"":1.2250111728,""1"":1.4702726235,""2"":1.8764069497,""3"":5.9542384809,""4"":2.5845273798,""5"":2.1639124416,""6"":1.836505891,""7"":1.5554469385,""8"":3.0189284178,""9"":2.0903627303,""10"":2.0693478261,""11"":2.6639710104,""12"":1.5666620529,""13"":4.4408341985,""14"":1.4383733762,""15"":4.2054452891,""16"":4.4540624082,""17"":3.1154078365,""18"":1.5888220383,""19"":2.8199827367,""20"":1.7818091627,""21"":1.6192699962,""22"":3.3482977574,""23"":2.0636636936,""24"":1.6042620932,""25"":2.1938659546,""26"":1.7853693246,""27"":2.13260916,""28"":1.7813695264,""29"":1.7316991006,""30"":1.7270022178,""31"":1.8469526946,""32"":2.9506405835,""33"":3.2140042945,""34"":3.1665293931,""35"":2.2878646874,""36"":1.6878373401,""37"":2.1066268589,""38"":2.0394804699,""39"":1.6068750186,""40"":2.0585067851,""41"":2.7489480762,""42"":1.5899131386,""43"":2.4537206626,""44"":1.8040590312,""45"":2.5811928523,""46"":2.8367858883,""47"":2.7290247672,""48"":1.5975215152,""49"":1.8154425716,""50"":1.7086972094,""51"":1.6018000452,""52"":2.3467538686,""53"":2.3657914214,""54"":2.321441793,""55"":2.4135138639,""56"":1.8124971079,""57"":3.359868471,""58"":1.7495041756,""59"":1.7911439212,""60"":2.0170907538,""61"":2.4077812154,""62"":2.304551489,""63"":2.5142259935,""64"":2.4498861076,""65"":2.807885258,""66"":1.5951043027,""67"":1.6709219385,""68"":1.6918283909,""69"":2.1015603634,""70"":2.1236216356,""71"":1.6534697894,""72"":1.6537805712,""73"":1.635422472,""74"":1.871726631,""75"":2.0543944733,""76"":2.2316027731,""77"":2.3087586117,""78"":2.0433943453,""79"":2.4476638065,""80"":1.6626696388,""81"":1.6968847798,""82"":2.3133489922,""83"":2.3118303033,""84"":2.7497541204,""85"":2.191421959,""86"":1.9963776933,""87"":1.9851078204,""88"":1.9933674665,""89"":1.8884150012,""90"":1.8385181528,""91"":2.3803769629,""92"":2.4306368034,""93"":2.4306368034,""94"":1.8510993117,""95"":2.4221841141,""96"":2.4179327966,""97"":1.8904331132,""98"":2.3201523579,""99"":2.4120245621,""100"":1.6241438659,""101"":1.6241438659,""102"":1.6241438659,""103"":1.9018948458,""104"":1.7837003233,""105"":1.6234043673,""106"":1.8302551397,""107"":1.805098477,""108"":2.0627590216,""109"":1.9900065017,""110"":1.8402714203,""111"":1.9363511429,""112"":1.9391644155,""113"":1.8157083175,""114"":1.6457941099,""115"":1.845164963,""116"":1.9759152766,""117"":1.9900051594,""118"":1.9714677708,""119"":1.8863853512,""120"":1.6882700066,""121"":1.9825715836,""122"":1.7607592689,""123"":1.9862853499,""124"":1.9088038921,""125"":1.9626502744,""126"":1.9825769569,""127"":1.987775797,""128"":1.9707333126,""129"":1.6852780518,""130"":1.9959672897,""131"":1.6239883342,""132"":1.6611300429,""133"":1.6611300429},""vocab_index"":{""0"":0,""1"":2,""2"":4,""3"":6,""4"":10,""5"":11,""6"":13,""7"":16,""8"":17,""9"":18,""10"":19,""11"":20,""12"":21,""13"":27,""14"":29,""15"":30,""16"":31,""17"":32,""18"":39,""19"":50,""20"":59,""21"":62,""22"":66,""23"":67,""24"":71,""25"":72,""26"":73,""27"":76,""28"":77,""29"":78,""30"":82,""31"":83,""32"":84,""33"":85,""34"":86,""35"":87,""36"":89,""37"":96,""38"":97,""39"":107,""40"":108,""41"":109,""42"":113,""43"":114,""44"":115,""45"":116,""46"":117,""47"":118,""48"":119,""49"":121,""50"":124,""51"":129,""52"":130,""53"":131,""54"":134,""55"":135,""56"":142,""57"":150,""58"":151,""59"":154,""60"":155,""61"":156,""62"":157,""63"":158,""64"":159,""65"":160,""66"":168,""67"":190,""68"":191,""69"":192,""70"":194,""71"":198,""72"":199,""73"":208,""74"":212,""75"":213,""76"":214,""77"":215,""78"":247,""79"":253,""80"":260,""81"":264,""82"":267,""83"":268,""84"":269,""85"":270,""86"":323,""87"":325,""88"":326,""89"":328,""90"":333,""91"":341,""92"":343,""93"":344,""94"":349,""95"":350,""96"":357,""97"":366,""98"":372,""99"":400,""100"":402,""101"":403,""102"":404,""103"":405,""104"":406,""105"":407,""106"":408,""107"":409,""108"":410,""109"":412,""110"":417,""111"":425,""112"":441,""113"":476,""114"":477,""115"":491,""116"":495,""117"":504,""118"":505,""119"":508,""120"":509,""121"":520,""122"":527,""123"":546,""124"":567,""125"":576,""126"":577,""127"":582,""128"":583,""129"":586,""130"":587,""131"":595,""132"":597,""133"":598},""word"":{""0"":""sensemaking"",""1"":""action"",""2"":""1"",""3"":""j"",""4"":""cid"",""5"":""e"",""6"":""2003"",""7"":""social"",""8"":""nurse"",""9"":""identity"",""10"":""g"",""11"":""m"",""12"":""organizations"",""13"":""r"",""14"":""change"",""15"":""d"",""16"":""k"",""17"":""a"",""18"":""1995"",""19"":""management"",""20"":""gioia"",""21"":""decision"",""22"":""ma"",""23"":""circumstances"",""24"":""talk"",""25"":""world"",""26"":""story"",""27"":""press"",""28"":""accuracy"",""29"":""university"",""30"":""enactment"",""31"":""strategic"",""32"":""ed"",""33"":""blackwell"",""34"":""sci"",""35"":""central"",""36"":""emotion"",""37"":""cognition"",""38"":""concept"",""39"":""baby"",""40"":""ductus"",""41"":""kid"",""42"":""data"",""43"":""found"",""44"":""perceptions"",""45"":""b"",""46"":""eds"",""47"":""h"",""48"":""words"",""49"":""features"",""50"":""situations"",""51"":""chia"",""52"":""noticing"",""53"":""bracketing"",""54"":""emotional"",""55"":""l"",""56"":""f"",""57"":""knew"",""58"":""questions"",""59"":""uk"",""60"":""2"",""61"":""c"",""62"":""cambridge"",""63"":""organ"",""64"":""admin"",""65"":""w"",""66"":""second"",""67"":""11"",""68"":""patent"",""69"":""worried"",""70"":""physician"",""71"":""paget"",""72"":""1988"",""73"":""study"",""74"":""3"",""75"":""york"",""76"":""malden"",""77"":""quart"",""78"":""patient"",""79"":""medical"",""80"":""causal"",""81"":""increase"",""82"":""berscheid"",""83"":""ammazzalorso"",""84"":""partner"",""85"":""stud"",""86"":""looked"",""87"":""symptoms"",""88"":""hours"",""89"":""x"",""90"":""nurses"",""91"":""labeling"",""92"":""functional"",""93"":""deployment"",""94"":""said"",""95"":""types"",""96"":""abstract"",""97"":""past"",""98"":""attending"",""99"":""corporate"",""100"":""sage"",""101"":""thousand"",""102"":""oaks"",""103"":""oxford"",""104"":""37"",""105"":""45"",""106"":""companion"",""107"":""rev"",""108"":""nj"",""109"":""edu"",""110"":""materialize"",""111"":""station"",""112"":""framing"",""113"":""517"",""114"":""names"",""115"":""instances"",""116"":""00"",""117"":""label"",""118"":""concrete"",""119"":""hunch"",""120"":""physicians"",""121"":""exactly"",""122"":""ecological"",""123"":""perceptual"",""124"":""institutionalization"",""125"":""vocabularies"",""126"":""direct"",""127"":""arousal"",""128"":""expectancy"",""129"":""7"",""130"":""arteriosus"",""131"":""london"",""132"":""erlbaum"",""133"":""mahwah""},""vector"":{""0"":""[-0.03080062 -1.5791849   0.83070135  1.8095512  -1.0622234  -3.8859706\n -0.7896978   0.02254622 -3.011368    5.0597987 ]"",""1"":""[ 0.16631119 -2.8148904   1.563512    1.8801396  -1.0938393  -3.3256605\n -1.1396658  -0.18903716 -2.81999     4.6326222 ]"",""2"":""[ 0.12247807 -2.404195    0.57134986 -0.09669296 -1.098793   -3.3699188\n -0.91462463 -0.39122948 -1.5354542   2.0652456 ]"",""3"":""[ 0.9348195   0.37817368  0.5546226   1.4271103  -1.9834876  -3.6003742\n -2.2640438   0.2995652  -1.3031428   2.1036363 ]"",""4"":""[ 1.2271731   0.26863158  0.70270425  1.2793874  -2.1854913  -3.18994\n -2.14138     0.5555455  -1.3157265   2.3379545 ]"",""5"":""[ 0.87151855  0.23967214  0.5045592   1.3465067  -1.8516421  -3.34641\n -1.9802332   0.6991421  -1.4923284   2.2994144 ]"",""6"":""[ 0.20982072 -2.7130327   0.62376106  0.30673388 -1.3591995  -3.642323\n -1.177724   -0.4101239  -1.5374234   2.690418  ]"",""7"":""[ 0.00845913 -1.7160995   0.9289295   1.5184816  -1.3080497  -4.0103207\n -1.1200906  -0.7006284  -3.0637598   4.577639  ]"",""8"":""[ 0.4457558  -1.116207    1.89492     1.8335258  -1.8624319  -3.5614355\n -1.5646956  -0.27407688 -2.4506416   4.41147   ]"",""9"":""[-0.0125777 -2.5716937  1.9171062  1.5909649 -1.0989617 -3.7316346\n -1.2380587 -0.7167046 -2.3194203  4.562198 ]"",""10"":""[ 1.0234784   0.50440323  0.51654077  1.3798382  -1.9055946  -3.3382018\n -2.211634    0.6385991  -1.2548642   1.941965  ]"",""11"":""[ 1.0268006   0.41034135  0.49358195  1.3491553  -2.102301   -3.2449994\n -2.2413623   0.73534644 -1.3058292   2.2143943 ]"",""12"":""[ 0.30185175 -2.4621837   1.8320903   1.5178714  -1.6702842  -3.7085958\n -1.5049145  -0.42064548 -2.0605507   4.3698134 ]"",""13"":""[ 0.8354279   0.2147873   0.6162593   1.4096117  -1.8015004  -3.4536693\n -2.1649685   0.45488665 -1.4454417   1.9042776 ]"",""14"":""[-0.06863596 -2.4634721   1.0447408   1.0276959  -0.6249899  -3.2479007\n -0.89534694 -0.83080643 -2.819668    3.6431923 ]"",""15"":""[ 0.9228706   0.22659835  0.4764247   1.2692401  -1.9262743  -3.2618215\n -2.0503907   0.7205414  -1.3627105   2.1274395 ]"",""16"":""[ 0.8999286   0.36122847  0.4734677   1.5668409  -1.9454345  -3.528658\n -2.214814    0.538546   -1.2038612   2.100727  ]"",""17"":""[-0.01176945 -2.5104642   0.8778228   0.7124841  -0.750002   -3.585066\n -0.8926498  -0.7050816  -2.5959032   3.5212777 ]"",""18"":""[ 0.22402656 -2.6987402   0.64079493  0.3090376  -1.3591478  -3.6484718\n -1.1774672  -0.3955393  -1.5374041   2.6766207 ]"",""19"":""[ 0.18898186 -1.8690505   1.4234855   1.5642326  -1.5358196  -3.6205978\n -1.3827623  -0.80499244 -2.8272746   4.196982  ]"",""20"":""[ 0.8473455  -0.06536148  0.75462526  1.4653037  -1.8119425  -3.3713112\n -1.7435232   0.48299026 -1.8808122   3.0353322 ]"",""21"":""[ 0.17677818 -2.7574449   1.6312855   1.8130662  -1.0207863  -3.2684996\n -1.1559857  -0.37913865 -2.8483334   4.4758506 ]"",""22"":""[ 1.0523782   0.2873619   0.69493663  1.446572   -2.083164   -3.2766194\n -2.1474864   0.61869353 -1.4846603   2.5073323 ]"",""23"":""[ 0.21049173 -2.8869126   1.6554834   1.6372355  -1.2620981  -3.5442526\n -1.2188603  -0.06783755 -2.2781794   4.6005507 ]"",""24"":""[ 0.21188109 -2.533318    1.3649043   0.86528176 -1.3809853  -3.7387695\n -1.3436787  -0.56129724 -1.7867925   3.2624612 ]"",""25"":""[ 0.34519187 -1.8814073   1.4090891   1.5202216  -1.597668   -4.0054536\n -1.686112   -0.881694   -2.510358    4.0285206 ]"",""26"":""[ 0.3292489 -2.4382317  1.7892205  1.7548625 -1.2948804 -3.6004927\n -1.5476543 -0.6251924 -2.5434504  4.205972 ]"",""27"":""[ 0.28740066 -2.092835    1.6107298   1.5913068  -1.4176451  -3.8165758\n -1.630561   -0.90224993 -2.5285637   4.057422  ]"",""28"":""[-0.07751936 -2.1852586   1.7500614   1.5698663  -1.2142395  -3.718865\n -1.0609066  -0.5395376  -2.4690492   4.6882443 ]"",""29"":""[ 0.39374283 -1.3294306   1.5883776   1.5769734  -1.7402902  -3.8202388\n -1.6941915  -0.82300746 -2.4414928   3.979836  ]"",""30"":""[ 0.152932   -2.5790045   1.382025    1.9712982  -1.0158502  -3.348374\n -1.0887704  -0.13209008 -2.9460552   4.701582  ]"",""31"":""[ 0.04487495 -1.8069121   0.9642058   1.3775505  -1.3159794  -3.8169503\n -1.1593362  -0.8199969  -3.0852127   4.203511  ]"",""32"":""[ 0.87798357 -0.02968509  1.0311104   1.278986   -1.9933863  -3.5328474\n -2.0676792   0.11031159 -1.6041024   2.7333205 ]"",""33"":""[ 0.87292606 -0.00575014  1.1490636   1.371209   -2.155529   -3.8769996\n -2.150618   -0.43920052 -1.7305641   3.0693142 ]"",""34"":""[ 0.8958291  -0.26179513  1.3834556   1.378137   -2.0831702  -3.6315682\n -2.0954347  -0.23887078 -1.6861202   3.139328  ]"",""35"":""[ 3.5243765e-03 -2.1476877e+00  8.0995518e-01  9.4818598e-01\n -1.0088470e+00 -3.7660251e+00 -1.0038221e+00 -7.7656364e-01\n -2.8236823e+00  3.7676096e+00]"",""36"":""[-0.09496597 -1.8873765   1.2222972   1.6887478  -1.2415326  -3.9380736\n -0.88136953 -0.36819968 -3.042492    5.0949826 ]"",""37"":""[ 3.1834707e-02 -1.6699766e+00  9.3847638e-01  1.8272740e+00\n -1.1272807e+00 -3.7987452e+00 -8.5184753e-01  1.0066882e-03\n -3.0192130e+00  5.0205398e+00]"",""38"":""[ 0.29301807 -2.5180154   1.6711802   1.7378637  -1.2259567  -3.417424\n -1.3307722  -0.3734509  -2.6552038   4.298515  ]"",""39"":""[ 0.5303712  -0.8613827   1.7850369   1.885333   -1.8315014  -3.695638\n -1.6879536  -0.17897311 -2.272713    4.225697  ]"",""40"":""[ 0.5041684 -0.6523626  0.8888675  1.5565195 -1.4967773 -3.493578\n -1.4814937  0.2328625 -2.370926   3.5460434]"",""41"":""[ 0.55779135 -1.06498     1.7897921   1.7518013  -1.7964177  -3.7811368\n -1.8843884  -0.51490927 -2.1895244   3.9553535 ]"",""42"":""[ 0.0897656  -2.2519124   1.9100637   1.6131485  -1.4052695  -3.4913108\n -1.2309235  -0.51924586 -2.327965    4.464578  ]"",""43"":""[-0.16754937 -3.0404925   0.86582184  0.7837611   0.07212218 -3.284874\n -0.7020172  -0.9569359  -2.9260547   3.5462809 ]"",""44"":""[ 0.0410408  -2.3458564   1.532842    1.6376271  -1.1268499  -3.7789538\n -0.9881433  -0.13318373 -2.4599638   4.9573975 ]"",""45"":""[ 0.8526827   0.24684983  0.48250383  1.2164607  -1.7414722  -3.2624705\n -1.9385178   0.7448403  -1.2769896   1.9887526 ]"",""46"":""[ 0.83043885 -0.16106866  1.1613504   1.3003275  -2.0184276  -3.6363966\n -2.0632093  -0.02753136 -1.6865736   2.9437919 ]"",""47"":""[ 1.0105717   0.4597393   0.57243115  1.3955345  -1.9863087  -3.4064627\n -2.242654    0.5188281  -1.2364352   2.0859208 ]"",""48"":""[ 0.16202042 -2.7160378   1.8523227   1.2744927  -1.114162   -3.6321993\n -1.1897677  -0.20868434 -1.8896878   4.2804914 ]"",""49"":""[ 0.32556054 -2.6716585   1.9592372   1.6221161  -1.3310866  -3.503613\n -1.4170244  -0.3013192  -2.1706936   4.341876  ]"",""50"":""[ 0.38629517 -2.774479    1.8275701   1.5856049  -1.5297632  -3.6021457\n -1.4020084  -0.03727451 -2.0077796   4.535704  ]"",""51"":""[ 8.6536211e-01 -3.5356855e-01  1.2751303e+00  1.4784505e+00\n -2.0005386e+00 -3.4752295e+00 -1.9159487e+00  4.9555581e-04\n -1.7137653e+00  3.2293730e+00]"",""52"":""[-0.2065946  -3.0149262   0.9295445   0.96476084 -0.0318984  -3.3848188\n -0.79763466 -1.021939   -2.917129    3.6223722 ]"",""53"":""[-0.03950214 -2.4892244   1.1078008   1.2168283  -0.6705261  -3.72593\n -1.0520957  -0.8029622  -2.7476013   4.0216045 ]"",""54"":""[-0.06785659 -1.7167594   0.9616597   1.5766351  -1.1815163  -3.9374552\n -0.8832921  -0.42173168 -3.1324232   4.8383803 ]"",""55"":""[ 1.0401702   0.25902724  0.6226247   1.3937923  -2.0279474  -3.2837944\n -2.152705    0.5738027  -1.3348389   2.2130134 ]"",""56"":""[ 1.0483292   0.39454284  0.6154843   1.4950231  -1.9594234  -3.2400053\n -2.1766348   0.71042234 -1.4027697   2.1043828 ]"",""57"":""[-0.18680137 -3.0654013   0.9315215   0.82655877 -0.06383912 -3.4420762\n -0.8647382  -0.8737286  -2.7782068   3.4450104 ]"",""58"":""[ 0.26514885 -2.6809673   1.8230683   1.5962905  -1.2527298  -3.5691106\n -1.1740252  -0.03692539 -2.1201413   4.6979537 ]"",""59"":""[ 0.94530165 -0.14004375  1.3746126   1.3732202  -2.2060192  -3.9733386\n -2.266813   -0.70625055 -1.624912    2.9715557 ]"",""60"":""[-0.06157728 -2.4137764   0.69865066 -0.17244655 -1.1969087  -3.4982817\n -0.77595425 -0.5286332  -1.6112709   2.2054987 ]"",""61"":""[ 1.0006081   0.17641076  0.58582044  1.1831063  -1.9051021  -3.2925248\n -2.069739    0.617755   -1.3270466   2.0072825 ]"",""62"":""[ 0.81109905 -0.1622002   1.3289291   1.3081189  -2.180759   -3.9598756\n -2.2193837  -0.61938393 -1.7783815   3.081508  ]"",""63"":""[-0.00966302 -1.525153    1.0917689   1.6483675  -1.4211167  -4.0562787\n -1.1011939  -0.5934177  -3.0919244   4.826432  ]"",""64"":""[ 0.59214884 -0.9478525   1.6699716   1.6232859  -1.8787552  -3.6870584\n -1.7805297  -0.34423137 -2.047321    3.8995616 ]"",""65"":""[ 0.85321283  0.09964836  0.56181437  1.1643556  -1.6921686  -3.3179376\n -1.9049673   0.5735523  -1.268012    1.9597255 ]"",""66"":""[ 0.01535152 -2.453942    0.76502824  0.4842186  -0.8722986  -3.5513685\n -0.88943815 -0.61931187 -2.310139    3.1284385 ]"",""67"":""[ 0.12431505 -2.730353    0.5255064  -0.09694716 -1.1529073  -3.5406983\n -0.9214549  -0.4259428  -1.5074406   2.2603254 ]"",""68"":""[ 0.35539377 -1.1506444   1.075762    1.5694945  -1.4298918  -3.587319\n -1.3744142  -0.1172763  -2.6036687   3.8944726 ]"",""69"":""[-0.04599952 -3.130464    0.9815088   0.82061213  0.10959093 -3.5226235\n -0.8062444  -0.7918383  -2.6912866   3.5454915 ]"",""70"":""[ 0.37266675 -1.1864923   1.7508986   1.7297058  -1.8852386  -3.533285\n -1.4274476  -0.22129543 -2.5516717   4.4574943 ]"",""71"":""[ 0.35663396 -1.1896162   1.4673573   1.9119544  -1.5725274  -3.6361997\n -1.2038807   0.1660373  -2.5285475   4.754954  ]"",""72"":""[ 0.28595448 -2.8418286   0.7420826   0.18614683 -1.255799   -3.748461\n -1.131468   -0.31158847 -1.4185258   2.6237388 ]"",""73"":""[ 0.09845232 -2.0002606   1.5535358   1.4855635  -1.1073177  -3.2551613\n -1.0994307  -0.6509562  -2.7129197   4.0584283 ]"",""74"":""[ 0.03002479 -2.439367    0.63689005 -0.10169423 -1.1144346  -3.4662297\n -0.8467854  -0.48220286 -1.6138488   2.2016153 ]"",""75"":""[ 0.87978387 -0.06806926  1.2626243   1.3234874  -2.1786232  -4.0086966\n -2.2660747  -0.6830868  -1.6756964   2.936654  ]"",""76"":""[ 0.31543234 -0.8650932   0.58966243  1.8514454  -1.3384895  -3.726452\n -0.910139    0.40572044 -2.6890354   4.6711273 ]"",""77"":""[ 1.0326511  -0.10769878  0.79714024  1.3363694  -1.8664302  -3.1201084\n -1.822192    0.573086   -1.4459512   2.4445155 ]"",""78"":""[ 0.34055692 -1.265499    1.669439    1.8420932  -1.6701083  -3.661216\n -1.3248647  -0.03397447 -2.4686277   4.685615  ]"",""79"":""[ 0.2711441 -1.1959763  1.4934776  1.6353894 -1.7766525 -3.8158312\n -1.4091843 -0.4758765 -2.659902   4.4580703]"",""80"":""[-0.05554725 -1.6605372   0.67358065  1.4913628  -1.0589417  -4.013944\n -0.9036126  -0.37605032 -3.0416453   4.648488  ]"",""81"":""[-0.07461657 -2.3008277   0.8642318   0.91947544 -0.6779502  -3.3377\n -0.8831678  -0.8317155  -2.852931    3.5340085 ]"",""82"":""[ 0.16535853 -1.0375714   0.6048267   1.8022631  -1.2561175  -3.804447\n -0.8287262   0.26850262 -2.8808804   4.8069034 ]"",""83"":""[ 0.7976215  -0.12403121  0.7433932   1.5229777  -1.7442274  -3.3600893\n -1.6786032   0.54291457 -1.8682286   3.0826154 ]"",""84"":""[ 0.38347688 -1.8158449   1.9747188   1.7457806  -1.4738237  -3.3015366\n -1.451105   -0.5035789  -2.57133     4.141002  ]"",""85"":""[ 0.48663667 -1.3613067   1.8487461   1.70563    -1.7848729  -3.6746564\n -1.7721646  -0.57904106 -2.2437952   4.0357223 ]"",""86"":""[-0.03917455 -2.9724064   0.8215931   0.62665236 -0.01996818 -3.334828\n -0.7018151  -0.7950924  -2.7705362   3.4365797 ]"",""87"":""[ 2.5206012e-01 -1.7417146e+00  1.6935676e+00  1.7844952e+00\n -1.5037663e+00 -3.6529546e+00 -1.2037762e+00 -1.5330222e-03\n -2.3996425e+00  4.8004928e+00]"",""88"":""[ 0.2712209  -2.576282    1.7435488   1.1886777  -1.3710909  -3.5997596\n -1.2673916  -0.07894211 -1.6641304   4.0408196 ]"",""89"":""[ 1.0787812   0.50699025  0.68723667  1.3429794  -1.7776129  -3.1525176\n -2.0350947   0.68718183 -1.2717793   2.0102158 ]"",""90"":""[ 0.3915049  -1.1947684   1.9039272   1.8705468  -1.8669147  -3.6556108\n -1.4949819  -0.21634783 -2.4482284   4.5852604 ]"",""91"":""[ 2.8782338e-03 -2.5498030e+00  1.5194997e+00  1.3748432e+00\n -8.4101045e-01 -3.6801336e+00 -1.2199440e+00 -8.9267182e-01\n -2.5318928e+00  4.1237350e+00]"",""92"":""[-0.04113606 -1.6365925   0.85001993  1.4003298  -1.3152982  -3.995839\n -1.064822   -0.7224106  -3.2054567   4.4434934 ]"",""93"":""[ 0.2447345  -2.5622938   1.6369494   1.8992363  -1.177017   -3.296789\n -1.2654428  -0.36175013 -2.8492174   4.448388  ]"",""94"":""[-0.1464715  -3.0384893   0.8896347   0.7632312   0.04238845 -3.337044\n -0.7462417  -0.90483373 -2.8557165   3.5152154 ]"",""95"":""[ 0.27112257 -2.6413379   1.9841645   1.5720215  -1.492008   -3.5049324\n -1.4483572  -0.4106244  -2.076254    4.3188534 ]"",""96"":""[ 0.0202763  -1.8103735   0.8753117   1.4596382  -1.0541464  -3.7812006\n -0.9099501  -0.32059065 -2.985357    4.4737616 ]"",""97"":""[ 0.0123357  -2.5575485   0.97033864  0.74392325 -0.79393053 -3.5196912\n -0.90419286 -0.6266616  -2.442708    3.5359304 ]"",""98"":""[-0.07069492 -2.8629448   1.0181339   0.86932176  0.03543206 -3.3050408\n -0.7096516  -0.93670994 -2.8631425   3.7230256 ]"",""99"":""[ 0.17121184 -1.755129    1.1489424   1.4508905  -1.4694809  -3.9051404\n -1.3912448  -0.85756326 -2.8602934   4.1440454 ]"",""100"":""[ 0.5440073  -1.1569663   1.6798161   1.5968133  -1.7846005  -3.5105786\n -1.6202704  -0.15607785 -1.9941988   3.926236  ]"",""101"":""[ 0.18342024 -2.7757468   1.6178988   1.0026834  -1.1949944  -3.5789897\n -1.1615735  -0.20263626 -1.7199734   3.882705  ]"",""102"":""[ 0.3962861  -1.5229075   1.7787074   1.5691475  -1.7067722  -3.624\n -1.5130874  -0.22522275 -1.9807663   4.1980004 ]"",""103"":""[ 0.8553977  -0.20057237  1.349569    1.3978614  -2.1173391  -3.9578636\n -2.163472   -0.6720989  -1.759525    3.1283922 ]"",""104"":""[ 0.11650744 -2.810412    0.53511536 -0.09211057 -1.2941239  -3.5646346\n -0.98036546 -0.38532704 -1.3848883   2.3259094 ]"",""105"":""[ 0.09307831 -2.8271816   0.6426091  -0.11700055 -1.3412478  -3.6671858\n -0.95951116 -0.46476886 -1.334151    2.2800107 ]"",""106"":""[ 0.4420574  -1.7698547   1.9804814   1.761329   -1.4761158  -3.311792\n -1.5031517  -0.36588266 -2.3931277   4.0801744 ]"",""107"":""[ 0.8695325   0.03362829  0.85613936  1.2255082  -1.8822365  -3.3998694\n -2.0143158   0.3160528  -1.5173104   2.4629762 ]"",""108"":""[ 0.93285537  0.0381838   1.0930369   1.3353511  -2.0961173  -3.941061\n -2.2541957  -0.52297217 -1.5786914   2.8056812 ]"",""109"":""[ 0.84209955 -0.30607978  1.4587871   1.3657234  -2.1344008  -3.88799\n -2.1912813  -0.67117846 -1.7574606   3.1870759 ]"",""110"":""[-0.1097857  -2.5516965   0.9276996   0.9188097  -0.42669377 -3.2468996\n -0.8327623  -0.8762102  -2.8637466   3.528279  ]"",""111"":""[ 0.32316917 -2.003812    1.8575616   1.7390352  -1.5137813  -3.5734558\n -1.5388452  -0.6017335  -2.4101193   4.2134414 ]"",""112"":""[ 0.03274973 -2.5467727   1.2678839   1.3949443  -0.7712086  -3.702143\n -1.1439695  -0.77143306 -2.7411075   4.156775  ]"",""113"":""[ 0.12629469 -2.6633968   0.58964086 -0.02070136 -1.2050083  -3.5813012\n -0.97825056 -0.42658252 -1.4883122   2.2995305 ]"",""114"":""[ 0.0990415  -2.7111309   1.9305581   1.4069753  -1.2123761  -3.6394486\n -1.2892922  -0.51995325 -2.01502     4.3221965 ]"",""115"":""[ 0.25098842 -2.8194048   1.802305    1.3744949  -1.3645282  -3.5610754\n -1.2758476  -0.16584553 -1.9169562   4.3231015 ]"",""116"":""[ 0.11671699 -2.8041081   0.64439553 -0.07691754 -1.340085   -3.6798556\n -1.0229709  -0.5149449  -1.3367423   2.1928866 ]"",""117"":""[ 0.08975329 -2.4561641   1.7301899   1.4821266  -1.0756911  -3.6685145\n -1.3622807  -0.8520526  -2.3959405   4.162367  ]"",""118"":""[-0.0065279  -1.9616209   0.7784503   1.2996494  -0.97034353 -3.7803946\n -0.9223801  -0.52274996 -3.020878    4.2441244 ]"",""119"":""[ 0.09242192 -2.8270013   1.6076871   1.6308742  -0.74643004 -3.2308943\n -1.0207669  -0.50402015 -2.8091965   4.37158   ]"",""120"":""[ 0.30337265 -1.3858365   1.8030589   1.7468737  -1.8400267  -3.6885033\n -1.3852195  -0.2196792  -2.446827    4.6602697 ]"",""121"":""[-0.0794407  -2.7564025   0.9215218   0.73783624 -0.4443123  -3.4797888\n -0.8666186  -0.7472568  -2.6326008   3.50263   ]"",""122"":""[ 5.6904904e-04 -1.6018207e+00  8.2704616e-01  1.5413121e+00\n -1.3273548e+00 -4.0579004e+00 -1.1158830e+00 -6.3124913e-01\n -3.1490641e+00  4.5823379e+00]"",""123"":""[-0.04756944 -1.7949913   0.92078775  1.6460843  -1.0936195  -3.9544997\n -0.89394635 -0.21537897 -2.951297    4.918023  ]"",""124"":""[ 0.10002183 -1.8793254   1.0085993   1.950543   -1.0827006  -3.6217263\n -0.9287365   0.05213181 -3.0402167   4.9427323 ]"",""125"":""[ 0.1072341  -2.6185832   1.8548278   1.4001514  -1.2097884  -3.7131956\n -1.1774641  -0.26340553 -2.0471342   4.526821  ]"",""126"":""[-0.05458727 -2.3011997   0.7588906   0.83429086 -0.7581915  -3.5658123\n -0.8845829  -0.7632009  -2.8049963   3.5876946 ]"",""127"":""[-0.05244537 -1.634861    1.0968511   1.7510083  -1.2077404  -3.9198518\n -0.79744947 -0.13253875 -2.9915404   5.1505094 ]"",""128"":""[ 0.07319594 -2.0356545   1.4501028   1.7219663  -1.2281011  -3.8144245\n -0.9981755  -0.04683995 -2.5522337   5.0294895 ]"",""129"":""[ 0.13892956 -2.5307195   0.5818711  -0.0184036  -1.2320911  -3.5432763\n -1.0316517  -0.40825233 -1.4352765   2.19569   ]"",""130"":""[ 0.6185546  -0.47027037  0.8418292   1.5533241  -1.5659972  -3.4212036\n -1.5256717   0.35734197 -2.210309    3.395896  ]"",""131"":""[ 0.73872155 -0.04407905  1.2317487   1.2578602  -2.2180347  -4.1138964\n -2.2328274  -0.65205425 -1.8281659   2.928933  ]"",""132"":""[ 0.2896153  -0.9110986   0.60795224  1.8467174  -1.3237321  -3.736155\n -0.90238655  0.38602975 -2.7236602   4.700888  ]"",""133"":""[ 0.22787073 -1.0306472   0.65972376  1.7890197  -1.2593349  -3.780175\n -0.8957687   0.26742175 -2.7953193   4.737734  ]""},""topic"":{""0"":5,""1"":4,""2"":0,""3"":1,""4"":1,""5"":1,""6"":0,""7"":5,""8"":3,""9"":4,""10"":1,""11"":1,""12"":4,""13"":1,""14"":-1,""15"":1,""16"":1,""17"":7,""18"":0,""19"":-1,""20"":-1,""21"":4,""22"":1,""23"":4,""24"":-1,""25"":4,""26"":4,""27"":4,""28"":-1,""29"":-1,""30"":-1,""31"":5,""32"":1,""33"":2,""34"":2,""35"":-1,""36"":5,""37"":5,""38"":4,""39"":3,""40"":-1,""41"":3,""42"":4,""43"":6,""44"":-1,""45"":1,""46"":2,""47"":1,""48"":4,""49"":4,""50"":4,""51"":-1,""52"":6,""53"":-1,""54"":5,""55"":1,""56"":1,""57"":6,""58"":4,""59"":2,""60"":0,""61"":1,""62"":2,""63"":5,""64"":3,""65"":1,""66"":-1,""67"":0,""68"":-1,""69"":6,""70"":3,""71"":3,""72"":0,""73"":-1,""74"":0,""75"":2,""76"":-1,""77"":1,""78"":3,""79"":3,""80"":5,""81"":7,""82"":-1,""83"":-1,""84"":-1,""85"":3,""86"":6,""87"":3,""88"":-1,""89"":1,""90"":3,""91"":-1,""92"":5,""93"":4,""94"":6,""95"":4,""96"":5,""97"":-1,""98"":6,""99"":5,""100"":3,""101"":-1,""102"":-1,""103"":2,""104"":0,""105"":0,""106"":-1,""107"":1,""108"":2,""109"":2,""110"":-1,""111"":4,""112"":-1,""113"":0,""114"":4,""115"":4,""116"":0,""117"":4,""118"":5,""119"":-1,""120"":3,""121"":7,""122"":5,""123"":5,""124"":5,""125"":4,""126"":7,""127"":5,""128"":-1,""129"":0,""130"":-1,""131"":2,""132"":-1,""133"":-1},""exemplar"":{""0"":null,""1"":null,""2"":null,""3"":null,""4"":null,""5"":null,""6"":null,""7"":null,""8"":""*"",""9"":null,""10"":null,""11"":null,""12"":null,""13"":null,""14"":null,""15"":""*"",""16"":null,""17"":""*"",""18"":null,""19"":null,""20"":null,""21"":null,""22"":null,""23"":null,""24"":null,""25"":null,""26"":null,""27"":null,""28"":null,""29"":null,""30"":null,""31"":null,""32"":null,""33"":null,""34"":null,""35"":null,""36"":null,""37"":""*"",""38"":null,""39"":null,""40"":null,""41"":null,""42"":null,""43"":""*"",""44"":null,""45"":null,""46"":null,""47"":""*"",""48"":null,""49"":""*"",""50"":null,""51"":null,""52"":""*"",""53"":null,""54"":""*"",""55"":""*"",""56"":""*"",""57"":""*"",""58"":null,""59"":""*"",""60"":null,""61"":null,""62"":""*"",""63"":null,""64"":null,""65"":null,""66"":null,""67"":""*"",""68"":null,""69"":null,""70"":""*"",""71"":null,""72"":null,""73"":null,""74"":null,""75"":""*"",""76"":null,""77"":null,""78"":""*"",""79"":null,""80"":null,""81"":""*"",""82"":null,""83"":null,""84"":null,""85"":null,""86"":null,""87"":null,""88"":null,""89"":null,""90"":""*"",""91"":null,""92"":null,""93"":null,""94"":""*"",""95"":null,""96"":null,""97"":null,""98"":null,""99"":null,""100"":null,""101"":null,""102"":null,""103"":""*"",""104"":""*"",""105"":""*"",""106"":null,""107"":null,""108"":null,""109"":null,""110"":null,""111"":null,""112"":null,""113"":""*"",""114"":""*"",""115"":""*"",""116"":null,""117"":null,""118"":null,""119"":null,""120"":""*"",""121"":""*"",""122"":null,""123"":""*"",""124"":null,""125"":""*"",""126"":""*"",""127"":""*"",""128"":null,""129"":null,""130"":null,""131"":null,""132"":null,""133"":null},""word*"":{""0"":""sensemaking"",""1"":""action"",""2"":""1"",""3"":""j"",""4"":""cid"",""5"":""e"",""6"":""2003"",""7"":""social"",""8"":""nurse*"",""9"":""identity"",""10"":""g"",""11"":""m"",""12"":""organizations"",""13"":""r"",""14"":""change"",""15"":""d*"",""16"":""k"",""17"":""a*"",""18"":""1995"",""19"":""management"",""20"":""gioia"",""21"":""decision"",""22"":""ma"",""23"":""circumstances"",""24"":""talk"",""25"":""world"",""26"":""story"",""27"":""press"",""28"":""accuracy"",""29"":""university"",""30"":""enactment"",""31"":""strategic"",""32"":""ed"",""33"":""blackwell"",""34"":""sci"",""35"":""central"",""36"":""emotion"",""37"":""cognition*"",""38"":""concept"",""39"":""baby"",""40"":""ductus"",""41"":""kid"",""42"":""data"",""43"":""found*"",""44"":""perceptions"",""45"":""b"",""46"":""eds"",""47"":""h*"",""48"":""words"",""49"":""features*"",""50"":""situations"",""51"":""chia"",""52"":""noticing*"",""53"":""bracketing"",""54"":""emotional*"",""55"":""l*"",""56"":""f*"",""57"":""knew*"",""58"":""questions"",""59"":""uk*"",""60"":""2"",""61"":""c"",""62"":""cambridge*"",""63"":""organ"",""64"":""admin"",""65"":""w"",""66"":""second"",""67"":""11*"",""68"":""patent"",""69"":""worried"",""70"":""physician*"",""71"":""paget"",""72"":""1988"",""73"":""study"",""74"":""3"",""75"":""york*"",""76"":""malden"",""77"":""quart"",""78"":""patient*"",""79"":""medical"",""80"":""causal"",""81"":""increase*"",""82"":""berscheid"",""83"":""ammazzalorso"",""84"":""partner"",""85"":""stud"",""86"":""looked"",""87"":""symptoms"",""88"":""hours"",""89"":""x"",""90"":""nurses*"",""91"":""labeling"",""92"":""functional"",""93"":""deployment"",""94"":""said*"",""95"":""types"",""96"":""abstract"",""97"":""past"",""98"":""attending"",""99"":""corporate"",""100"":""sage"",""101"":""thousand"",""102"":""oaks"",""103"":""oxford*"",""104"":""37*"",""105"":""45*"",""106"":""companion"",""107"":""rev"",""108"":""nj"",""109"":""edu"",""110"":""materialize"",""111"":""station"",""112"":""framing"",""113"":""517*"",""114"":""names*"",""115"":""instances*"",""116"":""00"",""117"":""label"",""118"":""concrete"",""119"":""hunch"",""120"":""physicians*"",""121"":""exactly*"",""122"":""ecological"",""123"":""perceptual*"",""124"":""institutionalization"",""125"":""vocabularies*"",""126"":""direct*"",""127"":""arousal*"",""128"":""expectancy"",""129"":""7"",""130"":""arteriosus"",""131"":""london"",""132"":""erlbaum"",""133"":""mahwah""},""pos"":{""0"":1,""1"":1,""2"":1,""3"":1,""4"":2,""5"":3,""6"":2,""7"":2,""8"":1,""9"":2,""10"":4,""11"":5,""12"":3,""13"":6,""14"":1,""15"":7,""16"":8,""17"":1,""18"":3,""19"":2,""20"":3,""21"":4,""22"":9,""23"":5,""24"":4,""25"":6,""26"":7,""27"":8,""28"":5,""29"":6,""30"":7,""31"":3,""32"":10,""33"":1,""34"":2,""35"":8,""36"":4,""37"":5,""38"":9,""39"":2,""40"":9,""41"":3,""42"":10,""43"":1,""44"":10,""45"":11,""46"":3,""47"":12,""48"":11,""49"":12,""50"":13,""51"":11,""52"":2,""53"":12,""54"":6,""55"":13,""56"":14,""57"":3,""58"":14,""59"":4,""60"":4,""61"":15,""62"":5,""63"":7,""64"":4,""65"":16,""66"":13,""67"":5,""68"":14,""69"":4,""70"":5,""71"":6,""72"":6,""73"":15,""74"":7,""75"":6,""76"":16,""77"":17,""78"":7,""79"":8,""80"":8,""81"":2,""82"":17,""83"":18,""84"":19,""85"":9,""86"":5,""87"":10,""88"":20,""89"":18,""90"":11,""91"":21,""92"":9,""93"":15,""94"":6,""95"":16,""96"":10,""97"":22,""98"":7,""99"":11,""100"":12,""101"":23,""102"":24,""103"":7,""104"":8,""105"":9,""106"":25,""107"":19,""108"":8,""109"":9,""110"":26,""111"":17,""112"":27,""113"":10,""114"":18,""115"":19,""116"":11,""117"":20,""118"":12,""119"":28,""120"":13,""121"":3,""122"":13,""123"":14,""124"":15,""125"":21,""126"":4,""127"":16,""128"":29,""129"":12,""130"":30,""131"":10,""132"":31,""133"":32},""x2D"":{""0"":-1.2846865654,""1"":-3.2959110737,""2"":-7.2891163826,""3"":9.9404640198,""4"":9.5472764969,""5"":9.111333847,""6"":-7.3648657799,""7"":-0.7294543386,""8"":-0.9625302553,""9"":-3.9363193512,""10"":9.6610021591,""11"":9.4327688217,""12"":-4.3155055046,""13"":9.5915031433,""14"":-5.8897194862,""15"":9.0181159973,""16"":9.8173828125,""17"":-6.0108075142,""18"":-7.2563118935,""19"":-2.2914721966,""20"":8.5887537003,""21"":-3.2663862705,""22"":9.4080286026,""23"":-3.7173855305,""24"":-4.8082151413,""25"":-2.118534565,""26"":-3.1664113998,""27"":-2.4616529942,""28"":-3.7033457756,""29"":-1.6683330536,""30"":-3.17694664,""31"":-0.9612227082,""32"":8.5232477188,""33"":7.8687052727,""34"":8.0008935928,""35"":-5.6102828979,""36"":-1.2631818056,""37"":-1.4169176817,""38"":-3.4030442238,""39"":-0.9682730436,""40"":8.0739812851,""41"":-1.2855633497,""42"":-3.7842152119,""43"":-6.4001879692,""44"":-3.039910078,""45"":9.1831436157,""46"":8.1999797821,""47"":9.85679245,""48"":-4.4140982628,""49"":-4.0573215485,""50"":-4.1221365929,""51"":8.1718645096,""52"":-6.2966918945,""53"":-5.0910682678,""54"":-1.037224412,""55"":9.4759044647,""56"":9.6583557129,""57"":-6.1626467705,""58"":-3.8370537758,""59"":8.1736354828,""60"":-7.4993839264,""61"":9.2852106094,""62"":7.9426026344,""63"":-0.6107334495,""64"":-1.1374667883,""65"":9.2225036621,""66"":-5.8197836876,""67"":-7.429579258,""68"":-0.6122257113,""69"":-6.1629705429,""70"":-0.8477972746,""71"":-0.9294902086,""72"":-7.5673232079,""73"":-3.1539022923,""74"":-7.4740967751,""75"":8.1912717819,""76"":-1.1415525675,""77"":9.0355653763,""78"":-0.8619469404,""79"":-0.9009043574,""80"":-0.9539057016,""81"":-6.0490498543,""82"":-1.1491611004,""83"":8.5367431641,""84"":-2.3888058662,""85"":-1.3938498497,""86"":-6.1389055252,""87"":-1.0174782276,""88"":-4.5072331429,""89"":9.6317749023,""90"":-1.0380936861,""91"":-3.972032547,""92"":-0.7675943375,""93"":-3.19211483,""94"":-6.2021617889,""95"":-4.1980929375,""96"":-0.9955859184,""97"":-5.901049614,""98"":-6.2686290741,""99"":-1.5611739159,""100"":-1.2211257219,""101"":-4.5735301971,""102"":-1.3403975964,""103"":8.0358276367,""104"":-7.3511896133,""105"":-7.7024259567,""106"":-2.1904900074,""107"":8.9622917175,""108"":8.0858983994,""109"":7.8968725204,""110"":-6.1023178101,""111"":-2.676440239,""112"":-4.1157698631,""113"":-7.5448651314,""114"":-4.2159967422,""115"":-4.2934231758,""116"":-7.4946575165,""117"":-3.7949931622,""118"":-1.1227591038,""119"":-3.4695436954,""120"":-0.9677407742,""121"":-6.041697979,""122"":-0.7602535486,""123"":-1.2713435888,""124"":-1.553407073,""125"":-4.0871658325,""126"":-6.1474561691,""127"":-1.3728665113,""128"":-1.9428591728,""129"":-7.6409020424,""130"":8.2078933716,""131"":8.060503006,""132"":-1.225975275,""133"":-1.2570117712},""y2D"":{""0"":3.2074270248,""1"":1.7317639589,""2"":-7.5611724854,""3"":-1.199411273,""4"":-1.9168101549,""5"":-1.780585289,""6"":-6.8829193115,""7"":2.4352221489,""8"":-0.2381145209,""9"":1.6039350033,""10"":-1.3445101976,""11"":-1.2734189034,""12"":2.2175424099,""13"":-1.4407775402,""14"":-0.2783282995,""15"":-1.6483639479,""16"":-1.3904139996,""17"":-0.1251976341,""18"":-7.025285244,""19"":1.0318818092,""20"":-2.7671098709,""21"":1.5732573271,""22"":-1.8941448927,""23"":2.4196462631,""24"":2.3048431873,""25"":0.8097658157,""26"":1.1433198452,""27"":0.9521442652,""28"":1.5179057121,""29"":-0.2412438244,""30"":1.7775989771,""31"":2.0020735264,""32"":-3.0944030285,""33"":-4.0733919144,""34"":-3.6761960983,""35"":0.0095020104,""36"":2.8677494526,""37"":3.0603649616,""38"":1.3309948444,""39"":-0.4435002506,""40"":-2.7183976173,""41"":-0.5729809999,""42"":1.5760143995,""43"":-1.0574164391,""44"":2.1584455967,""45"":-1.8414084911,""46"":-3.5667483807,""47"":-1.3732157946,""48"":2.4236843586,""49"":2.3875362873,""50"":2.6196870804,""51"":-3.3928833008,""52"":-1.1478091478,""53"":0.1642345637,""54"":2.8281252384,""55"":-1.8408347368,""56"":-1.5694588423,""57"":-1.0557661057,""58"":2.3495926857,""59"":-4.140873909,""60"":-7.493001461,""61"":-1.5100828409,""62"":-4.1117148399,""63"":2.7335789204,""64"":-0.5345428586,""65"":-1.5174725056,""66"":0.0366527773,""67"":-7.3042807579,""68"":-0.1964490861,""69"":-1.3417203426,""70"":0.0361793339,""71"":0.4831271768,""72"":-7.0277180672,""73"":0.8690796494,""74"":-7.3677682877,""75"":-4.3677549362,""76"":3.6886541843,""77"":-2.200322628,""78"":0.2317212671,""79"":0.0519836023,""80"":2.7007579803,""81"":-0.135744065,""82"":3.5838661194,""83"":-2.6518905163,""84"":0.5579543114,""85"":-0.4240777493,""86"":-1.2982527018,""87"":0.6264076233,""88"":2.5755190849,""89"":-1.4312907457,""90"":0.0234668478,""91"":0.8653906584,""92"":2.2639067173,""93"":1.6269193888,""94"":-1.1956324577,""95"":2.4588868618,""96"":2.6849584579,""97"":-0.2016953677,""98"":-1.2625102997,""99"":1.5109490156,""100"":-0.4616184533,""101"":2.4499559402,""102"":-0.1702546179,""103"":-4.2750558853,""104"":-7.3280081749,""105"":-7.2077593803,""106"":0.3831689656,""107"":-2.3920938969,""108"":-4.1715688705,""109"":-3.991089344,""110"":-0.4814023077,""111"":0.6977232099,""112"":0.7243652344,""113"":-7.1618351936,""114"":2.1045935154,""115"":2.569609642,""116"":-7.1834764481,""117"":1.0118451118,""118"":2.2460522652,""119"":1.3502546549,""120"":0.2375316173,""121"":-0.3894035518,""122"":2.5280835629,""123"":3.020709753,""124"":2.9806637764,""125"":2.4153094292,""126"":-0.0609548911,""127"":3.1418962479,""128"":2.6627457142,""129"":-7.4016098976,""130"":-2.8345825672,""131"":-4.1963739395,""132"":3.7484343052,""133"":3.5837538242}}",False,False,False,http://www.elgaronline.com/view/9781849807623.00024.xml,,Organization Science,PPNESMHH,False,False
9BL2E5F8,ERVZICSJ,"BiSet: Semantic Edge Bundling with Biclusters for Sensemaking

Maoyuan Sun, Peng Mi, Chris North and Naren Ramakrishnan

Fig. 1. An overview of BiSet. Entities are represented in lists.
In the space between each neighboring pair of lists, BiSet adds a
“in-between” layer, displaying edges. BiSet bundles edges based on biclusters and allows users to directly manipulate bundles. The
bundles can reveal task-oriented semantic insights about coordinated relationships. BiSet also applies accumulated highlighting to
entities, bundles and edges to indicate highly shared entities and relationships.

Abstract— Identifying coordinated relationships is an important task in data analytics. For example, an intelligence analyst might
want to discover three suspicious people who all visited the same four cities. Existing techniques that display individual relationships,
such as between lists of entities, require repetitious manual selection and signiﬁcant mental aggregation in cluttered visualizations
to ﬁnd coordinated relationships.
In this paper, we present BiSet, a visual analytics technique to support interactive exploration of
coordinated relationships. In BiSet, we model coordinated relationships as biclusters and algorithmically mine them from a dataset.
Then, we visualize the biclusters in context as bundled edges between sets of related entities. Thus, bundles enable analysts to infer
task-oriented semantic insights about potentially coordinated activities. We make bundles as ﬁrst class objects and add a new layer,
“in-between”, to contain these bundle objects. Based on this, bundles serve to organize entities represented in lists and visually reveal
their membership. Users can interact with edge bundles to organize related entities, and vice versa, for sensemaking purposes. With
a usage scenario, we demonstrate how BiSet supports the exploration of coordinated relationships in text analytics.
Index Terms—Bicluster, coordinated relationship, semantic edge bundling

1 INTRODUCTION
Analysts often face difﬁcult challenges in exploring complex relations
and identifying meaningful ones for sensemaking [39]. Current vi-
sual analysis tools emphasize individual relationships and just display
simple ones. This makes it hard for analysts to see more complex re-
lationships (e.g., coordinated relationship). Coordinated relationships
are grouped relations between sets of entities of different types (e.g.,
three people who all visited the same four cities). Due to the complex-
ity, compared with simple relationship, coordinated relationship needs
more cognitive effort for exploration.

Existing techniques that display individual relationships, such as
between lists of entities, require repetitious manual selection and sig-
niﬁcant mental aggregation in cluttered visualizations to ﬁnd coordi-
nated relationships. For example, Jigsaw [19] provides a List View
to support exploring relationships between lists of entities (e.g., peo-
ple, location, date, organization, etc.). In the List View, Jigsaw applies
visual links between related entities to show their connections and con-
trols the shading of colors for entities to indicate their co-occurrence.
With these visual encodings, in Jigsaw, users can recognize relations

• Maoyuan Sun, Peng Mi, Chris North and Naren Ramakrishnan are all
with the Discovery Analytics Center, Department of Computer Science,
Virginia Tech. E-mail: {smaoyuan | mipeng | north | naren}@cs.vt.edu.

Manuscript received 31 Mar. 2015; accepted 1 Aug. 2015; date of
publication xx Aug. 2015; date of current version 25 Oct. 2015.
For information on obtaining reprints of this article, please send
e-mail to: tvcg@computer.org.

between entities without much effort, but these relations are limited
to simple individual ones (e.g., a person visited three cities). Users
have to repetitiously click entities, visually check and mentally com-
pare their linked entities to identify coordinated relationships. Since
Jigsaw’s List View does not provide clear visual clues on coordinated
relations, users have to manually test all possible entities before they
ﬁnally ﬁnd a meaningful one. This potentially forces users to solve a
combinatorial problem of selection without much support. Thus, due
to deﬁcient clues to direct user selections, tools like Jigsaw have lim-
ited capabilities to support exploring coordinated relationships.

Visual analytics can potentially better support this by computation-
ally ﬁnding complex relationships and revealing them in context. This
enables analysts to see complex relations with other data (e.g., enti-
ties in lists). Speciﬁcally, we can compute coordinated relationships
with biclustering algorithms and display them in context using edge
bundling. In this case, edge bundles can reveal semantic insights from
coordinated relationships, which is meaningful from a task-oriented
perspective. The reason is that edges are bundled using semantic edge
bundling that is based on results of biclustering algorithms, rather than
using spatial edge bundling which is based on spatial proximity to sim-
plify visual representations.

Biclustering algorithms compute coordinated relationships as bi-
clusters. A bicluster can be considered a grouped relationship between
two sets of entities, where each entity in one set is connected with all
in another. Figure 2 shows an example of a bicluster that indicates
a coordinated relation between three people and four locations. It is
clear that a bicluster can bundle edges that link pairs of related entities,
and group entities that belong to the same coordinated set. Biclusters
provide a conceptual format to present coordinated relationships in an

organized manner. To take advantage of this for sensemaking, a ﬁve-
level design framework for bicluster visualizations has been proposed
in [49]. However, existing techniques are inefﬁcient to support explor-
ing coordinated relationships, and few attempt to adapt biclusters to
facilitate this by following the design framework. Thus, it is still chal-
lenging to design a technique that can take advantage of biclusters and
make them usable to support coordinated relationship explorations.

Fig. 2. An example of a bicluster, indicating a coordinated relationship
between three people and four locations. (A) presents all connections
between each pair of related entities from the two domains. (B) shows
the result of bundling edges in this bicluster. (C) demonstrates the result
of both bundling edges and grouping entities in this bicluster.

To address such challenges, we present BiSet, a visual analytics
technique to support interactively exploring coordinated relationships
with biclusters. Our key contributions in this paper are as follows:

1) We formalize coordinated relationships as biclusters and algo-

rithmically mine them from a dataset.

2) We visualize the biclusters in context as bundled edges between
sets of related entities. These bundles enable analysts to infer semantic
insights about potentially coordinated activities.

3) We make bundles as the ﬁrst class objects and add a new layer
“in-between” lists to contain these bundle objects. We allow users to
direct manipulate bundles for organizing entities represented in lists.
4) We apply interactions to both edge bundles and entities for re-
vealing and organizing relevant information in a bidirectional way.
Users can interact with edge bundles to forage and organize relevant
entities and, vice versa, for sensemaking purposes.

5) We present a usage scenario to demonstrate how BiSet can sup-

port the coordinated relationship exploration in text analytics.

2 RELATED WORK
Four key aspects are involved in BiSet: biclustering, list layout, visual
link and edge bundling, which outlines the discussion of related work.

2.1 Biclusters and Bicluster-Chains
Biclustering attempts to ﬁnd both subsets of entities and subsets of
dimensions with the restriction that for each identiﬁed subset of en-
tities, they identically behave within the corresponding subset of di-
mensions [36]. Biclusters are computational results from biclustering
algorithms that identify coordinated relations between two entity sets.
An entity set refers to a set of unique objects from a speciﬁc domain
(e.g., people) extracted from a dataset (e.g., documents).

Relationship between two entity sets. Given two entity sets E and
F, a (binary) relationship R (E, F) between E and F is a subset of
E × F (the Cartesian product of E and F). We say that E is connected
to F. There are different ways to model relationship R in different sce-
narios. In text analytics, R can be determined by word co-occurrence
in documents or semantic meanings identiﬁed with natural language
processing. For example, person X is related to city Y , since they are
mentioned in the same document or based on semantic meanings of
some sentences that indicate person X visited city Y .
Bicluster. We deﬁne a bicluster (E(cid:48), F(cid:48)) on R (E, F) as a set E(cid:48) ⊆ E
and a set F(cid:48) ⊆ F such that E(cid:48) × F(cid:48) ⊆ R. That is, there is a relationship
between each element of E(cid:48) with every element of F(cid:48). We use |E(cid:48)| +
|F(cid:48)| to denote the size of a bicluster (E(cid:48), F(cid:48)) where |E(cid:48)| and |F(cid:48)| are
the cardinality of E(cid:48) and F(cid:48). In addition, bicluster (E(cid:48), F(cid:48)) is thin if
there is only one entity in either E(cid:48) or F(cid:48).

Closed bicluster. A bicluster (E(cid:48),F(cid:48)) is closed if:

(i) For every entity e ∈ E − E(cid:48), there is some entity f ∈ F(cid:48) such that
(ii) For every entity f ∈ F −F(cid:48), there is some entity e ∈ E(cid:48) such that

(e, f ) /∈ R, and
(e, f ) /∈ R.

Algorithms for bicluster mining typically aim to ﬁnd closed biclus-
ters. These algorithms (e.g., CHARM [56] and LCM [51]) function
level-wise with regard to one domain (e.g., E), wherein they attempt to
mine closed biclusters involving one entity of E, then closed biclusters
involving two entities of E, and so on. The key parameter inﬂuencing
such mining is the size of a bicluster in terms of the other domain (e.g.,
F), also referred to as the minimum support threshold. The setting of
this parameter is done heuristically by users; a low threshold will yield
a plethora of biclusters whereas a stringent (high) threshold will yield
few (or no) biclusters. Typically, users begin with a high threshold and
gradually lower it until it yields a sufﬁcient number of biclusters [56].
In this paper, we use CHARM and LCM, although any biclustering
algorithm can be utilized in BiSet.

Biclusters logically aggregate multiple individual relations to form
coordinated sets, so they provide an opportunity to visually bundle
edges between entities. Bicluster-based edge bundles organize edges
in a semantic manner, potentially revealing semantic insights. For ex-
ample, four suspicious people may collude about a terrorist attack,
since they are all related to the same three terrorist organizations. This
is different from spatial edge bundling that bundle edges based on spa-
tial proximity to reduce visual clutter [58].

Fig. 3. An example of a bicluster-chain consisting of two biclusters.
(A) presents all edges between related entities. (B) shows that the two
biclusters connect together as a chain by their shared phone numbers.

Bicluster-chains. Based on shared entities, if there are any, multi-
ple biclusters (consisting of different pairs of domains) can connect to
form bicluster-chains. With compositional mining methods [29, 54],
bicluster-chains can be identiﬁed from a dataset. Figure 3 shows an
example of a bicluster-chain with two biclusters. One shows coordi-
nated relations between three people and four phone numbers, and the
other presents relations between three phone numbers and four loca-
tions. They share three phone numbers. One possible semantic insight
revealed from this chain is: three people may visit the same four cities,
since they called each other via four phone numbers, and phone calls
from three of these numbers were all reported at the four cities.

A ﬁve-level design framework for bicluster visualizations has
been proposed based on ﬁve hierarchical levels of relationships poten-
tially existing in a dataset [49]. Keywords corresponding to the ﬁve
levels are: entity, group, bicluster, chain and schema. Entity-level
relations refer to those between two individual entities, while group-
level relations are relations between one individual entity and a group
of entities. Bicluster-level and chain-level relations represent two lev-
els of coordinated relations: biclusters and bicluster-chains. The lat-
ter is more complex than the former, since a bicluster-chain consists
of multiple biclusters. Schema-level relations indicates database-like
patterns in a dataset, which reveals the overview of a dataset. Relations
in higher levels (e.g., bicluster-level and chain-level) are usually con-
structed based on those in lower levels (e.g., entity-level and group-
level), so relations in lower levels provide a critical support for the
exploration and interpretation of those in higher levels. These ﬁve lev-
els of relations systematically present the space of relationship, which
works as an important guideline for us to follow. Speciﬁcally, it guides
us to identify potential tasks that BiSet needs to support, by consider-
ing the implicit linkage of these ﬁve levels.

2.2 Visualizations for Exploring Coordinated Relations
List and matrix views are two layouts that can potentially support ex-
ploring coordinated relationships. Two corresponding visualization
techniques are parallel coordinates [28] and scatterplot matrix [6]. The
former uses spatial position to present attributes as individual axes at
once, while the latter embeds multiple scatterplots in a matrix layout
that shows all pairwise combinations of attributes [37]. They are use-
ful for discovering correlation, which potentially can be adapted for
exploring coordinated relationship. Brushing is a common interaction
technique in both of them to explore correlation [4, 45] and it helps
users manually ﬁnd correlations by selecting a group of records in an
axis or in a region. However, similar to the problem of Jigsaw’s List
View, users are not clearly directed to know where they should brush.
Moreover, brushing is designed for selecting a group of entities, rather
than an individual one, so it is hard to use this to support users to
delve into detailed information of a coordinated relation. Thus, nei-
ther parallel coordinates nor scatterplot matrix, without any adaption,
can effectively support visual exploration of coordinated relationship.
List (or list view) holds a similar concept to that of parallel coor-
dinates which manages entities in lists by domains. Instead of using
brushing to select a group of entities, in a list view, users usually select
individual entities. ConTour [38] and Jigsaw [19] are two examples
that applied a list layout to support meaningful relations discovery.
The problem with Jigsaw’s List View is that its visual representation
is explicit but interaction is implicit. Different from Jigsaw, ConTour
suffers from the problem of implicit visual representation. ConTour
highlights related entities when users hover an entity. This serves as
explicit visual clues to direct users’ attention to some potential targets.
However, ConTour does not show visual links between related entities.
Just with color changes, it is hard for users to visually discriminate
one coordinated relationship from another, especially when there are
many and some of them overlap each other. ConTour applies recursive
nesting to reduce such visual clutter, but it requires entity duplication,
which may confuse users. BiSet is inspired by the good parts of both
Jigsaw and ConTour, which provides both visual links and visual clues
to guide users for coordinated relationship exploration.

Matrix is a preferred layout for exploring coordinated relationship
(in bicluster-level) that has been well explored in bioinformatics do-
main (e.g., BicAt [3], Bicluster viewer [22], BicOverlapper 2.0 [43],
BiGGEsTS [18], BiVoc [21], Expression Proﬁler [31] and GAP [55]).
By reordering and duplicating rows and columns, biclusters can be vi-
sually revealed in a matrix [21, 22]. However, similar to the problem
of ConTour, row and column duplication in a matrix may cause more
confusion than entity duplication in a list. In addition, interacting with
entities in a matrix is not as easy as that in a list. Thus, compared with
list, matrices are not ﬂexible enough to support coordinated relation-
ship exploration (e.g., drilling down to details of relations), although
it can provide a visual representation for such relationship.

Node-link diagrams in the context of multivariate or heteroge-
neous networks can also be used to visualize coordinated relationships.
For example, PivotPaths [12] applies a modiﬁed node-link diagram to
support relationship exploration in heterogenous networks.
It sepa-
rates a 2D space into three regions to contain entities from different
domain (e.g., authors, articles and keywords). This explicitly sepa-
rates nodes in a node-link diagram into different groups based on do-
mains, which is similar to a list view. Entities in the middle region
are horizontally aligned. Edges are presented to show connections be-
tween entities in two neighboring domains. By following edges, users
can manually discover coordinated relationships in PivotPaths (e.g.,
ﬁnding three co-authors of four papers with the same two keywords).
OnionGraph [44] used a similar visual representation to show bibli-
ographic networks. Pretorius et al. also applied a similar layout to
show structures of multivariate graphs and edge labels [40]. In their
method, edge labels are listed in the middle region. Related entities are
highlighted when users select these labels. This is a good example of
enabling interactivity on edges for revealing relevant nodes. However,
their method lacks the ability to manage nodes via interactions on the
labels. Related nodes are highlighted but they do not move close to
the selected label. Thus, users still have to navigate in a graph (e.g.,

scrolling up and down) to ﬁnd highlighted nodes, if the graph is large.
Hybrid layout combines two or more layouts together. Usually it
uses a list or a node-link diagram as the basic layout and replaces enti-
ties with matrices (or other types of visualizations). Matchmaker [34]
and VisBrick [33] took a list view as the major layout, while Bixplorer
[14], Furby [47] and NodeTrix [23] applied a node-link diagram as
the key layout. The former group organizes relations in lists and the
latter group uses a 2D space to manage relations. Since entities are re-
placed with relations, it is difﬁcult to further explore detailed informa-
tion (e.g., entities and entity-level relations) to interpret a coordinated
relationship. This may be even harder here than using a matrix layout.
In BiSet, we choose list as the key layout. The detailed rationale for

our decision is discussed in Section 3.2.

2.3 Visual Links and Edge Bundling
Visual links (e.g., edges in graphs) are important for assisting visual
navigation [24] and indicate certain types of relations (e.g., causality
[57]). By following links, users can navigate their foci from one part
of a visualization to another, or across different visualizations [52] or
applications [53]. This helps to direct users to potentially related con-
tent for comparison and evaluation [9, 46] or assist users to explore
visually hidden (or being covered) content [16]. However, cases are
not always optimistic. If too many edges exist, a visual layout (e.g.,
graph) will become a hairball of visual clutter [37]. Edge bundling is a
useful technique to reduce visual clutter and reveal high level edge pat-
terns by visually aggregating edges based on certain rules (e.g., force-
directed model [26], image-based rule [50], geometry-based rule [11],
etc.). However, there are two major problems with these edge bundling
techniques: 1) spatial-based bundling in the visual level (losing rela-
tions in the data level), and 2) lack of interactions on edge bundles.

Traditional edge bundling techniques simply group edges based on
spatial proximity (e.g., the position of nodes or edges), which may ig-
nore some implicit relations in a dataset. Since visual adjacency is
determined by layout algorithms (e.g., force-directed layout), rather
than knowledge discovery algorithms (e.g., biclustering), bundling vi-
sually adjacent edges does not guarantee that a bundle of these indi-
vidual relations reﬂect meaningful semantic insights from the dataset.
To deal with such problems, a hierarchical edge bundling technique is
proposed in [25] that bundles adjacent edges by considering the hier-
archical relations in a dataset. However, compared with coordinated
relationships, hierarchical relationships are relatively simple because
they can not reveal high level semantic insights implied by the co-
ordination of individual relationships. Despite this, the hierarchical
edge bundling technique inspires our design of BiSet that bundle edges
based on coordinated relationship. This potentially enables users to in-
fer semantic insights from these edge bundles.

Deﬁcient interaction on edge bundles is another problem with exist-
ing edge bundling techniques. Such bundles have limited capabilities
to support users exploring the space of relationship, although they help
to reduce visual clutter. This partially results from the previous prob-
lem since edge bundles depend on the layout of nodes. If positions of
nodes change, the existing bundles may also change. This means that
these edge bundles are not stable. In BiSet, we map algorithmically
discovered coordinated relationships to edge bundles. This assures
that each bundle visually presents a certain coordinated relationship.
Thus, bundles in BiSet are more independent from the layout of nodes
than existing techniques. Based on this, BiSet allows interactions on
edge bundles which enables users to manipulate bundles to forage re-
lated information, and organize spatializations for synthesis [2].

3 DESIGN REQUIREMENT ANALYSIS
3.1 A Design Trade-off
Figure 2 shows that a bicluster can both bundle connections and group
entities and this can be clearly conveyed in a list view. However, cases
are not always that easy. When certain entities belong to more than
one bicluster, it becomes difﬁcult to visually group all entities of the
same bicluster together. Figure 4 shows an example of this case. There
are three biclusters indicating three different coordinated relations be-
tween people and locations. They share some entities (e.g., P1 and

to show connections between the newly added entities and those from
one domain of the existing matrix. This leads to two problems: entity
duplication and direction (row or column) selection. To build the new
matrix, entities from one domain of the existing matrix have to be du-
plicated to form either row names or column names in the new matrix.
If replicated entities work as the row names in the new matrix, newly
added ones will be the column names, and vice versa. Compared with
matrices, in a list whenever a group of entities are to be added or re-
moved, we can easily add or remove one list. Thus, compared with the
other two layouts, lists organize entities in a consistent manner.

P2 are associated with both bicluster A and bicluster B). This brings
about an Euler diagram problem [1, 42] when visually grouping enti-
ties. When the number of shared entities increases, it becomes more
difﬁcult to present a visual representation that show the membership
of these entities without replicating some of them. This suggests a
key design trade-off: entity-centric versus relationship-centric, which
means that we cannot easily achieve the goal of clearly presenting both
entities (without duplications) and relationships (without separations).
Techniques such as bubble sets [10] and untangling Euler diagrams
[41] attempt to balance this trade-off by using a 2D space. They show
relationships with their members in a calculated spatial layout with
certain boundaries. However, they do not scale up well. In a list, there
is just one dimension to use for organizing entities, so it is even harder
to balance this trade-off.

Entity-centric requires that entities that belong to a certain domain
(e.g., people in Figure 4) should be listed in a certain order without
duplication. The positions of entities can be reordered to fulﬁll some
purpose (e.g., listing names in an alphabetical order or ranking them
based on frequency in documents). Since entities cannot be duplicated,
relationships that consist of shared entities may be separated apart.
Thus, an entity-centric design can help to avoid the ambiguity caused
by entity replication, but it costs the completeness of relationships.

Fig. 5. A 2D space is sliced into two types of subspaces in a list view.

Organized alternate subspaces for entities and relationships. In
a list view, a 2D space is sliced into two types of subspaces, where en-
tities and relationships appear alternately. Figure 5 gives an example
of such slicing that generates three subspaces for entities and two sub-
spaces for relationships. This provides an opportunity to leverage the
design trade-off by using the relationship subspace. In node-link dia-
grams, the space of entities is intertwined with that of relations so there
is no clear boundary between the two spaces. Matrices potentially em-
phasize the space of relationships (e.g., the structure of a dataset) [17],
so it is difﬁcult to support simple relationship (e.g., entity-level or
group-level relations) exploration in a matrix. Visually, in a matrix,
the proportion of the space for relations (the total area of all cells in
a matrix) is larger than that for entities (one column and one row in
the matrix) and the ratio of the two increases when the size of a matrix
gets larger. Thus, compared with the other two layouts, lists slice a 2D
space for entities and relations in a clearly organized and usable way.

3.3 Requirements Description with Identiﬁed Tasks
Based on the design trade-off and the selected layout, we identify four
important requirements with key tasks that BiSet needs to support.

R1: Entity and relationship encodings. Efﬁcient visual encodings
for both entity and relationship are necessary which should attempt
to achieve four important goals. First, visual encodings should assist
users to discriminate entities from relations (a). Then visual encodings
(particularly for relationships) should potentially help to reduce visual
clutter (b). Third, visual encodings should provide clues to reveal the
membership of entities (c). Finally, visual encodings should reﬂect the
changes when the state of entities or relations updates (d).

R2: Four types of exploration. There are four possible types of
exploration in a list layout based on the space slicing: i) from entity to
entity, ii) from entity to relationship, iii) from relationship to relation-
ship, and iv) from relationship to entity. The ﬁrst type of exploration
refers to when users start from entities and focus on ﬁnding related
entities. The second one may happen in the scenario where users take
the strategy of following the clues from identiﬁed meaningful entities
[30] and search for more relevant information. The third type of ex-
ploration may be performed when users seek additional relationships
based on current one. This is a possible case for text analytics which
has been reported in [48]. The last one may be used to compare sev-
eral hypotheses, which has been identiﬁed as a common intelligence
analysis strategy [7]. For example, several biclusters share some indi-
vidual relations, but they still have their unique ones. This may form
(partially) conﬂicted relations that lead to different hypotheses. In this

Fig. 4. A detailed example to illustrate the Euler diagram problem that
arises when visually presenting the membership of entities in the do-
main of people shared by three biclusters. This problem indicates a key
design trade-off: entity-centric versus relationship-centric.

Relationship-centric requires that entities that belong to the same
relationships (e.g., biclusters) should be placed near each other, which
visually preserves the completeness of relationships. To achieve this,
entities may be duplicated, particularly when several relationships
share two or more entities. A relationship-centric design (e.g., bub-
ble sets technique [10]) can maintain the integrity of relationships with
the cost of entity duplication. This may confuse users, especially when
they see some entities appear at several different positions in a list.
3.2 Layout Candidate Selection
Three layouts can be potentially applied to show coordinated relation-
ships: node-link diagram, matrix, and list (including parallel coordi-
nates). A detailed discussion about applying them in bicluster visual-
izations are addressed in [49]. Because of the following two advan-
tages, we choose list as the major layout of BiSet.

Consistent, domain-based entity management. In a list layout,
entities are organized in a consistent manner by domains. In a node-
link diagram, nodes are placed either randomly or based on certain
layout algorithms (e.g., force-directed layout [15]), so it is hard to sep-
arate entities of one domain (e.g., people) from those of another (e.g.,
location). Compared with a node-link diagram, a matrix is a better
organized layout, where relations are more readable [17]. Entities in a
matrix are organized in two orthogonal directions based on domains.
However, when a new group of entities are to be added, it is impossi-
ble to add them in the existing matrix. A new matrix has to be built

case, users may have to compare these biclusters by drilling down to
detailed level of information (e.g., entities) for competing them.

There are two ways to perform the four types of exploration: from
one to many and from many to many. For instance, users may want to
ﬁnd related entities based on one or multiple biclusters. Based on this,
we identify eight user tasks involved in such explorations, which are
summarized in Table 1. For each type of exploration, users can start
from either an entity (or a bicluster) or multiple entities (or biclusters)
and then try to ﬁnd relevant entities or biclusters. A user’s analytical
process may consist of a series of these tasks that iteratively forage rel-
evant information and identify some meaningful pieces [30]. Detailed
examples of these tasks are addressed and labeled in Section 5.

R3: Organizing entities and relationships. Entities and relation-
ships should be visually represented in an organized way. This can
help users to easily ﬁnd useful information. In addition, users may
want to make changes to the automatically generated layouts so that
they can organize entities or relationships in personalized, meaningful
ways (e.g., using spatialization) for sensemaking [2].

R4: Retrieving original data for reference. To evaluate algorith-
mically discovered coordinated relationships, users may refer to the
content from the original dataset (e.g., documents) because they need
contextual information to help them to interpret and further evaluate
these relations [19]. BiSet should attempt to efﬁciently direct users to
useful information, rather than keep them from reading documents.

4 BISET TECHNIQUE
Three key aspects are involved in BiSet: coordinated relationship dis-
covery in data level; bundles as objects and a “in-between” layer in
visual level; and interactions to support four types of exploration and
two ways of organizing information. In this section, we discuss them
in detail and explain how identiﬁed design requirements are satisﬁed.

4.1 Data Level: Bicluster Discovery
Coordinated relationship discovery is the fundamental step in BiSet
since it determines how edges are bundled. In BiSet, we formalize co-
ordinated relationships as biclusters. Suppose that entities have been
extracted from a dataset (e.g., documents) with named entity recogniz-
ers such as LingPipe [5] or similar tools. We use closed itemset algo-
rithms (e.g., LCM [51] and CHARM [56]) to discover biclusters based
on extracted entities. Each unique pair of entity types (e.g., people and
location, people and date, location and date, etc.) is considered a type
of coordinated relationship and is computed separately to generate re-
sults that include all unique pairs of entity types. Results are stored in
a database and associated with the dataset under investigation.

The mined biclusters indicate different coordinated relationships
and some of them may share entities and relations in entity-level or
group-level. This suggests that some entities and edges (individual re-
lationships) are members of biclusters. Thus, membership in BiSet, in
the data level, can be considered from two aspects: entity and edge.

4.2 Visual Level: Bundles as Objects and “In-between”
In BiSet, we propose two important concepts to balance the key design
trade-off: making bundles as ﬁrst class objects and adding a new layer
“in-between” lists to contain bundle objects. The former enables users
to directly manipulate relationships (relationship-centric) and the lat-
ter helps to visually reveal membership of entities in two neighboring
lists without duplicating entities (entity-centric).

Making Bundles as Objects In BiSet, we make bundles the ﬁrst
class objects so users can directly manipulate them for sensemaking
purposes (e.g., organizing information). BiSet bundles edges based
on computed biclusters that reﬂect algorithmically discovered coordi-
nated relationships. Different from spatial edge bundling techniques
that emphasize bundling based on spatial proximity, BiSet bundles
edges based on coordinated relationships that reveal task-oriented se-
mantic insights. This assures that edge bundles remain stable, regard-
less of the positions of associated entities. Thus, bundles potentially
enables users to use space (e.g., vertical position) to organize informa-
tion (e.g., entities) (for R3), and safely retrieve related information by
interacting with edge bundles (for R2, iii and iv).

Adding an “in-between” Layer To make bundles usable, we add
a new layer, called “in-between”, visually locating in the space be-
tween two neighboring entity-lists. It contains bundles and edges (e.g.,
those that do not belong to any coordinated relationship). In this layer,
BiSet allows users to manipulate bundles for sensemaking (e.g., orga-
nizing entities and checking their membership), so bundles can support
users interactively exploring coordinated relationships.
4.2.1 Semantic Edge Bundling in BiSet
BiSet has two types of edges: independent and associated, which are
mutually exclusive. The former refers to edges that do not belong to
any coordinated relationship and the latter are those that can form one
or more coordinated relationships. For instance, in Figure 6, the edge
on top in (A) is an independent edge and other edges are associated
ones. Independent edges can reﬂect entity-level and group-level rela-
tionships, but they are not associated with others to form coordinated
relationship. Based on membership, associated edges that belong to
the same bicluster can be aggregated and represented as an edge bun-
dle. BiSet takes the following three steps to bundle edges (for R1(b)).

Fig. 6. Three modes in the “in-between” layer for displaying edges. (A)
is the edge only mode that shows all edges between related entities. (B)
is the hybrid mode, which presents bundles with individual edges. (C) is
the bundle only mode that just displays bundles.

1) Grouping edges based on membership. We separate associated
edges into different groups based on their associated biclusters. For

those in multiple biclusters, we duplicate and assign them respectively
to multiple groups, so each group has a complete number of edges.

2) Bundling edges based on groups. For each group obtained from
the previous step, we bundle all its edges together and visually replace
these edges with a rectangle to indicate an edge bundle.

3) Connecting bundles with entities. We link bundles and entities
based on membership. This assures that entities and their associated
bundles are fully connected (for R1(c)).

This bicluster-based edge bundling can potentially reduce visual
clutter and clearly present a coordinated relationship (for R1(b)). As
is shown in Figure 6, compared with (A), (B) clearly illustrates the
coordinated relationship between four people and ﬁve phone numbers.
In fact, BiSet supports three modes to show edges: edge only mode
(EM), hybrid mode (HM) and bundle only mode (BM), shown as (A),
(B) and (C) respectively in Figure 6. In EM, BiSet shows edges with-
out bundling. In HM, BiSet shows independent edges and bundles. In
BM, BiSet just displays bundles. The three modes attempt to meet dif-
ferent user needs. For example, EM potentially reveals the overview
of relationships between two entity sets (e.g., (A) in Figure 6). BM
enables users to focus on analysis just with coordinated relationships.
HM can help to visually organize groups of individual relations into
multiple levels (e.g., coordinated bundles with individual entity-level
relationships). In BiSet, users can switch modes during their analysis.
An example of using semantic edge bundling in BiSet is shown in Fig-
ure 7, which reduces 164 edges to 9 bundles. In this example, we use
LCM to calculate biclusters and set the minimum support parameter
to three, which assures that each calculated bicluster has at least three
entities in one of the two related domains (here is the people’s name).

Fig. 7. A semantic edge bundling example in BiSet. (A) shows the orig-
inal 164 edges. (B) After semantic edge bundling, there are 9 bundles.

In addition to improving readability, bundles in BiSet preserve the
coordinated attribute of entities and edges. This enables users to infer
semantic meanings about potentially coordinated activities. For exam-
ple, why are the four people all related with the ﬁve phone numbers
in Figure 6? Perhaps they colluded about a terrorist assault. Such se-
mantic insights cannot be easily revealed from separated entity-level
or group-level of relations. Thus, edge bundles in BiSet serve two im-
portant roles: improving readability and revealing semantic insights.

4.2.2 Visual Encoding in BiSet
BiSet uses four major visual channels [37] to encode bundles, entities
and edges: shape, size, color and position. Figure 8 shows a detailed
example of visual encodings in BiSet.

Shape and Size In BiSet, entities and bundles are represented
as rectangles (e.g., (1) and (2) in Figure 8). Edges are visualized as
B´ezier curves. We choose B´ezier curves since they can generate more
smooth edges, compared with polylines [32].

Length, width and font size are three speciﬁc types of size channel
used in BiSet. Rectangles indicating entities are equal in length, while
those representing bundles are not. BiSet applies a linear mapping
function to determine the length of a bundle based on the total number
of its related entities. In a bundle, BiSet uses two colored regions (light
green and light gray) to indicate the proportion between its related
entities in the left list and those in the right list. In an entity rectangle,
a small rectangle is presented on the left to indicate its frequency in
a dataset. The length of these small rectangles is determined by the
frequency of the associated entities. Based on these with different
color encoding and position, users can easily discriminate entities from
bundles (for R1(a)). In addition, the width of edges can reﬂect results
of user selections. For instance, in Figure 8, compared with the width
of those in (3), the width of edges in (8) is larger, since two relevant
entities are selected. Moreover, when hovering an selected entity or
bundle, related entities will be displayed in larger fonts. This helps
users to review relevant information of previous selections (for R1(c)).

Fig. 8. Visual encodings in BiSet. (1), (2) and (3) present the normal
state of an entity, a bundle and edges, respectively. (4) and (4’) show the
selected state of an entity and a bundle with accumulated highlighting.
(5) and (5’) present the mouseover state of an entity and a bundle. (6)
shows accumulated highlighting of an entity. (7) presents the highlight-
ing state of edges. (8) shows the accumulated highlighting of edges.

Color Coding BiSet applies color coding to entities, bundles and
edges to indicate their states. In BiSet, entities and bundles have three
different states (normal, mouseover and selected), and edges has two
different states (normal and highlighting). In Figure 8, (1), (2) and (3)
respectively present the normal state of an entity, a bundle and edges;
(4) and (4’) show the selected state of an entity and a bundle; (5) and
(5’) illustrate the mouseover state of an entity and a bundle; and (7)
and (8) demonstrate the highlighting state of edges. In addition, two
different colored borders (blue and black) are used to help users further
discriminate the mouseover state from the selected state (for R1(d)).
When hovering an entity or a bundle, a blue border will be added to the
rectangle. This border will change to black after user selection, which
indicates that the state has changed from mouseover to selected.

Accumulated highlighting is important in BiSet, which is triggered
by mouseover and selection. Different from simple highlighting, ac-
cumulated highlighting provides useful visual clues (e.g., darker in
orange) for shared entities (for R1(c)) and bundles. BiSet applies ac-
cumulated highlighting to entities, bundles and edges by increasing
the shading of their colors. For example, in Figure 8, the entity in
(6) is in darker orange, compared with those in (4) and (5), since its
highlighting is accumulated based on selections of the entity in (4) and
AMTRAK, and the mouseover on (5).

Position Position is used to organize entities and bundles in BiSet.
A set of entities of a certain domain (e.g., people) is organized as an
entity-list. In between two neighboring entity-lists (the “in-between”
layer), there is one relationship-list that contains coordinated relation-
ships as biclusters (visually as edge bundles).

In entity-lists, the positions of entities can be determined in three
ways (for R3):
in an alphabetical order, based on frequency, or
based on the order of (one-side) associated bundles. Alphabetical and
frequency-based ordering can help to organize entities. However, they
may lead to a severe problem of membership separation, since entities

belonging to the same bicluster may not be listed close to each other.
This results from the trade-off discussed in Section 3.1. To balance
this trade-off, BiSet provides the third approach to organize the po-
sition of entities based on the order of (one-side) associated bundles.
For example, entities in the left list in Figure 8 are ordered based on
their associated biclusters in the middle list.

The larger a bicluster’s size is, the more important it is likely to
be. A bicluster in larger size contains more information, so it is more
likely to reveal potentially meaningful coordinated relationships. With
this rationale, we apply a greedy algorithm, listed below, to organize
entities based on the size of their associated biclusters.

Algorithm 1: Get positions of entities associated with biclusters
input : curPos, initialized as 0 for the top position

orderedBics, a list of ordered biclusters
bicEntDict, a dictionary stores entities for each bicluster
entBicDict, a dictionary stores biclusters for each entity
rankedEntSet, a set stores entities already ranked

totalRank += bicluster.rank;
num += 1;

if not entity in rankedEntSet then
bicList = entBicDict(entity);
totalRank = 0, num = 0;
foreach bicluster in bicList do

1 foreach bic in orderedBics do
entList = bicEntDict(bic);
2
foreach entity in entList do
3
4
5
6
7
8
9
10
11
12
13
14
15 end
16 orderedEnts = entList.sort(sel f .rank);
17 foreach entity in orderedEnts do
18
19 end

end
entity.rank = totalRank / num;
rankedEntSet.add(entity);

entity.pos = curPos++

end

end

BiSet also allows automatically changing positions of groups of en-
tities (for R3) by dragging a bundle in the “in-between” layer. Figure
9 shows such an example. After dragging a bundle, two groups of en-
tities in its two neighboring lists automatically move to new positions.
In the “in-between” layer, BiSet supports two ways to organize po-
sitions of bundles: automatically adjusting positions based on related
entities, and manually dragging and moving bundles to new positions.
The former allows listing bundles based on the positions of entities
in either or both neighboring list(s), while the latter enables users to
adjust the automatically generated layout based on their ad hoc needs
(e.g., synthesis with created spatializations).

4.3 Interaction: Exploring and Organizing Information
Revealing and organizing information in a bidirectional manner serves
as a key design principle for interactions in BiSet. By enabling users
to directly interact with entities in entity-lists, and bundles in the “in-
between” layer, BiSet can potentially support four types of exploration
and two ways of organizing information.

Revealing Information BiSet supports bidirectional information
revealing. Speciﬁcally, users can ﬁnd relevant bundles by selecting or
hovering over entities, and vice versa (for R2, ii and iv). Relevant
entities or bundles in entity-lists or “in-between” layer will also be
highlighted in BiSet (for R2, i and iii), when users interact with an
entity or a bundle. This means that when users select (or hover over)
entities, BiSet can use accumulated highlighting to reveal four types
of potentially relevant information: 1) entities in the same list that
belong to the same bicluster(s) with the selected entities, 2) entities
in other list(s) that are related with the selected entities, 3) bundles in
neighboring “in-between” layer that are directly connected with the

Fig. 9. Dragging a bundle in the “in-between” layer. Entities associated
with this bundle automatically move to their new positions.

selected entities, and 4) bundles in other relationship-list(s) that are
associated with the selected entities via bicluster-chain(s). 1) and 2)
satisfy the requirement of T1 and T2 (from entity to entity), and 3)
and 4) support T3 and T4 (from entity to relationship). Similarly,
when users select (or hover over) bundles, BiSet can reveal the same
four types of information, but they are related with selected bundles.
In this case, 1) and 2) fulﬁll the requirement of T7 and T8 (from
relationship to entity), and 3) and 4) can support T5 and T6 (from
relationship to relationship). For example, in Figure 8 when users
hover the entity in (5), three entities in the left list and six entities in the
right list are highlighted. Of the six entities, the FBI one is in darker
orange, which indicates that it is shared with another bundle (bicluster)
on the bottom. The bundle on top is also highlighted, since it is directly
related to the entity. With such ways of revealing information, BiSet
can support the four types of exploration.

Fig. 10. The document view from bundles in BiSet. (A) shows bicluster
ID, related document and associated entities. (B) shows the content of a
document. (C) lists all document ID(s) in the data with a search function.

Organizing Information BiSet supports two ways of organizing
information, which is also bidirectional. Users can organize the posi-
tion of entities based on bundles, and vice versa. BiSet uses vertical
positions to visually externalize the organized entities and bundles. As
discussed above, for bundles in the “in-between” layer, BiSet can not
only automatically organize them based on the position of related en-
tities, but also enable users to manually adjust their positions by drag-
ging and moving them. For entities, BiSet provides three options to
automatically order them in an entity-list. When users drag and move
a bundle, associated entities in two neighboring lists move with it, as
is shown in Figure 9. This enables users to manually adjust positions
of a group of related entities by using bundles. Thus, in BiSet, entities
and bundles can mutually impact each other, which provides a ﬂexible
way for users to organize information in lists.

BiSet also allows users to review documents directly from bundles
and entities with a right click menu (for R4), shown in Figure 10.
When ﬁnding an interesting bundle or entity, users can use a right click
menu to open a popup view where relevant documents are listed. This
view is on top of the view for relationship exploration. After reading,
users can quickly return to previous view by closing it.

5 USAGE SCENARIO
In this section, we walk through a text analytics scenario to demon-
strate how BiSet supports an analyst to identify a coordinated activity.
We use The Sign of the Crescent dataset [27] which contains 41 ﬁc-
tional intelligence reports regarding a coordinated terrorist plot in three
US cities, and each plot involves a group of (at least four) suspicious
people. In fact, 24 of them are relevant to the plot. We used LCM
[51] to generate biclusters from the dataset with the minimum support
parameter set to 3, which assured that each bicluster has at least three
entities from one domain. This resulted in 284 unique entities, 495
relationships, and 337 biclusters (including 122 thin biclusters).

Suppose that Sarah is an intelligence analyst. She is assigned a task
to read intelligence reports and identify potential terrorist threats with
key persons. She opens BiSet, selects four identiﬁed domains (people,
location, phone number and date) and starts her analysis. Figure 11
shows the key steps of Sarah’s analytical process.

Rapid discovery of insights from coordinated relationships with
bidirectional exploration. Sarah begins analysis by hovering indi-
vidual entities in the list of people’s names. BiSet highlights related
bundles and entities, each time when she hovers the mouse over an
entity (T1 and T3). Immediately she ﬁnds that A. Ramazi is active
in three bundles, which indicates that this person is involved in three
coordinated activities (T3). Sarah selects it (Figure 11 (1)) to focus
on highlighted entities of the three bundles (T8). She ﬁnds that A.
Ramazi is involved in two cells with ﬁve other people. One is in Ger-
many and the other is more broad including four countries. A. Ramazi
is the only person connecting the two cells, and there are two over-
lapped subgroups of people involved in the broader cell. Moreover,
each subgroup has its unique person (B. Dhaliwal and F. Goba) (T7).
BiSet quickly directs Sarah to such insights with just one click. With-
out BiSet, Sarah has to select and deselect many entities to ﬁnd these
meaningful semantic insights, particularly with tools that only display
simple relationships (e.g., entity-level or group-level), such as Jigsaw.
Easily gaining insights from bundles for exploration in entity-
space. Then Sarah decides to explore the two overlapped subgroups,
because she wants to know what brings the unique people to them. She
checks B. Dhaliwal ﬁrst by hovering the mouse over it. After this, two
bundles are highlighted (T3). By following edges from them, Sarah
ﬁnds that they share two people’s name and three locations, but the
bigger one (shown in Figure 11 (2)) is related to a new name (H. Pakes)
(T8). Then she examines F. Goba in the same way. This time three
bundles and three names are highlighted (T1 and T3), and one name
(M. Galab) has a high frequency. This quickly catches Sarah’s atten-
tion, so she decides to temporarily pause the analytical branch of B.
Dhaliwal, and moves on with the branch of F. Goba. Sarah hovers the
mouse over M. Galab to check whether it leads to more information
(T1 and T3). However, it turns out that no additional bundles or names
are highlighted. Sarah realizes that people potentially related with M.
Galab have already been highlighted in her current workspace. The
bundle (shown in Figure 11 (3) as the black dot box in the middle)
clearly reveals the people related with M. Galab, and their activities
are all in the US (T7). With this bundle, Sarah easily acquires this
key insight revealed by a group of locations. The relations revealed in
this bundle are important, and Sarah infers that the three people (M.
Galab, Y. Mosed and Z. al Shibh) may work on something together
in the US. Thus, she decides to ﬁnd more relevant information by fol-
lowing this tail [30] (T2, T4 and T7). Without bundles, Sarah has to
mentally aggregate such pieces of information (18 edges crossed with
each other) to gain this insight (e.g., in Jigsaw’s List View).

Visually connecting semantic insights using bundles for explo-
ration in relationship-space. Sarah selects the same bundle. BiSet
highlights relevant bundles that potentially form bicluster chains with

the selected one (T5). She ﬁnds that ﬁve bundles, in the space be-
tween the location list and the phone number list, are highlighted, and
two bundles, in the space between the phone number list and the date
list, are highlighted. Relevant entities in lists are also highlighted (T7).
In the two lists of newly highlighted bundles, Sarah ﬁnds that there
are two big ones (relatively longer in width shown in Figure 11 (4))
in each list. These two bundles seem useful since they contain more
relations. Sarah wants to investigate these ﬁrst and tries to check how
bundles from different relationship lists are connected (T6). For bun-
dles between the location list and the phone number list (from top to
bottom), Sarah ﬁnds that the ﬁrst bundle and the third one share two
locations (Charlottesville and Virginia) with the selected bundle, and
other highlighted bundles just share one location with the selected one
(T6). Compared with the third bundle, the ﬁrst one is related with
more locations that are not associated the selected bundle (T7). Sarah
wants to focus on information highly connected with the selected bun-
dle, rather than more additional information. Thus, she considers the
third bundle, in this case, a useful one. Using the same strategy in an-
other relationship-list, she ﬁnds that the bigger bundle is more useful.
After this, Sarah hides edges of other bundles with the right click
menu to keep a clear view. Then her workspace shows that three bun-
dles connected to each other through two shared locations and three
shared phone numbers. Sarah feels that she has found a good number
of relations, connecting four groups of entities, which may reﬂect a
suspicious activity. Therefore, she decides to read relevant documents
to ﬁnd details of such connections and generate her hypothesis.

Efﬁciently directing to relevant documents based on bundle ob-
jects. The three connected bundles direct Sarah to eight reports, which
are all relevant to the plot. Sarah quickly goes through these reports
by referring to the entities with bright shading in the four connected
groups (shown in Figure 11 (4)). The darker shading of an entity in-
dicates that it is shared more times. Sarah uses this to help keep her
attention to more important entities in reports. After reading the re-
ports, she identiﬁes a potential threat with four key persons.

Aiding hypothesis generation. By visually following the bicluster-
chain (linked bundles, shown in Figure 11 (4)), Sarah quickly remem-
bers what she has already read [2]. Finally she makes a hypothesis of
the identiﬁed attack as follows:

F. Goba, M. Galab and Y. Mosed, following the commands from A.

Ramazi, plan to attack AMTRAK Train 19 at 9:00 am on April 30.

6 CONCLUSION AND FUTURE WORK
We present BiSet, a visual analytics technique, which bundles edges
based on biclusters to reveal task-oriented semantic insights about po-
tentially coordinated activities for sensemaking. In BiSet, we make
edge bundles the ﬁrst class objects that enable users to directly ma-
nipulate relationships. In addition, we add a new layer, “in-between”,
containing bundles, which assists to visually reveal membership of en-
tities in neighboring entity-lists without entity duplication.

By applying interactions on bundles and entities, BiSet enables
bidirectional information foraging to support exploration between the
entity-space and the relationship-space. Moreover, BiSet allows or-
ganizing entities in lists, either automatically based on the positions
of associated bundles or manually by dragging and moving bundles.
With a usage scenario, we demonstrate how BiSet can potentially sup-
port an analyst to explore coordinated activities. However, there are
still three challenges that need further explorations.

C1: Seriation in lists. In BiSet, we apply a greedy approach to
order entities in lists based on bicluters in neighboring relationship-
list(s). Compared with traditional ordering (in an alphabetical order
or by frequency), this attempts to keep entities, belonging to the same
biclusters (especially those in a larger size), close to each other. How-
ever, this approach may lead to a membership separation problem for
smaller sized biclusters (those with a small number of entities), espe-
cially if some of their entities are shared by bigger sized biclusters. In
fact, this brings about an ordering problem in lists when considering
the design trade-off discussed before. Seriation methods, commonly
used in matrices [35], can reveal clustering structure by permuting the
presentation order [8]. However, applying a seriation method to order-

Fig. 11. A process of ﬁnding a major threat plot with key steps. (1): Based on A. Ramazi, ﬁnding that there are two similar bundles and two cells.
(2): One name and two bundles are highlighted when hovering the mouse over B. Dhaliwal. (3): Three names and three bundles are highlighted
when exploring F. Goba. (4) Referring to the four connected groups of useful entities for hypothesis generation.

ing entities in lists, based on coordinated relationships, is challenging.
Seriation in lists based on biclusters may better organize entities and
reduce edge crossings between shared entities and edge bundles.

C2: Variant visualizations in lists. BiSet chooses list as its ma-
jor layout to organize entities and applies interactions to bundles to
enhance its capability to utilize the relationship-space. However, or-
ganizing entities in a list may not always be the best choice. For exam-
ple, entities of locations (e.g., Chicago, Boston, Seattle, etc.) may bet-
ter reveal meaningful, contextual information, if visualized in a map,
rather than simply listed as vertically piled bars. Similar to the tech-
nique proposed in [20], it is possible to substitute some entity-lists
with variant types of visualizations in BiSet, which may help users to
infer contextual clues. If such substitution could be switched on and
off, users would infer semantic insights from lists, and gain contextual
clues from variant views (e.g., maps).

C3: Semantic Interactions in lists. Semantic interaction provides
an efﬁcient way to facilitate visual analytics by enabling users to im-
plicitly steer machine learning algorithms to support the human rea-
soning process [13]. This allows users to modify algorithmic outcomes
for sensemaking purposes. Currently BiSet does not support this. Se-
mantic interactions on bundles for organizing entities, such as split-
ting and merging bundles (similar to those in NodeTrix [23]), can help
users to adjust algorithmically discovered biclusters and efﬁciently re-
trieve relevant information. In addition, merging bundles also provides
a good opportunity for BiSet to scale up to a large dataset.

ACKNOWLEDGMENTS
The authors wish to thank Kurt Luther for his feedback on the initial
version of BiSet, and Junyang Chen and Bin He for supporting the

backend development of BiSet. This research was supported in part
by a grant from L-3 Communications and NSF grant IIS-1447416.

REFERENCES
[1] B. Alsallakh, L. Micallef, W. Aigner, H. Hauser, S. Miksch, and
P. Rodgers. Visualizing Sets and Set-typed Data: State-of-the-Art and
Future Challenges. In EuroVis-STARs. Eurographics Association, 2014.
large high-
resolution displays for sensemaking. In Proceedings of the Conference
on Human Factors in Computing Systems, pages 55–64. ACM, 2010.

[2] C. Andrews, A. Endert, and C. North. Space to think:

[3] S. Barkow, S. Bleuler, A. Preli´c, P. Zimmermann, and E. Zitzler. Bicat: a
biclustering analysis toolbox. Bioinformatics, 22(10):1282–1283, 2006.
[4] R. A. Becker and W. S. Cleveland. Brushing scatterplots. Technometrics,

[5] B. Carpenter. Phrasal queries with lingpipe and lucene: ad hoc genomics

29(2):127–142, 1987.

text retrieval. In TREC, 2004.

[6] D. B. Carr, R. J. Littleﬁeld, W. Nicholson, and J. Littleﬁeld. Scatterplot
matrix techniques for large n. Journal of the American Statistical Associ-
ation, 82(398):424–436, 1987.

[7] G. Chin Jr, O. A. Kuchar, and K. E. Wolf. Exploring the analytical pro-
cesses of intelligence analysts. In Proceedings of the SIGCHI Conference
on Human Factors in Computing Systems, pages 11–20. ACM, 2009.

[8] J. Chuang, C. D. Manning, and J. Heer. Termite: Visualization techniques
for assessing textual topic models. In Proceedings of International Work-
ing Conference on Advanced Visual Interfaces, pages 74–77. ACM, 2012.
[9] C. Collins and S. Carpendale. VisLink: Revealing Relationships
Amongst Visualizations. Visualization and Computer Graphics, IEEE
Transactions on, 13(6):1192–1199, 2007.

[10] C. Collins, G. Penn, and S. Carpendale. Bubble sets: Revealing set re-
lations with isocontours over existing visualizations. Visualization and

Computer Graphics, IEEE Transactions on, 15(6):1009–1016, 2009.

[11] W. Cui, H. Zhou, H. Qu, P. C. Wong, and X. Li. Geometry-based edge
clustering for graph visualization. Visualization and Computer Graphics,
IEEE Transactions on, 14(6):1277–1284, 2008.

[12] M. D¨ork, N. H. Riche, G. Ramos, and S. Dumais. Pivotpaths: Strolling
through faceted information spaces. Visualization and Computer Graph-
ics, IEEE Transactions on, 18(12):2709–2718, 2012.

[13] A. Endert, P. Fiaux, and C. North. Semantic interaction for sensemak-
ing: inferring analytical reasoning for model steering. Visualization and
Computer Graphics, IEEE Transactions on, 18(12):2879–2888, 2012.

[14] P. Fiaux, M. Sun, L. Bradel, C. North, N. Ramakrishnan, and A. En-
dert. Bixplorer: Visual analytics with biclusters. Computer, 46(8):90–94,
2013.

[15] T. M. Fruchterman and E. M. Reingold. Graph drawing by force-directed
placement. Software: Practice and experience, 21(11):1129–1164, 1991.
[16] T. Geymayer, M. Steinberger, A. Lex, M. Streit, and D. Schmalstieg.
Show me the invisible: visualizing hidden content. In Proceedings of the
Conference on Human Factors in Computing Systems, pages 3705–3714.
ACM, 2014.

[17] M. Ghoniem, J. Fekete, and P. Castagliola. A comparison of the readabil-
ity of graphs using node-link and matrix-based representations. In Infor-
mation Visualization, IEEE Symposium on, pages 17–24. IEEE, 2004.

[18] J. P. Gonc¸alves, S. C. Madeira, and A. L. Oliveira. Biggests: integrated
environment for biclustering analysis of time series gene expression data.
BMC Research Notes, 2(1):124, 2009.

[19] C. Gorg, Z. Liu, J. Kihm, J. Choo, H. Park, and J. Stasko. Combining
computational analyses and interactive visualization for document explo-
ration and sensemaking in jigsaw. Visualization and Computer Graphics,
IEEE Transactions on, 19(10):1646–1663, 2013.

[20] S. Gratzl, N. Gehlenborg, A. Lex, H. Pﬁster, and M. Streit. Domino: Ex-
tracting, Comparing, and Manipulating Subsets Across Multiple Tabular
Datasets. Visualization and Computer Graphics, IEEE Transactions on,
20(12):2023–2032, 2014.

[21] G. A. Grothaus, A. Mufti, and T. Murali. Automatic layout and visual-

ization of biclusters. Algorithms for Molecular Biology, 1(1):15, 2006.

[22] J. Heinrich, R. Seifert, M. Burch, and D. Weiskopf. Bicluster viewer:
a visualization tool for analyzing gene expression data. In Advances in
Visual Computing, pages 641–652. Springer, 2011.

[23] N. Henry, J. Fekete, and M. J. McGufﬁn. Nodetrix: a hybrid visualization
of social networks. Visualization and Computer Graphics, IEEE Trans-
actions on, 13(6):1302–1309, 2007.

[24] I. Herman, G. Melanc¸on, and M. S. Marshall. Graph visualization and
navigation in information visualization: A survey. Visualization and
Computer Graphics, IEEE Transactions on, 6(1):24–43, 2000.

[25] D. Holten. Hierarchical edge bundles: Visualization of adjacency rela-
tions in hierarchical data. Visualization and Computer Graphics, IEEE
Transactions on, 12(5):741–748, 2006.

[26] D. Holten and J. J. Van Wijk. Force-directed edge bundling for graph
visualization. In Computer Graphics Forum, volume 28, pages 983–990.
Wiley Online Library, 2009.

[27] F. Hughes and D. Schum. Discovery-proof-choice, the art and science of
the process of intelligence analysis-preparing for the future of intelligence
analysis. Washington, DC: Joint Military Intelligence College, 2003.

[28] A. Inselberg and B. Dimsdale. Parallel coordinates. In Human-Machine

Interactive Systems, pages 199–233. Springer, 1991.

[29] Y. Jin, T. M. Murali, and N. Ramakrishnan. Compositional mining of
multirelational biological datasets. ACM Transactions on Knowledge Dis-
covery from Data, 2(1):1–35, Mar. 2008.

[30] Y.-a. Kang, C. Gorg, and J. Stasko. Evaluating visual analytics systems
for investigative analysis: Deriving design principles from a case study. In
Visual Analytics Science and Technology, 2009. VAST 2009. IEEE Sym-
posium on, pages 139–146. IEEE, 2009.

[31] M. Kapushesky, P. Kemmeren, A. C. Culhane, S. Durinck, J. Ihmels,
C. K¨orner, M. Kull, A. Torrente, U. Sarkans, J. Vilo, et al. Expression
proﬁler: next generation-an online platform for analysis of microarray
data. Nucleic acids research, 32(suppl 2):W465–W470, 2004.

[32] A. Lambert, R. Bourqui, and D. Auber. Winding Roads: Routing edges

into bundles. Computer Graphics Forum, 29(3):853–862, Aug. 2010.

[33] A. Lex, H. Schulz, M. Streit, C. Partl, and D. Schmalstieg. VisBricks:
Multiform Visualization of Large, Inhomogeneous Data. IEEE Transac-
tions on Visualization and Computer Graphics, 17(12):2291–2300, 2011.
[34] A. Lex, M. Streit, C. Partl, K. Kashofer, and D. Schmalstieg. Compara-
tive Analysis of Multidimensional, Quantitative Data. Visualization and

Computer Graphics, IEEE Transactions on, 16(6):1027–1035, 2010.

[35] I. Liiv. Seriation and matrix reordering methods: An historical overview.
Statistical Analysis and Data Mining: The ASA Data Science Journal,
3(2):70–91, 2010.

[36] S. C. Madeira and A. L. Oliveira. Biclustering algorithms for biologi-
cal data analysis: a survey. Computational Biology and Bioinformatics,
IEEE/ACM Transactions on, 1(1):24–45, 2004.

[37] T. Munzner. Visualization Analysis and Design. CRC Press, 2014.
[38] C. Partl, A. Lex, M. Streit, H. Strobelt, A. M. Wassermann, H. Pﬁster, and
D. Schmalstieg. ConTour: Data-Driven Exploration of Multi-Relational
Datasets for Drug Discovery. Visualization and Computer Graphics,
IEEE Transactions on, 20(12):1883–1892, 2014.

[39] P. Pirolli and S. Card. The sensemaking process and leverage points for
analyst technology as identiﬁed through cognitive task analysis. In Pro-
ceedings of international conference on intelligence analysis, volume 5,
pages 2–4, 2005.

[40] A. J. Pretorius and J. J. Van Wijk. Visual inspection of multivariate
graphs. In Computer Graphics Forum, volume 27, pages 967–974. Wiley
Online Library, 2008.

[41] N. H. Riche and T. Dwyer. Untangling euler diagrams. IEEE Transac-
tions on Visualization and Computer Graphics, 16(6):1090–1099, 2010.
[42] P. Rodgers. A survey of euler diagrams. Journal of Visual Languages &

Computing, 25(3):134–155, 2014.

[43] R. Santamar´ıa, R. Ther´on, and L. Quintales. Bicoverlapper 2.0: visual

analysis for gene expression. Bioinformatics, page btu120, 2014.

[44] L. Shi, Q. Liao, H. Tong, Y. Hu, Y. Zhao, and C. Lin. Hierarchical fo-
cus+ context heterogeneous network visualization. In Paciﬁc Visualiza-
tion Symposium (PaciﬁcVis), 2014 IEEE, pages 89–96. IEEE, 2014.

[45] H. Siirtola and K.-J. R¨aih¨a. Interacting with parallel coordinates. Inter-

acting with Computers, 18(6):1278–1309, 2006.

[46] M. Steinberger, M. Waldner, M. Streit, A. Lex, and D. Schmalstieg.
Context-Preserving Visual Links. Visualization and Computer Graphics,
IEEE Transactions on, 17(12):2249–2258, 2011.

[47] M. Streit, S. Gratzl, M. Gillhofer, A. Mayr, A. Mitterecker, and
S. Hochreiter. Furby: fuzzy force-directed bicluster visualization. BMC
bioinformatics, 15(Suppl 6):S4, 2014.

[48] M. Sun, L. Bradel, C. L. North, and N. Ramakrishnan. The role of in-
teractive biclusters in sensemaking. In Proceedings of the Conference on
Human Factors in Computing Systems, pages 1559–1562. ACM, 2014.

[49] M. Sun, C. North, and N. Ramakrishnan. A Five-Level Design Frame-
work for Bicluster Visualizations. Visualization and Computer Graphics,
IEEE Transactions on, 20(12):1713–1722, 2014.

[50] A. Telea and O. Ersoy.

Image-Based Edge Bundles: Simpliﬁed Visu-
alization of Large Graphs. Computer Graphics Forum, 29(3):843–852,
2010.

[51] T. Uno, T. Asai, Y. Uchida, and H. Arimura. An efﬁcient algorithm for
enumerating closed patterns in transaction databases. In Discovery Sci-
ence, pages 16–31. Springer, 2004.

[52] C. Viau and M. J. McGufﬁn. ConnectedCharts: Explicit Visualization
of Relationships between Data Graphics. Computer Graphics Forum,
31(3pt4):1285–1294, June 2012.

[53] M. Waldner, W. Puff, A. Lex, M. Streit, and D. Schmalstieg. Visual links
In Proceedings of Graphics Interface 2010, pages

across applications.
129–136. Canadian Information Processing Society, 2010.

[54] H. Wu, J. Vreeken, N. Tatti, and N. Ramakrishnan. Uncovering the plot:
detecting surprising coalitions of entities in multi-relational schemas.
Data Mining and Knowledge Discovery, 28(5-6):1398–1428, 2014.

[55] H.-M. Wu, Y.-J. Tien, and C.-h. Chen. Gap: A graphical environment
for matrix visualization and cluster analysis. Computational Statistics &
Data Analysis, 54(3):767–778, 2010.

[56] M. J. Zaki and C.-J. Hsiao. Efﬁcient algorithms for mining closed item-
sets and their lattice structure. Knowledge and Data Engineering, IEEE
Transactions on, 17(4):462–478, 2005.

[57] H. Zhang, M. Sun, D. D. Yao, and C. North. Visualizing trafﬁc causality
for analyzing network anomalies. In Proceedings of the 2015 ACM Inter-
national Workshop on International Workshop on Security and Privacy
Analytics, pages 37–42. ACM, 2015.

[58] H. Zhou, P. Xu, X. Yuan, and H. Qu. Edge bundling in information visu-

alization. Tsinghua Science and Technology, 18(2):145–156, 2013.

","{""pos"":{""0"":1,""1"":2,""2"":3,""3"":4,""4"":5,""5"":6,""6"":7},""1"":{""0"":""cid"",""1"":""j"",""2"":""sarah*"",""3"":""acm*"",""4"":""r1*"",""5"":""lex*"",""6"":""t3*""},""2"":{""0"":""e*"",""1"":""m*"",""2"":""h*"",""3"":""r*"",""4"":""p"",""5"":""n*"",""6"":""l*""},""4"":{""0"":""visual"",""1"":""edge"",""2"":""visualization*"",""3"":""layout*"",""4"":""computer*"",""5"":""graphics*"",""6"":""diagram*""},""0"":{""0"":""biset*"",""1"":""streit*"",""2"":""\ufb01nds*"",""3"":""galab*"",""4"":""schmalstieg*"",""5"":""ramazi*"",""6"":""goba*""},""3"":{""0"":""entities*"",""1"":""entity"",""2"":""users"",""3"":""relationships*"",""4"":""relationship"",""5"":""relations*"",""6"":""level""},""5"":{""0"":""coordinated*"",""1"":""related*"",""2"":""a*"",""3"":""48"",""4"":""associated*"",""5"":""selected"",""6"":""highlighted""}}",2016,{},False,False,journalArticle,False,9BL2E5F8,[],self.user,"{""Unnamed: 0"":{""0"":0,""1"":1,""2"":2,""3"":3,""4"":4,""5"":5,""6"":6,""7"":7,""8"":8,""9"":9,""10"":10,""11"":11,""12"":12,""13"":13,""14"":14,""15"":15,""16"":16,""17"":17,""18"":18,""19"":19,""20"":20,""21"":21,""22"":22,""23"":23,""24"":24,""25"":25,""26"":26,""27"":27,""28"":28,""29"":29,""30"":30,""31"":31,""32"":32,""33"":33,""34"":34,""35"":35,""36"":36,""37"":37,""38"":38,""39"":39,""40"":40,""41"":41,""42"":42,""43"":43,""44"":44,""45"":45,""46"":46,""47"":47,""48"":48,""49"":49,""50"":50,""51"":51,""52"":52,""53"":53,""54"":54,""55"":55,""56"":56,""57"":57,""58"":58,""59"":59,""60"":60,""61"":61,""62"":62,""63"":63,""64"":64,""65"":65,""66"":66,""67"":67,""68"":68,""69"":69,""70"":70,""71"":71,""72"":72,""73"":73,""74"":74,""75"":75,""76"":76,""77"":77,""78"":78,""79"":79,""80"":80,""81"":81,""82"":82,""83"":83,""84"":84,""85"":85,""86"":86,""87"":87,""88"":88,""89"":89},""C"":{""0"":33.8421009347,""1"":20.7829554473,""2"":13.1954448793,""3"":13.2565125855,""4"":19.735917499,""5"":13.6274895884,""6"":11.0805116922,""7"":15.4042321671,""8"":8.9345265297,""9"":6.8087726676,""10"":6.3387707497,""11"":8.8633978349,""12"":12.1709324274,""13"":9.5388615109,""14"":13.0393051756,""15"":11.5812001439,""16"":6.1304270071,""17"":33.0878448364,""18"":9.952763684,""19"":18.8241916741,""20"":23.5236318446,""21"":8.4627610854,""22"":19.3751020407,""23"":9.9872495783,""24"":6.5372798391,""25"":6.7044082244,""26"":20.9840327198,""27"":12.3730366627,""28"":46.3980379166,""29"":31.3404788245,""30"":6.0649510624,""31"":38.3597820963,""32"":21.4667405053,""33"":29.4908761973,""34"":11.9427128385,""35"":27.6882091049,""36"":16.1945953384,""37"":9.5763116431,""38"":10.7154904156,""39"":7.1744523468,""40"":17.5330148982,""41"":18.9523872632,""42"":10.8265196258,""43"":9.9010338779,""44"":7.631956538,""45"":14.3505440824,""46"":8.090263,""47"":11.2939732942,""48"":12.3750292482,""49"":11.5086114882,""50"":12.7617314301,""51"":8.552674845,""52"":9.9004436433,""53"":6.3399875709,""54"":9.9324735547,""55"":9.0069670543,""56"":9.4172019731,""57"":6.0529680448,""58"":5.9902399388,""59"":7.5841431296,""60"":9.7649851487,""61"":9.6706619843,""62"":11.5470151538,""63"":10.5288162408,""64"":6.7270003465,""65"":9.6462560347,""66"":8.2636321969,""67"":6.5451547488,""68"":7.1113891602,""69"":9.9667522531,""70"":8.358776685,""71"":7.6966458881,""72"":8.9277687537,""73"":6.1453059688,""74"":6.1136021739,""75"":6.1185184779,""76"":6.8758900289,""77"":8.4868539563,""78"":6.3654528699,""79"":6.5795148899,""80"":6.1563719168,""81"":6.2313718086,""82"":6.3305705428,""83"":6.6297198998,""84"":6.6001374637,""85"":6.6066996668,""86"":6.0806185438,""87"":6.5118548183,""88"":6.4697987953,""89"":6.573937615},""count"":{""0"":354,""1"":236,""2"":184,""3"":180,""4"":176,""5"":148,""6"":144,""7"":136,""8"":132,""9"":116,""10"":114,""11"":114,""12"":112,""13"":108,""14"":94,""15"":90,""16"":74,""17"":74,""18"":72,""19"":68,""20"":68,""21"":66,""22"":66,""23"":58,""24"":56,""25"":56,""26"":56,""27"":56,""28"":52,""29"":52,""30"":50,""31"":50,""32"":48,""33"":48,""34"":44,""35"":44,""36"":40,""37"":38,""38"":36,""39"":32,""40"":32,""41"":32,""42"":30,""43"":28,""44"":26,""45"":26,""46"":24,""47"":22,""48"":22,""49"":20,""50"":20,""51"":20,""52"":18,""53"":18,""54"":18,""55"":18,""56"":18,""57"":16,""58"":16,""59"":16,""60"":16,""61"":16,""62"":14,""63"":14,""64"":14,""65"":14,""66"":14,""67"":12,""68"":12,""69"":12,""70"":12,""71"":12,""72"":12,""73"":12,""74"":12,""75"":12,""76"":12,""77"":10,""78"":10,""79"":10,""80"":10,""81"":10,""82"":10,""83"":8,""84"":8,""85"":8,""86"":8,""87"":8,""88"":8,""89"":8},""sigma_nor"":{""0"":2.7635800721,""1"":2.3137770569,""2"":1.9356364408,""3"":1.9497526715,""4"":2.4330845526,""5"":2.0699886859,""6"":1.8791980792,""7"":2.2591956296,""8"":1.7357393221,""9"":1.5916396687,""10"":1.5542292972,""11"":1.7801646197,""12"":2.084861917,""13"":1.8614239057,""14"":2.2589927274,""15"":2.1383269757,""16"":1.6474913743,""17"":4.582661119,""18"":2.076406901,""19"":3.1061522888,""20"":3.6373782021,""21"":1.9469105618,""22"":3.1967765261,""23"":2.1848811789,""24"":1.7780164003,""25"":1.7985795005,""26"":3.5555123414,""27"":2.496034778,""28"":6.8649793849,""29"":4.9524323252,""30"":1.7539156518,""31"":5.925000678,""32"":3.79033447,""33"":4.8447870178,""34"":2.5944479936,""35"":4.7405453798,""36"":3.2595380602,""37"":2.3480751296,""38"":2.5452901485,""39"":2.0673589218,""40"":3.6740526946,""41"":3.8942084091,""42"":2.6738429101,""43"":2.5657617584,""44"":2.226799416,""45"":3.3556861041,""46"":2.3404869814,""47"":2.9528209363,""48"":3.1459869987,""49"":3.0557356029,""50"":3.2873527575,""51"":2.5093827665,""52"":2.8185641509,""53"":2.1361698406,""54"":2.8247029795,""55"":2.6473211056,""56"":2.725946419,""57"":2.1180685146,""58"":2.1055673495,""59"":2.4232183722,""60"":2.857841191,""61"":2.8390434059,""62"":3.3004908734,""63"":3.088819098,""64"":2.2984655534,""65"":2.9053450407,""66"":2.6179135392,""67"":2.3091579374,""68"":2.4323979591,""69"":3.0538632087,""70"":2.703889876,""71"":2.559778158,""72"":2.8277300975,""73"":2.2221314844,""74"":2.2152312037,""75"":2.2163012295,""76"":2.3811419466,""77"":2.8054722207,""78"":2.3200847358,""79"":2.3690632275,""80"":2.2722459378,""81"":2.289406299,""82"":2.3121034798,""83"":2.4350212566,""84"":2.4278743739,""85"":2.4294597503,""86"":2.3023627094,""87"":2.4065459846,""88"":2.3963855818,""89"":2.4215446975},""vocab_index"":{""0"":0,""1"":1,""2"":2,""3"":3,""4"":4,""5"":5,""6"":6,""7"":7,""8"":8,""9"":12,""10"":13,""11"":14,""12"":15,""13"":16,""14"":17,""15"":18,""16"":22,""17"":23,""18"":24,""19"":25,""20"":26,""21"":29,""22"":30,""23"":33,""24"":36,""25"":38,""26"":39,""27"":40,""28"":41,""29"":42,""30"":43,""31"":44,""32"":46,""33"":47,""34"":55,""35"":56,""36"":61,""37"":65,""38"":72,""39"":75,""40"":76,""41"":77,""42"":80,""43"":85,""44"":94,""45"":95,""46"":97,""47"":115,""48"":116,""49"":136,""50"":138,""51"":140,""52"":154,""53"":155,""54"":159,""55"":160,""56"":161,""57"":174,""58"":176,""59"":182,""60"":183,""61"":184,""62"":215,""63"":216,""64"":217,""65"":218,""66"":219,""67"":228,""68"":252,""69"":261,""70"":263,""71"":264,""72"":266,""73"":269,""74"":270,""75"":271,""76"":272,""77"":316,""78"":318,""79"":319,""80"":320,""81"":321,""82"":325,""83"":357,""84"":377,""85"":389,""86"":401,""87"":405,""88"":407,""89"":409},""word"":{""0"":""entities"",""1"":""bundles"",""2"":""biset"",""3"":""e"",""4"":""entity"",""5"":""coordinated"",""6"":""users"",""7"":""edges"",""8"":""relationships"",""9"":""bicluster"",""10"":""visual"",""11"":""relationship"",""12"":""list"",""13"":""edge"",""14"":""relations"",""15"":""bundle"",""16"":""related"",""17"":""m"",""18"":""level"",""19"":""f"",""20"":""visualization"",""21"":""c"",""22"":""a"",""23"":""bundling"",""24"":""figure"",""25"":""layout"",""26"":""48"",""27"":""matrix"",""28"":""cid"",""29"":""j"",""30"":""group"",""31"":""sarah"",""32"":""computer"",""33"":""ieee"",""34"":""associated"",""35"":""graphics"",""36"":""h"",""37"":""selected"",""38"":""highlighted"",""39"":""positions"",""40"":""pages"",""41"":""transactions"",""42"":""8"",""43"":""r"",""44"":""state"",""45"":""2014"",""46"":""highlighting"",""47"":""p"",""48"":""n"",""49"":""nodes"",""50"":""centric"",""51"":""shown"",""52"":""diagram"",""53"":""certain"",""54"":""l"",""55"":""acm"",""56"":""2010"",""57"":""levels"",""58"":""contour"",""59"":""r1"",""60"":""t"",""61"":""streit"",""62"":""mouseover"",""63"":""\ufb01nds"",""64"":""proceedings"",""65"":""2009"",""66"":""lex"",""67"":""complex"",""68"":""2d"",""69"":""mode"",""70"":""t3"",""71"":""t7"",""72"":""galab"",""73"":""conference"",""74"":""computing"",""75"":""systems"",""76"":""schmalstieg"",""77"":""end"",""78"":""quickly"",""79"":""reports"",""80"":""ramazi"",""81"":""goba"",""82"":""forum"",""83"":""threshold"",""84"":""labels"",""85"":""subspaces"",""86"":""modes"",""87"":""length"",""88"":""normal"",""89"":""foreach""},""vector"":{""0"":""[ 0.2715517   0.28920713  2.8187559  -3.7337232   1.6826204   4.931976\n -1.4003568   0.03738664  0.22955757 -6.955579  ]"",""1"":""[ 0.80242115  0.70458025  2.3967676  -3.1651895   0.7845945   4.733215\n -1.4111274   0.3111022   0.05570586 -6.310121  ]"",""2"":""[ 0.49689376  1.7872763   1.1226325  -2.0707314   2.2511811   4.7416906\n  0.36434704  1.6704355  -0.6601503  -4.018504  ]"",""3"":""[ 1.6238558   1.5120997   1.4782109  -2.8843062   3.7110255   4.709504\n -0.3170294   0.77268326 -0.24490526 -4.1833467 ]"",""4"":""[ 0.42156276  0.03992872  3.0177464  -3.4428332   1.5491354   4.9668503\n -1.1414506   0.03355946 -0.1428878  -6.839796  ]"",""5"":""[ 1.6805079  0.4317019  3.0488622 -2.4513364  0.5569045  4.7284904\n -1.1051515  0.3032543 -0.7896352 -6.129327 ]"",""6"":""[ 0.4007653   0.72103566  2.4935546  -4.042873    1.9125135   4.988441\n -1.34059     0.04827933  0.27707788 -6.6911783 ]"",""7"":""[ 1.1556163   0.67599154  1.971331   -3.5158837   1.9228754   5.3049555\n -0.5592205  -0.14130145  0.11183666 -5.8526955 ]"",""8"":""[ 0.2956143   0.31110623  2.6788614  -3.7406116   1.2897547   5.0156474\n -1.396748    0.10646898  0.04752784 -6.998066  ]"",""9"":""[ 0.6506924   1.3311032   1.8361458  -3.481461    2.1007154   5.0039287\n -0.6745055   0.6765208   0.16183218 -5.490611  ]"",""10"":""[ 1.5183531   1.4056718   2.1733108  -3.2851906   1.6626836   5.0569086\n -0.65058404  0.42048684  0.07596406 -5.5661845 ]"",""11"":""[ 0.4814152   0.02560194  2.7765834  -3.5664523   1.1722686   5.0624\n -1.2306569  -0.04432211 -0.3270543  -6.943601  ]"",""12"":""[ 0.96788627  0.02574772  2.9383516  -2.9224632   1.3027008   4.9781823\n -0.88158333  0.0418191  -0.46379742 -6.398006  ]"",""13"":""[ 1.3479708   0.46174142  2.23897    -3.3308318   1.7540187   5.2769933\n -0.5124394  -0.22865713 -0.08973189 -5.8592186 ]"",""14"":""[ 3.5836601e-01  2.7659974e-01  2.8233118e+00 -3.8967071e+00\n  1.4018433e+00  4.9848027e+00 -1.4455590e+00 -2.9926375e-03\n -2.3286700e-01 -6.9686546e+00]"",""15"":""[ 1.0101297   0.5679834   2.5526037  -2.9505053   0.66540045  4.7333384\n -1.3035063   0.25090072 -0.10032328 -6.279915  ]"",""16"":""[ 1.7649623   0.44270766  3.3055065  -2.5946207   0.68632895  4.6540604\n -1.1232316   0.40674913 -0.5316683  -6.060162  ]"",""17"":""[ 1.4355446   1.3444226   1.497124   -2.9642258   3.537194    4.879721\n -0.48565832  0.63767564 -0.17354093 -4.41874   ]"",""18"":""[ 0.9391569   0.0903504   3.0500998  -3.7892272   1.4483002   5.157416\n -0.9346446  -0.2985234   0.12172834 -6.485583  ]"",""19"":""[ 1.6710052   1.2781335   1.2956111  -2.978004    3.6587946   5.0782776\n -0.47363117  0.8566097  -0.24423455 -4.327731  ]"",""20"":""[ 1.1766365   1.3938063   1.9760528  -3.4785833   1.6666476   5.1360626\n -0.69255483  0.39399877  0.26324823 -5.79213   ]"",""21"":""[ 1.9624586   1.4260817   1.4861225  -2.8648884   3.3590307   4.9718294\n -0.38066864  0.8746654  -0.10177016 -4.288104  ]"",""22"":""[ 1.4803908   0.33451965  3.1699784  -2.760008    1.0296922   4.868797\n -0.9243398   0.37512034 -0.36216143 -6.1322045 ]"",""23"":""[ 1.1292866   0.5800375   2.6653218  -2.8998675   0.603191    4.693948\n -1.3882437   0.27100492 -0.2744829  -6.27848   ]"",""24"":""[ 0.6989589  -0.03875631  2.8056412  -3.1913433   1.262327    5.136882\n -0.81814814 -0.04027171 -0.24609165 -6.6720915 ]"",""25"":""[ 1.4430985   1.2547029   2.3578074  -3.6887407   1.6230171   5.161291\n -0.7663384   0.10243358  0.2288581  -5.9405    ]"",""26"":""[ 1.5718652   0.18557797  2.8372228  -2.7069693   1.6563007   4.947401\n -0.63581985  0.18023919 -0.69926536 -5.6065803 ]"",""27"":""[ 0.46036568  0.802258    2.3618414  -3.308175    1.5892538   4.972727\n -0.8396319   0.55377257  0.20104517 -6.151953  ]"",""28"":""[ 1.3113261e+00  1.6500072e+00  1.3635112e+00 -2.6912456e+00\n  3.2795694e+00  4.8388281e+00 -2.4040985e-01  1.1212130e+00\n -2.6272999e-03 -4.2148986e+00]"",""29"":""[ 1.2428178   1.5325992   1.2635365  -2.8125958   3.5979028   4.8507667\n -0.3772252   0.89724094 -0.23063123 -4.206434  ]"",""30"":""[ 0.5819715   0.17273618  2.9359314  -3.2921705   1.5332425   4.9497504\n -0.999218    0.16930771 -0.26750523 -6.561121  ]"",""31"":""[ 1.0572829   1.6139585   0.9969312  -2.74628     3.5602598   4.9505\n -0.26653883  1.1820613  -0.2705599  -4.063691  ]"",""32"":""[ 1.0163659   1.260697    2.3288705  -3.7318711   1.7798861   5.047794\n -0.855335    0.33957204  0.2509133  -5.9262404 ]"",""33"":""[ 0.8804503   1.592433    0.9332915  -2.7933795   3.3383071   4.998229\n -0.22911212  1.3421766  -0.2545317  -4.132097  ]"",""34"":""[ 1.7679578   0.42673582  3.092242   -2.4843297   0.71486425  4.736851\n -0.9528321   0.2622708  -0.66474706 -5.9808197 ]"",""35"":""[ 1.3462504   1.3640572   2.1816325  -3.671096    1.8052108   5.124009\n -0.7419553   0.2743696   0.23858695 -5.7428255 ]"",""36"":""[ 1.4577975  1.4643939  1.3796545 -2.75594    3.6212742  4.899283\n -0.5314275  0.803241  -0.2427698 -4.2448554]"",""37"":""[ 1.6198379   0.21652079  2.9731472  -2.334605    0.7942458   4.830335\n -0.9508853   0.18575032 -1.0136216  -6.037821  ]"",""38"":""[ 1.5945956   0.38437647  2.9204175  -2.5088267   0.530941    4.7577314\n -1.2200423   0.1601838  -1.0328935  -6.210123  ]"",""39"":""[ 0.5915496   0.3101591   2.800776   -3.9378028   1.2637147   5.131653\n -1.2036533  -0.09399761  0.23412062 -6.787154  ]"",""40"":""[ 0.61731106  0.8747717   2.426882   -4.060336    1.8789883   4.997545\n -1.2339708   0.08521648  0.1620492  -6.361541  ]"",""41"":""[ 0.28136626  0.44574803  2.7421296  -4.0058675   1.6402076   4.8940654\n -1.5549254   0.01631008  0.06245457 -6.8640575 ]"",""42"":""[ 1.5076708   0.16540293  2.71584    -2.8089035   1.8129467   5.0304317\n -0.5215116   0.12691604 -0.6365516  -5.6035557 ]"",""43"":""[ 1.5367544   1.4299136   1.5799551  -2.6883273   3.3714855   4.8774204\n -0.5991257   0.69606805 -0.2072083  -4.3911676 ]"",""44"":""[ 0.77211475  0.16101749  3.1506262  -3.4584951   1.4510018   4.8917117\n -1.3157488  -0.0481081  -0.17887378 -6.71041   ]"",""45"":""[ 0.8551916  -0.25430605  2.8335285  -3.4476304   1.6805545   5.1623616\n -0.5403026  -0.3332367  -0.6276112  -6.3163896 ]"",""46"":""[ 1.5112711   0.3503109   2.8445287  -2.5673265   0.63245714  4.8513427\n -1.1056898   0.10658289 -0.95744765 -6.231098  ]"",""47"":""[ 1.4933245  1.3138947  1.5685515 -2.9828718  3.1784072  4.9917526\n -0.569814   0.7893635 -0.0319187 -4.6319795]"",""48"":""[ 1.3177161   1.2967213   1.4426354  -3.001195    3.3787606   4.928642\n -0.5288045   0.67229694 -0.25240368 -4.5229144 ]"",""49"":""[ 0.5547547   0.95736766  1.9344298  -3.7307534   1.8928539   5.1061893\n -0.9043884   0.2846471   0.30727887 -6.01289   ]"",""50"":""[ 0.54757184  0.86478037  2.5643225  -3.5733871   1.3311695   4.9559035\n -1.1901762   0.41707626  0.2708367  -6.5717134 ]"",""51"":""[ 1.7055705   0.30617473  2.9650185  -2.379951    0.72959     4.7744455\n -0.981235    0.14786635 -0.99120975 -5.9823856 ]"",""52"":""[ 1.2541938   1.1704538   2.1080327  -3.4291487   1.4915105   5.2064776\n -0.69732654  0.20533094  0.22389694 -6.0551424 ]"",""53"":""[ 1.6499107   0.3026544   3.1911283  -2.5962844   0.98715955  4.8187857\n -0.90187734  0.33380106 -0.52863204 -5.9493146 ]"",""54"":""[ 1.5567092   1.3747971   1.6036522  -2.8252773   3.4768224   4.819533\n -0.48808327  0.6731638  -0.20608072 -4.381811  ]"",""55"":""[ 0.96219015  1.6529864   1.0399473  -2.779422    3.2407253   4.9742494\n -0.17279182  1.3598677  -0.09074703 -4.200974  ]"",""56"":""[ 0.8727937  -0.24309002  2.8512626  -3.4409142   1.6618575   5.167453\n -0.554856   -0.3262798  -0.59600365 -6.329321  ]"",""57"":""[ 0.8196195   0.27401495  2.944511   -3.9125059   1.3926681   5.126954\n -1.080917   -0.21356888  0.23840006 -6.5726457 ]"",""58"":""[ 1.441258    0.8633411   2.2039516  -3.425802    1.7057916   5.254946\n -0.5610446  -0.07915462  0.05336454 -5.856584  ]"",""59"":""[ 1.2216873   1.6955566   1.1404154  -2.5774186   3.3219025   5.076538\n -0.24094346  1.3008139   0.11013453 -4.1350217 ]"",""60"":""[ 1.6779562e+00  1.4220523e+00  1.5551580e+00 -2.8355496e+00\n  3.5063407e+00  4.8878636e+00 -3.0086994e-01  7.8320408e-01\n -1.3628972e-03 -4.2698226e+00]"",""61"":""[ 0.4095183  1.6703193  1.1959895 -2.0726995  2.0579202  4.782097\n  0.3346118  1.6571662 -0.6210749 -4.15726  ]"",""62"":""[ 1.4737877   1.525501    1.952954   -3.2808158   1.8744093   5.0910816\n -0.59645647  0.5053681   0.14235103 -5.4530315 ]"",""63"":""[ 0.48884636  1.7590114   0.9576108  -2.2509677   2.3592274   4.7998934\n  0.18320306  1.6898364  -0.6493537  -3.990061  ]"",""64"":""[ 0.6097824   0.407059    2.8969784  -4.0981355   1.7383806   4.884297\n -1.3875332  -0.12180737 -0.6064051  -6.506719  ]"",""65"":""[ 0.92034626 -0.26049465  2.9265432  -3.4462957   1.6039228   5.1894217\n -0.63241845 -0.3569036  -0.5239442  -6.4142113 ]"",""66"":""[ 0.96216136  1.7371156   0.8565598  -2.7950583   3.4432547   5.1024733\n -0.15123348  1.4454103  -0.00921237 -4.131865  ]"",""67"":""[ 1.5714648   0.4822428   3.217579   -2.6976757   0.8197794   4.796224\n -0.98637044  0.47758824 -0.35221273 -6.195631  ]"",""68"":""[ 1.6981181   1.3325812   1.6411209  -2.9881186   3.017724    5.010005\n -0.43423587  0.7717321   0.01944635 -4.6169996 ]"",""69"":""[ 0.8888406   0.6391601   2.8062057  -3.7943623   1.5283587   5.066436\n -0.95154405  0.04898138  0.29557687 -6.249938  ]"",""70"":""[ 1.4232528   1.6875063   1.2780694  -2.5792737   3.3132644   5.1320457\n -0.32586488  1.1966484   0.27039838 -4.215979  ]"",""71"":""[ 1.2515907   1.6123376   1.2450514  -2.6333532   3.18567     5.0189514\n -0.19652139  1.2385911   0.07427461 -4.235978  ]"",""72"":""[ 0.43910676  1.6013339   1.0165954  -2.076935    2.3616385   4.8232136\n  0.34653768  1.8271563  -0.5286889  -3.9523005 ]"",""73"":""[ 0.6472195   0.3550011   2.8920927  -3.9583588   1.8179456   4.9120903\n -1.22504    -0.09822644 -0.6962123  -6.430758  ]"",""74"":""[ 0.79274404  1.3130876   2.0871694  -3.6039293   1.9569126   5.0048294\n -0.7845364   0.5415895   0.19473651 -5.7166004 ]"",""75"":""[ 0.40013015  0.6835474   2.6530674  -3.8055556   1.4667854   4.93351\n -1.3583624   0.23344152  0.35251272 -6.754393  ]"",""76"":""[ 0.39004913  1.6166313   1.0433083  -2.1834075   2.2220569   4.8650503\n  0.2361206   1.7198899  -0.5508917  -4.1050315 ]"",""77"":""[ 1.4179294   0.18410054  2.6181548  -3.0484018   1.5594772   5.1205316\n -0.6356866  -0.2109269  -0.48241553 -5.949436  ]"",""78"":""[ 1.4429473   0.16224508  3.0967274  -2.7418354   1.2638754   4.9482937\n -0.80694556  0.31056035 -0.55192256 -6.0302057 ]"",""79"":""[ 0.6880133   0.52805835  2.8242364  -4.005178    1.5347581   4.8687325\n -1.4728618  -0.04327141 -0.42672756 -6.4989114 ]"",""80"":""[ 0.5360202   1.6700923   0.99813974 -2.2278247   2.514106    4.8579574\n  0.20569438  1.6501411  -0.51323605 -4.0263624 ]"",""81"":""[ 0.48590657  1.6542326   1.0192376  -2.105194    2.4012308   4.8118396\n  0.32651326  1.782566   -0.5439753  -3.9511967 ]"",""82"":""[ 0.62691575  0.43382552  2.8496184  -4.0351043   1.9364678   4.9361343\n -1.1677617  -0.1020269  -0.47494194 -6.404985  ]"",""83"":""[ 1.0810071e+00  8.8244699e-02  2.9516127e+00 -3.5280502e+00\n  1.3441734e+00  5.1769595e+00 -7.8120184e-01 -2.6381516e-01\n -2.1113951e-03 -6.3676424e+00]"",""84"":""[ 0.49756446  0.2792521   2.5945039  -3.626061    1.5663131   5.139052\n -1.1938258  -0.05384256  0.22523497 -6.9455204 ]"",""85"":""[ 0.39749014  0.86855793  2.091077   -3.4866574   1.6429294   5.0123878\n -0.913551    0.48076704  0.30132267 -6.095189  ]"",""86"":""[ 0.5730737   0.63934153  2.6452866  -3.978626    1.5673598   5.043054\n -1.2151661   0.04163998  0.3465701  -6.5542226 ]"",""87"":""[ 1.4322139   0.4094968   2.5938241  -3.2498868   1.7089045   5.098231\n -0.7045174  -0.15723005 -0.2633295  -5.8484406 ]"",""88"":""[ 1.6129866   0.37096044  3.115326   -2.8355658   1.1489483   4.881373\n -0.83682585  0.21745816 -0.40039185 -5.9021115 ]"",""89"":""[ 1.1363683   1.7090108   1.0632071  -2.8505015   3.3611941   5.0908556\n -0.21325473  1.3122358   0.15553202 -4.2860966 ]""},""topic"":{""0"":3,""1"":-1,""2"":0,""3"":2,""4"":3,""5"":5,""6"":3,""7"":-1,""8"":3,""9"":-1,""10"":4,""11"":3,""12"":-1,""13"":4,""14"":3,""15"":-1,""16"":5,""17"":2,""18"":3,""19"":-1,""20"":4,""21"":-1,""22"":5,""23"":-1,""24"":3,""25"":4,""26"":5,""27"":-1,""28"":1,""29"":1,""30"":3,""31"":1,""32"":4,""33"":-1,""34"":5,""35"":4,""36"":2,""37"":5,""38"":5,""39"":3,""40"":3,""41"":3,""42"":-1,""43"":2,""44"":3,""45"":-1,""46"":5,""47"":2,""48"":2,""49"":-1,""50"":3,""51"":5,""52"":4,""53"":5,""54"":2,""55"":1,""56"":-1,""57"":3,""58"":4,""59"":1,""60"":2,""61"":0,""62"":-1,""63"":0,""64"":3,""65"":3,""66"":1,""67"":5,""68"":-1,""69"":3,""70"":1,""71"":1,""72"":0,""73"":-1,""74"":4,""75"":3,""76"":0,""77"":4,""78"":5,""79"":3,""80"":0,""81"":0,""82"":-1,""83"":3,""84"":3,""85"":3,""86"":3,""87"":4,""88"":5,""89"":1},""exemplar"":{""0"":""*"",""1"":null,""2"":""*"",""3"":""*"",""4"":null,""5"":""*"",""6"":null,""7"":null,""8"":""*"",""9"":null,""10"":null,""11"":null,""12"":null,""13"":null,""14"":""*"",""15"":null,""16"":""*"",""17"":""*"",""18"":null,""19"":null,""20"":""*"",""21"":null,""22"":""*"",""23"":null,""24"":null,""25"":""*"",""26"":null,""27"":null,""28"":null,""29"":null,""30"":null,""31"":""*"",""32"":""*"",""33"":null,""34"":""*"",""35"":""*"",""36"":""*"",""37"":null,""38"":null,""39"":""*"",""40"":null,""41"":""*"",""42"":null,""43"":""*"",""44"":null,""45"":null,""46"":""*"",""47"":null,""48"":""*"",""49"":null,""50"":null,""51"":""*"",""52"":""*"",""53"":""*"",""54"":""*"",""55"":""*"",""56"":null,""57"":null,""58"":""*"",""59"":""*"",""60"":""*"",""61"":""*"",""62"":null,""63"":""*"",""64"":null,""65"":null,""66"":""*"",""67"":null,""68"":null,""69"":null,""70"":""*"",""71"":""*"",""72"":""*"",""73"":null,""74"":""*"",""75"":""*"",""76"":""*"",""77"":null,""78"":null,""79"":null,""80"":""*"",""81"":""*"",""82"":null,""83"":null,""84"":null,""85"":null,""86"":""*"",""87"":null,""88"":null,""89"":""*""},""word*"":{""0"":""entities*"",""1"":""bundles"",""2"":""biset*"",""3"":""e*"",""4"":""entity"",""5"":""coordinated*"",""6"":""users"",""7"":""edges"",""8"":""relationships*"",""9"":""bicluster"",""10"":""visual"",""11"":""relationship"",""12"":""list"",""13"":""edge"",""14"":""relations*"",""15"":""bundle"",""16"":""related*"",""17"":""m*"",""18"":""level"",""19"":""f"",""20"":""visualization*"",""21"":""c"",""22"":""a*"",""23"":""bundling"",""24"":""figure"",""25"":""layout*"",""26"":""48"",""27"":""matrix"",""28"":""cid"",""29"":""j"",""30"":""group"",""31"":""sarah*"",""32"":""computer*"",""33"":""ieee"",""34"":""associated*"",""35"":""graphics*"",""36"":""h*"",""37"":""selected"",""38"":""highlighted"",""39"":""positions*"",""40"":""pages"",""41"":""transactions*"",""42"":""8"",""43"":""r*"",""44"":""state"",""45"":""2014"",""46"":""highlighting*"",""47"":""p"",""48"":""n*"",""49"":""nodes"",""50"":""centric"",""51"":""shown*"",""52"":""diagram*"",""53"":""certain*"",""54"":""l*"",""55"":""acm*"",""56"":""2010"",""57"":""levels"",""58"":""contour*"",""59"":""r1*"",""60"":""t*"",""61"":""streit*"",""62"":""mouseover"",""63"":""\ufb01nds*"",""64"":""proceedings"",""65"":""2009"",""66"":""lex*"",""67"":""complex"",""68"":""2d"",""69"":""mode"",""70"":""t3*"",""71"":""t7*"",""72"":""galab*"",""73"":""conference"",""74"":""computing*"",""75"":""systems*"",""76"":""schmalstieg*"",""77"":""end"",""78"":""quickly"",""79"":""reports"",""80"":""ramazi*"",""81"":""goba*"",""82"":""forum"",""83"":""threshold"",""84"":""labels"",""85"":""subspaces"",""86"":""modes*"",""87"":""length"",""88"":""normal"",""89"":""foreach*""},""pos"":{""0"":1,""1"":1,""2"":1,""3"":1,""4"":2,""5"":1,""6"":3,""7"":2,""8"":4,""9"":3,""10"":1,""11"":5,""12"":4,""13"":2,""14"":6,""15"":5,""16"":2,""17"":2,""18"":7,""19"":6,""20"":3,""21"":7,""22"":3,""23"":8,""24"":8,""25"":4,""26"":4,""27"":9,""28"":1,""29"":2,""30"":9,""31"":3,""32"":5,""33"":10,""34"":5,""35"":6,""36"":3,""37"":6,""38"":7,""39"":10,""40"":11,""41"":12,""42"":11,""43"":4,""44"":13,""45"":12,""46"":8,""47"":5,""48"":6,""49"":13,""50"":14,""51"":9,""52"":7,""53"":10,""54"":7,""55"":4,""56"":14,""57"":15,""58"":8,""59"":5,""60"":8,""61"":2,""62"":15,""63"":3,""64"":16,""65"":17,""66"":6,""67"":11,""68"":16,""69"":18,""70"":7,""71"":8,""72"":4,""73"":17,""74"":9,""75"":19,""76"":5,""77"":10,""78"":12,""79"":20,""80"":6,""81"":7,""82"":18,""83"":21,""84"":22,""85"":23,""86"":24,""87"":11,""88"":13,""89"":9},""x2D"":{""0"":14.2228136063,""1"":10.4589357376,""2"":-8.3186244965,""3"":0.3232757449,""4"":13.1858243942,""5"":9.1147899628,""6"":13.9270782471,""7"":10.7180366516,""8"":14.2558107376,""9"":10.787566185,""10"":10.382938385,""11"":13.0422554016,""12"":11.8313732147,""13"":10.5439682007,""14"":13.9880371094,""15"":10.0819606781,""16"":9.1062660217,""17"":0.6419556737,""18"":12.9346179962,""19"":0.2571178377,""20"":10.5500230789,""21"":0.2875364423,""22"":9.441649437,""23"":9.7302350998,""24"":12.3802700043,""25"":10.7323503494,""26"":10.0526885986,""27"":11.6686668396,""28"":-0.8804935813,""29"":-0.1578762084,""30"":12.7099456787,""31"":-1.1552113295,""32"":10.9533033371,""33"":-1.3271366358,""34"":9.0156784058,""35"":10.5813302994,""36"":0.5630388856,""37"":8.9551010132,""38"":9.0959367752,""39"":13.6497173309,""40"":13.6196622849,""41"":14.2009963989,""42"":10.2928104401,""43"":0.4526313543,""44"":12.9910316467,""45"":12.2250928879,""46"":9.1877450943,""47"":0.9739140868,""48"":0.8784457445,""49"":11.39108181,""50"":13.8215351105,""51"":8.8423261642,""52"":10.4924583435,""53"":9.2142744064,""54"":0.665546298,""55"":-1.5662530661,""56"":12.1326789856,""57"":13.2497081757,""58"":10.4976596832,""59"":-1.2513198853,""60"":0.5008806586,""61"":-8.4280481339,""62"":10.3254232407,""63"":-8.1813278198,""64"":13.9314670563,""65"":12.2185773849,""66"":-1.5149754286,""67"":9.4779424667,""68"":0.5515127778,""69"":13.3233547211,""70"":-1.0436441898,""71"":-1.1434183121,""72"":-8.0622119904,""73"":13.5399188995,""74"":10.9385442734,""75"":14.1669502258,""76"":-8.2516517639,""77"":10.7348976135,""78"":9.7091941833,""79"":13.5956764221,""80"":-8.1980333328,""81"":-7.9723863602,""82"":13.6976680756,""83"":12.5586252213,""84"":14.0675573349,""85"":11.5270528793,""86"":13.7826881409,""87"":10.6720685959,""88"":9.6400251389,""89"":-1.2976617813},""y2D"":{""0"":5.8298420906,""1"":7.7646884918,""2"":1.2867087126,""3"":-3.7124609947,""4"":6.6915521622,""5"":7.9351553917,""6"":5.3801908493,""7"":5.155148983,""8"":5.9958405495,""9"":4.145922184,""10"":4.5391721725,""11"":6.5956196785,""12"":6.6371984482,""13"":5.5450763702,""14"":6.0882091522,""15"":7.7841496468,""16"":7.6413984299,""17"":-3.2211613655,""18"":5.8519964218,""19"":-3.5209772587,""20"":4.4121079445,""21"":-3.1087255478,""22"":7.2896432877,""23"":7.895406723,""24"":6.5037388802,""25"":4.682905674,""26"":6.6826686859,""27"":4.4781947136,""28"":-3.5442633629,""29"":-3.4945049286,""30"":6.6244063377,""31"":-3.3377385139,""32"":4.408850193,""33"":-3.2912716866,""34"":7.8147187233,""35"":4.4925966263,""36"":-3.4407584667,""37"":8.0851144791,""38"":8.2270584106,""39"":5.8904790878,""40"":5.000058651,""41"":5.9500007629,""42"":6.4999256134,""43"":-3.3841905594,""44"":6.4585242271,""45"":6.0073103905,""46"":8.0809011459,""47"":-3.4793820381,""48"":-3.3416554928,""49"":4.3304829597,""50"":5.2179045677,""51"":8.1812934875,""52"":4.8033013344,""53"":7.4379148483,""54"":-3.671841383,""55"":-3.4291059971,""56"":6.1684336662,""57"":5.7893686295,""58"":5.0509109497,""59"":-3.7309789658,""60"":-3.7866132259,""61"":1.3996298313,""62"":4.2932829857,""63"":1.1490530968,""64"":6.6105484962,""65"":6.2633905411,""66"":-3.3261113167,""67"":7.5903468132,""68"":-3.3070631027,""69"":5.2970423698,""70"":-3.7571129799,""71"":-3.6680963039,""72"":1.0290901661,""73"":6.7010760307,""74"":4.2102174759,""75"":5.5215673447,""76"":1.2193346024,""77"":6.2078170776,""78"":7.1101007462,""79"":6.3264932632,""80"":1.1658492088,""81"":0.9357142448,""82"":6.4283471107,""83"":5.9780831337,""84"":5.8297567368,""85"":4.4360785484,""86"":5.4589576721,""87"":5.8744063377,""88"":7.1808328629,""89"":-3.6058404446}}",False,False,False,http://ieeexplore.ieee.org/document/7192715/,,BiSet: Semantic Edge Bundling with Biclusters for Sensemaking,9BL2E5F8,False,False
L239LNLV,NPGU7FZK,"WeSearch: Supporting Collaborative Search and 

Sensemaking on a Tabletop Display 

Daniel Wigdor 

Microsoft Surface 

Redmond, WA, USA 

Meredith Ringel Morris 

Jarrod Lombardo 

Microsoft Research 
Redmond, WA, USA 
merrie@microsoft.com 

Averro 

Bellevue, WA, USA 

jarrod@network-science.net 

dwigdor@microsoft.com 

 

ABSTRACT 
Groups of users often have shared information needs  – for 
example,  business  colleagues  need  to  conduct  research 
relating to joint projects and students must work together on 
group  homework  assignments.  In  this  paper,  we  introduce 
WeSearch, a  collaborative  Web  search  system  designed  to 
leverage  the  benefits  of  tabletop  displays  for  face-to-face 
collaboration  and  organization  tasks.  We  describe  the 
design of WeSearch and explain the interactions it affords. 
We  then  describe  an  evaluation  in  which  eleven  groups 
used  WeSearch  to  conduct  real  collaborative  search  tasks. 
Based on our study‟s findings, we analyze the effectiveness 
of the features introduced by WeSearch. 

Author Keywords 
Interactive  tables,  surface  computing,  tabletop  computing, 
collaborative search, Web search, sensemaking. 

ACM Classification Keywords 
H5.3.  Information  interfaces  and  presentation  (e.g.,  HCI): 
Group  and  Organization  Interfaces:  computer-supported 
cooperative work.  

INTRODUCTION 
Web search is often considered a solitary activity, but there 
are  many  situations  in  which  groups  of  people  share  an 
information need, and may benefit from the ability to search 
the  Web  collaboratively  in  both  education  [1,  15,  33]  and 
workplace [5, 9, 19] scenarios.  

Several  researchers  have  begun  to  introduce  technologies 
that  support  collaborative  search  tasks.  For  example, 
SearchTogether  [18]  is  a  browser  plug-in  that  facilitates 
remote  collaboration  on  Web  search.  Unlike  the  designers 
of  SearchTogether,  however,  our  focus  is  on  supporting 
collaborative search among co-located group members. For 
example, business colleagues may need to find information 
related  to  a  question  that  arises  during  the  course  of  a 
meeting; students working together in the library on a joint 
homework project may need to find materials to include in 
their  report;  and  family  members  gathered  in  their  home 

Permission  to  make  digital  or  hard  copies  of  all  or  part  of  this  work  for 
personal or classroom use is granted  without fee  provided  that  copies are 
not made or distributed for profit or commercial advantage and that copies 
bear this notice and the  full  citation on the  first  page. To copy  otherwise, 
or  republish,  to  post  on  servers  or  to  redistribute  to  lists,  requires  prior 
specific permission and/or a fee. 
CSCW 2010, February 6–10, 2010, Savannah, Georgia, USA. 
Copyright 2010 ACM  978-1-60558-795-0/10/02...$10.00. 
 

 

 

 

Figure 1. A group of students conducts a collaborative Web 

search using the WeSearch tabletop application. 

may  wish  to  explore  topics  such  as  researching  joint 
purchases,  planning  an  upcoming  vacation,  or  seeking 
medical information to assist a loved one.    

Proposed  systems  for  supporting  co-located  collaborative 
Web search generally provide each group member with her 
own  device,  sometimes  supplemented  by  a  shared  display. 
For  example,  CoSearch  [1]  provides  a  mobile  phone  for 
each  user,  plus  one  shared  PC  display  for  the  group. 
Cerchiamo  [24]  provides  a  dedicated  PC  for  each  of  two 
collaborators that shows role-specific content, plus a shared 
wall  display  providing  joint  information.  Maekawa  et  al. 
describe  a  system  [16]  which  divides  a  Web  page  into 
sections  and  puts  one  section  on  each  user‟s  personal 
mobile  device.  WebGlance  [22]  lets  a  group  browse  the 
Web together by providing an interface on each user‟s PDA 
that controls a browser shown on a large wall display.  

These  prior  systems‟  rationale  for  providing  each  group 
member  with  a  personal  device  is  to  enable  all  group 
members  to  participate  and  work  in  parallel.  This  is 
necessary  because  traditional  PCs  (and  many  large  wall 
displays) permit only a single mouse or keyboard to interact 
at  a  time,  which  can  result  in  frustration  for  the  group 
member  who  is  not  “driving”  the  input  devices  [1]. 
However,  providing  separate  devices  for  each  co-located 
group  member  has  some  drawbacks,  such  as  reduced 
awareness  [1],  which  may  be  particularly  problematic  for 
collaborative 
awareness 
information has been found to be valuable [18, 23].    

applications,  where 

search 

Multi-touch  tabletop  technologies  (e.g.,  [2,  7])  provide  a 
promising  platform  for  co-located  collaborative  search 
applications.  Such 
technologies  enable  simultaneous 

participation  by  all  group  members,  while  providing  a 
shared  display  to  facilitate  awareness.  Indeed,  groups 
already  gather  around  traditional  tables  in  many  of  the 
situations in which  the needs for collaborative search arise 
(in  business  meetings,  in  classrooms  and  libraries,  and  at 
home), making next-generation, interactive tables a logical 
venue  for  supporting  information-finding  tasks.  Tables‟ 
large  size  affords  spatially  organizing  content,  which  also 
makes them well-suited to search and sensemaking tasks.     

A  few  researchers  have  begun  to  explore  the  harmony 
between  tabletops  and  information-seeking  tasks,  although 
they  have  focused  on  specialized  domains.  TeamSearch 
[17]  provides  a  visual  query  language  to  support  tabletop 
search over a tagged image database. The Personal Digital 
Historian  [29]  also  supports  image  search,  by  filtering  a 
tagged  collection  based  on  who  is  shown  in  the  photo, 
where it was taken, or when it was taken. Físchlár-DT [31] 
enables  partners  to  collaboratively  explore  a  collection  of 
video  clips  on  a  tabletop  display,  and  Cambiera  [13] 
supports 
investigation  of  a  database  of  news  clips 
associated with the VAST visual analytics challenge.  

(and 

search 

In this paper, we introduce WeSearch, a system designed to 
support  collaborative  Web 
subsequent 
sensemaking)  for  groups  of  up  to  four  co-present  users 
gathered  around  a  multi-touch  tabletop  display.      We  first 
articulate design criteria specific to tabletop search systems, 
and  introduce  user  interface  features  to  address  those 
criteria.  We  then  describe  an  evaluation  of  WeSearch,  in 
which  student,  co-worker,  and  family  groups  conducted 
real-world  search  tasks.  We  discuss  the  findings  from  our 
study, reflecting on the effectiveness of each of WeSearch‟s 
features. 

WESEARCH 
In order to explore the potential for interactive tabletops to 
support collaborative Web search, we developed WeSearch. 
WeSearch 
tabletop  application  which  supports 
collaborative  Web  search,  browsing,  and  sensemaking 
among groups of up to four people.  

is  a 

Design Criteria 
When  designing  WeSearch,  our  goal  was  to  leverage  the 
affordances  of  tabletops  that  would  benefit  collaborative 
search  tasks.  Examples  of  such  affordances  include  high 
levels  of  awareness  from  sharing  a  single  display  and  the 
affordances  of  large  horizontal  surfaces  for  spatially 
organizing content [21].  

In 

Prior  work  on  collaborative  Web  search  tools  for  the  PC 
informed  our  system‟s  design. 
their  work  on 
SearchTogether  [18],  Morris  and  Horvitz  identify  three 
traits that are important for facilitating collaborative search 
tasks.  Awareness  of  other  group  members‟  activities, 
facilities  for  supporting  division  of  labor  among  group 
members,  and  facilities  for  persistence  of  a  search  session 
in  order  to  facilitate  asynchronous  collaboration  and 
resumption  of  multi-session,  exploratory  search  tasks. 
Morris and Horvitz also noted that, in initial evaluations of 

SearchTogether,  participants  requested  richer  sensemaking 
[25] support. Studies of the CoSense system [23] reiterated 
the  importance  of  sensemaking  support  for  collaborative 
Web search tools.  

Research  from  the  surface  computing  community  has 
shown  that  there  are  several  challenges  in  adapting 
horizontal surfaces to productivity tasks [20]. Text entry on 
tabletops  is  one  challenge  [35];  virtual  keyboards  are  not 
nearly  as  efficient  as  their  physical  counterparts,  and 
appropriate  alternative  techniques  are  still  a  subject  of 
ongoing  research  [12].  Clutter  is  also  a  challenge  of 
adapting search and sensemaking applications to tabletops, 
since  displaying  content  for  multiple  users  on  a  single 
display is a constant challenge for single display groupware 
systems  [32].  The  clutter  issue  is  further  compounded  by 
the  information-intensive  nature  of  Web  search  tasks,  as 
well  as  by  the  tendency  of  tabletops  to  utilize  projected 
displays;  XGA  (1024  x  768)  is  still  the  predominant 
projector resolution, so while most tabletops are larger than 
PC  monitors,  they  may 
in  fact  have  fewer  pixels. 
Orientation is also a challenge for tabletop system designers 
[30], since what‟s right-side-up for some group members is 
upside-down  for  others;  Web  search  exacerbates  this 
challenge,  since  text-heavy  applications  are  particularly 
challenging to use from odd viewing angles [34]. 

In light of these findings from the collaborative search and 
tabletop communities, our design goals for WeSearch were: 

  Support awareness among group members. 
  Support division of labor among group members. 
  Enable  the  shared  search  to  persist  beyond  a  single 

session. 

  Support  sensemaking  as  an  integral  part  of  the 

collaborative search process. 

  Provide facilities for reducing the frequency of virtual-

keyboard text entry. 

  Reduce clutter on the shared display. 
  Address the orientation challenges posed by text-heavy 

tabletop applications. 

Next,  we  describe  the  features  of  WeSearch,  and  explain 
how they address these design goals.  

System Description 
Since  collaborative  search  and  sensemaking  are  data-
intensive  tasks,  we  designed  WeSearch  for  a  large-form-
factor  surface,  4x6  [10]  (Figure  1).  4x6  is  a  custom-built, 
standing-height  interactive  tabletop  measuring  4  feet  wide 
by 6 feet long (1.2 m x 1.8 m). The display is top-projected 
by  two  tiled  XGA  projectors,  for  a  total  display  resolution 
of  1024  x  1536  pixels.  The  table  is  illuminated  from 
beneath by infrared light, and touch inputs are detected by a 
vision system.  

The  4x6  table  can  receive  multiple,  simultaneous  touch 
inputs,  but  cannot  associate  inputs  with  a  particular  group 
member.  Users  can  freely  rotate  all  objects;  because  our 
tabletop  hardware  is  not  user-differentiating,  we  use 

Browser Controls 
We have designed the WeSearch browser with the needs of 
touch-based  interaction  in  mind.  The  browser  can  be 
moved, rotated, and scaled using direct touch manipulations 
[8].  Because  touches  on  the  browser  are  by  default 
interpreted  as  manipulations,  we  augment  the  browser‟s 
border with buttons to enable additional actions (pan, link, 
and  clips),  shown  in  Figure  3.  A  future  implementation  of 
WeSearch might remap these buttons to gestures; we chose 
to  sidestep  the  issue  of  gesture  selection  by  using  buttons 
which  are  held  with  one  hand  while  the  browser  is 
manipulated  with  the  second  hand.  The  buttons  must  be 
held  to  maintain  the  mode  in  order  to  reduce  errors  [28]. 
Horizontal  and  vertical  scrolling  are  accomplished  by 
holding  the  “pan”  button  with  one  hand  while  using  the 
other  hand  to  pull  the  Web  page‟s  content  in  the  desired 
direction,  and  link-following  is  accomplished  by  holding 
the  “link”  button  with  one  hand  while  tapping  the  desired 
link with the other. 

Clips 
Holding a browser‟s “clips” button divides the current web 
page  into  multiple  smaller  chunks  (Figure  3b);  a  user  can 
grab  a  chunk  with  his  other  hand  and  drag  it  beyond  the 
borders  of  the  browser,  where  it  will  become  a  separate 
entity that we call a clip. Upon releasing the “clips” button, 
the  browser  page returns to  its  undivided  state.  In  order  to 
divide  a  Web  page  into  clips,  WeSearch  parses  the  DOM 
(document object model) of each page when it is loaded; we 
then create clip boundaries surrounding  DOM objects such 
as paragraphs, lists, and images. The ability to divide a page 
into  clips  supports  division  of  labor  and  readability  by 
enabling  different  group  members  to  claim  responsibility 
over distinct portions of a page‟s  contents, which can then 
be  individually  rotated  into  a  proper  reading  orientation; 
clips  also  support  clutter  reduction  –  the  small  chunks  of 
relevant content can remain open on the table and the parent 
page  can  be  closed.  Our  clips  build  upon  prior  work 
demonstrating  the  value  of  micro-mobility  of  content  on 
tables, such as DocuBits [4], which enabled easy transfer a 
screen-captured  chunk  of 
images 
between a tabletop and associated supplementary displays. 

text  documents  or 

 

Figure  2.  A  WeSearch  session.  Each  group  member  has  a 
color-coded toolbar in which they can enter queries or urls, 
and  a  marquee  containing  awareness  information.  Spread 
around the table are several browsers, clips, and containers. 

 
objects‟ orientation as a proxy for identity (i.e., whether an 
object  is  right-side  up  for  the  North,  South,  East,  or  West 
edge  of  the  tabletop).  Because  of  the  readability  issues 
concerning text on tabletops [34], orientation of text-heavy 
documents  such as  Web  pages  seems  like  a  reliable  proxy 
for  the  identity  of  the  currently-interacting  user,  and  is 
consistent  with  how  users  utilize  orientation  of  objects  to 
denote ownership [14, 27]. 

Toolbars 
When  WeSearch  initializes,  it  displays  four  color-coded 
toolbars  (one  per  group  member),  one  along  each  edge  of 
the  tabletop  (Figure  2).  If  desired,  these  toolbars  can  be 
repositioned 
direct-touch 
manipulations.  The  color  of  a  user‟s  toolbar  is  associated 
with him in other aspects of the user interface.  

re-oriented 

and 

through 

Touching  the  toolbar‟s  text  field  opens  a  virtual  keyboard 
that enables users to enter urls or query terms. Tapping the 
toolbar‟s “go” button opens the WeSearch browser (Figure 
3a) to that url (if the terms begin with “http” or “www”) or 
opens a search engine page containing search results for the 
terms entered. 

(A) 

 (B)

 

Figure  3.  (A)  The  WeSearch  browser  provides  a  panel  of  kinesthetically-held  buttons  to  distinguish  between  direct 
manipulations  (translation,  rotation,  and scaling),  and  actions such  as  panning, link-following,  and  dividing a  page  into  clips. 
(B) When the clips button is held, a webpage is automatically divided based on the underlying DOM. The resulting clips can be 
pulled out of a page and treated as individual objects. 

 

Figure 4. A clip tagged by both the green and red users. 

 

 

Figure  5.  The clips-search  function  creates four  types  of  clips 
directly  from  query  terms:  related  keywords,  Web  search 
results, images, and news article summaries. 

Clips can be moved, rotated, and scaled in the same manner 
as  browser  windows.  Like  browsers,  clips  are  augmented 
with  a  “link”  button  that,  when  depressed,  interprets 
touches as clicks on links rather than direct manipulations. 
Clips  are  also  augmented  by  a  “tag”  button;  pressing  this 
opens  a  virtual  keyboard, and  the  user  can augment  a  clip 
with tags. Tags are displayed on the clip in the color of the 
user  who  entered  them  (Figure  4).  We  included the  ability 
to augment clips with tags in order to support sensemaking 
as a key part of the task. 

Clips-Search 
In addition to creating clips by pulling chunks out of  Web 
pages in WeSearch browser windows, users can also create 
clips  directly  by  pressing  the  “clips”  button  in  lieu  of  the 
“go”  button  after  they  have  entered  query  terms  into  their 
toolbar.  This  sends  the  query  to  a  search  engine  via  its 
public API, and automatically creates four piles of five clips 
each in front of the user (Figure 5) one containing the most 
relevant  images  for  the  query,  another  containing  snippets 
describing  related  Web  pages,  a  third  containing  news 
article  summaries  on  that  topic,  and  a  fourth  containing 
suggested  related  query  keywords.  The  clips-search  button 
provides  another  easy  way  for  groups  to  divide  labor 
amongst  themselves,  if  each  chooses  to  take  responsibility 
for a different content type. 

Marquee 
Another  component  of  the  WeSearch  interface  is  the 
marquee  region  of  each  user‟s  toolbar  (Figure  6).  The 
marquee  displays  a  slowly  flowing  stream  of  text  and 
images  that  reflect  the  group  members‟  activities:  query 
terms  used,  titles  of  pages  opened  in  browsers,  and  clips 
created.  The  marquee  is  visually  similar  to  an  interface 
current  [11],  but  the  marquee‟s  content  is  generated 
automatically  based  on  users‟  actions,  while  objects  must 
be  manually  added  to  interface  currents.  The  colored 
borders  surrounding  marquee  items  indicate  which  user‟s 

Figure  6.  Each  toolbar  contains  a  marquee,  where  search 
terms,  page  titles,  and  clips  from  all  group  members  slowly 
scroll  past  for  awareness  and  readability.  Terms  from  the 
marquee can be reused via dragging onto the search box. 

activities  each  item represents.  Scroll  buttons  at  either  end 
of the marquee enable the user to manually rewind or fast-
forward  the  display,  in  order  to  review  the  content.  The 
marquee  addresses  the  issue  of  awareness  of  group 
members‟  activities,  as  well  as  offering  a  solution  to  the 
challenge of reading text at odd orientations by giving each 
group  member  a  right-side-up  view  of  key  bits  of  textual 
material from other team members. 

Marquee  items  are  interactive.  Pressing  and  holding  a 
marquee  item  causes  the  corresponding  original  clip  or 
browser (if still open) to become highlighted in the pressing 
user‟s  color  and  to  blink,  offering  a  method  of  mitigating 
the  clutter  issue  by  simplifying  the  process  of  finding 
content  within  a  crowded  UI.  Marquee  items  (and  clips) 
also provide another opportunity to reduce the frustration of 
virtual keyboard text entry: users can drag items out of the 
marquee and onto the toolbar‟s text area, in order to re-use 
the text they contain; clips can also be used in this manner. 
For  example,  the  “keyword  suggestion”  clips  created  by  a 
clips-search  can  be  dragged  directly  onto  the  textbox  in 
order to save the effort of manually re-typing those terms. 

Containers 
Another  type  of  sensemaking  support  WeSearch  provides, 
in addition to the ability to create and tag clips, is the ability 
for  clips  to  be  organized  in  containers,  which  a  user  can 
create via a button on the toolbar (Figure 7). The ability to 
create  collections  of  material  from  disparate  websites  has 
been  demonstrated  by  prior  systems  such  as  Dontcheva  et 
al.‟s  system  [3],  Hunter  Gatherer  [26],  and  Google 
this  concept  by  offering 
Notebook.  We  expand  on 
containers  designed 
in  multi-user,  direct 
manipulation  environments,  and  augmented  by  features 
such as the ability to “search by example.” 

for  use 

WeSearch offers several container variants, which organize 
clips in different manners, such as via lists, grids, and free-
form  positioning.  The  virtual  keyboards  can  be  used  to 
specify  a  title  for  the  container.  Containers  can  be 
translated,  rotated,  and  scaled  through  direct  manipulation 
interactions  on  their  background,  and  clips  can  be  added 
and removed from containers via drag-and-drop.  

Search by Example 
In  addition  to  providing  a  mechanism  for  organizing  a 
group‟s  clips,  containers  also  facilitate  discovering  new 

 

Figure  7.  Clips  can  be  organized  within  containers. 
Containers  also  provide  a  “search  by  example” 
capability, suggesting search terms related to a group of 
clips along the container’s bottom edge (in this case, the 
terms “top breed”). 

information  via  their  “search  by  example”  functionality. 
Every time a clip is added to or removed from a container, 
the  search  preview  region  at  the  bottom  of  that  container 
updates,  to  indicate  what  query  the  system  thinks  is 
suggested  by  the  container‟s  current  clips  (Figure  7). 
Pressing  the  “search”  button  adjacent  to  the  preview 
executes  the  search,  opening  the  search  results  in  a  new 
browser  window.  The  suggested  queries  are  generated  by 
analyzing  what  terms  (excepting  stopwords)  a  group  of 
clips  has  in  common;  if  there  are  no  common  terms,  the 
algorithm  instead  composes  a  query  by  choosing  a  salient 
term  from  each  clip;  saliency  is  determined  by  heuristics 
including  the  frequency  with  which  a  term  appears  and 
whether the term is a proper noun. This functionality helps 
to reduce the need for tedious virtual keyboard text entry. 

Metadata 
WeSearch  automatically  associates  several 
types  of 
metadata  with  clips,  structured  around  the  six  journalistic 
interrogatives: 

  Who: The identity of the user who created the clip. 
  What: The content type of the clip (text, image, etc). 
  Where: The URL of the Web page the clip is from. 
  When: The timestamp of the clip‟s creation. 
  Why: The tags associated with the clip. 
  How:  The  query  keywords  used  to  find  the  clip  (or  to 

find its parent Web page). 

Exportable Record 
These  metadata  are  used  to  create  a  record  of  the  group‟s 
search session. This record is saved as an XML file, with an 
accompanying  XSL  file  that  enables  the  records  to  be 
viewed  in  any  standard  Web  browser.  Figure  8  shows  a 
sample record, viewed after a WeSearch session on a group 
member‟s  PC.  Pressing  the  “save”  button  on  a  toolbar 
creates  this  record,  as  well  as  creating  a  session  file  that 
captures the current application state, enabling the group to 
reload  and  resume  the  WeSearch  session  at  a  later  time. 
This  supports  our  design  goal  of  persistence  by  providing 

 

Figure  8. WeSearch  exports  the  session  record  as XML 
with  an  accompanying  XSL  file  that  enables  users  to 
view the record from any Web browser for post-meeting 
reflection and sensemaking. 

both persistence of the session for resumption by the group 
on the table at a later time, as well as persistence in terms of 
an  artifact  (the  XML  record) 
that  can  be  viewed 
individually  away  from 
tabletop  computer.  The 
metadata included in the record also supports sensemaking 
of  the  search  process  by  exposing  detailed  information 
about  the  lineage  of  each  clip  (i.e.,  which  group  member 
found  it,  how  they  found  it,  etc),  as  well  as  information 
about the assignment of clips to containers. 

the 

EVALUATION 
We conducted an evaluation of WeSearch in order to learn 
more about how groups would use a tabletop collaborative 
search system, and whether the features we included in light 
of our design criteria were effective.  

there 

We decided to conduct an observational study rather than a 
formal  experiment,  since 
is  no  clear  baseline 
condition  to  compare  to,  as  there  are  currently  no  other 
tabletop  Web  search  systems  of  which  we  are  aware. 
Comparing  to  a  naïve  system  (such  as  running  a  standard 
Web  browser  on  a  table)  would  yield  little  additional 
insight, as we already understand the shortcomings of such 
systems  based  on  our  own  experiences,  prior  work  on 
tabletop  systems,  and  prior  work  on  collaborative  search 
(and chose our design criteria based on those issues!). 

We  decided  to  recruit  groups  who  had  an  existing  shared 
information need, in order to observe the use of  WeSearch 
for  real,  ecologically  valid  tasks.  Questions  we  hoped  to 
address through our evaluation included: 

  What  types  of  search  tasks  would  groups  want  to 

conduct using an interactive tabletop? 

  How  will  groups  use  the  WeSearch  application;  what 
types  of  work  styles  and  group  dynamics  does  it 
engender? 

  Were  WeSearch‟s 

interface  features  effective 

in 

achieving our design goals? 

Participants 
We recruited 44 participants (11 groups with four members 
per  group)  from  outside  our  institution.  In  one  of  the 
groups, two members had an unexpected absence, resulting 
in  42  participants 
total.  Group  members  had  prior 
relationships – three were family groups (each consisting of 
two  adults  plus  children),  three  were  groups  of  college 
students  taking  classes  together,  and  five  (including  the 
two-member group) were groups of colleagues who worked 
together.  Participants‟  ages  ranged  from  10  to  54  years. 
43% were female. Participants did not have backgrounds in 
computer  science,  usability,  or  related  fields.  When  asked 
to describe their Web search skills, 1 self-rated as a novice, 
19 as average, and 22 as above-average. 

Methodology 
Sessions began with a “group interview,” during which the 
experimenter asked the group members to describe a shared 
information  need  that  is  typical  in  their  interactions  with 
one  another.  They  were  then  asked  to  describe  how  their 
group  would  normally  go  about 
this 
information  need  (i.e.,  what  tools  would  they  use,  how 
would they divide up the task, etc.). The tasks groups chose 
were: 

investigating 

  Select  the  location  for  their  company‟s  next  offsite 

meeting (colleagues: administrative assistants) 

  Conduct  background  research  on  a  plaintiff  in  a 

pending court case (colleagues: paralegals) 

  Learn about local  businesses  who might be in need of 

financial services (colleagues: bankers) 

  Research  and  describe  antimicrobial  peptides  for 

identifying bacteria (colleagues:  food scientists) 

  Compile  a  list  of  commonly  reported  problems  with  a 
their 

piece  of 
customers (colleagues:  technical support technicians) 

technology  commonly  utilized  by 

  Shop for a new home computer (family) 
  Plan an upcoming ski trip to Colorado (family) 
  Plan an upcoming trip to Montana (family) 
  Research treatments for Alzheimer‟s disease (students) 
  Learn  about  art  classes  they  might  take  together 

(students) 

  Plan  a  trip  to  Austin,  Texas  (students)  (Note  that  this 
student  group  was  unable  to  agree  upon  their  search 
task, so we prompted them with a variant of the travel 
planning  task  used  in  Paul  &  Morris‟  collaborative 
sensemaking study [23].) 

After  the  initial  interview,  groups  completed  a  tutorial,  in 
which  an  experimenter  demonstrated  each  of  WeSearch‟s 
features,  and  participants  were  able  to  try  using  each 
feature. Participants were also free to ask the experimenter 
for  assistance  during the  study  (for  instance, if  they  forgot 
how to access a particular feature). 

After completing the tutorial, groups were given 30 minutes 
to  use  WeSearch to  conduct  the  joint  search  task  they  had 
specified  during  the  group  interview.  All  interactions  with 
WeSearch were logged automatically. Sessions were video 
recorded,  and  each  session  was  observed  by 
three 
experimenters who took notes.   

the  conclusion  of 

At 
the  session,  group  members 
individually  completed  questionnaires  soliciting  feedback 
on their experience using WeSearch.  

RESULTS 
Participants  reported  that  WeSearch  was  easy  to  learn 
(median  score  of  6  on  a  7-point  Likert  scale),  and  was 
helpful in completing their chosen task (median = 5). In this 
section,  we  revisit  the  seven  challenges  we  designed  our 
system  to  address,  and  examine  how  they  impacted  the 
WeSearch  experience  based  on  log,  observation,  and 
questionnaire data. 

Awareness 
WeSearch was designed to support awareness among group 
members through (1) use of a single, shared display and (2) 
the marquee feature, which displays other group members‟ 
query terms and clips in a slowly moving stream atop each 
user‟s toolbar. 

Participants strongly agreed that seeing everyone‟s  content 
on  the  shared  display  was  a  useful  aspect  of  the  system 
(median  =  6),  and  reported  generally  high  awareness  of 
other group members‟ activities (median = 5). Additionally, 
several  users  commented  on  the  benefits  of  the  shared 
tabletop form-factor. For example, when asked to compare 
using  WeSearch 
their  current  method  of  finding 
information as a group, one user commented that she liked 
how  WeSearch‟s  shared  display  offered  the  ability  to 
“glance  over  and  see  that  someone  found  something 
interesting,” another said she liked “being able to see other 
people's  pages  &  searches  at  the  same  time,”  and  another 
reported liking that “we are able to see what each person is 
working on and can expand on that particular idea.” 

to 

The  marquee  feature  proved  successful  in  facilitating 
additional awareness, particularly  of the search terms other 
group  members  had 
typed.  One  user  described  her 
experience  with  the  marquee  by  noting,  “I  found  search 
terms coming up that I did not anticipate and this improved 
the value and speed of the searches,” and another reported 
that  “seeing  other  people's  search  queries  reminded  me  of 
things  to  search  for.”  During  the  sessions,  we  observed 
many  instances  where  the marquee  sparked awareness  and 
discussion.  For  example,  among  the  group  searching  for  a 
location  for  a  company  offsite  meeting,  one  participant 
questioned  another,  “Why  did  you  put  „weddings‟?”  when 
she  saw  that  term  scroll  past  in  her  marquee,  and  learned 
that her colleague thought wedding venues might also have 
catering  facilities  appropriate  for  corporate  meetings.  The 
marquee  made  one  of  the  bankers  aware  that  his  partner 
was searching for businesses in an area he didn‟t anticipate, 
causing  him  to  comment,  “oh,  you  did  „city  of  <anon>‟?” 

it  provided  him  of 

when he  saw  her  search  terms  in his marquee.  One  of  the 
paralegals  commented  in  surprise  when  he  noticed  a 
colleague‟s  search  term,  “McDonald‟s,”  appear  in  the 
marquee, and his colleague explained that the plaintiff had 
in  the  past  sued  that  restaurant  chain.  One  participant 
commented  that he  felt  that the  collaborative  aspect  of  the 
system  was  most  clear  in  the  marquee  feature,  due  to  the 
awareness 
the  keywords  other 
participants  were  using.  Another  participant  removed 
search terms that seemed most useful from the marquee and 
arranged  them  in  a  pile  near  his  toolbar,  in  order  to  help 
him  keep  track  of  which  directions  of  the  group‟s 
investigation 
promising.  However, 
participants  also  commented  that  they  felt  the  marquee 
sometimes became too cluttered; in particular, they felt that 
the  clips  that  appeared  in  the  marquee  took  up  too  much 
space,  and  were  not  as  valuable  as  the  search  terms,  since 
clips were already easily visible by glancing at the tabletop. 

appeared  most 

Division of Labor 
One  motivation  behind  the  design  of  WeSearch‟s  clips 
feature  was  to  facilitate  division  of  labor  among  group 
members. We envisioned that group members might divide 
up  responsibility  for  portions  of  a  web  page,  for  instance, 
by dividing it into several clips and each claiming some, or 
that users might find the different clip types returned by the 
clips-search  feature  (news, 
images,  web  results,  and 
keyword  suggestions)  to  be  a  convenient  way  to  allocate 
different media types among themselves.  However, groups 
did not  use  clips  to  divide  labor  in  this  manner,  but rather 
used clips mainly for sensemaking and clutter reduction.  

However,  the  large,  shared  display  provided  by  WeSearch 
seemed to adequately support division of labor by providing 
each  group  member  with  space  to  interact  and  facilitating 
conversation  and  awareness  through  co-presence  and  co-
visibility.  All  groups  followed  a  divide-and-conquer 
strategy for their search task, wherein group members each 
were assigned sub-tasks (either by a de facto “leader,” or by 
each  volunteering  for  a  particular  task);  group  members 
then  communicated  orally  to  resolve  questions,  update 
others  on  the  status  of  their  subtask,  and  to  share  and 
compare key findings.  

Persistence 
WeSearch  provides  persistence  of  information  through  the 
ability to save and reload the table‟s state, and the ability to 
export  an  XML 
record  containing  metadata  about 
containers  and  the  clips  they  contain,  such  as  who  found 
each item,  what  terms they  used  to  find it,  what  tags  were 
added  to  it,  and  a  link  back  to  the  url  where  each  clip 
originated.  Because  our  evaluation  took  place  during  a 
single  session, participants did not have  the  opportunity  to 
make  use  of  this  record  feature,  although  we  did  show 
participants their record webpage at the end of the session, 
to  get  their  reactions.  Participants  strongly  agreed  that  the 
ability  to  export  a  record  for  later  viewing  away  from  the 
tabletop  was  a  valuable  feature  (median  =  6).  Despite  the 
fact that the task was only occurring during a single session, 

9  of  the  11  groups  used  the  “save”  button  at  least  once 
during the task, in order to export their record and capture 
the table‟s current state, further emphasizing the value users 
attribute to persistence features. 

Sensemaking 
WeSearch  offered  several  features  designed  to  support  an 
integrated  search  and  sensemaking  cycle,  including  the 
ability to create clips representing the key portions of  web 
pages,  the  ability  to  tag  clips,  and  the  ability  to  organize 
clips in various types of containers.  

Participants appreciated the ability to create clips, although 
they preferred creating clips by selecting chunks of pages in 
their  browsers  rather  than through  the  clips-search  feature, 
which  created  clips  directly  from  search terms.  They  rated 
the ability to break up pages into clips as significantly more 
useful  (median  =  6)  than  the  ability  to  do  a  clips-search 
directly (median = 5), as confirmed by a Wilcoxon test (z = 
-2.54,  p  =  .01).  Participants  frequently  broke  pages  into 
clips (previewing the available clips by using the browser‟s 
“clips” button 74.7 times per group, and removing from the 
browser  38.3  clips  per  group,  on  average),  but  rarely 
executed  a  clips-search  (only  2.2  times  per  group,  on 
average).  The  relative  unpopularity  of  the  clips-search 
feature  seemed 
issue,  with 
participants commenting that the number of clips created at 
once  via  the  search  feature  was  overwhelming  (the  feature 
by  default  created  20  clips  relevant  to  the  current  query); 
for  example,  one  user  noted,  “clips-search  …  added  too 
much clutter to the table.”  

to  be  a  clutter 

largely 

While  making  clips  from  web  pages  was  quite  popular, 
participants rarely chose to add tags to their clips  – only 2 
of the 11 groups used this feature at all; the slowness of text 
entry  with  virtual  keyboards  may  have  contributed  to  the 
disuse  of  the  tagging  feature.  Several  participants  also 
suggested  improving  upon  our  current  clip  feature  by 
enabling manual demarcation of clips (such as by circling a 
region  of  the  page  with  one‟s  finger),  in  addition  to  the 
automatic, DOM-based chunking that our system used. 

The  ability  to  organize  clips  in  containers  in  order  to  help 
make  sense  of  the  information  the  group  had  discovered 
was  popular  among  our  participants.  All  groups  created  at 
least one container, with an average of 5.7 per group. Of the 
four  container  types,  the  list  format  was  the  most  popular; 
however,  several  participants  requested  the  ability  to 
change  a  container‟s  organizational  style  on-the-fly  (rather 
than  have  to  choose  a  style  a  priori),  so  that  they  could 
preview what their content looked like organized in varying 
fashions (lists, grids, etc.).  

While we had anticipated that containers would be used for 
sensemaking at the group, rather than individual, level, this 
was  not  typically  the  case;  participants  seemed  to  feel 
ownership  over  the  containers  they  had  created,  and 
typically each group member had one (or more) containers 
of his own. The exceptions were two of the family groups – 
in one, one of the parents created a container and instructed 

the  other  family  members  that  each  should  place  clips 
related  to  his  favorite  candidate  laptops  inside  it;  in  the 
other, one of the children created a container about weather 
conditions  in  Montana  and  instructed  the  other  family 
members  to  “throw  any  clips  you  find  for  weather  stuff 
here.” Generally, however, participants felt awkward about 
using  a  container  someone  else  had  created,  apologizing 
when they did so (such as when one participant exclaimed 
“oops, I was naming your container!”) or asking for explicit 
permission, such as when one colleague asked another “can 
I  use  your  bucket?”  Groups  that  followed  this  “individual 
sensemaking”  trend  typically  followed  up  with  a  round  of 
collective  sensemaking,  where  they  discussed  what  was  in 
each container; for example, near the end of the task one of 
the  administrative  assistants  declared  “now  it‟s  time  to 
compare [containers].” 

The metadata (who, what, where, when, why, and how) that 
was automatically associated with each clip and exposed in 
the  exported  session  records  was  designed  to  support 
individual  sensemaking  and  reflection  away  from  the 
tabletop; however, since our experiment took place during a 
single,  around-the-table  session,  we  did  not  have  the 
opportunity to evaluate that sensemaking feature. 

Text Entry 
As expected, participants reported that entering text (query 
terms, urls, tags, etc.) using our tabletop‟s virtual keyboards 
was  slower  and 
than  using  traditional 
keyboards,  expressing  disagreement  with  the  statement 
“typing  on  the  virtual  keyboard  was  easy”  (median  =  3), 
and providing several comments to that effect, such as “take 
the  keyboard  off  the  table  and  make  it  separate  hardware. 
Typing was a bottleneck to my efficiency.” 

less  pleasant 

WeSearch attempted to mediate this problem by facilitating 
easy  reuse  of  text,  such  as  by  enabling  reuse  of  terms 
appearing in the  marquee  and  clips,  and  by  the  “search  by 
example”  feature  that  suggests  search  keywords  based  on 
the set of clips in a container.  Participants made use of the 
search by example feature, though not extensively; 7 of the 
11 groups used it at least once, with an average of 2.8 uses 
per group.  

The  ability  to  reuse  items  appearing  in the  marquee  was  a 
very  popular  alternative  to  typing,  and  enabled  group 
members to leverage text entry  work already done by their 
teammates.  Groups  used  this  feature  an  average  of  16.8 
times  each  (66.2%  of  all  words  entered  in  the  query  box 
were from re-used, rather than typed, text), and participants 
strongly  agreed  that  the  ability  to  reuse  text  from  the 
marquee was helpful (median = 6). For example, when the 
group  of  administrative  assistants  was  searching  for  a 
location  for  their  company‟s  offsite  meeting,  one  woman 
said  to  another  “thanks  for  typing  „conference‟”  as  she 
pulled  that  term  from  her  marquee  and  appended  it  to  her 
own  query.  Another  participant  had  begun  typing  a  long 
keyword  when  he  saw  it  appear  in  his  marquee  because 
another  group  member  had  typed  it  already  –  “why  am  I 

typing this when it‟s on the marquee?” he said, abandoning 
typing and adding the marquee text to his query instead. 

Clutter 
WeSearch  allowed  participants  to  extract  clips  containing 
the most relevant content from web pages so that the pages 
themselves  could  be  closed,  thus  reducing  clutter  on  the 
tabletop.  Our  system  also  employed  a  large  form-factor 
table with a tiled projector system in order to alleviate space 
issues.  Nonetheless,  clutter  remained  one  of  the  most 
problematic aspects of the WeSearch experience, prompting 
tense dialogue between participants such as “will you move 
your  stuff?”,  “you‟re  taking  up  my  space,  man”,  and  “I‟ll 
just start stealing Dad‟s space.” These remarks also reflect 
participants‟  sense  of  ownership  over  a  portion  of  space, 
reconfirming  Scott  et  al.‟s  findings  regarding  territoriality 
on  tabletop  displays  [27].  Participants  strongly  agreed  that 
the table was too cluttered during the activity (median = 6), 
and 18 participants (43%) mentioned clutter as a problem in 
their 
responses.  Common 
suggestions  made  by  our  participants  on  the  post-task 
questionnaire included the ability to group items and mark 
them for simultaneous deletion (i.e., deleting an entire pile 
of  clips  at  once),  and  allowing  users  to  hide  or  minimize 
their  toolbars  (which  are  currently  always  visible  in 
WeSearch).  

questionnaire 

free-form 

Orientation 
As  mentioned  in  the  “Awareness”  section,  the  marquee 
appeared to successfully address the issue of reading text at 
odd  orientations  by  providing  a  user-oriented  view  of  the 
search  terms  other  group  members  were  typing.  However, 
WeSearch  permitted  clips  and  browser  windows  to  be 
freely  rotated  via  two-fingered  manipulations  in  order  to 
permit  the  use  of  orientation  for  communicative  purposes, 
as  suggested  by  Kruger  et  al  [14].  Participants  frequently 
performed  rotations  unintentionally  (while  scaling  or 
moving documents), and spent time trying to return browser 
windows  to  straight  orientations  –  even  slight  angles 
seemed  to  annoy  our  participants,  several  of  whom 
requested  that  browsers  and  clips  should  “snap”  to  align 
with  table  edges  rather  than  be  fully  rotatable  (such  as  in 
[30]).  One  participant  captured  this  sentiment  on  his 
questionnaire,  indicating  that  we  should  “change  the 
sensitivity  to  rotation.  I  spent  too  much  time  having  to 
continually readjust the rotation.” 

DISCUSSION 
In  light  of  our  findings,  we  revisit  the  questions  that 
motivated our evaluation: 

What  types  of  search  tasks  would  groups  want  to  conduct 
using an interactive tabletop? 

types 

(families, 

In  our  study  we  had  the  opportunity  to  observe  groups  of 
several 
colleagues) 
conducting  collaborative  searches  on  topics  of  interest  to 
them.  Our  post-study  questionnaire  also  asked  participants 
to discuss any other information needs they had where they 
might want to use a system such as  WeSearch. In addition 

students, 

and 

to providing examples of several specific productivity tasks 
(i.e.  job  or  school-related  joint research  tasks) and  family-
oriented tasks (i.e. shopping, travel planning, entertainment 
planning)  involving  collaboration  among  groups  of  peers, 
several  participants  also  suggested  that  a  collaborative 
tabletop  search  system  might  be  valuable  in  situations 
where a professional and a customer work together, such as 
a librarian and a student finding information together, or a 
salesperson  helping  a  client  to  explore  various  product 
options together. 

How will groups use the WeSearch application; what types 
of work styles and group dynamics does it engender? 

WeSearch  supported  natural  transitions  between  closely- 
and loosely-coupled (i.e., parallel) work styles, with groups 
typically  dividing  a  search  task  into  sub-tasks  on  which 
members worked in parallel, with interwoven discussion of 
items  of  interest  to  the  group  at  large,  such  as  interesting 
results discovered. 

Were  WeSearch’s  interface  features  effective  in  achieving 
our design goals? 

Awareness:  WeSearch  adequately  supported  awareness 
among  group  members;  the  marquee  feature,  in  particular, 
provided heightened awareness of the query terms used by 
other  group  members,  which  stimulated  discussions  about 
search strategy among group members. 

Division of Labor: While the clips feature did not support 
division  of  labor  as  originally  envisioned,  the  tabletop 
environment  itself,  which  supported  individual  action  and 
shared communication, was adequate for enabling effective 
division of work among group members. 

Persistence:  The  system‟s  record-exporting  and  state-
saving  features  received  positive  reactions  from  our 
participants. 

their 

to 
Sensemaking:  WeSearch  enabled  group  members 
integrate 
activities 
seamlessly. The ability to create clips and to organize them 
in  containers  was  highly  valued,  although 
tagging 
capabilities were underutilized. 

sensemaking 

search 

and 

the 

Text Entry: The ability to reuse existing text rather than re-
typing  everything  on  virtual  keyboards  was  highly 
appreciated,  although  participants  still  found  the  occasions 
when  they  needed  to  use  the  virtual  keyboards  to  be 
frustrating.  Augmenting 
tabletop  with  physical 
keyboards (perhaps fixed in place around the bezels  of the 
display so that they don‟t add to the clutter problem) might 
address  this  frustration.  Since  text  entry  was  a  key 
frustration  for  users,  we  expect  that  offering  physical 
keyboards may change work styles from what we observed; 
however, evaluating WeSearch without physical keyboards 
to  optimize 
offered  value 
productivity 
common  hardware 
configuration, such as by maximizing text reusability. 

in  understanding  how 

systems 

this 

for 

to 

the 

Clutter: The ability to create a clip and then close the web 
page  it  came  from  helped  to  reduce  clutter  somewhat. 
Despite this, clutter remained a key frustration  when using 
WeSearch  due 
large  number  of  documents 
participants  explored  during  their  search  tasks.  Further 
clutter  reduction  techniques,  such  as  ZoomScapes  [6], 
might  prove  valuable.  A  higher-resolution  display  would 
also  reduce  clutter,  since  objects  could  be  legible  at  a 
smaller  size.  Note  that  popular  commercially-available 
tabletops such as DiamondTouch [2] and Microsoft Surface 
would  not  be  appropriate  for  collaborative  search  and 
sensemaking tasks due to their small sizes (since the custom 
table we used in our study was over twice as large as these 
technologies and still suffered from clutter issues). We note 
that a common suggestion made by participants of allowing 
the  toolbar  to  be  minimized  would  reduce  its  benefits  for 
awareness,  and  so  alternative  clutter-reduction  approaches 
would be preferable.  

Orientation:  While  the  marquee  provided  group  members 
with  a  way  to  see  other  users‟  text  at  a  right-side-up 
orientation,  group  members  were  more  concerned  with 
maintaining  a  right-side-up  orientation  for  items  that 
belonged  to  them  –  the  freedom  to  reorient  objects  freely 
confused  them  and  they  did  not  seem  interested  in  the 
communicative  benefits  of  orientation; 
they 
indicated  a  strong  preference  for  forced  rectilinear 
orientations for text-heavy objects such as web browsers. 

rather, 

In  light  of  these  findings,  we  believe  that  WeSearch 
effectively  illustrates  the  potential  of  interactive  tabletops 
as  a  platform  for  collaborative  search  tasks,  by  easily 
facilitating  awareness  and  division  of  labor,  which  PC-
based  collaborative  search  tools  struggle  to  enable  [1,  18], 
and by offering interface solutions to challenges specific to 
the tabletop form-factor, such as text-entry and clutter. Note 
that  by  choosing  a  holistic  evaluation,  we  were  unable  to 
evaluate alternative designs for any particular UI innovation 
introduced  by  WeSearch;  while  such  assessments  would 
also be beneficial, we leave them to future work. 

CONCLUSION AND FUTURE WORK 
In this paper, we investigated whether interactive tabletops 
could be an effective platform for facilitating collaborative 
Web  search.  The  contributions  of  this  work  included:  (1) 
Identifying  seven  design  criteria  for  successful  tabletop 
search  systems,  based  on  a  review  of  literature  from  both 
the  collaborative  search  and  tabletop  communities;  (2) 
WeSearch,  a  system  that  addresses  these  design  criteria 
through  a  combination  of  novel  interface  features;  and  (3) 
An evaluation of WeSearch, in which 42 participants (in 11 
groups)  performed 
thereby 
providing data on the effectiveness of WeSearch‟s interface 
features as well as on how groups work together using this 
new type of system. 

real-world  search 

tasks, 

We  found  that  WeSearch‟s  marquee  feature  enhanced 
awareness  of  group  members‟  search  terms,  clips  and 
containers supported sensemaking as an integral part of the 

search process, and text-reuse and report-exporting features 
were  highly  valued.  The  main  obstacles  to  a  smooth 
tabletop  search  experience  were  hardware-based:  larger, 
higher-resolution  tabletops  would  alleviate  clutter  issues, 
and  the integration  of  physical  keyboards  would  provide  a 
more positive text-entry experience. 

The  success  of  WeSearch 
in  facilitating  co-located 
collaborative  search  shows  the  potential  for  tabletop 
computers  to  serve  this  need.  Our  design  criteria,  system, 
and study  findings provide a  first step toward adapting the 
properties of tabletop displays for group Web search tasks.  

REFERENCES 
1.  Amershi, S. and Morris, M.R. CoSearch: A System for Co-
located Collaborative Web Search.  CHI 2008, 1647-1656. 

2.  Dietz, P. and Leight, D. DiamondTouch: A Multi-User Touch 

Technology.  UIST 2001, 219-226. 

3.  Dontcheva, M., Drucker, S., Wade, G., Salesin, D., and Cohen, 

M. Summarizing Personal Web Browsing Sessions.  UIST 
2006, 115-124.  

4.  Everitt, K., Shen, C., Ryall, K., and Forlines, C. DocuBits and 
Containers: Providing e-Document Micro-mobility in a Walk-
Up Interactive Tabletop Environment.  Interact 2005. 

5.  Fidel, R., Bruce, H., Peitersen, A., Dumais, S., Grudin, J., and 

Poltrock, S. Collaborative Information Retrieval. Review of 
Information Behavior Research 1, 1 (2000). 

6.  Guimbretiere, F., Stone, M., and Winograd, T. Fluid 

Interaction with High-Resolution Wall-Size Displays.  UIST 
2001, 21-30. 

7.  Han, J. Low-Cost Multi-Touch Sensing through Frustrated 

Total Internal Reflection.  UIST 2005, 115-118. 

8.  Hancock, M., Vernier, F. D., Wigdor, D., Carpendale, S., and 

Shen, C. Rotation and Translation Mechanisms for Tabletop 
Interaction.  Tabletop 2006, 79-86. 

9.  Hansen, P., and Jarvelin, K. Collaborative Information 

Retrieval in an Information-Intensive Domain. Information 
Processing and Management 41, 5 (2005), 1101-1119. 

10. Hartmann, B., Morris, M.R., Benko, H., and Wilson, A. 

Augmenting Interactive Tables with Mice & Keyboards. UIST 
2009. 

11. Hinrichs, U., Carpendale, S., and Scott, S. D. Interface 

currents: supporting fluent face-to-face collaboration. In ACM 
SIGGRAPH 2005 Sketches. 

12. Hinrichs, U., Hancock, M., Collins, C., and Carpendale, S. 

Examination of Text-Entry Methods for Tabletop Displays.  
IEEE Tabletop 2007, 105-112. 

13. Isenberg, P. and Fisher, D. Collaborative Brushing and 
Linking for Co-located Visual Analytics of Document 
Collections.  Eurographics/IEEE-VGTC Symposium on 
Visualization (EuroViz 2009), 1031-1038. 

14. Kruger, R., Carpendale, M.S.T., Scott, S.D., and Greenberg, S. 

Roles of Orientation in Tabletop Collaboration: 
Comprehension, Coordination and Communication. Computer 
Supported Cooperative Work, Volume 14, Issue 5-6, December 
2004, 501-537.  

15. Large, A., Beheshti, J., and Rahman, T. Gender Differences in 

Collaborative Web Searching Behavior: An Elementary 

School Study. Information Processing and Management 38, 3 
(2002), 427-443. 

16. Maekawa, T., Hara, T., and Nishio, S. A Collaborative Web 

Browsing System for Multiple Mobile Users.  PERCOM 2006. 

17. Morris, M.R., Paepcke, A., and Winograd, T. TeamSearch: 

Comparing Techniques for Co-Present Collaborative Search of 
Digital Media.  IEEE Tabletop 2006, 97-104. 

18. Morris, M.R. and Horvitz, E. SearchTogether: An Interface for 

Collaborative Web Search.  UIST 2007, 3-12. 

19. Morris, M.R. A Survey of Collaborative Web Search 

Practices.  CHI 2008, 1657-1660. 

20. Morris, M.R., Brush, A.J.B., and Meyers, B. A Field Study of 
Knowledge Workers‟ Use of Interactive Horizontal Displays.  
IEEE Tabletop 2008, 113-120. 

21. Morris, M.R. Supporting Effective Interaction with Tabletop 
Groupware. Stanford University Technical Report (Doctoral 
Dissertation), April 2006. 

22. Paek, T., Agrawala, A., Basu, S., Drucker, S., Kristjansson, T., 

Logan, R., Toyoma, K., and Wilson, A. Toward Universal 
Mobile Interaction Shared Displays.  CSCW 2004, 266-269. 

23. Paul, S. and Morris, M.R. CoSense: Enhancing Sensemaking 

for Collaborative Web Search.  CHI 2009, 1771-1780. 

24. Pickens, J., Golovchinsky, G., Shah, C., Qvarfordt, P., and 

Back, M. Algorithmic Mediation for Collaborative 
Exploratory Search.  SIGIR 2008, 315-322. 

25. Russell, D.M., Stefik, M.J., Pirolli, P., and Card, S.K. The 

Cost Structure of Sensemaking.  CHI 1993, 269-276. 

26. schraefel, m.c., Zhu, Y., Modjeska, D., Wigdor, D., and Zhao, 

S. Hunter-Gatherer. Interaction Support for the Creation and 
Management of Within-Web-Page Collections.  WWW 2002. 

27. Scott, S.D., Carpendale, M.S.T., and Inkpen, K. Territoriality 

in Collaborative Tabletop Workspaces.  CSCW 2004, 294-303. 

28. Sellen, A., Kurtenbach, G., and Buxton, W. (1992). The 

prevention of mode errors through sensory feedback. Human 
Computer Interaction, 7(2). p. 141-164. 

29. Shen, C., Lesh, N., Vernier, F., Forlines, C., and Frost, J. 

Building and Sharing Digital Group Histories.  CSCW 2002, 
324-333. 

30. Shen, C. Vernier, F., Forlines, C., and Ringel, M. 

DiamondSpin: An Extensible Toolkit for Around-the-Table 
Interaction.  CHI 2004, 167-174. 

31. Smeaton,  A.F.,  Lee,  H.,  Foley,  C.,  and  McGivney,  S. 
Collaborative  Video  Searching  on  a  Tabletop.  Multimedia 
Systems Journal, 2006, Vol. 12, No. 4, 375-391. 

32. Stewart,  J.,  Bederson,  B.,  and  Druin,  A.  Single  Display 
Groupware:  A  Model  for  Co-present  Collaboration.    CHI 
1999, 286-293. 

33. Twidale,  M.,  Nichols,  D.,  and  Paice,  C.  Browsing  is  a 
and 

Information  Processing 

Collaborative 
Management 33, 6 (1997), 761-783. 

Process. 

34. Wigdor,  D.  and  Balakrishnan,  R.  Empirical  Investigation  into 
the  Effect  of  Orientation  on  Text  Readability  in  Tabletop 
Displays.  ECSCW 2005, 205-224.  

35.Wigdor, D., Penn, G., Ryall, K., Esenther, A., Shen, C. Living 
with  a  Tabletop:  Analysis  and  Observations  of  Long  Term 
Office Use of a Multi-Touch Table.  Tabletop 2007. 

","{""pos"":{""0"":1,""1"":2,""2"":3,""3"":4,""4"":5},""2"":{""0"":""m"",""1"":""d"",""2"":""c*"",""3"":""r*"",""4"":""t""},""0"":{""0"":""created*"",""1"":""located*"",""2"":""reported"",""3"":""commented*"",""4"":""held*""},""5"":{""0"":""tasks"",""1"":""terms*"",""2"":""session"",""3"":""orientation*"",""4"":""task*""},""4"":{""0"":""clip"",""1"":""containers*"",""2"":""container*"",""3"":""space"",""4"":""reuse*""},""1"":{""0"":""2006*"",""1"":""2005*"",""2"":""2008*"",""3"":""2004*"",""4"":""2010*""},""3"":{""0"":""marquee"",""1"":""feature"",""2"":""button"",""3"":""a"",""4"":""touch*""}}",2010,{},False,False,conferencePaper,False,L239LNLV,[],self.user,"{""Unnamed: 0"":{""0"":0,""1"":1,""2"":2,""3"":3,""4"":4,""5"":5,""6"":6,""7"":7,""8"":8,""9"":9,""10"":10,""11"":11,""12"":12,""13"":13,""14"":14,""15"":15,""16"":16,""17"":17,""18"":18,""19"":19,""20"":20,""21"":21,""22"":22,""23"":23,""24"":24,""25"":25,""26"":26,""27"":27,""28"":28,""29"":29,""30"":30,""31"":31,""32"":32,""33"":33,""34"":34,""35"":35,""36"":36,""37"":37,""38"":38,""39"":39,""40"":40,""41"":41,""42"":42,""43"":43,""44"":44,""45"":45,""46"":46,""47"":47,""48"":48,""49"":49,""50"":50,""51"":51,""52"":52,""53"":53,""54"":54,""55"":55,""56"":56,""57"":57,""58"":58,""59"":59,""60"":60,""61"":61,""62"":62,""63"":63,""64"":64,""65"":65,""66"":66,""67"":67,""68"":68,""69"":69,""70"":70,""71"":71,""72"":72,""73"":73,""74"":74,""75"":75,""76"":76,""77"":77,""78"":78,""79"":79,""80"":80},""C"":{""0"":6.8600315558,""1"":20.5898303575,""2"":4.8686836093,""3"":10.9840975949,""4"":16.6814950245,""5"":15.1100435025,""6"":5.4288006984,""7"":6.3585305409,""8"":5.8498016095,""9"":7.97139008,""10"":4.7842661435,""11"":5.3589671889,""12"":18.7920253326,""13"":16.180578224,""14"":5.2810231237,""15"":6.291085663,""16"":5.0967614733,""17"":13.3471912704,""18"":6.3753210077,""19"":9.7748110797,""20"":12.9092451426,""21"":10.309025054,""22"":5.1271981949,""23"":17.9243017816,""24"":5.1908341589,""25"":16.7798950392,""26"":6.4605941816,""27"":5.5545858349,""28"":15.0999041832,""29"":7.6452821083,""30"":5.7755804519,""31"":14.1239643657,""32"":4.5346524286,""33"":5.6810207728,""34"":9.5057337062,""35"":5.0174244197,""36"":10.2729139619,""37"":4.5878053882,""38"":6.3317193654,""39"":6.0005192305,""40"":8.3195239328,""41"":6.1200070709,""42"":7.1343614134,""43"":10.1057602624,""44"":7.1783544712,""45"":5.4769579306,""46"":5.2004675717,""47"":6.3731816681,""48"":5.8398532053,""49"":6.9516792182,""50"":8.480962414,""51"":7.2045894573,""52"":6.2521164356,""53"":6.2613561125,""54"":7.6049917531,""55"":4.4641246738,""56"":5.5122583635,""57"":5.6695648481,""58"":6.1055237191,""59"":6.6119415908,""60"":5.6028244466,""61"":4.4643190431,""62"":5.3008497927,""63"":6.1115773857,""64"":6.4214678591,""65"":5.0381210236,""66"":4.5003120605,""67"":4.7129610852,""68"":4.5857235388,""69"":5.9097779285,""70"":5.2863480941,""71"":4.6770454931,""72"":4.6929128999,""73"":4.7088045643,""74"":4.6849743306,""75"":4.5591686374,""76"":4.6968950219,""77"":4.4543538555,""78"":4.6612186247,""79"":4.6691361871,""80"":4.504239159},""count"":{""0"":220,""1"":170,""2"":160,""3"":94,""4"":84,""5"":76,""6"":72,""7"":70,""8"":54,""9"":54,""10"":50,""11"":48,""12"":46,""13"":46,""14"":44,""15"":40,""16"":40,""17"":38,""18"":34,""19"":32,""20"":30,""21"":30,""22"":28,""23"":28,""24"":26,""25"":26,""26"":24,""27"":24,""28"":24,""29"":22,""30"":22,""31"":22,""32"":20,""33"":20,""34"":20,""35"":16,""36"":16,""37"":14,""38"":14,""39"":14,""40"":14,""41"":12,""42"":12,""43"":12,""44"":12,""45"":12,""46"":12,""47"":12,""48"":12,""49"":12,""50"":12,""51"":12,""52"":10,""53"":10,""54"":10,""55"":10,""56"":10,""57"":10,""58"":10,""59"":10,""60"":8,""61"":8,""62"":8,""63"":8,""64"":8,""65"":8,""66"":8,""67"":8,""68"":8,""69"":8,""70"":8,""71"":6,""72"":6,""73"":6,""74"":6,""75"":6,""76"":6,""77"":6,""78"":6,""79"":6,""80"":6},""sigma_nor"":{""0"":1.4438369808,""1"":2.5200262136,""2"":1.3626706305,""3"":2.0580662203,""4"":2.6984158285,""5"":2.6062842213,""6"":1.577793322,""7"":1.6884927869,""8"":1.7038290413,""9"":1.9689828339,""10"":1.588506962,""11"":1.6736102188,""12"":3.4822158839,""13"":3.1328379199,""14"":1.686465505,""15"":1.8553856198,""16"":1.686050376,""17"":2.8940539018,""18"":1.9225254749,""19"":2.4706948251,""20"":3.0051527405,""21"":2.5915223943,""22"":1.785882406,""23"":3.8764857531,""24"":1.8166312759,""25"":3.763876358,""26"":2.0583787281,""27"":1.9015416889,""28"":3.5539099841,""29"":2.3008627222,""30"":1.9667792686,""31"":3.4584915538,""32"":1.7667220777,""33"":1.9786080793,""34"":2.6855389143,""35"":1.9116936899,""36"":2.9590669793,""37"":1.853751668,""38"":2.2162912101,""39"":2.1474385334,""40"":2.6295327845,""41"":2.2166252194,""42"":2.4373978336,""43"":3.0841180815,""44"":2.4469728529,""45"":2.0766665937,""46"":2.0164889055,""47"":2.271728269,""48"":2.1556501748,""49"":2.3976373435,""50"":2.7304834062,""51"":2.452682856,""52"":2.2941527764,""53"":2.296266862,""54"":2.6036976107,""55"":1.8850510606,""56"":2.1248694423,""57"":2.1608619754,""58"":2.2606116085,""59"":2.3764826235,""60"":2.1869314322,""61"":1.911877526,""62"":2.1139767428,""63"":2.3098421209,""64"":2.3847092097,""65"":2.0505035489,""66"":1.9205731545,""67"":1.971947478,""68"":1.9412078925,""69"":2.2610889671,""70"":2.110473247,""71"":1.9833003569,""72"":1.9873633034,""73"":1.9914324611,""74"":1.9853305842,""75"":1.9531172679,""76"":1.98838295,""77"":1.9262788027,""78"":1.9792477906,""79"":1.9812751308,""80"":1.9390522394},""vocab_index"":{""0"":0,""1"":1,""2"":2,""3"":6,""4"":8,""5"":10,""6"":11,""7"":12,""8"":15,""9"":16,""10"":18,""11"":20,""12"":22,""13"":23,""14"":25,""15"":29,""16"":30,""17"":32,""18"":35,""19"":40,""20"":46,""21"":47,""22"":51,""23"":52,""24"":58,""25"":59,""26"":62,""27"":66,""28"":67,""29"":74,""30"":75,""31"":76,""32"":82,""33"":86,""34"":87,""35"":103,""36"":108,""37"":113,""38"":118,""39"":130,""40"":132,""41"":146,""42"":148,""43"":149,""44"":155,""45"":162,""46"":164,""47"":165,""48"":166,""49"":167,""50"":168,""51"":169,""52"":182,""53"":195,""54"":205,""55"":207,""56"":208,""57"":209,""58"":210,""59"":211,""60"":212,""61"":214,""62"":249,""63"":260,""64"":271,""65"":272,""66"":281,""67"":285,""68"":286,""69"":287,""70"":288,""71"":289,""72"":304,""73"":305,""74"":331,""75"":347,""76"":350,""77"":399,""78"":412,""79"":413,""80"":425},""word"":{""0"":""search"",""1"":""clips"",""2"":""group"",""3"":""collaborative"",""4"":""participants"",""5"":""marquee"",""6"":""groups"",""7"":""text"",""8"":""tasks"",""9"":""terms"",""10"":""ability"",""11"":""browser"",""12"":""m"",""13"":""feature"",""14"":""clutter"",""15"":""clip"",""16"":""containers"",""17"":""figure"",""18"":""session"",""19"":""button"",""20"":""container"",""21"":""record"",""22"":""orientation"",""23"":""d"",""24"":""task"",""25"":""c"",""26"":""tabletops"",""27"":""pages"",""28"":""r"",""29"":""created"",""30"":""t"",""31"":""a"",""32"":""touch"",""33"":""typing"",""34"":""median"",""35"":""interaction"",""36"":""j"",""37"":""located"",""38"":""challenge"",""39"":""average"",""40"":""k"",""41"":""direct"",""42"":""buttons"",""43"":""hand"",""44"":""pressing"",""45"":""reported"",""46"":""participant"",""47"":""space"",""48"":""reuse"",""49"":""chi"",""50"":""uist"",""51"":""2006"",""52"":""applications"",""53"":""color"",""54"":""commented"",""55"":""popular"",""56"":""shen"",""57"":""2005"",""58"":""f"",""59"":""carpendale"",""60"":""usa"",""61"":""introduce"",""62"":""held"",""63"":""opens"",""64"":""file"",""65"":""learn"",""66"":""felt"",""67"":""2008"",""68"":""management"",""69"":""ieee"",""70"":""2004"",""71"":""wa"",""72"":""copies"",""73"":""2010"",""74"":""affordances"",""75"":""4x6"",""76"":""inputs"",""77"":""viewed"",""78"":""plan"",""79"":""trip"",""80"":""export""},""vector"":{""0"":""[ 0.53907156 -0.57669324 -2.5455365  -0.31359014  2.2832973   3.963422\n -0.32376057  1.0623227   1.9046073  -0.93665344]"",""1"":""[ 1.5928739  -0.89353305 -2.7276316  -0.23472172  2.5011024   4.5566173\n  0.2563455   1.1004754   1.5366336  -0.80868614]"",""2"":""[ 1.0527905  -0.8481053  -3.1929886  -0.4286559   2.0294545   5.0321507\n -0.06871778  0.46390972  2.5515807  -0.3569871 ]"",""3"":""[ 0.39324197 -0.43739098 -3.0637205  -0.26341015  2.364806    4.648555\n -0.24940301  1.0784835   2.3036866  -0.7297318 ]"",""4"":""[ 0.7669632  -0.5703445  -3.12372    -0.22095793  2.4380536   5.3414464\n  0.0704515   0.68774825  2.2970543  -0.3552552 ]"",""5"":""[ 1.194221  -0.8865988 -2.5770972 -0.8338011  2.2336874  3.8956895\n -0.5302505  1.2657565  2.2375517 -0.7711099]"",""6"":""[ 1.0582173  -0.568719   -3.178835   -0.01459284  2.265484    5.1558814\n  0.2349109   0.4278838   2.1796563  -0.5655031 ]"",""7"":""[ 1.4342414  -0.7250461  -2.863208    0.48528737  2.2854216   4.309327\n  0.50674057  0.668892    1.3368175  -1.1887525 ]"",""8"":""[ 0.555293   -0.3141521  -2.909213    0.12204507  2.3167784   5.051861\n -0.21254495  0.5402457   2.367193   -0.6512214 ]"",""9"":""[ 0.9544764  -0.2433716  -3.0327642  -0.072103    2.4294806   5.121621\n  0.16340616  0.4595563   2.2782657  -0.8618911 ]"",""10"":""[ 0.54207    -0.57448107 -2.700388   -0.24336301  2.0996063   4.556434\n -0.7270556   0.785717    2.601573   -0.47097898]"",""11"":""[ 0.93719214 -0.56139535 -2.8505301   0.09986225  2.3011773   4.3847446\n  0.14949909  0.83182967  1.5657278  -1.0890508 ]"",""12"":""[ 2.044756   -0.64246255 -2.824052    1.7635912   2.3857033   3.722258\n  1.5077847   0.21708104  1.235935   -1.4868449 ]"",""13"":""[ 1.3651235  -0.91260093 -2.4059918  -0.9423706   2.230853    3.7024915\n -0.73433495  1.3701129   2.2631755  -0.80027205]"",""14"":""[ 0.53287137 -0.3663333  -2.6560843   0.02533751  2.7892756   4.4517894\n  0.05866152  1.2569526   1.9326615  -0.81939495]"",""15"":""[ 1.5648954  -0.99964285 -2.7350268  -0.6051237   2.4759514   4.5186353\n  0.11121598  1.2215198   1.770191   -0.7126373 ]"",""16"":""[ 1.163374   -0.39783207 -2.7687504  -0.07312202  2.949432    4.8685803\n  0.51335096  1.1695411   1.6865838  -0.90271807]"",""17"":""[ 1.3004498  -0.8732625  -2.9784594  -0.5450325   1.9208394   4.789513\n -0.35129315  0.52075905  2.5595589  -0.46988428]"",""18"":""[ 0.86489946 -1.0755959  -3.0472932  -0.5747436   2.1906328   4.977326\n -0.13406079  0.8617405   2.4319117  -0.17870042]"",""19"":""[ 1.2104218  -0.8470042  -2.5658143  -0.03358383  2.0841517   3.7034206\n -0.2582448   1.1437901   1.5212224  -1.007819  ]"",""20"":""[ 1.1097023  -0.6348777  -2.8122723  -0.39500257  2.8572845   4.720401\n  0.45386592  1.2861007   1.7495736  -0.8497748 ]"",""21"":""[ 1.2550627  -1.0324391  -2.8480358  -0.8449709   2.3125594   4.511714\n -0.05384227  1.100612    2.197447   -0.54014915]"",""22"":""[ 0.5634847  -0.82925135 -3.0809507  -0.0827603   2.1704082   4.920611\n -0.11902357  0.71025485  2.4057858  -0.27949443]"",""23"":""[ 2.137456   -0.66794723 -3.105008    1.5188535   2.4777026   3.8439212\n  1.3822469   0.28615507  1.251178   -1.3520306 ]"",""24"":""[ 0.6544545  -0.69955283 -2.8053322  -0.29785526  2.1035872   4.8238444\n -0.53537184  0.65484476  2.6350908  -0.36251673]"",""25"":""[ 2.0662248  -0.7365623  -2.8805425   1.3505038   2.4934802   3.7066133\n  1.3160385   0.41662478  1.219886   -1.383289  ]"",""26"":""[ 1.1990191  -0.41615707 -2.7265093   0.40131298  2.789219    4.520756\n  0.55295056  1.0415766   1.5902579  -0.97118926]"",""27"":""[ 1.3052324  -0.55263126 -2.9618666   0.02310962  2.5218778   4.9740057\n  0.42781886  0.7037973   1.7068163  -0.85018206]"",""28"":""[ 2.2130928 -0.8093629 -2.8097248  1.4674042  2.2430205  3.6808913\n  1.3128463  0.1885113  1.3815241 -1.3966062]"",""29"":""[ 1.267965   -0.37647298 -1.7859358  -1.6318266   2.390665    2.4214363\n -1.7306736   1.8101547   2.7409124  -1.2484334 ]"",""30"":""[ 2.0677254  -0.6083033  -3.0364048   1.6137632   2.532337    3.7886505\n  1.3938141   0.33059728  1.1608506  -1.3406557 ]"",""31"":""[ 0.7855709  -0.66813433 -2.611525   -0.7869901   2.0143921   3.641173\n -0.70543855  1.1495725   2.3672953  -0.8417336 ]"",""32"":""[ 1.0287541  -0.8133564  -2.3609524  -0.3958828   2.0594068   3.482711\n -0.8244663   1.3207676   2.010449   -0.84462744]"",""33"":""[ 0.70017844 -0.6490951  -2.6022813  -0.05985286  2.1291878   3.8300335\n -0.33347452  1.0800608   1.7026389  -0.96368206]"",""34"":""[ 1.0859634  -0.6483457  -3.064066   -0.5371663   1.9385319   4.2465205\n  0.11374298  0.40975577  2.3751256  -0.7990824 ]"",""35"":""[ 0.4474386  -0.5327342  -2.9708664   0.1803146   2.2782645   4.738549\n -0.18530664  0.84754646  2.163464   -0.571741  ]"",""36"":""[ 2.1549652  -0.58483773 -2.7686446   1.4988685   2.2537022   3.834792\n  1.1175095   0.04816274  1.1810244  -1.4081126 ]"",""37"":""[ 1.3751336  -0.40240797 -1.7545857  -1.6358413   2.3986952   2.3280787\n -1.6970937   1.7980742   2.6814742  -1.3505789 ]"",""38"":""[ 0.70563906 -0.6798117  -2.58888    -0.41864857  2.074699    4.291689\n -0.8024294   0.92289317  2.5344985  -0.5157907 ]"",""39"":""[ 1.0824699  -0.7352679  -3.0237675  -0.6568258   1.9648452   4.2794533\n -0.01218228  0.5594383   2.4377043  -0.685086  ]"",""40"":""[ 2.1055884  -0.62409747 -2.654151    1.491009    2.2714963   3.6945472\n  1.2421176   0.14506896  1.1851242  -1.52048   ]"",""41"":""[ 0.82565546 -0.70937145 -2.4308236  -0.69326574  2.1498222   3.5566092\n -0.7672827   1.3943962   2.1601155  -0.889335  ]"",""42"":""[ 1.1505744  -0.7346123  -2.652294    0.09838042  2.1891723   4.025036\n -0.1266868   1.0526413   1.5353379  -0.96375185]"",""43"":""[ 0.9004548  -0.79810816 -2.496885   -0.24936427  1.9559941   3.6586175\n -0.7094758   1.1439573   1.9856642  -0.7856289 ]"",""44"":""[ 1.0480274  -0.79289764 -2.501328   -0.1670797   2.0111978   3.5840678\n -0.54621184  1.1908486   1.7363322  -0.9389377 ]"",""45"":""[ 1.3928     -0.31565666 -1.7365407  -1.3372985   2.5323758   2.180313\n -1.8208143   1.7876433   2.8919039  -1.314068  ]"",""46"":""[ 0.76689816 -0.756045   -3.1528015  -0.35683733  2.2734141   5.170609\n -0.05580983  0.727801    2.399883   -0.25853157]"",""47"":""[ 0.74164003 -0.3952294  -2.8502638   0.02657179  2.7859497   4.754133\n  0.32960624  1.0922079   1.867564   -0.8454043 ]"",""48"":""[ 0.9601792  -0.360559   -2.6441972  -0.30767253  2.981227    4.6723375\n  0.25912845  1.3502926   1.8611784  -0.8926032 ]"",""49"":""[ 2.0210721  -0.36280024 -2.8904018   1.5936834   2.20517     3.9997547\n  1.1509217  -0.01488148  1.182969   -1.5699044 ]"",""50"":""[ 1.6762242  -0.4647224  -2.7807713   1.3483226   2.154237    4.105919\n  0.67637986  0.14520815  1.3028605  -1.4042007 ]"",""51"":""[ 1.9700636  -1.2786062  -3.3372529  -0.82536066  1.1548773   5.073437\n -0.40270996  0.36115763  2.9077647  -0.57496476]"",""52"":""[ 1.0180107  -0.3250754  -2.9521427   0.06307273  2.5464897   5.0086484\n  0.2961138   0.6378943   1.9474036  -0.9384194 ]"",""53"":""[ 1.5757258  -0.7271802  -2.8322477   0.58243763  2.4304338   4.165495\n  0.76688683  0.6761956   1.488534   -1.1287483 ]"",""54"":""[ 1.2682073 -0.4940333 -1.7659974 -1.3232979  2.4144642  2.487249\n -1.6963983  1.7836745  2.8413193 -1.3150549]"",""55"":""[ 1.0313203  -0.7244954  -2.4988883  -1.0231373   2.075525    3.4905577\n -0.8384757   1.2632551   2.4409304  -0.88045275]"",""56"":""[ 2.2023683  -0.48652938 -2.7475085   1.654618    2.0776885   3.955207\n  1.0305375  -0.19537055  1.2315829  -1.4535395 ]"",""57"":""[ 1.7607344  -1.0753969  -3.5108924  -0.8667262   1.3713224   5.240984\n -0.47931817  0.1791222   3.0468812  -0.5454933 ]"",""58"":""[ 2.0248196  -0.7748204  -2.7248929   1.2888579   2.2443843   3.7992058\n  1.1518409   0.25997755  1.3717571  -1.3787017 ]"",""59"":""[ 1.6230772 -0.5080986 -2.7959955  1.2678542  2.2147171  4.105374\n  0.6860389  0.2352016  1.3216403 -1.3862381]"",""60"":""[ 2.2864487  -0.65586245 -2.6665924   1.7479863   1.9864228   3.8722467\n  1.0115845  -0.28500807  1.3623782  -1.3141781 ]"",""61"":""[ 1.1048493  -0.68656844 -2.1451292  -0.8902925   2.3093398   3.2920046\n -1.0669261   1.55013     2.3010027  -0.925799  ]"",""62"":""[ 1.336848  -0.3308494 -1.717186  -1.6788344  2.3976367  2.4026592\n -1.7364471  1.7461413  2.6894405 -1.2999924]"",""63"":""[ 1.3592288  -0.45066234 -1.8196588  -1.5700679   2.3752675   2.4403782\n -1.5768839   1.7611593   2.5920467  -1.2936316 ]"",""64"":""[ 1.4649352  -0.9083528  -2.8070786  -0.57504076  2.6313322   4.4982414\n  0.4156839   1.2120965   1.7249643  -0.8558086 ]"",""65"":""[ 0.93097866 -0.65933514 -2.1931727  -0.6487154   2.2578597   3.3853638\n -1.0233494   1.4598215   2.2274756  -0.8794033 ]"",""66"":""[ 1.3014479  -0.30410248 -1.7181631  -1.2047027   2.5372858   2.4718084\n -1.8383749   1.7152923   2.9042964  -1.2400535 ]"",""67"":""[ 1.9076174  -1.1799316  -3.4094915  -0.96610725  1.2309238   5.105623\n -0.5487925   0.2885564   3.0360408  -0.46952415]"",""68"":""[ 0.7636701  -0.3853996  -2.8744614  -0.26424745  2.3997445   4.945104\n -0.1701073   0.6494534   2.5146956  -0.725737  ]"",""69"":""[ 2.2119799  -0.6095973  -2.5766597   1.5435578   1.9967839   3.9526243\n  0.85875314 -0.22464158  1.3394423  -1.3089184 ]"",""70"":""[ 1.8239037 -1.1436795 -3.3968272 -0.8223726  1.3270026  5.12415\n -0.4399569  0.2844271  2.9340827 -0.5089538]"",""71"":""[ 2.3753352  -0.7268397  -2.8760464   1.7179924   2.1826162   3.7494652\n  1.3371959  -0.05577353  1.3671153  -1.3979515 ]"",""72"":""[ 1.524062   -0.6760143  -2.873177   -0.15600781  2.5905445   4.869757\n  0.47366235  0.85606545  1.6312227  -0.88981676]"",""73"":""[ 1.9266127  -1.182631   -3.4307332  -0.9870974   1.2236974   5.1259055\n -0.5696708   0.31073517  3.0545104  -0.5008899 ]"",""74"":""[ 0.6269165  -0.4163177  -2.8736703   0.44919777  2.4235747   4.6376915\n  0.06013241  0.8458937   1.8671954  -0.8243657 ]"",""75"":""[ 1.5135095 -0.6036907 -2.756597   0.5013716  2.6282482  4.279426\n  0.7633551  0.8354828  1.5457261 -1.0475597]"",""76"":""[ 0.6402508  -0.3302169  -2.8733716   0.14955571  2.415059    5.026474\n -0.12036193  0.65749556  2.230642   -0.67964226]"",""77"":""[ 1.3474396  -0.35698166 -1.6401241  -1.5551887   2.4461594   2.3502374\n -1.8777908   1.8131897   2.8871636  -1.3794996 ]"",""78"":""[ 0.80095714 -0.73397636 -2.7972813  -0.49384105  2.186923    4.919885\n -0.44803238  0.64325196  2.7998056  -0.40960687]"",""79"":""[ 0.86260307 -0.9862839  -2.8216238  -0.6024187   2.178412    4.7540846\n -0.3281863   0.8524396   2.5237372  -0.28695878]"",""80"":""[ 1.2395365  -0.70120364 -2.7063878  -0.6340379   2.815991    4.536371\n  0.27842122  1.394333    1.834762   -0.83967465]""},""topic"":{""0"":-1,""1"":-1,""2"":-1,""3"":-1,""4"":-1,""5"":3,""6"":-1,""7"":-1,""8"":5,""9"":5,""10"":-1,""11"":-1,""12"":2,""13"":3,""14"":-1,""15"":4,""16"":4,""17"":-1,""18"":5,""19"":3,""20"":4,""21"":-1,""22"":5,""23"":2,""24"":5,""25"":2,""26"":-1,""27"":-1,""28"":2,""29"":0,""30"":2,""31"":3,""32"":3,""33"":3,""34"":-1,""35"":5,""36"":2,""37"":0,""38"":-1,""39"":-1,""40"":2,""41"":3,""42"":3,""43"":3,""44"":3,""45"":0,""46"":5,""47"":4,""48"":4,""49"":2,""50"":2,""51"":1,""52"":4,""53"":-1,""54"":0,""55"":3,""56"":2,""57"":1,""58"":2,""59"":2,""60"":2,""61"":3,""62"":0,""63"":0,""64"":4,""65"":3,""66"":0,""67"":1,""68"":-1,""69"":2,""70"":1,""71"":2,""72"":-1,""73"":1,""74"":-1,""75"":-1,""76"":5,""77"":0,""78"":-1,""79"":5,""80"":4},""exemplar"":{""0"":null,""1"":null,""2"":null,""3"":null,""4"":null,""5"":null,""6"":null,""7"":null,""8"":null,""9"":""*"",""10"":null,""11"":null,""12"":null,""13"":null,""14"":null,""15"":null,""16"":""*"",""17"":null,""18"":null,""19"":null,""20"":""*"",""21"":null,""22"":""*"",""23"":null,""24"":""*"",""25"":""*"",""26"":null,""27"":null,""28"":""*"",""29"":""*"",""30"":null,""31"":null,""32"":""*"",""33"":""*"",""34"":null,""35"":""*"",""36"":""*"",""37"":""*"",""38"":null,""39"":null,""40"":null,""41"":""*"",""42"":null,""43"":null,""44"":""*"",""45"":null,""46"":""*"",""47"":null,""48"":""*"",""49"":null,""50"":null,""51"":""*"",""52"":null,""53"":null,""54"":""*"",""55"":""*"",""56"":""*"",""57"":""*"",""58"":""*"",""59"":null,""60"":null,""61"":null,""62"":""*"",""63"":""*"",""64"":""*"",""65"":null,""66"":null,""67"":""*"",""68"":null,""69"":null,""70"":""*"",""71"":null,""72"":null,""73"":""*"",""74"":null,""75"":null,""76"":""*"",""77"":""*"",""78"":null,""79"":null,""80"":""*""},""word*"":{""0"":""search"",""1"":""clips"",""2"":""group"",""3"":""collaborative"",""4"":""participants"",""5"":""marquee"",""6"":""groups"",""7"":""text"",""8"":""tasks"",""9"":""terms*"",""10"":""ability"",""11"":""browser"",""12"":""m"",""13"":""feature"",""14"":""clutter"",""15"":""clip"",""16"":""containers*"",""17"":""figure"",""18"":""session"",""19"":""button"",""20"":""container*"",""21"":""record"",""22"":""orientation*"",""23"":""d"",""24"":""task*"",""25"":""c*"",""26"":""tabletops"",""27"":""pages"",""28"":""r*"",""29"":""created*"",""30"":""t"",""31"":""a"",""32"":""touch*"",""33"":""typing*"",""34"":""median"",""35"":""interaction*"",""36"":""j*"",""37"":""located*"",""38"":""challenge"",""39"":""average"",""40"":""k"",""41"":""direct*"",""42"":""buttons"",""43"":""hand"",""44"":""pressing*"",""45"":""reported"",""46"":""participant*"",""47"":""space"",""48"":""reuse*"",""49"":""chi"",""50"":""uist"",""51"":""2006*"",""52"":""applications"",""53"":""color"",""54"":""commented*"",""55"":""popular*"",""56"":""shen*"",""57"":""2005*"",""58"":""f*"",""59"":""carpendale"",""60"":""usa"",""61"":""introduce"",""62"":""held*"",""63"":""opens*"",""64"":""file*"",""65"":""learn"",""66"":""felt"",""67"":""2008*"",""68"":""management"",""69"":""ieee"",""70"":""2004*"",""71"":""wa"",""72"":""copies"",""73"":""2010*"",""74"":""affordances"",""75"":""4x6"",""76"":""inputs*"",""77"":""viewed*"",""78"":""plan"",""79"":""trip"",""80"":""export*""},""pos"":{""0"":1,""1"":2,""2"":3,""3"":4,""4"":5,""5"":1,""6"":6,""7"":7,""8"":1,""9"":2,""10"":8,""11"":9,""12"":1,""13"":2,""14"":10,""15"":1,""16"":2,""17"":11,""18"":3,""19"":3,""20"":3,""21"":12,""22"":4,""23"":2,""24"":5,""25"":3,""26"":13,""27"":14,""28"":4,""29"":1,""30"":5,""31"":4,""32"":5,""33"":6,""34"":15,""35"":6,""36"":6,""37"":2,""38"":16,""39"":17,""40"":7,""41"":7,""42"":8,""43"":9,""44"":10,""45"":3,""46"":7,""47"":4,""48"":5,""49"":8,""50"":9,""51"":1,""52"":6,""53"":18,""54"":4,""55"":11,""56"":10,""57"":2,""58"":11,""59"":12,""60"":13,""61"":12,""62"":5,""63"":6,""64"":7,""65"":13,""66"":7,""67"":3,""68"":19,""69"":14,""70"":4,""71"":15,""72"":20,""73"":5,""74"":21,""75"":22,""76"":8,""77"":8,""78"":23,""79"":9,""80"":8},""x2D"":{""0"":4.7763838768,""1"":2.5627965927,""2"":1.4136506319,""3"":1.2281494141,""4"":1.9692676067,""5"":5.5866279602,""6"":2.0657744408,""7"":3.5785169601,""8"":1.7032790184,""9"":1.9510645866,""10"":1.0026540756,""11"":3.3079915047,""12"":0.3060833216,""13"":5.5683274269,""14"":2.2581422329,""15"":2.1154165268,""16"":2.5412828922,""17"":1.2699751854,""18"":1.7598091364,""19"":5.0937623978,""20"":2.5646867752,""21"":1.5400627851,""22"":1.6182118654,""23"":0.326086998,""24"":1.1293789148,""25"":0.453096211,""26"":3.0456740856,""27"":2.7808122635,""28"":0.6425048113,""29"":-12.1094455719,""30"":0.1568210125,""31"":5.510383606,""32"":5.3590636253,""33"":5.000433445,""34"":1.2452862263,""35"":1.4628334045,""36"":0.9138526917,""37"":-11.8902111053,""38"":1.7506638765,""39"":1.2287429571,""40"":0.5232586265,""41"":5.5084576607,""42"":4.6591210365,""43"":5.1411442757,""44"":5.2898702621,""45"":-11.8184537888,""46"":1.7103347778,""47"":2.4130609035,""48"":2.3463573456,""49"":1.0406048298,""50"":1.2347909212,""51"":-0.2670689821,""52"":2.5864982605,""53"":3.4563932419,""54"":-11.7290554047,""55"":5.8056168556,""56"":1.3155370951,""57"":-0.460190624,""58"":0.6770252585,""59"":1.051815629,""60"":1.3070440292,""61"":5.8819065094,""62"":-12.1402606964,""63"":-11.9637470245,""64"":2.2523627281,""65"":5.6654276848,""66"":-11.6444101334,""67"":-0.2075152844,""68"":1.3951759338,""69"":1.1896499395,""70"":-0.4291196167,""71"":1.014765501,""72"":2.9536523819,""73"":-0.1726268828,""74"":2.157109499,""75"":3.3734879494,""76"":1.6051462889,""77"":-12.069393158,""78"":0.868868947,""79"":1.109592557,""80"":2.1937553883},""y2D"":{""0"":-5.2228097916,""1"":-2.6518688202,""2"":-5.8387169838,""3"":-4.8213467598,""4"":-5.2507266998,""5"":-6.1566848755,""6"":-5.0112838745,""7"":-3.5676808357,""8"":-4.8940234184,""9"":-4.655040741,""10"":-5.6048254967,""11"":-3.9672648907,""12"":14.7782087326,""13"":-6.2289290428,""14"":-3.7163360119,""15"":-2.6427826881,""16"":-3.4099032879,""17"":-6.3010473251,""18"":-5.9199671745,""19"":-4.9558119774,""20"":-3.0383048058,""21"":-3.3472955227,""22"":-5.4332900047,""23"":14.5318756104,""24"":-5.592294693,""25"":14.545176506,""26"":-3.469037056,""27"":-3.6654736996,""28"":15.0729808807,""29"":-4.5193009377,""30"":14.3637609482,""31"":-5.8685383797,""32"":-5.6112070084,""33"":-5.0578770638,""34"":-6.2151446342,""35"":-4.6953415871,""36"":14.8816919327,""37"":-4.7384257317,""38"":-6.2705116272,""39"":-6.3138780594,""40"":14.8913040161,""41"":-5.729552269,""42"":-4.7373600006,""43"":-5.3580012321,""44"":-5.2208161354,""45"":-4.8095932007,""46"":-5.6471571922,""47"":-3.7166876793,""48"":-3.1943304539,""49"":14.5423688889,""50"":14.3986616135,""51"":-5.5342922211,""52"":-4.1736688614,""53"":-3.3161048889,""54"":-4.8982195854,""55"":-5.9227814674,""56"":14.7270584106,""57"":-5.7709293365,""58"":14.5161581039,""59"":14.1626815796,""60"":14.9149169922,""61"":-6.1347522736,""62"":-4.4885191917,""63"":-4.6649332047,""64"":-2.7614338398,""65"":-5.9118881226,""66"":-4.9810576439,""67"":-5.5381836891,""68"":-5.074862957,""69"":15.0230560303,""70"":-5.7206478119,""71"":14.9993133545,""72"":-3.1762490273,""73"":-5.6202230453,""74"":-4.2929334641,""75"":-3.4565024376,""76"":-4.7381663322,""77"":-4.55919981,""78"":-5.8126950264,""79"":-6.0200781822,""80"":-2.8982954025}}",False,False,False,http://portal.acm.org/citation.cfm?doid=1718918.1718987,,WeSearch: supporting collaborative search and sensemaking on a tabletop display,L239LNLV,False,False
YA4MYR2A,UPR74L2P,"Eurographics Conference on Visualization (EuroVis) (2015)
R. Borgo, F. Ganovelli, and I. Viola (Editors)

STAR – State of The Art Report

Visualizing High-Dimensional Data:

Advances in the Past Decade

S. Liu1, D. Maljovec1, B. Wang1, P.-T. Bremer2 and V. Pascucci1

1Scientiﬁc Computing and Imaging Institute, University of Utah

2Lawrence Livermore National Laboratory

Abstract
Massive simulations and arrays of sensing devices, in combination with increasing computing resources, have
generated large, complex, high-dimensional datasets used to study phenomena across numerous ﬁelds of study.
Visualization plays an important role in exploring such datasets. We provide a comprehensive survey of advances
in high-dimensional data visualization over the past 15 years. We aim at providing actionable guidance for data
practitioners to navigate through a modular view of the recent advances, allowing the creation of new visualiza-
tions along the enriched information visualization pipeline and identifying future opportunities for visualization
research.

Categories and Subject Descriptors (according to ACM CCS):
Generation—Line and curve generation

I.3.3 [Computer Graphics]: Picture/Image

1

Introduction

With the ever-increasing amount of available computing
resources, our ability to collect and generate a wide vari-
ety of large, complex, high-dimensional datasets continues
to grow. High-dimensional datasets show up in numerous
ﬁelds of study, such as economy, biology, chemistry, polit-
ical science, astronomy, and physics, to name a few. Their
wide availability, increasing size and complexity have led
to new challenges and opportunities for their effective vi-
sualization. The physical limitations of the display devices
and our visual system prevent the direct display and instanta-
neous recognition of structures with higher dimensions than
two or three. In the past decade, a variety of approaches have
been introduced to visually convey high-dimensional struc-
tural information by utilizing low-dimensional projections
or abstractions: from dimension reduction to visual encod-
ing, and from quantitative analysis to interactive exploration.
A number of surveys have focused on different aspects of
high-dimensional data visualization, such as parallel coordi-
nates [Ins09, HW13], quality measures [BTK11], clutter re-
duction [ED07], visual data mining [HG02, Kei02, DOL03],
and interactive techniques [BCS96]. High-dimensional as-
pects of scientiﬁc data have also been investigated within the
surveys [BH07,KH13]. The surveys [WB94,Cha06,Mun14]
focus on the various aspects of visual encoding techniques

c(cid:13) The Eurographics Association 2015.

for multivariate data. These papers provide a valuable sum-
mary of existing techniques and inspiring discussions of fu-
ture directions in their respective domains. However, few
surveys in the past decade have aimed at providing a general,
coherent, and uniﬁed picture that addresses the full spectrum
of techniques for visualizing high-dimensional data.

We provide a comprehensive survey of advances in high-
dimensional data visualization over the past 15 years, with
the following objectives: providing actionable guidance for
data practitioners to navigate through a modular view of the
recent advances, allowing the creation of new visualizations
along the enriched information visualization pipeline, and
identifying opportunities for future visualization research.

Our contributions are as follows. First, we propose a cat-
egorization of recent advances based on the information vi-
sualization (InfoVis) pipeline [CMS99] enriched with cus-
tomized action-driven classiﬁcations (Figure 2, Section 2).
We further assess the amount of interplay between user in-
teractions and pipeline-based categorization and put user in-
teractions into a measurable context (Table 1, Section 6).
Second, we highlight key contributions of each advancement
(Sections 3, Section 4, Section 5). In particular, we provide
an extensive survey of visualization techniques derived from
topological data analysis (Section 3.5, Section 4.4), a new
area of study that provides a multi-scale and coordinates-

S. Liu, D. Maljovec, B. Wang, P.-T Bremer & V. Pascucci / Visualizing High-Dimensional Data:Advances in the Past Decade

free summary of high-dimensional data [Car09]. Further-
more, we connect advances in high-dimensional data visu-
alization with volume rendering and machine learning (Sec-
tion 7). Finally, we reﬂect on our categorization with respect
to actionable tasks, and identify emerging future directions
in subspace analysis, model manipulation, uncertainty quan-
tiﬁcation, and topological data analysis (Section 8).

Figure 1: Interactive survey website for paper navigation.

2 Survey Method and Categorization

We conduct a thorough literature review based on relevant
works from major visualization venues, namely Visweek,
EuroVis, PaciﬁcVis, and the journal IEEE Transactions on
Visualization and Computer Graphics (TVCG) from the pe-
riod between 2000 and 2014. To ensure the survey covers
the state-of-the-art, we further selectively search through ref-
erences within the initial set of papers. Beyond the visual-
ization ﬁeld, we also dedicate special attention to the ex-
ploratory data analysis techniques in the statistics commu-
nity. Through such a rigorous search process, we have iden-
tiﬁed more than 200 papers that focus on a wide spectrum
of techniques for high-dimensional data visualization. To
help organize the large quantity of papers, we have produced
an interactive survey website (www.sci.utah.edu/
~shusenl/highDimSurvey/website, based on the
SurVis [Bec14] framework; a screen shot is shown in Fig-
ure 1) that allows readers to interactively select and ﬁlter
papers through various tags. However, due to the space limi-
tation, only a subset of the complete list of references (avail-
able through the survey website) is mentioned in the paper.
As illustrated in Figure 2, we base our main catego-
rization on the three transformation steps of the informa-
tion visualization pipeline [CMS99] (and its minor varia-
tion in [BTK11]), namely, data transformation, visual map-
ping, and view transformation. Each category is enriched
with novel, customized subcategories. Data transformation
(Section 3) corresponds to the analysis-centric methods such
as dimension reduction, regression, subspace clustering, fea-
ture extraction, topological analysis, data sampling, and ab-
straction. Visual mapping (Section 4), the key for most vi-
sual encoding tasks, focuses on organizing the information
from the data transformation stage for visual representa-

tion. This category includes visual encodings based on axes
(e.g., scatterplots and parallel coordinate plots), glyphs, pix-
els, and hierarchical representations; together with anima-
tion and perception. View transformation (Section 5) corre-
sponds to methods focusing on screen space and rendering,
including illustrative rendering for various visual structures,
as well as screen space measures for reducing clutter or arti-
facts and highlighting important features.

Such a design allows us to easily classify the core con-
tribution of vastly different methods that operate on en-
tirely different objects, but at the same time, reveal their
interconnections through the linked pipeline. In addition,
the pipeline-based categorization provides the reader with
a modular view of the recent advances, allowing new sys-
tems to be conﬁgured based on possibilities provided by the
reviewed methods.

User interactivity is an integral part within each pro-
cessing step of the pipeline, as illustrated in Figure 2.
Based on the amount of user interaction, we can classify
all high-dimensional data visualization methods into three
categories: computation-centric, interactive exploration, and
model manipulation. The distinction between interactive ex-
ploration and model manipulation is made to emphasize a
particular manipulation paradigm, where the underlying data
model is modiﬁed based on interaction to reﬂect user inten-
tion. A summary of the interplay between processing steps
and interactions is illustrated in Table 1, where user interac-
tions are put into a measurable context. The corresponding
details are discussed in Section 6.

3 Data Transformation

We start by describing different types of high-dimensional
datasets. We then give an in-depth discussion on the action-
driven subcategories centered around typical analysis tech-
niques during data transformation, namely, dimension re-
duction, clustering (in particular, subspace clustering) and
regression analysis. We focus especially on their usages in
visualization methods. In addition, we pay special attention
to topological data analysis, which is a promising emerging
ﬁeld.
3.1 High-Dimensional Data

We provide an overview of the different aspects of high-
dimensional datasets, to deﬁne the scope of our discussion
and highlight distinct properties of these datasets. Our dis-
cussions on different data types are inspired by the book by
Munzner [Mun14].
Data Types. In our survey, we limit our exposition to
table-based data, and exclude (potentially high-dimensional)
graph/network data from the discussion. A high-dimensional
dataset is commonly modeled as a point cloud embedded in
a high-dimensional space, with the values of attributes cor-
responding to the coordinates of the points. Based on the un-
derlying model of the data and the analysis and visualization

c(cid:13) The Eurographics Association 2015.

S. Liu, D. Maljovec, B. Wang, P.-T Bremer & V. Pascucci / Visualizing High-Dimensional Data:Advances in the Past Decade

Figure 2: Categorization based on transformation steps within the information visualization pipeline, with customized action-
driven subcategories.

goals, the attributes consist of input parameters and output
observations, and the data could be modeled as a scalar or
vector-valued function (where the function values are based
on the output observations) on the point cloud deﬁned by the
input parameters. Topological data analysis (Section 3.5) ap-
plies to both point cloud data and functions on point cloud
data (e.g., [GBPW10, SMC07]), while regression analysis
(Section 3.4) typically applies to the latter (e.g., [PBK10]).
Attribute Types. The attribute type (e.g., nominal vs. nu-
merical) can greatly impact the visualization method. In
many ﬁelds and applications, the value of the attributes is
nominal in nature. However, most commonly available high-
dimensional data visualization techniques such as scatter-
plots or parallel coordinate plots are designed to handle
numerical values only. When utilizing these methods for
visualizing nominal data, information overlapping and vi-
sual elements stacking usually exist. One way to address
the challenge is mapping the nominal values to numeri-
cal values [RRB∗04] (e.g. as implemented in the Xmdv-
Tool [War94]). Through such a mapping, each axis is used
more efﬁciently and the spacing becomes more meaningful.
In the Parallel Sets work [BKH05], the authors introduce a
new visual representation that adapts the notion of parallel
coordinates but replaces the data points with a frequency-
based visual representation that is designed for nominal
data. The Conjunctive Visual Form [Wea09] allows users to
rapidly query nominal values with certain conjunctive rela-
tionships through simple interactions. The GPLOM (Gener-
alized Plot Matrix) [IML13] extends the Scatterplot Matrix
(SPLOM) to handle nominal data.
Spatiotemporal Data. Some recent advances focus on de-
veloping visual encoding that capture the spatiotemporal as-

c(cid:13) The Eurographics Association 2015.

pects of high-dimensional data. Visual analysis of the ﬁnan-
cial time series data is explored in the work by Ziegler et
al. [ZJGK10]. The work presented by Tam et al. [TFA∗11]
studies facial dynamics utilizing the analysis of time-series
data in parameter space. Datasets with spatial information
such as multivariate volumes [BDSW13] or multi-spectral
images [LAK∗11] are very common in scientiﬁc visualiza-
tion, and numerous methods have been introduced within the
scientiﬁc visualization domain, see [BH07, KH13] for com-
prehensive surveys on these topics. We discuss the intrinsic
interconnections between these two areas in Section 7.
3.2 Dimension Reduction

Dimension reduction techniques are key components for
many visualization tasks. Existing work either extends the
state-of-the-art techniques, or improves upon their capabili-
ties with additional visual aid.
Linear Projection. Linear projection uses linear transfor-
mation to project the data from a high-dimensional space to
a low-dimensional one. It includes many classical methods,
such as Principal component analysis (PCA), Multidimen-
sional scaling (MDS), Linear discriminate analysis (LDA),
and various factor analysis methods.

PCA [Jol05] is designed to ﬁnd an orthogonal linear
transformation that maximizes the variance of the result-
ing embedding. PCA can be calculated by an eigende-
composition of the data’s covariance matrix or a singular
value decomposition of the data matrix. The interactive PCA
(iPCA) [JZF∗09] introduces a system that visualizes the re-
sults of PCA using multiple coordinated views. The system
allows synchronized exploration and manipulations among
the original data space, the eigenspace, and the projected
space, which aids the user in understanding both the PCA

Source DataData TransformationViewTransformationVisualMappingTransformedDataVisualStructureViewsUserUser InteractionsDimension Reduction linear projection[KC03], non-linear DR[WM04],Control Points Projection[DST04],Distance Metric[LMZ∗14], Precision Measures[LV09]Data TransformationVisual MappingView TransformationAxis BasedScatterplot Matrix[WAG06],Parallel Coordinate[JJ09],Radial Layout[LT13],Hybrid Construction[YGX∗09, CvW11]Illustrative RenderingIllustrative PCP[MM08], Illuminated 3D scatterplot[SW09],PCP density basedtransfer function[JLJC05]Subspace ClusteringDimension Space Exploration [TFH11, YRWG13],Subset of Dimension[TMF∗12],Non-Axis-Parallel Subspace[Vid11, AWD12]Topological Data AnalysisMorse-Smale Complex[GBPW10, CL11],Reeb Graph & Contour Tree[PSBM07],Topological Features[WSPVJ11]Regression AnalysisOptimization & Design Steering[BPFG11, DW13],Structural Summaries[PBK10, GBPW10]GlyphsPer-Element Glyphs[CCM10, GWRR11][CCM13],Multi-Object Glyphs [War08, CGSQ11]Pixel-OrientedJigsaw Map,Pixel Bar Charts[KHL01],Value & RelationDispaly[YHW∗07]Hierarchy BasedDimension Hierarchy[WPWR03], Topology-based Hierarchy[HW10, OHWS13],Others[ERHH11]AnimationGGobi[SLBC03],TripAdvisorND[NM13],Rolling the Dice[EDF08]EvaluationScatterplot Guideline[SMT13],PCPs Effectiveness,[HVW10],Animation [HR07]Continuous Visual RepresentationContinuous Scatterplot[BW08], Continuous Parallel Coordiante[HW09, LT11],Splatterplots[MG13]Accurate Color BlendingHue-Preserving Blending[KGZ∗12],Weaving vs. Blending[HSKIH07]Image Space MetricsClutter Reduction[AdOL04, JC08],Pargnostics[DK10],Pixnostic[SSK06]S. Liu, D. Maljovec, B. Wang, P.-T Bremer & V. Pascucci / Visualizing High-Dimensional Data:Advances in the Past Decade

process and the dataset. When visualizing labeled data, class
separation is usually desired. Methods such as LDA aim to
provide a linear projection that maximizes the class separa-
tion. The recent work by Koren et. al. [KC03] generalizes
PCA and LDA by providing a family of ﬂexible linear pro-
jections to cope with different kinds of data.
Non-linear Dimension Reduction. There are two distinct
groups of techniques in non-linear dimension reduction, un-
der either the metric or non-metric setting. The graph-based
techniques are designed to handle metric inputs, such as
Isomap [TDSL00], Local Linear Embedding (LLE) [RS00],
and Laplacian Eigenmap (LE) [BN03], where a neighbor-
hood graph is used to capture local distance proximities and
to build a data-driven model of the space.

The other group of techniques address non-metric prob-
lems commonly referred to as non-metric MDS or stress-
based MDS by capturing non-metric dissimilarities. The
fundamental idea behind the non-metric MDS is to mini-
mize the mapping error directly through iterative optimiza-
tions. The well-known Shepard-Kruskal algorithm [Kru64]
begins by ﬁnding a monotonic transformation that maps the
non-metric dissimilarities to the metric distances, which pre-
serves the rank-order of dissimilarity. Then, the resulting
embedding is iteratively improved based on stress. The pro-
gressive and iterative nature of these methods has been ex-
ploited recently by Williams et al. [WM04], where the user
is presented with a coarse approximation from partial data.
The reﬁnement is on-demand based on user inputs.
Control Points Based Projection. For handling large and
complex datasets, the traditional linear or non-linear di-
mension reductions are limited by their computational efﬁ-
ciency. Some recent developments, e.g., [DST04, PNML08,
PEP∗11a, JPC∗11, PSN10], utilize a two-phases approach,
where the control points (anchor points) are projected ﬁrst,
followed by the projection of the rest of the points based on
the control points location and local features preservation.
Such designs lead to a much more scalable system. Further-
more, the control points allow the user to easily manipulate
and modify the outcome of the dimension reduction compu-
tation to achieve desirable results.
Distance Metric. For a given dimension reduction algo-
rithm, a suitable distance metric is essential for the com-
putation outcome as it is more likely to reveal important
structural information. Brown et al. [BLBC12] introduce
the distance function learning concept, where a new dis-
tance metric is calculated from the manipulation of point
layouts by an expert user. In [Gle13], the author attempts
to associate a linear basis with a certain meaningful con-
cept constructed based on user-deﬁned examples. Machine
learning techniques can then be employed to ﬁnd a set of
simple linear bases that achieve an accurate projection ac-
cording to the prior examples. The structure-based analysis
method [LMZ∗14] introduces a data-driven distance metric

inspired by the perceptual processes of identifying distance
relationships in parallel coordinates using polylines.
Dimension Reduction Precision Measure. One of the fun-
damental challenges in dimension reduction is assessing and
measuring the quality of the resulting embeddings. Lee et al.
introduce the ranking-based metric [LV09] that assesses the
ranking discrepancy before and after applying dimension re-
duction. This technique is then generalized [MLGH13] and
used for visualizing dimension reduction quality. A projec-
tion precision measure is introduced in [SvLB10], where a
local precision score is calculated for each point with a cer-
tain neighborhood size. In the distortion-guided exploration
work [LWBP14], several distortion measures are proposed
for different dimension reduction techniques, where these
measures aid in understanding the cause of highly distorted
areas during interactive manipulation and exploration. For
MDS, the stress can be used as a precision measure. Seifert
et al. [SSK10] further develop this idea by incorporating the
analysis and visualization for better understanding of the lo-
calized stress phenomena.
3.3 Subspace Clustering

Clustering is one of the most widely used data-driven
analysis methods. Instead of providing an in-depth discus-
sion on all clustering techniques, in this survey, we fo-
cus on subspace clustering techniques which have a great
impact for understanding and visualizing high-dimensional
datasets. Dimension reduction aims to compute one sin-
gle embedding that best describes the structure of the data.
However, this could become ineffective due to the increas-
ing complexity of the data. Alternatively, one could perform
subspace clustering, where multiple embeddings can be gen-
erated through clustering either the dimensions or the data
points, for capturing various aspects of the data.
Dimension Space Exploration. Guided by the user, dimen-
sion space exploration methods interactively group relevant
dimensions into subsets. Such exploration allows us to better
understand their relationships and to identify shared patterns
among the dimensions. Turkay et al. introduce a dual visual
analysis model [TFH11] where both the dimension embed-
ding and point embedding can be explored simultaneously.
Their later improvement [TLLH12] allows for the group-
ing of a collection of dimensions as a factor, which per-
mits effective exploration of the heterogeneous relationships
among them. The Projection Matrix/Tree work [YRWG13]
extends a similar concept to allow a recursive exploration of
both the dimension space and data space. Several visual en-
coding methods also rely on the concept of dimension space
exploration. These methods are discussed in Section 4.3.
Clustering Subsets of Dimensions. Comparing to the di-
mension space exploration, where the user is responsible
for identifying patterns and relationships, subspace clus-
tering/ﬁnding methods automatically group related dimen-
sions into clusters. Subspace clustering ﬁlters out the in-
terferences introduced by irrelevant dimensions, allowing

c(cid:13) The Eurographics Association 2015.

S. Liu, D. Maljovec, B. Wang, P.-T Bremer & V. Pascucci / Visualizing High-Dimensional Data:Advances in the Past Decade

lower-dimensional structures to be discovered. These meth-
ods, such as ENCLUS [CFZ99], originate from the data
mining and knowledge discovery community. They in-
troduce some very interesting exploration strategies for
high-dimensional datasets, and can be particularly effec-
tive when the dimensions are not
tightly coupled. The
TripAdvisorND [NM13] system employs a sightseeing
metaphor for high-dimensional space navigation and explo-
ration. It utilizes subspace clustering to identify the sights
for the exploration. The subspace search and visualization
work [TMF∗12] utilizes the SURFING (subspaces rele-
vant for clustering) [BPR∗04] algorithm to search the high-
dimensional space and automatically identiﬁes a large can-
didate set of interesting subspaces. For the work presented
by Ferdosi et al. [FBT∗10], morphological operators are ap-
plied on the density ﬁeld generated from the (3D) PCA pro-
jection of the high-dimensional data for identifying subspace
clusters.
Non-Axis-Aligned Subspaces. Instead of clustering the di-
mensions, which essentially creates axis-aligned linear sub-
spaces, identifying non-axis-aligned subspaces is a more
ﬂexible alternative. Projection Pursuit [FT74] is one of the
earliest works aimed at automatically identifying the inter-
esting non-axis-aligned subspaces. Projections are consid-
ered to be more interesting when they deviate more from a
normal distribution. Some advances have been made in the
machine learning community to perform non-axis-aligned
subspace clustering [Vid11]. Instead of clustering the dimen-
sions, the points are grouped together for sharing similar lin-
ear subspaces. In particular, we assume the complex struc-
ture of the data can be approximated by a mixture of linear
subspaces (of varying dimensions), and each of the linear
subspaces corresponds to a set of points where their rela-
tionships can be approximately captured by the same linear
subspace.

For very high-dimensional data, the subspace ﬁnding
algorithms typically have a relatively high computational
complexity. By utilizing random projection, Anand et
al. [AWD12] introduce an efﬁcient subspace ﬁnding algo-
rithm for data with thousands of dimensions. It generates a
set of candidate subspaces through random projections and
presents the top-scoring subspaces in an exploration tool.
3.4 Regression Analysis

Regression analysis in high dimension is an extensive and
active ﬁeld of research in its own right. We make no attempt
to survey the entire area, but rather focus on the interplay
between visualization and regression analysis.
Optimization and Design Steering. Pure optimization
problems often are not the focus in the visualization com-
munity. What is more common are design steering methods
where, in addition to a multivariate input space, the user has
one or several output or response variables they want to ex-
plore (e.g., [BPFG11,TWSM∗11]), where the results require
a qualitative examination, or are used to inform decisions.

c(cid:13) The Eurographics Association 2015.

HyperMoVal [PBK10] is a software system used for val-
idating regression models against actual data. It uses sup-
port vector regression (SVR) [SS04b] to ﬁt a model to high-
dimensional data, highlights discrepancies between the data
and the model, and computes sensitivity information on the
model. The software allows for adding more model param-
eters to reﬁne their regression to an acceptable level of ac-
curacy. Berger et al. [BPFG11] utilize two different types of
regression models (SVR and nearest neighbor regression) to
analyze a trade-off study in performance car engine design.
Utilizing the predictive power of the regression, they are able
to provide a guided navigation of the high-dimensional space
centered around a user-selected focal point. The user adjusts
the focal point through multiple linked views, and sensitiv-
ity and uncertainty information are encoded around the focal
point.

Tuner [TWSM∗11] begins as an automated adaptive sam-
pling algorithm where a sparse sampling of the parame-
ter space is reﬁned by building a Gaussian Process Model
(GPM) (see [RW06] for a good overview) and using adap-
tive sampling to focus additional samples in areas with ei-
ther a high goodness of ﬁt or high uncertainty. The software
then relies heavily on user interaction to study the sensitivi-
ties with respect to each input parameter and steers the com-
putation toward the user-deﬁned optimal solution. Demir et
al. [DW13] improve the effectiveness of GPMs by utiliz-
ing a block-wise matrix inversion scheme that can be im-
plemented on the GPU, greatly increasing efﬁciency. In ad-
dition, their method involves progressive reﬁnement of the
GPM and can be halted at any point, if the improvement be-
comes insigniﬁcant.

Most of these methods convey sensitivity information
through user exploration of the input space. In Section 4.2,
explicit visual encodings for understanding sensitivity infor-
mation are also discussed.
Structural Summaries. Researchers have also used re-
gression to summarize data as in the works by Reddy et
al. [RPH08] and Gerber et al. [GBPW10]. Both methods
summarize the structures of the data via skeleton repre-
sentations. Reddy et al. [RPH08] use a clustering algo-
rithm followed by construction of a minimum spanning
tree of the cluster centroids in order to determine possible
trends in the data. These trends are then ﬁtted with princi-
ple curves [HS89] which go through the medial-axis of the
data. HDViz [GBPW10], on the other hand, approximates a
topological segmentation (for more details, see Section 3.5)
and constructs an inverse linear regression for each segment
of the data. In both examples, regression is used as a post-
processing step of the algorithms in order to present sum-
maries of the extracted subsets of the data.
3.5 Topological Data Analysis

A crucial step in gaining insights from large, complex,
high-dimensional data involves feature abstraction, extrac-
tion, and evaluation in the spatiotemporal domain for ef-

S. Liu, D. Maljovec, B. Wang, P.-T Bremer & V. Pascucci / Visualizing High-Dimensional Data:Advances in the Past Decade

fective exploration and visualization. Topological data anal-
ysis (TDA), a new ﬁeld of study (see [Zom05, BDFF∗08,
EH08,EH10,Car09,Ghr08] for seminal works and surveys),
has provided efﬁcient and reliable feature-driven analysis
and visualization capabilities. Speciﬁcally, the construction
of topological structures [Ree46, Sma61] from scalar func-
tions on point clouds (e.g., Morse-Smale complexes, con-
tour trees, and Reeb graphs) as “summaries” over data is at
the core of such TDA methods. Reeb graphs/contour trees
capture very different structural information of a real-valued
function compared to the Morse-Smale complexes as the for-
mer is contour-based and the latter is gradient-based (Figure
3). They both provide meaningful abstractions of the high-
dimensional data, which reduces the amount of data needed
to be processed or stored; and they utilize sophisticated hier-
archical representations capturing features at multiple scales,
which enables progressive simpliﬁcations of features differ-
entiating small and large scale structures in the data.
Morse-Smale Complexes. The Morse-Smale complex
(MSC) [EHNP03, EHZ03] describes the topology of a func-
tion by clustering the points in the domain into regions of
monotonic gradient ﬂow, where each region is associated
with a sink-source pair deﬁned by local minima and max-
ima of the function. The MSC can be represented using a
graph where the vertices are critical points and the edges
are the boundaries of areas of similar gradient behavior. The
simpliﬁcation of the MSC is obtained by removing pairs
of vertices in the graph and updating connectivities among
their neighboring vertices, merging nearby clusters by redi-
recting the gradient ﬂow. MSCs have been shown to be ef-
fective in identifying, ordering, and selectively removing
features of large-scale data in scientiﬁc visualizations (e.g.,
[BEHP04, GBPH08, GNP∗05]).

HDViz [GBPW10] employs an approximation of the
MSC (in high dimensions) to analyze scalar functions on
point cloud data. It creates a hierarchical segmentation of
the data by clustering points based on their monotonic ﬂow
behavior, and designs new visual metaphors based on such
a segmentation. Correa et al. [CL11] suggest that by con-
sidering a different type of neighborhood structure, we can
improve the accuracy in the extracted topology compared to
those obtained within HDViz.
Reeb Graphs and Contour Trees. The Reeb graph of a
real-valued function describes the connectivity of its level
sets. A contour tree is a special case of Reeb graph that arises
in simply-connected domains. The Reeb graph stores infor-
mation regarding the number of components at any function
value as well as how these components split and merge as the
function value changes. Such an abstraction offers a global
summary of the topology of the level sets and enables the
development of compact and effective methods for modeling
and visualizing scientiﬁc data, especially in high dimensions
(i.e., [NLC11, SMC07]).
algorithms

computing

Efﬁcient

for

the

contour

tree [CSA03] and Reeb graph [PSBM07] in arbitrary dimen-
sions have been developed. A generalization of the contour
tree has been introduced by Carr et al. [CD14, DCK∗12]
called the joint contour net (JCN), which allows for the
analysis of multi-ﬁeld data.

Figure 3: Contour- and gradient-based topological structure
of a 2D scalar function.

Other Topological Features. Ghrist [Ghr08] and Carls-
son [Car09] both offer several applications of TDA and in
particular highlight the topological theory used in a study
of statistics of natural images [LPM03]. Mapper [SMC07]
decomposes data into a simplicial complex resembling a
generalized Reeb graph, and visualizes the data using a
graph structure with varying node sizes. The software is
shown to extract salient features in a study of diabetes by
correctly classifying normal patients and patients with two
causes of diabetes. Wang et al. [WSPVJ11] utilize TDA
techniques developed by Silva et al. [dSMVJ09] to re-
cover important structures in high-dimensional data con-
taining non-trivial topology. Speciﬁcally, they are interested
in high-dimensional branching and circular structures. The
circle-valued coordinate functions are constructed to repre-
sent such features. Subsequently, they perform dimension re-
duction on the data while ensuring such structures are visu-
ally preserved.

4 Visual Mapping

Visual mapping plays an essential role in converting the
analysis result or the original dataset into visual structures
based on various visual encodings. Here, we divide the ap-
proaches based on their structural patterns, compositions,
and movements (i.e., animations). In addition, the methods
that evaluate the effectiveness of visual encoding are also
discussed.
4.1 Axis-Based Methods

Axis-based methods refer to visual mappings where el-
ement relationships are expressed through axes represent-
ing the dimensions/variables. These methods include some
of the most well-known visual mapping approaches, such as
scatterplot matrices (SPLOMs) and parallel coordinate plots
(PCPs).
Scatterplot Matrix. A scatterplot matrix, or SPLOM, is a

c(cid:13) The Eurographics Association 2015.

2D Scalar function Reeb Graph/Contour Tree/Merge Tree Morse-Smale Complex S. Liu, D. Maljovec, B. Wang, P.-T Bremer & V. Pascucci / Visualizing High-Dimensional Data:Advances in the Past Decade

collection of bivariate scatterplots that allows users to view
multiple bivariate relationships simultaneously. One of the
primary drawbacks of SPLOMs is the scalability. The num-
ber of the bivariate scatterplots increases quadratically with
respect to the dataset’s dimensionality. Numerous studies
have introduced methods for improving the scalability of
SPLOMs by automatically or semi-automatically identify-
ing more interesting plots.

Scagnostics are a set of measures designed for identify-
ing interesting plots originally introduced by John W. Tukey.
The recent works of Wilkinson et al. [WAG05, WAG06] ex-
tend the concept to include nine measures capturing proper-
ties such as outliers, shape, trend, and density. In addition,
they improve the computational efﬁciency by using graph-
theoretic measures. Scagnostics is also extended to handle
time series data [DAW13]. Guo [Guo03] introduces an inter-
active feature selection method for ﬁnding interesting plots
by evaluating the maximum conditional entropy of all pos-
sible axis-parallel scatterplots. The rank by feature frame-
work [SS04a, SS06] allows users to choose a ranking crite-
rion, such as histogram distribution properties and correla-
tion coefﬁcients between axes, for scatterplots in SPLOMs.
Data class labels can play an important role in identifying
interesting plots and selecting a meaningful ranking order.
Sips et al. utilize class consistency [SNLH09] as a quality
metric for 2D scatterplots. The class consistency measure
is deﬁned by the distance to the class’s center or entropies
of the spatial distributions of classes. Tatu et al. [TAE∗09]
introduce different metrics for ranking the “interestingness”
of scatterplots and PCPs for both classiﬁed and unclassiﬁed
datasets. For data with labels, a class density measure and a
histogram density measure are adopted as ranking functions
for the scatterplots.

The ranking order provides only an indirect way to as-
sess the scatterplots, Lehmann et al. [LAE∗12] introduces a
system for visually exploring all the plots as a whole. By re-
ordering the rows and columns in the SPLOMs, this method
groups relevant plots in the spatial vicinity of one another. In
addition, an abstraction can be obtained from the reordered
SPLOM to provide a global view.
Parallel Coordinates. Compared to a SPLOM, where only
bivariate relationships can be directly expressed, the Paral-
lel Coordinate Plot (PCP) [Ins09, ID91] allows patterns that
highlight multivariate relations to be revealed by showing
all the axes at once (typically, in a vertical layout). How-
ever, due to the linear ordering of the PCP axes, for a given
n-dimensional dataset, there are n! permutations of the or-
dering of the axes. Each of the orderings highlights certain
aspects of the high-dimensional structure. Therefore, one of
the signiﬁcant challenges when dealing with PCPs is deter-
mining an appropriate order of the axes. In addition, as the
number of points increases, the line density in the PCP in-
creases dramatically, which can lead to overplotting and vi-
sual clutter thus hindering the discovery of patterns.

c(cid:13) The Eurographics Association 2015.

A few methods have proposed metrics for ordering
the axes automatically. Tatu et al. [TAE∗09] introduce
PCP ranking methods for both classiﬁed and unclassiﬁed
datasets. For unlabeled data, the Hough space measure is
used, and for labeled data, a similarity measure and overlap
measures are adopted. Ferdosi et al. introduce a dimension
ordering method [FR11] that is applicable for both PCPs
and SPLOMs utilizing the subspace analysis method from
their earlier work [FBT∗10] discussed in the Section 3.3.
Johansson and Johansson [JJ09] propose an interactive sys-
tem adopting a weighted combination of quality metrics for
dimension selection and automatic ordering of the axes to
enhance visual patterns such as clustering and correlation.
Hurley et al. utilize Eulerian tours and Hamiltonian decom-
positions of complete graphs, which represent the relation-
ship between the dimensions, in their recent work [HO10] to
address the axis ordering challenge.

Clutter reduction is another important aspect in PCPs, es-
pecially for large point counts. Peng et al. [PWR04] were
able to reduce clutter for both SPLOMs and PCPs without
altering the information content simply by reordering the di-
mensions. A focus+context visualization scheme can also be
used for reducing the clutter and highlighting the essential
features in the PCP [NH06]. In this context, the overview
captures both the outliers and the trends in the dataset. The
outliers are indicated by single lines, and the trends that cap-
ture the overall relationship between axes are approximated
by polygon strips. The selected data items are emphasized
through visual highlighting. In addition, several of the clut-
ter reduction methods employing screen space measures are
discussed in detail in Section 5.4.

Finally, many visual encoding improvements exist for
PCPs. Progressive PCPs [RZH12] demonstrate the power of
a progressive reﬁnement scheme for enhancing the ability
of PCPs to handle large datasets. In the work of Dang et
al. [DWA10], density is expressed by stacking overlapping
elements. For the PCP case, a 3D visualization is presented,
where either the edges are stacked as curves or the points on
the axes are stacked vertically as dots.
Radial Layout. The star coordinate plot [Kan00], also re-
ferred to as a bi-plot [HGM∗97], is a generalization of the
axis-aligned bivariate scatterplot. The star coordinate axes
represent the unit basis vectors of an afﬁne projection. The
user is allowed to modify the orientation and the length of
the axes as a way of altering the projection. However, due
to the unbounded manipulation, star coordinates may pro-
duce afﬁne projections where substantial distortion occurs.
Lehmann et al. extend the star coordinate concept with an
orthographic constraint [LT13] to restrict the generated pro-
jection to be orthographic, which better preserves the struc-
ture of the original dataset.

Similar to the star coordinates, Radviz [HGM∗97] adopts
a circular pattern.The difference is that Radviz does not de-
ﬁne an explicit projection matrix. In Radviz, n dimensional

S. Liu, D. Maljovec, B. Wang, P.-T Bremer & V. Pascucci / Visualizing High-Dimensional Data:Advances in the Past Decade

anchors are placed along the perimeter of a circle, each rep-
resenting one of the dimensions of an n-dimensional dataset.
A spring model is constructed for each point, where one end
of a spring is attached to a dimensional anchor and the other
is attached to the data point. The point is then displayed
where the sum of the spring forces equals zero. Albuquerque
et al. [AEL∗10] devise a RadViz quality measure allowing
automatic optimization of the dimensional anchor layout.

DataMeadow [EST07] introduces a radial visual encod-
ing named DataRoses, which is represented as a PCP laid
out radially as opposed to linearly. Lastly, PolarEyez [JN02]
introduces a focus+context visualization where the high-
dimensional function parameter space is encoded in a radial
fashion around a user-controlled focal point. Data near the
focal point is represented with more precision, and the focal
point can be altered to focus on different parts of the data.

Figure 4: Scattering points in parallel coordinates by Yuan et
al. [YGX∗09].

Hybrid Construction. The axis-based methods can also be
combined to create new visualizations. The scattering points
in parallel coordinate work [YGX∗09] (Figure 4) embeds a
MDS plot between a pair of PCP axes. The ﬂexible linked
axes work [CvW11] is a generalization of the PCP and the
SPLOM. The tool gives the user the ability to create new
conﬁgurations by drawing and linking axes in either scat-
terplot or PCP style. Proposed by Fanea et al., the integra-
tion of parallel coordinate and star glyphs [FCI05] provides
a way to “unfold” the overlapped values in the PCP axis in
3D space. In this work [FCI05], each axis in the PCP is re-
placed with a star glyph that represents the values across all
points, and then each high-dimensional point is described as
a set of line segments in 3D connecting the individual values
in the star glyphs.

In addition, there is a number of visual representations
that derive from the the well-known visual mappings. Angu-
lar histograms [GPL∗11] introduced a novel visual encoding
that improves the scalability of PCPs by overcome the over-
plotting issue. The tiled PCP [CMR07] adopts a row-column
2D conﬁguration instead of the 1D linear layout of the tra-
ditional PCP for simultaneous visualization of multiple time
steps and variables.
4.2 Glyphs

Chernoff faces [Che73] are one of the ﬁrst attempts to map
a high-dimensional data point into a single glyph. The sys-

tem works by mapping different facial features to separate
dimensions. In a few recent works, glyphs have been utilized
to provide statistical and sensitivity information in order to
present trends in the data. By utilizing local linear regression
to compute partial derivatives around sampled data points
and representing the information in terms of glyph shape,
sensitivity information can be visually encoded into scatter-
plots [CCM09, CCM10, GWRR11, CCM13].

Correa et al. [CCM09] aimed at incorporating uncertainty
information into PCA projections and k-means clustering
and accomplished this goal by augmenting scatterplots with
tornado plots. Together these glyphs encode uncertainty and
partial derivative information. The idea of mapping sen-
sitivity information to a line segment through each data
point has been extended in their later work [CCM10] with
the introduction of the ﬂow-based scatterplot (FBS) that
highlights functional relationships between inputs and out-
puts. The works by Guo et al. [GWRR11] and Chan et
al. [CCM13] attempt to provide more than a single partial
derivative information into their scatterplots by experiment-
ing with different glyph shapes such as star plots among oth-
ers. [GWRR11] also uses a bar chart similar to the tornado
plot used in [CCM09], and [CCM13] provides two other in-
terpretations. The ﬁrst is a generalization of the FBS called
the generalized sensitivity scatterplot (GSS). By using or-
thogonal regression, GSSs can represent the partial deriva-
tive of any variable with respect to any other variable. The
other is a fan glyph that works similarly to the star glyph,
allowing for viewing multiple partial derivatives, but rather
than displaying magnitude as in the star glyph, the fan glyph
highlights the direction of each partial derivative, since all
line segments are normalized in length.

The methods described above all deal with encoding ex-
tra information per data point into glyphs, but the DICON
system [CGSQ11] attempts to show the trend of data within
a collection of data points by visually encoding statistical
information about the set of points being represented. DI-
CON uses dynamic icons based on treemap visualization to
encode clusters of data into separate icons, and allows the
user to interactively merge, split, ﬁlter, regroup, and high-
light clusters or data within clusters. Due to the interactive
nature, the authors have developed a stabilized Voronoi lay-
out that allows data within the treemap to maintain spatial
coherence as the user edits the clusters. They further encode
skew and kurtosis into the shape of the icon before applying
the Voronoi algorithm, thus allowing for statistical details to
be presented.

Finally, Ward [War08] gives a thorough, practical treat-
ment of generating and organizing effective glyphs for mul-
tivariate data, paying particular attention to the common pit-
falls involving the use of glyphs.
4.3 Pixel-Oriented Approaches

In an effort to encode the maximal amount of informa-
tion, several works have targeted dense pixel displays. Re-

c(cid:13) The Eurographics Association 2015.

S. Liu, D. Maljovec, B. Wang, P.-T Bremer & V. Pascucci / Visualizing High-Dimensional Data:Advances in the Past Decade

searchers have focused on encoding data values as individ-
ual pixels and creating separate displays, or subwindows, for
each dimension.

Some of the earliest works in this area date back to the mid
1990s [KK94,AKpK96]. VisDB [KK94] visualizes database
queries by creating a 2D image for each dimension involved
in the query and mapping individual values of a dimension
to pixels. The mapped data is sorted and colored by rele-
vance such that the data most related to the query appears
in the center of the image, and the data spirals outward as
it loses relevance to the query. Circle segments [AKpK96]
arrange multidimensional data in a radial fashion with equal
size sectors being carved out for each dimension.

The pixel concept can be applied to bar charts to create
pixel bar charts [KHL∗01]. Pixel bar charts ﬁrst separate
data into separate bars based on one dimension or attribute,
and it can also split the data along the orthogonal direction
using another dimension, although most results are reported
using only one direction for splitting data. Once split, the
data points are sorted along the horizontal axis within the
bars using one dimension and ordered along the vertical axis
using another dimension. Wattenberg introduces the jigsaw
map [Wat05], which again maps data points to pixels and
uses discrete space-ﬁlling curves in order to ﬁll a 2D plane
in a more sensible fashion than a comparative treemap lay-
out.

The Value and Relation (VaR) displays

[YPS∗04,
YHW∗07] combine the recursive pattern displays [KKA95]
with MDS in order to lay out the separate subwindows
such that similar dimensions are placed closer together. A
latter iteration [YHW∗07] enhances the work by provid-
ing more robust visualizations including jigsaw maps, scat-
terplot glyphs, and a novel concept known as the Rainfall
metaphor geared at establishing the relationship of all di-
mensions to a single dimension of interest.
4.4 Hierarchy-Based Approaches

For visualizing high-dimensional datasets, hierarchical vi-
sual representations are used to capture dimensional rela-
tionships, represent contour tree structure, and provide new
visual encodings for representing high-dimensional struc-
tures.
Dimension Hierarchies. Large numbers of dimensions hin-
der our ability to navigate the data space and cause scala-
bility issues for visual mapping. A hierarchical organization
of dimensions explicitly reveals the dimension relationships,
helping to alleviate the complexity of the dataset. Yang et
al. propose an interactive hierarchical dimension ordering,
spacing, and ﬁltering approach [WPWR03] based on dimen-
sion similarity. The dimension hierarchy is represented and
navigated by a multiple ring structure (InterRing [YWR02]),
where the innermost-ring represents the coarsest level in the
hierarchy.
Topology-Based Hierarchies. In Section 3.5, we have dis-

c(cid:13) The Eurographics Association 2015.

cussed topological structures, which can provide a ranking
of features with the help of persistence simpliﬁcation and
thus be treated as a hierarchy.

Various visual metaphors have been designed for con-
tour trees [PCMS09, WBP12]. In particular, variations of
landscapes have been proposed [BMW∗12,
topological
DBW∗12, HW10, OHJS10, OHJ∗11, WBP07]. These visual
metaphors have, or potentially have, capabilities for the visu-
alization of high-dimensional datasets. In particular, Weber
et al. [WBP07] have presented such a metaphor for visu-
ally mapping the contour tree of high-dimensional functions
to a 2D terrain where the relative size, volume, and nest-
ing of the topological features are preserved. Harvey and
Wang [HW10] have extended this work by computing all
possible planar landscapes and they are able to preserve ex-
actly the volumes of the high-dimensional features in the
areas of the terrain. In addition, the works of Oesterling et
al. [OHJS10, OHJ∗11] have used this same metaphor to vi-
sualize a related structure, the join tree. They use a novel
high-dimensional interpolation scheme in order to estimate
the density from the raw data points, and visually map the
density as points on top of their generated terrains.

Oesterling et al. [OHWS13] continued this line of work
by creating a linked view software system including user in-
teractions into the analysis by allowing users to brush and
link with PCPs and PCA projections of the data. In addition,
they have presented a new method of sorting the features
based on either persistence, cluster size, or cluster stability,
thus adjusting the placement of features in the topological
landscape.
Other Hierarchical Structures. In the structure-based
brushes work [FWR00], a data hierarchy is constructed to
be visualized by both a PCP and a treemap [Shn92], allow-
ing users to navigate among different levels-of-detail and se-
lect the feature(s) of interest. The structure decomposition
tree [ERHH11] presents a novel technique that embeds a
cluster hierarchy in a dimensional anchor-based visualiza-
tion using a weighted linear dimension reduction technique.
It provides a detail plus overview structural representation,
and conveys coordinate value information in the same con-
struction. The system supports user-guided pruning, opti-
mization of the decision tree, and encoding the tree structure
in an explorable visual hierarchy. Kreuseler et al. present a
novel visualization technique [KS02] for visualizing com-
plex hierarchical graphs in a focus+context manner for vi-
sual data mining tasks.
4.5 Animation

Many techniques for visualizing high-dimensional data
utilize animated transitions to enhance the perception of
point and structure correspondences among multiple rele-
vant plots.

The GGobi system [SLBC03] provides a mechanism for
calculating a continuous linear projection transition between
any pair of linear projections based on the principal an-

S. Liu, D. Maljovec, B. Wang, P.-T Bremer & V. Pascucci / Visualizing High-Dimensional Data:Advances in the Past Decade

gles between them. In the Rolling the Dice work [EDF08],
a transition between any pair of scatterplots in a SPLOM
is made possible by connecting a series of 3D tran-
sitions between scatterplots that share an axis. Rnav-
Graph [WO11] constructs a graph connecting a number of
interesting scatterplots. A smooth animation is generated be-
tween all scatterplots that are connected by an edge. The
TripAdvisorND [NM13] system allows users to explore the
neighborhood of a subspace by tilting the projection plane
using a polygonal touchpad interface.
4.6 Perception Evaluation

The design goal of visual mapping and encoding is to di-
rectly convey the information to the user through visual per-
ception. The evaluation of this mapping is vitally important
in determining the effectiveness of the overall visualization.
Sedlmair et al. have carried out an extensive investigation
of the effectiveness of visual encoding choices [SMT13],
including 2D scatterplot, interactive 3D scatterplot, and
SPLOMs. Their ﬁndings reveal that the 2D scatterplot is
often decent, and certain dimension reduction techniques
provide a good alternative. In addition, SPLOMs some-
times add additional value, and the interactive 3D scatter-
plot rarely helps and often hurts the perception of class
separation. The efﬁcacy of several PCP variants for clus-
ter identiﬁcation has been studied in [HVW10]. The com-
parison is performed among nine PCP variations based on
existing methods and combinations of them. The evalu-
ation reveals that, aside from the scatterplots embedded
into parallel coordinates [YGX∗09], a number of seemingly
valid improvements do not result in signiﬁcant performance
gains for cluster identiﬁcation tasks. Heer et al. investi-
gate the animated transition effectiveness between statistic
graphs [HR07] such as bar charts, pie charts, and scatter-
plots. Their results reveal that animated transitions, when
used appropriately, can signiﬁcantly improve graphical per-
ception.

5 View Transformation

View transformations dictate what we ultimately see on
the screen. As pointed out by Bertini et al. [BTK11], the
view transformation can also be described as the rendering
process that generates images in the screen space.
5.1

Illustrative Rendering

Illustrative rendering describes methods that focus on
achieving a speciﬁc visual style by applying custom-
designed rendering algorithms. The illustrative PCPs
work [MM08] provides a set of artistic style rendering
techniques for enhancing parallel coordinate visualization.
Some of the rendering techniques include spline-based edge
bundling, opacity-based hints to convey cluster density, and
shading effects to illustrate local line density. Illuminated
scatterplots [SW09] (Figure 5) classify points based on
the eigenanalysis of the covariance matrix, and give the

user the opportunity to see effects such as planarity and
linearity when visualizing dense scatterplots. Johansson et
al. [JLJC05] reveal structures in PCPs by adopting the trans-
fer function concept commonly used in volume rendering.
Based on user input, the transfer function maps the line den-
sities into different opacities to highlight features.

Illustrative rendering techniques are also used for high-
lighting the focused areas, such as the well-known Table-
Lens approach [RC94] for visualizing large tables. Such a
magic lens based approach permits fast exploration of an
area of interest without presenting all the details, therefore,
reduces clutter in the view. MoleView [HTE11], for visual-
izing scatterplots and graphs, adopts a semantic lens for al-
lowing users to focus on the area of interest and keep the in-
focused data unchanged while simplifying or deforming the
rest of data to maintain context. A survey on the distortion-
oriented magic lens techniques is presented by Leung and
Apperley [LA94].

Figure 5: Illuminated 3D scatterplot by Sanftmann et
al. [SW09].

5.2 Continuous Visual Representation

For most high-dimensional visualization techniques, a
discrete visual representation is assumed since each element
corresponds to a data point. However, due to limitations such
as visual clutter and computational cost, many applications
prefer a continuous representation.

The work of Bachthaler and Weiskopf [BW08] presents a
mathematical model for constructing a continuous scatter-
plot. The follow-up work [BW09] introduces an adaptive
rendering extension for continuous scatterplots increasing
the rendering efﬁciency. This concept is extended to create
continuous PCPs [HW09] based on the point and line duality
between scatterplots and parallel coordinates. The authors
propose a mathematical model that maps density from a con-
tinuous scatterplot [BW08] to parallel coordinates. Lehmann
et al. introduce a feature detection algorithm design for con-
tinuous PCPs [LT11].

Clutter caused by overlapping in PCPs and scatterplots
occludes data distribution and outliers. In the splatterplot
work [MG13], the authors introduce a hybrid representation
for scatterplots to overcome the overdraw issue when scal-
ing to very large datasets. The proposed abstraction auto-
matically groups dense data points into an abstract contour
representation and renders the rest of the area using selected
representatives, thus preserving the visual cue for outliers. A

c(cid:13) The Eurographics Association 2015.

S. Liu, D. Maljovec, B. Wang, P.-T Bremer & V. Pascucci / Visualizing High-Dimensional Data:Advances in the Past Decade

splatting framework for extracting clusters in PCPs is pre-
sented by [ZCQ∗09], where a polyline splatter is introduced
for cluster detection, and a segment splatter is used for clut-
ter reduction.
5.3 Accurate Color Blending

When rendering semi-transparent objects, color blending
methods have a signiﬁcant impact on the perception of order
and structure.

As

stated in the Hue-Preserving Color-Blending
work [KGZ∗12], the commonly adopted alpha-compositing
can result in false colors that may lead to a deceiving visual-
ization. The authors propose a data-driven machine learning
model
for optimizing and predicting a hue-preserving
blending. This model can be applied to high-dimensional
visualization techniques such as illustrative PCPs [MM08],
where a depth ordering clue is better preserved. In the
Weaving vs. Blending work [HSKIH07],
the authors
investigate the effectiveness of two color mixing schemes:
color blending and color weaving (interleaved pattern). The
results indicate that color weaving allows users to better
infer the value of individual components; however, as the
number of components increases, the advantage of color
weaving diminishes.
5.4

Image Space Metrics

As discussed in Section 4.1, a number of quality mea-
sures have been proposed to analyze the visual structure and
automatically identify interesting patterns in PCPs or scat-
terplots. In this section, we discuss the image space based
quality measures that are applied in the screen space.

Arterode et al. propose a method [AdOL04] for uncov-
ering clusters and reducing clutter by analyzing the density
or frequency of the plot. Image processing based techniques
such as grayscale manipulation and thresholding are used to
achieve the desired visualization. Johansson et al. introduce
a screen space quality measure for clutter reduction [JC08]
to address the challenge of very large datasets. The metric
is based on distance transformation, and the computation is
carried out on the GPU for interactive performance.

Pargnostics [DK10], a portmanteau for parallel coordi-
nates and diagnostics (similar to Scagnostics [WAG05]), is
a set of screen space measures for identifying distance pat-
terns among pairs of axes in PCPs. The metrics include line
crossings, crossing angles, convergence, and over-plotting.
For each of the metrics, the system provides ranked views for
pairs of axes, allowing the user to guide exploration and vi-
sualization. Pixnostic [SSK06] is an image space based qual-
ity metric for ranking interestingness for pixel based (Sec-
tion 4.3) visualization such as Pixel Bar Chars [KHL∗01].

6 User Interaction

As illustrated in Figure 2,

interaction is integrated
with each of the processing steps. An alternative sub-
categorization for each of the processing steps based on the

c(cid:13) The Eurographics Association 2015.

amount of user interaction is shown in Table 1. In this cat-
egorization, each step is further divided into computation-
centric approaches, interactive exploration, and model ma-
nipulation. In both of the recent surveys [MPG∗14,TJHH14]
on the user interaction in visualization applications, the level
of integration between the computation and visualization
(indicate user interaction) is used for classifying the meth-
ods. In many ways, their classiﬁcations are aligned with our
proposed approach, with the distinction that our discussion is
directly connected to the information visualization pipeline.
6.1 Computation-Centric Approaches

input

such as

Computation-centric approaches require only limited
setting initial parameters. These
user
methods center around algorithms designed for well-
deﬁned computational problems such as dimension re-
duction [RS00, MRC02, KC03, WM04], subspace analy-
sis [CFZ99, TMF∗12, FBT∗10, AWD12], regression anal-
[BPFG11, BPFG11], quality metric based rank-
ysis
ing [WAG05, TAE∗09], etc. Computation-centric ap-
proaches exist at each of the processing steps, but are most
concentrated in the data transformation step.
6.2 Interactive Exploration

Interactive methods navigate, query, and ﬁlter the exist-
ing model interactively for more effective visual communi-
cation. In this section, we focus only on representative meth-
ods where the interactive exploration mechanism is their key
contribution.

In the data transformation step, the interactive explo-
ration scheme allows users to guide progressive dimen-
sion reduction, where a partial result is presented upon re-
quest [WM04]. In works by Turkay et al. [TFH11,TLLH12]
and Yuan et al. [YRWG13], a subset of dimensions is inter-
actively selected and explored in dimension space.

In the visual mapping step, there are large number of
methods focused on interactive exploration and querying
the high-dimensional dataset. Such methods play an impor-
tant role in the knowledge Discovery in Databases (KDD)
process, where the term visual data mining [KK96, Kei02,
DOL03] is used to describe these applications. Interac-
tive ﬁltering, zooming, distortion, linking and brushing, or
a combination of them have been adopted to include the
user as part of the exploring and querying process. Po-
laris [STH02] is a visual query and analysis system de-
signed for relational databases. This system is later de-
veloped into the well-known commercial product Tableau.
Stolte et al. introduce an approach for zooming along one
or more dimensions for multi-scale exploration by travers-
ing a graph [STH03]. In this system, relational queries can
be deﬁned by visual speciﬁcations allowing fast incremen-
tal development and intuitive understanding of the data.
Hao et al. have introduced the Intelligent Visual Analyt-
ics Queries [HDK∗07]. Their approach utilizes correlation
and similarity measurements for mining data relationships.
We believe new research directions could stem from visual

S. Liu, D. Maljovec, B. Wang, P.-T Bremer & V. Pascucci / Visualizing High-Dimensional Data:Advances in the Past Decade

Computation-Centric

Interactive Exploration

Model Manipulation

Data Transformation
dimension
reduc-
tion [WM04],
subspace
ﬁnding [TMF∗12], regres-
sion analysis
progres-
interactive,
sive
reduc-
tion [WM04], dimension
space exploration [TFH11]
user-guided
embedding
manipulation [LWBP14],
control point based projec-
tion [JPC∗11]

dimension

parallel
axis

Visual Mapping
co-
automatic
ordinate
reorder-
ing [PWR04], scatterplot
ranking [WAG05]
visual querying and ﬁl-
tering [SVW10], animated
transition [SLBC03]

[JC08],

View Transformation
quality metrics in image
continu-
space
ous
visual
representa-
tion [BW08]
interactive magic lens ef-
fects [HTE11], illuminated
3D scatterplot [SW09]

distance function learning
[BLBC12, Gle13], visual
to parameter
interaction
[HBM∗13]

transfer
[JLJC05],

PCP
tion
projection
tion [PdSABD∗12]

func-
inverse
extrapola-

Table 1: The transformation pipelines intertwine with user interaction. The subcategorizing is based on the different levels of
user involvement.

data mining and visual queries. The Select and Slice Ta-
ble [SVW10] allows users to study the relationships between
data subsets and the semantic zone (user-deﬁned areas of in-
terest). The semantic zones are arranged along one axis of
the table, while the data subsets are arranged along the other
axis. In addition, the method enables the combination and
manipulation of the semantic zones for further exploration.
More recent works [GLG∗13, GGL∗14] by Gratzl et al. in-
troduce some very interesting interactive methods for rank-
ings multi-attributes and explore subsets of tabular datasets.
Both of the works of Poco et al. [PEP∗11b] and Sanft-
mann and Weiskopf [SW12] present methods for navigat-
ing a 3D projection. However, their approaches are quite
different. The method introduced by Poco et al. [PEP∗11b]
focuses on enhancing the visual encoding and exploration
usability of a 3D projection calculated by the Least-Square
Projection [PNML08] algorithm. On the other hand, Sanft-
mann and Weiskopf [SW12] present an interpolation scheme
for generating 3D rigid body rotations between a pair of 3D
axis-aligned scatterplots that share a common axis.

In the view transformation step, interactivity is inherent in
both the magic lens based methods [HTE11,LA94], and illu-
minated 3D scatterplots [SW09] (discussed in Section 5.1).
6.3 Model Manipulation

Model manipulation techniques represent a class of meth-
ods that integrate user manipulation as part of the algorithm,
and update the underlying model to reﬂect the user input to
obtain new insights.

Take the distance function learning work [BLBC12],
for example. The initial embedding is created using a
default distance measure. Through interaction, the initial
point layout is modiﬁed based on the expert user’s domain
knowledge. The system then adjusts the underlying dis-
tance model to reﬂect the user input. Hu et al. present a
method [HBM∗13] for improving the translation of user in-
teraction to algorithm input (visual to parameter interaction)

for distance learning scenarios. The explainers [Gle13] are
projection functions created from a set of user-deﬁned anno-
tations.

The control point based projection methods [DST04,
PNML08,PEP∗11a,JPC∗11,PSN10] update the overall pro-
jection result based on user manipulation of the control
points. In the iLAMP method [PdSABD∗12], inverse pro-
jection extrapolation is used for generating synthetic mul-
tidimensional data out of existing projections for param-
eter space exploration. In the Local Clustering Operation
work [GXWY10], the visual structure is modiﬁed in PCPs
through user-guided deformation operators. Finally, Liu et
al. [LWBP14] allow for direct manipulation of the dimen-
sion reduction embedding to resolve structural ambiguities.
The interactively updated distortion measure is used for
feedback during manipulation.

7 Connections with Related Fields

We investigate the connections between recent advances
in high-dimensional data visualization and related ﬁelds in
the hope of inspiring new research directions.
7.1 Multivariate Volume Visualization

Multivariate volume visualization and high-dimensional
visualization are often studied under different contexts: the
former is normally considered as scientiﬁc visualization re-
search [BH07,KH13], while the latter is mostly studied from
the perspective of information visualization and visual ana-
lytics. In addition, they focus on different kinds of data and
attempt to accomplish distinct goals.

Despite the differences, recent advances in both areas
have shown that they share a number of fundamental tech-
niques and principles. Standard high-dimensional data visu-
alization techniques, such as PCPs, scatterplots, and dimen-
sion reduction, have found their way into the multivariate
volume visualization literature. For example, the scattering
points in parallel coordinates work [YGX∗09] is adopted

c(cid:13) The Eurographics Association 2015.

S. Liu, D. Maljovec, B. Wang, P.-T Bremer & V. Pascucci / Visualizing High-Dimensional Data:Advances in the Past Decade

by [GXY12] as a design space for multivariate volume trans-
fer functions. In the work of Liu et al. [LWT∗14a], dynamic
projection and subspace analysis are utilized for exploring
the high-dimensional parameter space of volumetric data.
We believe useful and interesting techniques may be devel-
oped by sharing ideas and discovering new connections be-
tween these two ﬁelds.
7.2 Machine Learning

Machine learning algorithms under many situations have
been treated as “black box” approaches, and the param-
eter tuning process can be tedious and unpredictable. To
resolve such a challenge, several visualization approaches
have been introduced to aid the understanding of the various
machine learning algorithms. Tzeng et al. present a visual-
ization system that helps users design neural networks more
efﬁciently [TM05]. The works of Teoh and Ma [TM03] and
van den Elzen and van Wijk [vdEvW11] investigate visual-
ization methods for interactively constructing and analyzing
decision trees. Visualization has also been used to aid model
validation [Rd00, MW10]. Numerous challenges for under-
standing machine learning algorithms coincide with high-
dimensional visualization. We believe high-dimensional vi-
sualization will play an important role in designing, tuning,
and validating machine learning algorithms.

8 Reﬂections and Future Directions

One of our primary objectives in presenting this survey is
to provide actionable guidance for data practitioners to nav-
igate through a modular view of the recent advances. To do
so, we provide a categorization of recent works along an en-
riched information visualization pipeline. We reﬂect on the
chosen categories and subcategories (as described brieﬂy in
Section 2) and describe on a high level how they provide
actionable guidance. To allow the creation of new visualiza-
tions along the pipeline, one should think beyond data tasks
to be performed in any single stage, and focus on under-
standing how results from one stage could be utilized most
effectively in the remaining stages. We argue that the sub-
categories discussed during each pipeline stage correspond
to sets of actionable items or toolsets that the data practi-
tioner could choose from and rely upon. The combinations
of techniques they chose to apply are largely data-driven
and application-dependent. Nevertheless, the techniques sur-
veyed following our categorization aim to provide a modular
view during the design process.

We now discuss the challenges addressed by the tech-
niques surveyed in the paper, and those that remain to be
tackled. Our discussion is partially inspired by Donoho’s
AMS lecture [Don00] where he discusses the curses
and blessings of dimensionality when it comes to high-
dimensional data analysis.

Data analysis, falls under the data transformation stage
within our categorization. Some of the surveyed, standard
data analysis tasks are widely applicable for studying var-

c(cid:13) The Eurographics Association 2015.

ious aspects of high-dimensional data: dimension reduc-
tion for feature selection and extraction; clustering for ex-
ploratory data mining and classiﬁcation; regression for rela-
tionship inference and prediction. However, we identify sev-
eral different directions in which we expect to see further
progress, namely: robust analysis and data de-noising; multi-
scale analysis; data skeletonization; and high-dimensional
approximations. First, more advanced regression techniques
could be developed that are robust to noise and outliers,
in particular, a new class of regression techniques inspired
by geometric and topological intuititions (e.g., [GBPW10]).
Second, topological data analysis has built-in capabilities in
separating features from noise at multi-scales; such a multi-
scale notion is expected to be transferrable to a larger class of
analysis techniques. Third, developing frameworks to extract
as well as to simplify “skeletons” from high-dimensional
data can be extremely useful for visual data abstraction
and exploration (e.g., [SMC07]). Finally, as pointed out by
Donoho [Don00], perhaps there exists new notions of high-
dimensional approximation theory, where we make different
regularity assumptions and obtain a very different picture in
approximating high-dimensional functions. Approximating
the Morse-Smale complex in high dimension is considered
such an example.

During visual mapping, our surveyed techniques convert
the analysis result into visual structures with various vi-
sual encodings. Development of new analysis results, for ex-
ample, new approximations of high-dimensional structures,
would inevitably lead to new visual metaphors (e.g., in the
case of topological landscape [HW10, DBW∗12]). Under
visual mapping and view transformation, we also see var-
ious methods aimed at summarizing trends in data, such
as glyph representations, edge bundling in PCPs, splatting
as presented in splatterplots [MG13] and PCP-based splat-
ters [ZCQ∗09], and hierarchical approaches. These could be
further enhanced with new data skeletonization techniques.
Finally, we identify a few opportunities for future visual-

ization research and discuss them in detail.
Subspace Clustering. Finding interesting projections
(views) has been an active and important research area for vi-
sualizing high-dimensional data. The motivation behind the
various view selection schemes can be traced back to much
earlier work such as projection pursuit [FT74].

Along a similar line of research, scatterplot ranking meth-
ods [SS04a, WAG06, TAE∗09] are introduced to automati-
cally identify the interesting scatterplots. However, a scat-
terplot matrix captures only limited bivariate relationships.
Subspace selection methods [CFZ99, BPR∗04], originally
developed in the data mining community, have recently been
adapted for high-dimensional data visualization [FBT∗10,
TMF∗12] to capture more complicated multivariate struc-
tures. Despite the added ﬂexibility, the search is still lim-
ited to axis-aligned subspaces. Recent advances in machine
learning, such as subspace clustering (e.g., [Vid11]), assume

S. Liu, D. Maljovec, B. Wang, P.-T Bremer & V. Pascucci / Visualizing High-Dimensional Data:Advances in the Past Decade

the high-dimensional dataset can be represented by a mix-
ture of low-dimensional linear subspaces with mixed dimen-
sions. Such methods produce non-axis-aligned subspaces,
which work well for datasets where different dimensions are
closely related. In addition, instead of capturing a single lin-
ear subspace, they can approximate non-linear structures by
ﬁtting together multiple linear subspaces.

We believe exploring various (non-axis-aligned) subspace
clustering methods will lead to new developments in high-
dimensional view selection techniques (e.g., some of the re-
cent work by the authors [LWT∗14a, LWT∗14b]).
Model Manipulation. We have seen an emerging user
interaction paradigm,
referred to as model manipula-
tion [BLBC12,PdSABD∗12,Gle13,HBM∗13] in this survey.
What differentiates the model manipulation interaction from
other types of interaction is the change of the underlying data
model to reﬂect user intention. These model manipulation
based methods allow users to easily transfer their domain
knowledge into the exploratory analysis process, allowing
for effective analysis and visualization. However, since such
interactive manipulations give users an enormous amount of
freedom, one of the main challenges in model manipulation
is to understand whether or not the manipulation faithfully
conveys the user intention. Rigorous validation between the
user intended operations and manipulation outcomes is es-
sential for evaluating the effectiveness and usability of these
methods.
Uncertainty Quantiﬁcation. Along with the large-scale and
high dimensionality of the data, information pertaining to
uncertainty is becoming increasingly available and impor-
tant. The addition of uncertainty information within visual-
izations has been deemed a top research problem in scien-
tiﬁc visualization [Joh04], due to the greater availability of
this information from simulation and quantiﬁcation, and the
importance of understanding data quality, conﬁdence, and
error issues when interpreting scientiﬁc results. Some recent
works in high-dimensional data visualization have focused
on analyzing the uncertainty stemming from the input data or
with respect to the accuracy of a ﬁtted model (see Section 3.4
and [ZSWR06]). We believe the extensions and generaliza-
tions of existing uncertainty visualization capabilities (e.g.,
[DKLP02, PWB∗09, SZD∗10]) to high-dimensional data is
one of the important future directions.

Another interesting aspect of uncertainty quantiﬁcation
is based on uncertainty-aware visual analytics discussed
by Correa et al. [CCM09], and further explored by Liu et
al. [LWBP14] and Schreck et al. [SvLB10], where the un-
certainty (e.g., bias and distortions) arises from the Data
transformation step. The work by Correa et al. [CCM09]
measures the uncertainty introduced by three common
Data transformation techniques; and the works of Liu et
al. [LWBP14] and Schreck et al. [SvLB10] quantiﬁes the
amount of distortion for projection techniques. While these
methods apply to the uncertainty stemming from the Data

transformation step, more work can be done to deﬁne mea-
sures of uncertainty associated with the two latter processing
steps in the visualization pipeline, namely Visual mapping
and View transformation.
Topological Data Analysis and Visualization. Another
important and interesting recent advance is the introduc-
tion of TDA to visualization (e.g., [GBPW10, WSPVJ11,
DCK∗12]). TDA provides an interesting alternative for cap-
turing the structure in high-dimensional data. Since topolog-
ical structures are typically scale-invariant, designing mean-
ingful and effective visual encodings that capture their inher-
ent properties is essential for future development. Approx-
imation algorithms exist for computing topological struc-
tures in high dimensions; therefore, it is important to strike
a balance between speed and accuracy, and to convey ap-
propriately the approximation error in the visualization.
Some initial work has been done to provide bounds or es-
timations on the accuracy of these approximated models
(e.g., [GBPW10, CL11, TFO09]).
Other Directions. Finally, as discussed in Section 7, ﬁelds
such as multivariate volume visualization and machine
learning share a number of common research problems
with high-dimensional data visualization. Finding connec-
tions and sharing ideas among these related topics will likely
not only yield interesting future research directions, but also
help resolve many challenges in high-dimensional data visu-
alization.

Acknowledgments

The ﬁrst two authors contributed equally to this work.
This work was performed in part under the auspices of the
US DOE by LLNL under Contract DE-AC52-07NA27344.,
LLNL-CONF-658933. This work is also supported in
part by NSF 0904631, DE-EE0004449, DE-NA0002375,
DE-SC0007446, DE-SC0010498, NSG IIS-1045032, NSF
EFT ACI-0906379, DOE/NEUP 120341, DOE/Codesign
P01180734.
References
[AdOL04] ARTERO A., DE OLIVEIRA M., LEVKOWITZ H.: Un-
covering clusters in crowded parallel coordinates visualizations.
In IEEE Symposium on Information Visualization (2004), pp. 81–
88. 11

[AEL∗10] ALBUQUERQUE G., EISEMANN M., LEHMANN
D. J., THEISEL H., MAGNOR M.: Improving the visual analy-
sis of high-dimensional datasets using quality measures. In IEEE
Symposium on Visual Analytics Science and Technology (2010),
IEEE, pp. 19–26. 8

[AKpK96] ANKERST M., KEIM D. A., PETER KRIEGEL H.:
Circle segments: A technique for visually exploring large mul-
In Proceedings of IEEE Visualization,
tidimensional data sets.
Hot Topic Session. (1996). 9

[AWD12] ANAND A., WILKINSON L., DANG T. N.: Visual pat-
tern discovery using random projections. In IEEE Conference on
Visual Analytics Science and Technology (2012), IEEE, pp. 43–
52. 5, 11

[BCS96] BUJA A., COOK D., SWAYNE D. F.: Interactive high-

c(cid:13) The Eurographics Association 2015.

S. Liu, D. Maljovec, B. Wang, P.-T Bremer & V. Pascucci / Visualizing High-Dimensional Data:Advances in the Past Decade

dimensional data visualization. Journal of Computational and
Graphical Statistics 5, 1 (1996), pp. 78–99. 1

[BDFF∗08] BIASOTTI S., DE FLORIANI L., FALCIDIENO B.,
FROSINI P., GIORGI D., LANDI C., PAPALEO L., SPAGNUOLO
M.: Describing shapes by geometrical-topological properties of
real functions. ACM Computing Surveys 40, 4 (2008), 12:1–
12:87. 6

[BDSW13] BISWAS A., DUTTA S., SHEN H.-W., WOODRING
J.: An information-aware framework for exploring multivari-
ate data sets. IEEE Transactions on Visualization and Computer
Graphics 19, 12 (2013), 2683–2692. 3

[Bec14] BECK F.: Survis. https://github.com/fabian-beck/survis,

2014. 2

[BEHP04] BREMER P.-T., EDELSBRUNNER H., HAMANN B.,
PASCUCCI V.: A topological hierarchy for functions on trian-
gulated surfaces. IEEE Transactions on Visualization and Com-
puter Graphics 10, 385-396 (2004). 6

[BH07] BÜRGER R., HAUSER H.: Visualization of multi-variate
scientiﬁc data. EuroGraphics State of the Art Reports (STARs)
(2007), 117–134. 1, 3, 12

[BKH05] BENDIX F., KOSARA R., HAUSER H.: Parallel sets:
visual analysis of categorical data. In IEEE Symposium on Infor-
mation Visualization (2005), pp. 133–140. 3

[BLBC12] BROWN E. T., LIU J., BRODLEY C. E., CHANG R.:
Dis-function: Learning distance functions interactively. In IEEE
Conference on Visual Analytics Science and Technology (2012),
IEEE, pp. 83–92. 4, 12, 14

[BMW∗12] BEKETAYEV K., MOROZOV D., WEBER G. H.,
ABZHANOV A., HAMANN. B.: Geometry–preserving topolog-
ical landscapes. In Proceedings of the Workshop at SIGGRAPH
Asia (2012), pp. 155–160. 9

[BN03] BELKIN M., NIYOGI P.: Laplacian eigenmaps for dimen-
sionality reduction and data representation. Neural computation
15, 6 (2003), 1373–1396. 4

[BPFG11] BERGER W., PIRINGER H., FILZMOSER P.,
GRÖLLER E.:
Uncertainty-aware exploration of continu-
ous parameter spaces using multivariate prediction. Computer
Graphics Forum 30, 3 (2011), 911–920. 5, 11

[BPR∗04] BAUMGARTNER C., PLANT C., RAILING K.,
KRIEGEL H.-P., KROGER P.: Subspace selection for clustering
high-dimensional data. In Fourth IEEE International Conference
on Data Mining (2004), IEEE, pp. 11–18. 5, 13

[BTK11] BERTINI E., TATU A., KEIM D.: Quality metrics in
high-dimensional data visualization: an overview and system-
IEEE Transactions on Visualization and Computer
atization.
Graphics 17, 12 (2011), 2203–2212. 1, 2, 10

[BW08] BACHTHALER S., WEISKOPF D.: Continuous scatter-
plots. IEEE Transactions on Visualization and Computer Graph-
ics 14, 6 (2008), 1428–1435. 10, 12

[BW09] BACHTHALER S., WEISKOPF D.: Efﬁcient and adaptive
rendering of 2-d continuous scatterplots. Computer Graphics Fo-
rum 28, 3 (2009), 743–750. 10

[Car09] CARLSSON G.: Topology and data. Bullentin of the

American Mathematical Society 46, 2 (2009), 255–308. 2, 6

[CCM09] CORREA C., CHAN Y.-H., MA K.-L.: A framework
for uncertainty-aware visual analytics. In IEEE Symposium on
Visual Analytics Science and Technology (2009), pp. 51–58. 8,
14

[CCM10] CHAN Y.-H., CORREA C., MA K.-L.: Flow-based
scatterplots for sensitivity analysis. In IEEE Symposium on Vi-
sual Analytics Science and Technology (2010), IEEE, pp. 43–50.
8

c(cid:13) The Eurographics Association 2015.

[CCM13] CHAN Y.-H., CORREA C., MA K.-L.: The general-
ized sensitivity scatterplot. IEEE Transactions on Visualization
and Computer Graphics 19, 10 (2013), 1768–1781. 8

[CD14] CARR H., DUKE D.: Joint contour nets.

IEEE Trans-
actions on Visualization and Computer Graphics 20, 8 (2014),
1100–1113. 6

[CFZ99] CHENG C.-H., FU A. W., ZHANG Y.: Entropy-based
subspace clustering for mining numerical data. In Proceedings of
the ﬁfth ACM SIGKDD international conference on Knowledge
discovery and data mining (1999), ACM, pp. 84–93. 5, 11, 13

[CGSQ11] CAO N., GOTZ D., SUN J., QU H.: Dicon: Interactive
visual analysis of multidimensional clusters. IEEE Transactions
on Visualization and Computer Graphics 17, 12 (2011), 2581–
2590. 8

[Cha06] CHAN W. W.-Y.: A survey on multivariate data visu-
alization. Department of Computer Science and Engineering.
Hong Kong University of Science and Technology 8, 6 (2006),
1–29. 1

[Che73] CHERNOFF H.: The use of faces to represent points in
k-dimensional space graphically. Journal of the American Statis-
tical Association 68, 342 (1973), 361–368. 8

[CL11] CORREA C., LINDSTROM P.: Towards robust topology
IEEE Transactions on Visualization

of sparsely sampled data.
and Computer Graphics 17, 12 (2011), 1852–1861. 6, 14

[CMR07] CAAT M., MAURITS N., ROERDINK J.: Design and
evaluation of tiled parallel coordinates visualization of multi-
channel eeg data. IEEE Transactions on Visualization and Com-
puter Graphics 13, 1 (2007), 70–79. 8

[CMS99] CARD S. K., MACKINLAY J. D., SHNEIDERMAN B.:
Readings in information visualization: using vision to think.
Morgan Kaufmann, 1999. 1, 2

[CSA03] CARR H., SNOEYINK J., AXEN U.: Computing con-
tour trees in all dimensions. Computational Geometry 24, 2
(2003), 75 – 94. Special Issue on the Fourth CGC Workshop
on Computational Geometry. 6

[CvW11] CLAESSEN J., VAN WIJK J.: Flexible linked axes for
multivariate data visualization. IEEE Transactions on Visualiza-
tion and Computer Graphics 17, 12 (2011), 2310–2316. 8

[DAW13] DANG T. N., ANAND A., WILKINSON L.: Timeseer:
Scagnostics for high-dimensional time series. IEEE Transactions
on Visualization and Computer Graphics 19, 3 (2013), 470–483.
7

[DBW∗12] DEMIR D., BEKETAYEV K., WEBER G. H., BRE-
MER P.-T., PASCUCCI V., HAMANN. B.: Topology exploration
with hierarchical landscapes. In Proceedings of the Workshop at
SIGGRAPH Asia (2012), pp. 147–154. 9, 13

[DCK∗12] DUKE D., CARR H., KNOLL A., SCHUNCK N., NAM
H. A., STASZCZAK A.: Visualizing nuclear scission through a
multiﬁeld extension of topological analysis. IEEE Transactions
on Visualization and Computer Graphics 18, 12 (2012), 2033–
2040. 6, 14

[DK10] DASGUPTA A., KOSARA R.: Pargnostics: Screen-space
metrics for parallel coordinates. IEEE Transactions on Visualiza-
tion and Computer Graphics 16, 6 (2010), 1017–1026. 11

[DKLP02] DJURCILOV S., KIM K., LERMUSIAUX P., PANG A.:
Visualizing scalar volumetric data with uncertainty. Computers
and Graphics 26 (2002), 239–248. 14

[DOL03] DE OLIVEIRA M. C. F., LEVKOWITZ H.: From visual
data exploration to visual data mining: A survey. IEEE Transac-
tions on Visualization and Computer Graphics 9, 3 (2003), 378–
394. 1, 11

S. Liu, D. Maljovec, B. Wang, P.-T Bremer & V. Pascucci / Visualizing High-Dimensional Data:Advances in the Past Decade

[Don00] DONOHO D. L.: High-dimensional data analysis: The
curses and blessings of dimensionality. AMS Lecture: Math
Challenges of the 21st Century, 2000. 13

[dSMVJ09] DE

SILVA V., MOROZOV D., VEJDEMO-
Persistent cohomology and circular
In Proceedings 25th Annual Symposium on

JOHANSSON M.:
coordinates.
Computational Geometry (2009), pp. 227–236. 6

[DST04] DE SILVA V., TENENBAUM J. B.: Sparse multidimen-
sional scaling using landmark points. Tech. rep., Technical re-
port, Stanford University, 2004. 4, 12

[DW13] DEMIR I., WESTERMANN R.: Progressive high-quality
response surfaces for visually guided sensitivity analysis. Com-
puter Graphics Forum 32, 3pt1 (2013), 21–30. 5

[DWA10] DANG T. N., WILKINSON L., ANAND A.: Stacking
graphic elements to avoid over-plotting. IEEE Transactions on
Visualization and Computer Graphics 16, 6 (2010), 1044–1052.
7

[ED07] ELLIS G., DIX A.: A taxonomy of clutter reduction for
IEEE Transactions on Visualization

information visualisation.
and Computer Graphics 13, 6 (2007), 1216–1223. 1

[EDF08] ELMQVIST N., DRAGICEVIC P., FEKETE J.-D.:
Rolling the dice: Multidimensional visual exploration using scat-
IEEE Transactions on Visualization
terplot matrix navigation.
and Computer Graphics 14, 6 (2008), 1539–1148. 10

[EH08] EDELSBRUNNER H., HARER J.: Persistent homology –

a survey. Contemporary Mathematics 453 (2008), 257. 6

[EH10] EDELSBRUNNER H., HARER J.: Computational Topol-
ogy - an Introduction. American Mathematical Society, 2010.
6

[EHNP03] EDELSBRUNNER H., HARER J., NATARAJAN V.,
PASCUCCI V.: Morse-Smale complexes for piece-wise linear
3-manifolds. In Proceedings 19th Annual symposium on Com-
putational geometry (2003), pp. 361–370. 6

[EHZ03] EDELSBRUNNER H., HARER J., ZOMORODIAN A. J.:
Hierarchical Morse-Smale complexes for piecewise linear 2-
manifolds. Discrete and Computational Geometry 30, 87-107
(2003). 6

[ERHH11] ENGEL D., ROSENBAUM R., HAMANN B., HAGEN
H.: Structural decomposition trees. Computer Graphics Forum
30, 3 (2011), 921–930. 9

[EST07] ELMQVIST N., STASKO J., TSIGAS P.: Datameadow:
A visual canvas for analysis of large-scale multivariate data. In
IEEE Symposium on Visual Analytics Science and Technology
(2007), pp. 187–194. 8

[FBT∗10] FERDOSI B. J., BUDDELMEIJER H., TRAGER S.,
WILKINSON M. H., ROERDINK J. B.: Finding and visualizing
relevant subspaces for clustering high-dimensional astronomical
data using connected morphological operators. In IEEE Sympo-
sium on Visual Analytics Science and Technology (2010), IEEE,
pp. 35–42. 5, 7, 11, 13

[FCI05] FANEA E., CARPENDALE S., ISENBERG T.: An inter-
active 3d integration of parallel coordinates and star glyphs. In
IEEE Symposium on Information Visualization (2005), pp. 149–
156. 8

[FR11] FERDOSI B. J., ROERDINK J. B.: Visualizing high-
dimensional structures by dimension ordering and ﬁltering us-
ing subspace analysis. Computer Graphics Forum 30, 3 (2011),
1121–1130. 7

[FT74] FRIEDMAN J., TUKEY J.: A projection pursuit algorithm
for exploratory data analysis. IEEE Transactions on Computers
C-23, 9 (1974), 881–890. 5, 13

[FWR00] FUA Y.-H., WARD M., RUNDENSTEINER E.:
Structure-based brushes: a mechanism for navigating hierarchi-
cally organized data and information spaces. IEEE Transactions
on Visualization and Computer Graphics 6, 2 (2000), 150–159.
9

[GBPH08] GYULASSY A., BREMER P.-T., PASCUCCI V.,
HAMANN B.: A practical approach to Morse-Smale complex
computation: Scalability and generality. IEEE Transactions on
Visualization and Computer Graphics 14, 6 (2008), 1619–1626.
6

[GBPW10] GERBER S., BREMER P., PASCUCCI V., WHITAKER
R.: Visual exploration of high dimensional scalar functions.
IEEE Transactions on Visualization and Computer Graphics 16,
6 (2010), 1271–1280. 3, 5, 6, 13, 14

[GGL∗14] GRATZL S., GEHLENBORG N., LEX A., PFISTER H.,
STREIT M.: Domino: Extracting, comparing, and manipulating
subsets across multiple tabular datasets. IEEE Transactions on
Visualization and Computer Graphics 20, 12 (2014), 2023–2032.
12

[Ghr08] GHRIST R.: Barcodes: The persistent topology of data.
Bulletin of the American Mathematical Society 45 (2008), 61–75.
6

[Gle13] GLEICHER M.: Explainers: Expert explorations with
IEEE Transactions on Visualization and

crafted projections.
Computer Graphics 19, 12 (2013), 2042–2051. 4, 12, 14

[GLG∗13] GRATZL S., LEX A., GEHLENBORG N., PFISTER H.,
STREIT M.: Lineup: Visual analysis of multi-attribute rankings.
IEEE Transactions on Visualization and Computer Graphics 19,
12 (2013), 2277–2286. 12

[GNP∗05] GYULASSY A., NATARAJAN V., PASCUCCI V., BRE-
MER P.-T., HAMANN B.: Topology-based simpliﬁcation for fea-
In Proceedings of IEEE
ture extraction from 3D scalar ﬁelds.
Visualization (2005), pp. 535–542. 6

[GPL∗11] GENG Z., PENG Z., LARAMEE R., ROBERTS J.,
WALKER R.: Angular histograms: Frequency-based visualiza-
tions for large, high dimensional data. IEEE Transactions on Vi-
sualization and Computer Graphics 17, 12 (2011), 2572–2580.
8

[Guo03] GUO D.: Coordinating computational and visual ap-
proaches for interactive feature selection and multivariate clus-
tering. Information Visualization 2, 4 (2003), 232–246. 7

[GWRR11] GUO Z., WARD M., RUNDENSTEINER E., RUIZ C.:
Pointwise local pattern exploration for sensitivity analysis.
In
IEEE Conference on Visual Analytics Science and Technology
(2011), pp. 131–140. 8

[GXWY10] GUO P., XIAO H., WANG Z., YUAN X.: Interactive
local clustering operations for high dimensional data in parallel
In IEEE Paciﬁc Visualization Symposium (2010),
coordinates.
pp. 97–104. 12

[GXY12] GUO H., XIAO H., YUAN X.: Scalable multivariate
volume visualization and analysis based on dimension projection
and parallel coordinates. IEEE transactions on visualization and
computer graphics (2012). 13

[HBM∗13] HU X., BRADEL L., MAITI D., HOUSE L., NORTH
IEEE
C.: Semantics of directly manipulating spatializations.
Transactions on Visualization and Computer Graphics 19, 12
(2013), 2052–2059. 12, 14

[HDK∗07] HAO M., DAYAL U., KEIM D., MORENT D.,
SCHNEIDEWIND J.: Intelligent visual analytics queries. In IEEE
Symposium on Visual Analytics Science and Technology (2007),
pp. 91–98. 11

c(cid:13) The Eurographics Association 2015.

S. Liu, D. Maljovec, B. Wang, P.-T Bremer & V. Pascucci / Visualizing High-Dimensional Data:Advances in the Past Decade

[HG02] HOFFMAN P. E., GRINSTEIN G. G.: A survey of visu-
alizations for high-dimensional data mining. Information visual-
ization in data mining and knowledge discovery (2002), 47–82.
1

[HGM∗97] HOFFMAN P., GRINSTEIN G., MARX K., GROSSE
I., STANLEY E.: DNA visual and analytic data mining. In Pro-
ceedings of IEEE Visualization (1997), pp. 437–441. 7

[HO10] HURLEY C., OLDFORD R.: Pairwise display of high-
dimensional information via eulerian tours and hamiltonian de-
compositions. Journal of Computational and Graphical Statis-
tics 19, 4 (2010). 7

[HR07] HEER J., ROBERTSON G. G.: Animated transitions in
statistical data graphics. IEEE Transactions on Visualization and
Computer Graphics 13, 6 (2007), 1240–1247. 10

[HSKIH07] HAGH-SHENAS H., KIM S.,

[HS89] HASTIE T., STUETZLE W.: Principal curves. Journal of
the American Statistical Association 84, 406 (1989), 502–516. 5
INTERRANTE V.,
HEALEY C.: Weaving versus blending: a quantitative assessment
of the information carrying capacities of two alternative methods
for conveying multivariate data with color. IEEE Transactions on
Visualization and Computer Graphics 13, 6 (2007), 1270–1277.
11

[HTE11] HURTER C., TELEA A., ERSOY O.: Moleview: An at-
tribute and structure-based semantic lens for large element-based
plots. IEEE Transactions on Visualization and Computer Graph-
ics 17, 12 (2011), 2600–2609. 10, 12

[HVW10] HOLTEN D., VAN WIJK J. J.: Evaluation of cluster
identiﬁcation performance for different PCP variants. Computer
Graphics Forum 29, 3 (2010), 793–802. 10

[HW09] HEINRICH J., WEISKOPF D.: Continuous parallel co-
IEEE Transactions on Visualization and Computer

ordinates.
Graphics 15, 6 (2009), 1531–1538. 10

[HW10] HARVEY W., WANG Y.: Topological landscape en-
sembles for visualization of scalar-valued functions. Computer
Graphics Forum 29, 3 (2010), 993–1002. 9, 13

[HW13] HEINRICH J., WEISKOPF D.: State of the art of parallel
coordinates. STAR Proceedings of Eurographics 2013 (2013),
95–116. 1

[ID91]

INSELBERG A., DIMSDALE B.: Parallel coordinates. In
Human-Machine Interactive Systems. Springer, 1991, pp. 199–
233. 7
[IML13]

IM J.-F., MCGUFFIN M., LEUNG R.: Gplom: The gen-
eralized plot matrix for visualizing multidimensional multivariate
data. IEEE Transactions on Visualization and Computer Graph-
ics 19, 12 (2013), 2606–2614. 3

[Ins09]

INSELBERG A.: Parallel Coordinates : Visual Multidi-
mensional Geometry and its Applications. Springer, 2009. 1,
7

[JC08]

JOHANSSON J., COOPER M.: A screen space quality
method for data abstraction. Computer Graphics Forum 27, 3
(2008), 1039–1046. 11, 12

[JJ09]

JOHANSSON S., JOHANSSON J.: Interactive dimensional-
ity reduction through user-deﬁned combinations of quality met-
rics. IEEE Transactions on Visualization and Computer Graphics
15, 6 (2009), 993–1000. 7

[JLJC05]

JOHANSSON J., LJUNG P., JERN M., COOPER M.: Re-
vealing structure within clustered parallel coordinates displays.
In IEEE Symposium on Information Visualization (2005), IEEE,
pp. 125–132. 10, 12

[JN02]

JAYARAMAN S., NORTH C.: A radial focus+context vi-
In Proceedings of

sualization for multi-dimensional functions.
IEEE Visualization (2002), pp. 443–450. 8

c(cid:13) The Eurographics Association 2015.

[Joh04]

problems.
14

JOHNSON C. R.: Top scientiﬁc visualization research
IEEE Computer Graphics and Applications (2004).

[Jol05]

JOLLIFFE I.: Principal component analysis. Wiley Online

Library, 2005. 3

[JPC∗11]

JOIA P., PAULOVICH F., COIMBRA D., CUMINATO J.,
IEEE
NONATO L.: Local afﬁne multidimensional projection.
Transactions on Visualization and Computer Graphics 17, 12
(2011), 2563–2571. 4, 12

JEONG D. H., ZIEMKIEWICZ C., FISHER B., RIB-
ARSKY W., CHANG R.:
iPCA: An interactive system for pca-
based visual analytics. Computer Graphics Forum 28, 3 (2009),
767–774. 3

[JZF∗09]

[Kan00] KANDOGAN E.: Star coordinates: A multi-dimensional
visualization technique with uniform treatment of dimensions. In
IEEE Information Visualization Symposium, Late Breaking Hot
Topics (2000), pp. 9–12. 7

[KC03] KOREN Y., CARMEL L.: Visualization of labeled data
using linear transformations. In IEEE Symposium on Information
Visualization (2003), pp. 121–128. 4, 11

[Kei02] KEIM D. A.: Information visualization and visual data
IEEE Transactions on Visualization and Computer

mining.
Graphics 8, 1 (2002), 1–8. 1, 11

[KGZ∗12] KUHNE L., GIESEN J., ZHANG Z., HA S., MUELLER
K.: A data-driven approach to hue-preserving color-blending.
IEEE Transactions on Visualization and Computer Graphics 18,
12 (2012), 2122–2129. 11

[KH13] KEHRER J., HAUSER H.: Visualization and visual anal-
ysis of multifaceted scientiﬁc data: A survey. IEEE Transactions
on Visualization and Computer Graphics 19, 3 (2013), 495–513.
1, 3, 12

[KHL∗01] KEIM D., HAO M., LADISCH J., HSU M., DAYAL
U.: Pixel bar charts: a new technique for visualizing large multi-
attribute data sets without aggregation. In IEEE Symposium on
Information Visualization (2001), pp. 113–120. 9, 11

[KK94] KEIM D., KRIEGEL H.-P.: Visdb: database exploration
using multidimensional visualization. Computer Graphics and
Applications, IEEE 14, 5 (1994), 40–49. 9

[KK96] KEIM D. A., KRIEGEL H.-P.: Visualization techniques
for mining large databases: A comparison. Knowledge and Data
Engineering, IEEE Transactions on 8, 6 (1996), 923–938. 11

[KKA95] KEIM D., KRIEGEL H.-P., ANKERST M.: Recursive
pattern: a technique for visualizing very large amounts of data.
In Proceedings of IEEE Visualization (1995), pp. 279–286, 463.
9

[Kru64] KRUSKAL J. B.: Multidimensional scaling by optimiz-
ing goodness of ﬁt to a nonmetric hypothesis. Psychometrika 29,
1 (1964), 1–27. 4

[KS02] KREUSELER M., SCHUMANN H.: A ﬂexible approach
for visual data mining. IEEE Transactions on Visualization and
Computer Graphics 8, 1 (2002), 39–51. 9

[LA94] LEUNG Y. K., APPERLEY M. D.: A review and taxon-
omy of distortion-oriented presentation techniques. ACM Trans-
actions on Computer-Human Interaction 1, 2 (1994), 126–160.
10, 12

[LAE∗12] LEHMANN D. J., ALBUQUERQUE G., EISEMANN
M., MAGNOR M., THEISEL H.: Selecting coherent and relevant
plots in large scatterplot matrices. Computer Graphics Forum 31,
6 (2012), 1895–1908. 7

[LAK∗11] LAWRENCE J., ARIETTA S., KAZHDAN M., LEPAGE

S. Liu, D. Maljovec, B. Wang, P.-T Bremer & V. Pascucci / Visualizing High-Dimensional Data:Advances in the Past Decade

D., O’HAGAN C.: A user-assisted approach to visualizing mul-
tidimensional images. IEEE Transactions on Visualization and
Computer Graphics 17, 10 (2011), 1487–1498. 3

[LMZ∗14] LEE J. H., MCDONNELL K. T., ZELENYUK A.,
IMRE D., MUELLER K.: A structure-based distance metric for
high-dimensional space exploration with multidimensional scal-
ing. IEEE Transations on Visualization and Computer Graphics
20, 3 (2014), 351–364. 4

[LPM03] LEE A. B., PEDERSEN K. S., MUMFORD D.: The non-
linear statistics of high-contrast patches in natural images. Inter-
national Journal of Computer Vision 54, 1-3 (2003), 83–103. 6
[LT11] LEHMANN D., THEISEL H.: Features in continuous par-
allel coordinates. IEEE Transactions on Visualization and Com-
puter Graphics 17, 12 (2011), 1912–1921. 10

[LT13] LEHMANN D. J., THEISEL H.: Orthographic star coordi-
nates. IEEE Transactions on Visualization and Computer Graph-
ics 19, 12 (2013), 2615–2624. 7

[LV09] LEE J. A., VERLEYSEN M.: Quality assessment of di-
mensionality reduction: Rank-based criteria. Neurocomputing
72, 7 (2009), 1431–1443. 4

[LWBP14] LIU S., WANG B., BREMER P.-T., PASCUCCI
V.: Distortion-guided structure-driven interactive exploration of
high-dimensional data. Computer Graphics Forum 33, 3 (2014),
101–110. 4, 12, 14

[LWT∗14a] LIU S., WANG B., THIAGARAJAN J. J., BREMER
P.-T., PASCUCCI V.: Multivariate volume visualization through
dynamic projections. Large Data Analysis and Visualization
(LDAV), 2014 IEEE Symposium on (2014). 13, 14

[LWT∗14b] LIU S., WANG B., THIAGARAJAN J. J., BREMER
P.-T., V V. P.: Visual exploration of high-dimensional data: Sub-
space analysis through dynamic projections. Tech. Rep. UUSCI-
2014-003, SCI Institute, University of Utah, 2014. 14

[MG13] MAYORGA A., GLEICHER M.: Splatterplots: Overcom-
ing overdraw in scatter plots. IEEE Transactions on Visualization
and Computer Graphics 19, 9 (2013), 1526–1538. 10, 13

[MLGH13] MOKBEL B., LUEKS W., GISBRECHT A., HAMMER
B.: Visualizing the quality of dimensionality reduction. Neuro-
computing 112 (2013), 109–123. 4

[MM08] MCDONNELL K. T., MUELLER K.: Illustrative paral-
lel coordinates. Computer Graphics Forum 27, 3 (2008), 1031–
1038. 10, 11

[MPG∗14] MUHLBACHER T., PIRINGER H., GRATZL S., SEDL-
MAIR M., STREIT M.: Opening the black box: Strategies for in-
creased user involvement in existing algorithm implementations.
IEEE Transactions on Visualization and Computer Graphics 20,
12 (2014), 1643–1652. 11

[MRC02] MORRISON A., ROSS G., CHALMERS M.: A hy-
brid layout algorithm for sub-quadratic multidimensional scaling.
In IEEE Symposium on Information Visualization (2002), IEEE,
pp. 152–158. 11

[Mun14] MUNZNER T.: Visualization Analysis and Design. CRC

Press, 2014. 1, 2

[MW10] MIGUT M., WORRING M.: Visual exploration of clas-
In IEEE Symposium on
siﬁcation models for risk assessment.
Visual Analytics Science and Technology (2010), pp. 11–18. 13
[NH06] NOVOTNY M., HAUSER H.: Outlier-preserving fo-
IEEE Trans-
cus+context visualization in parallel coordinates.
actions on Visualization and Computer Graphics 12, 5 (2006),
893–900. 7

[NLC11] NICOLAU M., LEVINE A. J., CARLSSON G.: Topology
based data analysis identiﬁes a subgroup of breast cancers with a

unique mutational proﬁle and excellent survival. In Proceedings
of the National Academy of Sciences (2011), vol. 108, pp. 7265–
7270. 6

[NM13] NAM J. E., MUELLER K.: Tripadvisor-nd: A tourism-
inspired high-dimensional space exploration framework with
IEEE Transactions on Visualization and
overview and detail.
Computer Graphics 19, 2 (2013), 291–305. 5, 10

[OHJ∗11] OESTERLING P., HEINE C., JANICKE H., SCHEUER-
MANN G., HEYER G.: Visualization of high-dimensional point
clouds using their density distribution’s topology. IEEE Trans-
actions on Visualization and Computer Graphics 17, 11 (2011),
1547–1559. 9

[OHJS10] OESTERLING P., HEINE C., JÄNICKE H., SCHEUER-
MANN G.: Visual analysis of high dimensional point clouds us-
ing topological landscape. In IEEE Paciﬁc Visualization Sympo-
sium (2010), pp. 113–120. 9

[OHWS13] OESTERLING P., HEINE C., WEBER G., SCHEUER-
MANN G.: Visualizing nd point clouds as topological landscape
proﬁles to guide local data analysis. IEEE Transactions on Visu-
alization and Computer Graphics 19, 3 (2013), 514–526. 9

[PBK10] PIRINGER H., BERGER W., KRASSER J.: Hypermoval:
Interactive visual validation of regression models for real-time
In Proceedings of the 12th Eurographics / IEEE -
simulation.
VGTC Conference on Visualization (2010), EuroVis’10, Euro-
graphics Association, pp. 983–992. 3, 5

[PCMS09] PASCUCCI V., COLE-MCLAUGHLIN K., SCORZELLI
G.: The toporrery: Computation and presentation of multi-
resolution topology. Mathematical Foundations of Scientiﬁc Vi-
sualization, Computer Graphics, and Massive Data Exploration
(2009), 19–40. 9

[PdSABD∗12] PORTES DOS SANTOS AMORIM E., BRAZIL
E. V., DANIELS J., JOIA P., NONATO L. G., SOUSA M. C.:
ilamp: Exploring high-dimensional spacing through backward
multidimensional projection. In IEEE Conference on Visual An-
alytics Science and Technology (2012), IEEE, pp. 53–62. 12, 14
[PEP∗11a] PAULOVICH F., ELER D., POCO J., BOTHA C.,
MINGHIM R., NONATO L.: Piece wise laplacian-based projec-
tion for interactive data exploration and organization. Computer
Graphics Forum 30, 3 (2011), 1091–1100. 4, 12

[PEP∗11b] POCO J., ETEMADPOUR R., PAULOVICH F., LONG
T., ROSENTHAL P., OLIVEIRA M., LINSEN L., MINGHIM R.:
A framework for exploring multidimensional data with 3d pro-
jections. Computer Graphics Forum 30, 3 (2011), 1111–1120.
12

[PNML08] PAULOVICH F., NONATO L., MINGHIM R., LEV-
KOWITZ H.: Least square projection: A fast high-precision mul-
tidimensional projection technique and its application to docu-
IEEE Transactions on Visualization and Com-
ment mapping.
puter Graphics 14, 3 (2008), 564–575. 4, 12

[PSBM07] PASCUCCI V., SCORZELLI G., BREMER P.-T., MAS-
CARENHAS A.: Robust on-line computation of reeb graphs: Sim-
plicity and speed. ACM Transactions on Graphics 26, 3 (2007).
6

[PSN10] PAULOVICH F., SILVA C., NONATO L.: Two-phase
mapping for projecting massive data sets. IEEE Transactions on
Visualization and Computer Graphics 16, 6 (2010), 1281–1290.
4, 12

[PWB∗09] POTTER K., WILSON A., BREMER P.-T., WILLIAMS
D., PASCUCCI V., JOHNSON C.: Ensemblevis: A ﬂexible ap-
proach for the statistical visualization of ensemble data. In Pro-
ceedings of IEEE Workshop on Knowledge Discovery from Cli-
mate Data: Prediction, Extremes, and Impacts (2009). 14

c(cid:13) The Eurographics Association 2015.

S. Liu, D. Maljovec, B. Wang, P.-T Bremer & V. Pascucci / Visualizing High-Dimensional Data:Advances in the Past Decade

[PWR04] PENG W., WARD M. O., RUNDENSTEINER E. A.:
Clutter reduction in multi-dimensional data visualization using
dimension reordering. In IEEE Symposium on Information Visu-
alization (2004), IEEE, pp. 89–96. 7, 12

[RC94] RAO R., CARD S. K.: The table lens: merging graph-
ical and symbolic representations in an interactive focus+ con-
In Proceedings of
text visualization for tabular information.
the SIGCHI conference on Human factors in computing systems
(1994), ACM, pp. 318–322. 10

[Rd00] RHEINGANS P., DESJARDINS M.: Visualizing high-
In Proceedings of IEEE

dimensional predictive model quality.
Visualization (2000), pp. 493–496. 13

[Ree46] REEB G.: Sur les points singuliers d’une forme de pfaff
completement intergrable ou d’une fonction numerique [on the
singular points of a complete integral pfaff form or of a numerical
function]. Comptes Rendus Acad. Science Paris 222 (1946), 847–
849. 6

[RPH08] REDDY C. K., POKHARKAR S., HO T. K.: Generating
hypotheses of trends in high-dimensional data skeletons. In IEEE
Symposium on Visual Analytics Science and Technology (2008),
IEEE, pp. 139–146. 5

[RRB∗04] ROSARIO G. E., RUNDENSTEINER E. A., BROWN
D. C., WARD M. O., HUANG S.: Mapping nominal values to
numbers for effective visualization. Information Visualization 3,
2 (2004), 80–95. 3

[RS00] ROWEIS S. T., SAUL L. K.: Nonlinear dimensionality
reduction by locally linear embedding. Science 290, 5500 (2000),
2323–2326. 4, 11

[RW06] RASMUSSEN C. E., WILLIAMS C. K. I.: Gaussian Pro-
cesses for Machine Learning (Adaptive Computation and Ma-
chine Learning). The MIT Press, 2006. 5

[RZH12] ROSENBAUM R., ZHI J., HAMANN B.: Progressive
In IEEE Paciﬁc Visualization Symposium

parallel coordinates.
(2012), pp. 25–32. 7

[Shn92] SHNEIDERMAN B.: Tree visualization with tree-maps: 2-
d space-ﬁlling approach. ACM Transactions on graphics (TOG)
11, 1 (1992), 92–99. 9

[SLBC03] SWAYNE D. F., LANG D. T., BUJA A., COOK D.:
GGobi: evolving from XGobi into an extensible framework for
interactive data visualization. Computational Statistics & Data
Analysis 43, 4 (2003), 423–444. 9, 12

[Sma61] SMALE S.: On gradient dynamical systems. The Annals

of Mathematics 74 (1961), 199–206. 6

[SMC07] SINGH G., MEMOLI F., CARLSSON G.: Topological
methods for the analysis of high dimensional data sets and 3d ob-
ject recognition. In Symposium on Point Based Graphics (2007),
pp. 91–100. 3, 6, 13

[SMT13] SEDLMAIR M., MUNZNER T., TORY M.: Empiri-
cal guidance on scatterplot and dimension reduction technique
IEEE Transactions on Visualization and Computer
choices.
Graphics 19, 12 (2013), 2634–2643. 10

[SNLH09] SIPS M., NEUBERT B., LEWIS J. P., HANRAHAN P.:
Selecting good views of high-dimensional data using class con-
sistency. Computer Graphics Forum 28, 3 (2009), 831–838. 7

[SS04a] SEO J., SHNEIDERMAN B.: A rank-by-feature frame-
work for unsupervised multidimensional data exploration using
low dimensional projections. In IEEE Symposium on Informa-
tion Visualization (2004), IEEE, pp. 65–72. 7, 13

[SS04b] SMOLA A. J., SCHÖLKOPF B.: A tutorial on support
vector regression. Statistics and Computing 14, 3 (2004), 199–
222. 5

c(cid:13) The Eurographics Association 2015.

[SS06] SEO J., SHNEIDERMAN B.: Knowledge discovery in
high-dimensional data: Case studies and a user survey for the
rank-by-feature framework. IEEE Transactions on Visualization
and Computer Graphics 12, 3 (2006), 311–322. 7

[SSK06] SCHNEIDEWIND J., SIPS M., KEIM D. A.: Pixnostics:
Towards measuring the value of visualization. In IEEE Sympo-
sium on Visual Analytics Science and Technology (2006), IEEE,
pp. 199–206. 11

[SSK10] SEIFERT C., SABOL V., KIENREICH W.: Stress maps:
analysing local phenomena in dimensionality reduction based vi-
sualisations. In IEEE International Symposium on Visual Analyt-
ics Science and Technology. (2010). 4

[STH02] STOLTE C., TANG D., HANRAHAN P.: Polaris: a sys-
tem for query, analysis, and visualization of multidimensional re-
lational databases. IEEE Transactions on Visualization and Com-
puter Graphics 8, 1 (2002), 52–65. 11

[STH03] STOLTE C., TANG D., HANRAHAN P.: Multiscale vi-
sualization using data cubes. IEEE Transactions on Visualization
and Computer Graphics 9, 2 (2003), 176–187. 11

[SvLB10] SCHRECK T., VON LANDESBERGER T., BREMM S.:
Techniques for precision-based visual analysis of projected data.
Information Visualization 9, 3 (2010), 181–193. 4, 14

[SVW10] SHRINIVASAN Y. B., VAN WIJK J. J.: Supporting ex-
ploratory analysis with the select & slice table. Computer Graph-
ics Forum 29, 3 (2010), 803–812. 12

[SW09] SANFTMANN H., WEISKOPF D.:

Illuminated 3d scat-
terplots. Computer Graphics Forum 28, 3 (2009), 751–758. 10,
12

[SW12] SANFTMANN H., WEISKOPF D.: 3d scatterplot naviga-
tion. IEEE Transactions on Visualization and Computer Graph-
ics 18, 11 (2012), 1969–1978. 12

[SZD∗10] SANYAL J., ZHANG S., DYER J., MERCER A., AM-
BURN P., MOORHEAD R. J.: Noodles: A tool for visualization
of numerical weather model ensemble uncertainty. IEEE Trans-
actions on Visualization and Computer Graphics 16, 6 (2010),
1421 – 1430. 14

[TAE∗09] TATU A., ALBUQUERQUE G., EISEMANN M.,
SCHNEIDEWIND J., THEISEL H., MAGNOR M., KEIM D.:
Combining automated analysis and visualization techniques for
effective exploration of high-dimensional data. In IEEE Sympo-
sium on Visual Analytics Science and Technology (2009), IEEE,
pp. 59–66. 7, 11, 13

[TDSL00] TENENBAUM J. B., DE SILVA V., LANGFORD J. C.:
A global geometric framework for nonlinear dimensionality re-
duction. Science 290, 5500 (2000), 2319–2323. 4

[TFA∗11] TAM G. K. L., FANG H., AUBREY A. J., GRANT
P. W., ROSIN P. L., MARSHALL D., CHEN M.: Visualization
of time-series data in parameter space for understanding facial
dynamics. Computer Graphics Forum 30, 3 (2011), 901–910. 3
[TFH11] TURKAY C., FILZMOSER P., HAUSER H.: Brushing
dimensions-a dual visual analysis model for high-dimensional
data. IEEE Transactions on Visualization and Computer Graph-
ics 17, 12 (2011), 2591–2599. 4, 11, 12

[TFO09] TAKAHASHI S., FUJISHIRO I., OKADA M.: Applying
manifold learning to plotting approximate contour trees. IEEE
Transactions on Visualization and Computer Graphics 15, 6
(2009), 1185–1192. 14

[TJHH14] TURKAY C., JEANQUARTIER F., HOLZINGER A.,
HAUSER H.: On computationally-enhanced visual analysis of
heterogeneous data and its application in biomedical informatics.
In Interactive Knowledge Discovery and Data Mining in Biomed-
ical Informatics. Springer, 2014, pp. 117–140. 11

S. Liu, D. Maljovec, B. Wang, P.-T Bremer & V. Pascucci / Visualizing High-Dimensional Data:Advances in the Past Decade

[TLLH12] TURKAY C., LUNDERVOLD A., LUNDERVOLD A. J.,
HAUSER H.: Representative factor generation for the interactive
visual analysis of high-dimensional data. IEEE Transactions on
Visualization and Computer Graphics 18, 12 (2012), 2621–2630.
4, 11

[TM03] TEOH S. T., MA K.-L.: Paintingclass: interactive con-
struction, visualization and exploration of decision trees. In Pro-
ceedings of the ninth ACM SIGKDD international conference on
Knowledge discovery and data mining (2003), ACM, pp. 667–
672. 13

[TM05] TZENG F.-Y., MA K.-L.: Opening the black box - data
driven visualization of neural networks. In Proceedings of IEEE
Visualization (2005), pp. 383–390. 13

[TMF∗12] TATU A., MAAS F., FARBER I., BERTINI E.,
SCHRECK T., SEIDL T., KEIM D.: Subspace search and vi-
sualization to make sense of alternative clusterings in high-
dimensional data. In IEEE Conference on Visual Analytics Sci-
ence and Technology (2012), IEEE, pp. 63–72. 5, 11, 12, 13

[TWSM∗11] TORSNEY-WEIR T., SAAD A., MOLLER T., HEGE
H.-C., WEBER B., VERBAVATZ J., BERGNER S.: Tuner: Princi-
pled parameter ﬁnding for image segmentation algorithms using
IEEE Transactions on Vi-
visual response surface exploration.
sualization and Computer Graphics 17, 12 (2011), 1892–1901.
5

[vdEvW11] VAN DEN ELZEN S., VAN WIJK J.: Baobabview:
Interactive construction and analysis of decision trees. In IEEE
Conference on Visual Analytics Science and Technology (2011),
pp. 151–160. 13

[Vid11] VIDAL R.: A tutorial on subspace clustering. IEEE Sig-

nal Processing Magazine (2011). 5, 13

[WAG05] WILKINSON L., ANAND A., GROSSMAN R.: Graph-
theoretic scagnostics. In IEEE Symposium on Information Visu-
alization (2005), vol. 0, p. 21. 7, 11, 12

[WAG06] WILKINSON L., ANAND A., GROSSMAN R.: High-
dimensional visual analytics: Interactive exploration guided by
pairwise views of point distributions. IEEE Transactions on Vi-
sualization and Computer Graphics 12, 6 (2006), 1363–1372. 7,
13

[War94] WARD M. O.: Xmdvtool: Integrating multiple methods
for visualizing multivariate data. In Proceedings of IEEE Visual-
ization (1994), pp. 326–333. 3

[War08] WARD M. O.: Multivariate data glyphs: Principles and
In Handbook of Data Visualization. Springer, 2008,

practice.
pp. 179–198. 8

[Wat05] WATTENBERG M.: A note on space-ﬁlling visualizations
and space-ﬁlling curves. In IEEE Symposium on Information Vi-
sualization (2005), pp. 181–186. 9

[WB94] WONG P. C., BERGERON R. D.: 30 years of multi-
In Proceedings of Sci-
dimensional multivariate visualization.
entiﬁc Visualization, Overviews, Methodologies, and Techniques
(1994), pp. 3–33. 1

[WBP07] WEBER G., BREMER P.-T., PASCUCCI V.: Topolog-
IEEE
ical landscapes: A terrain metaphor for scientiﬁc data.
Transactions on Visualization and Computer Graphics 13, 6
(2007), 1416–1423. 9

[WBP12] WEBER G. H., BREMER P.-T., PASCUCCI V.: Topo-
logical cacti: Visualizing contour-based statistics. Topological
Methods in Data Analysis and Visualization II Mathematics and
Visualization (2012), 63–76. 9

[Wea09] WEAVER C.: Conjunctive visual forms.

IEEE Trans-
actions on Visualization and Computer Graphics 15, 6 (2009),
929–936. 3

[WM04] WILLIAMS M., MUNZNER T.: Steerable, progressive
In IEEE Symposium on Information

multidimensional scaling.
Visualization (2004), pp. 57–64. 4, 11, 12

[WO11] WADDELL A., OLDFORD R. W.: RnavGraph: A visual-

ization tool for navigating through high-dimensional data. 10

[WPWR03] WANG J., PENG W., WARD M. O., RUNDEN-
STEINER E. A.:
Interactive hierarchical dimension ordering,
spacing and ﬁltering for exploration of high dimensional datasets.
In IEEE Symposium on Information Visualization (2003), IEEE,
pp. 105–112. 9

[WSPVJ11] WANG B., SUMMA B., PASCUCCI V., VEJDEMO-
JOHANSSON M.: Branching and circular features in high dimen-
sional data. IEEE Transactions on Visualization and Computer
Graphics 17, 12 (2011), 1902–1911. 6, 14

[YGX∗09] YUAN X., GUO P., XIAO H., ZHOU H., QU H.: Scat-
tering points in parallel coordinates. IEEE Transactions on Visu-
alization and Computer Graphics 15, 6 (2009), 1001–1008. 8,
10, 12

[YHW∗07] YANG J., HUBBALL D., WARD M. O., RUNDEN-
STEINER E. A., RIBARSKY W.: Value and relation display: in-
teractive visual exploration of large data sets with hundreds of
dimensions. IEEE Transactions on Visualization and Computer
Graphics 13, 3 (2007), 494–507. 9

[YPS∗04] YANG J., PATRO A., SHIPING H., MEHTA N., WARD
M., RUNDENSTEINER E.: Value and relation display for inter-
active exploration of high dimensional datasets. In IEEE Sympo-
sium on Information Visualization (2004), pp. 73–80. 9

[YRWG13] YUAN X., REN D., WANG Z., GUO C.: Dimen-
sion projection matrix/tree: Interactive subspace visual explo-
ration and analysis of high dimensional data. IEEE Transactions
on Visualization and Computer Graphics 19, 12 (2013), 2625–
2633. 4, 11

[YWR02] YANG J., WARD M. O., RUNDENSTEINER E. A.: In-
terring: An interactive tool for visually navigating and manipulat-
ing hierarchical structures. In IEEE Symposium on Information
Visualization (2002), IEEE, pp. 77–84. 9

[ZCQ∗09] ZHOU H., CUI W., QU H., WU Y., YUAN X., ZHUO
W.: Splatting the lines in parallel coordinates. Computer Graph-
ics Forum 28, 3 (2009), 759–766. 11, 13

[ZJGK10] ZIEGLER H., JENNY M., GRUSE T., KEIM D.: Visual
In IEEE
market sector analysis for ﬁnancial time series data.
Symposium on Visual Analytics Science and Technology (2010),
pp. 83–90. 3

[Zom05] ZOMORODIAN A. J.: Topology for Computing (Cam-
bridge Monographs on Applied and Computational Mathemat-
ics). Cambridge University Press, 2005. 6

[ZSWR06] ZAIXIAN X., SHIPING H., WARD M., RUNDEN-
STEINER E.: Exploratory visualization of multivariate data with
variable quality. In IEEE Symposium on Visual Analytics Science
and Technology (2006), pp. 183–190. 14

c(cid:13) The Eurographics Association 2015.

S. Liu, D. Maljovec, B. Wang, P.-T Bremer & V. Pascucci / Visualizing High-Dimensional Data:Advances in the Past Decade

ments. Valerio earned a Ph.D. in computer science at Purdue
University in May 2000, and a EE Laurea (Master), at the
University “La Sapienza” in Roma, Italy, in December 1993,
as a member of the Geometric Computing Group. His recent
research interest is in developing new methods for massive
data analysis and visualization.

Brief Biographies of the Authors

Shusen Liu received his bachelor degree in Biomedical
Engineering and Computer Science from Huazhong Univer-
sity of Science and Technology, China, in 2009, where he
worked at Wuhan National Laboratory for Optoelectronic on
GPU accelerated biophotonics applications. Currently he is
a PhD student at University of Utah. His research interests
lie primarily in high-dimensional data visualization and mul-
tivariate volume visualization.

Dan Maljovec is a graduate student working on his PhD
from the School of Computing at the University of Utah. Dan
has been a research assistant at the University of Utah’s Sci-
entiﬁc Computing and Imaging Institute since 2012. He re-
ceived his B.S. in computer science from Gannon University
in 2009. His research focuses on analysis and visualization
of high-dimensional scientiﬁc data and intuitive visualiza-
tion.

Bei Wang received her Ph.D. in Computer Science from
Duke University in 2010. She is currently a Research Sci-
entist at the Scientiﬁc Computing and Imaging Institute,
University of Utah. Her main research interests are com-
putational topology, computational geometry, scientiﬁc data
analysis and visualization. She is also interested in computa-
tional biology and bioinformatics, machine learning and data
mining. She is a member of the IEEE Computer Society.

Peer-Timo Bremer is a member of technical staff and
project leader at the Center for Applied Scientiﬁc Comput-
ing (CASC) at the Lawrence Livermore National Laboratory
(LLNL) and Associated Director for Research at the Center
for Extreme Data Management, Analysis, and Visualization
at the University of Utah. His research interests include large
scale data analysis, performance analysis and visualization
and he recently co-organized a Dagstuhl Perspectives work-
shop on integrating performance analysis and visualization.
Prior to his tenure at CASC, he was a postdoctoral research
associate at the University of Illinois, Urbana-Champaign.
Peer-Timo earned a Ph.D. in Computer science at the Uni-
versity of California, Davis in 2004 and a Diploma in Math-
ematics and Computer Science from the Leipniz University
in Hannover, Germany in 2000. He is a member of the IEEE
Computer Society and ACM.

Valerio Pascucci is the founding Director of the Center
for Extreme Data Management Analysis and Visualization
(CEDMAV) of the University of Utah. Valerio is also a Fac-
ulty of the Scientiﬁc Computing and Imaging Institute, a
Professor of the School of Computing, University of Utah,
and a DOE Laboratory Fellow, of the Paciﬁc Northwest Na-
tional Laboratory. Previously, Valerio was a Group Leader
and Project Leader in the Center for Applied Scientiﬁc Com-
puting at the Lawrence Livermore National Laboratory, and
Adjunct Professor of Computer Science at the University of
California Davis. Prior to his CASC tenure, he was a senior
research associate at the University of Texas at Austin, Cen-
ter for Computational Visualization, CS and TICAM Depart-

c(cid:13) The Eurographics Association 2015.

","{""pos"":{""0"":1,""1"":2,""2"":3,""3"":4},""4"":{""0"":""ieee*"",""1"":""pcp"",""2"":""acm*"",""3"":""utah""},""6"":{""0"":""a*"",""1"":""interesting*"",""2"":""nominal*"",""3"":""partial*""},""7"":{""0"":""subspace*"",""1"":""scatterplots*"",""2"":""subspaces*"",""3"":""glyph*""},""3"":{""0"":""reeb*"",""1"":""keim*"",""2"":""hamann"",""3"":""kriegel*""},""1"":{""0"":""2011"",""1"":""2010"",""2"":""2009*"",""3"":""2013*""},""9"":{""0"":""science"",""1"":""research"",""2"":""technology*"",""3"":""university*""},""8"":{""0"":""visualization*"",""1"":""cloud*"",""2"":""software*"",""3"":""generalization*""},""2"":{""0"":""j"",""1"":""h"",""2"":""al"",""3"":""et""},""0"":{""0"":""12*"",""1"":""6"",""2"":""11*"",""3"":""1""},""10"":{""0"":""model*"",""1"":""view*"",""2"":""figure*"",""3"":""leader*""},""5"":{""0"":""based"",""1"":""provide"",""2"":""coordinate"",""3"":""introduce""},""11"":{""0"":""transactions"",""1"":""methods*"",""2"":""tree"",""3"":""values*""}}",2017,{},False,False,journalArticle,False,YA4MYR2A,[],self.user,"{""Unnamed: 0"":{""0"":0,""1"":1,""2"":2,""3"":3,""4"":4,""5"":5,""6"":6,""7"":7,""8"":8,""9"":9,""10"":10,""11"":11,""12"":12,""13"":13,""14"":14,""15"":15,""16"":16,""17"":17,""18"":18,""19"":19,""20"":20,""21"":21,""22"":22,""23"":23,""24"":24,""25"":25,""26"":26,""27"":27,""28"":28,""29"":29,""30"":30,""31"":31,""32"":32,""33"":33,""34"":34,""35"":35,""36"":36,""37"":37,""38"":38,""39"":39,""40"":40,""41"":41,""42"":42,""43"":43,""44"":44,""45"":45,""46"":46,""47"":47,""48"":48,""49"":49,""50"":50,""51"":51,""52"":52,""53"":53,""54"":54,""55"":55,""56"":56,""57"":57,""58"":58,""59"":59,""60"":60,""61"":61,""62"":62,""63"":63,""64"":64,""65"":65,""66"":66,""67"":67,""68"":68,""69"":69,""70"":70,""71"":71,""72"":72,""73"":73,""74"":74,""75"":75,""76"":76,""77"":77,""78"":78,""79"":79,""80"":80,""81"":81,""82"":82,""83"":83,""84"":84,""85"":85,""86"":86,""87"":87,""88"":88,""89"":89,""90"":90,""91"":91,""92"":92,""93"":93,""94"":94,""95"":95,""96"":96,""97"":97,""98"":98,""99"":99,""100"":100,""101"":101,""102"":102,""103"":103,""104"":104,""105"":105,""106"":106,""107"":107,""108"":108,""109"":109,""110"":110,""111"":111,""112"":112,""113"":113,""114"":114,""115"":115,""116"":116,""117"":117,""118"":118,""119"":119,""120"":120,""121"":121,""122"":122,""123"":123,""124"":124,""125"":125,""126"":126,""127"":127,""128"":128,""129"":129,""130"":130,""131"":131,""132"":132,""133"":133,""134"":134,""135"":135,""136"":136,""137"":137,""138"":138,""139"":139,""140"":140,""141"":141,""142"":142,""143"":143,""144"":144,""145"":145,""146"":146,""147"":147,""148"":148,""149"":149,""150"":150,""151"":151,""152"":152,""153"":153,""154"":154,""155"":155,""156"":156,""157"":157,""158"":158,""159"":159,""160"":160,""161"":161,""162"":162,""163"":163,""164"":164,""165"":165,""166"":166,""167"":167,""168"":168,""169"":169,""170"":170,""171"":171,""172"":172},""C"":{""0"":14.3742471281,""1"":95.759486753,""2"":63.6476926125,""3"":59.1087200299,""4"":6.0975906263,""5"":5.5366267274,""6"":9.3889695613,""7"":57.1378401226,""8"":50.3919765462,""9"":36.637174236,""10"":35.9905235499,""11"":42.2330992065,""12"":30.1166627956,""13"":41.9748052751,""14"":11.0347514693,""15"":8.1467473408,""16"":39.7625248862,""17"":16.6224468946,""18"":6.9628186521,""19"":4.6855363604,""20"":5.3476843882,""21"":7.4696017279,""22"":13.2057986257,""23"":8.9685715607,""24"":10.0161180218,""25"":11.8894994118,""26"":5.8323441411,""27"":5.4178723989,""28"":9.3785458332,""29"":10.5004763832,""30"":7.3394234908,""31"":5.3266512073,""32"":18.8218889501,""33"":7.9133633201,""34"":5.7349149873,""35"":20.1945065283,""36"":10.1255982066,""37"":11.96205088,""38"":13.1477795105,""39"":19.5201416721,""40"":16.7777202767,""41"":9.6622938323,""42"":13.4950592751,""43"":13.8823271468,""44"":19.303412459,""45"":10.4977984873,""46"":14.0464282586,""47"":10.3019726263,""48"":5.6385972592,""49"":16.7243731465,""50"":5.8469126022,""51"":7.1921200647,""52"":12.4956907043,""53"":12.6249432539,""54"":12.3189857612,""55"":12.825434898,""56"":7.0593798571,""57"":5.7797097436,""58"":8.5468065298,""59"":8.6368588192,""60"":13.1174927169,""61"":5.1325038204,""62"":4.5130862129,""63"":6.5999312271,""64"":7.6298570658,""65"":6.1483729044,""66"":11.480197847,""67"":11.8019939832,""68"":8.2380037616,""69"":7.5105277515,""70"":9.2820414703,""71"":10.1711876105,""72"":11.023131717,""73"":8.5195678729,""74"":6.0674557061,""75"":5.5507025557,""76"":7.5126321568,""77"":9.1475343039,""78"":5.1286126701,""79"":7.9578575364,""80"":7.0313616108,""81"":4.6101039461,""82"":5.3363060851,""83"":6.1471610411,""84"":8.5180512041,""85"":5.13395579,""86"":8.3886898944,""87"":5.5465188002,""88"":5.9058941092,""89"":6.0730104404,""90"":6.8503524088,""91"":7.5238692141,""92"":5.8696458132,""93"":7.6247601047,""94"":6.1315563156,""95"":5.5460574084,""96"":6.4574942664,""97"":7.3348084314,""98"":7.4583190358,""99"":4.5111174771,""100"":5.2502619003,""101"":7.9890422648,""102"":6.1712951336,""103"":6.5202836477,""104"":6.2444273246,""105"":6.8766609916,""106"":6.6401588311,""107"":10.1479061874,""108"":10.710759349,""109"":8.6668265647,""110"":4.6903953507,""111"":5.5165865821,""112"":7.8046363421,""113"":6.5342172907,""114"":4.8593254474,""115"":5.0361332315,""116"":5.1825600625,""117"":4.7427838334,""118"":5.4668800837,""119"":5.3095177143,""120"":4.8925204258,""121"":5.0518520587,""122"":5.0660009891,""123"":5.7534153608,""124"":5.435913448,""125"":5.4625530975,""126"":7.4216404805,""127"":9.4115346376,""128"":4.422564204,""129"":5.2782171935,""130"":7.9708959494,""131"":5.1556342556,""132"":4.4374338512,""133"":6.05506219,""134"":4.4584215687,""135"":6.68181516,""136"":5.868396568,""137"":6.3437035997,""138"":6.3430352023,""139"":4.5839408634,""140"":5.8187383227,""141"":6.4917445611,""142"":6.553690794,""143"":4.5629930189,""144"":4.700184263,""145"":6.5693464967,""146"":6.3144726094,""147"":5.7353812126,""148"":4.7768241417,""149"":5.0034930656,""150"":5.3947068251,""151"":6.5917894673,""152"":5.4671137417,""153"":6.2017351472,""154"":6.2976386395,""155"":4.7157287518,""156"":4.7214901784,""157"":4.5969250431,""158"":4.394315319,""159"":4.4092320002,""160"":4.5813524706,""161"":4.4826867481,""162"":4.5223735132,""163"":4.4981839106,""164"":4.6225721421,""165"":4.6525586719,""166"":4.6525586719,""167"":4.6525661673,""168"":4.4785668306,""169"":4.4206817059,""170"":4.5585816033,""171"":4.5731067866,""172"":4.5558056226},""count"":{""0"":400,""1"":282,""2"":192,""3"":176,""4"":172,""5"":168,""6"":168,""7"":154,""8"":138,""9"":132,""10"":130,""11"":128,""12"":126,""13"":118,""14"":114,""15"":112,""16"":112,""17"":108,""18"":106,""19"":104,""20"":104,""21"":102,""22"":94,""23"":90,""24"":86,""25"":86,""26"":82,""27"":72,""28"":70,""29"":70,""30"":70,""31"":66,""32"":64,""33"":64,""34"":62,""35"":62,""36"":58,""37"":58,""38"":58,""39"":58,""40"":54,""41"":54,""42"":54,""43"":52,""44"":52,""45"":48,""46"":48,""47"":46,""48"":46,""49"":46,""50"":44,""51"":44,""52"":44,""53"":42,""54"":42,""55"":40,""56"":40,""57"":40,""58"":40,""59"":40,""60"":40,""61"":38,""62"":38,""63"":38,""64"":38,""65"":38,""66"":36,""67"":36,""68"":34,""69"":34,""70"":34,""71"":34,""72"":34,""73"":32,""74"":32,""75"":32,""76"":30,""77"":30,""78"":30,""79"":30,""80"":28,""81"":28,""82"":26,""83"":26,""84"":26,""85"":26,""86"":26,""87"":24,""88"":24,""89"":24,""90"":24,""91"":24,""92"":24,""93"":24,""94"":24,""95"":24,""96"":24,""97"":24,""98"":24,""99"":22,""100"":22,""101"":22,""102"":22,""103"":22,""104"":22,""105"":20,""106"":18,""107"":18,""108"":18,""109"":18,""110"":18,""111"":18,""112"":18,""113"":16,""114"":16,""115"":16,""116"":16,""117"":16,""118"":14,""119"":14,""120"":14,""121"":14,""122"":14,""123"":14,""124"":12,""125"":12,""126"":12,""127"":12,""128"":12,""129"":10,""130"":10,""131"":10,""132"":10,""133"":10,""134"":10,""135"":10,""136"":10,""137"":10,""138"":10,""139"":10,""140"":8,""141"":8,""142"":8,""143"":8,""144"":8,""145"":8,""146"":8,""147"":8,""148"":8,""149"":8,""150"":8,""151"":8,""152"":8,""153"":8,""154"":8,""155"":6,""156"":6,""157"":6,""158"":6,""159"":6,""160"":6,""161"":6,""162"":6,""163"":6,""164"":6,""165"":6,""166"":6,""167"":6,""168"":6,""169"":6,""170"":6,""171"":6,""172"":6},""sigma_nor"":{""0"":1.7038503345,""1"":6.57835034,""2"":5.4533097735,""3"":5.3089692395,""4"":1.4415811589,""5"":1.4045237474,""6"":1.6921639713,""7"":5.435105354,""8"":5.1160127773,""9"":4.0519631369,""10"":4.0191964331,""11"":4.5704328093,""12"":3.5613436963,""13"":4.6844433192,""14"":1.9744845993,""15"":1.7217752299,""16"":4.5743448013,""17"":2.5113390254,""18"":1.6303262195,""19"":1.4231238088,""20"":1.4849374051,""21"":1.6889790602,""22"":2.2752698897,""23"":1.8778107198,""24"":2.0022616792,""25"":2.1929461393,""26"":1.5884566433,""27"":1.5765888474,""28"":2.0255300743,""29"":2.1507388539,""30"":1.7979616031,""31"":1.5877101837,""32"":3.1620531615,""33"":1.8956262053,""34"":1.6513006298,""35"":3.3534735631,""36"":2.2016469583,""37"":2.424197488,""38"":2.5678900201,""39"":3.3401247718,""40"":3.0695882922,""41"":2.1803101244,""42"":2.6593249322,""43"":2.7349722139,""44"":3.4235353941,""45"":2.3489046011,""46"":2.815230427,""47"":2.3463562608,""48"":1.7224567433,""49"":3.2055906715,""50"":1.7635957466,""51"":1.9469463486,""52"":2.6698183937,""53"":2.7194715611,""54"":2.6769558735,""55"":2.7818473213,""56"":1.9643169182,""57"":1.7828810463,""58"":2.1752092039,""59"":2.1879771161,""60"":2.8232562473,""61"":1.7046643132,""62"":1.6149799694,""63"":1.9171304466,""64"":2.0662515273,""65"":1.851750142,""66"":2.6584624315,""67"":2.7060864009,""68"":2.204582104,""69"":2.0944240909,""70"":2.3626754542,""71"":2.4973143574,""72"":2.6263199449,""73"":2.275996822,""74"":1.8956551164,""75"":1.8155026758,""76"":2.1466858332,""77"":2.4067581033,""78"":1.7674476257,""79"":2.217510118,""80"":2.0969567349,""81"":1.7014071214,""82"":1.84107411,""83"":1.9773175332,""84"":2.3756849469,""85"":1.8070743217,""86"":2.3539490895,""87"":1.900145223,""88"":1.9623558633,""89"":1.9912849904,""90"":2.1258488861,""91"":2.2424398446,""92"":1.9560810034,""93"":2.2599048366,""94"":2.0014197333,""95"":1.9000653525,""96"":2.0578421088,""97"":2.2097119636,""98"":2.2310926027,""99"":1.7408415334,""100"":1.8729138995,""101"":2.362286736,""102"":2.0374866603,""103"":2.0998448915,""104"":2.0505541221,""105"":2.1996011193,""106"":2.1937004367,""107"":2.8659926344,""108"":2.9738686445,""109"":2.5821300373,""110"":1.8200102469,""111"":1.9783574317,""112"":2.4168833132,""113"":2.2139772976,""114"":1.8801859418,""115"":1.9154221932,""116"":1.9446037852,""117"":1.8569602133,""118"":2.036501128,""119"":2.0037873118,""120"":1.9170983993,""121"":1.9502216027,""122"":1.9531630016,""123"":2.0960684974,""124"":2.0677333271,""125"":2.0735314046,""126"":2.4999236671,""127"":2.9330209751,""128"":1.847179471,""129"":2.0713196183,""130"":2.6874183737,""131"":2.0432720113,""132"":1.878944063,""133"":2.249065751,""134"":1.8837461608,""135"":2.3924700557,""136"":2.2063556961,""137"":2.3151083908,""138"":2.3149554581,""139"":1.9124656213,""140"":2.239094518,""141"":2.4016875054,""142"":2.4166532256,""143"":1.9357163786,""144"":1.9688606987,""145"":2.4204355196,""146"":2.3588600031,""147"":2.2189560991,""148"":1.9873762876,""149"":2.042137708,""150"":2.1366518599,""151"":2.4258575639,""152"":2.1541447986,""153"":2.3316235234,""154"":2.354793049,""155"":1.9932054416,""156"":1.9946806901,""157"":1.9627850262,""158"":1.9109055686,""159"":1.9147250759,""160"":1.9587975739,""161"":1.9335336129,""162"":1.9436956516,""163"":1.9375017561,""164"":1.9693521226,""165"":1.9770303568,""166"":1.9770303568,""167"":1.977032276,""168"":1.9324786829,""169"":1.9176568431,""170"":1.9529669542,""171"":1.9566862162,""172"":1.9522561474},""vocab_index"":{""0"":1,""1"":4,""2"":6,""3"":7,""4"":8,""5"":10,""6"":11,""7"":12,""8"":14,""9"":16,""10"":17,""11"":18,""12"":20,""13"":22,""14"":24,""15"":27,""16"":28,""17"":30,""18"":31,""19"":32,""20"":33,""21"":34,""22"":36,""23"":40,""24"":41,""25"":42,""26"":43,""27"":46,""28"":48,""29"":49,""30"":50,""31"":53,""32"":54,""33"":56,""34"":62,""35"":63,""36"":67,""37"":68,""38"":69,""39"":70,""40"":71,""41"":75,""42"":77,""43"":80,""44"":81,""45"":86,""46"":87,""47"":90,""48"":91,""49"":92,""50"":94,""51"":98,""52"":100,""53"":106,""54"":107,""55"":108,""56"":110,""57"":111,""58"":116,""59"":117,""60"":118,""61"":119,""62"":121,""63"":122,""64"":123,""65"":125,""66"":133,""67"":134,""68"":135,""69"":136,""70"":138,""71"":139,""72"":140,""73"":141,""74"":142,""75"":143,""76"":149,""77"":152,""78"":153,""79"":154,""80"":155,""81"":164,""82"":167,""83"":168,""84"":169,""85"":172,""86"":174,""87"":175,""88"":180,""89"":184,""90"":186,""91"":188,""92"":192,""93"":193,""94"":194,""95"":197,""96"":198,""97"":199,""98"":200,""99"":203,""100"":215,""101"":218,""102"":221,""103"":225,""104"":226,""105"":228,""106"":269,""107"":273,""108"":274,""109"":276,""110"":278,""111"":279,""112"":280,""113"":291,""114"":294,""115"":295,""116"":300,""117"":316,""118"":333,""119"":342,""120"":345,""121"":346,""122"":358,""123"":361,""124"":363,""125"":375,""126"":404,""127"":414,""128"":424,""129"":432,""130"":439,""131"":455,""132"":490,""133"":516,""134"":521,""135"":522,""136"":524,""137"":530,""138"":531,""139"":532,""140"":536,""141"":548,""142"":625,""143"":626,""144"":633,""145"":643,""146"":650,""147"":652,""148"":658,""149"":660,""150"":668,""151"":675,""152"":679,""153"":680,""154"":681,""155"":877,""156"":908,""157"":917,""158"":919,""159"":920,""160"":923,""161"":959,""162"":970,""163"":977,""164"":984,""165"":1020,""166"":1021,""167"":1022,""168"":1023,""169"":1026,""170"":1027,""171"":1028,""172"":1029},""word"":{""0"":""visualization"",""1"":""ieee"",""2"":""computer"",""3"":""graphics"",""4"":""analysis"",""5"":""based"",""6"":""12"",""7"":""j"",""8"":""h"",""9"":""al"",""10"":""et"",""11"":""transactions"",""12"":""m"",""13"":""pp"",""14"":""user"",""15"":""methods"",""16"":""a"",""17"":""6"",""18"":""exploration"",""19"":""space"",""20"":""11"",""21"":""dimension"",""22"":""g"",""23"":""techniques"",""24"":""e"",""25"":""work"",""26"":""1"",""27"":""points"",""28"":""model"",""29"":""point"",""30"":""linear"",""31"":""subspace"",""32"":""science"",""33"":""14"",""34"":""clustering"",""35"":""symposium"",""36"":""7"",""37"":""scatterplots"",""38"":""k"",""39"":""9"",""40"":""r"",""41"":""section"",""42"":""axis"",""43"":""transformation"",""44"":""l"",""45"":""8"",""46"":""pcps"",""47"":""manipulation"",""48"":""regression"",""49"":""2011"",""50"":""research"",""51"":""pcp"",""52"":""analytics"",""53"":""technology"",""54"":""2010"",""55"":""university"",""56"":""view"",""57"":""recent"",""58"":""non"",""59"":""metric"",""60"":""2009"",""61"":""provide"",""62"":""uncertainty"",""63"":""works"",""64"":""axes"",""65"":""w"",""66"":""2013"",""67"":""forum"",""68"":""allows"",""69"":""tree"",""70"":""interesting"",""71"":""19"",""72"":""proceedings"",""73"":""f"",""74"":""star"",""75"":""addition"",""76"":""rendering"",""77"":""subspaces"",""78"":""n"",""79"":""2012"",""80"":""pipeline"",""81"":""density"",""82"":""encoding"",""83"":""2014"",""84"":""coordinate"",""85"":""users"",""86"":""17"",""87"":""conference"",""88"":""figure"",""89"":""values"",""90"":""introduce"",""91"":""reeb"",""92"":""relationships"",""93"":""measure"",""94"":""ranking"",""95"":""2004"",""96"":""keim"",""97"":""2003"",""98"":""y"",""99"":""acm"",""100"":""hierarchy"",""101"":""order"",""102"":""aligned"",""103"":""2008"",""104"":""2007"",""105"":""utah"",""106"":""concept"",""107"":""2d"",""108"":""sploms"",""109"":""glyph"",""110"":""2005"",""111"":""30"",""112"":""o"",""113"":""nominal"",""114"":""introduces"",""115"":""control"",""116"":""partial"",""117"":""2002"",""118"":""mds"",""119"":""utilize"",""120"":""patterns"",""121"":""automatically"",""122"":""hamann"",""123"":""x"",""124"":""laboratory"",""125"":""\ufb01eld"",""126"":""focal"",""127"":""separate"",""128"":""z"",""129"":""providing"",""130"":""papers"",""131"":""cloud"",""132"":""software"",""133"":""believe"",""134"":""kriegel"",""135"":""edelsbrunner"",""136"":""american"",""137"":""paulovich"",""138"":""nonato"",""139"":""1994"",""140"":""enriched"",""141"":""website"",""142"":""msc"",""143"":""\ufb02ow"",""144"":""generalization"",""145"":""radviz"",""146"":""encode"",""147"":""treemap"",""148"":""transition"",""149"":""magic"",""150"":""aware"",""151"":""harer"",""152"":""mueller"",""153"":""valerio"",""154"":""member"",""155"":""vertices"",""156"":""spring"",""157"":""derivative"",""158"":""direction"",""159"":""lay"",""160"":""pixels"",""161"":""querying"",""162"":""connections"",""163"":""surveyed"",""164"":""quanti\ufb01cation"",""165"":""heine"",""166"":""scheuer"",""167"":""minghim"",""168"":""hanrahan"",""169"":""ph"",""170"":""interests"",""171"":""leader"",""172"":""casc""},""vector"":{""0"":""[ 5.3118887   4.827456    4.0610886   0.6978197   2.4889085   2.124399\n  2.919689   -0.18713455  0.86799157 -2.6711776 ]"",""1"":""[ 5.272981    3.5172675   4.242116    0.8402291   2.6489289   0.9849425\n  0.68792987 -0.70438856  0.9276968  -1.7241896 ]"",""2"":""[ 5.441896    4.807953    3.6991518   0.36082685  2.7006311   2.0605786\n  3.0506957  -0.42365155  1.2322116  -3.2060378 ]"",""3"":""[ 5.277786    4.771789    3.795486    0.54880124  2.6567216   2.135735\n  2.8392506  -0.2737504   1.1653441  -2.8702557 ]"",""4"":""[ 4.9646134   5.0381665   3.8309982   0.5777448   2.156692    1.9269975\n  3.4209578  -0.27048662  0.5955139  -3.0917451 ]"",""5"":""[ 3.9099798   5.2887287   2.3482785   1.8126128   1.8354695   1.6000781\n  3.2363307  -0.30230558  0.3369562  -3.4069118 ]"",""6"":""[ 1.7010112   0.91350394  1.6709075   0.32080376  0.98952425  2.050052\n -1.1110533  -0.40387994 -0.14674059 -0.8396067 ]"",""7"":""[ 4.48048     2.3793678   3.883998    1.1795462   1.0089263   0.33866668\n -0.3624387  -0.5621648   1.2224451  -2.0795553 ]"",""8"":""[ 4.223917    2.2380176   3.7275984   0.96937054  0.9807464   0.3511332\n -0.4801122  -0.7681698   1.0938921  -2.0304606 ]"",""9"":""[ 4.4151726   2.3731658   3.5879347   1.0322759   1.132352    0.18409562\n -0.06834152 -0.7311897   0.95285666 -2.3950276 ]"",""10"":""[ 4.418337    2.3658104   3.5848448   1.0119941   1.152677    0.1989632\n -0.05468833 -0.7284672   0.9487106  -2.4197981 ]"",""11"":""[ 5.4132133   5.4114866   3.9345179   0.5007128   2.3501222   1.9098719\n  3.7597373  -0.40810952  1.1364979  -3.8892365 ]"",""12"":""[ 4.3264303   2.2977068   3.7811422   1.1866049   1.0694163   0.24624965\n -0.54049045 -0.6754133   1.3110973  -2.1343827 ]"",""13"":""[ 4.318436    2.4041414   3.530279    0.9607366   1.1453445   0.32022643\n -0.11040133 -0.7351438   0.96792144 -2.2961414 ]"",""14"":""[ 4.977475   4.920916   3.4305153  0.7948512  2.523015   1.7459809\n  3.077223  -0.6037043  1.5222967 -3.2317145]"",""15"":""[ 5.2489023   5.1140475   3.965105    0.44930804  2.1789734   2.0012531\n  3.8341713  -0.3008014   0.87949145 -3.5772696 ]"",""16"":""[ 4.268627    5.057606    2.4471476   1.536986    1.5901686   1.4202107\n  2.7702734  -0.4221895   0.26800027 -3.5571773 ]"",""17"":""[ 1.7754279   0.88136107  1.7187725   0.14007464  0.8433593   2.0599163\n -1.0289224  -0.29132345 -0.3753783  -0.8466142 ]"",""18"":""[ 5.401759    5.0883946   3.8496962   0.21373272  2.7024343   1.7455819\n  3.3200536  -0.46099356  0.7091781  -3.465299  ]"",""19"":""[ 5.2374315  4.818163   3.9222338  1.0445166  2.1216576  1.537542\n  2.9182987 -0.56103    1.1030784 -3.121888 ]"",""20"":""[ 1.7333373   0.8699317   1.6906395   0.3787046   1.0402464   2.0648806\n -1.0843211  -0.44253418 -0.09207205 -0.8581915 ]"",""21"":""[ 5.001214    4.835346    3.728904    1.150192    1.9084995   1.4796216\n  3.120835   -0.52161807  0.97730947 -3.294236  ]"",""22"":""[ 4.334885    2.2427366   3.7479265   1.0534908   1.0106894   0.35133213\n -0.46538895 -0.6940287   1.0977448  -2.0315244 ]"",""23"":""[ 5.216062    5.0376673   3.9442115   0.51219803  2.182917    2.0992315\n  3.6774786  -0.16316123  0.69105166 -3.3095343 ]"",""24"":""[ 4.4917407   2.2975943   3.678604    1.024136    1.1051531   0.08701494\n -0.23521216 -0.776774    0.9885322  -2.284451  ]"",""25"":""[ 5.118941    5.063276    3.31403     0.4312894   2.3020182   1.767776\n  3.429219   -0.4433813   0.60113806 -3.6520295 ]"",""26"":""[ 1.866243    0.83412045  1.789207    0.20184004  0.8081904   1.9996147\n -1.1276586  -0.34369087 -0.31901124 -0.98421663]"",""27"":""[ 4.5637093   4.964149    3.3877075   1.053039    1.901804    1.6375362\n  3.6821215  -0.48857102  1.067393   -3.551333  ]"",""28"":""[ 5.0752673  5.159536   3.570023   0.8918331  1.6633991  1.7143189\n  3.5487473 -0.4814091  0.6218592 -3.6242056]"",""29"":""[ 4.4266887   4.980283    3.0566735   1.1943557   1.7353925   1.5399842\n  3.580672   -0.49578604  0.7377904  -3.5786135 ]"",""30"":""[ 4.638429    4.875217    2.8772466   1.3446767   1.578451    1.386599\n  2.7217927  -0.47712374  0.3595955  -3.4545717 ]"",""31"":""[ 5.1370444  4.7192698  4.0050554  1.2104787  2.1312187  1.5847343\n  2.6461275 -0.5024394  1.1569829 -2.719568 ]"",""32"":""[ 5.671646    4.8994107   3.6852868   0.25432912  2.521708    2.0447495\n  3.2275183  -0.40171692  0.87931484 -3.6047635 ]"",""33"":""[ 1.6883607   0.96958476  1.6257477   0.33048517  0.9975117   2.009101\n -1.063875   -0.37814718 -0.10564259 -0.83416146]"",""34"":""[ 5.2914042   4.8575716   4.111093    1.0404145   2.1526012   1.8674197\n  2.9492702  -0.29684758  0.81378514 -2.7855527 ]"",""35"":""[ 5.2102156   5.1937904   3.445779    0.37643188  2.6241167   1.7069126\n  3.6749437  -0.62011826  1.3868154  -3.924317  ]"",""36"":""[ 1.8820162   0.8625081   1.8343236   0.1637308   0.8895499   2.0647175\n -0.91277075 -0.40143514 -0.36073923 -0.7633763 ]"",""37"":""[ 5.257172    4.504072    4.141504    0.98665094  2.343066    1.7937251\n  2.407173   -0.33270833  0.8854912  -2.367005  ]"",""38"":""[ 4.374986    2.4534366   3.8487716   1.1577626   1.127211    0.34374812\n -0.51792246 -0.6568889   1.3424802  -2.005826  ]"",""39"":""[ 1.7820121   0.8049048   1.7482653   0.23331071  0.9378442   2.104787\n -1.0376732  -0.4158714  -0.272112   -0.8118986 ]"",""40"":""[ 4.586384    2.3043385   3.8405719   1.035256    1.3429143   0.14743575\n -0.48699188 -0.7737284   1.1611756  -1.9404813 ]"",""41"":""[ 4.269891    4.9811916   2.844994    1.0521078   1.8922908   1.6847159\n  3.490263   -0.4840717   0.73003644 -3.6127496 ]"",""42"":""[ 4.602225   4.625183   3.3243873  1.4937587  1.7361951  1.2287529\n  2.6729898 -0.4834171  0.7805483 -3.122001 ]"",""43"":""[ 5.1754117   4.940577    3.5672898   0.8695061   1.8785712   1.8080716\n  3.4308076  -0.3118503   0.34409514 -3.3379092 ]"",""44"":""[ 4.408449    2.3005118   3.7261827   1.0973574   1.1621228   0.18271528\n -0.40078032 -0.7307888   1.16835    -2.220228  ]"",""45"":""[ 1.8503118   0.784778    1.8202121   0.19315587  0.90098673  2.1144054\n -1.003228   -0.43927574 -0.35553107 -0.7614857 ]"",""46"":""[ 5.431759    3.5986352   4.2605596   0.772698    3.0424457   1.1969652\n  0.6577175  -0.67617744  0.8266314  -1.4398075 ]"",""47"":""[ 5.241466    4.9186497   3.8712306   0.49400187  2.2018342   2.0711212\n  3.594843   -0.16887341  0.54685444 -3.2006352 ]"",""48"":""[ 5.204722    4.927732    3.778463    0.8640553   1.8040996   1.827187\n  3.2894037  -0.31652135  0.36099955 -3.154301  ]"",""49"":""[ 1.9427207   3.3192234   0.52555984  1.8863642   0.63129926  0.7276427\n  1.9872699  -1.4339113   0.19891204 -3.7032323 ]"",""50"":""[ 5.3217807   4.9964504   3.6740937   0.14041542  2.608677    1.787392\n  3.4350104  -0.51488984  0.90068924 -3.591442  ]"",""51"":""[ 5.2853436   3.5685763   4.27463     0.86322707  2.5534115   1.0322086\n  0.7571187  -0.66151524  0.9643598  -1.7594938 ]"",""52"":""[ 5.3752275   4.917702    4.1284757   0.45428616  2.5113344   2.154925\n  3.1347492  -0.20979823  0.9072864  -2.8256035 ]"",""53"":""[ 5.4872737   4.916791    3.7262652   0.3357829   2.5100062   2.032821\n  3.1327567  -0.36293864  0.9850371  -3.389571  ]"",""54"":""[ 2.1236262   3.4487169   0.70273733  1.9101363   0.6124462   0.7129976\n  1.9201759  -1.5292401   0.34356278 -3.641699  ]"",""55"":""[ 5.478923    4.906179    3.6234353   0.17871836  2.6651866   1.9110354\n  3.3302543  -0.51990485  1.0811414  -3.5876515 ]"",""56"":""[ 4.510219    4.948102    3.13791     0.9836333   1.8627315   1.6380912\n  3.5732906  -0.48592612  0.7357151  -3.5563557 ]"",""57"":""[ 3.9292295   4.9621115   2.2879612   1.3616947   1.6728177   1.5383779\n  3.1096733  -0.49656573  0.4308561  -3.6660967 ]"",""58"":""[ 4.316539    4.906121    2.4718764   1.5062222   1.502107    1.2701279\n  2.549878   -0.47509438  0.2643696  -3.5384614 ]"",""59"":""[ 4.9479675   5.0330043   3.7428236   1.3180711   1.9446088   1.4613445\n  3.0497017  -0.48405847  0.9629251  -3.1902938 ]"",""60"":""[ 1.9470947   3.3990593   0.57180035  1.8732884   0.7069077   0.7000517\n  2.0011592  -1.3559967   0.09716554 -3.7293024 ]"",""61"":""[ 3.9068973   5.4161596   2.4500473   1.7912258   1.9743682   1.6398755\n  3.0457942  -0.16720004  0.21760495 -3.170498  ]"",""62"":""[ 5.343794    4.8762484   3.8382914   0.89396495  2.3380835   1.9808073\n  3.2350986  -0.22156757  0.5813679  -3.1327171 ]"",""63"":""[ 5.086369    5.1175785   3.4245403   0.4116258   2.1806343   1.8866966\n  3.3865404  -0.4088029   0.84140664 -3.760461  ]"",""64"":""[ 4.654732    4.672679    3.4422326   1.3945351   1.8344328   1.3658217\n  2.808852   -0.45205784  0.83647376 -3.0723503 ]"",""65"":""[ 4.4785767   2.3663464   3.6504776   1.0562112   1.2038311   0.13478121\n -0.3526523  -0.8038979   1.1049902  -2.2188156 ]"",""66"":""[ 1.9765791  3.3235655  0.5618713  1.8821961  0.6177797  0.7228643\n  1.951337  -1.4575195  0.2641279 -3.6375933]"",""67"":""[ 5.067172    5.1359787   3.3171837   0.5324594   2.5654247   1.7342007\n  3.502677   -0.62746304  1.4542214  -3.7659328 ]"",""68"":""[ 3.7446446   5.332719    2.209952    1.697442    1.7541898   1.5562001\n  2.7813487  -0.17231968  0.10868758 -3.2505739 ]"",""69"":""[ 5.298029    5.361618    3.9011765   0.9728051   1.7832508   1.7723958\n  3.5653865  -0.34176156  0.78202164 -3.8108337 ]"",""70"":""[ 4.148807    5.0503936   2.4725168   1.4097272   1.7041136   1.4713681\n  3.10376    -0.44995368  0.442451   -3.6359859 ]"",""71"":""[ 1.7459576   0.9886292   1.7012208   0.31066585  0.9768478   2.145617\n -1.0758408  -0.50056803 -0.11563093 -0.95104766]"",""72"":""[ 5.220168    5.3414536   3.6651955   0.44806406  2.4794667   1.7482175\n  3.8540642  -0.52219033  1.3214076  -4.0522995 ]"",""73"":""[ 4.3275843   2.4183483   3.643122    0.9613173   1.0959777   0.3759759\n -0.33093163 -0.76060337  1.0673754  -2.0320487 ]"",""74"":""[ 5.0210686   5.1877666   3.4167762   1.1676723   1.7097166   1.6003557\n  3.5815315  -0.49825972  0.8112662  -3.6585987 ]"",""75"":""[ 3.8412447   5.0658064   2.3728542   1.3189241   1.8455428   1.7635525\n  3.2530215  -0.39633182  0.41691235 -3.5233347 ]"",""76"":""[ 4.633196    5.068903    3.2736604   1.0964689   2.262851    2.0470884\n  3.0865443  -0.10169166  0.5682947  -2.9279995 ]"",""77"":""[ 5.137383   4.643463   4.037827   1.1674656  2.171196   1.6414057\n  2.5693047 -0.4480489  1.1459953 -2.6408417]"",""78"":""[ 4.388821    2.3088443   3.7128775   1.1141136   1.187896    0.21209238\n -0.48700395 -0.74130124  1.2182171  -2.1361945 ]"",""79"":""[ 2.0679102   3.3903623   0.63790125  1.7868237   0.6188127   0.8362073\n  2.059221   -1.4783865   0.15628353 -3.7315042 ]"",""80"":""[ 5.42354     5.0348825   3.8367555   0.25245026  2.6571467   1.8856691\n  3.2274215  -0.39708433  0.8271727  -3.386818  ]"",""81"":""[ 5.317772   4.8356366  4.1113496  1.0961059  2.1302342  1.6540467\n  2.904601  -0.4630669  1.035263  -2.9536777]"",""82"":""[ 5.005056    4.8872104   3.8472815   0.9827939   2.318898    1.9797096\n  2.89887    -0.145316    0.82270193 -2.6931868 ]"",""83"":""[ 2.0665576   3.384493    0.6171475   1.802469    0.63666534  0.83358175\n  2.0598993  -1.4805913   0.17361932 -3.6884656 ]"",""84"":""[ 4.168281    5.372769    2.7404425   1.8701707   1.9394271   1.3936493\n  2.9700894  -0.23990946  0.33880946 -3.1536689 ]"",""85"":""[ 5.078225    5.02577     3.5604424   0.67604154  2.5609121   1.8565565\n  3.2090228  -0.5307372   1.5079479  -3.3391814 ]"",""86"":""[ 1.7126024   0.9956771   1.6463939   0.31729016  1.0055298   1.9477433\n -0.99380577 -0.37941527 -0.14955059 -0.73053455]"",""87"":""[ 5.225056    5.234337    3.5112715   0.4303586   2.5403683   1.7351484\n  3.738895   -0.56624526  1.3317754  -3.9691136 ]"",""88"":""[ 4.892023    5.178645    3.3398373   0.99879164  1.7060754   1.626798\n  3.6011033  -0.53204876  0.73789173 -3.7059357 ]"",""89"":""[ 5.345963    5.273572    4.102385    0.7016943   2.0770023   1.8431892\n  3.7919016  -0.35429493  0.9648486  -3.7403553 ]"",""90"":""[ 3.9241703   5.491304    2.5169153   1.8398678   1.974678    1.5128024\n  2.93245    -0.15615526  0.19664691 -3.1201882 ]"",""91"":""[ 5.526449    3.3125212   4.4837723   0.7851247   3.2258103   1.0726099\n  0.27697664 -0.60133946  0.601903   -1.0554334 ]"",""92"":""[ 5.407399    5.3446465   3.9769354   0.68372947  1.9863068   1.8703563\n  3.7382274  -0.3388052   0.792813   -3.8417964 ]"",""93"":""[ 4.628302    5.2791896   3.302853    1.5433769   1.9371297   1.4543525\n  3.0875103  -0.34083572  0.5624867  -3.1968443 ]"",""94"":""[ 4.9619064   5.427715    3.8172688   1.1544937   1.9225881   1.586868\n  3.6074934  -0.39987952  1.0742216  -3.8389392 ]"",""95"":""[ 2.3438504  3.582366   0.8256924  1.6659361  0.8028145  0.9763994\n  2.152481  -1.357986   0.2989214 -3.5804427]"",""96"":""[ 5.512055    3.4142869   4.312924    0.739599    3.4354591   1.2049781\n  0.17870475 -0.71459776  0.7395893  -1.0286915 ]"",""97"":""[ 2.3443851   3.6312435   0.8189575   1.7551223   0.78954315  0.88891464\n  2.062495   -1.4224441   0.2449778  -3.5756693 ]"",""98"":""[ 4.583779    2.453168    3.7614477   1.1074007   0.9733536   0.03370323\n -0.32093805 -0.74242043  1.0813599  -1.887248  ]"",""99"":""[ 5.279632    3.4476845   4.212398    0.80361426  2.7473986   1.0134742\n  0.56725246 -0.7479504   0.9312647  -1.6260885 ]"",""100"":""[ 5.1420555   5.4763417   3.8540564   1.072537    1.8052729   1.671013\n  3.6539304  -0.35176703  0.87430423 -3.9349556 ]"",""101"":""[ 5.045711   5.4286103  3.8286755  0.9761791  1.9387352  1.6090243\n  3.6951282 -0.3688764  0.9718104 -4.0161643]"",""102"":""[ 4.052284    5.3271422   2.560265    1.9067684   1.8892536   1.4422218\n  3.2030947  -0.30751923  0.4394162  -3.317571  ]"",""103"":""[ 2.0556135   3.4366455   0.6551704   1.7827653   0.6540698   0.8088069\n  2.038283   -1.4184887   0.04847649 -3.8182726 ]"",""104"":""[ 2.1648304   3.433923    0.72573245  1.699873    0.6643417   0.9241629\n  2.146263   -1.4208883   0.13834132 -3.745733  ]"",""105"":""[ 5.151356    3.4100091   4.1294193   0.9268558   2.3927324   0.8898508\n  0.66807795 -0.69767886  0.9936121  -1.9195026 ]"",""106"":""[ 5.047845    5.056545    3.511426    0.7579428   1.8569566   1.671173\n  3.3066692  -0.46002632  0.7001359  -3.66777   ]"",""107"":""[ 2.086064    1.0745176   1.9521581   0.25700536  0.91214716  1.8913419\n -0.9370346  -0.39695543 -0.17155308 -1.0070692 ]"",""108"":""[ 5.3186703   3.6075313   4.2121215   0.7994763   2.8485997   1.168976\n  0.6867602  -0.7427038   0.94591707 -1.657544  ]"",""109"":""[ 5.038495    4.7261634   3.8702414   1.0080571   2.3895478   1.9017929\n  2.606406   -0.22660749  1.0536339  -2.5978923 ]"",""110"":""[ 2.2253206   3.5189815   0.70658654  1.7836225   0.71382403  0.8619589\n  2.0570064  -1.4590707   0.21935488 -3.610513  ]"",""111"":""[ 1.6600336   1.0171113   1.5772496   0.30591038  0.95890033  1.9509991\n -1.0729891  -0.31147435 -0.11523378 -0.8436864 ]"",""112"":""[ 4.490167    2.2520902   3.7641947   1.0958792   1.0481058   0.0305661\n -0.37776318 -0.771007    1.0666667  -2.1696732 ]"",""113"":""[ 4.490403    4.976624    2.6518939   1.5555676   1.4622431   1.2246761\n  2.775301   -0.48815548  0.27412984 -3.5461907 ]"",""114"":""[ 3.8109035   5.4715576   2.3608427   1.797573    1.8943914   1.5612686\n  2.911646   -0.13311349  0.15905589 -3.1861053 ]"",""115"":""[ 4.5802207   5.17012     3.011274    1.4654684   1.7946486   1.4017656\n  3.1163244  -0.34365427  0.34836137 -3.4131782 ]"",""116"":""[ 4.421763    4.9609137   2.5821166   1.447079    1.540957    1.3247614\n  2.747424   -0.4982096   0.32037905 -3.6108985 ]"",""117"":""[ 2.3466485   3.7578964   0.8408337   1.8099526   0.8436516   0.8277609\n  1.9845922  -1.4282757   0.14104502 -3.637546  ]"",""118"":""[ 5.3095574   3.571171    4.2766986   0.88549083  2.6333017   1.0861778\n  0.74008286 -0.64252687  0.9334821  -1.7074853 ]"",""119"":""[ 3.8957646   5.4613147   2.5581734   1.902321    1.9537628   1.4631181\n  3.0197306  -0.21378489  0.29344994 -3.1542583 ]"",""120"":""[ 5.303967    5.2132106   4.06734     0.61373985  2.1317642   2.0290496\n  3.715408   -0.26227242  0.92913747 -3.4987628 ]"",""121"":""[ 3.994353    5.153312    2.3014526   1.5453585   1.6508682   1.4801472\n  2.5985131  -0.25657767  0.14014404 -3.3235488 ]"",""122"":""[ 5.3723655   3.4981852   4.383362    0.6157624   3.3825285   1.2114658\n  0.17848077 -0.64510024  0.7197483  -0.95865446]"",""123"":""[ 4.519521    2.432941    3.8229852   1.152058    0.92012966  0.16361287\n -0.38412294 -0.66001266  1.1603113  -1.8675858 ]"",""124"":""[ 5.4709225   4.835429    3.74814     0.11643896  2.5741444   1.8837569\n  3.3619847  -0.48943147  0.8943029  -3.4592779 ]"",""125"":""[ 5.5073285   4.6200438   3.856832    0.32552236  2.6534894   1.6744845\n  2.833726   -0.54435724  0.8170824  -3.0603106 ]"",""126"":""[ 4.4322615  4.8871017  3.0025065  1.327616   1.6331927  1.4252053\n  3.334566  -0.4842691  0.6887949 -3.528893 ]"",""127"":""[ 4.2665906   5.1727524   2.5690215   1.665637    1.6865829   1.3481414\n  2.8494267  -0.377335    0.28391364 -3.4434347 ]"",""128"":""[ 4.4983544   2.388313    3.8424218   1.1225005   1.1112379   0.16347525\n -0.4918256  -0.7309776   1.2262049  -1.8699613 ]"",""129"":""[ 3.9849262   5.2438645   2.463413    1.5312604   1.9096507   1.7973945\n  3.0792937  -0.19672497  0.2812282  -3.2843165 ]"",""130"":""[ 5.256001   5.13853    3.5769377  0.2404423  2.554156   1.7791995\n  3.705435  -0.5596947  1.1285012 -3.8775213]"",""131"":""[ 5.429383    4.8397975   3.9716897   0.7868741   2.4338183   2.079271\n  3.1278522  -0.22616455  0.7817437  -2.976036  ]"",""132"":""[ 5.300554   4.8940244  3.8003519  0.5446554  2.5648859  2.0531788\n  3.0387826 -0.3344809  1.1419188 -3.0692575]"",""133"":""[ 3.8625197   5.0439      2.4717479   1.6146622   1.726572    1.4984627\n  3.4182646  -0.402942    0.60897315 -3.382977  ]"",""134"":""[ 5.4424      3.2958877   4.4500837   0.7205104   3.3996644   1.1207582\n  0.10431125 -0.6657298   0.70015556 -0.9246453 ]"",""135"":""[ 5.493925    3.2518291   4.541459    0.83156544  3.1240695   0.9982948\n  0.37190837 -0.57085603  0.70475084 -1.2366549 ]"",""136"":""[ 5.0903964   3.4654431   3.9774587   0.9133087   2.3255777   0.8929603\n  0.77192396 -0.76005065  0.9790081  -2.0558355 ]"",""137"":""[ 5.5715294   3.3802998   4.4369454   0.7936133   3.3019247   1.1490046\n  0.3507307  -0.60349816  0.68375856 -1.1738886 ]"",""138"":""[ 5.392262    3.361523    4.3644996   0.73880106  3.0386868   1.0875317\n  0.27969325 -0.7021614   0.78944343 -1.1878455 ]"",""139"":""[ 2.3187575   3.637532    0.77863306  1.768352    0.80259633  0.88255435\n  2.0626438  -1.4188699   0.21999678 -3.5559044 ]"",""140"":""[ 4.1197495   5.299742    2.4867475   1.5666587   1.9282175   1.6435739\n  3.1670523  -0.29497072  0.33473325 -3.499754  ]"",""141"":""[ 4.955218    5.0483723   3.271682    0.6256911   2.4670832   1.7603521\n  3.359624   -0.58894813  1.3546863  -3.609643  ]"",""142"":""[ 5.2239165  3.465841   4.149101   0.8157629  2.5827448  0.9569166\n  0.6594351 -0.7800347  0.9918791 -1.8152909]"",""143"":""[ 5.423207   4.470457   4.0912514  0.7185129  2.52166    1.6955292\n  2.4259138 -0.4350416  0.7895162 -2.5227413]"",""144"":""[ 5.1199393   4.8998175   3.9574022   0.7158495   2.102754    1.9494728\n  3.2983198  -0.21781346  0.49051702 -2.9217174 ]"",""145"":""[ 5.4053445   3.4692824   4.309286    0.73962176  3.0375674   1.1192484\n  0.44272524 -0.68972665  0.7794501  -1.306922  ]"",""146"":""[ 4.153544    5.4656034   2.7747073   1.8277527   2.05059     1.549375\n  2.9088278  -0.11641553  0.29067835 -2.9840732 ]"",""147"":""[ 5.3242955   4.5197983   4.1456537   0.84017175  2.4963021   1.9039462\n  2.417174   -0.2834631   0.88918597 -2.3660924 ]"",""148"":""[ 5.1467614   5.018298    3.4951038   0.9543865   1.9172652   1.797777\n  3.456269   -0.32932317  0.36709535 -3.4333205 ]"",""149"":""[ 5.510437    4.8257337   3.7476387   0.45561445  2.2616968   2.0412683\n  3.3450377  -0.29954347  0.6924442  -3.3800187 ]"",""150"":""[ 3.975153    5.148877    2.5103426   1.7104522   1.7696292   1.4600494\n  3.341038   -0.32654348  0.57477576 -3.3487003 ]"",""151"":""[ 5.5458646   3.3191183   4.491658    0.8248482   3.241525    1.0964849\n  0.30067533 -0.57856077  0.6378633  -1.0990186 ]"",""152"":""[ 5.1678486   3.4498174   4.1572533   0.85725045  2.5420346   0.97830886\n  0.615371   -0.7360678   1.0036559  -1.790207  ]"",""153"":""[ 5.290771    3.2018309   4.3083086   0.7399794   3.0108666   1.0076945\n  0.04424088 -0.76222104  0.8306091  -1.0923585 ]"",""154"":""[ 4.787543   5.23644    3.2555358  1.0867579  1.9359117  1.6108751\n  3.6101818 -0.5547301  1.1007724 -3.7641115]"",""155"":""[ 5.095082    4.615647    3.9647765   1.1304502   2.259002    1.6839767\n  2.489148   -0.41295436  1.1854664  -2.5957255 ]"",""156"":""[ 2.3745837   3.6524696   0.8519965   1.7329605   0.8148879   0.904203\n  2.0815556  -1.3997867   0.23016767 -3.5858207 ]"",""157"":""[ 5.0048857   5.0058327   3.2875302   0.60663414  1.9162419   1.6699252\n  3.0730042  -0.45734918  0.6379693  -3.7630177 ]"",""158"":""[ 4.723029    5.037657    3.2393363   1.2316525   1.8696982   1.4603889\n  3.3420265  -0.42085782  0.5470249  -3.4847736 ]"",""159"":""[ 3.9992054   5.46332     2.4958842   1.8772722   1.9232321   1.6329798\n  3.0620544  -0.11479412  0.23838688 -3.096717  ]"",""160"":""[ 5.192816    4.7011023   3.9463363   0.94182724  2.3956861   1.8237221\n  2.6423435  -0.393852    1.2470536  -2.7257981 ]"",""161"":""[ 4.2838736   5.193821    2.8640254   1.4023182   2.0503817   1.9069111\n  3.2070658  -0.14168495  0.44964248 -3.125966  ]"",""162"":""[ 5.2901936   5.3528857   3.9362748   0.58328485  2.1150813   1.9379417\n  3.8014076  -0.33443707  0.9106211  -3.797456  ]"",""163"":""[ 4.069173    5.4244046   2.5917544   1.9603875   1.9387443   1.5446658\n  3.2812393  -0.19529119  0.45563996 -3.1708398 ]"",""164"":""[ 5.1156497   4.83853     3.9953136   0.69839966  2.2778141   1.9561422\n  3.106843   -0.21057513  0.6159055  -2.7818897 ]"",""165"":""[ 5.4986067   3.3835673   4.465391    0.68745977  3.413557    1.1390324\n  0.15150146 -0.6038003   0.57969147 -0.865602  ]"",""166"":""[ 5.3980427   3.3457186   4.4744678   0.65008825  3.4816554   1.172318\n  0.08138569 -0.6456893   0.6771457  -0.83119607]"",""167"":""[ 5.496095    3.503113    4.3638515   0.81337094  3.1401129   1.1950758\n  0.48462263 -0.6338638   0.7680795  -1.3803421 ]"",""168"":""[ 5.3820114   3.2587597   4.3677135   0.722477    3.2815561   1.0745907\n  0.02770616 -0.702506    0.71528876 -0.94008815]"",""169"":""[ 4.3091493   2.339757    3.7140923   0.94573975  1.1124473   0.40304387\n -0.2710133  -0.71901125  0.9925976  -1.9542    ]"",""170"":""[ 5.391596    5.262637    3.8759336   0.42751452  2.2376366   1.8879247\n  3.7287083  -0.39902693  0.89061064 -3.845717  ]"",""171"":""[ 4.930418    5.224158    3.3532324   1.1605659   1.8354584   1.5749224\n  3.5872672  -0.48104444  0.8848798  -3.7100317 ]"",""172"":""[ 5.4327197   3.4261968   4.3909144   0.81051224  2.9831364   1.0759962\n  0.5274152  -0.65038884  0.79097146 -1.3700843 ]""},""topic"":{""0"":8,""1"":4,""2"":-1,""3"":-1,""4"":-1,""5"":5,""6"":0,""7"":2,""8"":2,""9"":2,""10"":2,""11"":11,""12"":2,""13"":2,""14"":-1,""15"":11,""16"":6,""17"":0,""18"":-1,""19"":-1,""20"":0,""21"":-1,""22"":2,""23"":-1,""24"":2,""25"":-1,""26"":0,""27"":-1,""28"":10,""29"":-1,""30"":-1,""31"":7,""32"":9,""33"":0,""34"":-1,""35"":-1,""36"":0,""37"":7,""38"":2,""39"":0,""40"":2,""41"":-1,""42"":-1,""43"":-1,""44"":2,""45"":0,""46"":-1,""47"":-1,""48"":-1,""49"":1,""50"":9,""51"":4,""52"":-1,""53"":9,""54"":1,""55"":9,""56"":10,""57"":-1,""58"":-1,""59"":-1,""60"":1,""61"":5,""62"":-1,""63"":-1,""64"":-1,""65"":2,""66"":1,""67"":-1,""68"":-1,""69"":11,""70"":6,""71"":0,""72"":-1,""73"":2,""74"":-1,""75"":-1,""76"":-1,""77"":7,""78"":2,""79"":1,""80"":9,""81"":-1,""82"":-1,""83"":1,""84"":5,""85"":-1,""86"":0,""87"":-1,""88"":10,""89"":11,""90"":5,""91"":3,""92"":11,""93"":-1,""94"":-1,""95"":1,""96"":3,""97"":1,""98"":2,""99"":4,""100"":-1,""101"":-1,""102"":5,""103"":1,""104"":1,""105"":4,""106"":-1,""107"":0,""108"":4,""109"":7,""110"":1,""111"":0,""112"":2,""113"":6,""114"":5,""115"":-1,""116"":6,""117"":1,""118"":4,""119"":5,""120"":11,""121"":-1,""122"":3,""123"":2,""124"":9,""125"":-1,""126"":-1,""127"":-1,""128"":2,""129"":5,""130"":-1,""131"":8,""132"":8,""133"":-1,""134"":3,""135"":3,""136"":-1,""137"":3,""138"":3,""139"":1,""140"":5,""141"":-1,""142"":4,""143"":-1,""144"":8,""145"":3,""146"":5,""147"":-1,""148"":-1,""149"":-1,""150"":5,""151"":3,""152"":4,""153"":-1,""154"":-1,""155"":7,""156"":1,""157"":-1,""158"":-1,""159"":5,""160"":-1,""161"":-1,""162"":11,""163"":5,""164"":8,""165"":3,""166"":3,""167"":3,""168"":3,""169"":2,""170"":11,""171"":10,""172"":3},""exemplar"":{""0"":""*"",""1"":""*"",""2"":null,""3"":null,""4"":null,""5"":null,""6"":""*"",""7"":null,""8"":null,""9"":null,""10"":null,""11"":null,""12"":null,""13"":null,""14"":null,""15"":""*"",""16"":""*"",""17"":null,""18"":null,""19"":null,""20"":""*"",""21"":null,""22"":""*"",""23"":null,""24"":""*"",""25"":null,""26"":null,""27"":null,""28"":""*"",""29"":null,""30"":null,""31"":""*"",""32"":null,""33"":""*"",""34"":null,""35"":null,""36"":null,""37"":""*"",""38"":null,""39"":""*"",""40"":null,""41"":null,""42"":null,""43"":null,""44"":""*"",""45"":null,""46"":null,""47"":null,""48"":null,""49"":null,""50"":null,""51"":null,""52"":null,""53"":""*"",""54"":null,""55"":""*"",""56"":""*"",""57"":null,""58"":null,""59"":null,""60"":""*"",""61"":null,""62"":null,""63"":null,""64"":null,""65"":null,""66"":""*"",""67"":null,""68"":null,""69"":null,""70"":""*"",""71"":null,""72"":null,""73"":null,""74"":null,""75"":null,""76"":null,""77"":""*"",""78"":""*"",""79"":""*"",""80"":""*"",""81"":null,""82"":null,""83"":""*"",""84"":null,""85"":null,""86"":null,""87"":null,""88"":""*"",""89"":""*"",""90"":null,""91"":""*"",""92"":null,""93"":null,""94"":null,""95"":null,""96"":""*"",""97"":null,""98"":null,""99"":""*"",""100"":null,""101"":null,""102"":""*"",""103"":null,""104"":null,""105"":null,""106"":null,""107"":null,""108"":null,""109"":""*"",""110"":null,""111"":null,""112"":null,""113"":""*"",""114"":""*"",""115"":null,""116"":""*"",""117"":null,""118"":null,""119"":""*"",""120"":null,""121"":null,""122"":null,""123"":null,""124"":""*"",""125"":null,""126"":null,""127"":null,""128"":null,""129"":null,""130"":null,""131"":""*"",""132"":""*"",""133"":null,""134"":""*"",""135"":null,""136"":null,""137"":null,""138"":null,""139"":null,""140"":null,""141"":null,""142"":""*"",""143"":null,""144"":""*"",""145"":null,""146"":null,""147"":null,""148"":null,""149"":null,""150"":null,""151"":null,""152"":""*"",""153"":null,""154"":null,""155"":""*"",""156"":null,""157"":null,""158"":null,""159"":""*"",""160"":null,""161"":null,""162"":""*"",""163"":null,""164"":""*"",""165"":""*"",""166"":""*"",""167"":null,""168"":null,""169"":null,""170"":""*"",""171"":""*"",""172"":null},""word*"":{""0"":""visualization*"",""1"":""ieee*"",""2"":""computer"",""3"":""graphics"",""4"":""analysis"",""5"":""based"",""6"":""12*"",""7"":""j"",""8"":""h"",""9"":""al"",""10"":""et"",""11"":""transactions"",""12"":""m"",""13"":""pp"",""14"":""user"",""15"":""methods*"",""16"":""a*"",""17"":""6"",""18"":""exploration"",""19"":""space"",""20"":""11*"",""21"":""dimension"",""22"":""g*"",""23"":""techniques"",""24"":""e*"",""25"":""work"",""26"":""1"",""27"":""points"",""28"":""model*"",""29"":""point"",""30"":""linear"",""31"":""subspace*"",""32"":""science"",""33"":""14*"",""34"":""clustering"",""35"":""symposium"",""36"":""7"",""37"":""scatterplots*"",""38"":""k"",""39"":""9*"",""40"":""r"",""41"":""section"",""42"":""axis"",""43"":""transformation"",""44"":""l*"",""45"":""8"",""46"":""pcps"",""47"":""manipulation"",""48"":""regression"",""49"":""2011"",""50"":""research"",""51"":""pcp"",""52"":""analytics"",""53"":""technology*"",""54"":""2010"",""55"":""university*"",""56"":""view*"",""57"":""recent"",""58"":""non"",""59"":""metric"",""60"":""2009*"",""61"":""provide"",""62"":""uncertainty"",""63"":""works"",""64"":""axes"",""65"":""w"",""66"":""2013*"",""67"":""forum"",""68"":""allows"",""69"":""tree"",""70"":""interesting*"",""71"":""19"",""72"":""proceedings"",""73"":""f"",""74"":""star"",""75"":""addition"",""76"":""rendering"",""77"":""subspaces*"",""78"":""n*"",""79"":""2012*"",""80"":""pipeline*"",""81"":""density"",""82"":""encoding"",""83"":""2014*"",""84"":""coordinate"",""85"":""users"",""86"":""17"",""87"":""conference"",""88"":""figure*"",""89"":""values*"",""90"":""introduce"",""91"":""reeb*"",""92"":""relationships"",""93"":""measure"",""94"":""ranking"",""95"":""2004"",""96"":""keim*"",""97"":""2003"",""98"":""y"",""99"":""acm*"",""100"":""hierarchy"",""101"":""order"",""102"":""aligned*"",""103"":""2008"",""104"":""2007"",""105"":""utah"",""106"":""concept"",""107"":""2d"",""108"":""sploms"",""109"":""glyph*"",""110"":""2005"",""111"":""30"",""112"":""o"",""113"":""nominal*"",""114"":""introduces*"",""115"":""control"",""116"":""partial*"",""117"":""2002"",""118"":""mds"",""119"":""utilize*"",""120"":""patterns"",""121"":""automatically"",""122"":""hamann"",""123"":""x"",""124"":""laboratory*"",""125"":""\ufb01eld"",""126"":""focal"",""127"":""separate"",""128"":""z"",""129"":""providing"",""130"":""papers"",""131"":""cloud*"",""132"":""software*"",""133"":""believe"",""134"":""kriegel*"",""135"":""edelsbrunner"",""136"":""american"",""137"":""paulovich"",""138"":""nonato"",""139"":""1994"",""140"":""enriched"",""141"":""website"",""142"":""msc*"",""143"":""\ufb02ow"",""144"":""generalization*"",""145"":""radviz"",""146"":""encode"",""147"":""treemap"",""148"":""transition"",""149"":""magic"",""150"":""aware"",""151"":""harer"",""152"":""mueller*"",""153"":""valerio"",""154"":""member"",""155"":""vertices*"",""156"":""spring"",""157"":""derivative"",""158"":""direction"",""159"":""lay*"",""160"":""pixels"",""161"":""querying"",""162"":""connections*"",""163"":""surveyed"",""164"":""quanti\ufb01cation*"",""165"":""heine*"",""166"":""scheuer*"",""167"":""minghim"",""168"":""hanrahan"",""169"":""ph"",""170"":""interests*"",""171"":""leader*"",""172"":""casc""},""pos"":{""0"":1,""1"":1,""2"":1,""3"":2,""4"":3,""5"":1,""6"":1,""7"":1,""8"":2,""9"":3,""10"":4,""11"":1,""12"":5,""13"":6,""14"":4,""15"":2,""16"":1,""17"":2,""18"":5,""19"":6,""20"":3,""21"":7,""22"":7,""23"":8,""24"":8,""25"":9,""26"":4,""27"":10,""28"":1,""29"":11,""30"":12,""31"":1,""32"":1,""33"":5,""34"":13,""35"":14,""36"":6,""37"":2,""38"":9,""39"":7,""40"":10,""41"":15,""42"":16,""43"":17,""44"":11,""45"":8,""46"":18,""47"":19,""48"":20,""49"":1,""50"":2,""51"":2,""52"":21,""53"":3,""54"":2,""55"":4,""56"":2,""57"":22,""58"":23,""59"":24,""60"":3,""61"":2,""62"":25,""63"":26,""64"":27,""65"":12,""66"":4,""67"":28,""68"":29,""69"":3,""70"":2,""71"":9,""72"":30,""73"":13,""74"":31,""75"":32,""76"":33,""77"":3,""78"":14,""79"":5,""80"":5,""81"":34,""82"":35,""83"":6,""84"":3,""85"":36,""86"":10,""87"":37,""88"":3,""89"":4,""90"":4,""91"":1,""92"":5,""93"":38,""94"":39,""95"":7,""96"":2,""97"":8,""98"":15,""99"":3,""100"":40,""101"":41,""102"":5,""103"":9,""104"":10,""105"":4,""106"":42,""107"":11,""108"":5,""109"":4,""110"":11,""111"":12,""112"":16,""113"":3,""114"":6,""115"":43,""116"":4,""117"":12,""118"":6,""119"":7,""120"":6,""121"":44,""122"":3,""123"":17,""124"":6,""125"":45,""126"":46,""127"":47,""128"":18,""129"":8,""130"":48,""131"":2,""132"":3,""133"":49,""134"":4,""135"":5,""136"":50,""137"":6,""138"":7,""139"":13,""140"":9,""141"":51,""142"":7,""143"":52,""144"":4,""145"":8,""146"":10,""147"":53,""148"":54,""149"":55,""150"":11,""151"":9,""152"":8,""153"":56,""154"":57,""155"":5,""156"":14,""157"":58,""158"":59,""159"":12,""160"":60,""161"":61,""162"":7,""163"":13,""164"":5,""165"":10,""166"":11,""167"":12,""168"":13,""169"":19,""170"":8,""171"":4,""172"":14},""x2D"":{""0"":10.1959400177,""1"":-5.8377652168,""2"":9.1849451065,""3"":9.7890691757,""4"":9.8023414612,""5"":13.024810791,""6"":-4.3944029808,""7"":-15.6660737991,""8"":-16.1369247437,""9"":-16.5604839325,""10"":-16.5864868164,""11"":8.2962741852,""12"":-15.9066724777,""13"":-16.5217075348,""14"":7.9996781349,""15"":8.6306838989,""16"":12.5412063599,""17"":-4.0924072266,""18"":8.6475601196,""19"":11.0853853226,""20"":-4.3847718239,""21"":11.1338100433,""22"":-15.992316246,""23"":9.3791713715,""24"":-16.4166297913,""25"":8.8175373077,""26"":-4.1836409569,""27"":10.6008806229,""28"":10.0320148468,""29"":11.0646371841,""30"":12.2338085175,""31"":11.205324173,""32"":8.6917953491,""33"":-4.4794688225,""34"":10.5970020294,""35"":7.9940509796,""36"":-3.9302756786,""37"":11.0741090775,""38"":-15.7642688751,""39"":-4.1225333214,""40"":-15.891040802,""41"":11.0452985764,""42"":11.7585163116,""43"":10.0170488358,""44"":-16.2930164337,""45"":-4.0257120132,""46"":-6.2143549919,""47"":9.5971851349,""48"":10.1006917953,""49"":-0.0443823747,""50"":8.5097351074,""51"":-5.722287178,""52"":9.9252243042,""53"":8.9513931274,""54"":0.057053104,""55"":8.6236915588,""56"":10.8585834503,""57"":12.6186666489,""58"":12.5115308762,""59"":11.2823858261,""60"":-0.0923018605,""61"":13.0781002045,""62"":9.9498767853,""63"":8.6487903595,""64"":11.5994710922,""65"":-16.1564750671,""66"":0.0800246894,""67"":7.9519991875,""68"":12.8716621399,""69"":9.3370485306,""70"":12.4598531723,""71"":-4.2566976547,""72"":8.0190563202,""73"":-16.2280101776,""74"":10.2241067886,""75"":12.5927457809,""76"":10.6330947876,""77"":11.196472168,""78"":-16.0593223572,""79"":0.1432930529,""80"":8.8212356567,""81"":11.0263328552,""82"":10.5710754395,""83"":0.0735355765,""84"":13.3564348221,""85"":8.0109510422,""86"":-4.3074707985,""87"":7.9957566261,""88"":10.3078565598,""89"":8.6501398087,""90"":13.1895475388,""91"":-6.6716680527,""92"":8.5779542923,""93"":11.6430568695,""94"":9.6439142227,""95"":0.5463542342,""96"":-6.6109104156,""97"":0.4119114876,""98"":-15.9570102692,""99"":-5.8716239929,""100"":9.4640741348,""101"":9.4730157852,""102"":13.3480472565,""103"":0.0220411327,""104"":0.2564764023,""105"":-5.5293416977,""106"":9.9034223557,""107"":-4.1699604988,""108"":-5.8023457527,""109"":11.0656757355,""110"":0.3671522737,""111"":-4.4359703064,""112"":-16.3487548828,""113"":12.3846406937,""114"":13.1536846161,""115"":11.6846666336,""116"":12.4296379089,""117"":0.6134136319,""118"":-5.6976161003,""119"":13.1142063141,""120"":8.6991920471,""121"":12.6991214752,""122"":-6.4157361984,""123"":-15.8089809418,""124"":8.6899833679,""125"":9.2452392578,""126"":11.2885398865,""127"":12.5533361435,""128"":-15.8696117401,""129"":12.7550077438,""130"":8.0982494354,""131"":9.9902563095,""132"":9.4802312851,""133"":12.8646316528,""134"":-6.5614595413,""135"":-6.3712801933,""136"":-5.6503915787,""137"":-6.4266872406,""138"":-6.4520072937,""139"":0.4823819995,""140"":12.7238540649,""141"":7.9909658432,""142"":-5.6788377762,""143"":10.9303007126,""144"":10.0409803391,""145"":-6.2554240227,""146"":13.2730379105,""147"":11.0602483749,""148"":10.0935754776,""149"":9.1161050797,""150"":12.9622774124,""151"":-6.3992352486,""152"":-5.6288108826,""153"":-6.493516922,""154"":10.4101896286,""155"":11.0775146484,""156"":0.496830821,""157"":10.0034255981,""158"":11.2837820053,""159"":13.3486413956,""160"":10.9739151001,""161"":12.6266412735,""162"":8.5400686264,""163"":13.277015686,""164"":10.2246685028,""165"":-6.6055254936,""166"":-6.5455265045,""167"":-6.2725477219,""168"":-6.5235180855,""169"":-16.1559047699,""170"":8.4837789536,""171"":10.3125219345,""172"":-6.2626137733},""y2D"":{""0"":0.0567206331,""1"":6.9974884987,""2"":-0.1013382375,""3"":-0.1151483804,""4"":1.0116766691,""5"":4.8961782455,""6"":-16.7063674927,""7"":11.3449239731,""8"":11.3196487427,""9"":11.1783189774,""10"":11.2688808441,""11"":1.8761006594,""12"":11.3700046539,""13"":11.2659492493,""14"":0.7934628725,""15"":1.8219718933,""16"":3.9551939964,""17"":-17.0071792603,""18"":0.1136671677,""19"":0.3551937044,""20"":-16.715970993,""21"":1.7704460621,""22"":11.4089832306,""23"":1.0685834885,""24"":10.9968528748,""25"":1.1365810633,""26"":-16.9157581329,""27"":2.6036934853,""28"":2.0844109058,""29"":2.7865488529,""30"":3.4788515568,""31"":0.1287660152,""32"":0.2372566909,""33"":-16.6213607788,""34"":0.2397825867,""35"":1.23290658,""36"":-17.1691741943,""37"":-0.3412530124,""38"":11.2349472046,""39"":-16.9772510529,""40"":10.8322944641,""41"":2.986686945,""42"":2.4257469177,""43"":1.4589802027,""44"":10.9043273926,""45"":-17.0739536285,""46"":5.9055371284,""47"":0.800884366,""48"":1.3535187244,""49"":-10.4973869324,""50"":0.3915931582,""51"":7.1568589211,""52"":0.0992100611,""53"":0.0154062863,""54"":-10.660364151,""55"":0.2302615196,""56"":2.6863560677,""57"":4.5140542984,""58"":3.8372564316,""59"":1.638117075,""60"":-10.4446372986,""61"":5.4003200531,""62"":0.6464557052,""63"":1.1224179268,""64"":2.2583851814,""65"":11.14473629,""66"":-10.5726108551,""67"":1.1741975546,""68"":5.4429707527,""69"":2.2789270878,""70"":4.2941451073,""71"":-16.8436603546,""72"":1.5273061991,""73"":11.4374465942,""74"":2.4034576416,""75"":4.6794595718,""76"":1.3066990376,""77"":0.0422738828,""78"":11.4958400726,""79"":-10.6682958603,""80"":0.0245656855,""81"":0.3099889457,""82"":0.2333622128,""83"":-10.6018638611,""84"":5.2375130653,""85"":0.8194875121,""86"":-16.792930603,""87"":1.3982925415,""88"":2.3233497143,""89"":1.9486449957,""90"":5.502117157,""91"":5.1198487282,""92"":1.9511525631,""93"":2.7159354687,""94"":2.459321022,""95"":-10.7782506943,""96"":4.6845030785,""97"":-10.9252328873,""98"":10.9947414398,""99"":6.9281525612,""100"":2.3851335049,""101"":2.393119812,""102"":4.9822392464,""103"":-10.6754493713,""104"":-10.7671880722,""105"":7.3268013,""106"":1.9614076614,""107"":-16.9296798706,""108"":6.9545001984,""109"":-0.021253651,""110"":-10.8608036041,""111"":-16.6646900177,""112"":10.9040956497,""113"":3.7500245571,""114"":5.5087509155,""115"":2.9315633774,""116"":3.8103928566,""117"":-10.9343233109,""118"":7.1345462799,""119"":5.534886837,""120"":1.6931414604,""121"":4.2865829468,""122"":4.8536901474,""123"":11.0819568634,""124"":0.1130905524,""125"":-0.1405530274,""126"":2.8462677002,""127"":4.1458110809,""128"":11.0136623383,""129"":5.0964560509,""130"":1.3707975149,""131"":0.2022165656,""132"":0.0163771771,""133"":4.727127552,""134"":4.6611661911,""135"":5.3420295715,""136"":7.2023348808,""137"":5.2280435562,""138"":5.450879097,""139"":-10.8087530136,""140"":4.8854579926,""141"":1.1429195404,""142"":7.1594429016,""143"":-0.3000374734,""144"":0.8147770762,""145"":5.6589941978,""146"":5.3103895187,""147"":-0.1782497019,""148"":1.6708147526,""149"":0.4265117049,""150"":4.8216042519,""151"":5.190346241,""152"":7.2207345963,""153"":5.0329065323,""154"":2.5289955139,""155"":-0.1331114173,""156"":-10.9318447113,""157"":1.8080431223,""158"":2.6269385815,""159"":5.2852964401,""160"":-0.1034604684,""161"":5.0684661865,""162"":1.7949048281,""163"":5.156642437,""164"":0.3598136902,""165"":4.6762604713,""166"":4.7518925667,""167"":5.6619524956,""168"":4.7955083847,""169"":11.4698591232,""170"":1.7580679655,""171"":2.3739113808,""172"":5.7277798653}}",False,False,False,http://ieeexplore.ieee.org/document/7784854/,,Visualizing High-Dimensional Data: Advances in the Past Decade,YA4MYR2A,False,False
3I937GAS,5H3LFLPI,"Collaborative Search Revisited 

  Meredith Ringel Morris 

 Microsoft Research 
 Redmond, WA, USA 

   merrie@microsoft.com 

ABSTRACT 
Despite  recent  innovations  in  technologies  supporting 
collaborative  web  search  [11,  13,  25,  34,  35,  37],  the 
features of the primary tools for digital information seeking 
(web  browsers  and  search  engines)  continue  to  reflect  a 
presumption  that  search  is  a  single-user  activity.  In  this 
paper,  we  present  the  findings  of  a  survey  of  167  diverse 
users’  collaborative  web  search  practices,  including  the 
prevalence and frequency of such activities, the information 
needs  motivating  collaboration,  the  methods  and  tools 
employed  in  such  tasks,  and  users’  satisfaction  with  the 
status quo. We find an increased prevalence and frequency 
of  collaborative  search,  particularly  by  younger  users,  and 
an appropriation of “old” technologies like e-mail as well as 
“new” technologies like smartphones and social networking 
sites,  rather  than  the  use  of  dedicated  collaborative  search 
tools.  We  reflect  on  how  and  why  collaborative  search 
practices have changed in the six years since the first survey 
detailing 
this  phenomenon  was  conducted  [22],  and 
synthesize  our  findings  to  offer  suggestions  for  the  design 
of future collaborative search technologies. 

Author Keywords 
Web search, collaborative search, social search, CSCW. 

ACM Classification Keywords 
H.5.m. Information interfaces and presentation (e.g., HCI): 
Miscellaneous.  

and 

technologies 

INTRODUCTION 
Information-seeking 
collaboration 
technologies are the two most popular online tools; a 2011 
Pew  Research  survey  [32]  found  that  92%  of  online 
American  adults  use  search  engines,  and  a  similar 
proportion  use  email.  However,  this  compartmentalization 
of  practices  as  either  search  or  collaboration  is  tenuous. 
Although  web  search  is  often  considered  a  de  facto  solo 
activity,  and  nearly  all  mainstream  search  technologies  are 
designed  for  single-user  scenarios,  a  growing  body  of 
research  suggests  that  active  collaboration  on  search  tasks 
among  users  with  shared  information  needs  is  relatively 
commonplace [13, 22, 25]. 

 
Permission  to  make  digital  or  hard  copies  of  all  or  part  of  this  work  for 
personal or classroom use is granted without fee provided that copies are 
not made or distributed for profit or commercial advantage and that copies 
bear this notice and the full citation on the first page. To copy otherwise, 
or  republish,  to  post  on  servers  or  to  redistribute  to  lists,  requires  prior 
specific permission and/or a fee. 
CSCW ’13, February 23–27, 2013, San Antonio, Texas, USA. 
Copyright 2013 ACM  978-1-4503-1331-5/13/02...$15.00. 

 

Our  20061  survey  of  204  Microsoft  employees  [22] 
provided data regarding the prevalence of collaborative web 
search, the tasks motivating such practices, and the methods 
used to enable such collaborations. In the six years since we 
conducted  that  survey,  the  technology  landscape  has 
undergone significant changes, particularly the rise of social 
networking  sites  (only  16%  of  Americans  had  social 
networking  profiles  in  2006,  compared  with  66%  in  2012 
[4])  and  the  growing  ubiquity  of  smartphones  (46%  of 
American  adults  owned  smartphones  as  of  February  2012 
[36])  and  other  powerful  portable  technologies  (e.g.,  tablet 
computers).  The  intervening  six  years  have  also  seen  a 
technologies  for 
flurry  of  research  and  commercial 
collaborative  search  support, 
though  none  have  had 
mainstream success.  

In  light  of  this  changed  landscape,  we  reassess  status  quo 
collaborative  search  practices  through  a  survey  of  167 
American  adults.  Our  results  provide  insight  into  the 
evolution  of  collaborative  and  social  search  practices;  for 
instance,  we  find  an  increase  in  the  prevalence  and 
frequency  of  collaborative  web  search,  as  well  as 
appropriation  of  new  technologies  like  social  networking 
sites and smartphones to support this phenomenon. We also 
find  that  users  continue  to  piece  together  general  purpose 
technologies to facilitate collaborative information seeking, 
rather 
taking  advantage  of  systems  designed 
specifically for such experiences. In light of these findings, 
we  reflect  on  barriers 
to  adoption  of  collaborative 
information  seeking  tools,  and  identify  key  research 
directions moving forward.  

than 

RELATED WORK 
The term social search is used to refer to a broad spectrum 
of  information  seeking  behaviors,  ranging  from  behaviors 
which  are  implicitly  social  (e.g.,  search  over  socially-
generated  data  sets)  to  those  that  are  explicitly  social  (e.g., 
interacting  with  other  people  during  various  stages  of  the 
search process) [13]. Evans and Chi [7] described the types 

                                                           

1 Though published in 2008, the  survey data  was collected 
in  November  2006.  We  refer  to  it  (and  other  surveys 
discussed) by the year of data-gathering rather than the year 
of  publication,  when  known,  since  the  former  more 
accurately  represents  the  socio-technical  context  of  the 
findings  given  the  rapid  evolution  of  technologies  and 
practices. 

 

 

of  social  engagements  possible  at  different  stages  of  the 
Web search process.  

Collaborative  search  [11,  13,  25,  34]  is  a  subset  of  social 
search  in  which  participants  work  together  to  satisfy  an 
information  need.  The  collaborative  nature  of  search  tasks 
in  pre-web  scenarios  (e.g.,  in  libraries  and  paper-driven 
offices)  has  a  long  history  of  scholarship  (e.g.,  [9,  38]). 
Academic  investigation  of  the  challenges  and  practices 
associated  with  collaborative  web  search  is  a  more  recent 
phenomenon, usually associated with the 2007 introduction 
of  the  SearchTogether  [24]  system,  whose  design  was 
informed by a survey of collaborative web search practices 
conducted  in  2006  (but  not  published  until  2008)  [22]. 
Collaborative search  has many benefits, including enabling 
participants  to  achieve  synergic  effects  such  as  greater 
recall  [31,  35],  offering  the  potential  to  improve  search 
skills  through  exposure  to  others’  behavior  [20,  21],  and 
providing  an  opportunity  to  strengthen  social  connections 
[27,  28].  Note  that  the  investigation  of  collaborative  web 
search  differs  from  prior  work  on  collaborative  web 
browsers  (e.g.,  [12])  in  that  its  focus  is  not  on  general-
purpose  web  browsing,  but  specifically  on  the  use  of  the 
web for information-seeking tasks. 

It 

representative 

is  unclear  how 

In [22], we reported the results of a November 2006 survey 
of  204  Microsoft  employees’  collaborative  web  search 
practices. 
this 
demographic’s  behavior  was,  as  respondents  differed  in 
many  ways  from  the  general  population,  primarily  on  the 
basis  of  their  technical  expertise,  as  well  as  along  other 
demographic  dimensions  that  were  also  non-typical  (e.g.,  
80.4%  of  respondents  were  male).  However,  [22]  presents 
the  most  complete  picture  available  of  the  prevalence  and 
characteristics  of  the  collaborative  search  phenomenon;  it 
found  that,  despite  the  lack  of  any  tools  designed  to 
explicitly support collaborative web search, 53.4% of those 
surveyed  had  engaged  in  such  activities  by  using  the 
bottom-up 
[41]  approach  of  appropriating  existing 
technologies  (e.g.,  email, 
to 
supplement  the  web  browser.  A  smaller,  diary-based  study 
of 20 Microsoft employees [2] conducted in 20072 provided 
additional  insights  into  the  specific  scenario  of  co-located 
collaborative  search.  More  recently,  several  studies  have 
characterized  the  asymmetric  collaborative  search  scenario 
(in  which  participants  have  different 
roles  and/or 
motivations [25]) of using social networking sites to engage 
contacts in various stages of an information-seeking task [6, 
17, 27, 29]. 

instant  messaging,  etc.) 

In the intervening six years since our survey [22], a number 
of research prototypes supporting collaborative search have 
been 
innovations  have  proposed 
algorithmic  techniques  to  enhance  the  collaborative  search 
experience, including role-specific weightings of input [31], 

introduced.  Some 

[15].  Others  have  proposed  user 

group personalization of results [26], expertise-matching of 
potential  collaborators  [16],  and  agents  that  use  context 
from  social  network  Q&A  exchanges  to  suggest  relevant 
links 
interface 
enhancements,  such  as  enhancing  collaborators’  awareness 
of  each  other’s  search  process 
[20,  24],  enabling 
distribution of control in co-located settings [1], supporting 
collaborative search among users with asymmetric access to 
devices  [42],  and  supporting  collaborative  search  on 
emerging technologies such as large touch surfaces [23].  

Some commercial technologies have also included features 
supportive  of  specific  subsets  of  collaborative  search 
activities.  Examples  include  Aardvark  (a  service  to  match 
users  with  experts  to  support  their  information-seeking; 
2007),  Flock  (a  web  browser  that  incorporated  social 
networking  as  a  first-class  feature  in  its  design;  2008), 
HeyStaks (which uses feedback from communities of users 
with  common  interests  to  re-rank  search  results;  2008), 
Pinterest  (a  shared  bulletin  board  for  collections  of  web 
imagery;  2010),  SearchTeam  (a  tool  whose  features  are 
highly reminiscent of SearchTogether [24], 2011), and So.cl 
(a social network based around sharing collections of search 
results  [8];  2011).  None  of  these  commercial  tools  has 
achieved  mainstream  adoption  –  some,  like  Aardvark  and 
Flock,  have  already  become  defunct;  others,  like  Pinterest 
and So.cl, are still in limited, invitation-only beta stages.  

This paper adds to this body of work on collaborative web 
search by presenting survey results that give an updated and 
more  complete  view  of  the  current  state  of  practice.  Our 
survey  reports  on  the  collaborative  search  practices  of  a 
more  representative  sample  of  the  general  public  (as 
opposed to highly technical knowledge workers, e.g., [22]), 
and  reflects  recent  changes  in  the  technological  landscape 
(such  as  the  growing  prevalence  of  social  networking  [4] 
and smartphone use [36]).   

open-ended 

and  multiple-choice 

to  assess  current  practices 

SURVEY 
We conducted an online survey over a one  week period in 
March  2012 
regarding 
collaborative  information  seeking.  The  survey  consisted  of 
both 
questions. 
Respondents  were  asked  whether 
they  had  ever 
collaborated  with  other  people  to  search  the  Web;  if  they 
answered  affirmatively,  they  were  asked  to  describe  their 
most recent collaborative search experience and to answer a 
series  of  questions  about  that  specific  search  incident  (a 
critical-incident  approach  [7,  10]).  Additional  survey 
questions  addressed  demographics  and  use  of  specific 
search and collaboration technologies.  

The  survey  was  advertised  as  a  questionnaire  on 
“Information  Seeking  Practices”  via  the  Survey  Monkey 
Audience  recruiting  service3  to  1,025  adult  American 

                                                           

                                                           

2 Data gathered in 2007; published in 2009.  

3 http://www.surveymonkey.com/mp/audience/ 

 

 

participants;  167  completed  the  entire  survey,  yielding  a 
16% response rate.  

RESULTS 
We  first  characterize  the  demographic  details  of  our  167 
respondents.  We  then  report  our  findings  regarding  the 
prevalence  of  collaborative  search  and  the  nature  of  such 
searches.  We  also  report  findings  on  the  use  of  specific 
technologies 
seeking, 
including smartphones, social networks, and Q&A tools.  

collaborative 

information 

for 

Note  that  we  use  non-parametric  statistical  tests  when 
analyzing  Likert  responses,  due  to  the  subjective  and 
potentially  non-linear  interpretations  of  the  “spacing” 
between adjacent items on such scales. 

Demographics 
Our 167 survey respondents were all residents of the United 
States; 40 of the 50 states were covered by our sample. 56% 
of respondents were female.  38% of respondents were aged 
18 – 29; 24% were aged 30 – 44; 27% were aged 45 – 60; 
and  11%  were  older  than  60  years.  5%  had  a  high  school 
diploma or less, 57% had completed some college, 29% had 
a college degree, and 9% had a graduate degree. 

Occupations  were  varied,  with  students  making  up  the 
largest  single  group  at  25%  of  respondents.  An  additional 
8% of the  group  was comprised of retirees. The remaining 
67%  of  respondents  had  diverse  vocations  including  sales 
person,  customer  service  representative,  teacher,  nurse, 
school counselor, homemaker,  mortgage broker, physician, 
stock analyst, insurance adjuster, cosmetologist, accountant, 
software engineer, dentist, paralegal, copy editor, and heavy 
equipment operator.  

Respondents used search engines frequently;  most (79.9%) 
reported  using  a  major  search  engine  (Ask,  Bing,  Google, 
or  Yahoo!)  several  times  per  day,  and  nearly  all  (94.1%) 
reported doing so at least once per day. 

Collaborative Search 
All  respondents  were  asked  “Have  you  ever  collaborated 
with  other  people  to  search  the  Web?”  If  they  answered 
negatively,  they  skipped  ahead  to  the  questions  about 
specific technologies (see the “Beyond ‘Traditional’ Search 
Engines”  section)  and  demographics.  However,  the  109 
respondents  (65.3%)  who  answered  affirmatively  were 
asked  several  follow-up  questions  about  their  experiences 
with collaborative search.  

that  65.3%  of  respondents  had  engaged 

Finding 
in 
collaborative  search  indicates  an  increased  prevalence  of 
collaborative search behavior – our 2006 survey [22] found 
the  prevalence  of  collaborative  search  to  be  only  53.4% 
(and that was with a more “tech-savvy” audience, Microsoft 
employees, whom one would assume might be more likely 
to  appropriate  technologies  in  novel  ways  than  the  more 
diverse  audience  of  the  current  survey).  The  prevalence  of 
collaboration  we  found  differs  significantly  from  the 

 

 

 

Daily 

Weekly 

Monthly 

Less Often 

2006  

0.9% 

25.7% 

48.6% 

24.8% 

2012 

11.0% 

38.5% 

15.6% 

34.8% 

Table 1. Percent of respondents reporting collaboratively 
searching at various frequencies. 2006 numbers are taken 

from Table 2 of [22]. 

 

hypothesized proportions based on the 2006 survey, χ2(1, N 
= 167) = 9.62, p = .002). 

Age  was  significantly  negatively  correlated  with  the 
likelihood  of  engaging 
in  collaborative  search  (e.g., 
younger  respondents  were  more  likely  to  engage  in  this 
behavior), r = -.26, p = .001. 

Note that percentages given in the remainder of this section 
(“Collaborative Search”) and its sub-sections are out of the 
109  people  who 
they  had  searched 
collaboratively  rather  than  out  of  the  full  167  survey 
respondents. 

indicated 

that 

11%  of  respondents  who  had  searched  collaboratively 
reported doing so on a daily basis, and an additional 38.5% 
report searching collaboratively at least once per week. This 
is  a  marked  increase  over  the  self-reported  frequency  of 
collaborative searching in 2006 [22], as illustrated in Table 
1, χ2(3, N = 108) = 155.26, p < .001). 

After  indicating  whether  they  had  ever  searched  the  Web 
collaboratively and how often they did so, participants who 
had  searched  collaboratively  were  asked  to  engage  in  a 
recent critical-incident self-report [7, 10]. They were asked 
in a free-text question to “think about the most recent time 
you collaborated with others to search the web,” and then to 
“describe the nature of the information need that prompted 
this  incident.”  They  were  then  asked  several  follow-up 
questions  about  that  specific  incident.  The  following  four 
sub-sections (“Topics,” “Group Configurations,”  “Methods 
and Tools,” and “Satisfaction”)  are based on the follow-up 
questions  about  the  respondents’  most  recent  collaborative 
search incident. 

Topics 
In  addition  to  describing  the  information  need  prompting 
their  most  recent  collaborative  search  in  a  free-response 
question, we also asked respondents to classify the nature of 
the  information  need  they  investigated  collaboratively  by 
selecting  one  or  more  topics  from  a  list.  The  list  of  topic 
choices  was  created  by  combining  the  topics  reported  as 
prompting  collaborative  searches  in  [22]  and  the  list  of 
topics reported as likely and unlikely to prompt requests for 
search help from members of one’s social network in [27].  

# of Respondents 

Example Task Description 

26 

21 

19 

18 

16 

15 

14 

11 

11 

10 

10 

“we  split  up  research  for  software  development,  searching 
individually  for  coding  issues,  gui  design,  and  what  would  be 
appealing to our audience” 

“we  needed  to  find  information  about  iron  deficiency  and 
hypokalemia” 

“looking for reference footage and images for a school project” 

“looking for printer parts for our business operation” 

“we were planning a trip to Alaska and all the details that go into 
it for a group of 10 of us” 

“looking for a used car” 

“searching for music on YouTube and lyrics” 

“genealogy” 

“we were researching different kinds of e-portfolios” 

“find local restaurants” 

“planning a wedding” 

Topic 

professional 

health/medicine 

news/current events 

technology 

travel 

shopping  

entertainment 

home/family 

finance 

restaurants 

social events 

 

Table 2. The most common topics motivating respondents’ recent collaborative Web searches. 

respondents  said  described 

Table  2  shows  the  most  popular  topics  (those  which  10  or 
more 
recent 
collaboratively-investigated  information  need),  and  gives 
examples from respondents’ free-form descriptions of their 
most recent search incident. 

their  most 

Group Configurations 
Small-group  collaboration  was  more  common  than  larger 
groups.  Pairs  were 
the  most  common  configuration 
(31.2%). Triads were also fairly common (22.9%), as were 
quartets  (23.9%).  Groups  larger  than  four  members  were 
infrequent – 9.2% reported working in groups of five, 4.6% 
in groups of six, and 8.3% in groups having seven or more 
members.  

Our  2006  survey  [22]  also  found  that  smaller  group  sizes 
were  more  common  than  larger  ones,  though  that  survey 
found  much  smaller  group  sizes,  reporting  that  80.7% 
collaborated in pairs and 19.3% in  groups of three or four, 
with  no larger  groups at all.  Comparing our frequencies of 
pairs,  groups  of  three  or  four,  and  larger  groups  to  this 
earlier  finding  shows  a  significant  change  in  group  sizes, 
χ2(2, N = 109) = 610, p < .001. Our 2007 diary study of co-
located  collaborative  search  [2]  also  found  smaller  group 
sizes  than  our  current  study,  with  85.7%  collaborating  in 
pairs and 9.5% in groups of three or four. 

We also asked respondents to characterize their relationship 
with their collaborators on their search task. 55.0% reported 
collaborating with colleagues or classmates. Family was the 
next  most  common  type  of  collaborator  relationship,  at 
25.7%,  followed  by  close  friends  (19.3%),  and  then  casual 

 

 

acquaintances  (11.0%).  Collaboration  with  strangers  or 
professionals  (e.g.,  librarians)  was  rare,  at  5.5%.  Note  that 
these  values 
than  100%,  as  some 
respondents  indicated  that  they  worked  with  a  group 
comprised of multiple relationship types.  

to  greater 

total 

roughly 

two-thirds  of 

than 
Synchronous  collaboration  was  more  common 
asynchronous,  comprising 
the 
incidents (64.2%). Remote collaboration was more common 
than  co-located,  characterizing  61.5%  of  the  described 
searches. This is in contrast to the 2006 survey [22], which 
found 
search 
configurations,  although 
their  question  was  phrased 
differently  (asking  respondents  which  of  the  following 
behaviors they  had ever engaged in,  versus asking them to 
describe  a  single  recent  critical  incident  as  we  do  here), 
making direct comparisons difficult. 

slight  prevalence  of 

a 

co-located 

Methods and Tools 
Participants  used  a  checklist  to  indicate  what  tools  they 
employed in their most recent collaborative search incident 
(they  could  check  as  many  items  as  applied).  The  use  of 
search  engines  was  common  (67.9%  of  respondents  used 
them  in  their  most  recent  collaborative  search  task),  but 
other  methods  of  online  information-seeking  were  also 
employed, such as using a social networking site (19.3%) or 
Q&A  site  (6.4%).  We  explore  the  use  of  these  latter  two 
technologies  in  further  detail  in  the  “Beyond  ‘Traditional’ 
Search Engines” section.   

Devices:  “Traditional”  devices  like  laptops  (61.5%)  and 
PCs  (39.4%)  were  the  most  common  devices  used  in  the 

 

Very 
Dissatisfied 

Dissatisfied  Neutral 

Satisfied  Very 

Satisfied 

 

Daily  Weekly  Monthly 

Never 

Less  than 
once  per 
month 

quality 
of 
answer 
found 

ease  of 
working 
with 
others 

2.8% 

1.8% 

12.8%  55.0%  27.5% 

1.8% 

2.8% 

16.5%  42.1%  35.8% 

Table  3.  Respondents’  satisfaction  with  the  informational 
and  social  aspects  of  their  most  recent  collaborative 
search incident. 

 

course  of  collaborative  information  seeking.  Newer  device 
types  were  also  common,  with  30.3%  of  the  searches 
involving  a  smartphone  and  11%  involving  a  tablet. 
Technologies  that  might  facilitate  public  sharing  such  as 
TVs and projectors were rarely employed, in only 1.8% and 
0.9%  of  the  searches,  respectively.  Non-digital  tools  were 
also an important part of collaborative search processes; for 
instance,  11%  of  respondents  reported  using  paper  to 
support their collaborative search task.  

Communication:  Since  mainstream  web  browsers  and 
search  engines  don’t  incorporate  communication  tools 
(which  are  important  for  facilitating  remote  collaborative 
search  [24]),  respondents  often  employed  out-of-band 
communication  channels.  Email  was  the  most  common 
communication  tool,  involved  in  46.8%  of  the  searches. 
Other  communication  channels  used  were  talking  on  the 
phone  (27.5%),  text  messaging/SMS  (30.3%),  and  instant 
messaging  (12.8%).  Videoconferencing  was  rare;  only  one 
participant  reported  employing  it  as  a  communications 
channel during a collaborative search.  

Satisfaction 
Responents used a five-point Likert scale to rate their level 
of  satisfaction  with  both  the  informational  (quality  of 
answer found) and social (ease of working collaboratively) 
aspects  of  their  most  recent  collaborative  search.  Table  3 
summarizes  those  results.  82.5%  reported  satisfaction  with 
the  informational  outcome  and  77.9%  reported  satisfaction 
with  the  ease  of  collaboration.  Though  positive  overall, 
these  figures  still 
is  room  for 
improvement of both the informational and social aspects of 
the collaborative search experience.  

indicate 

there 

that 

Respondents were also given space to compose a free-form 
response  regarding  suggestions  for  how  their  collaborative 
search  experience  could  have  been  improved.  The  most 
common  response  (7  people)  was  for  facilities  to  make  it 
easier to share the products of  search  with  group  members 
and  increase  group  awareness  of  mutual  activities  (two 
issues  that  systems  like  SearchTogether  [24],  Coagmento 
[35],  and  WeSearch  [23]  sought  to  address).  For  example, 
one respondent said, “It might have helped if we had some 
sort  of  online  bulletin  board  on  which  to  post  our 
findings…”  Another  noted  that  he  would  have  liked  “an 

 

 

% of 
smartphone 
owners 

% of co-
located 
searchers 

36.1% 

24.7% 

21.6% 

10.3% 

7.2% 

38.9% 

26.7% 

23.3% 

11.1% 

N/A 

Table  4.  The  reported  frequency  of  engaging  co-located  multi-
party  smartphone  searches  among  all  smartphone  owners  in 
our  sample  (97  participants),  and  among  those  who  reported 
engaging in this behavior at least occasionally (90 participants). 

 

easier  way  for the rest of  the  group  members to access the 
information  each  of  us  found  separately,”  and  one  person 
desired the ability  to have  “real-time comparisons between 
mine  and  my  colleagues’  information.”  Redundant  work 
[22] remained problematic, with one respondent noting that 
“if  there  was  a  better  way  to  communicate  where  one 
person had already looked it would have prevented overlap  

of  seeking  for  information,”  and  another  observing  that  it 
would  be  helpful 
tracks 
collaborators’  searches  in  a  private  group,  so  that  you  can 
see which papers others have already found.”  

to  have  “a  database 

that 

Beyond “Traditional” Search Engines 
Although  the  questions  surrounding  respondents’  most 
recent collaborative search incident  were  asked only  to the 
109  respondents  who  indicated  that  they  had  engaged  in 
collaborative Web search, all 167 respondents were asked a 
series  of  questions  about  their  use  of  several  specific 
technologies, independent of the critical incident inquiry. In 
particular,  we  were 
the 
collaborative use of information-seeking technologies other 
than  the  traditional  “using  a  search  engine  in  a  PC  web 
browser.” Our questions focused on three kinds of tools that 
have experienced significant changes or growth since 2006 
– smartphones, social networking sites, and Q&A sites. 

investigating 

interested 

in 

Smartphones 
Though  smartphones  (which  permit  browsing  the  web  and 
running  third-party  applications)  existed  in  2006,  the 
capabilities  and  adoption  of 
smartphones  changed 
dramatically  in  2007  with  the  introduction  of  Apple’s 
iPhone,  whose  Safari  browser  provided  the  ability  to  view 
and  interact  with  “real”  web  pages  (rather  than  special 
mobile  versions).  By  early  2012,  46%  of  American  adults 
owned  a  smartphone  [36].  Recent  work  suggests  that 
mobile  local  searches  (i.e.,  searching  for  businesses  or 
services  near  a  user’s  current  geo-location)  are  often 
undertaken  in  a  social  setting,  but  does  not  offer  detailed 
insight into multi-phone collaborative search practices [39].  

In  our  survey  sample,  58.1%  of  respondents  reported 
owning  a  smartphone.  Of  these  97  smartphone-owning 
respondents,  48.5%  had  Android  devices,  34.0%  had  iOS 
(Apple) devices, and the remainder had devices running the 

 

Facebook  Twitter  Google+  LinkedIn 

have 
accounts 

have ever 
asked a 
question 

ask 
questions at 
least once 
per week 

lurk (read 
content but 
never post) 

139 

49 

42   

50  

(83.2%) 

(29.3%) 

(25.1%) 

(29.9%) 

50.0% 

33.3% 

24.6% 

24.6% 

15.4% 

9.5% 

9.8% 

4.6% 

4.3% 

8.8% 

12.5% 

15.9% 

Table  5.  The  first  row  reports  how  many  of  the  167 
respondents  had  accounts  on  each  social  networking  site. 
Additional  rows  report  the  percentage  of  those  account-
holders engaging in specific behaviors. 

 
Palm,  RIM  (Blackberry),  or  Windows  operating  systems. 
Smartphone ownership was not significantly correlated with 
any demographic factors. 

Although  they  may  not  have  previously  self-identified  as 
having  engaged  in  collaborative  search,  nearly  all  of  the 
smartphone owners (92.8%) reported using their phones  to 
engage  in  co-located  collaborative  searches  in  which 
several  people  simultaneously  used  their  smartphones  to 
look  up 
information  (Table  4).  This  behavior  was 
surprisingly frequent – of the 90 respondents  who reported 
engaging in this behavior, 38.9% reported doing so at least 
once  per  day,  and  65.6%  at  least  a  few  times  per  week. 
Younger  respondents  engaged  in  co-located  multi-phone 
searches more frequently than older respondents (r = -.26, p 
=  .01).  These  initial  findings  suggest  that  studying  co-
located collaborative smartphone search may be a rich area 
for  further  investigation  to  answer  questions  beyond  the 
scope  of  our  current  survey,  such  as  exploring  what  role 
specialized “apps” might play in such scenarios.   

Social Networking Sites 
Social  networking  sites  were  used  by  only  16%  of 
Americans  in  2006  (the  year  in  which  Facebook  opened 
enrollment  to  the  general  public  rather  than  merely  to 
students  at  selected  universities);  by  2012,  66%  had  an 
account  [4].  Social  networking  sites  have  taken  on  an 
increasingly  prominent  role  in  asymmetric  collaborative 
information  seeking  [25],  through  mechanisms  such  as 
posting search results directly to social network feeds (e.g., 
Bing  and  Ping  [5]  or  So.cl  [8]),  using  socially  embedded 
search  engines  (e.g.,  SearchBuddies  [15]),  or  asking 
questions via status messages [6, 17, 27, 29]. For instance, a 
20094  survey  of  Microsoft  employees  [27]  found  that 
50.6% had posted questions to Facebook or Twitter.  

                                                           

 

Figure 1. Self-reported frequency of posting a  question as  a 
status update, a form of asymmetric collaborative search, by 
account-holders on each social network. 

 
87.4%  of  our  survey  respondents  reported  having  social 
networking accounts,  with Facebook being by  far the  most 
popular,  distantly  followed  by  Twitter,  LinkedIn,  and 
Google+  (Table  5).  Other  networks  like  MySpace,  Orkut, 
Tumblr,  and  Yammer  had  negligible  representation. 
Younger  respondents  were  more  likely  to  have  social 
networking accounts than older ones (r = -.27, p < .001). 

Asking  questions  on  these  social  networking  sites  was 
common. 50.0% of those  with Facebook accounts reported 
having used that network to ask a question, as did 33.3% of 
those  with  Twitter  accounts,  and  24.6%  of  those  with 
LinkedIn  and  Google+  accounts.  Our  finding  that  half  of 
Facebook  users  have  engaged  in  status-message  question 
asking is similar to the findings of a survey we conducted in 
2009  [27],  despite  the  fact  that  the  2009  survey  audience 
was  comprised  of  Microsoft  employees  while  our  current 
survey draws  from a  more diverse demographic. However, 
it  conflicts  with  the  findings  of  a  survey  by  Lampe  et  al. 
conducted  in  20115  [17]  that  found  that  most  Facebook 
users  in  their  sample  did  not  view  Facebook  as  an 
appropriate  venue  for  information-seeking  (i.e.,  via  status 
message Q&A). The Lampe survey’s audience consisted of 
employees at a U.S. university, who were less diverse (e.g., 
more  educated,  more  female,  older)  than  our  sample 
population, which may explain this difference. 

While  prevalent,  this  behavior  appears  to  be  relatively 
infrequent  (frequency  of  social  network  Q&A  was  not 
reported  in  prior  surveys  such  as  [27],  which  focused 
primarily on prevalence, motivations, and topics associated 
with this phenomenon). Only 15.4% of the Facebook users, 
9.8% of Google+ users, 9.5% of Twitter users, and 4.6% of 
LinkedIn  users  reported  asking  questions  at  least  once  per 
week.  The  low  use  of  LinkedIn  for  question-asking  may 
reflect competition from other professional forums, such as 
internal  enterprise  SNS  sites  [40].  Figure  1  shows  the 
reported  frequency  of  question-asking  by  respondents 
holding accounts on each of those social networking sites. 
                                                           

4 Survey conducted in 2009; published in 2010. 

5 Survey conducted in 2011; published in 2012. 

 

 

 

 

 

 

Figure  2.  Frequencies  of  viewing  content,  posting  content,  and  posting  questions  by  account-holders  on  four  social  networks. 
The  higher  frequency  of  lurking  (users  who  view  but  never  post  content)  on  Google+  and  LinkedIn  may  contribute  to  their 
being viewed as less useful venues for getting questions answered. 

 

On  all  of  these  social  networks,  viewing  content  is  more 
common than posting content, which is more common than 
posting  questions.  “Lurking”  (having  an  account  and 
logging  in  to  view  content,  but  never  posting  any  content 
yourself)  was 
relatively  uncommon.  Only  4.3%  of 
respondents  with Facebook accounts  were lurkers. Lurking 
on Twitter was more common, at 8.8% (note that this figure 
only  includes  respondents  with  Twitter  accounts;  many 
additional  people  likely  read  Twitter  without  having 
accounts  at  all).  The  lurking  rates  for  Google+  and 
LinkedIn  were  higher  still,  at  12.5%  and  15.9%, 
respectively.  The 
is  strongly  negatively 
correlated  (r  =  -.94)  with  the  rate  of  question-asking  on 
each  service,  perhaps  because  it  relates  to  the  likelihood 
that  someone  who  views  a  question  will  chime  in  with  an 
answer.  Figure  2  shows 
the  frequency  of  different 
interactions on each social network. 

lurking  rate 

The frequency of question asking on the three less popular 
social  networks  was  significantly  correlated  (p  <  .01) 
(Twitter/Google+:  r  =  .36;  Twitter/LinkedIn,  r  =  .34, 
Google+/LinkedIn:  r  =  .44),  perhaps  representing  a  clique 
of “hard-core” askers who try many social venues in pursuit 
of an information need. In contrast, the frequency of asking 
on  Facebook  (a  more  popular  activity  overall),  was  not 
correlated  significantly  with  asking  on  LinkedIn  (the  least 
popular venue for question asking), and had relatively weak 

correlations with asking frequency on Google+ and Twitter 
(r = .19, p = .03). 

Demographic  factors  correlated  weakly  with  the  frequency 
of  question  asking  on  certain  social  networks.  Younger 
respondents were more likely to ask questions on LinkedIn 
frequently  (r  =  -.24,  p  <  .01),  as  were  respondents  with 
lower education levels (r = -.18, p = .03). Among Facebook 
users,  women  reported  asking  questions  more  often  than 
men (r = -.18, p - .03).  

Q&A Sites 
Q&A  sites  provide  an  alternative  method  of  online 
information  seeking  than  traditional  Web  search.  These 
forums  allow  users  to  post  questions  for  answering  by 
either  the  general  Web  population  (e.g.,  Yahoo!  Answers, 
Mahalo  Answers,  Ask  MetaFilter  [14]),  paid  staffers  (e.g., 
ChaCha, kgb), or self-identified topical experts (e.g., Quora 
[30]).  Such  sites  typically  archive  past  questions  and 
answers,  which  are  browseable  and/or  searchable  by  other 
users.  

The past few years have seen an increase in the prominence 
of  tools  that  form  social  structure  around  non-anonymous 
Q&A exchanges (e.g., Quora [33], founded in 2009) and of 
those  that  operate  on  a  paid-staffer  model,  which  is  a 
modern-day  analog  of 
librarian,  (e.g., 
ChaCha, founded in 2006, whose answer volume surpassed 

the  reference 

 

 

that  of  Yahoo!  Answers  in  2011  [18]).  Use  of  such  “next-
generation”  Q&A  sites  could  be  construed  as  a  form  of 
asymmetric collaborative search [25]. 

We  asked  all  respondents  how  often  they  posted  questions 
to  a  variety  of  Q&A  sites.  Most  respondents  reported  that 
they  had  never  posted  a  question  to  Ask  MetaFilter 
(97.3%),  ChaCha  (93.2%),  kgb  (98.6%),  Mahalo  Answers 
(100%),  or  Quora  (99.3%).  The  only  Q&A  site  in  our 
survey  that  was  occasionally  used  was  Yahoo!  Answers  – 
24%  of  respondents  had  posted  a  question  at  least  once, 
though  this  behavior  was  infrequent  (only  4.8%  reported 
posting a question at least once a week).  

The frequency of posting questions to Yahoo! Answers was 
not  significantly  correlated  with  demographic  factors  (age, 
gender,  or  education).  There  was,  however,  a  significant 
negative  correlation  between  the  frequency  of  posting  to 
Yahoo! Answers and the frequency of posting questions to 
some of the less popular social networking sites (Google+: r 
=  -.30,  p  <  .01;  LinkedIn:  r  =  -.17,  p  =  .04).  This  might 
indicate  that  users  employ  two  distinct  “backup”  strategies 
for seeking answers to difficult questions – either posting to 
a Q&A site or posting to a “secondary” social network. 

We also asked whether respondents perused the archives of 
these  Q&A  sites  for  answers,  even  if  they  did  not  post  a 
question  themselves.  48.6%  of  respondents  reported  using 
Yahoo!  Answers  in  this  manner  at  least  once,  and  11% 
reported using ChaCha in this manner. The use of archived 
answers from Ask Metafilter, kgb, Mahalo, and Quora was 
negligible.  Reusing  answers  was  a  more  frequent  behavior 
than  posting  new  questions;  1.4%  of  respondents  used  the 
ChaCha archives at least once per week, and 11.7% did so 
for  Yahoo!  Answers  (a  Wilcoxon  test  comparing  the 
frequency  of  posting  vs.  perusing  Yahoo!  Answers  found 
that the latter was significantly more frequent, z = -5.41, p < 
.001). Reusing existing answers on Yahoo and ChaCha was 
significantly  inversely  correlated  with  age  –  younger  users 
were  more  likely  to  engage  in  this  behavior  frequently 
(Yahoo!  Answers: r =  -.41, p < .01; ChaCha: r =  -.23, p < 
.01).  

DISCUSSION 
In this section,  we reflect on our survey findings. First, we 
compare and contrast our results with those of prior studies 
of  collaborative  search  behavior,  and  discuss  possible 
causes  of  differences.  We  then  discuss  the  implications  of 
our findings for the design of technical solutions supporting 
collaborative search. 

Comparison with Prior Findings 
Compared to six years ago [22], we found that more people 
are engaging in collaborative web search, and  that they are 
doing so with greater frequency.  65.3% of our respondents 
reported having collaborated on web search, with 49.5% of 
those  collaborative  searchers  engaging  in  such  activities  at 
least  once  per  week.  When  asked  about  specific  behaviors 
(such as engaging in co-located smartphone searches), even 

 

 

higher  prevalence  and 
reported, 
suggesting that the 65.3% number may be an underestimate, 
perhaps due to the generic nature of the question (“have you 
ever collaborated with other people to search the web?”). 

frequencies  were 

to 

likely  due 

The  typical  group  size  involved  in  such  collaborations  has 
increased,  as  well, 
the  adoption  of 
technologies  that  facilitate  simultaneous  interaction  of 
larger groups of users for remote collaboration (e.g., social 
networking  sites),  and  technologies  that  support  larger 
group engagement in co-located collaboration by providing 
each  group  member  with  their  own  input  device  (e.g., 
smartphones).  Despite  the  considerable  press  attention 
some  emerging  social  information  seeking  solutions  have 
received  (e.g.,  Quora  [33]),  community  Q&A  sites  do  not 
appear  to  be  part  of  a  typical  user’s  collaborative  search 
repertoire.  

We found that younger users were more likely to engage in 
collaborative  searches.  It  is  unclear  whether  the  observed 
increase in collaborative search activities is due primarily to 
the coming-of-age of a new generation of technology users 
who  are  more  comfortable  pushing  the  bounds  of  a  tool’s 
intended  use  and/or  have  differing  attitudes 
toward 
collaboration,  or  whether  it  is  due  to  the  invention  and 
adoption  of  new 
(smartphones,  social 
networking,  etc.).  It  is  likely  that  both  of  these  factors 
played a role in shaping our findings. 

technologies 

search 

create 

solutions 

tendency  of  respondents 
technologies 

to  appropriate  existing 
The 
facto 
to 
de 
communications 
using 
collaborative 
than 
increasingly  available  dedicated  collaborative 
tools) 
remains similar to six years ago. Consequently, respondents 
reported  many  of  the  same  frustrations  with  collaborative 
search  (lack  of  awareness,  wasted  duplication  of  effort)  as 
in our earlier survey [22].  

(rather 

Our  findings  suggest  that  the  meaning  of  the  term 
“collaborative search” has evolved (or should evolve!). Our 
initial conception of collaborative search in our survey [22] 
and  SearchTogether  prototype 
the 
synchronous  or  asynchronous  use  of  search  engines  by 
multiple  parties  with  a  shared  information  need.  However, 
our  survey  findings  indicate  that  collaborative  search  now 
occurs  beyond 
in  apps  on 
smartphones, in questions on social networking sites, etc.).  

the  search  engine  (e.g., 

involved 

[24] 

Limitations 
The  reader  should  note  that  differences  between  our 
findings  and  prior  work  (particularly  [22])  are  difficult  to 
attribute to a single cause. Differences may be due to social 
and  technological  changes  occurring  between  2006  and 
2012,  which  is  our  primary  hypothesis.  Other  sources  of 
differential findings may be in the survey audience (highly 
technical  respondents  in  [22]  versus  the  more  general 
population we reached with this survey), or in the nature of 
the  questions  themselves  (the  “have  you  ever”  approach 

employed 
approach [7, 10] employed in the current work). 

in  [22]  versus 

the  recent  critical-incident 

To  explore  whether  our  findings  were  due  to  audience 
background  rather  than  sociotechnical  changes  occurring 
between 2006 and 2012, we issued the same survey to 250 
randomly  selected U.S.-based  Microsoft  employees in July 
2012;  63  completed  the  survey  (25%  response  rate).  The 
results  from  this  group  were  very  similar  to  the  results  of 
the  more  diverse  2012  audience  discussed  in  this  paper  – 
for  instance,  61.9%  of  the  2012  Microsoft  employee 
respondents  reported  having  engaged  in  collaborative  Web 
search,  which  is  not  significantly  different  than  the  65.3% 
figure for the diverse group (χ2(1, N=63) = .279, p = .597). 
Similarly,  of  the  2012  Microsoft  employees  who  searched 
collaboratively,  49.5%  reported  doing  so  at  least  once  per 
week,  which  is  quite  similar  to  the  47.3%  of  our  more 
diverse  sample 
that  collaboratively  searched  at  least 
weekly.  The  similarity  between  the  diverse  and  tech 
audiences’ 
that 
differences in audience background between our survey and 
the  2006  survey  are  not  the  primary  source  of  the 
differences in our findings. 

increased  our  confidence 

responses 

Additionally,  the  reader  should  bear  in  mind  the  inherent 
limits  of  all  self-report  studies,  such  as  potential 
inaccuracies in participants’ memory or biases in what they 
choose  to  report  (for  more  detail  on  the  pros  and  cons  of 
retrospective  self-report  methods,  see  [19]).  It  is  also 
unclear  whether 
to  other 
demographics,  such  as  children  or  people  outside  the 
United  States  (e.g.,  staffed  Q&A  sites  are  reportedly  a 
popular  form  of  asymmetric  collaborative  search  amongst 
Korean  teenagers  [18]).  Combining  our  survey  findings 
with  other  approaches,  such  as  interview  or  observational 
methods,  would  provide  a  richer  understanding  of  this 
phenomenon, and is a suggested direction for further study. 

findings 

these 

extend 

the 

[24],  and  So.cl 

increasing  availability  of 

Challenges for Collaborative Search Solutions 
Despite 
tools  designed 
specifically  to  support  collaborative  web  search  (e.g.,  free 
online  tools  including  Coagmento  [35],  HeyStaks  [37], 
SearchTogether 
[8]),  none  of  our 
respondents  utilized  such  technologies.  General-purpose 
tools that could provide rich collaborative experiences, such 
as  videoconferencing  or  projection  technologies,  were  also 
rarely  used.  Instead,  respondents  repurposed  simpler 
communications 
that  were  part  of  their 
everyday  routines  (e-mail,  texting,  instant  messaging, 
phone calls, and social networking) as a way to supplement 
status quo web browser and search engine technologies and 
enable collaborative information seeking. This suggests that 
technologies 
for  collaborative  web  search  must  be 
sufficiently  lightweight  compared  with  status  quo  ad  hoc 
solutions.    One  of  our  survey  respondents  articulated  this 
well, observing, “It might have helped if we had some sort 
of online bulletin board on which to post our findings – but 
only  if  posting  something  to  the  bulletin  board  was  faster 

technologies 

 

 

and required fewer mouse clicks than copying a link into an 
e-mail  message.”  The  tension  between  dedicated,  “top 
down” solutions versus ad hoc “bottom up” solutions is not 
unique  to  collaborative  search;  lessons  learned  about 
similar issues in areas like cyberinfrastructure development 
[41]  may  be  applicable.  Reflecting  on  our  survey  findings 
in  light  of  this  related  work  suggests  that  rather  than 
creating  dedicated  tools  for  collaborative  search,  creating 
“glue”  systems  that  offer  integration,  tighter  coupling,  and 
functionality  between  existing  social  and 
symbiotic 
information-seeking 
technologies  might  be  a  more 
promising approach. 

Despite the challenge of striking a proper  balance between 
having a low barrier to entry and offering rich collaboration 
support, there appears to be an unmet need for technologies 
supporting  collaborative  web  search,  as  evidenced  by  the 
increasing prevalence and frequency of such activities. Our 
finding  that  collaborative  search  is  more  common  among 
younger  demographics  suggests  that  its  prevalence  might 
continue  to  increase  as  a  new  generation  of  users  with 
different  attitudes  about  collaboration  and  technology 
emerges into the marketplace.  

Our  results  suggest  that  systems  that  address  users’ 
frustrations  regarding  lack  of  awareness  of  collaborators’ 
activities  and  the  resulting  redundant  work  that  occurs 
would  be  particularly  valued;  these  findings  reinforce 
similar findings from prior work [22, 24], indicating a need 
that  has  continued  to  go  unmet  by  technical  advances. 
Solutions  that  can  enhance  common  scenarios,  such  as  the 
use  of  social  networks  for  Q&A  activities  or  the  use  of 
several  smartphones  for  synchronous  co-located  searching, 
may  be  a  particularly  promising  direction  for  research  and 
development.  

Shortly  after  the  completion  of  our  survey,  Microsoft 
introduced collaborative search support into its Bing search 
engine  with the “sidebar” feature [3], which enables a user 
to start a conversation with social network contacts around 
a query and a set of curated search results. The introduction 
of  collaborative  features  into  a  mainstream  search  engine 
could  potentially  significantly  alter  the  status  quo  reliance 
on bottom-up solutions. Revisiting the state of collaborative 
search practice in a few years seems prudent given the rapid 
evolution  of  technologies  and  attitudes  in  the  social  search 
space. 

CONCLUSION 
In this paper, we added to the growing body of knowledge 
about  collaborative  web  search  by  presenting  survey  data 
about  167  diverse  users’  status  quo  collaborative  search 
practices.  We  found  that  collaborative  search  has  become 
an 
information-seeking 
experience  (and  that  the  notion  of  what  constitutes  a 
“collaborative  search”  has  evolved  to  include  technologies 
beyond  search  engines,  such  as  smartphones  and  social 
networking sites). We also found that ad hoc combinations 
of  everyday 
to  support  such 

technologies  are  used 

increasingly  common 

type  of 

collaborations,  rather  than  dedicated  solutions  designed 
specifically for collaborative information seeking. 

By contrasting our findings with earlier work, we identified 
changes  in  the  prevalence  of  this  practice  and  in  the 
technologies  employed.  We  also 
important 
challenges  that  remain  to  be  addressed  by  designers  of 
collaborative  web search technologies. Our results indicate 
that  there  is  great  potential  for  technological  innovation  to 
enhance 
surprisingly  commonplace  practice  of 
collaborative information seeking in the digital era. 

identified 

the 

REFERENCES 
1.  Amershi, S. and Morris, M.R. CoSearch: A System for 
Co-located Collaborative Web Search. Proceedings of 
CHI 2008, 1647-1656. 

2.  Amershi, S. and Morris, M.R. Co-located Collaborative 
Web Search: Understanding Status Quo Practices. CHI 
2009 Extended Abstracts, 3637-3642. 

3.  Bing Team. Introducing the New Bing: Spend Less 

Time Searching, More Time Doing. Bing Search Blog, 
May 10, 2012. 

4.  Brenner, J. Social Networking. Pew Internet and 

American Life Project, March 29, 2012. 

5.  Dybwad, B. Bing and Ping: Share Search Results on 

Facebook and Twitter. Mashable, Sept. 3, 2009. 

6.  Efron, M. and Winget, M. Questions are Content: A 

Taxonomy of Questions in a Microblogging 
Environment. Proceedings of ASIS&T 2010. 

7.  Evans, B. and Chi, E. Towards a Model of 

Understanding Social Search. Proceedings of CSCW 
2008, 485-494. 

8.  Farnham, S.D., Lahav, M., Raskino, D., Cheng, L., 

Ickman, T., and Laird-McConnell, T. So.cl: An Interest 
Network for Informal Learning. Proceedings of ICWSM 
2012. 

9.  Fidel, R., Bruce, H., Pejtersen, A.M., Dumais, S.T., 

Grudin, J., and Poltrock, S. Collaborative Information 
Retrieval. The New Review of Information Behaviour 
Research, 2000, volume 1, 235-247. 

10. Flanagan, J. The critical incident technique. 

Psychological Bulletin, 51:327-358, 1954. 

11. Foster, J. Collaborative Information Behavior: User 

Engagement and Communication Sharing. IGI Global, 
June 2010. 

12. Greenberg, S. and Roseman, M. GroupWeb: A WWW 
Browser as Real Time Groupware. Proceedings of the 
CHI 1996 Conference Companion, 271-272. 

13. Golovchinksy, G., Morris, M.R., and Pickens, J. 

Introduction to the special issue. Information Processing 
& Management, Special Issue on Collaborative 
Information Seeking, 46(6), November 2010. 

 

 

14. Harper, F., Moy, D., and Konstan, J. Facts or friends? 

Distinguishing informational and conversational 
questions in social Q&A sites. Proceedings of CHI 
2009, 759-768. 

15. Hecht, B., Teevan, J., Morris, M.R., and Liebling, D. 

SearchBuddies: Bringing Search Engines into the 
Conversation. Proceedings of ICWSM 2012. 

16. Horowitz, D. and Kamvar, S.D. The Anatomy of a 
Large-Scale Social Search Engine. Proceedings of 
WWW 2010, 431-440. 

17. Lampe, C., Vitak, J., Gray, R., & Ellison, N. Perceptions 

of Facebook’s Value as an Information Source. 
Proceedings of CHI 2012, 3195-3204. 

18. Lee, U. Kang, H. Yi, E., Yi, M.Y., Kantola, J. 

Understanding Mobile Q&A Usage: An Exploratory 
Study. Proceedings of CHI 2012, 3215-3224. 

19. Metts, S., Sprecher, S., and Cupach, W.R. Retrospective 

Self-Reports. In Studying Interpersonal Interaction 
(Montgomery, B.M. and Duck, S., eds.). The Guilford 
Press: 1991. 

20. Moraveji, N., Morris, M.R., Morris, D., Czerwinski, M., 

and Riche, N. ClassSearch: Facilitating the 
Development of Web Search Skills through Social 
Learning. Proceedings of CHI 2011, 1797-1806. 

21. Morris, M.R. Interfaces for Collaborative Exploratory 

Web Search: Motivations and Directions for Multi-User 
Designs. CHI 2007 Workshop on Exploratory Search 
and HCI. 

22. Morris, M.R. A Survey of Collaborative Web Search 

Practices. Proceedings of CHI 2008, 1657-1660. 

23. Morris, M.R., Fisher, D., and Wigdor, D. Search on 

Surfaces: Exploring the Potential of Interactive 
Tabletops for Collaborative Search Tasks. Information 
Processing and Management, 46(6), November 2010. 

24. Morris, M.R. and Horvitz, E. SearchTogether; An 

Interface for Collaborative Web Search. Proceedings of 
UIST 2007, 3-12. 

25. Morris, M.R. and Teevan, J. Collaborative Web Search: 

Who, What, Where, When, and Why? Morgan & 
Claypool, 2010. 

26. Morris, M.R., Teevan, J., and Bush, S. Enhancing 

Collaborative Web Search with Personalization: 
Groupization, Smart Splitting, and Group Hit-
Highlighting. Proceedings of CSCW 2008, 481-484. 

27. Morris, M.R., Teevan, J., and Panovich, K. What Do 

People Ask Their Social Networks, and Why? A Survey 
Study of Status Message Q&A Behavior. Proceedings 
of CHI 2010, 1739-1748. 

28. Morris, M.R., Teevan, J., and Panovich, K. A 

Comparison of Information Seeking Using Search 
Engines and Social Networks. Proceedings of ICWSM 
2010. 

29. Paul, S.A., Hong, L., and Chi, E.H. Is Twitter a Good 

36. Smith, A. Nearly half of American adults are 

Place for Asking Questions? A Characterization Study. 
Proceedings of ICWSM 2011. 

smartphone owners. Pew Internet & American Life 
Project, March 1, 2012. 

30. Paul, S.A., Hong, L., and Chi, E.H. Who is 

37. Smyth, B., Briggs, P., Coyle, M., and O’Mahoney, M. 

Authoritative? Understanding Reputation Mechanisms 
in Quora. Proceedings of Collective Intelligence 2012. 

Google Shared: A Case Study in Social Search. 
Proceedings of UMAP 2009. 

31. Pickens, J., Golovchinsky, G., Shah, C., Qvarfordt, P., 
and Back, M. Algorithmic Mediation for Collaborative 
Exploratory Search. Proceedings of SIGIR 2008, 315-
322. 

32. Purcell, K. Search and email still top the list of most 

popular online activities. Pew Internet &American Life 
Project, August 9, 2011. 

38. Taylor, R.S. Question-Negotiation and Information-
Seeking in Libraries. College & Research Libraries, 
29(3), 1968, 178-194. 

39. Teevan, J., Karlson, A., Amini, S., Brush, A.J.B., and 
Krumm, J. Understanding the Importance of Location, 
Time, and People in Mobile Local Search Behavior. 
Proceedings of Mobile HCI 2011. 

33. Rivlin, G. Does Quora Really Have All the Answers? 

40. Thom, J., Helsley, S.Y., Matthews, T.L., Daly, E.M., 

Wired, May 2011. 

34. Shah, C. Collaborative Information Seeking: The Art 

and Science of Making the Whole Greater than the Sum 
of All. The Information Retrieval Series, Springer, 2012. 

35. Shah, C. and Gonzalez-Ibanez, R. Evaluating the 

Synergic Effect of Collaboration in Information 
Seeking. Proceedings of SIGIR 2011, 913-922. 

Millen, D.R. What Are You Working On? Status 
Message Q&A within an Enterprise SNS. Proceedings 
of ECSCW 2011. 

41. Twidale, M.B. and Floyd, I.R. Infrastructures from the 

Bottom-Up and Top-Down: Can They Meet in the 
Middle? Proceedings of PDC 2008, 238-241. 

42. Wiltse, H. and Nichols, J. PlayByPlay: Collaborative 

Web Browsing for Desktop and Mobile Devices. 
Proceedings of CHI 2009, 1781-1790.  

 

 

 

 

","{""pos"":{""0"":1,""1"":2,""2"":3,""3"":4},""4"":{""0"":""technologies*"",""1"":""proceedings*"",""2"":""practices"",""3"":""solutions""},""0"":{""0"":""morris*"",""1"":""facebook"",""2"":""twitter"",""3"":""linkedin*""},""3"":{""0"":""users*"",""1"":""groups*"",""2"":""accounts"",""3"":""members*""},""1"":{""0"":""r"",""1"":""m"",""2"":""p"",""3"":""j""},""5"":{""0"":""collaborative"",""1"":""reported*"",""2"":""recent"",""3"":""asking""},""2"":{""0"":""8*"",""1"":""13*"",""2"":""01*"",""3"":""03*""}}",2013,{},False,False,conferencePaper,False,3I937GAS,[],self.user,"{""Unnamed: 0"":{""0"":0,""1"":1,""2"":2,""3"":3,""4"":4,""5"":5,""6"":6,""7"":7,""8"":8,""9"":9,""10"":10,""11"":11,""12"":12,""13"":13,""14"":14,""15"":15,""16"":16,""17"":17,""18"":18,""19"":19,""20"":20,""21"":21,""22"":22,""23"":23,""24"":24,""25"":25,""26"":26,""27"":27,""28"":28,""29"":29,""30"":30,""31"":31,""32"":32,""33"":33,""34"":34,""35"":35,""36"":36,""37"":37,""38"":38,""39"":39,""40"":40,""41"":41,""42"":42,""43"":43,""44"":44,""45"":45,""46"":46,""47"":47,""48"":48,""49"":49,""50"":50,""51"":51,""52"":52,""53"":53,""54"":54,""55"":55,""56"":56,""57"":57,""58"":58,""59"":59,""60"":60,""61"":61,""62"":62,""63"":63,""64"":64,""65"":65,""66"":66,""67"":67,""68"":68,""69"":69,""70"":70,""71"":71,""72"":72,""73"":73,""74"":74,""75"":75},""C"":{""0"":8.7296358113,""1"":7.5513998243,""2"":15.7025591625,""3"":4.5845920359,""4"":8.5665900327,""5"":9.3492112844,""6"":11.3370745405,""7"":5.9098008473,""8"":4.3705521263,""9"":25.6484687004,""10"":8.9448478689,""11"":5.02718116,""12"":4.3744153339,""13"":31.7329165878,""14"":4.981688623,""15"":6.0629857787,""16"":5.8945533271,""17"":4.1960392628,""18"":4.0176466557,""19"":24.2723930786,""20"":15.0992838497,""21"":5.0176241533,""22"":8.3419839515,""23"":14.2122716836,""24"":13.8779168062,""25"":12.1059133866,""26"":5.9177310858,""27"":5.3475528416,""28"":7.9745826634,""29"":6.1460083307,""30"":13.3976519132,""31"":7.6263383217,""32"":8.7799381671,""33"":5.7158184578,""34"":8.7642031713,""35"":14.7225302438,""36"":5.743230018,""37"":4.06172759,""38"":11.1859911305,""39"":12.6509279892,""40"":6.6376358201,""41"":5.5108078498,""42"":6.6834182478,""43"":4.8679649867,""44"":4.0280805268,""45"":4.6924969113,""46"":10.5599456013,""47"":8.0196240058,""48"":3.9956446877,""49"":5.9299401571,""50"":4.928365272,""51"":4.8542238631,""52"":8.0971399739,""53"":5.3102898845,""54"":6.3034324006,""55"":8.0949856153,""56"":6.5659920786,""57"":4.0232619884,""58"":4.7372732264,""59"":6.2610046164,""60"":6.4588939001,""61"":4.2840697055,""62"":4.279930322,""63"":4.8615550546,""64"":4.8323986014,""65"":5.3925487791,""66"":4.6938503222,""67"":4.7133423291,""68"":4.6782864848,""69"":4.5739020987,""70"":4.1150779093,""71"":4.183622679,""72"":4.5893158167,""73"":3.9918092174,""74"":4.2499035043,""75"":4.3207260687},""count"":{""0"":312,""1"":240,""2"":122,""3"":104,""4"":78,""5"":70,""6"":70,""7"":68,""8"":54,""9"":54,""10"":52,""11"":50,""12"":50,""13"":50,""14"":44,""15"":42,""16"":40,""17"":38,""18"":38,""19"":38,""20"":36,""21"":34,""22"":34,""23"":32,""24"":30,""25"":30,""26"":30,""27"":28,""28"":28,""29"":26,""30"":24,""31"":22,""32"":22,""33"":22,""34"":22,""35"":22,""36"":20,""37"":20,""38"":20,""39"":20,""40"":18,""41"":18,""42"":16,""43"":14,""44"":14,""45"":14,""46"":14,""47"":14,""48"":12,""49"":12,""50"":12,""51"":12,""52"":12,""53"":10,""54"":10,""55"":10,""56"":10,""57"":8,""58"":8,""59"":8,""60"":8,""61"":8,""62"":8,""63"":8,""64"":8,""65"":8,""66"":6,""67"":6,""68"":6,""69"":6,""70"":6,""71"":6,""72"":6,""73"":6,""74"":6,""75"":6},""sigma_nor"":{""0"":1.4799798861,""1"":1.4695833014,""2"":2.3496632691,""3"":1.4137003393,""4"":1.8920962297,""5"":2.0222563038,""6"":2.2441042002,""7"":1.6463062619,""8"":1.5189540685,""9"":4.1782446697,""10"":2.1078346136,""11"":1.6198809979,""12"":1.5355720954,""13"":5.0690983987,""14"":1.6456664741,""15"":1.8076255016,""16"":1.7991639504,""17"":1.5690753207,""18"":1.543246181,""19"":4.4758939126,""20"":3.1940662561,""21"":1.7169363066,""22"":2.2203272983,""23"":3.1589795445,""24"":3.1592443104,""25"":2.8773626378,""26"":1.8929767395,""27"":1.8218807207,""28"":2.2510463753,""29"":1.9771238497,""30"":3.2592369749,""31"":2.2974777942,""32"":2.5036061993,""33"":1.9561008305,""34"":2.5007946268,""35"":3.5654449574,""36"":1.9901063628,""37"":1.6793102492,""38"":2.9961049109,""39"":3.2668726926,""40"":2.1932168783,""41"":1.9772498842,""42"":2.2437117487,""43"":1.9119936076,""44"":1.7373913443,""45"":1.8755158246,""46"":3.095290532,""47"":2.567187059,""48"":1.7542611152,""49"":2.175257457,""50"":1.9572662714,""51"":1.9411295113,""52"":2.6469450607,""53"":2.078658015,""54"":2.3058941332,""55"":2.7158107278,""56"":2.3659691387,""57"":1.8053216279,""58"":1.9778210991,""59"":2.3459425586,""60"":2.3937510454,""61"":1.8683307108,""62"":1.8673306685,""63"":2.0078466064,""64"":2.0008026378,""65"":2.136130493,""66"":1.9876033361,""67"":1.9925943835,""68"":1.9836181204,""69"":1.9568898607,""70"":1.839405124,""71"":1.856956431,""72"":1.9608366373,""73"":1.8078414223,""74"":1.8739280412,""75"":1.8920625915},""vocab_index"":{""0"":0,""1"":1,""2"":3,""3"":5,""4"":7,""5"":9,""6"":10,""7"":11,""8"":15,""9"":17,""10"":20,""11"":21,""12"":22,""13"":23,""14"":30,""15"":33,""16"":36,""17"":37,""18"":40,""19"":41,""20"":44,""21"":45,""22"":48,""23"":51,""24"":52,""25"":54,""26"":58,""27"":62,""28"":63,""29"":69,""30"":76,""31"":79,""32"":80,""33"":81,""34"":82,""35"":83,""36"":90,""37"":94,""38"":96,""39"":97,""40"":111,""41"":114,""42"":129,""43"":130,""44"":133,""45"":149,""46"":150,""47"":152,""48"":161,""49"":187,""50"":188,""51"":189,""52"":190,""53"":226,""54"":231,""55"":233,""56"":234,""57"":247,""58"":255,""59"":286,""60"":288,""61"":295,""62"":296,""63"":297,""64"":298,""65"":299,""66"":311,""67"":354,""68"":370,""69"":374,""70"":381,""71"":382,""72"":399,""73"":402,""74"":409,""75"":410},""word"":{""0"":""search"",""1"":""collaborative"",""2"":""respondents"",""3"":""web"",""4"":""technologies"",""5"":""reported"",""6"":""r"",""7"":""questions"",""8"":""findings"",""9"":""m"",""10"":""users"",""11"":""sites"",""12"":""8"",""13"":""proceedings"",""14"":""group"",""15"":""common"",""16"":""question"",""17"":""recent"",""18"":""p"",""19"":""j"",""20"":""answers"",""21"":""practices"",""22"":""asking"",""23"":""posting"",""24"":""morris"",""25"":""chi"",""26"":""asked"",""27"":""searches"",""28"":""facebook"",""29"":""twitter"",""30"":""linkedin"",""31"":""yahoo"",""32"":""table"",""33"":""collaboratively"",""34"":""groups"",""35"":""accounts"",""36"":""2008"",""37"":""likely"",""38"":""solutions"",""39"":""d"",""40"":""0"",""41"":""content"",""42"":""topics"",""43"":""13"",""44"":""quo"",""45"":""larger"",""46"":""chacha"",""47"":""b"",""48"":""h"",""49"":""01"",""50"":""figure"",""51"":""understanding"",""52"":""teevan"",""53"":""members"",""54"":""account"",""55"":""lurking"",""56"":""differences"",""57"":""commercial"",""58"":""stages"",""59"":""pairs"",""60"":""sizes"",""61"":""posted"",""62"":""l"",""63"":""icwsm"",""64"":""c"",""65"":""exploratory"",""66"":""copies"",""67"":""aged"",""68"":""looking"",""69"":""relationship"",""70"":""ease"",""71"":""aspects"",""72"":""03"",""73"":""kgb"",""74"":""k"",""75"":""shah""},""vector"":{""0"":""[ 3.1810894  -5.82333    -3.1150928   3.193294    0.8967888  -0.9673918\n  0.9284144   0.5300843  -6.0370755   0.39285383]"",""1"":""[ 3.7658584  -5.9372063  -2.8105237   3.235335    1.5683743  -1.0297164\n  0.65649486  1.0039282  -6.12179     0.5537354 ]"",""2"":""[ 2.9596174  -6.000642   -4.056805    3.4396946   1.818522   -0.26520053\n  0.9949768   0.768087   -6.086398    0.5806256 ]"",""3"":""[ 3.115064   -5.6017656  -2.9183078   2.7539606   1.3746012  -0.4286533\n  1.6297196   0.58675694 -5.730392    0.6899879 ]"",""4"":""[ 2.8150961 -6.190997  -3.5255938  3.363326   1.9391637 -0.4476465\n  1.0523742  0.5417931 -6.025013   1.1405272]"",""5"":""[ 3.7871165  -5.116351   -3.3817606   3.4914138   0.5376451  -1.4721333\n  0.2203677   0.44939196 -6.1381764  -0.25714767]"",""6"":""[ 4.015201   -3.6255748  -2.518874    1.9726875  -0.29458398 -0.65891415\n  2.197245    0.03184345 -4.478338   -0.0200951 ]"",""7"":""[ 3.102301   -5.7803774  -3.7515101   3.6162412   1.2130316  -0.8646258\n  0.51165783  0.4483399  -6.2311835   0.23375611]"",""8"":""[ 3.024272   -5.983671   -3.6660955   3.392813    1.6389235  -0.97951996\n  0.52701133  0.6008338  -6.1947885   1.0063608 ]"",""9"":""[ 4.1799803  -3.193185   -2.3716805   1.9627742  -0.20144899 -0.4062006\n  2.1448932  -0.01548113 -4.624724   -0.3171786 ]"",""10"":""[ 3.1434844  -5.882107   -3.7778986   3.172654    2.0118134  -0.02871616\n  1.3708042   0.8951332  -5.81013     0.68699116]"",""11"":""[ 3.0294168  -5.9151754  -3.2700887   2.9610636   1.8551459  -0.25348616\n  1.42272     0.78498375 -5.8533726   0.87299144]"",""12"":""[ 4.279794   -3.74447    -2.5564802   2.4115174  -0.10111704 -1.0758291\n  1.2651498   0.14656964 -5.148529   -0.4367053 ]"",""13"":""[ 2.8497589  -5.940533   -3.6916249   3.182231    1.90817    -0.6952424\n  0.80114084  0.7060212  -6.2316227   1.1305883 ]"",""14"":""[ 3.6091506 -5.6820946 -3.49419    2.9562442  2.0066123 -0.3239355\n  1.0547321  1.2497327 -5.807254   0.5768162]"",""15"":""[ 4.112412   -5.50478    -2.8638585   3.298223    1.2340543  -1.3929049\n  0.28913337  0.92617774 -6.062492    0.25874123]"",""16"":""[ 3.4187708  -5.566385   -3.7499726   3.6121414   1.2761858  -0.9338541\n  0.3475137   0.65709716 -6.2385592   0.04713861]"",""17"":""[ 4.080214   -5.283934   -3.0264015   3.2588406   0.92105573 -1.4886962\n  0.24414164  0.79059505 -6.008898    0.04167043]"",""18"":""[ 4.2530274  -3.5986502  -2.445037    1.7820363  -0.17957194 -0.8047382\n  2.1598866  -0.1169071  -4.516775   -0.19334087]"",""19"":""[ 3.8371522  -3.5838401  -2.25312     1.8136567   0.0370433  -0.33617517\n  2.2872722  -0.01811893 -4.801751   -0.13825995]"",""20"":""[ 3.1452532  -5.910949   -3.513014    3.522425    1.1185358  -0.7081131\n  0.76855403  0.4768311  -6.055597    0.26887047]"",""21"":""[ 3.084975   -6.1666064  -3.64144     3.3662596   1.9863869  -0.57697326\n  0.88617605  0.72857136 -5.8946133   1.1743968 ]"",""22"":""[ 3.3886364  -5.6666493  -3.52208     3.511227    0.6943265  -1.374748\n  0.32719648  0.5766848  -6.1499085  -0.02760573]"",""23"":""[ 3.4073756  -5.2600946  -3.4312823   3.4712973   0.6822763  -1.0212618\n  0.637693    0.30168355 -6.109888   -0.12565191]"",""24"":""[ 3.3936458  -4.5688405  -2.6310873   2.0293827   0.67356914 -0.29961702\n  2.4082658   0.2829225  -4.9831257   0.35563946]"",""25"":""[ 3.9793656  -3.492645   -2.2237787   1.708616   -0.21788299 -0.5413178\n  2.3553963  -0.09039471 -4.5336385  -0.08135861]"",""26"":""[ 3.559483   -5.4514003  -3.5776892   3.4541311   0.6142751  -1.405229\n  0.24103594  0.52122915 -6.1063094  -0.21672373]"",""27"":""[ 3.0728667  -5.968871   -3.21318     3.200703    1.1693081  -0.87495935\n  0.9226927   0.58917606 -6.084058    0.61326337]"",""28"":""[ 3.162992   -4.967425   -2.8460436   2.204639    0.9089355  -0.25928658\n  2.4247859   0.38416505 -5.109417    0.48675245]"",""29"":""[ 3.2068822  -5.0807066  -2.9005773   2.319519    1.0638275  -0.28659642\n  2.243742    0.4236928  -5.2118464   0.5461433 ]"",""30"":""[ 3.2891023  -4.7771373  -2.7983024   2.3016179   0.80908847 -0.30005434\n  2.2491574   0.2895111  -5.2422447   0.44769716]"",""31"":""[ 3.238178   -4.902034   -2.589713    2.1506588   0.8711656  -0.3578912\n  2.2373462   0.4499057  -5.0487747   0.44979742]"",""32"":""[ 3.6045506  -5.630371   -3.7689447   3.5975757   1.8838313  -0.5738336\n  0.46674243  0.9170743  -6.072452    0.3182382 ]"",""33"":""[ 3.583174  -6.108163  -3.105537   3.3581033  1.8574716 -0.6374441\n  0.8030997  1.0465573 -6.0656185  0.5203593]"",""34"":""[ 3.3153203 -5.924984  -3.6192515  3.041047   2.2488146 -0.2127116\n  1.1346173  1.1342244 -5.809176   0.9373567]"",""35"":""[ 3.10345    -5.578149   -3.7847161   3.0842485   1.9334888  -0.23990828\n  1.3756281   0.64911747 -5.7309303   0.98174775]"",""36"":""[ 4.425545   -3.971774   -2.651495    2.2928495   0.23856226 -1.0829448\n  1.1499711   0.5554757  -4.930934   -0.27559727]"",""37"":""[ 3.9258614  -5.1909204  -3.148679    3.29196     0.6438484  -1.4870168\n  0.28259113  0.62996    -5.9978585  -0.14797884]"",""38"":""[ 2.977591   -6.1986403  -3.408916    3.493117    1.6439712  -0.51663643\n  0.9050362   0.5319213  -6.0494347   0.7363495 ]"",""39"":""[ 4.248127   -3.3373187  -2.4239917   1.9768842  -0.34324014 -0.7065393\n  1.9580554   0.01918255 -4.586476   -0.32274067]"",""40"":""[ 4.2638326  -3.585178   -2.4395504   2.2196755  -0.24005455 -0.9948557\n  1.4992028   0.12180846 -4.9239483  -0.3917219 ]"",""41"":""[ 2.832614   -5.789377   -3.2175589   3.2345788   1.8213743  -0.36903733\n  1.2105798   0.47406694 -6.209974    0.6922229 ]"",""42"":""[ 2.8126726  -5.828243   -3.5966306   3.3352873   1.9459971  -0.42846754\n  0.99188703  0.5285325  -6.222532    0.8504022 ]"",""43"":""[ 4.3102612  -3.9074337  -2.6489642   2.422753   -0.07947914 -1.1800778\n  1.0989377   0.2819879  -5.08184    -0.46184742]"",""44"":""[ 3.220051   -5.8752747  -3.7953756   3.5352087   1.9676949  -0.6862054\n  0.44876403  0.9464518  -6.4287853   0.51327944]"",""45"":""[ 4.07344    -5.670699   -2.834905    3.259372    1.4912616  -1.2083281\n  0.43527988  1.0219785  -6.0103164   0.4634494 ]"",""46"":""[ 3.446989   -4.3692074  -2.6751904   2.1733146   0.5276356  -0.3363755\n  2.2669284   0.20363605 -5.074083    0.32779634]"",""47"":""[ 4.239439   -3.5038035  -2.5730155   1.8920151  -0.3845533  -0.9144895\n  1.978743   -0.01876846 -4.559601   -0.26717547]"",""48"":""[ 3.9551024  -3.3686833  -2.1646123   1.8710476  -0.3106009  -0.44025487\n  2.233679   -0.02521364 -4.559832   -0.06808177]"",""49"":""[ 4.4676228e+00 -3.7210593e+00 -2.5328250e+00  2.1538627e+00\n  2.7040716e-03 -1.0547572e+00  1.3214915e+00  3.4547335e-01\n -4.8114257e+00 -3.8186991e-01]"",""50"":""[ 3.6700883  -5.3983445  -3.7864673   3.3643963   1.7989428  -0.64774036\n  0.52176785  1.0360479  -6.0820985   0.25295416]"",""51"":""[ 3.475826   -5.7148104  -3.373986    3.4682722   1.349737   -1.1751642\n  0.33383867  0.74849087 -6.2623363   0.37997574]"",""52"":""[ 3.4853728  -4.382063   -2.9449663   2.3650677   0.6253199  -0.29609996\n  2.1112323   0.17455953 -5.370579    0.3677003 ]"",""53"":""[ 3.3105276  -5.90138    -3.7465794   3.1872592   1.9377888  -0.07187871\n  1.2134444   1.0025336  -5.77666     0.53764933]"",""54"":""[ 3.2858586  -5.2577543  -3.7882648   3.0971913   1.7830505  -0.4704583\n  1.2095456   0.60776997 -5.793339    0.8187317 ]"",""55"":""[ 3.601745   -5.2427273  -3.296141    3.419411    0.69619036 -1.2175748\n  0.43623406  0.47283575 -6.087584   -0.12364948]"",""56"":""[ 3.2201817  -5.9001713  -3.4386492   3.441365    1.9986283  -0.84538037\n  0.50060534  0.74159133 -6.2276387   0.8848974 ]"",""57"":""[ 3.8682177  -5.7541685  -2.7477486   3.1898303   1.5470192  -1.1653392\n  0.5726038   0.9266846  -6.1348844   0.65648985]"",""58"":""[ 2.9491892 -5.9279895 -3.4760165  3.0261464  2.0954006 -0.5334852\n  0.9302061  0.8937302 -6.192917   1.0662237]"",""59"":""[ 3.6281085  -5.9070287  -3.552695    3.2542357   2.1344845  -0.2099558\n  0.96234375  1.168655   -5.7395096   0.6057335 ]"",""60"":""[ 3.5198417  -5.9706855  -3.5121841   3.2863493   2.245188   -0.4897844\n  0.7901535   1.0682534  -5.83043     0.99453217]"",""61"":""[ 3.5328262  -5.2279487  -3.4741843   3.4427893   0.59193    -1.2164862\n  0.42038128  0.36034212 -6.1158237  -0.2484817 ]"",""62"":""[ 3.9920924  -3.5391927  -2.2757077   2.0164418  -0.33207646 -0.5833103\n  2.0809898   0.05844437 -4.6091146  -0.18426451]"",""63"":""[ 3.386314   -4.628407   -3.0237186   2.4495752   0.78800803 -0.2912055\n  2.0813975   0.262981   -5.4429264   0.48426434]"",""64"":""[ 4.2436814  -3.501222   -2.434448    1.9314777  -0.22104038 -0.8090615\n  1.8934397   0.00605347 -4.64627    -0.2482856 ]"",""65"":""[ 3.5559154  -5.9796834  -2.9187977   3.231082    1.31944    -1.069492\n  0.6920279   0.87789506 -6.1179204   0.51992697]"",""66"":""[ 3.3253038  -5.9065323  -3.6492605   3.3948956   1.6609726  -0.09763002\n  1.2109554   0.7581033  -5.7459955   0.36296105]"",""67"":""[ 3.9952319  -4.4089556  -2.9221528   2.7532983   0.30185828 -1.0761048\n  0.9640451   0.35608593 -5.485898   -0.2746655 ]"",""68"":""[ 3.627329   -5.271769   -3.2083087   3.224       0.6102516  -1.3070562\n  0.5236348   0.58038074 -5.92855    -0.05833449]"",""69"":""[ 3.4333994  -5.713475   -3.5449193   3.4210584   1.8783128  -0.88168573\n  0.4053387   0.93610114 -6.3109765   0.5587649 ]"",""70"":""[ 3.8719416  -5.5348854  -3.1649864   3.4842007   1.2930872  -1.2473176\n  0.24549477  0.83048457 -6.1618094   0.19232652]"",""71"":""[ 2.8993452  -5.8882203  -3.3846722   3.2484257   2.0637827  -0.7044354\n  0.74836373  0.68594056 -6.3650465   0.9816713 ]"",""72"":""[ 4.355204   -3.7768989  -2.500188    2.2958012  -0.11793007 -1.1467475\n  1.2181121   0.36242163 -4.932051   -0.39415234]"",""73"":""[ 3.3681746  -4.5531273  -2.6480105   2.2436676   0.6447223  -0.36702374\n  2.1593406   0.27308246 -5.1563087   0.36292425]"",""74"":""[ 3.8946252  -3.630701   -2.4044602   1.9327054  -0.04568657 -0.4423744\n  2.232913    0.02119049 -4.712355   -0.05176731]"",""75"":""[ 3.6654694  -4.0149593  -2.562753    2.0474713   0.2437775  -0.390419\n  2.2822633   0.10955485 -4.8710895   0.17028749]""},""topic"":{""0"":-1,""1"":5,""2"":-1,""3"":-1,""4"":4,""5"":5,""6"":1,""7"":-1,""8"":-1,""9"":1,""10"":3,""11"":-1,""12"":2,""13"":4,""14"":-1,""15"":-1,""16"":-1,""17"":5,""18"":1,""19"":1,""20"":-1,""21"":4,""22"":5,""23"":5,""24"":0,""25"":1,""26"":5,""27"":-1,""28"":0,""29"":0,""30"":0,""31"":0,""32"":-1,""33"":-1,""34"":3,""35"":3,""36"":-1,""37"":5,""38"":4,""39"":1,""40"":1,""41"":-1,""42"":4,""43"":2,""44"":-1,""45"":5,""46"":0,""47"":1,""48"":1,""49"":2,""50"":-1,""51"":4,""52"":0,""53"":3,""54"":-1,""55"":5,""56"":4,""57"":-1,""58"":4,""59"":3,""60"":-1,""61"":5,""62"":1,""63"":0,""64"":1,""65"":5,""66"":-1,""67"":-1,""68"":5,""69"":4,""70"":5,""71"":4,""72"":2,""73"":0,""74"":1,""75"":-1},""exemplar"":{""0"":null,""1"":null,""2"":null,""3"":null,""4"":""*"",""5"":""*"",""6"":null,""7"":null,""8"":null,""9"":null,""10"":""*"",""11"":null,""12"":""*"",""13"":""*"",""14"":null,""15"":null,""16"":null,""17"":null,""18"":null,""19"":null,""20"":null,""21"":null,""22"":null,""23"":null,""24"":""*"",""25"":null,""26"":""*"",""27"":null,""28"":null,""29"":null,""30"":""*"",""31"":""*"",""32"":null,""33"":null,""34"":""*"",""35"":null,""36"":null,""37"":null,""38"":null,""39"":""*"",""40"":null,""41"":null,""42"":""*"",""43"":""*"",""44"":null,""45"":null,""46"":null,""47"":null,""48"":null,""49"":""*"",""50"":null,""51"":null,""52"":null,""53"":""*"",""54"":null,""55"":""*"",""56"":null,""57"":null,""58"":null,""59"":""*"",""60"":null,""61"":""*"",""62"":""*"",""63"":null,""64"":""*"",""65"":null,""66"":null,""67"":null,""68"":null,""69"":null,""70"":null,""71"":""*"",""72"":""*"",""73"":""*"",""74"":""*"",""75"":null},""word*"":{""0"":""search"",""1"":""collaborative"",""2"":""respondents"",""3"":""web"",""4"":""technologies*"",""5"":""reported*"",""6"":""r"",""7"":""questions"",""8"":""findings"",""9"":""m"",""10"":""users*"",""11"":""sites"",""12"":""8*"",""13"":""proceedings*"",""14"":""group"",""15"":""common"",""16"":""question"",""17"":""recent"",""18"":""p"",""19"":""j"",""20"":""answers"",""21"":""practices"",""22"":""asking"",""23"":""posting"",""24"":""morris*"",""25"":""chi"",""26"":""asked*"",""27"":""searches"",""28"":""facebook"",""29"":""twitter"",""30"":""linkedin*"",""31"":""yahoo*"",""32"":""table"",""33"":""collaboratively"",""34"":""groups*"",""35"":""accounts"",""36"":""2008"",""37"":""likely"",""38"":""solutions"",""39"":""d*"",""40"":""0"",""41"":""content"",""42"":""topics*"",""43"":""13*"",""44"":""quo"",""45"":""larger"",""46"":""chacha"",""47"":""b"",""48"":""h"",""49"":""01*"",""50"":""figure"",""51"":""understanding"",""52"":""teevan"",""53"":""members*"",""54"":""account"",""55"":""lurking*"",""56"":""differences"",""57"":""commercial"",""58"":""stages"",""59"":""pairs*"",""60"":""sizes"",""61"":""posted*"",""62"":""l*"",""63"":""icwsm"",""64"":""c*"",""65"":""exploratory"",""66"":""copies"",""67"":""aged"",""68"":""looking"",""69"":""relationship"",""70"":""ease"",""71"":""aspects*"",""72"":""03*"",""73"":""kgb*"",""74"":""k*"",""75"":""shah""},""pos"":{""0"":1,""1"":1,""2"":2,""3"":3,""4"":1,""5"":2,""6"":1,""7"":4,""8"":5,""9"":2,""10"":1,""11"":6,""12"":1,""13"":2,""14"":7,""15"":8,""16"":9,""17"":3,""18"":3,""19"":4,""20"":10,""21"":3,""22"":4,""23"":5,""24"":1,""25"":5,""26"":6,""27"":11,""28"":2,""29"":3,""30"":4,""31"":5,""32"":12,""33"":13,""34"":2,""35"":3,""36"":14,""37"":7,""38"":4,""39"":6,""40"":7,""41"":15,""42"":5,""43"":2,""44"":16,""45"":8,""46"":6,""47"":8,""48"":9,""49"":3,""50"":17,""51"":6,""52"":7,""53"":4,""54"":18,""55"":9,""56"":7,""57"":19,""58"":8,""59"":5,""60"":20,""61"":10,""62"":10,""63"":8,""64"":11,""65"":11,""66"":21,""67"":22,""68"":12,""69"":9,""70"":13,""71"":10,""72"":4,""73"":9,""74"":12,""75"":23},""x2D"":{""0"":5.4066772461,""1"":6.1619215012,""2"":6.0958571434,""3"":6.2023038864,""4"":5.1421227455,""5"":5.0044522285,""6"":-6.7138547897,""7"":5.0335359573,""8"":5.0060553551,""9"":-6.174352169,""10"":6.7225089073,""11"":6.3075928688,""12"":-5.8531222343,""13"":5.3388442993,""14"":7.2169260979,""15"":5.9068336487,""16"":5.026512146,""17"":4.7150783539,""18"":-6.5240297318,""19"":-6.7439146042,""20"":5.1239442825,""21"":5.4955062866,""22"":5.2522292137,""23"":4.8170824051,""24"":-7.4034919739,""25"":-6.5714430809,""26"":5.2620644569,""27"":5.4153518677,""28"":-7.4030680656,""29"":-7.2478652,""30"":-7.7459897995,""31"":-7.2770299911,""32"":5.6121468544,""33"":6.2191991806,""34"":7.0126624107,""35"":6.5243124962,""36"":-5.9638600349,""37"":4.7972970009,""38"":5.1991333961,""39"":-6.1928524971,""40"":-6.0438294411,""41"":5.7402381897,""42"":5.4955096245,""43"":-5.6877222061,""44"":5.4349403381,""45"":6.0881109238,""46"":-7.7324018478,""47"":-6.2726955414,""48"":-6.5168399811,""49"":-5.9686326981,""50"":5.5975594521,""51"":5.6373009682,""52"":-7.8598871231,""53"":6.7739863396,""54"":6.6340203285,""55"":4.9006280899,""56"":5.2951159477,""57"":6.1964373589,""58"":5.673157692,""59"":6.879222393,""60"":6.668463707,""61"":5.0777192116,""62"":-6.1495475769,""63"":-7.5947151184,""64"":-6.1934576035,""65"":6.0487337112,""66"":6.7091884613,""67"":-5.6198959351,""68"":4.7543692589,""69"":5.4095644951,""70"":5.736987114,""71"":5.2003006935,""72"":-5.9219207764,""73"":-7.5548062325,""74"":-6.9814319611,""75"":-7.1132721901},""y2D"":{""0"":-5.6440610886,""1"":-5.7213535309,""2"":-3.1948840618,""3"":-2.4790902138,""4"":-3.14341712,""5"":-7.6777305603,""6"":2.9343070984,""7"":-5.6617794037,""8"":-4.0677924156,""9"":3.0650002956,""10"":-2.7106719017,""11"":-2.627815485,""12"":1.0270364285,""13"":-3.4379086494,""14"":-3.3149135113,""15"":-6.5692605972,""16"":-6.0348615646,""17"":-7.4810557365,""18"":2.7999432087,""19"":3.389598608,""20"":-5.4429969788,""21"":-3.5842356682,""22"":-7.0171141624,""23"":-7.0086503029,""24"":-12.5576505661,""25"":3.3534965515,""26"":-7.3209476471,""27"":-5.3891062737,""28"":-12.1233205795,""29"":-11.9445343018,""30"":-12.1633501053,""31"":-12.3016042709,""32"":-4.7712740898,""33"":-4.9563741684,""34"":-3.3415493965,""35"":-2.8812336922,""36"":0.8761778474,""37"":-7.3181653023,""38"":-3.812926054,""39"":2.7822327614,""40"":1.4493201971,""41"":-2.854101181,""42"":-3.0637991428,""43"":1.0629630089,""44"":-4.3462691307,""45"":-6.269753933,""46"":-12.6677246094,""47"":2.5189669132,""48"":3.295694828,""49"":1.2221759558,""50"":-4.8965821266,""51"":-5.9522533417,""52"":-12.3111791611,""53"":-3.1333358288,""54"":-2.936565876,""55"":-7.0267438889,""56"":-4.2159385681,""57"":-6.1167149544,""58"":-3.2958254814,""59"":-3.610928297,""60"":-3.8521885872,""61"":-7.1894598007,""62"":3.027967453,""63"":-12.0756187439,""64"":2.6078841686,""65"":-5.7626414299,""66"":-3.2093458176,""67"":0.816522181,""68"":-7.2571783066,""69"":-4.7143669128,""70"":-6.4415345192,""71"":-3.5198972225,""72"":1.2052067518,""73"":-12.3220405579,""74"":3.1999731064,""75"":3.3378055096}}",False,False,False,http://dl.acm.org/citation.cfm?doid=2441776.2441910,,Collaborative search revisited,3I937GAS,False,False
H4Y2RXSJ,KAV3IH93,"This paper is © IEEE and appears reformatted in IEEE Transactions on Visualization and Computer Graphics, 30(1), 
2016, DOI: 10.1109/TVCG.2015.2467552 

The Data Context Map:                                                                     

Fusing Data and Attributes into a Unified Display 

Shenghui Cheng, Student Member, IEEE and Klaus Mueller, Senior Member, IEEE 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

  

  

 
 

  

(a
) 

  

(b) 

(c) 

 
 

 
 

(d) 

C                                         

B                                         

A                                         

(e) 

Fig.1.  The  process  to  find  a  dream  university.  (a)  good  academics  region(>9).  (b)  good  athletic  region  (>9).  (c)  combined 
region by (a) and (b). (d) low tuition region(<$18,000). (e) combined region by region (c) and (d). 

Abstract— Numerous methods have been described that allow the visualization of the data matrix. But all suffer from a common 
problem – observing the data points in the context of the attributes is either impossible or inaccurate. We describe a method that 
allows  these  types  of  comprehensive  layouts.  We  achieve  it  by  combining  two  similarity  matrices  typically  used  in  isolation  –  the 
matrix encoding the similarity of the attributes and the matrix encoding the similarity of the data points. This combined matrix yields 
two of the four submatrices needed for a full multi-dimensional scaling type layout. The remaining two submatrices are obtained by 
creating a fused similarity matrix – one that measures the similarity of the data points with respect to the attributes, and vice versa. 
The resulting layout places the data objects in direct context of the attributes and hence we call it the data context map. It allows 
users  to  simultaneously  appreciate  (1)  the  similarity  of  data  objects,  (2)  the  similarity  of  attributes  in  the  specific  scope  of  the 
collection of data objects, and (3) the relationships of data objects with attributes and vice versa. The contextual layout also allows 
data regions to be segmented and labeled based on the locations of the attributes. This enables, for example, the map’s application 
in selection tasks where users seek to identify one or more data objects that best fit a certain configuration of factors, using the map 
to visually balance the tradeoffs.  
Index Terms— High Dimensional Data, Low-Dimensional Embedding, Visual Analytics, Decision Make, Tradeoffs  
 

1 

I NTRODUCTION 

The data matrix, DM, is one of the most fundamental structures in 
data analytics. It is the M×N rectangular array of N variables (often 
referred  to  as  attributes  or  labels)  and  M  samples  (also  frequently 
called  cases,  observations,  or  data  items).  The  N×N  or  M×M 
similarity (or co-occurrence, correlation) matrix S is another often 
used  structure  and  frequently  derived  from  DM.  Here  it  should  be 
noted that the roles of variables and samples can change – there are 
many  practical  settings  in  which  we  consider  the  ‘variables’  as 
outcomes we wish to predict (or use for prediction) using the set of 

 
  Shenghui Cheng and Klaus Mueller are with the Visual Analytics and 

Imaging Laboratory, Computer Science Department, Stony Brook 
University and SUNY Korea. Email: {shecheng, mueller}@cs.sunysb.edu 

Manuscript received 31 Mar. 2015; accepted 1 Aug. 2015; date of   
publication xx Aug. 2015; date of current version 25 Oct. 2015. 
For information on obtaining reprints of this article, please send  e-mail  to: 
tvcg@computer.org.  

 

1 

samples  acquired  before.  To  visualize  DM,  current  methods  either 
focus on spatially preserving the relations among the samples or on 
spatially preserving  the  relations among the variables, but they  are                    
typically  not  capable  to  do  both.  This  is  a  severe  limitation  when 
one  wishes  to  transform  DM  into  a  comprehensive  map  in  which 
the acquired samples are accurately presented in the context of the 
variables. Our paper describes new data and similarity matrices that 
overcome these deficiencies.   

to  consider  –  academic 

To  illustrate  these  points,  let’s  consider  a  parent  looking  for  a 
university  for their  child.  This  is  an  important  decision  with  many 
factors 
tuition,  athletics, 
teacher/student  ratio  and  many  others.  College  Prowler  [15]  is  a 
popular  website  that  allows  users  to  navigate  this  parameter  space 
by  filtering  –  using  slider  bars  and  menu  selections  for  each 
parameter to narrow down the search. But this is rather tedious and 
it  also  makes  it  difficult  to  recognize  tradeoffs.  Conversely,  a 
visualization  expert  would  use  interactive  parallel  coordinates  [17] 

score, 

plots  but  it  is  difficult  to  imagine  that  an  average  parent  would 
engage in such an advanced interface. There are other visualization 
methods,  such  as  biplots  or  interior  layouts  but  these  are  seldom 
found in the mainstream arena. The wide-spread familiarity of maps, 
on  the  other  hand,  makes  these  a  natural  canvas  to  overview  the 
landscape  of  universities  in  the  context  of  the  various  factors 
(attributes) to consider. Parents could simply sit back and examine 
this  illustration  like  an  infographic  and  then  decide  on  a  school. 
They could still use a filter to eliminate some schools from the map 
but they would never lose sight of the big picture. 

Methods  like  Multidimensional  scaling  (MDS)  [23][2],  self-
organizing  map  (SOM)  [6][22],  t-distributed  stochastic  neighbor 
embedding (t-SNE) [28], locally linear embedding (LLE) [31], etc. 
create  2D  map-like  data  layouts  computed  from  the  similarity 
matrix  S  of  schools  (in  this  case).  The  entries  of  S  are  derived  by 
assessing  the distances of pairs of the M schools in  the  N-D space 
spanned  by  the  N  attribute  axes.  The  maps  will  show  similar 
schools as clusters, and special schools as outliers. This is certainly 
useful,  but  parents  will  not  know  from  the  plot  alone  why  some 
schools are special and  others are  clustered. What is their ranking, 
tuition, athletics, etc.?  

It  is  important  to  note  that  S  could  just  as  well  hold  the 
similarities  of  attributes.  The  maps  mentioned  above  would  then 
allow  a  visual assessment  of  the  grouping  of  attributes.  So  instead 
of  finding  that  schools  A  and  B  are  very  similar  (or  dissimilar)  in 
terms of their attributes, one would find that attributes C and D are 
heavily  correlated  (or  not)  in  this  set  of  schools.  A  parent  might 
learn that the higher the academic score, the higher the tuition, and 
the  higher  the  number  of  students  per  faculty  (see  findings 
presented in [37] where such a map was presented). And so, if the 
parent is interested in smaller classes, schools with lower academic 
scores might be a better choice. Hence, while such a plot is useful 
in  explaining  the  relationships  of  the  different  features  of  the 
educational  landscape,  what  it  now  cannot  do  is  allow  anxious 
parents  pick  a  specific  school  for  their  child,  which  is  what  they 
really wish to do. 

We  propose  a  framework  that  overcomes  these  limitations  and 
combines  both  of  the  similarity  aspects  derived  from  DM  into  a 
single  comprehensive  map  which  we  call  the  data  context  map.  It 
requires  a  non-trivial  fusion  of  the  two  alternative  similarity 
matrices  S  discussed  above.  By  ways  of  this  fused  matrix  a 
mapping can be performed that allows users to faithfully appreciate 
all three types of relationships in a single display: (1) the patterns of 
the  collection  of  samples,  (2)  the  patterns  of  the  collection  of 
attributes,  and  (3)  the  relationships  of  samples  with  the  attributes 
and  vice  versa.  Further,  the  contextual  mapping  also  provides  the 
information needed to add semantic labelling of the samples as well 
as  the  regions  they  reside  in.  Iso-contouring  these  regions  then 
creates  decision  boundaries  by  which  one  can  easily  recognize 
trade-offs  among  different  samples  which  can  be  helpful  in 
complex decision making. Our paper demonstrates this by ways of 
a few practical examples. 

Our paper is structured as follows. Section 2 summarizes related 
work. Section 3 provides its theoretical aspects. Section 4 describes 
the  construction  of  our  data  context  map.  Section  5  presents  case 
studies. Section 6 concludes the paper and expands on future work.   

2  REL ATED W ORK 

The  visualization  of  high-dimensional  data  on  a  2D  canvas 
essentially follows three major paradigms – projective data displays, 
interior  displays,  and  space  embeddings.  However,  since  the 
visualization  of  high-dimensional  data  in  2D  is  inherently  an  ill-
posed problem, there is no method without drawbacks. It is simply 
impossible  to  preserve  all  variances  of  a  high-dimensional  point 
cloud in a 2D mapping. Hence the different methods that have been 
described  offer  different  strengths  and  weaknesses,  but  some  do 
better than others.  

2.1 

Projective and interior displays 

These  displays  typically  warp  the  data  in  some  way  to  emphasize 
certain  properties,  such  as  locality  or  similarity.  A  projective 
display  is  the  scatterplot  matrix  [12]  which  is  an  extension  of  the 
scatterplot.  It  reserves  a  scatterplot  tile  for  each  pair  of  variables 
and projects the data items into it. This distributes the data context 
into two variables per tile which makes it difficult to appreciate the 
overall  context  pertaining  to  all  variables  simultaneously.  In 
addition,  the  mapping  operation  can  lead  to  ambiguities  as  points 
located far way in high-dimensional space may project into similar 
2D  locations.  This  adds  to  the  difficulties  for  recognizing 
multivariate relationships.    

Parallel  coordinates  and  their  radial  version,  the  star  plot  [1], 
represent  the  variables  as  parallel  or  radial  axes,  respectively,  and 
map  the  data  as  polylines  across  the  axes.  However,  the  clutter  of 
polylines  can  become  a  significant  problem  once  the  number  of 
dimensions  and  data  points  increases.  In  order  to  decrease  the 
clutter of lines, star coordinates [20] arrange the attribute axes in a 
radial  fashion  but  instead  of  constructing  polylines,  they  plot  the 
data  points  as  a  vector  sum  of  the  individual  axis  coordinates. 
However, since a vector sum is an aggregation, it maps the data to 
locations  that  are  not  unique.  In  other  words,  points  that  map  to 
nearby  locations  may  not  be  close  in  high-dimensional  space,  and 
vice versa. To help users resolve these ambiguities, at least partially, 
an interactive interface is often provided that allows them to rotate 
and scale the data axes and so uncover false neighbors.  

In  fact,  there  are  number  of  displays  that  are  similar  to  star 
coordinates and share its shortcomings [32]. These are Radviz [13], 
Generalized Barycentric Coordinates (GBC) plot [29], and PolyViz 
[14].  We  call  them  interior  displays  since  they  all  lay  out  the 
variables  as  dimension  anchors  [14]  around  a  circle  and  map  the 
data  items  as  points  inside  it,  given  some  weighting  function  that 
relates  to  a  data  point’s  different  attribute  strengths.  All  of  these 
displays are useful in what they have been designed to convey, that 
is, the relation of data points with respect to the attributes. But since 
the  mapping  function  does  not  involve  the  similarity  of  the  data 
points, ambiguities result. 

Our research described here has been motivated by recent work 
presented  by  the  authors  [7]  which  proposes  an  optimization 
approach  to  reduce  the  data  mapping  ambiguities  in  Radviz-type 
displays.  The  current  framework  is  radically  different  in  that  it 
maps  the  attributes  not  in  the  periphery  along  a  circle,  but 
intersperses  them  into  the  data  distribution  which  reduces  all 
mapping errors significantly. It also enables the region labelling and 
decision boundaries discussed above.  

2.2 

Comparing the interior displays 

We have shown in [7] that the method of GBC [29] can serve as a 
standard  reference  framework  to  describe  most  interior  displays. 
The  GBC  plot  uses  the  dimension  values  of  an  N-D  point  as 
weights in a weighted sum of the anchor 2D locations to determine 
the point’s placement in the 2D polygon.   

Using  the GBC plots, we conducted  a controlled experiment  to 
compare  them  with  the  method  proposed  here.  For  this,  we 
generated  a  test  dataset  comprised  of  a  set  of  6  6-D  Gaussian 
distributions. We first randomized the 6 6-D center vectors and then 
randomized  600  data  points  following  these  distributions.  Fig.  5d 
visualizes  this  dataset  using  parallel  coordinates,  assigning  each 
Gaussian  a  unique  color.  In  addition,  we  also  colored  the  axes 
(representing  the  6  dimensions)  such  that  each  axis  color  matches 
that of the cluster with the highest value for that dimension. Fig. 2 
shows  how  (a)  standard  GBC  compares  with  (b)  the  optimized 
GBC  plot  [7],  and  (c)  the  method  proposed  in  this  paper  which 
allows  the attribute  nodes  to  intersperse  with  the  samples.  We  can 
show  our  method  is  more  flexible  and  can  preserve  the  pairwise 
distances well. We will describe more comparison in section 4.1.7. 

 
 

 

2 

affects  the  accuracy  of  the  decision  boundaries  computed 
from these regions [4].  

3  T HEORY  AND M ETHOD 

We  wish  to  create  a  mapping  in  which  all  three  types  of 
relationships  in  DM  are  preserved  –  the  relationships  among  the 
samples, among the attributes, and mutually among the samples and 
attributes. Here, the notion of relationship can be a distance, such as 
Euclidian  (across  space)  or  geodesic  (across  a  manifold),  or  a 
similarity, such as Pearson’s correlation [33], cosine, or pattern, or 
it  can  be  some  measure  of  significance,  such  as  value  or  feature. 
We  combine  these functions collectively into a  distance  metric, F, 
and note that, depending on the application, each relationship might 
be  expressed  in  a  different  F.  For  example,  the  similarity  of 
attributes might be measured by correlation, while the proximity of 
samples might be gauged via the Euclidian distance. We wish for a 
mapping that preserves this set of  simultaneous constraints as well 
as  possible.  It  calls  for  an  optimization  strategy  on  a  fused 
representation  of  three  types  of  relationships.  The  pipeline  of  this 
process is shown in Fig.3.  
 
 
 
 
 
 

Fig. 3 The fusion pipeline 

Mapping 

Distance 

Fusion 

Data 

 
 
In the following we outline the various steps of this pipeline in 
detail. The underlying primitive is a distance matrix, one for each of 
the three pairs, encoding the respective  F. The fusion process then 
merges 
into  a  single  distance  matrix 
emphasizing  certain  constituents  or  equalizing  them.  This  is 
followed  by  a  mapping  to  2D  using  an  optimization  process.  We 
use  an  MDS-type  strategy  because  it  is  well  tested  for  such 
mapping problems.    

three  matrices 

these 

Data Matrix 

3.1 
We begin with 𝐷𝑀, the data matrix, with 𝑚 rows and 𝑛 columns, 

𝑥11 ⋯ 𝑥1𝑛
⋮
⋮

⋱

] 

𝐷𝑀 = [

𝑥𝑚1 ⋯ 𝑥𝑚𝑛

Here,  the  rows  denote  the  data  samples,  the  columns  denote  the 
variables  and  xij  is  the  data  value  in  the  ith  row  and  jth  column. 
Without loss of generality, we assume 𝐷𝑀 is normalized to [0, 1].  

Depending  on  how  we  look  at  DM,  row-wise  or  column-wise, 
we  have  two  types  of  spaces  –  the  data  space  D  and  the  variable 
space  V,  respectively.  The  data  space  D  contains  all  m  data  items 
(samples): 

𝐷𝑖 = [𝑥𝑖1, 𝑥𝑖2, … , 𝑥𝑖𝑛]             (𝑖 = 1,2, … , 𝑚) 

 
 
 
 
 
 
 
 
 
 
 

(a)

                          (b)                              (c)                   
Fig.2.  Comparing  different  attribute/sample  layout  schemes:      
(a) standard GBC, (b) optimized GBC, and (c) our new method.  

 

2.3 

Embedded displays  

The  ambiguities  in  the  relations  of  the  data  points  are  often 
overcome  by  embedding  the  high-dimensional  space  into  the  2D 
canvas.  Principal  component  analysis  (PCA)  [19]  finds  the  two 
eigenvectors  associated  with  the  largest  variation  in  the  data 
(expressed by the largest positive eigenvalues) and then projects the 
data points into the plane spanned by these vectors. Other methods 
seek  to  create  a  mapping  from  high-dimensional  to  2D  space  that 
optimizes  for  some  measure  of  data  point  similarity.  MDS  [23] 
aims  to  preserve  some  distance  metric,  such  as  Euclidian  distance 
or  pattern  distance  [24].  Other  mappings,  such  as  ISOMAP  [34], 
LLE  [31],  SOM  [6][22],  t-SNE  [28],  LAMP  [18],  and  PLP  [30] 
optimize for geodesic distance, distribution distance, locality, etc.  

In  these  2D  embeddings,  the  viewer  can  easily  appreciate 
neighborhood  relations  and  obtain  a  good  overview  of  the  space 
quickly.  However,  these  methods  also  have  a  shortcoming  –  the 
mapped  data  points  no  longer  maintain  any  context  with  the 
attribute  space  as  this  information  is  typically not  preserved  in  the 
mapping. If users wish to see the relationships of both attributes and 
data  samples  then  two  separate  maps  need  to  be  created  using  the 
two alternative forms of the similarity matrix  S as presented in the 
introduction  –  one  for  the  samples  and  one  for  the  attributes.  But 
with two separately and independently created maps, it is difficult, 
if  not  impossible,  to  appreciate  the  mutual  relationships  of  the 
samples and their attributes – the context. The method we describe 
in this paper fuses the two alternative similarity matrices and so is 
able  to  create  an  embedding  in  which  the  relationships  among 
samples,  among  attributes,  and  among  the  two  of  them  is  equally 
well preserved.  We note that in practice we use a dissimilarity (or 
distance) matrix. Similarity is just the reverse of dissimilarity.   

2.4 

Fused displays 

The  work  on  fused  displays  is  relatively  rare.  One  recent 
implementation is by Broeksema  et  al.  [3] who similar  to us,  have 
also created a fused matrix of samples and attributes and used it for 
2D layouts. Our approach is different from theirs in multiple ways: 

Their  framework  is  primarily  designed  for  categorical  data. 
Numerical  data  are  binned  into  regular  intervals  which  can 
be 
inaccurate.  Conversely,  our  approach  starts  with 
numerical  data  by  default  and  could  use  the  approach  of 
Zhang et al. [37] to transform any categorical variables into 
numerical ones, taking into account the pairwise distribution 
relationships. 
They  use  a  linear  projection  approach  based  on  Multiple 
Correspondence Analysis (MCA) to create the 2D mapping. 
Our layouts are generated via numerical optimization  which 
can  support  a  variety  of  constraints  and  can  also  better 
preserve high-dimensional relationships. 
They compute a tiled Voronoi diagram to divide the domain 
into value regions which only accounts for the relationships 
among 
levels.  Our  approach 
generates  a  set  of  general  iso-contours  computed  from  a 
continuous  heat  map  of  the  data,  using  adaptive  kernel 
density  estimation.  The  extended  accuracy  this  affords  also 

the  attributes  and 

their 

3 

 

 

 

 

n 
V

m 

D
  

.... 

2 

D
  
  

  

V
3
  

D
  

1 
2 
V
  

m 

D
  

V1 
  

.... 

n 
V

2 
V
  

1 
V
  

(a)

                                                (b) 

 
Fig. 4. The two spaces: (a) data space D and (b) variable space V. 
  

3 

D
  

2 

D
  

1 

D
  

and is spanned by the n orthogonal attribute (or variable) axes (see 
Fig,  4a)  Conversely,  the  variable  space  V  contains  all  n  data 
attributes: 

𝑉𝑗 = [𝑥1𝑗, 𝑥2𝑗, … , 𝑥𝑚𝑗]′              (𝑗 = 1,2, … , 𝑛) 

and is spanned by a set of m orthogonal data item axes (Fig. 4b).  

The  data  space  D  is  the  more  familiar  of  the  two  but  there  are 
many  applications,  in  which  samples  can  turn  into  attributes  and 
vice versa depending on the focus of the analytics. For example, for 
a  data  matrix  storing  the  results  of  a  DNA  microarray  experiment 
for  multiple  specimens,  one  research  objective  might  consider  the 
genes  expressed  in  the  microarray  to  be  the  samples  and  the 
specimens to be the attributes, or vice versa.  

VD is not a transpose of DV, like Euclidian or correlation distance, 
we typically select one of DV or VD – using the one with the larger 
matrix  norm  –  and  computing  the  other  by  transposing  it.  In  this 
case, DV and VD become symmetric. 

Assembling the composite distance matrix (CM) 

3.2.2 
With all four constraint matrices in place, we can now assemble the 
composite  distance  matrix  CM  from  them.  The  fused  space 
composed  of  D  and  V  and  the  composite  distance  matrix  CM  are 
shown  in  Fig.  5.  We  can  now  use  it  within  an  MDS-like 
optimization  framework  to  achieve  the  2D  mapping  into  the  joint 
sample/attribute  display.  But  first  we  need 
to  make  some 
adjustments as is described in the following section.   

3.2 

The Composite Distance Matrix (CM) 

The  next  step  is  to  define  the  desired  distance  or  similarity  metric 
for  each  relationship.  Mapping  more  similar  items  into  closer 
proximity, we need to use (1-correlation), and (1-attribute value) etc, 
while the spatial distance metrics, such as Euclidian can be used as 
is. We have four different distance matrices: 

  DD to store the pairwise distance of data items 
 
VV to store the pairwise distance of attributes (variables) 
 
VD to store the pairwise distance of attributes to data items 
  DV to store the pairwise distance of data items to attributes  

DD is an n×n matrix with elements DDij=F(Di, Dj) and VV is a 
m×m  matrix  with  elements  VVij=F(Vi,Vj).  Fig.  6a  and  Fig.  6  b 
shows  an  MDS  layout  of  DD  and  VV  respectively  for  the  6  test 
Gaussians described in Section 2.2.  

The Data to Variables Distance Matrices (DV, VD)  

3.2.1 
The  DV  and  VD  matrices  are  new  types  of  matrices.  They  are 
required to enforce the distance/similarity constraints in the relation 
of the data samples with the attribute (dimension) anchors and vice 
versa. In the following, let us first consider DV – similar arguments 
also hold for VD. 

Referring  to  Fig.  4a  which  shows  the  data  space  D,  one  can 
make  the  argument that  an  attribute axis  is  essentially just  another 
data sample – a (fictional) data point with unit length, n dimensions, 
and  a  single  non-zero  component,  namely  a  value  of  1  for  the 
attribute’s dimension  j. So essentially, the attribute vector serves a 
dual role: (1) as a dimension axis and (2) as a data point. With this 
in  mind  we  can  then  impose  any  distance  metric  that  links  the  m 
data samples with the n attribute axes to fill the m×n matrix DV.    

The  derivation  of  the  matrix  VD  follows  a  similar  line  of 
thought. Just now we consider the variable space V depicted in Fig. 
4b where the axes are m-dimensional unit vectors each with exactly 
one dimension component set to 1. A point in that space is defined 
by the values a certain variable has for all of the data samples – one 
column of DM. For example, for a car dataset, if V1 is horsepower 
(hp)  and  V2  is  miles  per  gallons  (mpg)  and  we  have  two  cars  –  a 
VW  and  a  Ford  –  then  the  coordinates  for  V1  would  be  [hp(VW), 
hp(Ford)]  and  the  coordinates  for  V2  would  be  [mpg(VW), 
mpg(Ford)]. We can again impose any distance metric between the 
n V-points and the m points constituted by the D-vectors to fill the 
n×m matrix VD. 

We note that in order for CM to be a proper distance matrix, VD 
should be  a  transpose  of  DV. This, however, is not  necessarily the 
case,  even  when  normalizing  the  vectors  in  V  and  D  which  would 
place  all  distance  relationships  on  the  surface  of  a  hypersphere.  It 
occurs  because  V  and  D  have  different  dimensionalities  (and 
different  hyperspheres)  and  are  also  not  related  by  a  simple  scale 
factor.  The  only  similarity  metric  we  know  that  fulfils  this  matrix 
identity is (1-value), where ‘value’ is the value a space point SP has 
for  a  space  dimension  vector  SD’s  coordinate.  The  (1-value) 
distance can be thought of as a significance distance. It is small for 
a  given  data  point  when  the  value  of  a  point’s  attribute  is  large, 
encoding a notion of affinity that SP has for SD. We have used this 
distance  for  all  examples  shown  in  this  paper.  For  the  case  when 

 

4 

                   (a)                                                          (b) 

Fig.  5:  (a)  The  fused  space  composed  of  D  and  V  and  (b)  the 
composite distance matrix CM and the extents of its submatrices 
DD, DV, VD, and VV.  

3.3 

Fusion 

In order to merge or fuse the two spaces, V and D, in consideration 
of  the  four  distance  constraint  matrices,  VV,  DD,  DV  and  VD, 
defined on them we require a set of transformations – scale, rotation, 
translation. For the time being we have only implemented scaling.   
     The four matrices  VV, DD, DV and  VD that make up  CM  were 
not  created  equally.  They  have  been  calculated  from  vectors  with 
different lengths – n or m – and they may also have used different 
distance  metrics  F.  We  have  observed  that  this  inequality,  if  not 
compensated  for,  can  lead  to  cases  in  which  data  samples  and 
attributes may not mix well. That is, points due to the data samples 
and those due to the attributes may clump together into separate and 
disjoint communities.   

Thus, transformations are necessary to enlarge or shrink the data 

or variable spaces. Suppose, we have the transformation 𝜃: 

𝐷𝜃 = 𝜃𝐷(𝐷)                          𝑉𝜃 = 𝜃𝑉(𝑉)                        (1) 

where 𝐷𝜃 and 𝑉𝜃 are the transformed D and V, respectively. 

There are different ways to define the 𝜃. In order to mix the data 
and variables spaces well, we should balance the difference of each 
of the four matrices. One simple way to define 𝜃 or achieve this is 
to make the four sub-matrices (the entities in each submatrix) have 
equal  mean.  In  this  way,  the  two  spaces  have  equal  scale.  In 
addition, in order to keep the distance matrixes unite, we make the 
DV and VD also have these equal scales 

̅̅̅̅̅̅̅ = 𝐷𝜃𝑉𝜃
𝐷𝜃𝐷𝜃

̅̅̅̅̅̅̅ = 𝑉𝜃𝐷𝜃

̅̅̅̅̅̅̅ = 𝑉𝜃𝑉𝜃

̅̅̅̅̅̅                        (2) 

where  the  ¯  operator  denotes  the  mean  of  the  distance  matrix.        
There  are  different  options  to  make  these  four  distance  matrices 
have the same mean (or L1 norm) – we can use a linear, polynomial, 
or  kennel  function.  A  linear  function  has  the  advantage  that  it 
preserves the distribution, topology, etc. and thus, for this paper we 
apply  a  linear  weight  adjustment  for  each  submatrix.  In  this  way, 

the transform is a simple weight adjustment for each submatrix. The 
weights are obtained as: 

𝑊𝐷𝐷: 𝑊𝐷𝑉: 𝑊𝑉𝐷: 𝑊𝑉𝑉 =

𝑀𝑚𝑎𝑥
̅̅̅̅̅̅̅̅ :
𝐷𝜃𝐷𝜃

𝑀𝑚𝑎𝑥
̅̅̅̅̅̅̅̅ :
𝐷𝜃𝑉𝜃

𝑀𝑚𝑎𝑥
̅̅̅̅̅̅̅̅ :
𝑉𝜃𝐷𝜃

𝑀𝑚𝑎𝑥
̅̅̅̅̅̅̅̅         (3) 
𝑉𝜃𝑉𝜃

where 𝑊 is the weight for the submatrix and Mmax is the maximum 
mean of all the submatrices.  

3.4  Mapping 

With the composite distance matrix CM in hand, the final step is to 
create the joint map of samples and attribute points. We have opted 
to use an optimization approach for the map layout, as opposed to a 
linear  projection  with  PCA  or  biplots  since  it  gives  us  more 
freedom  in  choosing  the  constraints  governing  the  layout,  such  as 
mixed  distance  functions,  layout  schedules,  and  mapping  criteria. 
There are a number of distance-preserving optimization algorithms 
applicable for our purposes. LLE produces locally optimal layouts, 
while  MDS-type  schemes  create  globally  optimal  layouts  which 
have  become  more  popular  in  recent  years  since  they  provide  a 
consistent  overview  of 
linear 
discriminant  analysis  (LDA)  [9]  excel  in  their  ability  to  isolate 
individual  clusters,  but  they  have  a  reduced  ability  to  preserve  the 
statistical appearance of the clusters which we feel is important for 
visualization.  We  have  therefore  chosen  a  metric  MDS  approach. 
Particularly  useful  here  is  the  iterative  and  progressive  point 
insertion  schedule  of  Glimmer  MDS  [16].  We  have  adopted  this 
multi-level  scheme  for  our  framework  since  it  allows  us  to 
implement a variety of strategies for controlling the layout.    

the  data.  Finally, 

t-SNE  or 

One  of  these  strategies  makes  use  of  the  weighting  scheme  for 
handling  the  submatrices  of  CM,  as  proposed  in  the  previous 
section.  It  results  in  a  rather  general  framework  and  offers  much 
freedom to design a visualization that fits current criteria of interest. 
Users  can  simply  assign  the  default  weights  that  give  equal 
emphasis to all submatrices or they can increase the weight for one 
of more submatrices that influence those aspects they would like to 
focus  on.  For  example,  a  user  might  want  to  have  an  accurate 
representation  of  the  relationships  among  the  samples  and  of  the 
samples  to  the  variables  but  is  less  interested  in  an  accurate 
representation  of  the  relationships  the  attributes  have  with  one 
another.  So  he/she  would  increase  WDD,  WDV  and  at  the  same 
amount  WVD,  but  reduce  WVV.  Reducing  one  or  more  constraints 
will  enable  the  mapping  algorithm  to  trade  the  precision  losses 
incurred  for  these  unimportant  relations  in  favor  of  those  that  are 
less desirable. Essentially, it serves as a buffer of the errors that are 
incurred  with  the  necessarily  imperfect  space  embedding.  Section 
4.1.1 describes another mechanism by which users can express their 
emphases  –  the  scheduling  of  the  data/variable  primitives  in  the 
MDS-like layout.   

(a)
  

(b)
  

(c)
  

(d)
  

(d)
  

Fig. 6: Layout experiment for the 6  Gaussian test dataset. (a) MDS 
layout  of  the  data  samples  (Euclidian  distance);  (b)  MDS  layout  of 
the  attributes  (correlation  distance);  (c)  parallel  coordinate  display 
with node colors marked; (d) MDS layout of samples and attributes 
using the CM matrix (samples: Euclidian, attributes: correlation).    

 

5 

3.5 

A First Example 

Fig.  6  shows  a  first  result  achieved  with  this  mapping  using  the  6 
test Gaussians introduced in Section 2.2. Fig. 6a is the MDS layout 
for  just  the  data  samples  using  the  Euclidian  distance  metric;  Fig. 
6b  is  a  MDS  layout  for  the  attributes  using  Pearson’s  correlation 
distance  [33];  Fig.  6c  is  the  layout  created  with  MDS  using  the 
entire  CM matrix and  weights set to  not give  emphasis to  any  CM 
submatrix,  and  Fig.  6d  is  the  parallel  coordinate  display  for  this 
dataset  with  the  axes  marked  with  the  colors  used  for the  attribute 
nodes in  Fig. 6b and c. We  used the (1-value) distance for the  DV 
and VD submatrices.   

We  first  observe  that  the  layout  of  the  clusters  in  the  sample-
only  MDS  plots  has  been  well  preserved  in  the  CM-based  MDS 
layout. On the other hand, the locations of the attributes, while still 
largely  isolated  to  account  for  the  correlation  differences,  have 
changed  and  better  match  the  associations  they have  with  the  data 
clusters. This shows that the fusion of the two spaces D and V is not 
just a trivial superposition of the two plots.  

Some  more  specific  observations  we  make  are:  (1)  the  red 
cluster  has  a  clear  dominance  in  the  red  attribute  and  indeed  its 
dimension node gets mapped right into the red cluster’s center, (2) 
the green and the brown cluster both have high values in the green 
attribute  and  so  the  green  attribute’s  node  gets  mapped  between 
these two clusters, (3) similar is true for the brown attribute and the 
red  and  brown  data  clusters;  (4)  the  dark  blue  and  black  attributes 
have somewhat similar (but switched) relationships with respect to 
high  values  of  the  black  and  dark  blue  clusters  and  so  they  get 
mapped more closely to each other right between these two clusters.  
On closer inspection of Fig. 6 it appears that lower levels in the 
attributes are being taken into lesser or no account in CM’s layout. 
This  can  be  explained  by  the  distance  metrics  we  chose  for  this 
particular case. The preference of the algorithm in picking attribute 
locations  with  respect  to  high  values  of  the  data  clusters  is  due  to 
the (1-value) distance we selected for the DV and VD submatrices. 
The  behavior  would  change  had  we  chosen  a  different  distance. 
This  and  other  choices,  as  well  as  their  effects,  largely  depend  on 
the aspects in the data the analyst would like to emphasize. Here in 
this example the emphasis was on extreme values.  

4  CONSTRUCTI NG  THE D AT A C ONTEXT M AP (DCM) 

In this section we provide more details on the map construction and 
its segmentation into regions of similar properties.  

 Populating the map 

4.1.1 
The submatrices of CM can not only be weighted differently during 
the  MDS  layout,  we  can  also impose  different  MDS  schedules  for 
the  samples  and  the  attribute  points.  We  take  advantage  of  this 
concept to achieve layouts with different priorities.  

We  require  an  iterative  MDS  algorithm  to  achieve  this  goal. 
Iterative  MDS  algorithms  often  do  not  update  all  points 
simultaneously  at  each  step.  Rather,  they  select  a  subset  of  points 
that is allowed to move, while another stays put, either indefinitely 
after an initial layout or the point sets alternate. The point sets can 
also  be  transient  and  can  change  over  time.  A  particularly 
convenient algorithm in this regards is the Glimmer MDS (G-MDS) 
algorithm [16]. It has a stochastic force algorithm which iteratively 
moves  each  point  until  a  stable  state  is  reached.  The  forces  acting 
on a  point are based on a  Near Set of points and a  Random  Set of 
points.  The  Near  Set  contains  those  points  that  are  nearest  to  the 
point  being  updated.  The  Random  Set  contains  points  that  are 
randomly  chosen  from  the  set  of  available  points.  It  ensures  some 
global  control  in  the  update  process.  We  have  altered  the  standard 
Glimmer MDS framework in two ways. First, we manipulate which 
types of points – variables or data – are allowed to be chosen for the 
Random  Set.  Second,  we  manipulate  which  types  of  points  are 
allowed to be updated. Both change the local minimum of G-MDS 
as it is a metric MDS scheme using non-convex optimization. 

First use case for the car dataset 

4.1.2 
We  use  the  UCI  Auto  MPG  dataset  for  our  first  non-toy  example. 
This  dataset    has  392  cars  built  1983  or  older  with  7  attributes  – 
MPG,  #cylinders  (CYL),  horsepower,  weight,  acceleration,  year, 
and origin (US, Japan, Europe). Note that acceleration is the time a 
car requires to reach 60 mph and so slower cars have higher values. 
Fig. 8 shows a data context map generated via M-MDS. In this map, 
the  large  red  points  represent  the  attributes  while  the  small  blue 
points represent the cars. Cars that locate close to a given attribute 
node have high values for this attribute. On the other hand, cars that 
locate far away from a certain attribute node have a low value for it.  

Using  this  flexible  update  scheme  we  currently  provide  four 
MDS  schedules:  (1)  Update  the  variables  and  the  data  points 
simultaneously (M-MDS); (2) Map the variables first, then fix them 
and  only  map  the  data  (VF-MDS);  (3)  Map  the  data  first,  then  fix 
them,  and  only  map  the  variables  (DF-MDS);  (4)  the  user  defined 
order (U-MDS). We describe each of these in turn in more detail.  

(a) Update all types of points simultaneously (M-MDS) 

This  first  schedule  is  the  most  general.  It  only  runs  G-MDS  once 
and both types of points can be in the Random Set. See Fig. 7a. 

(b) Update variables first, then the data (VF-MDS) 

Here  the  goal  is  to  achieve  a  layout  that  prioritizes  the  fidelity  of 
the variable-variable (V-V) distances. It runs G-MDS two times. In 
the first run only the V-points are entered into the G-MDS point set. 
This  results  in  an  accurate  V-layout.  Then  we  run  G-MDS  the 
second  time  with  the  V-points  frozen.  Essentially,  we  add  a 
statement  that  disallows  the  selection  of  a  V-point  for  update,  that 
is,  only the  data  points  (D-points)  are  allowed  to  move.  Since  this 
has the tendency to drive the D-points away from the V-points we 
only  allow  V-points  in  the  Random  Set.  This  preserves  the 
influence the V-points have on the layout of the D-points. See Fig. 
7b. 

(c) Update data first, then the variables (DF-MDS) 

This  is  essentially  the  reverse  of  the  VF-MDS  scheduling  scheme 
and  prioritizes  the  fidelity  of  the  data-data  (D-D)  distances.  This 
schedule  also  has  two  stages.  First  G-MDS  is  run  in  the  D-points 
only. Next, G-MDS is run on the V-points with the D-points frozen 
and the D-points are only allowed in the Random Set. See Fig. 7c.  

(d) User-defined iteration schedule (U-MDS) 

Fig.8. The data context map for the car data.   

The  three  schemes  just  presented  are  very  basic  update  schedules 
and maybe there are better ones. For this purpose we allow users to 
draw a customized schedule via a timing (iteration) diagram editor. 
It first runs the VF-MDS schedule for a few iterations, then the DF-
MDS schedule, and finally the M-MDS schedule. See Fig. 7d. 

(e) Comparing the schedules 

Comparing  the  layouts  achieved  with  the  different  schedules  we 
observe  that  for  VF-MDS  the  variable  to  variable  error  is  lowest 
and for the DF-MDS the data to data error is lowest. It also appears 
that M-MDS and U-MDS are good compromises. It depends on the 
user’s priorities which method to choose. Considering the accuracy 
and  complexity,  we  normally  choose  the  first  schedule,  but  the 
others are also useful for different preferences.  

We  observe  that  there  are  two  main  populations  of  correlated 
attributes. On one side there are horsepower, weight, and CYL, and 
on  the  other  there  are  acceleration,  mpg,  and  year.  Origin  is 
somewhat  separate.  We  can  also  observe  four  distinct  clusters  of 
cars (with some sub-clusters) which are all heavily elongated in the 
vertical direction. Their relation with the attributes reveals that each 
cluster  has  a  fairly  large  diversity  in  car  attributes.  Using  the 
attribute  nodes  as  landmarks  we  can  now  gauge  the  types  of  cars 
these  clusters  contain.  For  example,  the  cluster  in  the  lower  left 
contains the large high-performance cars with high horsepower and 
weight. The other clusters are more difficult to judge since they are 
so elongated and span a large attribute interval.   

 The map can be readily used for informed selection tasks. The 
user would simply look for features he is most interested in (or not 
at  all),  observe how  many cars are  actually available that  have the 
desired  feature  constellation,  and  then  select  cars  near  these 
attributes (or far away depending on preference). For example, the 
user  may  be  interested  in  a  full-sized  car,  clicks  on  a  node  in  that 
region on the map, and uncovers a 1975 Pontiac Catalina which is 
an  entry-level  full-size  car  (red-circled  sample  node  in  bottom 
cluster).  Or  he  may  be  interested  in  a  newer  economic  car  and  so 
selects a node close to the year attribute and fairly close to the mph 
and  acceleration  attribute.  He  correctly  finds  a  newer  (for  the 
dataset) 1982 Chevy Cavalier which is an economy-grade compact 
car (red-circled sample node in top left cluster).   

(a)                                         

(c)                                         

(b)                                         

Error evaluation   

4.1.3 
Since  our  data  context  map  is  a  2D  optimized  layout,  there  is 
necessarily an error. As in every layout scheme we can estimate the 
error  by  comparing  the  distance  in  the  matrix  CM  with  the 
corresponding Euclidian distances in the 2D layout. We can use 𝐷𝐷̃ , 
𝐷𝑉̃ , 𝑉𝐷̃  and 𝑉𝑉̃  to  store  the  2D  layout  distances,  respectively.  A 
popular  metric  to  summarize  the  layout  error  is  stress  [23].  The 
error E in each sub-matrix is:  

(d)                                         

Fig.7.  MDS  layout  schedules.  (a)  M-MDS  layout.  (b)  VF-
MDS. (c) DF-MDS (d) U-MDS. 

                   𝐸𝐼𝐽 = √

∑

(𝑖∈𝐼,𝑗∈𝐽)

(𝐼𝐽𝑖𝑗−𝐼𝐽̃ 𝑖𝑗)2

∑

(𝑖∈𝐼,𝑗∈𝐽)

2
𝐼𝐽𝑖𝑗

      𝐼, 𝐽 ∈ {𝐷, 𝑉}           (4) 

 

6 

The overall error EA is also weighted based on different blocks, 

                                          𝐸𝐴 = ∑

𝐼,𝐽∈{𝐷,𝑉}

𝛽𝐼𝐽𝐸𝐼𝐽

                              (5) 

where βIJ is the weight. Typically, we set the βIJ to: 

𝛽𝐷𝐷: (𝛽𝐷𝑉 + 𝛽𝑉𝐷): 𝛽𝑉𝑉 = 1: 2: 4                    (6) 

As  mentioned  in  Section  2.2,  we  have  used  the  GBC  plot  as  the 
standard formulation to describe the set of interior displays, and we 
also presented an optimized plot to improve the GBC plot error [7], 
called DIFGBC. In this section we compare this error with the one 
we can now reach with the data context map (DCM).Table 1 below 
compares the error for three datasets we studied.  

We find that EVV improves greatly – this is because the interior 
layouts map the variables to the 1-dimensional space (the boundary 
of  the  enclosing  shape)  but  the  DCM  maps  them  into  2-
dimensional space which naturally incurs less error. The EDD error 
also  greatly  improved,  but  the  EDV  error  did  not  or  even  grew 
slightly for these examples, but this is also dependent on the update 
schedule,  the  distance  metric,  and  the  weighting.  Yet,  the  overall 
error  improved  greatly  and  this  quantitatively  shows  our  data 
context  map  is  more  accurate  than  the  competing  interior  layouts 
even when optimized. 

Table 1. Comparing the error of the optimized GBC plot and the DCM 

DataSet 

Car 

University 

Campaign 

DCM 

DIFGBC 

DCM 

Layout 
DIFGBC 

𝐸𝑉𝑉 
0.34 
0.16 
2.07 
0.38 

𝐸𝐴 
0.3 
0.19 
1.35 
0.39 
DIFGBC  0.33  0.26  0.31  0.31 
0.16  0.23 

𝐸𝐷𝐷 
0.23 
0.17 
0.49 
0.36 

𝐸𝐷𝑉 
0.25 
0.27 
0.32 
0.41 

DCM 

0.22 

0.3 

Up% 

36.7% 

71.1% 

25.8% 

4.2 

Segmenting the Map 

The  data  context  map  as  presented  so  far  already  allows  attribute-
informed  selection  of  data  objects,  as  we  have  demonstrated  in 
Section  4.1.6.  But  it  was  somewhat  difficult  to  judge  the  different 
value regions for combinations of attributes. This would be easy if 
the map could be somehow colored into distinct spatial areas which 
then  could  each  be  tagged  by  the  respective  attribute  value 
combinations.  To  achieve  this  goal  we  require  a  continuous 
representation  of  the  map.  We  have  used  adaptive  kernel  density 
estimation (AKDE) for this purpose.   

 Adaptive Kernel Density Estimation (AKDE) 

4.2.1 
The  AKDE  [21]  is  a  method  for  estimating  the  density  of  a  point 
cloud.  It  first  estimates  the  local  density  of  each  sample  and  then 
shrinks  or  enlarges  the  sample’s  bandwidth.  Suppose  we  have  N 
points and each point is marked as Pi with a fixed bandwidth H. For 
any point P, its local density f is obtained by: 

𝑓(𝑃) =

1

𝑁

∑ 𝐾𝐻(‖𝑃 − 𝑃𝑖‖)

𝑁
𝑖=1

                    (7) 

density estimation (KDE) (Fig. 9a) with AKDE (Fig. 9b) for the car 
dataset. In this figure the brighter values correspond to lower values 
and vice versa. Consider the regions pointed to by the yellow arrow 
where we can see two separate regions for the AKDE, while these 

  

  

(a)                                         
a)                                         

(b)                                         
b)                                         

Fig.9.The KDE (a) and AKDE (b) show the density of the data points 
respectively.    

regions  appear  mixed  together  for  the  KDE.  There  are  also  other 
examples in the map where AKDE gives a more accurate estimate 
of the local density.  

Creating the attribute distance field using AKDE 

4.2.2 
We  estimate  the  values  in  the  continuous  map  based  on  adaptive 
kernels – when the point has a higher density, it would have lower 
bandwidth to shrink its effect area, and vice versa. Then, based on 
the  adaptive  kernel  distance,  we  use  Nadaraya-Watson  kernel 
regression [27][35] to obtain the estimated value. Suppose the value 
at Pi is xi, then the value x at the estimated point P is 

𝑥 = ∑

N
i=1

KH(‖P−Pi‖)∙xi
N
∑
KH(‖P−Pj‖)
j=1

                           (9) 

where  KH  is  the  kennel  function.  Here  we  choose  Gaussian 
function. However, some areas on the 2D canvas are far away from 
the  samples  and  are  therefore  undefined.  Thus  it  is  important  to 
control  the  border  of  the  map  and  remove  these  undefined  areas. 
We set the threshold ε for the sum distance – if the estimated point 
is far away from all the samples, we ignore it. 

∑

𝑁
𝑗=1

𝐾𝐻(‖𝑃 − 𝑃𝑗‖) ≥ 𝜖

                          (10) 

Fig.  10  shows  how  we  convert  the  point  map  into  a  distance 
heatmap using AKDE. Here we first color the data points based on 
their  values  (here,  of  the  horsepower  attribute,  Fig.  10a)  and  then 
generate  the  heatmap  based  on  AKDE-based  interpolation  (Fig. 
10b). We can  see  that the  AKDE can estimate the  values well and 
the border of this heatmap is also well defined.  

where  ||.||  is  the  L2  distance.  We  can  then  estimate  the  local 
smoothing  parameter  𝜆𝑖  and  from  it,  the  new  bandwidth  Hi  for 
adaptive smoothing:  

λi = (G/f(Pi))2                𝐻𝑖 = 𝐻 × 𝜆𝑖              (8) 

 

 

where G is the geometric mean of all the samples local density.  

The  adaptive  bandwidth  of  the  AKDE  kernels  makes  sure  that 
small dense regions are preserved and not over-smoothed while less 
dense  regions  are  properly  fused.  Fig.  9  compares  fixed  kernel 

Hpower 

Hpower 

(a)                                         
a)                                         

Fig.10. The samples’ (a) “Horsepower” values  and (b) its heatmap.  

(b)                                         
b)                                         

 

7 

Creating the contour fields 

4.2.3 
Just by using the distance heatmap alone it is difficult to make out 
actual  values.  A  common  technique  to  visualize  distance  fields  is 
via topographic maps. Then if a point is within a certain pair of iso-
contours  we  can  easily  read  off  its  value.  We  generate  these 
contours  via  the  conrec  algorithm  [1].  Fig.  11a  shows  the  contour 
field of Fig. 10a, for the horsepower attribute. We observe that the 
contour  region’s  value  decreases  level  by  level  as  we  move  away 
from the attribute node.   

 The contour field can also compare the  layouts generated  with 
standard  MDS  and  our  DCM.  Fig.  11b  shows  the  contour  field 
generated from a distance heatmap based on a standard MDS layout 
(also  using  Glimmer  MDS  but  without  using  attribute  points).  We 
find that the contour field has a rather ragged appearance with many 
more  islands  than  the  one  generated  from  the  DCM.  In  the  data 
context  map,  on  the  other  hand,  the  attribute  nodes  attract  high-
valued  points  and  push  low-valued  points  away.  This  magnetic 
force  organizes  the  samples  and  so  a  smooth  distance  field  can  be 
created.       

 

 

(a)                                         (b)                                         

Fig.11. The data context map contour (a) and MDS plot contour (b). 

Hpower 

Hpower 

  

  

  

MPG 

  

(a)                                         

(b)                                         

MPG 

  

Origin 

(c)                                         
 

 

(d)                                         

MPG 

Origin 

Creating the decision regions 

4.2.4 
Each attribute gives rise to a set of contours, and a closed range of 
attribute  values  gives  rise  to  a  filled  region  between  the  two 
corresponding  contours.  Fig.  12a  shows  such  a  region  for  the 
horsepower  range  (120~230).  We  emphasize  that  this  region  has 
been  computed  from  the  value  field  generated  by  the  actual  data 
samples  and  so  any  sample  selection  that  is  based  on  it  will  be 
accurate. As such any of the cars that get mapped into the salmon-
colored region in Fig. 12a indeed has a horsepower value in it.  

Fig.  12b  shows  the  iso-region  for  the  (15-46)  mpg  value  range 
which  we  can  obtain  in  a  similar  fashion.  This  purple  region 
contains all cars that have a mpg rating in that range. Next we can 
superimpose these regions to create the joint map shown in Fig. 12c. 
This  joint  map  has  three  regions.  The  first  is  due  to  the  original 
horsepower range only, the second is due to the original mpg range, 
and  the  third,  overlapping  region  blending  into  a  darker  salmon 
color, contains cars that fit both value ranges. So if we wanted a car 
that fits both criteria we would pick a car from this overlap region.  
Finally,  we  add  a  third  constraint  –  origin.  Origin  is  a  discrete 
variable and we select the value 2  – the European cars. This gives 
rise  to  the  green  region  in  Fig.  12d.  Blending  it  with  the 
horsepower-mpg  joint  map  creates  the  triple-attribute  joint  map 
shown in Fig. 12e. Now if we wanted to buy a car that is European 
and fits the other two range constraints we would look into the olive 
green  region  on  the  lower  right.  There  are  still  some  choices.  We 
could pick a car on the upper boundary of that region which would 
be a more efficient car but with less horsepower. There is a car that 
fits the bill, which has been circled in the figure. Alternatively, we 
could  pick  a  car  from  the  left  region  boundary  which  would  be  a 
less efficient car but with a bit more muscle. There is also a car that 
fits  this  preference.  However,  if  we  sought  to  find  a  car  that 
represents  a  compromise  of  mpg  and  horsepower  –  one  that  falls 
right into center of the region – we learn from the map that there is 
no  such  car  in  the  database.  There  are  obviously  many  more 

 

8 

Hpower 

(e)                                         

Fig.12.  The  decision  of  (a)  “Hpower”  (120~230),  (b)  “MPG”  (15~46) 
and (d) “Origin” (“European”) and (c) (e) their merge process. 

explorations we can do with this map in hand. Since the interface is 
fully  interactive,  the  user  is  free  to  modify  his  preferences  in  real 
time and fit the map to these preferences.  

Creating a fully segmented and self-labeled map 

4.2.5 
Now suppose we have k attributes and each attribute can be divided 
into lk levels based on users’ preference. For example, these levels 
can be high level, middle level, low level etc. Then we can encode 
the  entire  area  and  see  the  combination  of  these  attributes.  Each 
region  can  then  be  encoded as [𝑅1, 𝑅2, … , 𝑅𝑘],  where  Ri  represents 
the level in the each factor i and 𝑅𝑖 ∈ [0, … , 𝑙𝑖]. We can divide the 
domain based on these codes and color the regions. However, it is 
important to maintain the color connection such that users can read 
the  combination  of  different  colors.  We  first  assign  the  color  for 
each attribute and let distances between colors are as big as possible. 
We set the intensity of each color based on the contour range level. 
Finally, when a region is composited we blend these colors. 
      Fig.13 shows an example for three attributes horsepower, mpg, 
and origin. We choose two levels - low or high (we set 40% as the 
threshold).  For  origin  we  split  the  set  between  Euro-Japanese  cars 
and  US  cars.  We  give  each  attribute  the  color  shown  inside  the 
attributes’  symbols  and  then  color  the  entire  domain  via  color 
blending.  We  can  now  color  each  of  the  regions  depending  on 
levels  of  the  participating  attributes.  The  legend  below  the  figure 
lists  a  human-created  annotation  for  the  regions.  However,  such  a 
labelling  could  also  be  done  automatically,  using  the  levels  of  the 
attributes in each region to support natural language generation.   

2 
 

3 
  

4 
  

5 
  

1 
 

6 
  

Euro-Japanese efficient compact cars 

  US efficient compact cars 
   US semi-efficient medium-power cars 
   US big block gas guzzlers 
  Euro-Japanese gas guzzlers 
   Euro-Japanese semi-efficient medium-power cars 

Fig.13.  The  fully  segmented  and  self-labeled  map  based  on 
“Horsepower”, “MPG” and “Origin”. 

5  C ASE STUDI ES 

5.1 

Selecting a College 

Let us now return to the scenario we mentioned in the introduction 
– selecting a college. Our database has 46 universities distinguished 
by 14 attributes of interest: academics, athletics, housing,  location, 
nightlife,  safety,  transportation,  weather,  score,  tuition,  dining, 
PhD/faculty,  population,  and  income.  Now  suppose  there  is  a 
prospective student, Tom, who is looking for a university. He aims 
for  a  school  that  has  high  athletics  (>9),  high  academics  (>9),  but 
low  tuition  (<$18,000).  He  searches  the  universities  with  a 
traditional browser, but sadly he cannot find one which can meet all 
three  requirements  at  the  same  time.  He  knows  that  he  needs  to 
make a compromise, trading  off a  few factors, and find  the  school 
that  offers  the  right  balance.  This,  however,  he  finds  hard  to  do 
because  he  does  not  even  know  what  his  personal  good  balance 
really is. He wants to see “what’s out there” and get inspired. So he 
calls  up  the  data  context  map  to  immersive  himself  into  the 
landscape of schools to find the elusive balance.  

He  begins  by  generating  the  decision  boundaries  based  on  his 
three criteria. This is shown in the teaser image, Fig.1a-d. Then he 
merges them and gets Fig. 1e. He (once more) recognizes that there 
is no university that can satisfy all three criteria at the same time – 
for example, the green tuition region does not overlap with the two 
other regions simultaneously. But now he sees in one view what his 
options  are.  He  notices  a  few  schools  that  meet  two  of  his 
conditions – those schools that fall into two-layer overlap areas. He 
picks  a  few  that  are  closest  to  the  third  layer  at  “just  the  right 
distance” as he describes it – the schools labelled A, B, and C in Fig. 
1e  He  says  that  he  likes  A  “because  it  has  good  athletics  and  low 
tuition, while the academics is not stellar but alright”. Similarly, B 
is good and he’d be “OK with paying a bit more tuition for the great 
value.” Finally, school C has good academics and low tuition which 
is great because he “could just use the savings to buy a big screen 
TV to watch the games of other schools”. Nevertheless, he picks A 
and lives happily ever after.   

 

9 

5.2 

Analyzing the business priorities 

Our second case study demonstrates the utility of the fused display 
of  samples  and  attributes.  We  peek  into  an  analysis  session  of  a 
group of top level managers of a multinational company with many 
subsidiaries  in  different  countries.  The  topic  is  to  determine  the 
different  priorities  these  companies  have  when  it  comes  to  sales 
strategy and long term goals. They have 600 samples of sales team 
data  with  10  attributes:  #Leads  (generated),  #Leads  Won  (LW), 
#Opportunities  (generated),  Pipeline  Revenue  (Rev),  Expected 
Return  on  Investment  (EROI),  Actual  Cost  (Cost),  Cost/WonLead 
(Cost/LW), Planned Revenue (Rev), and Planned ROI (PROI). The 
highly  paid  visual analytics  consultant  the  firm  has  hired  pulls  out 
the  data  context  map  and  with  a  few  mouse  clicks  produces  the 
visualization shown in Fig. 14. It is quickly seen that there are three 
clusters, call them red group, blue group, and green group. It turns 
out these three groups have rather different strategies and priorities. 
      The  red  group’s  focus  is  dominated  by  #Opp,  PROI, 
Cost/WL,  where  they  have  high  values  and  achievements.  At  the 
same time, however, they score very low in #Leads, LW, Rev, etc. 
The members of this group tend to focus on the individual leads and 
invest a lot in these, and as a result they have usually a high number 
of  opportunities.  The  blue  group,  in  contrast,  are  possibly  larger 
companies – they have high revenue and they can generate a large 
amount  of  Leads.  The  green  group  is  dominated  by  PRev 
and  %Comp.  Since 
revenue, 
their  %completed is high. But clearly all  groups have one thing in 
common  –  cost.  This  factor  has  equal  distance  for  all  of  them.  It 
means they all care about the cost with similar weights. 

they  have  high  expected 

  

Fig.14. The data context map for the business priority case study. 

6  CONCLUSI ON 

We have described the data context map – a framework and visual 
interface  that  enables  a  comprehensive  layout  of  both  data  points 
and variables. We achieve it by fusing two  distance matrices – the 
data  and  the  attribute  distance  matrix.  We  create  an  optimized 
layout  that  can  be  used  for  in  data-driven  decision  selection  and 
decision problems that require a mindful balancing of trade-offs. 

While  we  provide  several  parameters  for  experts  to  guide  the 
layout  for  their  goals,  they  are  not  essential  to  produce  usable 
results.  Casual  users  can  just  use  the  pre-set  weights,  upload  the 
data,  generate  the  initial  map,  and  interact  with  the  value  sliders. 
Future work will explore how casual users actually do this.  

AC KNOWLEDGEM ENT S 

This research was supported by NSF grant IIS 1117132 and by the 
MSIP (Ministry of Science, ICT and Future Planning), Korea, under 
the  “ICT  Consilience  Creative  Program”  supervised  by  the  IITP 
(Institute for Information & Communications Techn. Promotion)"". 

[29]  M.  Meyer,  A.  Barr,  H.  Lee,  M.  Desbrun,  “Generalized  Barycentric 
Coordinates  on  Irregular  Polygons,”  J.  Graphics  Tools,  7(1):13-22, 
2002. 

[30]  F. Paulovich, C. Silva, L. Nonato, “Two-Phase Mapping for Projecting 
Massive  Data  Sets”,  IEEE  Trans.  Vis.  Comput.  Graph.  16(6):  1281-
1290 (2010) 

[31]  L. Saul  ,  S. Roweis, “An Introduction to Locally Linear Embedding” 

IJPRAI 01/2009; 23:1739-1752. DOI: 10.1142/S0218001409007752. 

[32]  R. Spence, Information Visualization, Addison-Wesley 2000 ISBN: 0-

201-59626-1. 

[33]  B. Tabachnick and L. Fidell, Using Multivariate Statistics, New York: 

Harper & Row, 2001. 

[34]  J.  Tenenbaum,  V.  de  Silva,  J.  C.  Langford,  “A  Global  Geometric 
Framework  for  Nonlinear  Dimensionality  Reduction,”  Science  290,  
2319–2323, 2000. 

[35]  G.Watson. ""Smooth regression analysis"". Sankhyā: The Indian Journal 

of Statistics, Series A 26 (4): 359–372. JSTOR 25049340, 1964. 

[36]  J.  Yi,  R.  Melton,  J.  Stasko,  J.  Jacko,  ""Dust  &  Magnet:  Multivariate 
Information  Visualization  using  a  Magnet  Metaphor,""  Information 
Visualization, 4(4) : 239-256, 2005. 

[37]  Z. Zhang, K. T. McDonnell, E. Zadok, K. Mueller, ""Visual Correlation 
Analysis of Numerical and Categorical Data on the Correlation Map,""  
IEEE  Trans.  on  Visualization  and  Computer  Graphics,  21(2):  289-
303, 2015 

REFERENCES 

[1]  P.  Bourke,  “CONREC:  A  contouring  subroutine,” Byte:  The  Small 

[2] 

Systems Journal 12 (6): 143–150, 1987. 
I.  Borg  and  P.  Groenen  (2005).  Modern  multidimensional  scaling 
theory and applications. 2nd edition. New York: Springer. 

[3]  B.  Broeksema,  A.  Telea,  T.  Baudel,  “Visual  Analysis  of  Multi-
Dimensional  Categorical  Data  Sets,”  Computer  Graphics  Forum, 
32(8): 158-169, 2012. 

[4]  B.  Broeksema,  T.  Baudel,,  A.  Telea,  P.  Crisafulli,  “Decision 
exploration lab: A visual analytics solution for decision management,” 
IEEE Trans. on  Visualization and Computer Graphics, 19(12), 1972-
1981, 2013. 
J.  Chambers,  W.  Cleveland,  P.  Tukey,  Graphical  Methods  for  Data 
Analysis, Duxbury Press, 1983. 

[5] 

[6]  S. Chen, D. Amid, O. Shir, L. Limonad,D.  Boaz, A. Anaby-Tavor, T. 
Schreck,  ""Self-organizing  maps  for  multi-objective  Pareto  frontiers,"" 
Proc. IEEE Pacific Visualization Symposium, pp.153-160, 2013. 

[7]  S.  Cheng,  K.  Mueller,  ""Improving  the  Fidelity  of  Contextual  Data 
Layouts  Using  a  Generalized  Barycentric  Coordinates  Framework,"" 
Proc. Pacific Vis, pp. 295-302, 2015. 
J. Choo, S. Bohn, H. Park. “Two-stage framework for visualization of 
clustered high dimensional data,” Proc. IEEE Visual Analytics Science 
and Technology Conference (VAST), pp. 67-74, 2009. 

[8] 

[9]  R. Duda, P. Hart, and D. Stork. Pattern Classification. Wiley, 2000. 
[10]  K. Gabriel, “The Biplot Graphic Display of Matrices with Application 

to Principal Component Analysis,” Biometrika, 58(3): 453-467, 1997. 

[11]  G. Grinstein, M. Trutschl, U, Cvek, “High-dimensional visualizations,” 

Proc. Visual Data Mining Workshop, KDD, 2001. 

[12]  J.  Hartigan,  ""Printer  graphics  for  clustering,""  Journal  of  Statistical 

Computation and Simulation,4(3):187-213, 1975. 

[13]  P.  Hoffman,  G.  Grinstein,  K.  Marx,  I.  Grosse,    E.  Stanley,  ""DNA 
Visual and Analytic Data Mining"",  Proc. IEEE Visualization, pp. 437-
441,  1997. 

[14]  P.  Hoffman,  G.  Grinstein,  D.  Pinkney,  “Dimensional  anchors:  a 
graphic  primitive  for  multidimensional  multivariate 
information 
visualizations,”  Proc.  Workshop  on  New  Paradigms  in  Information 
Visualization and Manipulation, pp. 9-16, 1999. 

[15]  https://colleges.niche.com/ 
[16]  S. Ingram, T. Munzner, M. Olano, “Glimmer: Multilevel MDS on the 
GPU,”  IEEE  Trans.  Visualization  and  Computer  Graphics,  15(2): 
249–261, 2009. 

[17]  A.  Inselberg,  B.  Dimsdale,  “Parallel  Coordinates:  A  Tool  for 
Visualizing Multi-Dimensional Geometry,” Proc. IEEE Visualization, 
pp. 361-378, 1990. 

[18]  P.  Joia,  D.  Coimbra,  J.  Cuminato,  F.  Paulovich,  L.  Nonato,  “Local 
Affine  Multidimensional  Projection”,  IEEE  Trans.  Vis.  Comput. 
Graph. 17(12): 2563-2571 (2011). 

[19]  I. Jolliffe,  “Principal Component Analysis,” Series: Springer Series in 
Statistics, 2nd ed., Springer, NY, 2002, XXIX, 487  pp.28 illus. ISBN 
978-0-387-95442-4. 

[20]  E.  Kandogan,  “Star  Coordinates:  A  Multi-Dimensional  Visualization 
Technique  with  Uniform  Treatment  of  Dimensions,”  Proc.  IEEE 
Information Visualization, Late Breaking Topics, pp. 9-12, 2000. 

[21]  P.  Kerm,  “Adaptive  Kernel  Density  Estimation,”  The  Stata  Journal, 

2:148–156, 2002. 

[22]  T. Kohonen. Self-Organizing Maps. Springer, 3rd edition, 2001. 
[23]  J.  Kruskal.  M.  Wish,  Multidimensional  Scaling.  Sage  Publications, 

1977. 

[24]  J.  Lee,  K.  McDonnell,  A.  Zelenyuk,  D.  Imre,  K.  Mueller,  ""A 
Structure-Based  Distance  Metric 
for  High-Dimensional  Space 
Exploration  with  Multi-Dimensional  Scaling,""  IEEE  Trans.  on 
Visualization and Computer Graphics, 20(3): 351-364, 2014. 

[25]  G.  McLachlan.  Discriminant  Analysis  and  Statistical  Pattern 

Recognition, John Wiley & Sons, Aug 4, 2004. 

[26]  J.  Nam,  K.  Mueller,  ""TripAdvisorN-D:  A  Tourism-Inspired  High-
Dimensional  Space  Exploration  Framework  with  Overview  and 
IEEE  Trans.  Visualization  and  Computer  Graphics, 
Detail,"" 
19(2):291-305, 2013. 

[27]  A. Nadaraya, ""On Estimating Regression"".  Theory of Probability and 

its Applications 9 (1): 141–2. doi:10.1137/1109020, 1964. 

[28]  L.  van  der  Maaten,  G.  Hinton,  “Visualizing  data  using  t-SNE,” 

Journal of Machine Learning Research, 9:2579–2605, 2008. 

 

10 

","{""pos"":{""0"":1,""1"":2,""2"":3,""3"":4,""4"":5},""3"":{""0"":""layout"",""1"":""visualization*"",""2"":""mapping*"",""3"":""visual*"",""4"":""graphics""},""2"":{""0"":""mds*"",""1"":""ieee*"",""2"":""vd"",""3"":""dv"",""4"":""akde""},""4"":{""0"":""distance*"",""1"":""point*"",""2"":""range*"",""3"":""away*"",""4"":""field*""},""5"":{""0"":""car"",""1"":""cars*"",""2"":""mpg*"",""3"":""horsepower*"",""4"":""schools""},""1"":{""0"":""fig"",""1"":""v"",""2"":""0"",""3"":""n*"",""4"":""2d""},""0"":{""0"":""matrix*"",""1"":""matrices*"",""2"":""dcm*"",""3"":""pairwise*"",""4"":""composite*""}}",2016,{},False,False,journalArticle,False,H4Y2RXSJ,[],self.user,"{""Unnamed: 0"":{""0"":0,""1"":1,""2"":2,""3"":3,""4"":4,""5"":5,""6"":6,""7"":7,""8"":8,""9"":9,""10"":10,""11"":11,""12"":12,""13"":13,""14"":14,""15"":15,""16"":16,""17"":17,""18"":18,""19"":19,""20"":20,""21"":21,""22"":22,""23"":23,""24"":24,""25"":25,""26"":26,""27"":27,""28"":28,""29"":29,""30"":30,""31"":31,""32"":32,""33"":33,""34"":34,""35"":35,""36"":36,""37"":37,""38"":38,""39"":39,""40"":40,""41"":41,""42"":42,""43"":43,""44"":44,""45"":45,""46"":46,""47"":47,""48"":48,""49"":49,""50"":50,""51"":51,""52"":52,""53"":53,""54"":54,""55"":55,""56"":56,""57"":57,""58"":58,""59"":59,""60"":60,""61"":61,""62"":62,""63"":63,""64"":64,""65"":65,""66"":66,""67"":67,""68"":68,""69"":69,""70"":70,""71"":71,""72"":72,""73"":73,""74"":74,""75"":75,""76"":76,""77"":77,""78"":78,""79"":79,""80"":80,""81"":81,""82"":82,""83"":83,""84"":84,""85"":85,""86"":86,""87"":87,""88"":88,""89"":89,""90"":90,""91"":91,""92"":92},""C"":{""0"":5.8741546432,""1"":14.6110636064,""2"":17.6588490069,""3"":7.5145787287,""4"":6.2435811282,""5"":8.8678578362,""6"":10.1444495492,""7"":8.6134939415,""8"":9.5412730584,""9"":7.9765684572,""10"":9.5195979002,""11"":13.3513080204,""12"":9.1027859534,""13"":12.0811122222,""14"":13.1044001916,""15"":10.2189861074,""16"":16.6386376397,""17"":6.2260541622,""18"":8.0691683287,""19"":9.6247855275,""20"":13.9530091149,""21"":12.3799955491,""22"":8.6248427647,""23"":6.7970356486,""24"":5.9436553951,""25"":9.2469905511,""26"":15.2601005503,""27"":18.0763330445,""28"":12.9713854353,""29"":7.1299054059,""30"":24.8018737306,""31"":16.8392453239,""32"":6.0459894517,""33"":7.3772191081,""34"":12.05157654,""35"":8.3400131145,""36"":10.4106720576,""37"":7.5600891728,""38"":19.2207377899,""39"":7.9212927293,""40"":6.1349350497,""41"":6.8001615399,""42"":7.0277945197,""43"":9.9551273494,""44"":8.0919264331,""45"":12.3535408259,""46"":7.88157417,""47"":7.1413644956,""48"":7.5644075733,""49"":6.2056155313,""50"":8.163474676,""51"":13.0804920264,""52"":8.3343998566,""53"":6.5498826638,""54"":7.246523548,""55"":12.2983325756,""56"":13.3383036864,""57"":12.4024539101,""58"":12.3902724242,""59"":6.5583921101,""60"":6.5741964621,""61"":10.3050853226,""62"":11.7025474953,""63"":8.552657401,""64"":8.7693843851,""65"":6.9790883187,""66"":7.5612327254,""67"":8.6500438093,""68"":8.6852253123,""69"":8.8644204934,""70"":8.238315084,""71"":9.6665941419,""72"":8.7168125787,""73"":9.2298849087,""74"":7.1511160225,""75"":6.2483485198,""76"":6.9175902303,""77"":7.0335223872,""78"":6.6673354676,""79"":6.2264406972,""80"":7.4939810632,""81"":8.117037684,""82"":6.0023590175,""83"":5.8611455268,""84"":6.6686278247,""85"":6.3636153784,""86"":6.5833538833,""87"":6.5874043552,""88"":6.2887797123,""89"":5.8293912263,""90"":6.4348352532,""91"":6.4348352532,""92"":6.2965231722},""count"":{""0"":256,""1"":132,""2"":120,""3"":118,""4"":116,""5"":112,""6"":108,""7"":86,""8"":76,""9"":74,""10"":58,""11"":58,""12"":54,""13"":52,""14"":52,""15"":48,""16"":46,""17"":46,""18"":44,""19"":44,""20"":44,""21"":42,""22"":36,""23"":36,""24"":34,""25"":34,""26"":32,""27"":32,""28"":32,""29"":32,""30"":32,""31"":30,""32"":30,""33"":30,""34"":28,""35"":28,""36"":26,""37"":24,""38"":24,""39"":22,""40"":22,""41"":22,""42"":20,""43"":20,""44"":20,""45"":20,""46"":20,""47"":18,""48"":18,""49"":18,""50"":18,""51"":18,""52"":18,""53"":16,""54"":16,""55"":16,""56"":16,""57"":16,""58"":16,""59"":14,""60"":14,""61"":14,""62"":14,""63"":14,""64"":14,""65"":12,""66"":12,""67"":12,""68"":12,""69"":12,""70"":12,""71"":12,""72"":12,""73"":12,""74"":12,""75"":10,""76"":10,""77"":10,""78"":10,""79"":10,""80"":10,""81"":10,""82"":10,""83"":8,""84"":8,""85"":8,""86"":8,""87"":8,""88"":8,""89"":8,""90"":8,""91"":8,""92"":8},""sigma_nor"":{""0"":1.3530009513,""1"":2.2103557018,""2"":2.5309030143,""3"":1.6492624948,""4"":1.5414638445,""5"":1.7868382464,""6"":1.91698628,""7"":1.8594938388,""8"":2.007112509,""9"":1.8485024119,""10"":2.1282088071,""11"":2.5925546239,""12"":2.1103834453,""13"":2.5061895615,""14"":2.6361632435,""15"":2.3122658358,""16"":3.1941203658,""17"":1.8010509051,""18"":2.0664872608,""19"":2.2785165261,""20"":2.86844962,""21"":2.6854337606,""22"":2.2358863717,""23"":1.9653814759,""24"":1.8571605343,""25"":2.3573678707,""26"":3.3215059671,""27"":3.758325573,""28"":2.9665084175,""29"":2.0604493441,""30"":4.8015093435,""31"":3.6303180266,""32"":1.9133794556,""33"":2.125144985,""34"":2.9170859199,""35"":2.3107450501,""36"":2.6936914435,""37"":2.2487097991,""38"":4.2672580939,""39"":2.350181062,""40"":2.0309897402,""41"":2.1498542459,""42"":2.2275354906,""43"":2.7686014157,""44"":2.4242215361,""45"":3.2119059123,""46"":2.3853416244,""47"":2.2897611342,""48"":2.3708412496,""49"":2.1104161975,""50"":2.4856579961,""51"":3.428049812,""52"":2.5184173866,""53"":2.21709927,""54"":2.3559337303,""55"":3.3627152672,""56"":3.5699724512,""57"":3.3834657423,""58"":3.3810380782,""59"":2.2634138515,""60"":2.2666993935,""61"":3.0423080283,""62"":3.332824248,""63"":2.6779985356,""64"":2.7230535685,""65"":2.4036028908,""66"":2.5303056978,""67"":2.7672837037,""68"":2.7749409021,""69"":2.8139424491,""70"":2.6776715996,""71"":2.9885342717,""72"":2.7818158205,""73"":2.8934851996,""74"":2.4410444477,""75"":2.2932906579,""76"":2.446416605,""77"":2.4729424791,""78"":2.3891570276,""79"":2.2882780353,""80"":2.5782977936,""81"":2.7208563546,""82"":2.2370069939,""83"":2.2493397633,""84"":2.4444211037,""85"":2.3707325077,""86"":2.4238195935,""87"":2.4247981555,""88"":2.3526528022,""89"":2.2416681753,""90"":2.3879386664,""91"":2.3879386664,""92"":2.354523561},""vocab_index"":{""0"":0,""1"":1,""2"":2,""3"":3,""4"":4,""5"":6,""6"":9,""7"":11,""8"":12,""9"":13,""10"":20,""11"":21,""12"":25,""13"":26,""14"":27,""15"":28,""16"":31,""17"":32,""18"":35,""19"":36,""20"":37,""21"":38,""22"":40,""23"":43,""24"":44,""25"":46,""26"":47,""27"":48,""28"":49,""29"":50,""30"":51,""31"":54,""32"":55,""33"":56,""34"":58,""35"":59,""36"":69,""37"":74,""38"":77,""39"":79,""40"":82,""41"":83,""42"":88,""43"":94,""44"":96,""45"":97,""46"":98,""47"":100,""48"":101,""49"":109,""50"":115,""51"":116,""52"":117,""53"":130,""54"":134,""55"":136,""56"":137,""57"":138,""58"":139,""59"":160,""60"":166,""61"":167,""62"":168,""63"":169,""64"":170,""65"":195,""66"":197,""67"":199,""68"":200,""69"":206,""70"":207,""71"":208,""72"":209,""73"":210,""74"":211,""75"":237,""76"":250,""77"":261,""78"":262,""79"":264,""80"":265,""81"":266,""82"":267,""83"":280,""84"":327,""85"":334,""86"":336,""87"":337,""88"":338,""89"":340,""90"":343,""91"":344,""92"":345},""word"":{""0"":""data"",""1"":""distance"",""2"":""mds"",""3"":""attributes"",""4"":""map"",""5"":""fig"",""6"":""points"",""7"":""samples"",""8"":""matrix"",""9"":""layout"",""10"":""space"",""11"":""v"",""12"":""point"",""13"":""region"",""14"":""0"",""15"":""visualization"",""16"":""similarity"",""17"":""dimensional"",""18"":""n"",""19"":""mapping"",""20"":""car"",""21"":""cars"",""22"":""relationships"",""23"":""2d"",""24"":""matrices"",""25"":""mpg"",""26"":""ieee"",""27"":""vd"",""28"":""cm"",""29"":""g"",""30"":""error"",""31"":""dv"",""32"":""j"",""33"":""horsepower"",""34"":""schools"",""35"":""displays"",""36"":""p"",""37"":""color"",""38"":""akde"",""39"":""visual"",""40"":""axes"",""41"":""gbc"",""42"":""tuition"",""43"":""schedule"",""44"":""node"",""45"":""update"",""46"":""origin"",""47"":""computer"",""48"":""graphics"",""49"":""dimension"",""50"":""dcm"",""51"":""contour"",""52"":""k"",""53"":""approach"",""54"":""weight"",""55"":""range"",""56"":""group"",""57"":""proc"",""58"":""pp"",""59"":""schedules"",""60"":""away"",""61"":""field"",""62"":""cost"",""63"":""a"",""64"":""trans"",""65"":""pairwise"",""66"":""composite"",""67"":""dd"",""68"":""vv"",""69"":""random"",""70"":""vf"",""71"":""heatmap"",""72"":""hpower"",""73"":""efficient"",""74"":""l"",""75"":""ambiguities"",""76"":""submatrix"",""77"":""allowed"",""78"":""df"",""79"":""estimate"",""80"":""bandwidth"",""81"":""leads"",""82"":""journal"",""83"":""parent"",""84"":""\ud835\udc40\ud835\udc5a\ud835\udc4e\ud835\udc65"",""85"":""run"",""86"":""\ud835\udc3c"",""87"":""\ud835\udc3d"",""88"":""difgbc"",""89"":""pi"",""90"":""euro"",""91"":""japanese"",""92"":""revenue""},""vector"":{""0"":""[ 0.551651    1.2147523   3.8033633   2.5779326  -3.2300067  -3.2720158\n  0.37705028  3.615797   -5.414479   -0.46903798]"",""1"":""[ 0.32292756  0.5901252   4.0935683   2.8870382  -3.3313923  -3.5945964\n -0.51090324  3.6032476  -5.1733665   0.79971755]"",""2"":""[ 0.2993443   2.7205565   3.087281    0.9684598  -3.607759   -2.1544511\n  0.6284438   4.3955603  -4.190858    0.40172657]"",""3"":""[-0.25964433  1.14274     4.0526586   3.1270273  -3.4844046  -3.0927043\n -0.09512698  3.3765116  -5.0505624  -0.06750877]"",""4"":""[ 0.37427598  1.2059427   4.153172    2.744234   -3.5868275  -3.5946136\n -0.31259164  3.7492564  -5.106372   -0.7496913 ]"",""5"":""[ 0.53997064  2.0935602   4.961694    1.5286812  -3.6374168  -2.4468791\n  0.5644388   4.139732   -4.585166    0.02901317]"",""6"":""[ 0.07463925  1.0150511   4.0326176   3.079611   -3.6090786  -3.086521\n -0.35666063  3.3798628  -4.831628    0.26288635]"",""7"":""[-4.2423495e-04  1.5957458e+00  3.9046142e+00  2.3926044e+00\n -3.2010722e+00 -2.9574029e+00  3.1902072e-01  3.8367782e+00\n -5.1657391e+00 -8.9674659e-02]"",""8"":""[ 0.38851503  1.7238864   3.508629    2.0515525  -3.1059897  -2.5302782\n  0.03046854  3.9055488  -4.8583274  -0.55485207]"",""9"":""[ 0.4954321   1.3799114   3.9444227   2.541094   -3.1804307  -3.7959456\n -0.34316638  3.5997972  -5.5147667  -0.41544053]"",""10"":""[ 0.84896976  0.93617505  3.8359745   2.492475   -2.958529   -3.2571309\n -0.26115182  3.5291898  -5.407155   -0.04953843]"",""11"":""[ 0.40378377  2.5690322   4.73579     1.042312   -3.562385   -2.08094\n  0.60036486  4.124658   -4.392621    0.23573658]"",""12"":""[ 0.08696686  0.73378396  4.158221    3.007925   -3.5480049  -3.34225\n -0.40951464  3.5140536  -4.965189    0.5063627 ]"",""13"":""[ 0.19695309  0.9330831   4.3918715   2.7800004  -3.709776   -3.5060816\n -0.04142391  3.892094   -5.016464    0.02811461]"",""14"":""[ 0.41479602  2.2980628   5.1615887   1.1907067  -3.322805   -2.0778682\n  0.37964526  3.980199   -4.7344937   0.12750736]"",""15"":""[ 0.5789568   1.5171705   3.8410413   2.4250243  -3.195288   -3.4499805\n -0.22013254  3.7039614  -5.3358097  -0.86056215]"",""16"":""[-0.2801355   1.1583343   4.107521    3.0495906  -3.4611053  -3.1757607\n -0.09808937  3.6859639  -5.0611672  -0.0828643 ]"",""17"":""[ 0.46200812  1.4278531   3.8653502   2.343908   -3.0850725  -2.787046\n -0.3612666   3.8431995  -4.971362   -0.53272766]"",""18"":""[ 0.3622627   2.3713253   4.8920407   1.2203401  -3.4074523  -2.082028\n  0.38512024  4.069099   -4.5893865   0.04315935]"",""19"":""[ 0.4871105  1.2742772  3.8666315  2.604065  -3.4319708 -3.4490538\n -0.1334614  3.7948685 -5.1662703 -0.8210957]"",""20"":""[ 1.1808767   1.311429    3.7669702   2.0614142  -3.0291104  -3.727353\n  0.38659433  3.4952645  -5.7283072   0.6907672 ]"",""21"":""[ 1.0590056   1.4883286   3.715364    2.0959427  -3.0709054  -3.6943533\n  0.51982176  3.409189   -5.822976    0.44205192]"",""22"":""[ 0.08392125  1.0106401   4.024782    2.8847604  -3.4293244  -3.0971892\n  0.4716253   3.6124938  -5.2620173  -0.030068  ]"",""23"":""[ 0.5463981   2.1814287   4.82156     1.5186894  -3.4116285  -2.482304\n  0.21277122  4.0322127  -4.7052655  -0.21029638]"",""24"":""[ 0.13924669  1.7503848   3.5735552   2.1129203  -3.1753435  -2.4388762\n  0.04048252  3.9827573  -4.749868   -0.36915687]"",""25"":""[ 1.4282198   1.4021492   3.6252742   1.937784   -2.8964076  -3.5376523\n  0.51440686  3.203428   -5.8485856   0.5139517 ]"",""26"":""[ 0.21780476  2.5704594   3.1125243   1.0609498  -3.6134686  -2.1221497\n  0.6229329   4.3936334  -4.2075586   0.3956337 ]"",""27"":""[ 0.31051293  2.82224     3.6770432   0.8437093  -3.624554   -2.0826824\n  0.6507485   4.4080806  -4.16474     0.3336759 ]"",""28"":""[ 0.7967407   2.2105608   4.9143457   1.291379   -3.336168   -2.4542596\n  0.5035234   3.979677   -4.7108006   0.30558833]"",""29"":""[ 0.65958095  2.4146214   4.7031302   0.9585319  -3.3115103  -2.0699587\n  0.5380607   4.2146006  -4.6238494   0.28860477]"",""30"":""[ 0.3692125  0.9161248  3.8807373  2.9122584 -3.2739735 -3.1995738\n  0.3572555  3.4936445 -5.4344497 -0.387294 ]"",""31"":""[ 0.50068474  2.7409368   3.496683    0.82530797 -3.5899029  -2.0322375\n  0.74279124  4.2921534  -4.2531734   0.45636567]"",""32"":""[ 0.318418    2.3977437   4.450238    1.093537   -3.2774873  -1.9113603\n  0.45253292  4.3419695  -4.5866756   0.06519464]"",""33"":""[ 1.3493375   1.1269987   3.6911225   2.1601968  -2.8794568  -3.5057814\n  0.41586027  3.2142026  -5.818978    0.35327795]"",""34"":""[ 0.7633791   1.1960809   3.8963463   2.4174767  -3.2365825  -3.631441\n  0.59631515  3.3244832  -5.769112    0.45818165]"",""35"":""[-0.3274693   1.3175701   4.0166373   2.9810662  -3.4393792  -3.464679\n -0.4215532   3.1284018  -5.1659904   0.08572257]"",""36"":""[ 0.440738    2.1327236   4.85755     1.4236578  -3.5019329  -2.3531842\n  0.47822544  4.122243   -4.62292     0.1335921 ]"",""37"":""[ 0.70327264  1.7876133   4.4693046   2.0355783  -3.2351563  -3.2182393\n -0.13504279  3.8576605  -5.2131047  -0.6111568 ]"",""38"":""[ 0.22709598  2.444517    3.1312807   1.293086   -3.5257647  -2.3248682\n  0.51581043  4.1858644  -4.3709455   0.15219621]"",""39"":""[ 0.3819547   1.6420504   3.8710198   2.3482664  -3.0616753  -3.4124324\n -0.34312132  3.6843824  -5.3708267  -0.56740564]"",""40"":""[ 0.27921668  0.9092564   3.9930193   2.944474   -3.443108   -2.8915997\n -0.38997352  3.584989   -4.8043256   0.14036095]"",""41"":""[ 0.25495967  2.69091     3.0741315   1.060242   -3.504972   -2.3556283\n  0.54224765  4.316121   -4.274906    0.28076786]"",""42"":""[ 0.9755627   0.95143914  3.7779257   2.4287229  -3.015206   -3.6964695\n  0.34866077  3.0435376  -5.9032335   0.5312419 ]"",""43"":""[ 0.55331695  0.90746546  3.9089434   2.67327    -3.1564388  -4.085623\n -0.21169777  3.1456351  -5.804033    0.3656783 ]"",""44"":""[ 0.49729055  1.450949    4.443499    2.0623538  -3.5218046  -2.8040931\n  0.63765866  3.9616623  -4.99972     0.0915411 ]"",""45"":""[ 0.45368463  0.81026334  3.9869258   2.8624408  -3.3080685  -3.937327\n -0.21629028  3.2150736  -5.6347156  -0.01284903]"",""46"":""[ 0.01670596  1.0410745   4.268295    2.9219005  -3.5839896  -3.1100626\n -0.04582664  3.8067825  -4.935203   -0.13115491]"",""47"":""[ 0.87904215  1.3993523   3.8266919   2.238471   -2.9641466  -3.349238\n  0.14038521  3.6115358  -5.5762286  -0.26059067]"",""48"":""[ 0.6968575   1.6434813   4.0068316   2.2216263  -3.038705   -3.426471\n -0.15108001  3.6592224  -5.4748354  -0.5131277 ]"",""49"":""[ 0.43537143  0.8298789   4.0474286   2.7270975  -3.230597   -2.878074\n -0.29578033  3.7474246  -4.9608607   0.10090999]"",""50"":""[ 0.43488994  1.7931792   3.229418    1.9046497  -3.4010756  -2.6341813\n  0.28389463  3.8978903  -4.709506   -0.23622943]"",""51"":""[ 0.5173997   1.3785459   4.1140018   2.5262656  -3.3943756  -3.5589097\n -0.34579402  3.8144195  -5.202307   -0.79732585]"",""52"":""[ 0.39795706  2.3260555   4.7559285   1.1189909  -3.3157203  -1.9767699\n  0.5209402   4.3454485  -4.7042227   0.10196046]"",""53"":""[-0.04332776  0.9138845   4.0996747   2.7792664  -3.478831   -3.5697145\n  0.02284459  3.5912306  -5.260222    0.5134018 ]"",""54"":""[ 0.8519153   0.67562777  4.065532    2.5774634  -3.0747433  -3.4727008\n -0.18833126  3.1971097  -5.525603    0.656844  ]"",""55"":""[ 0.39881825  0.54895586  4.2544475   2.8217146  -3.4075592  -3.5817413\n -0.31087437  3.5812361  -5.2174606   0.6417658 ]"",""56"":""[-2.2175508e-03  1.2006021e+00  4.3306789e+00  2.4043434e+00\n -3.5012589e+00 -3.3336239e+00  1.7565465e-01  3.8484175e+00\n -5.1189508e+00  4.5852211e-01]"",""57"":""[ 0.40304744  2.6128738   3.065273    0.98866093 -3.595104   -2.0237405\n  0.6944728   4.3153167  -4.2229867   0.53159714]"",""58"":""[ 0.5796118   2.2907233   4.975974    1.3271792  -3.5778544  -2.3822553\n  0.56429094  4.0481305  -4.5152054   0.2273006 ]"",""59"":""[ 0.65759546  1.0411856   3.8386872   2.5914207  -3.1382031  -3.9702945\n  0.03608007  3.1929522  -5.8505387   0.18370527]"",""60"":""[ 0.12641093  0.76949775  4.1275177   2.7651422  -3.3368099  -3.574108\n -0.5441702   3.3801682  -5.176425    0.89237773]"",""61"":""[ 0.25061566  0.72879076  4.1946125   2.7991297  -3.497334   -3.5871649\n -0.17130494  3.8772223  -5.1167474   0.5345839 ]"",""62"":""[ 0.7746792   0.7805495   3.8867714   2.559719   -3.0495718  -3.65444\n  0.01845477  3.0564768  -5.723747    0.5973641 ]"",""63"":""[-0.19901524  1.3910704   4.079812    2.388491   -3.312865   -3.3328593\n -0.22389916  3.5258958  -5.1309237   0.60949427]"",""64"":""[ 0.38782287  1.8894842   4.855615    1.7105231  -3.361073   -2.6004\n  0.20233063  3.9413977  -4.8572655   0.07395867]"",""65"":""[-0.02572112  1.9084215   3.5292647   1.9834774  -3.2716346  -2.469555\n  0.11215264  4.005194   -4.680795   -0.18351084]"",""66"":""[ 0.14135411  1.6086632   3.6771624   2.2930605  -3.1496441  -2.7164102\n -0.06214108  3.8441532  -4.9389815  -0.44801214]"",""67"":""[ 0.6665592   2.4576302   3.5146143   1.0006825  -3.408651   -2.1298594\n  0.71087444  4.070902   -4.3657837   0.4299707 ]"",""68"":""[ 0.42764422  2.6884425   4.3254614   0.95891845 -3.64806    -2.1221669\n  0.6522372   4.2336226  -4.266117    0.31831774]"",""69"":""[-0.04762808  1.8067425   3.884207    2.0332205  -3.2076256  -3.0370178\n  0.12913314  3.7106907  -5.1216693   0.37473187]"",""70"":""[ 0.31563538  2.7232804   3.3473954   0.93559563 -3.5208843  -2.1883576\n  0.59645647  4.3835917  -4.179628    0.2386602 ]"",""71"":""[ 0.3340022   1.5487072   3.8002453   2.492934   -3.4559872  -3.3946939\n -0.25145027  3.7511234  -5.0621624  -0.9634512 ]"",""72"":""[ 1.1799473   1.1125615   3.682444    2.2085538  -3.0116022  -3.389416\n  0.56920785  3.2702036  -5.6987634   0.31615332]"",""73"":""[-0.01712129  1.3229373   3.9364464   2.4080856  -3.1857898  -3.531187\n -0.23630472  3.2712808  -5.3705397   0.6284577 ]"",""74"":""[ 0.47748953  2.4280348   4.761082    1.0261145  -3.2318118  -2.0061562\n  0.4777966   4.096334   -4.66316     0.23513387]"",""75"":""[ 0.13014263  0.9657831   3.9570282   2.976581   -3.3729656  -2.977815\n  0.4274782   3.6117547  -5.2531834  -0.30995673]"",""76"":""[ 0.17959137  2.0985744   3.3714676   1.6736042  -3.3146443  -2.2743132\n  0.27857703  4.109709   -4.5250144  -0.1283326 ]"",""77"":""[-0.27398765  1.1963785   4.0191708   2.8703265  -3.3955615  -3.521689\n -0.4558068   3.0868714  -5.1933746   0.49306583]"",""78"":""[ 0.57414603  2.5443356   3.2427511   0.9792058  -3.522247   -2.1036108\n  0.7373282   4.1539063  -4.32069     0.47591788]"",""79"":""[ 0.46038696  0.6297399   4.046017    2.8642027  -3.3071113  -3.7593813\n -0.15602225  3.2366135  -5.5361      0.36900172]"",""80"":""[ 1.0855693   0.9778108   3.8061483   2.357807   -2.9061892  -3.3243494\n  0.10160681  3.2948995  -5.6382246   0.08050262]"",""81"":""[-0.2972938   1.2130538   4.0588627   2.9218032  -3.46973    -3.4213138\n -0.42586046  3.1723363  -5.0897436   0.3934122 ]"",""82"":""[ 0.40623623  0.93381906  4.198075    2.5239763  -3.4243145  -3.4720204\n  0.11395143  4.0372396  -5.1469193   0.4916582 ]"",""83"":""[ 0.25554782  1.2789726   4.3871846   2.318412   -3.5131884  -3.067074\n  0.5419208   3.826281   -5.148841    0.26711214]"",""84"":""[ 0.845098    1.980648    3.1891143   1.3601118  -3.5835614  -2.7170393\n  0.85303503  3.5592442  -4.8675547   0.5734261 ]"",""85"":""[ 0.04017001  0.8806262   4.061799    2.7736814  -3.3280458  -3.7248428\n -0.45614985  3.2231758  -5.3326316   0.7225815 ]"",""86"":""[ 0.7024652   2.030385    3.017025    1.4192096  -3.6339712  -2.6980526\n  0.82762456  3.4764352  -4.9579573   0.5177933 ]"",""87"":""[ 0.7923896   1.9401983   3.1383476   1.4366657  -3.5596673  -2.7600405\n  0.80619127  3.5432992  -4.921623    0.5331496 ]"",""88"":""[ 0.39384666  2.2895463   3.1208873   1.3325515  -3.4195955  -2.1856818\n  0.54100144  4.1277385  -4.342713    0.19834179]"",""89"":""[ 0.37738907  2.211536    4.7048135   1.2762262  -3.412557   -2.10048\n  0.49786314  4.3325186  -4.666909    0.05942502]"",""90"":""[ 1.047922    1.6124582   3.6687098   1.8255781  -3.1353638  -3.5489361\n  0.57059664  3.5449386  -5.617806    0.6814145 ]"",""91"":""[ 0.48089626  2.0009754   3.5145397   1.651975   -3.256693   -3.093023\n  0.42835823  3.7213042  -5.1672373   0.47485653]"",""92"":""[ 1.0570693   0.89841855  3.7327876   2.4153757  -2.9593916  -3.5273244\n  0.36336052  3.0723302  -5.8179097   0.38416013]""},""topic"":{""0"":-1,""1"":4,""2"":2,""3"":-1,""4"":-1,""5"":1,""6"":-1,""7"":-1,""8"":0,""9"":3,""10"":-1,""11"":1,""12"":4,""13"":-1,""14"":1,""15"":3,""16"":-1,""17"":-1,""18"":1,""19"":3,""20"":5,""21"":5,""22"":-1,""23"":1,""24"":0,""25"":5,""26"":2,""27"":2,""28"":1,""29"":1,""30"":-1,""31"":2,""32"":1,""33"":5,""34"":5,""35"":-1,""36"":1,""37"":-1,""38"":2,""39"":3,""40"":-1,""41"":2,""42"":5,""43"":5,""44"":-1,""45"":-1,""46"":-1,""47"":-1,""48"":3,""49"":-1,""50"":0,""51"":3,""52"":1,""53"":-1,""54"":-1,""55"":4,""56"":-1,""57"":2,""58"":1,""59"":-1,""60"":4,""61"":4,""62"":5,""63"":-1,""64"":-1,""65"":0,""66"":0,""67"":2,""68"":1,""69"":-1,""70"":2,""71"":3,""72"":5,""73"":-1,""74"":1,""75"":-1,""76"":0,""77"":-1,""78"":2,""79"":5,""80"":5,""81"":-1,""82"":-1,""83"":-1,""84"":-1,""85"":-1,""86"":-1,""87"":-1,""88"":2,""89"":1,""90"":-1,""91"":-1,""92"":5},""exemplar"":{""0"":null,""1"":""*"",""2"":""*"",""3"":null,""4"":null,""5"":null,""6"":null,""7"":null,""8"":""*"",""9"":null,""10"":null,""11"":null,""12"":""*"",""13"":null,""14"":null,""15"":""*"",""16"":null,""17"":null,""18"":""*"",""19"":""*"",""20"":null,""21"":""*"",""22"":null,""23"":null,""24"":""*"",""25"":""*"",""26"":""*"",""27"":null,""28"":null,""29"":null,""30"":null,""31"":null,""32"":null,""33"":""*"",""34"":null,""35"":null,""36"":""*"",""37"":null,""38"":null,""39"":""*"",""40"":null,""41"":""*"",""42"":null,""43"":null,""44"":null,""45"":null,""46"":null,""47"":null,""48"":null,""49"":null,""50"":""*"",""51"":""*"",""52"":""*"",""53"":null,""54"":null,""55"":""*"",""56"":null,""57"":null,""58"":null,""59"":null,""60"":""*"",""61"":""*"",""62"":null,""63"":null,""64"":null,""65"":""*"",""66"":""*"",""67"":null,""68"":null,""69"":null,""70"":""*"",""71"":""*"",""72"":""*"",""73"":null,""74"":""*"",""75"":null,""76"":null,""77"":null,""78"":""*"",""79"":null,""80"":null,""81"":null,""82"":null,""83"":null,""84"":null,""85"":null,""86"":null,""87"":null,""88"":null,""89"":""*"",""90"":null,""91"":null,""92"":""*""},""word*"":{""0"":""data"",""1"":""distance*"",""2"":""mds*"",""3"":""attributes"",""4"":""map"",""5"":""fig"",""6"":""points"",""7"":""samples"",""8"":""matrix*"",""9"":""layout"",""10"":""space"",""11"":""v"",""12"":""point*"",""13"":""region"",""14"":""0"",""15"":""visualization*"",""16"":""similarity"",""17"":""dimensional"",""18"":""n*"",""19"":""mapping*"",""20"":""car"",""21"":""cars*"",""22"":""relationships"",""23"":""2d"",""24"":""matrices*"",""25"":""mpg*"",""26"":""ieee*"",""27"":""vd"",""28"":""cm"",""29"":""g"",""30"":""error"",""31"":""dv"",""32"":""j"",""33"":""horsepower*"",""34"":""schools"",""35"":""displays"",""36"":""p*"",""37"":""color"",""38"":""akde"",""39"":""visual*"",""40"":""axes"",""41"":""gbc*"",""42"":""tuition"",""43"":""schedule"",""44"":""node"",""45"":""update"",""46"":""origin"",""47"":""computer"",""48"":""graphics"",""49"":""dimension"",""50"":""dcm*"",""51"":""contour*"",""52"":""k*"",""53"":""approach"",""54"":""weight"",""55"":""range*"",""56"":""group"",""57"":""proc"",""58"":""pp"",""59"":""schedules"",""60"":""away*"",""61"":""field*"",""62"":""cost"",""63"":""a"",""64"":""trans"",""65"":""pairwise*"",""66"":""composite*"",""67"":""dd"",""68"":""vv"",""69"":""random"",""70"":""vf*"",""71"":""heatmap*"",""72"":""hpower*"",""73"":""efficient"",""74"":""l*"",""75"":""ambiguities"",""76"":""submatrix"",""77"":""allowed"",""78"":""df*"",""79"":""estimate"",""80"":""bandwidth"",""81"":""leads"",""82"":""journal"",""83"":""parent"",""84"":""\ud835\udc40\ud835\udc5a\ud835\udc4e\ud835\udc65"",""85"":""run"",""86"":""\ud835\udc3c"",""87"":""\ud835\udc3d"",""88"":""difgbc"",""89"":""pi*"",""90"":""euro"",""91"":""japanese"",""92"":""revenue*""},""pos"":{""0"":1,""1"":1,""2"":1,""3"":2,""4"":3,""5"":1,""6"":4,""7"":5,""8"":1,""9"":1,""10"":6,""11"":2,""12"":2,""13"":7,""14"":3,""15"":2,""16"":8,""17"":9,""18"":4,""19"":3,""20"":1,""21"":2,""22"":10,""23"":5,""24"":2,""25"":3,""26"":2,""27"":3,""28"":6,""29"":7,""30"":11,""31"":4,""32"":8,""33"":4,""34"":5,""35"":12,""36"":9,""37"":13,""38"":5,""39"":4,""40"":14,""41"":6,""42"":6,""43"":7,""44"":15,""45"":16,""46"":17,""47"":18,""48"":5,""49"":19,""50"":3,""51"":6,""52"":10,""53"":20,""54"":21,""55"":3,""56"":22,""57"":7,""58"":11,""59"":23,""60"":4,""61"":5,""62"":8,""63"":24,""64"":25,""65"":4,""66"":5,""67"":8,""68"":12,""69"":26,""70"":9,""71"":7,""72"":9,""73"":27,""74"":13,""75"":28,""76"":6,""77"":29,""78"":10,""79"":10,""80"":11,""81"":30,""82"":31,""83"":32,""84"":33,""85"":34,""86"":35,""87"":36,""88"":11,""89"":14,""90"":37,""91"":38,""92"":12},""x2D"":{""0"":4.6743974686,""1"":4.637160778,""2"":0.313805759,""3"":5.7783842087,""4"":4.5513601303,""5"":-8.4642086029,""6"":5.7094717026,""7"":3.204305172,""8"":2.9711384773,""9"":4.6025032997,""10"":3.325013876,""11"":-9.8565120697,""12"":4.9137029648,""13"":4.7526679039,""14"":-8.9675626755,""15"":4.2098727226,""16"":5.6557049751,""17"":3.628077507,""18"":-9.0989341736,""19"":4.3255467415,""20"":2.1568007469,""21"":2.1753525734,""22"":5.0720076561,""23"":-8.598361969,""24"":2.760373354,""25"":2.1640732288,""26"":0.5494874716,""27"":0.4767845869,""28"":-8.8381214142,""29"":-9.4991035461,""30"":5.0998749733,""31"":0.2518095672,""32"":-9.3850250244,""33"":2.4693813324,""34"":2.5953691006,""35"":5.7509655952,""36"":-8.5493116379,""37"":4.0308880806,""38"":0.7518727779,""39"":4.1570491791,""40"":5.4399356842,""41"":0.634606123,""42"":2.8254520893,""43"":3.6988065243,""44"":3.8143389225,""45"":3.8554852009,""46"":5.3456664085,""47"":4.3229351044,""48"":4.3906550407,""49"":5.104970932,""50"":2.4344437122,""51"":4.4430122375,""52"":-9.4213075638,""53"":4.7952947617,""54"":3.4575829506,""55"":4.4356079102,""56"":4.4137277603,""57"":0.6052601933,""58"":-8.9417877197,""59"":3.3854782581,""60"":4.7669548988,""61"":4.5161237717,""62"":3.1570174694,""63"":5.2575159073,""64"":-8.6497907639,""65"":2.6516866684,""66"":3.1071448326,""67"":0.2389338166,""68"":-9.7732439041,""69"":2.7450840473,""70"":0.2203284204,""71"":4.1189842224,""72"":2.4574952126,""73"":5.2280297279,""74"":-9.4513940811,""75"":5.2223348618,""76"":2.2493076324,""77"":5.4713354111,""78"":0.6991412044,""79"":4.0131902695,""80"":2.8379983902,""81"":5.6272950172,""82"":4.4822258949,""83"":4.2704515457,""84"":1.6041799784,""85"":4.9473824501,""86"":1.4343010187,""87"":1.465716362,""88"":0.8087469935,""89"":-9.1449842453,""90"":1.9445289373,""91"":1.7424663305,""92"":2.7116465569},""y2D"":{""0"":-2.0542755127,""1"":0.9126636982,""2"":-5.1099214554,""3"":-0.3505553007,""4"":-3.0177884102,""5"":5.0083723068,""6"":0.0855854526,""7"":-2.5121166706,""8"":-3.1874985695,""9"":-2.6849248409,""10"":0.3117780685,""11"":5.0339751244,""12"":0.4634098113,""13"":-0.3710339069,""14"":4.8756685257,""15"":-3.0796518326,""16"":-0.4320349097,""17"":-2.957955122,""18"":4.8787369728,""19"":-3.1000926495,""20"":1.158223629,""21"":1.0417696238,""22"":-1.0107505322,""23"":4.8012943268,""24"":-3.2731654644,""25"":1.1032187939,""26"":-4.8795547485,""27"":-5.197593689,""28"":5.1212038994,""29"":4.8137168884,""30"":-1.4419095516,""31"":-4.8945274353,""32"":5.293636322,""33"":0.9261099696,""34"":1.2582832575,""35"":0.348552376,""36"":4.9278578758,""37"":-2.6692204475,""38"":-4.5076451302,""39"":-2.7781963348,""40"":-0.1642319262,""41"":-4.6005511284,""42"":1.3401813507,""43"":1.2701206207,""44"":-1.3349106312,""45"":1.0590685606,""46"":-0.6039831638,""47"":-2.048469305,""48"":-2.5107672215,""49"":-0.5639874339,""50"":-3.5347723961,""51"":-2.9176995754,""52"":5.2909827232,""53"":0.1902457625,""54"":0.9167588353,""55"":0.5981318355,""56"":-0.4672399759,""57"":-5.1269087791,""58"":5.0337939262,""59"":1.2651741505,""60"":0.8688519597,""61"":0.2846574783,""62"":1.0701649189,""63"":0.4909835756,""64"":4.7180576324,""65"":-3.3377764225,""66"":-3.0032994747,""67"":-4.5982112885,""68"":5.2242898941,""69"":-2.5838701725,""70"":-5.1930484772,""71"":-2.9671082497,""72"":1.1209315062,""73"":0.8440330029,""74"":5.0727667809,""75"":-1.242806077,""76"":-3.6237289906,""77"":0.6329251528,""78"":-4.9003338814,""79"":0.9460449219,""80"":0.728577733,""81"":0.4526428282,""82"":-0.2049202025,""83"":-0.882034421,""84"":-3.6992716789,""85"":0.9671074152,""86"":-3.8640007973,""87"":-3.8249919415,""88"":-4.470500946,""89"":5.2578392029,""90"":1.0342432261,""91"":-3.4882824421,""92"":1.1335422993}}",False,False,False,http://ieeexplore.ieee.org/document/7194836/,,The Data Context Map: Fusing Data and Attributes into a Unified Display,H4Y2RXSJ,False,False
LXQ5QRAX,YMDGBMNA,"Co-located Collaborative Sensemaking on a Large  
High-Resolution Display with Multiple Input Devices 

Katherine Vogt1, Lauren Bradel2, Christopher Andrews2, Chris North2,  

Alex Endert2, and Duke Hutchings1 

1 Department of Computing Sciences 
Elon University, Elon, NC 27244, USA 
{kvogt,dhutchings}@elon.edu 

2 Department of Computer Science 

Virginia Tech, Blacksburg, VA 24060, USA 

{lbradel1,cpa,north,aendert}@cs.vt.edu 

Abstract. This study adapts existing tools (Jigsaw and a text editor) to support 
multiple input devices, which were then used in a co-located collaborative intel-
ligence analysis study conducted on a large, high-resolution display. Exploring 
the sensemaking process and user roles in pairs of analysts, the two-hour study 
used a fictional data set composed of 50 short textual documents that contained 
a  terrorist  plot  and  subject  pairs  who  had  experience  working  together.  The 
large display facilitated the paired sensemaking process, allowing teams to spa-
tially arrange information and conduct individual work as needed. We discuss 
how the space and the tools affected the approach to the analysis, how the teams 
collaborated, and the user roles that developed. Using these findings, we sug-
gest design guidelines for future co-located collaborative tools. 

Keywords:  Visual  analytics,  sensemaking,  co-located,  CSCW,  large  high-
resolution display. 

1   Introduction 

As analysts sort through the growing amounts of data every day, tools that can display 
the information in a useful manner without overwhelming their sensemaking process are 
a beneficial component of their workflow. Visual analytics works to improve analysts’ 
experience in their work and productivity. As such, exploring what collaborative visual 
analytics may contribute to this challenge has become a key area of research within vis-
ual  analytics  [1].  Through  the  support  of  collaboration  within  the  analytic  process,  
designers can improve the effectiveness though leveraging various social and group dy-
namics [2]. Various design guidelines and structured collaborative techniques exist [3], 
but, as the culture of intelligence analyst working within an agency can be described as 
“competitive”, where sharing of knowledge may adversely affect their job security, col-
laboration occurs at a much less formal level, if at all [4]. The study presented here does 
not  present  a  formal  collaborative  method,  but  places  the  users  in  a  setting  where  
information and knowledge is inherently shared through the use of a shared workspace.  

P. Campos et al. (Eds.): INTERACT 2011, Part II, LNCS 6947, pp. 589–604, 2011. 
© IFIP International Federation for Information Processing 2011 

590 

K. Vogt et al. 

Fig. 1. Study setup, two users with their own input devices in front of the large display 

 

Large, high-resolution workspaces (such as the one shown in Fig. 1) are beneficial 
to intelligence analysis in that they allow for spatial information organization to act as 
an external representation or memory aid [5]. This advantage was shown to help indi-
vidual intelligence analysts in their task, in that they were able to spatially organize 
and  reference  information.  This  work  explores  how  such  a  workspace,  allowing  for 
these spatial strategies, can impact the strategy and workflow of a team (of 2) users 
working  collaboratively  on  an  intelligence  analysis  task.  In  this  environment,  we  
provide  users  with  a  social  setting  in  which  to  perform  their  analysis,  and  a  shared 
representation in which to organize their thoughts. We analyze their process in terms 
of their activities and roles exemplified during their task, their use of space, and level 
of collaboration. 

In  such co-located  settings (versus remote  settings), it  has been  shown  that  teams 
experience a greater quality of communication because of subtle physical interaction 
cues and a stronger trust that develops with the shared experience [6]. Also, given that 
analysts often work with large collections of electronic documents, it is worthwhile to 
explore how the design of tools on large, high-resolution displays could facilitate col-
laboration  during  analysis.  Further,  if  this  environment  supports  collaborative  work, 
then the ability to make sense of documents develops great potential. To investigate the 
collaborative use of a large, high-resolution display environment, we have completed 
an  exploratory  study  of  two  visual  analytic  tools:  Jigsaw  [7],  and  a  simple  multi-
window text editor. The study we present involves synchronous, co-located collabora-
tive  sensemaking.  Here,  we  define  co-located  work  as  multiple  users  working  each 
with his or her own input devices (mouse and keyboard) on the same computer display. 

2   Related Work 

Design tensions exist in collaborative tools between “individual control of the appli-
cation,  and  support  for  workspace  awareness”  [8].  Some  previous  groupware  tools 
have had difficulty achieving a balance between these extremes, either supporting the 

 

Co-located Collaborative Sensemaking on a Large High-Resolution Display 

591 

group through consistent view sharing (“What You See Is What I See” – WYSIWIS) 
or the individual through relaxed view sharing [9]. However, Gutwin and Greenberg 
feel that a solution to this tension exists, stating that “the ideal solution would be to 
support both needs – show everyone the same objects as in WYSIWIS systems, but 
also  let  people  move  freely  around  the  workspace,  as  in  relaxed-WYSIWIS  group-
ware” [8]. Single display groupware provides an interface to achieve this balance. 

Single Display Groupware (SDG) concerns face-to-face collaboration around a single 
shared  display  [10].  Early  SDG  systems  include  Liveboard  [11],  Tivoli  [12],  and  the 
Digital Whiteboard [13]. When compared to co-located multi-display groupware, SDG 
resulted in increased collaborative awareness [14]. Stewart et al. continued to investigate 
SDG systems  in subsequent work ([15, 16]). They proposed that  the multi-user nature 
of SDG systems on early displays with limited screen size “may result in reduced func-
tionality compared with similar single-user programs” [16], although this concern can be 
alleviated by increasing the physical size (and resolution) of the SDG display. 

SDG systems using multiple input devices have been found to increase interaction 
between  participants  and  keep  participants  “in  the  zone”  [15].  Providing  a  separate 
mouse and keyboard to each participant has been shown to allow users to complete 
more  work  in  parallel  than  if  they  were  restricted  to  a  single  mouse  and  keyboard 
[17]. Multiple input devices provide the benefit of allowing reticent users to contrib-
ute to the task [18, 19]. As a result of our desire to keep participants in the “cognitive 
zone” [20], given the cognitively demanding nature of sensemaking tasks, we chose 
to implement multiple input devices for our set-up. 

The sensemaking process has been illustrated by Pirolli and Card (Fig. 2) to outline 
the cognitive process of “making sense” of documents throughout their investigation 
in  order  to  produce  a  cohesive  and  coherent  story  of  interwoven  information  found 
across document sources [21]. This process can be broken down into two broad cate-
gories: foraging and sensemaking. The foraging loop involves extracting and filtering 
relevant  information.  The  sensemaking  loop  represents  the  mental  portion  of  sense-
making where a schema, hypothesis, and presentation are iteratively developed. The 
analyst is not restricted to a single entry point to this loop, and instead can enter at the 
top or bottom before looping through the various steps [21]. The sensemaking process 
has been studied and observed on large, high-resolution displays as well as multiple 
monitor set-ups for individual users [5, 7, 22].  

Paul and Reddy observed, through an ethnographic study concerning collaborative 
sensemaking of healthcare information, that collaborative sensemaking should focus 
on the following factors: prioritizing relevant information, the trajectories of the sen-
semaking activity, and activity awareness [23]. We believe that the large display used 
in our study provides users with the opportunity for this awareness and prioritization. 
Collaborative sensemaking has also been studied in terms of web searches [24, 25], as 
well  as  remote  collaborative  sensemaking  for  intelligence  analysis  [26].  Furthermore, 
collaborative sensemaking has been observed in co-located tabletop settings [27-29], al-
though, to the best of our knowledge, co-located collaborative sensemaking applied to  
intelligence analysis has not been investigated on large, high-resolution vertical displays. 

 
 

592 

K. Vogt et al. 

Fig. 2. Adapted from sensemaking loop, Pirolli and Card [21] 

 

User performance on simple tasks, such as pattern matching, has been shown to im-
prove when using a large, high-resolution vertical display when contrasted with a stan-
dard single monitor display [30]. In addition to quantitative improvement, users were ob-
served  using  more  physical  navigation  (e.g.  glancing,  head/body  turning)  than  virtual  
navigation  (e.g.  manually  switching  windows  or  tasks,  minimizing/maximizing  docu-
ments) when using large, high-resolution displays, such as the one shown in Fig. 1. 

Andrews  et  al.  expanded  the  benefits  of  using  large,  high-resolution  display  to 
cognitively demanding tasks (i.e., sensemaking) [5]. We chose to use these displays to 
explore collaborative sensemaking on large vertical displays, especially the user roles 
that develop throughout the sensemaking process and how the sensemaking process is 
tackled by teams of two. 

3   Study Design 

We  have  conducted  an  exploratory  study  examining  the  collaborative  sensemaking 
process on a large, high-resolution display. Teams of two were asked to assume the 
role of intelligence analysts tasked  with analyzing a collection of text documents to 
uncover a hidden plot against the United States. The teams were provided with one of 
two tools, Jigsaw or a multi-document text editor, with which they were asked to con-
duct  their  analysis.  While  each  team  was  told  that  they  were  expected  to  work  col-
laboratively, the nature of that collaboration was left entirely up to the participants.  

3.1   Participants 

We recruited eight pairs of participants (J1-J4 used Jigsaw, T1-T4 used the text editor). 
All pairs knew one another and had experience working together prior to the study. Six 
of the eight pairs were students and the other two pairs consisted of research associates 

 

Co-located Collaborative Sensemaking on a Large High-Resolution Display 

593 

and faculty. There were four all male groups, one all female, and three mixed gender. 
Each participant was compensated $15 for participation. As a form of motivation, the so-
lutions generated by the pairs of participants were scored and the participants received an 
additional financial award for the four highest scores. The rubric for evaluating the par-
ticipants’  verbal  and  written  solutions  was  based  on  the  strategy  for  scoring  Visual  
Analytics  Science  and  Technology  (VAST)  challenges  [22].  The  participants  earned 
positive points for the people, events, and locations related to the solution and negative 
points for those that were irrelevant or incorrect. They also received points based on the 
accuracy of their overall prediction of an attack.  

3.2   Apparatus 

Each pair of users sat in front of a large display consisting of a 4x2 grid of 30” LCD 
2560x1600  pixel  monitors  totaling  10,240x3,200  pixels  or  32  megapixels  (Fig.  1). 
The display was slightly curved around the users, letting them view the majority, if 
not all, of the display in their peripheral vision. A single machine running Fedora 8 
drove the display. A multi-cursor window manager based on modified versions of the 
IceWM and x2x was used to support two independent mice and keyboards [31]. Thus, 
each user was able to type and use the mouse independently and simultaneously in the 
shared workspace. This multi-input technology allowed two windows to be “active” 
at  the  same  time,  allowing  participants  to  conduct  separate  investigations  if  they 
chose. A whiteboard, markers, paper, and pens were also available for use. These ex-
ternal artifacts were provided as a result of a pilot study where participants explicitly 
requested to use the whiteboard or write on sheets of paper. Each participant was pro-
vided  with  a  rolling  chair  and  free-standing,  rolling  table  top  holding  the  keyboard 
and  mouse  so  that  they  could  move  around  if  they  chose  to  do  so.  The  desks  and 
chairs were initially positioned side-by-side in the central area of the screen space. 

3.3   Analytic Environment 

During this exploratory study, four of the pairs (J1-J4) examined the documents within 
Jigsaw, a recent visual analytics tool, while the other four (T1-T4) used a basic text edi-
tor, AbiWord [32], as a contrasting tool. We chose to investigate these two tools due to 
the different analytical approaches the tools inherently foster. Jigsaw supports a function-
based  approach  to  analysis,  allowing  the  tool  to  highlight  connections  between  docu-
ments and entities. The Text Editor instead forces the participants to read each document 
first, and then draw connections themselves without any analytical aid. We do not intend 
for these two tools to be representative of all visual analytics tools. Instead, we sought to 
explore  co-located  collaborative  sensemaking  in  two  different  environments.  This  text 
editor allows the user to highlight individual document sections and edit existing docu-
ments or create text notes. Teams using this text editor were also provided with a file 
browser in which they could search for keywords across the document collection. Jigsaw 
[7, 33] is a system that has been designed to support analysts; it visualizes document col-
lections  in  multiple  views  based  on  the  entities  (people,  organizations,  locations,  etc.) 
within those documents. It also allows textual search queries of the documents and enti-
ties. The views are linked by default so that exploring an entity in one visualization will 
simultaneously  expand  it  in  another. This  feature  is  controlled  by  the  user  and  can  be 
turned on or off within each view. We were not able to change Jigsaw’s source code to 

594 

K. Vogt et al. 

allow  windows  to  be  linked  separately  for each participant, therefore  all Jigsaw  views 
were connected unless the linking feature was disabled by the participant teams. Jigsaw 
can sort documents based on entity frequency, type, and relations. This information can 
be displayed in many different ways, including interactive graphs, lists, word clouds, and 
timelines. Jigsaw also comes  equipped  with a recently added Tablet view  where users 
can  record  notes,  label  connections  made  between  entities,  identify  aliases,  and  create 
timelines. As a result of the complexity of the visualizations available in Jigsaw, pairs  
using this visual analytics tool were given a thirty minute tutorial prior to the start of the 
scenario, while pairs using the text editor only required a five minute tutorial. 

3.4   Task and Procedure 

After a tutorial on Jigsaw or the text editor with a sample set of documents, each pair was 
given two hours to analyze a set of 50 text documents and use the information gathered 
to predict a future event. This scenario comes from an exercise developed to train intelli-
gence analysts and consists of a number of synthetic intelligence reports concerning vari-
ous incidents around the United States, some of which can be connected to gain insight 
into  a  potential  terrorist  attack.  This  same  scenario  was  also  used  in  a  previous  study 
evaluating  individual  analysts  with  Jigsaw  [33].  Following  the  completion  of  the  sce-
nario, each  participant  filled out  a  report  sheet  to  quantitatively  assess  their  individual 
understanding of the analysis scenario, then verbally reported their final solution together 
to  the  observers.  Finally,  individual  semi-structured  interviews  were  conducted  where 
each participant commented on how they solved the scenario, how this involved collabo-
ration, and their sense of territoriality.  

3.5   Data Collection 

During each scenario, an observer was always present taking notes. Video and audio 
of every scenario, debriefing, and interview was recorded. The video was coded using 
PeCoTo  [34].  We  also  collected  screenshots  in  fifteen  second  intervals  and  logged 
mouse actions and active windows. The screenshots played two roles in our analysis. 
Their primary role was to allow us to “play back” the process of the analysis so that 
we could observe window movements and the use of the space. Furthermore, we ap-
plied the previously described point system in order to evaluate the accuracy of their 
debriefing, providing a way to quantitatively measure their performance. The scores 
can  be  seen  below  in  Table  1.  There  was  no  significant  difference  between  overall 
performance between the Jigsaw and Text Editor tool conditions when evaluated with 
a t-test, although statistical significance is difficult to show with small sample sizes. 

Table 1. Overall team scores grouped by tool used comparing aggregated performance 

Jigsaw 

J1 
J2 
J3 
J4 

11 
-1 
-2 
-7 

Text Editor 
T1 
13 
-1 
T2 
10 
T3 
T4 
14 

 

Co-located Collaborative Sensemaking on a Large High-Resolution Display 

595 

4   Analysis 

4.1   User Activities 

Each group exhibited a variety of activities depending on their amount of progress to 
achieve a satisfactory solution. After analyzing the video, interviews, and solution re-
ports, we have concluded that five major activities that were used by the participants, 
which together formed a strategy for analyzing the data. These were not usually ex-
plicitly  identified  by  the  participants,  but  rather  tasks  that  the  participants  naturally 
took  on  in  order  to  uncover  the  underlying  terrorist  plot.  The  five  activities  are  ex-
tract, cluster, record, connect, and review and will be described in greater detail be-
low.  Although  each  group  exhibited  the  execution  of  each  activity  (one  exception  
being cluster which we will discuss later), the groups used different methods to im-
plement that activity that were often based on the interface condition (Jigsaw or text 
editor) of the group [Table 2]. 

Extract. The groups had no starting point or lead to begin with - just fifty text docu-
ments and the knowledge that there was a terrorist threat to the nation. Therefore, they 
needed to familiarize themselves with the information presented within the documents 
and then extract that  which  seemed important. In Jigsaw, the visualizations allowed 
for participants to begin this process by looking at frequently occurring entities and 
the other entities and documents to which they connected. With the text editor, these 
features  were  not  available  therefore  the  participants  were  forced  to  open  and  read 
each  document.  They  then  all  used  color-coded  highlighting  to  distinguish  entities 
and/or important phrases. The coloring scheme was decided upon by the participants, 
whereas Jigsaw maintains a set color scheme for entities. In the text editor groups, the 
subjects opened documents in consistent locations to read them, but soon moved the 
opened  documents  into  meaningful  clusters  (see  next  activity).  The  Extract  activity 
required little display space to complete in either study condition. This activity  was 
done together in some groups with both participants simultaneously reading the same 
document  and  in  parallel  in  others  with  each  participant  reading  half  of  the  docu-
ments, often split by document number. 

Table 2. Five sensemaking activities and their methods for corresponding tool 

Activity 
Extract 

Cluster 

Record 

Connect 

Review 

Method 
Tool 
Jigsaw 
Look over frequently occurring entities and related documents 
Text Editor  Read all of the documents, together or separately, and highlight 
Jigsaw 

(did not occur with this tool as Jigsaw automatically color codes 
and groups the entities by type) 

Text Editor  Group document windows by related content 
Jigsaw 
Text Editor  Whiteboard, paper 
Jigsaw 

Tablet (3 groups), whiteboard & paper (1 group) 

Loop  between 
per/whiteboard), together or separately 

list,  document  view,  and  Tablet  (or  pa-

Text Editor  Search function; reread paper, whiteboard, and documents 
Jigsaw 
Text Editor  Reread, possibly close windows after reviewing 

Reread, search for unviewed documents (2 groups) 

 

596 

K. Vogt et al. 

Cluster.  With the text editor, all of the groups found a need to cluster and organize the 
documents. The groups clustered by grouping the document windows by content in the 
space (they resembled piles), using whitespace between clusters as boundaries. The clus-
ters eventually filled the display space, allowing the participants to view all documents at 
once  in  a  meaningful  configuration.  Even  when  only  one  partner  organized  the  docu-
ments into clusters, the other partner could easily find documents relevant to a certain 
topic due to their agreed upon clustering scheme (e.g. chronological order, geographical 
as shown in Fig. 3). Most text editor groups used the multi-mouse functionality to simul-
taneously  organize  the  display  space.  Three  of  the  four  groups  eventually  re-clustered 
their documents after some analysis. The cluster activity as defined above (spatially ar-
ranging document windows) was not present in any of the Jigsaw groups, because Jigsaw 
organizes  the  entities  and  documents  through  its  various  functionalities.  Many  Jigsaw 
groups,  however,  clustered  relevant  entities  within  their  Tablet  views,  giving  spatial 
meaning to the information recorded. 

 
Fig. 3. Geographical clustering of documents on the large display screen, done by group T4 (T4-B, 
the forager, arranged the space while T4-A, the sensemaker, instructed document placement) 

Record. Recording important information proved to be a useful strategy for all groups. 
Through interviews the participants revealed that this not only served as a memory aid, 
but also a way to see what events, dates, people, and organizations related. In the scenar-
ios with the text editor, with two of the groups using the whiteboard and three using scrap 
paper (one used both), all groups found a need to use an external space to record impor-
tant information regardless of how much of the display was filled by clusters. This al-
lowed them to preserve the cluster set-up and keep the documents persistent. Three of the 
Jigsaw  groups  used  the  Tablet  view  to  take  notes  and  one  group  used  paper  and  the 
whiteboard. Thus all participants devoted a separate space to keep track of pertinent in-
formation. Groups also recorded important information verbally to alert their partner to a 
potential lead, allowing their partner to create a mental record. 
Connect. In order to make connections and look for an overall plot, the Jigsaw partici-
pants would often loop through the list view, document view, and the Tablet, connecting 
the information they discovered. Two groups worked on this separately and two did this 
together. With the text editor, participants searched for entities and reread their notes. In 
comparison to their discourse during the other activities, the groups were more talkative 
when making connections. Text editor group T1 cleared a screen to use as a workspace 
for  their  current  hypotheses.  They  opened  relevant  documents  in  their  workspace  and 
closed irrelevant documents or documents from which they had extracted all information.  
 

 

Co-located Collaborative Sensemaking on a Large High-Resolution Display 

597 

In all text editor cases, the meaning conveyed by clustered documents on the display was 
helpful in drawing connections. 
Review. This appeared to be a very important element in the groups’ analyses. Often 
when  one  or  both  partners  reread  a  document  for  the  second,  third,  or  even  fourth 
time, it took on a new meaning to them after they understood the greater context of 
the scenario. This element of review could also help the participants as they worked to 
Connect. Two of the Jigsaw groups chose to search for unviewed documents to ensure 
that they had encountered all potentially important information. Two of the text editor 
groups  began  closing  windows  after  they  had  reread  them.  Sometimes  this  was  be-
cause the document  was considered irrelevant. For example, group T3 moved  unre-
lated documents to what they called the “trash window”. They later reread all of the 
trash window documents and closed those which still seemed irrelevant. The Review 
activity also included discussing current and alternative hypotheses. 

While the activities listed in the table can be loosely defined in this sequential or-
der, the order is certainly not set nor were they visited only once within each scenario. 
Rather, there was often rapid but natural movement between these activities and their 
methods depending on the current needs of the analysis. In particular, the middle three 
activities were present many times throughout the study. Extract was only necessary 
during  the  first  part  of  each  scenario  and  review  was  usually  only  seen  after  a  
significant portion of the first activity had been completed. 

4.2   Comparison between Sensemaking Loop and Activities 

The processes we observed closely reflect the Pirolli and Card [21] sensemaking model 
(Fig. 2)   which  was developed for individual  analysts. We  have  found  that it  may  also 
generally be applied to collaborative pairs, although the loop is utilized differently because 
of the roles that developed. Extract and cluster relate to steps two through seven. The Evi-
dence  File  and  Schema  steps  were  combined  by  the  pairs  due  to  the  available  display 
space. They were able to sort evidence into a meaningful schema by placing documents in 
different areas of the display. Record is very similar to schematizing and connect is a part 
of developing hypotheses. Review does not directly map to one stage of the sensemaking 
loop,  but  rather  it  is  the  equivalent  of  moving  back  down  the  loop,  analyzing  previous 
work, and returning to the shoebox and evidence file. Note that External Data Sources is 
not mentioned here because the participants were only presented with fifty documents so 
we are assuming that prior analysis has moved through this step. The cumulative Presen-
tation directly links to the debriefing following the scenario.  

Fig. 4. Screenshot of one of the scenarios, group J2, using Jigsaw, illustrating one way in which 
the users partitioned the display to conduct individual investigations 

 

598 

K. Vogt et al. 

While the activities described above and the sensemaking loop hold parallel ideas, 
we do want to distinguish the two concepts. The overall strategy we propose has been 
condensed to  five activities as a result of the collaboration and  space.  Additionally, 
we have given the idea of review new emphasis. This is a very important element in 
the sensemaking process, but is not explicitly identified in the sensemaking loop. 

All  of  the  activities,  excluding  Cluster,  were  present  in  both  scenarios.  This  is  
notable considering the vast differences of the scenarios based on tool type. Since the 
activities  we  observed  correspond  to  the  Pirolli  and  Card  sensemaking  model  [21], 
with the primary difference in user behavior being the tool-specific methods adopted to  
fulfill those activities, we propose that these activities are very likely to be universal. 

4.3   Collaboration Levels 

The amount of time spent working closely together appears to have impacted the scores. 
We applied the video coding code set from Isenberg et al. [29] to determine how much 
time was spent closely coupled (collaborating together) versus loosely coupled (working 
individually). Closely coupled is defined by Isenberg et al. active discussion, viewing the 
same document, or working on the same specific problem [29]. Loosely coupled is de-
fined as working on the same general problem, different problems, or being disengaged 
from the task. Upon graphing this data (Fig. 5), two clusters appear separating the high-
scoring groups from the low-scoring ones. The high scoring cluster worked closely over 
89% of the time spent on the scenario. The low scoring cluster only worked closely in be-
tween 42% and 67% of the time. All but one group at least collaborated closely during 
the remaining half hour of the scenario in order to synthesize their hypotheses. The corre-
lation  coefficient  between  the  amount  of  time  spent  collaborating  closely  and  score  is 
.96105, suggesting that there is a strong correlation between these variables. This rein-
forces the result from [29] that strongly links collaboration levels with performance.  

Fig. 5. Jigsaw (dark blue) and Text Editor (light green) scores versus collaboration levels 

 

 

Co-located Collaborative Sensemaking on a Large High-Resolution Display 

599 

4.4   User Roles 

All  groups  divided  the  responsibilities  of  the  collaborative  sensemaking  task.  The 
roles  could  be  observed  during  the  study  because  of  actions  and  conversation,  but 
they  were  also  evident  during  the  interviews  following  the  study.  Five  of  the  eight 
groups established clearly defined collaborative roles (measured through  video cod-
ing). This appeared to be because the three groups were going through the steps of the 
analysis  independently,  but  in  parallel.  Therefore  various  team-related  roles  and  
responsibilities in the analysis were less likely to develop. 

For the five groups who established clearly defined roles, the two broad roles we 
identified  through  this  analysis  are  sensemaker  and  forager.  These  high-level  roles 
were primarily established after a considerable amount of the investigation had been 
completed, normally after the half-way point of the study session. Primarily, the sen-
semaker  tended  to  be  the  dominant  partner,  often  dictating  what  the  forager  did. 
Common activities for the sensemaker included standing, writing on the whiteboard, 
using  a  hand  to  point  to  information  (instead  of  using  a  cursor),  and  rarely  using  a 
mouse, instead requesting the forager to perform various activities. The forager’s role 
consisted of questioning the current hypotheses, finding information, and maintaining 
a  better  awareness  of  where  the  information  was  located.  For  example,  the  sense-
maker would request actions such as “can you open [a particular document]?” and the 
forager would perform the action.  

These two roles closely match the two primary sub-loops (Fig. 2) in the Pirolli and 
Card model [21]. The first loop, foraging, involves sorting through data to distinguish 
what is relevant from the rest of the information. The second loop, sensemaking, in-
volves utilizing the information pulled aside during the foraging process to schema-
tize and form a hypothesis during the analysis. Thus, the sensemaker was more con-
cerned with the synthesizing of the information, while the forager was more involved 
in the gathering, verifying, and organizing of the information. While the sensemaker 
and forager each spent the majority of their time at their respective ends of the loop, 
they did not isolate themselves from the rest of the sensemaking process. 

To illustrate the distribution of responsibilities prompted by the roles adopted, we 
will  explain  in  detail  two  of  the  pairs  where  the  participants  formed  distinct  roles. 
These  are  the  two  groups  in  which  the  roles  are  most  clearly  defined,  and  are  
therefore the most interesting to talk about.  

In  group  T1,  the  team  with  the  second-highest  score,  both  participants  spent  the 
first  hour  foraging  (i.e.,  exposing,  clustering)  for  information  while  taking  a  few 
breaks  to  engage  in  sensemaking  activities  (i.e.,  connecting).  Participant  T1-A  (the 
subject who sat on the left) at times led T1-B’s (the participant who sat on the right) 
actions by initializing activities or finalizing decisions.  At the 68-minute  mark, par-
ticipant T1-B moved to the whiteboard (never to return to the computer input devices) 
and established a clear, dominant role as sensemaker while T1-A continued to forage 
for information. Specifically, T1-A organized the documents, searched, and provided  
 

600 

K. Vogt et al. 

dates, locations, relevant events, etc., but T1-B drew a picture connecting the relevant 
events working to form a hypothesis and requested information from T1-A. T1-B be-
gan focusing on Record and Connect, but they both engaged in the Review activity to-
gether.  The  Review  activity  was  interspersed  throughout  the  scenario  as  pieces  of  
information inspired participants to revisit a document. During the interviews, T1-B 
revealed that he wanted to build a chart or timeline to organize their thoughts better. 
Although  interviewed  separately,  they  seemed  to  have  similar  views  on  their  roles. 
T1-B stated, “I basically just tried to stand up there and construct everything while he 
finds evidence,” while T1-A said, “I was just trying to feed him the data, that was my 
skill, find it, and he can put it in a flow chart.” 

The other pair is group T4, the group with the highest score, where T4-A was the sen-
semaker and T4-B the forager. Again, the sensemaker is the participant (T4-A) who built 
a picture on the whiteboard, meaning he drove Record and Connect. In fact, T4-A barely 
touched his mouse after the first fifteen minutes of the scenario. He only had 104 mouse 
clicks while T4-B had 1374. They worked through Extract and Cluster together, but T4-
A verbally dictated the clustering while T4-B controlled it with the mouse. While T4-A 
worked on the whiteboard, T4-B fed him details as needed. As T4-A stated, “We ended 
up splitting the tasks into organization and story-building… I would say I built most of 
the story.” Both participants worked on the Review activity, but during this T4-B ques-
tioned T4-A’s  hypotheses  which  forced  him  to  justify  and  support  his  thoughts.    This 
lopsided mouse usage is not a new method of interaction [35], however, it is interesting 
that T4-A abandoned his mouse in favor of instructing his partner. 

5   Design Implications 

Viewing  all  documents  simultaneously  appeared  to  be  an  effective  strategy,  
given the added space provided by the large display. All 50 documents comfortably 
fit into user-defined clusters. No Jigsaw groups chose this approach, instead relying 
on the specialized views available. Visual analytics tools designed for large displays 
should  take  this  into  consideration  by  allowing  users  to  open  many  documents  and 
flexibly rearrange the clusters as needed. This may not be feasible after the document 
collection becomes large enough, in which case a tool such as Jigsaw would be valu-
able  in  narrowing  down  the  document  collection.  We  recommend  that  developers 
combine  these  two  analysis  approaches  to  perform  well  on  all  document  collection 
sizes. 

Because the highest scoring groups had clearly defined user roles while the lowest 
scoring groups did not, we recommend that co-located collaborative visual analytics 
tools  support  the  division  of  responsibilities.  One  way  to  achieve  this  would  be  to  
implement specialized views for foragers and sensemakers. 

Some sensemakers stood and used a physical whiteboard to record their thoughts. 
All text editor groups used the whiteboard or paper to record their thoughts. One Jig-
saw  group used the  whiteboard while the rest used Jigsaw’s Tablet view. From this 
we can see a clear need for tools that integrate evidence marshaling and sensemaking  
 

 

Co-located Collaborative Sensemaking on a Large High-Resolution Display 

601 

into the analytic process. The Tablet view in Jigsaw and other integrated sensemaking  
environments such as the Sandbox in the nSpace suite [36] are one approach. Another 
approach, suggested by  the studies conducted by Robinson [18] and  Andrews et al. 
[5] as well as our observations of the text editor group would be to integrate sense-
making tools right into the document space. As we observed in this study, the users of 
the  text  editor  already  were  arranging  documents  into  structures  based  on  their  
content.  A  logical  continuation  of  this  would  be  to  integrate  sensemaking  tools  and 
representations into this space directly, so that the sensemaking is done directly with 
the  documents,  allowing  the  user  to  maintain  the  context  of  the  original  source  
material.  

We have also considered some frustrations expressed by the users while develop-
ing design implications. One issue involved the presence of the taskbar on only one of 
the  eight  monitors,  an  issue  recognized  in  the  past  (for  example  GroupBar  [37]).  It 
became difficult and inconvenient for the users to locate windows in the taskbar, es-
pecially  with over fifty  windows opened  simultaneously.  For future  visual analytics 
tools,  we  recommend  implementing  a  feature  that  allows  easier  location  of  docu-
ments. This could be done through a better search feature, such as flashing document 
windows to make locating them easier.  

6   Conclusion 

We have conducted a study which explores an arrangement for co-located collabora-
tive sensemaking and applied it to intelligence analysis, an application that, to the best 
of our knowledge, has not yet been seen for this specific set-up and application. We 
extracted five common activities which the participants used in their overall strategy 
during collaborative sensemaking. While the activities were common with all groups, 
the execution of the activities varied based on the tool (Jigsaw or text editor). These 
activities reflected many of the steps in the Pirolli and Card sensemaking loop [21]. 
The participants also  moved through the loop by using the roles of sensemaker and 
forager  so  that  the  two  major  areas  of  sensemaking  could  be  performed  synchro-
nously. The groups that adopted these roles tended to score higher. Taking all of these 
findings  into  account,  we  have  developed  design  implications  for  systems  that  use 
multiple input devices collaboratively on a large, vertical display. 

The application of co-located collaboration to other visual analytics tools should be 
further investigated in order to develop a more accurate set of guidelines for designing 
co-located collaborative systems on large displays. We are also interested in studying 
the impacts of spatially arranged data on co-located collaborative analysis.  
 
Acknowledgments.  This  research  was  supported  by  National  Science  Foundation 
grants NSF-IIS-0851774 and NSF-CCF-0937133. 

602 

K. Vogt et al. 

References 

1.  Thomas, J., Cook, K.: Illuminating the Path: The Research and Development Agenda for 

Visual Analytics (2005) 

2.  Heer,  J.:  Design  considerations  for  collaborative  visual  analytics.  Information Visualiza-

tion 7, 49–62 (2008) 

3.  Heuer, R.J., Pherson, R.H.: Structured Analytic Techniques for Intelligence Analysis. CQ 

Press, Washington, DC (2010) 

4.  Chin, G.: Exploring the analytical processes of intelligence analysts, p. 11 (2009) 
5.  Andrews, C., Endert, A., North, C.: Space to think: large high-resolution displays for sen-
semaking.  In:  Proceedings  of  the  28th  International  Conference  on  Human  Factors  in 
Computing Systems. ACM, Atlanta (2010) 

6.  Waltz, E.: The Knowledge-Based Intelligence Organization. In: Knowledge Management 

in the Intelligence Enterprise. Artech House, Boston (2003) 

7.  Stasko, J.: Jigsaw: supporting investigative analysis through interactive  visualization. In-

formation Visualization 7, 118–132 (2008) 

8.  Gutwin,  C.,  Greenberg,  S.:  Design  for  individuals,  design  for  groups:  tradeoffs  between 
power and workspace awareness. In: Proceedings of the 1998 ACM Conference on Com-
puter Supported Cooperative Work. ACM, Seattle (1998) 

9.  Stefik,  M.,  Foster,  G.,  Bobrow,  D.G.,  Kahn,  K.,  Lanning,  S.,  Suchman,  L.:  Beyond  the 
chalkboard: computer support for collaboration and problem solving in meetings. Commu-
nications of the ACM 30, 32–47 (1987) 

10.  Stewart, J.E.: Single display groupware. In: CHI 1997 Extended Abstracts On Human Fac-

tors In Computing Systems: Looking to The Future, pp. 71–72. ACM, Atlanta (1997) 

11.  Elrod, S., Bruce, R., Gold, R., Goldberg, D., Halasz, F., Janssen, W., Lee, D., McCall, K., 
Pederson, E., Pier, K., Tang, J., Welch, B.: Liveboard: a large interactive display support-
ing  group  meetings,  presentations,  and  remote  collaboration.  In:  Proceedings  of  the 
SIGCHI Conference on Human Factors in Computing Systems, pp. 599–607. ACM, Mon-
terey (1992) 

12.  Pedersen, E.R., McCall, K., Moran, T.P., Halasz, F.G.: Tivoli: an electronic whiteboard for 
informal  workgroup  meetings.  In:  Proceedings  of  the  INTERACT  1993  and  CHI  1993 
Conference  on  Human  Factors  in  Computing  Systems,  pp.  391–398.  ACM,  Amsterdam 
(1993) 

13.  Rekimoto, J.: A multiple device approach for supporting whiteboard-based interactions. In: 
Proceedings  of  the  SIGCHI  Conference  on  Human  Factors  in  Computing  Systems,  pp. 
344–351. ACM Press/Addison-Wesley Publishing Co., Los Angeles, California (1998) 

14.  Wallace, J., Scott, S., Stutz, T., Enns, T., Inkpen, K.: Investigating teamwork and taskwork 
in single- and multi-display groupware systems. Personal and Ubiquitous Computing 13, 
569–581 (2009) 

15.  Stewart, J., Raybourn, E.M., Bederson, B., Druin, A.: When two hands are better than one: 
enhancing collaboration using single display groupware. In: CHI 1998 Conference Sum-
mary on Human Factors in Computing Systems, pp. 287–288. ACM, Los Angeles (1998) 

16.  Stewart, J., Bederson, B.B., Druin, A.: Single display groupware: a model for co-present 
collaboration. In: Proceedings of the SIGCHI Conference on Human Factors in Computing 
Systems: the CHI is the Limit, pp. 286–293. ACM, Pittsburgh (1999) 

 
 

 

Co-located Collaborative Sensemaking on a Large High-Resolution Display 

603 

17.  Birnholtz,  J.P.,  Grossman,  T.,  Mak,  C.,  Balakrishnan,  R.:  An  exploratory  study  of  input 
configuration and group process in a negotiation task using a large display. In: Proceedings 
of  the  SIGCHI  Conference  on  Human  Factors  in  Computing  Systems.  ACM,  San  Jose 
(2007) 

18.  Robinson, A.: Collaborative Synthesis of Visual Analytic Results. IEEE Visual Analytics 

Science and Technology, 67–74 (2008) 

19.  Rogers, Y.,  Lim, Y.-k., Hazlewood, W.R., Marshall, P.: Equal Opportunities: Do Share-
able  Interfaces  Promote  More  Group  Participation  Than  Single  User  Displays?  Human–
Computer Interaction 24, 79–116 (2009) 

20.  Green, T.M., Ribarsky, W., Fisher, B.: Building and applying a human cognition model for 

visual analytics. Information Visualization 8, 1–13 (2009) 

21.  Pirolli, P., Card, S.: The Sensemaking Process and Leverage Points for Analyst Technol-
ogy as Identified Through Cognitive Task Analysis. In: International Conference on Intel-
ligence Analysis (2005) 

22.  Plaisant, C., Grinstein, G., Scholtz, J., Whiting, M., O’Connell, T., Laskowski, S., Chien, 
L., Tat, A., Wright, W., Gorg, C., Liu, Z., Parekh, N., Singhal, K., Stasko, J.: Evaluating 
Visual Analytics at the 2007 VAST Symposium Contest. In: Computer Graphics and Ap-
plications, vol. 28, pp. 12–21. IEEE, Los Alamitos (2008) 

23.  Paul, S.A., Reddy, M.C.: Understanding together: sensemaking in collaborative informa-
tion seeking. In: Proceedings of the 2010 ACM Conference on Computer Supported Coop-
erative Work, pp. 321–330. ACM, Savannah (2010) 

24.  Paul, S.A., Morris, M.R.: CoSense: enhancing sensemaking for collaborative web search. 
In: Proceedings of the 27th International Conference on Human Factors in Computing Sys-
tems, pp. 1771–1780. ACM, Boston (2009) 

25.  Morris, M.R., Lombardo, J., Wigdor, D.: WeSearch: supporting collaborative search and 
sensemaking  on  a  tabletop  display.  In:  Proceedings  of  the  2010  ACM  Conference  on 
Computer Supported Cooperative Work, pp. 401–410. ACM, Savannah (2010) 

26.  Pioch, N.J., Everett, J.O.: POLESTAR: collaborative knowledge management and sense-
making tools for intelligence analysts. In: Proceedings of the 15th ACM International Con-
ference  on  Information  and  Knowledge  Management,  pp.  513–521.  ACM,  Arlington 
(2006) 

27.  Tobiasz,  M.,  Isenberg,  P.,  Carpendale,  S.:  Lark:  Coordinating  Co-located  Collaboration 
with Information Visualization. IEEE Transactions on Visualization and Computer Graph-
ics 15, 1065–1072 (2009) 

28.  Isenberg, P., Fisher, D.: Collaborative Brushing and Linking for Co-located Visual Ana-

lytics of Document Collections. Computer Graphics Forum 28, 1031–1038 (2009) 

29.  Isenberg, P., Fisher, D., Morris, M.R., Inkpen, K., Czerwinski, M.: An exploratory study 
of co-located collaborative visual analytics around a tabletop display. In: 2010 IEEE Sym-
posium on Visual Analytics Science and Technology, VAST, pp. 179–186 (2010) 

30.  Ball,  R.,  North,  C.,  Bowman,  D.A.:  Move  to  improve:  promoting  physical  navigation  to 
increase user performance with large displays. In: Proceedings of the SIGCHI Conference 
on Human Factors in Computing Systems, pp. 191–200. ACM, San Jose (2007) 

31.  Wallace, G., Li, K.: Virtually shared displays and user input devices. In: 2007 Proceedings 
of the USENIX Annual Technical Conference, pp. 1–6. USENIX Association, Santa Clara 
(2007) 

32.  http://www.abisource.com/ 
 

604 

K. Vogt et al. 

33.  Kang,  Y.-a.,  Gorg,  C.,  Stasko,  J.:  Evaluating  visual  analytics  systems  for  investigative 
analysis: Deriving design principles from a case study. In: IEEE Visual Analytics Science 
and Technology, Atlantic City, NJ, pp. 139–146 (2009) 

34.  http://www.lri.fr/~isenberg/wiki/pmwiki.php?n=MyUniversity.P

eCoTo 

35.  Pickens, J.: Algorithmic mediation for collaborative exploratory search, p. 315 (2008) 
36.  Wright,  W.,  Schroh,  D.,  Proulx,  P.,  Skaburskis,  A.,  Cort,  B.:  The  Sandbox  for  analysis: 
concepts and methods. In: CHI 2006: Proceedings of the SIGCHI Conference on Human 
Factors in Computing Systems, pp. 801–810. ACM, New York (2006) 

37.  Patrick, G.S., Baudisch, P., Robertson, G., Czerwinski, M., Meyers, B., Robbins, D., An-

drews, D.: GroupBar: The TaskBar Evolved. In: OZCHI, pp. 34–43 (2003) 

","{""pos"":{""0"":1,""1"":2,""2"":3,""3"":4,""4"":5,""5"":6},""4"":{""0"":""acm*"",""1"":""sensemaker"",""2"":""sdg"",""3"":""sigchi*"",""4"":""ieee*"",""5"":""elon*""},""3"":{""0"":""b"",""1"":""j"",""2"":""t1"",""3"":""p"",""4"":""r*"",""5"":""m*""},""1"":{""0"":""jigsaw"",""1"":""groups*"",""2"":""participants"",""3"":""activities"",""4"":""tools"",""5"":""analytics""},""0"":{""0"":""2010*"",""1"":""2009*"",""2"":""1998*"",""3"":""2007"",""4"":""2011*"",""5"":""1993""},""2"":{""0"":""a"",""1"":""displays"",""2"":""single"",""3"":""record"",""4"":""closely"",""5"":""defined*""}}",2011,{},False,False,bookSection,False,LXQ5QRAX,"[{u'tag': u'co-located'}, {u'tag': u'collaborative'}, {u'tag': u'large display'}, {u'tag': u'sensemaking'}]",self.user,"{""Unnamed: 0"":{""0"":0,""1"":1,""2"":2,""3"":3,""4"":4,""5"":5,""6"":6,""7"":7,""8"":8,""9"":9,""10"":10,""11"":11,""12"":12,""13"":13,""14"":14,""15"":15,""16"":16,""17"":17,""18"":18,""19"":19,""20"":20,""21"":21,""22"":22,""23"":23,""24"":24,""25"":25,""26"":26,""27"":27,""28"":28,""29"":29,""30"":30,""31"":31,""32"":32,""33"":33,""34"":34,""35"":35,""36"":36,""37"":37,""38"":38,""39"":39,""40"":40,""41"":41,""42"":42,""43"":43,""44"":44,""45"":45,""46"":46,""47"":47,""48"":48,""49"":49,""50"":50,""51"":51,""52"":52,""53"":53,""54"":54,""55"":55,""56"":56,""57"":57,""58"":58,""59"":59,""60"":60,""61"":61,""62"":62,""63"":63,""64"":64,""65"":65,""66"":66,""67"":67,""68"":68,""69"":69,""70"":70,""71"":71,""72"":72,""73"":73,""74"":74,""75"":75,""76"":76,""77"":77,""78"":78,""79"":79},""C"":{""0"":4.6908997161,""1"":8.0670535205,""2"":5.0745766385,""3"":14.2954450268,""4"":6.65446301,""5"":4.9751845884,""6"":8.3406051713,""7"":8.8845218409,""8"":6.8604348068,""9"":9.3225357833,""10"":7.5215109035,""11"":6.4770784228,""12"":11.044301746,""13"":22.4848462356,""14"":12.6821461087,""15"":7.8558924032,""16"":14.9690838745,""17"":19.4720833113,""18"":5.3124834593,""19"":8.1557720895,""20"":9.8962088534,""21"":16.3120122328,""22"":5.4535728448,""23"":15.086125692,""24"":10.2498890177,""25"":9.4430009786,""26"":4.6576689453,""27"":7.3308383497,""28"":4.8387591811,""29"":13.8776070201,""30"":12.3196409533,""31"":8.7326907562,""32"":6.4011594951,""33"":4.9965956404,""34"":7.6985387578,""35"":12.2599694285,""36"":11.8459497325,""37"":7.0935753046,""38"":10.7072919141,""39"":12.0621598804,""40"":9.4443245063,""41"":5.6671537389,""42"":5.4501774538,""43"":4.2734372127,""44"":5.8303652133,""45"":5.1442905316,""46"":8.7118466826,""47"":7.9800532629,""48"":11.7607893275,""49"":4.1895034387,""50"":4.513426258,""51"":7.3890523768,""52"":4.2161541341,""53"":9.651775022,""54"":6.2757610159,""55"":4.3264897502,""56"":5.1580717922,""57"":5.0384252463,""58"":8.1646739504,""59"":6.2314239677,""60"":4.2167151811,""61"":7.1832484582,""62"":4.7272539562,""63"":4.8635302397,""64"":6.3371260936,""65"":6.2056744232,""66"":5.3760686066,""67"":6.5755015422,""68"":5.5022564003,""69"":4.2858543679,""70"":4.7091884595,""71"":4.6868961703,""72"":4.6336421657,""73"":4.6824484547,""74"":4.3423164516,""75"":4.4891654078,""76"":4.4843223606,""77"":4.4501711782,""78"":4.3115753798,""79"":4.6869167432},""count"":{""0"":110,""1"":82,""2"":78,""3"":74,""4"":72,""5"":62,""6"":62,""7"":50,""8"":46,""9"":44,""10"":42,""11"":42,""12"":40,""13"":40,""14"":38,""15"":38,""16"":36,""17"":36,""18"":34,""19"":32,""20"":30,""21"":30,""22"":28,""23"":28,""24"":26,""25"":26,""26"":26,""27"":26,""28"":26,""29"":26,""30"":24,""31"":24,""32"":22,""33"":22,""34"":22,""35"":22,""36"":22,""37"":20,""38"":20,""39"":18,""40"":18,""41"":16,""42"":16,""43"":16,""44"":16,""45"":16,""46"":16,""47"":16,""48"":14,""49"":14,""50"":14,""51"":14,""52"":14,""53"":14,""54"":14,""55"":12,""56"":12,""57"":12,""58"":12,""59"":12,""60"":10,""61"":10,""62"":10,""63"":10,""64"":10,""65"":10,""66"":8,""67"":8,""68"":8,""69"":8,""70"":6,""71"":6,""72"":6,""73"":6,""74"":6,""75"":6,""76"":6,""77"":6,""78"":6,""79"":6},""sigma_nor"":{""0"":1.4132559995,""1"":1.8208530626,""2"":1.5207097127,""3"":2.5365124967,""4"":1.7128810479,""5"":1.5618657023,""6"":1.9580406432,""7"":2.1180813427,""8"":1.8859228588,""9"":2.23732015,""10"":2.0103013636,""11"":1.8651675913,""12"":2.529312357,""13"":4.15139069,""14"":2.7977632278,""15"":2.0989787708,""16"":3.1747974118,""17"":3.8412153192,""18"":1.7615853601,""19"":2.219569261,""20"":2.5258536039,""21"":3.5464483546,""22"":1.8392007159,""23"":3.4128261139,""24"":2.6666759685,""25"":2.5310990842,""26"":1.727046507,""27"":2.176204211,""28"":1.7574740865,""29"":3.2762211347,""30"":3.0726249556,""31"":2.4516961855,""32"":2.0785594591,""33"":1.8275881119,""34"":2.3103787674,""35"":3.1254277925,""36"":3.0514496102,""37"":2.2396939103,""38"":2.9076257903,""39"":3.2328770453,""40"":2.7311447031,""41"":2.041179084,""42"":1.9979376003,""43"":1.7634235199,""44"":2.0737057092,""45"":1.936977001,""46"":2.6479598678,""47"":2.5021198133,""48"":3.3449320512,""49"":1.7709493003,""50"":1.8382891073,""51"":2.4360985118,""52"":1.7764896716,""53"":2.9064923743,""54"":2.2046581165,""55"":1.8262690184,""56"":2.0072615313,""57"":1.9812206503,""58"":2.6616437236,""59"":2.2408749303,""60"":1.8284424955,""61"":2.5072005746,""62"":1.9452563944,""63"":1.9764371093,""64"":2.3136034236,""65"":2.283526605,""66"":2.1321490136,""67"":2.42192253,""68"":2.1626349871,""69"":1.8687618711,""70"":1.9915307599,""71"":1.985822683,""72"":1.9721866698,""73"":1.9846838183,""74"":1.8975909409,""75"":1.9351925133,""76"":1.9339524215,""77"":1.9252078026,""78"":1.8897195017,""79"":1.9858279508},""vocab_index"":{""0"":0,""1"":3,""2"":4,""3"":5,""4"":6,""5"":9,""6"":10,""7"":16,""8"":18,""9"":20,""10"":22,""11"":24,""12"":26,""13"":27,""14"":28,""15"":29,""16"":32,""17"":35,""18"":38,""19"":40,""20"":43,""21"":44,""22"":49,""23"":50,""24"":51,""25"":54,""26"":56,""27"":58,""28"":59,""29"":60,""30"":68,""31"":69,""32"":72,""33"":75,""34"":76,""35"":77,""36"":78,""37"":86,""38"":87,""39"":95,""40"":96,""41"":97,""42"":101,""43"":104,""44"":107,""45"":108,""46"":109,""47"":110,""48"":117,""49"":127,""50"":128,""51"":129,""52"":130,""53"":131,""54"":132,""55"":149,""56"":151,""57"":154,""58"":155,""59"":157,""60"":180,""61"":189,""62"":190,""63"":191,""64"":192,""65"":193,""66"":240,""67"":247,""68"":250,""69"":251,""70"":254,""71"":268,""72"":284,""73"":321,""74"":333,""75"":346,""76"":356,""77"":358,""78"":361,""79"":362},""word"":{""0"":""sensemaking"",""1"":""documents"",""2"":""jigsaw"",""3"":""groups"",""4"":""text"",""5"":""editor"",""6"":""participants"",""7"":""activities"",""8"":""visual"",""9"":""a"",""10"":""tools"",""11"":""analytics"",""12"":""t4"",""13"":""acm"",""14"":""systems"",""15"":""b"",""16"":""pp"",""17"":""j"",""18"":""loop"",""19"":""t1"",""20"":""scenario"",""21"":""conference"",""22"":""activity"",""23"":""proceedings"",""24"":""computing"",""25"":""p"",""26"":""displays"",""27"":""single"",""28"":""tool"",""29"":""human"",""30"":""entities"",""31"":""cluster"",""32"":""factors"",""33"":""record"",""34"":""review"",""35"":""r"",""36"":""m"",""37"":""forager"",""38"":""d"",""39"":""closely"",""40"":""c"",""41"":""teams"",""42"":""groupware"",""43"":""time"",""44"":""defined"",""45"":""sensemaker"",""46"":""2010"",""47"":""2009"",""48"":""sdg"",""49"":""connect"",""50"":""extract"",""51"":""important"",""52"":""clusters"",""53"":""reread"",""54"":""worked"",""55"":""table"",""56"":""connections"",""57"":""hypotheses"",""58"":""spent"",""59"":""sigchi"",""60"":""notes"",""61"":""1998"",""62"":""chi"",""63"":""w"",""64"":""2007"",""65"":""ieee"",""66"":""clustered"",""67"":""coupled"",""68"":""established"",""69"":""clearly"",""70"":""elon"",""71"":""2011"",""72"":""wysiwis"",""73"":""tutorial"",""74"":""color"",""75"":""scenarios"",""76"":""integrate"",""77"":""application"",""78"":""meetings"",""79"":""1993""},""vector"":{""0"":""[ 0.9853743  -4.1309624  -0.8104559  -0.28147185  5.1932945   1.8965029\n -1.4442573   0.9057677   2.038501    0.617555  ]"",""1"":""[ 0.11855584 -3.991004   -1.1823719  -0.7642258   5.5356827   1.8804623\n -2.4454677   1.9622762   2.5225158   1.2621365 ]"",""2"":""[ 0.423181  -4.0544567 -0.9842292 -1.2352941  5.384193   2.0415776\n -2.1466296  2.2717307  1.6757814  1.3998159]"",""3"":""[ 0.8361948  -3.813132   -0.8980397  -1.399027    5.631975    1.9705253\n -2.903788    1.9493514   2.1229916   0.94128275]"",""4"":""[ 0.09489692 -4.1042047  -1.2782309  -0.347742    5.3488755   1.9614494\n -1.2586007   1.4555719   2.6488624   1.4826487 ]"",""5"":""[ 0.36426562 -4.180231   -1.1298289  -0.5031003   5.448443    1.8623317\n -1.52306     1.5719508   2.2084272   1.1882774 ]"",""6"":""[ 0.70148665 -3.865285   -0.9385465  -1.1924573   5.840929    1.6794815\n -2.8547156   1.8161404   2.1942446   0.81760377]"",""7"":""[ 0.36259055 -4.100958   -0.7972375  -1.0172222   5.7297115   1.7388018\n -2.831535    2.008523    2.056251    0.9006855 ]"",""8"":""[-0.08272786 -4.086663   -0.7390968  -0.8070763   4.734172    2.5600522\n -1.1842281   2.012482    2.1034317   2.046526  ]"",""9"":""[-0.42030236 -4.026227   -0.7060548  -0.78946024  4.8150845   2.580766\n -1.4521527   2.2479088   2.0839655   2.1836052 ]"",""10"":""[ 0.64026827 -3.9653072  -1.0778263  -1.1952806   5.1579127   2.1692405\n -2.275145    2.177108    1.8178374   1.2729483 ]"",""11"":""[ 0.8309291 -3.9306903 -1.0093526 -1.1808541  5.2485332  2.06231\n -2.2428882  1.9345832  1.7981102  1.102946 ]"",""12"":""[ 0.55947304 -4.2284884  -0.9801802   0.28862524  5.1451373   1.9240292\n -0.3868523   0.59154856  2.457123    0.9255571 ]"",""13"":""[ 0.8271343  -4.0609984  -0.9533456   0.04956508  5.1470933   1.7497382\n -0.6965326   0.5338707   2.3082201   0.65061545]"",""14"":""[ 0.68123627 -3.8441267  -0.9883691  -1.3819677   5.332589    2.2408087\n -2.6783092   2.101334    2.073861    1.2151492 ]"",""15"":""[ 0.09889758 -4.3394833  -1.107395   -0.08011413  5.07575     2.25202\n -0.23984927  0.983028    2.7561083   1.856904  ]"",""16"":""[ 0.06789592 -4.112207   -1.2433364  -0.03218715  4.983017    2.1591938\n -0.88974434  1.1099632   3.0189722   1.5155784 ]"",""17"":""[ 0.44495988 -4.17728    -1.1181743   0.1037955   4.989127    2.1212473\n -0.23637263  0.6952037   2.7755945   1.3928322 ]"",""18"":""[ 0.17031562 -4.1372743  -0.6069903  -1.1711031   5.347168    2.296653\n -2.6981518   2.3067555   1.9817421   1.3792255 ]"",""19"":""[ 0.49172744 -4.202087   -1.066005    0.24309587  5.122014    1.9709685\n -0.39151463  0.6843014   2.5671065   1.0466607 ]"",""20"":""[ 0.25631705 -3.8112478  -1.1805341  -1.4057006   5.8311787   1.7255012\n -2.3618689   2.3868175   1.7931054   1.4279649 ]"",""21"":""[ 0.39913797 -3.998364   -0.84997    -0.6063159   5.552439    1.7156864\n -2.357588    1.3640715   2.3538883   0.7798417 ]"",""22"":""[ 0.2855601 -4.19418   -0.6869472 -1.0164661  5.667875   1.7882628\n -2.387879   2.082497   1.7958575  1.0679269]"",""23"":""[ 0.14900202 -4.118058   -0.87150097 -0.7658735   5.7143946   1.6302694\n -2.600631    1.7993572   2.1672618   0.9778095 ]"",""24"":""[ 0.7131777 -3.951884  -0.6834007 -0.8640398  4.892154   2.4575686\n -2.3706677  1.585441   2.1754534  1.0110036]"",""25"":""[ 0.23247193 -4.1718698  -1.2414781  -0.14495714  5.0233955   2.1736293\n -0.6282027   0.9381042   3.1382492   1.4921303 ]"",""26"":""[-0.48798415 -4.0644736  -0.7384814  -0.694996    4.4860573   2.771936\n -1.5852171   2.1162603   2.8211122   2.1764755 ]"",""27"":""[-0.15600121 -4.033254   -0.7305943  -0.9726072   5.0705085   2.3533332\n -1.6319493   2.1331925   2.0868542   1.9023947 ]"",""28"":""[ 0.18059354 -4.060983   -1.0233059  -1.0353557   5.3243885   2.012853\n -1.9978924   2.2792785   1.7486484   1.4770069 ]"",""29"":""[ 0.03660912 -4.076564   -0.71433216 -0.9275562   4.7993145   2.5083172\n -1.2928101   2.040003    1.9943588   1.9490551 ]"",""30"":""[ 0.6898532 -3.8557856 -1.0527021 -1.3772275  5.5764575  2.0688472\n -2.9637084  2.0836318  2.236258   1.0583469]"",""31"":""[ 0.37905276 -3.9834845  -0.6017443  -0.8987077   4.7561007   2.6659422\n -2.4397855   1.8825594   2.2322545   1.3215628 ]"",""32"":""[ 0.69519717 -3.78168    -1.0510131  -1.5119141   5.607694    1.9827118\n -2.8022065   2.2628472   1.8891577   1.1694862 ]"",""33"":""[-0.38275182 -4.0098286  -0.90882605 -0.8289359   5.2417035   2.1859336\n -1.7468449   2.1946723   2.2745085   1.9220803 ]"",""34"":""[-0.33891422 -4.248027   -0.77154905 -0.4975947   5.222014    2.1981664\n -2.1410544   2.0467322   2.107814    1.5366949 ]"",""35"":""[ 0.19015196 -4.106262   -1.2053713  -0.0198725   5.1003      2.0103354\n -0.21977249  0.8393191   2.9434395   1.5523976 ]"",""36"":""[ 0.20872246 -4.1722026  -1.2574735   0.1337017   4.969493    2.2124228\n -0.18742524  0.8733504   2.9348373   1.6154585 ]"",""37"":""[ 0.61164844 -4.182162   -0.9828203  -0.6213291   5.481658    1.8124471\n -1.6427194   1.4652016   2.0368483   0.9611452 ]"",""38"":""[ 0.02997127 -4.271714   -1.232388    0.11166708  5.0682125   2.2589283\n -0.31363383  1.0400851   2.877194    1.7128078 ]"",""39"":""[-0.5425252  -4.10075    -0.522086   -0.64816695  4.5184407   3.0786598\n -2.039854    2.3773704   2.3750753   2.194248  ]"",""40"":""[ 0.19125807 -4.1219316  -1.0970948  -0.05582009  4.9529266   2.1830597\n -0.25883812  1.0008084   2.7455478   1.7543998 ]"",""41"":""[ 0.822435   -3.8011227  -1.0436795  -1.370599    5.6920605   1.8236085\n -2.7096598   1.9392318   2.0472724   0.98372966]"",""42"":""[ 1.0029641  -4.122003   -0.72545767 -0.14645492  5.057041    2.027527\n -1.3869169   0.7974112   2.125901    0.6279755 ]"",""43"":""[-0.3862045  -3.9486494  -1.0122848  -0.95638293  5.3234015   2.1129415\n -1.6634414   2.3925426   1.9591144   2.0139456 ]"",""44"":""[-0.7296052 -4.086768  -0.543249  -0.4643529  4.2830586  3.0778756\n -1.8168982  2.2453058  2.589806   2.2924216]"",""45"":""[ 0.869976   -4.2198687  -0.82813185  0.16116402  5.1147275   1.9370317\n -0.82073027  0.63004297  2.2149982   0.69846994]"",""46"":""[-0.3253604 -3.774291  -1.4510827 -1.2868563  6.0681195  1.4287852\n -1.5221713  2.4708743  1.6479912  1.9392016]"",""47"":""[-0.31166795 -3.8165731  -1.449075   -1.396391    6.0797772   1.4183991\n -1.4615872   2.5796616   1.5171156   2.014212  ]"",""48"":""[ 0.655632   -4.0744567  -1.0223465  -0.01924374  5.2390475   1.752436\n -1.1092278   0.6585421   2.3756754   0.6464435 ]"",""49"":""[-0.68537474 -4.185869   -0.4728233  -0.46042788  4.3706346   2.9183893\n -2.1157546   2.1201935   2.7620113   2.0044045 ]"",""50"":""[-0.6161946  -4.2198544  -0.81328195 -0.3361283   4.8597627   2.6214664\n -2.0843256   2.04924     2.710136    1.8670468 ]"",""51"":""[-0.60832036 -4.0102644  -0.7115178  -0.5981294   4.604417    2.8275206\n -1.6142828   2.3465564   2.235814    2.3051703 ]"",""52"":""[ 0.52125067 -3.9213142  -0.6644247  -0.9486637   4.866293    2.5980997\n -2.6299763   1.8100839   2.3439178   1.1872183 ]"",""53"":""[-0.7980452  -4.185092   -0.69104236 -0.2509399   4.6839895   2.7380204\n -2.1254597   2.172337    2.4803987   1.9854695 ]"",""54"":""[-0.8759545  -4.0906324  -0.48805535 -0.3668953   4.1711445   3.2123234\n -2.0868123   2.3186824   2.5345747   2.2888854 ]"",""55"":""[-0.1627926  -3.9546318  -1.2531146  -0.61678123  5.2687564   2.130464\n -1.6043146   1.9302948   2.67411     1.7621784 ]"",""56"":""[ 0.28010654 -4.0892997  -0.64736205 -1.1422987   5.4020233   2.2284915\n -2.9189527   2.1928053   2.1296117   1.1896285 ]"",""57"":""[ 0.505985  -3.8083403 -1.1310079 -1.4277765  5.799728   1.7907069\n -2.7354014  2.282189   1.9088151  1.1789533]"",""58"":""[-0.91303384 -3.9959202  -0.62138647 -0.19989648  4.2039304   3.1058156\n -2.167781    2.2426434   2.4736001   2.1897805 ]"",""59"":""[ 0.9049819  -4.1100955  -0.84492594 -0.05740087  5.206107    1.7961996\n -1.2143672   0.66460043  2.1575525   0.50991786]"",""60"":""[-0.12502028 -4.019704   -1.1842026  -0.59044266  5.319414    2.0516534\n -1.8340873   1.918346    2.5867047   1.6014812 ]"",""61"":""[-0.22238982 -3.8690922  -1.345342   -1.2712827   5.861312    1.6167631\n -1.3971545   2.4855554   1.7262836   2.0490265 ]"",""62"":""[ 0.36818027 -4.000402   -1.1714846   0.05159982  4.9548545   2.051224\n -0.3047748   0.7598237   2.963534    1.3608913 ]"",""63"":""[ 0.06896315 -4.141124   -1.1517828  -0.23063564  5.152768    2.1012142\n -0.17409393  1.1267781   2.654711    1.8956879 ]"",""64"":""[-0.43751788 -3.735089   -1.576864   -1.282282    6.114454    1.365902\n -1.4188225   2.4515302   1.6329458   2.0697343 ]"",""65"":""[ 0.7266608  -4.1739707  -0.8912098   0.11713996  5.1012735   2.0125685\n -0.93170816  0.7100547   2.27366     0.7098908 ]"",""66"":""[-0.29081786 -4.0480905  -0.47878534 -0.64080286  4.3617535   3.0938811\n -2.30667     2.1471014   2.4693263   1.8821728 ]"",""67"":""[-0.58482337 -4.132359   -0.47509193 -0.591779    4.1444564   3.2000847\n -1.8214047   2.1719024   2.7911913   2.262257  ]"",""68"":""[-0.9176592 -4.0480895 -0.6241931 -0.2905695  4.2553215  3.2229922\n -2.03462    2.3391669  2.420783   2.3421922]"",""69"":""[-0.5837695 -4.0456114 -0.7041847 -0.6536388  4.594891   2.8171296\n -1.5881937  2.2666976  2.5063744  2.2893586]"",""70"":""[ 0.7583049  -4.1451845  -0.96456563  0.14877062  5.0558085   1.9093294\n -0.53943866  0.5397867   2.3964353   0.9091833 ]"",""71"":""[-0.3172972 -3.8192368 -1.4599527 -1.3919023  6.0861516  1.4064714\n -1.4284036  2.5706978  1.5245615  2.0400639]"",""72"":""[ 0.8313613  -4.196098   -0.78193426 -0.06859471  5.173599    1.9834114\n -1.1242194   0.9608327   2.0768533   0.75901806]"",""73"":""[ 0.52405846 -4.0259137  -0.720406   -0.5731544   5.054057    2.2088237\n -2.144159    1.3972694   2.2107801   0.9366504 ]"",""74"":""[ 0.09418833 -4.1417723  -1.2334833  -0.2618229   5.195472    2.1039066\n -0.8384546   1.29014     2.7462      1.6537396 ]"",""75"":""[ 0.49232787 -3.7671099  -1.1660563  -1.3715755   5.7213955   1.848197\n -2.688814    2.2838612   1.9631219   1.2261703 ]"",""76"":""[-0.7176123 -4.2092752 -0.645601  -0.3454131  4.555391   3.0023472\n -2.2483165  2.2037022  2.6503239  2.0366974]"",""77"":""[ 0.18327585 -4.1528807  -0.82222956 -0.88731915  5.3394394   2.0002005\n -2.2590313   2.0919018   1.8572576   1.2537526 ]"",""78"":""[ 0.28799275 -4.0154257  -0.852206   -0.7985752   5.6640787   1.7675238\n -2.6902437   1.7434253   2.3602114   0.8961142 ]"",""79"":""[-0.32626528 -3.7685077  -1.443769   -1.2476852   5.8418293   1.6289867\n -1.3810704   2.4736938   1.8001069   1.933399  ]""},""topic"":{""0"":-1,""1"":-1,""2"":1,""3"":1,""4"":-1,""5"":-1,""6"":1,""7"":1,""8"":-1,""9"":2,""10"":1,""11"":1,""12"":-1,""13"":4,""14"":1,""15"":3,""16"":-1,""17"":3,""18"":1,""19"":3,""20"":1,""21"":-1,""22"":1,""23"":1,""24"":-1,""25"":3,""26"":2,""27"":2,""28"":1,""29"":-1,""30"":1,""31"":-1,""32"":1,""33"":2,""34"":-1,""35"":3,""36"":3,""37"":-1,""38"":3,""39"":2,""40"":3,""41"":1,""42"":-1,""43"":-1,""44"":2,""45"":4,""46"":0,""47"":0,""48"":4,""49"":2,""50"":-1,""51"":2,""52"":-1,""53"":2,""54"":2,""55"":-1,""56"":1,""57"":1,""58"":2,""59"":4,""60"":2,""61"":0,""62"":3,""63"":3,""64"":0,""65"":4,""66"":2,""67"":2,""68"":2,""69"":2,""70"":4,""71"":0,""72"":4,""73"":-1,""74"":-1,""75"":1,""76"":2,""77"":1,""78"":1,""79"":0},""exemplar"":{""0"":null,""1"":null,""2"":null,""3"":""*"",""4"":null,""5"":null,""6"":null,""7"":null,""8"":null,""9"":null,""10"":null,""11"":null,""12"":null,""13"":""*"",""14"":null,""15"":null,""16"":null,""17"":null,""18"":null,""19"":null,""20"":null,""21"":null,""22"":null,""23"":null,""24"":null,""25"":null,""26"":null,""27"":null,""28"":null,""29"":null,""30"":""*"",""31"":null,""32"":""*"",""33"":null,""34"":null,""35"":""*"",""36"":""*"",""37"":null,""38"":""*"",""39"":null,""40"":""*"",""41"":""*"",""42"":null,""43"":null,""44"":""*"",""45"":null,""46"":""*"",""47"":""*"",""48"":null,""49"":""*"",""50"":null,""51"":null,""52"":null,""53"":null,""54"":""*"",""55"":null,""56"":null,""57"":null,""58"":""*"",""59"":""*"",""60"":null,""61"":""*"",""62"":null,""63"":null,""64"":null,""65"":""*"",""66"":null,""67"":null,""68"":null,""69"":null,""70"":""*"",""71"":""*"",""72"":""*"",""73"":null,""74"":null,""75"":null,""76"":null,""77"":null,""78"":null,""79"":null},""word*"":{""0"":""sensemaking"",""1"":""documents"",""2"":""jigsaw"",""3"":""groups*"",""4"":""text"",""5"":""editor"",""6"":""participants"",""7"":""activities"",""8"":""visual"",""9"":""a"",""10"":""tools"",""11"":""analytics"",""12"":""t4"",""13"":""acm*"",""14"":""systems"",""15"":""b"",""16"":""pp"",""17"":""j"",""18"":""loop"",""19"":""t1"",""20"":""scenario"",""21"":""conference"",""22"":""activity"",""23"":""proceedings"",""24"":""computing"",""25"":""p"",""26"":""displays"",""27"":""single"",""28"":""tool"",""29"":""human"",""30"":""entities*"",""31"":""cluster"",""32"":""factors*"",""33"":""record"",""34"":""review"",""35"":""r*"",""36"":""m*"",""37"":""forager"",""38"":""d*"",""39"":""closely"",""40"":""c*"",""41"":""teams*"",""42"":""groupware"",""43"":""time"",""44"":""defined*"",""45"":""sensemaker"",""46"":""2010*"",""47"":""2009*"",""48"":""sdg"",""49"":""connect*"",""50"":""extract"",""51"":""important"",""52"":""clusters"",""53"":""reread"",""54"":""worked*"",""55"":""table"",""56"":""connections"",""57"":""hypotheses"",""58"":""spent*"",""59"":""sigchi*"",""60"":""notes"",""61"":""1998*"",""62"":""chi"",""63"":""w"",""64"":""2007"",""65"":""ieee*"",""66"":""clustered"",""67"":""coupled"",""68"":""established"",""69"":""clearly"",""70"":""elon*"",""71"":""2011*"",""72"":""wysiwis*"",""73"":""tutorial"",""74"":""color"",""75"":""scenarios"",""76"":""integrate"",""77"":""application"",""78"":""meetings"",""79"":""1993""},""pos"":{""0"":1,""1"":2,""2"":1,""3"":2,""4"":3,""5"":4,""6"":3,""7"":4,""8"":5,""9"":1,""10"":5,""11"":6,""12"":6,""13"":1,""14"":7,""15"":1,""16"":7,""17"":2,""18"":8,""19"":3,""20"":9,""21"":8,""22"":10,""23"":11,""24"":9,""25"":4,""26"":2,""27"":3,""28"":12,""29"":10,""30"":13,""31"":11,""32"":14,""33"":4,""34"":12,""35"":5,""36"":6,""37"":13,""38"":7,""39"":5,""40"":8,""41"":15,""42"":14,""43"":15,""44"":6,""45"":2,""46"":1,""47"":2,""48"":3,""49"":7,""50"":16,""51"":8,""52"":17,""53"":9,""54"":10,""55"":18,""56"":16,""57"":17,""58"":11,""59"":4,""60"":12,""61"":3,""62"":9,""63"":10,""64"":4,""65"":5,""66"":13,""67"":14,""68"":15,""69"":16,""70"":6,""71"":5,""72"":7,""73"":19,""74"":20,""75"":18,""76"":17,""77"":19,""78"":20,""79"":6},""x2D"":{""0"":-7.2152571678,""1"":5.530023098,""2"":6.4752650261,""3"":6.5774688721,""4"":-9.5579633713,""5"":4.5124635696,""6"":6.5142855644,""7"":6.0911793709,""8"":3.0621006489,""9"":2.8265185356,""10"":6.2823338509,""11"":6.4356765747,""12"":-8.0283546448,""13"":-7.6364703178,""14"":6.6713023186,""15"":-9.3794755936,""16"":-9.1710147858,""17"":-8.7789201736,""18"":6.1003451347,""19"":-8.2002534866,""20"":7.116394043,""21"":5.2828836441,""22"":5.9397172928,""23"":5.7869653702,""24"":5.2871408463,""25"":-9.0760412216,""26"":2.1423869133,""27"":3.4582002163,""28"":5.8679580688,""29"":3.2260735035,""30"":6.6989393234,""31"":5.4116024971,""32"":6.8408899307,""33"":3.6518867016,""34"":3.975124836,""35"":-9.0304851532,""36"":-9.0520515442,""37"":4.7744626999,""38"":-9.4560785294,""39"":1.80849123,""40"":-9.2617616653,""41"":6.8225975037,""42"":-7.4633803368,""43"":3.5940060616,""44"":1.5539780855,""45"":-7.7277317047,""46"":-0.3162264228,""47"":-0.0981571004,""48"":-7.3900036812,""49"":1.4284687042,""50"":1.7043945789,""51"":2.246670723,""52"":5.5116991997,""53"":1.4984422922,""54"":1.208042264,""55"":3.7516009808,""56"":6.1863260269,""57"":6.888733387,""58"":1.1041728258,""59"":-7.4052171707,""60"":3.9242002964,""61"":-0.0337510742,""62"":-8.6476650238,""63"":-9.4739589691,""64"":-0.3335348964,""65"":-7.4939808846,""66"":1.6056995392,""67"":1.4523637295,""68"":1.19670856,""69"":2.1600561142,""70"":-7.9198899269,""71"":-0.2222147733,""72"":-7.5103826523,""73"":5.0350570679,""74"":-9.3741283417,""75"":7.0834922791,""76"":1.5575875044,""77"":5.8404593468,""78"":5.7939476967,""79"":-0.3455683887},""y2D"":{""0"":-1.5944516659,""1"":-1.503366828,""2"":-0.0630584657,""3"":-1.5537298918,""4"":0.7274229527,""5"":-0.9595868587,""6"":-1.6755459309,""7"":-1.6267915964,""8"":1.0674338341,""9"":1.2138620615,""10"":-0.4541906714,""11"":-0.4056697786,""12"":-0.7623993158,""13"":-0.9636082053,""14"":-0.797771275,""15"":-0.0924023762,""16"":0.3720219731,""17"":-0.2444913238,""18"":-0.6105365753,""19"":-0.6033610702,""20"":-0.8315322399,""21"":-1.3356463909,""22"":-1.083209753,""23"":-1.4096118212,""24"":-0.5269476771,""25"":0.1808012277,""26"":0.6405328512,""27"":1.2830878496,""28"":0.0299161896,""29"":1.2016282082,""30"":-1.2694823742,""31"":-0.3812164366,""32"":-1.16492033,""33"":1.0681566,""34"":0.9350822568,""35"":-0.2966255248,""36"":-0.2717289031,""37"":-1.1627477407,""38"":-0.1918439865,""39"":0.5884705782,""40"":0.0687198117,""41"":-1.4330196381,""42"":-1.7150354385,""43"":1.4573870897,""44"":0.406674087,""45"":-1.1234151125,""46"":2.702303648,""47"":2.4192187786,""48"":-1.2659549713,""49"":0.9446148872,""50"":1.2730033398,""51"":1.0198844671,""52"":-0.6264474988,""53"":1.2476712465,""54"":0.6755188107,""55"":1.0992105007,""56"":-0.8908135295,""57"":-1.0851415396,""58"":0.7090591192,""59"":-1.3855403662,""60"":0.7270039916,""61"":2.4317166805,""62"":-0.1016612872,""63"":-0.0127522992,""64"":2.720228672,""65"":-0.9828122854,""66"":0.981433928,""67"":0.3896967173,""68"":0.55914855,""69"":0.7104976773,""70"":-0.9068923593,""71"":2.6100683212,""72"":-1.5272173882,""73"":-0.8641164899,""74"":0.4347994924,""75"":-1.0292254686,""76"":0.9219046235,""77"":-0.2082895339,""78"":-1.6217033863,""79"":2.7458870411}}",False,False,False,http://link.springer.com/10.1007/978-3-642-23771-3_44,,Co-located Collaborative Sensemaking on a Large High-Resolution Display with Multiple Input Devices,LXQ5QRAX,False,False
