index,pdf_file,text,topics,year,author,clusterID,citations,type,abstract,globalID,tags,user,words,pages,citationsList,versions,url,notes,title,bert_vector,parent_item,organization,citationArticles,vec_2d
7YWBXAWZ,N6NB5V6C,"Volume xx (200y), Number z, pp. 1–29

8
1
0
2

 

b
e
F
2
2

 

 
 
]
L
M

.
t
a
t
s
[
 
 

1
v
4
5
9
7
0

.

2
0
8
1
:
v
i
X
r
a

The State of the Art in

Integrating Machine Learning into Visual Analytics

A. Endert1, W. Ribarsky2, C. Turkay3, W. Wong4, I. Nabney5, I. D´ıaz Blanco6, F. Rossi7

1Georgia Tech, USA

2University of North Carolina, Charlotte, USA

3City University of London, UK

4Middlesex University, UK

5Aston University, UK

6University of Oviedo, Spain

7Paris 1 Panth´eon Sorbonne University, Paris

Abstract
Visual analytics systems combine machine learning or other analytic techniques with interactive data visualization
to promote sensemaking and analytical reasoning. It is through such techniques that people can make sense of large,
complex data. While progress has been made, the tactful combination of machine learning and data visualization
is still under-explored. This state-of-the-art report presents a summary of the progress that has been made by
highlighting and synthesizing select research advances. Further, it presents opportunities and challenges to enhance
the synergy between machine learning and visual analytics for impactful future research directions.

Categories and Subject Descriptors (according to ACM CCS): Human-centered computing - Visualization, Visual
analytics

1. Introduction

We are in a data-driven era. Increasingly more domains
generate and consume data. People have the potential to un-
derstand phenomena in more depth using new data analysis
techniques. Additionally, new phenomena can be uncovered
in domains where data is becoming available. Thus, making
sense of data is becoming increasingly important, and this is
driving the need for systems that enable people to analyze
and understand data.

However, this opportunity to discover also presents chal-
lenges. Reasoning about data is becoming more complicated
and diﬃcult as data scales and complexities increase. People
require powerful tools to draw valid conclusions from data,
while maintaining trustworthy and interpretable results.

We claim that visual analytics (VA) and machine learn-
ing (ML) have complementing strengths and weaknesses
to address these challenges. Visual analytics (VA) is a
multi-disciplinary domain that combines data visualization
with machine learning (ML) and other automated tech-
niques to create systems that help people make sense of
data [TC05, KSF∗08, Kei02, KMSZ06]. Over the years, much
work has been done to establish the foundations of this area,

submitted to COMPUTER GRAPHICS Forum (6/2018).

create research advances in select topics, and form a com-
munity of researchers to continue to evolve the state of the
art.

Currently, VA techniques exist that make use of select
ML models or algorithms. However, there are additional
techniques that can apply to the broader visual data analysis
process. Doing so reveals opportunities for how to couple user
tasks and activities with such models. Similarly, opportunities
exist to advance ML models based on the cognitive tasks
invoked by interactive VA techniques.

This state-of-the-art report brieﬂy summarizes the ad-
vances made at the intersection of ML and VA. It describes
the extent to which machine learning methods are utilized in
visual analytics to date. Further, it illuminates the opportuni-
ties within both disciplines that can drive important research
directions in the future. Much of the content and inspiration
for this paper originated during a Dagstuhl Seminar titled,
“Bridging Machine Learning with Information Visualization
(15101)” [KMRV15].

2

Endert et al. / Integrating Machine Learning into Visual Analytics

1.1. Report organization

This report is organized as follows. Section 2 of the report
discusses three categories of models: human reasoning, visual
analytics and information visualization, and machine learning.
The models describing the cognitive activity of sensemaking
and analytical reasoning characterize the processes that hu-
mans engage in cognitively to gain understanding of data.
The models and frameworks for visual analytics depict sys-
tematic descriptions of how computation and analytics can
be incorporated in the systematic construction and design
of visual analytic applications. Finally, the machine learning
community has several models that illustrate how models
are trained, used, and interactively steered.

Section 3 categorizes the integration of machine learning
techniques into visual analytic systems. Section 4 discusses
how such systems have been used in speciﬁc domains to solve
real-world challenges. Section 5 discusses a research direc-
tion for integrating steerable dimension reduction techniques
into visual analytics. Finally, Section 6 discusses open chal-
lenges and opportunities for ML and VA. While the current
work shows how some progress has been made in bringing
these two communities closer together, there are several open
challenges.

2. Models and Frameworks

To ground the discussion of embedding ML techniques into
VA systems for data analysis and knowledge discovery, we
describe three categories of models and frameworks below.
First, we discuss existing models meant to describe the cog-
nitive stages people progress through while analyzing data.
These models show the complex processes people go through
to gain insight from data, which developed systems must sup-
port. Second, we discuss existing models and frameworks that
describe interaction and information design of visual analytic
applications. These models illustrate how data transforma-
tion and analytic computation are involved in generating the
visual representations of data in tools. User interaction is
critical in tuning and steering the parameters of these models.
Finally, we show select ML frameworks that emphasize the
importance of training data and ground truth for generating
accurate and eﬀective computational models. In addition, we
describe the main techniques developed in the ML ﬁeld to
integrate user feedback in the training process.

2.1. Models of Sensemaking and Knowledge

Discovery

One should emphasize that a primary purpose of data analyt-
ics is for people to understand, and gain insights into, their
data [CMS99,Chr06]. Thus, it is important to understand the
cognitive processes of people as they reason about data. It is
from such an understanding that “human-in-the-loop” appli-
cation designs are realized. Prior work exists that provides
models and design guidelines for visual analytics.

Sense-making is the process of “structuring the unknown”

Figure 1: The “sensemaking loop” (from [PC05]) illustrating
the cognitive stages people go through to gain insight from
data.

by organising data into a framework that enables us “to
comprehend, understand, explain, attribute, extrapolate,
and predict” [Anc12]. It is this activity of structuring–the
ﬁnding and assembly of data into meaningful explanatory
sequences [LI57]–that enables us to turn ever more com-
plex observations of the world into ﬁndings we can under-
stand “explicitly in words and that serves as a springboard
into action” [WSO05]. By attempting to articulate the un-
known, we are driven more by “plausibility rather than
accuracy” [Wei95] as we create plausible explanations that
can be used to evolve and test our understanding of the
situation or the data. Decision makers are often faced with
inaccurate representations of the world [EPT∗05] and have
to ﬁll-in the gaps with strategies such as “story-telling” to
create stories that explain the situation.

One of the earliest models to describe the iterative process
of data analysis as “sensemaking” [RSPC93] is presented
in Figure 1 and illustrates the well-known (and probably
the most frequently cited) Pirolli and Card sensemaking
model [PC05]. Proposed in the context of intelligence analysis,
it is useful for showing how information is handled through
the process of searching and retrieving relevant information,
organizing, indexing and storing the information for later use,
structuring the information to create a schema or a way to
explain what has been observed, the formulation and testing
of hypotheses, which then leads to the determination of a
conclusion, and a sharing of that conclusion. This notional
model depicts the cognitive stages of people as they use
visual analytic tools to gain understanding of their data.

From Pirolli and Card’s perspective, sensemaking can be
categorized into two primary phases: foraging and synthesis.
Foraging refers to the stages of the process where models
ﬁlter and users gather collections of interesting or relevant
information. This phase emphasizes the computational ability
of models, as the datasets are typically much larger than
what a user can handle. Then, using that foraged information,
users advance through the synthesis stages of the process,
where they construct and test hypotheses about how the

submitted to COMPUTER GRAPHICS Forum (6/2018).

Endert et al. / Integrating Machine Learning into Visual Analytics

3

foraged information may relate to the larger plot. In contrast
to foraging, synthesis is more “cognitively intensive”, as much
of the insights stem from the user’s intuition and domain
expertise. Most existing visualization tools focus on either
foraging or synthesis, separating these two phases.

As with all models of cognitive processes, there have been
criticisms. For instance, while there are feedback loops and
repeat loops, and cycles within cycles, it still is somewhat a
linear model. It describes the data transaction and informa-
tion handling and transformation processes, “... rather than
how analysts work and how they transition” [KS11]. Human
analysts carry out their work within this framework, but
their thinking and reasoning processes are much less linear
and structured. For example, although recognised as a part
of the sense-making loop, there is little explanation about the
thinking and reasoning strategies that are invoked to formu-
late hypotheses. This is a critical aspect of the sense-making
process: how are explanations of the situation or data formed
in the mind of the human in order that the explanation can
be used to test one’s understanding of the data or situation?
Later in this section, we report on work that is attempting
to unravel this aspect of how analysts think.

Another useful model that can be employed to describe
the human-centered sense-making process is the “data-frame
model” by Klein et al. [KMH06b, KMH06a]. Their model
(Figure 2) depicts an exchange of information between the
human and the data in terms of frames. People make sense of
a situation by interpreting the data they are presented with
in relation to what they already know to create a new under-
standing. A user has an internal “frame” that represents her
current understanding of the world. The data connects with
the frame. As she continues to explore a particular dataset,
her frames of the world are mapped against the information
she uncovers. If the information supports a speciﬁc frame,
that frame is thought to strengthen in a process they call
elaboration. As she understands the situation better, she
searches for more relevant information, learning that there
may be other factors to the problem than originally thought
or known, therefore driving the demand for more information,
and building her frame. However, when evidence is discovered
through exploration that contradicts or refutes the existence
of such a mental frame, the frame can either be augmented
or a new one created. This is the important process that
leads her to question her earlier conclusions or assumptions
made to arrive at these conclusions. Additionally new frames
can also be created to reframe the problem. In situations
where data is missing or ambiguous or unknown, reframing
enables her to articulate the problem in diﬀerent ways that
may allow her to change her information search strategy
and perhaps even her goals. One of the key beneﬁts of the
Data-Frame Model is that it points to the importance of de-
signing visual analytics in a way that encourages analysts to
question their data and their understanding, and to facilitate
visualizations and transformations that enable reframing of
their understanding of the situation.

Recently a set of knowledge generation and synthesis mod-

submitted to COMPUTER GRAPHICS Forum (6/2018).

Figure
making [KMH06b].

2:

The Data-Frame Model

of

Sense-

els have been proposed that comprehensively attack a central
issue of visual analytics: developing a human-computer sys-
tem that enables analytic reasoning to produce actionable
knowledge. The ﬁrst of these models was proposed by Sacha
et. al. [SSS∗14] and is shown in Figure 3. One sees looping
structures and components familiar from Pirolli and Card’s
sensemaking model, as depicted in Figure 1 above. However,
the computer and human regions of the model, and their re-
lationship with each other, are now explicitly expressed, and
the paper shows a clear relationship, via interaction, between
the human and both the visualization and the model. The pa-
per also describes detailed steps for the data-visualization and
data-model pipelines (the latter in terms of KDD processes
that couple, for example, to machine learning algorithms).
Whereas the sensemaking model was conceptual, this model
is concrete and shows, better than other models, where to put
computing and (via interactive interfaces) human-in-the-loop
steps in order to build an actual system.

The Sacha et al. model has recently been generalized to
produce a more complete knowledge generation and synthesis
(KGS) model [RF16]. The KGS model explicityly accounts for
both Prior Knowledge (placed between Data, Visualization,
and Model in Figure 3) and User Knowledge (placed between
Action and Finding). Prior Knowledge is quite important
for any exploration involving experts or based on expertise;
experts will want to know immediately the relationship of new
knowledge to existing domain knowledge. User knowledge
is built up during complex reasoning, where it can then
be the basis for generating additional knowledge or can be
synthesized with Prior Knowledge to produce more general
truths. The KGS model posits an iterative process that
addresses high level reasoning, such as inductive, deductive,
and abductive reasoning, in the knowledge generation and
exploration loops. It is based on a framework by Gahegan
et al. [GWHR01] that was developed for GIScience but is
generalizable.

These models provide a roadmap for visualization and
analytics processes, and for the role of human-computer in-
teraction. In particular, they illuminate the relationships
among machine learning, visualization, and analytics rea-

4

Endert et al. / Integrating Machine Learning into Visual Analytics

Figure 3: Human-Computer knowledge generation model
of Sacha et al. [SSS∗14].

Figure 4: The information visualization pipeline [Hee06]
depicting the data transformation and visual mapping process
for constructing visualizations.

soning processes including exploration and knowledge gen-
eration. For example, Klein’s data frame model, discussed
above, would ﬁt in this structure, providing a focus for ML
components while the models in Figure 3 would show how
to connect the data frame model with interactive visualiza-
tion and hypothesis-building. There are no VA systems that
embody all the components of the Sacha and KGS models,
but there are some (e.g., VAiRoma [CDW∗16]) that include
parts of the model. Typically in these systems, ML is a static
pre-processing step applied to the data at the beginning.
For example, in VAiRoma time-dependent, hierarchical topic
modeling is applied to large text collections [CDW∗16]. How-
ever, the KGS model shows how interactive ML can be placed
in the human-computer process and how it relates to interac-
tive visualization and reasoning. There is further discussion
of interactivity in VAML systems below. The discussion in
Sacha et al. [SSS∗14] implies two main roles for ML; one is to
transform unstructured or semi-structured data into a form
more meaningful for human exploration and insight discov-
ery. The other is to use unsupervised or semi-supervised ML
to guide the analysis itself by suggesting the best visualiza-
tions, sequences of steps in the exploration, veriﬁcation, or
knowledge generation processes, guarding against cognitive
bias, etc. In addition, since the KGS model was derived with
reference to cognitive science principles [GRF09], there is a
possibility for merging ML with cognitive models to produce
even more powerful human-machine models. To illustrate,
one could explore Fu and Pirolli’s SNIF-ACT cognitive ar-
chitecture model [FP07], which connects human exploration
and information foraging in a sensemaking context. This
could be married with ML approaches to reﬁne and focus the
parameters of the ML approach for particular exploration
strategies.

2.2. Models of Interactivity in Visual Analytics

Frameworks or pipelines for information visualization have
been previously developed [Hee06, Van05]. For example, the

information visualization pipeline depicted in Figure 5 shows
how data characteristics are extracted and assigned visual
attributes or encodings, ultimately creating a visualization.
The designs of visualizations adhering to this pipeline exhibit
two primary components of the visual interface: the visualiza-
tion showing the information, and a graphical user interface
(GUI) consisting of graphical controls or widgets. The graph-
ical controls in the GUI (e.g., sliders, knobs, etc.) allow
users to directly manipulate the parameters they control. For
example, “direct manipulation” [Shn83] user interfaces for
information visualizations enable users to directly augment
the values of data and visualization parameters to see the
corresponding change in the visualization (e.g., using a slider
to set the range of home prices and observing the ﬁltering
of results in a map showing homes for sale). This model
is a successful user interaction framework for information
visualizations.

Visual analytic systems have adopted this method for user
interaction, but with the distinct diﬀerence of including ana-
lytic models or algorithms, as discussed earlier in this section.
For example, in addition to ﬁltering the data by selecting
ranges for home prices, users could be given graphical con-
trols over model parameters such as weighting the mixture
of eigenvectors of a principal component analysis (PCA) di-
mension reduction (DR) model to produce two-dimensional
views showing pairwise similarity of homes across all of the
available dimensions. To users who lack expertise in such
models, this may pose fundamental usability challenges.

In contrast, prior work has proposed frameworks to per-
form model steering via machine learning techniques applied
to the user interactions performed during visual data analysis,
called semantic interaction [EFN12b]. Semantic interaction is
an approach to user interaction for visual data exploration in
which analytical reasoning of the user is inferred and in turn
used to steer the underlying models implicitly (illustrated in
Figure 5). The goal of this approach to user interaction is
to enable co-reasoning between the human and the analytic
model (or models) used to create the visualization (coupling
cognition and computation) without requiring the user to
directly control the models.

The approach of semantic interaction is to overload the
visual metaphor through which the insights are obtained (i.e.,
the visualization of information created by computational
models) and the interaction metaphor through which hy-
potheses and assertions are communicated (i.e., interaction
occurs within the visual metaphor). Semantic interaction
enables users to directly manipulate data within visualiza-
tions, from which tacit knowledge of the user is captured,
and the underlying analytic models are steered. The analytic
models can be incrementally adapted based on the user’s
sensemaking process and domain expertise explicated via
the user interactions with the system (as described in the
models of Section 2.1).

The semantic interaction pipeline (shown in Figure 5) takes
an approach of directly binding model steering techniques
to the interactive aﬀordances created by the visualization.

submitted to COMPUTER GRAPHICS Forum (6/2018).

Endert et al. / Integrating Machine Learning into Visual Analytics

5

Figure 5: The semantic interaction pipeline [EFN12b] show-
ing how the user interactions in a spatial visualization can be
incorporated into the computation of a visual analytic system.

For example, a distance function used to determine the
relative similarity between two data points (often visually
depicted using distance in a spatial layout), can serve as
the interactive aﬀordance to allow users to explore that
relationship. Therefore, the user interaction is directly in the
visual metaphor, creating a bi-directional medium between
the user and the analytic models [LHM∗11].

2.3. Machine Learning Models and Frameworks

There is not as much work in machine learning models and
frameworks. Most of the proposals correspond to some form of
de facto industrial standards, such as the SEMMA (Sample,
Explore, Modify, Model, and Assess) methodology adver-
tised by SAS Institute Inc. Among those, a vendor neutral
framework, CRISP-DM [She00], is somewhat comparable to
knowledge discovery and visual analytics frameworks. There
are six phases in the framework: business (or problem) un-
derstanding; data understanding (developed through explo-
ration of the data and discussion with data owners); data
preparation (including feature extraction, noise removal, and
transformation); modeling; evaluation (testing the quality of
the model, and particularly its generalization performance);
deployment (embedding the model in practice). In some
versions of this framework, there is an additional link from
deployment back to business understanding - this represents
the fact that the underlying data generator may change over
time. The model needs continuous evaluation in deployment
and when performance degrades, the process starts again.
Perhaps more importantly, all the steps of the framework
are embedded in a general loop comparable to the ones ob-
served in other frameworks. This emphasize the feedback
from the latter stage of the process (evaluation in numerous
machine learning applications) to the early stages (e.g. data
preparation in CRISP-DM).

As pointed out in e.g. [ACKK14], the traditional imple-
mentation of the machine learning workﬂow leads to long
development cycles where end users (who are also domain
experts) are asked to give feedback on the modeling results.
This feedback is used by machine learning experts to tune the
whole processing chain, especially at the data preparation
stage. Ideally, this feedback should take the form of speciﬁc
and formal user inputs, for example positive and negative
feedback on exemplars (such as “those two objects should not
belong to the same cluster” or “this object is misclassiﬁed”).

User feedback in this formal, expressive form lends it-
self very well to steering and training machine learning
models, for example via interactive machine learning ap-

submitted to COMPUTER GRAPHICS Forum (6/2018).

proaches [PTH13]. Figure 6 shows an early model of inter-
active machine learning that emphasizes the feedback that
users give to train classiﬁers [FOJ03]. Through multiple iter-
ations of feedback, the classiﬁer gets more training examples,
and is thus able to more closely approximate the phenomena
or concept being classiﬁed in the data.

To further establish an ML framework, we note the follow-
ing. Machine learning tasks are traditionally divided into two
broad categories, supervised tasks and unsupervised tasks.
In supervised learning, the goal is to construct a model that
maps an input to an output, using a set of examples of
this mapping, the training set. The quality of the model is
evaluated via a ﬁxed loss criterion. Up till recently, it has
generally been considered that human input is not needed in
the model construction phase. On the contrary, it could lead
to undetected overﬁtting. Indeed the expected quality of the
model on future data (its so-called generalization ability) is
generally estimated via an independent set of examples, the
test set. Allowing the user (or a program) to tune the model
using this set will generally reduce the generalization ability
of the model and prevent any sound evaluation of this ability
(unless yet another set of examples is available).

Supervision via examples can be seen as a direct form of
user control over the training process. Allowing the user to
modify the training set interactively provides an indirect way
of integrating user inputs into the model construction phase.
In addition, opportunities for user feedback and control are
available before and after this modeling step (e.g., using
the CRISP-DM phases). For instance, user feedback can be
utilized at the feature selection, error preferences, and other
steps. Leveraging those opportunities (including training
set modiﬁcation) has been the main focus of interactive
machine learning approaches. For instance, tools such as the
Crayons system from [FOJ03] allow the user to add new
training data by specifying in a visual way positive and
negative examples. This speciﬁc type of user feedback in the
form of labelling new examples is exactly the focus of the
active learning framework [Set09] in machine learning. This
learning paradigm is a variation over supervised learning
in which ML algorithms are able to determine interesting
inputs for which they do not know the desired outputs (in
the training set), in such a way that given those outputs the
predictive performances of the model would greatly improve.
Interestingly active learning is not the paradigm used in
e.g. [FOJ03]. It seems indeed that in real world applications,
active learning algorithms tend to ask too many questions
and possibly to similar ones, as reported in e.g., [GB11].
More generally, the need for speciﬁc and formal user inputs
can create usability issues with regards to people and their
tasks, as pointed out in e.g., [ACKK14,EHR∗14]. That is, the
actions taken by the user to train the systems are often not
the actions native to the exploratory data analysis described
in the previously mentioned frameworks. This is starting
to become more commonly used in the ML community, as
exempliﬁed by [BH12]. In this paper the authors consider
additional questions a system can ask a user, beyond just
labelling. They focus in particular on class conditional queries

6

Endert et al. / Integrating Machine Learning into Visual Analytics

Figure 6: A model for interactive machine [FOJ03] learning
depicting user feedback for model training.

– the system shows the user unlabeled examples and asks
him or her to select one that belongs to a given class (if one
exists).

In unsupervised learning, the data has no input/output
structure and the general goal is to summarize the data in
some way. For instance, as discussed further below, dimension
reduction techniques build low dimensional approximations
of the data from their high dimensional initial representation;
clustering groups data into similar objects; etc. Unsuper-
vised learning is generally considered ill posed in the ML
ﬁeld in the following sense: most of the tasks of unsupervised
learning (clustering, dimensionality reduction, etc.) have only
an informal description to which numerous formal models
can be related. Those models are very diﬃcult to compare
on a theoretical point of view as well as on a practical one.
In unsupervised learning, the need for user input, steering
and control is therefore broadly accepted and techniques to
include user feedback into e.g., clustering have been studied
for some time. Variations over unsupervised methods that
take explicitly into account some form of additional infor-
mation are generally called semi-supervised methods. The
supervision is frequently provided by external data in an
automated way, but those methods can lead to principled
ways of integrating user feedback.

It should be noted however that most of the methodolog-
ical development in machine learning that can be used to
integrate user feedback, from active learning to triplet based
constraints [vdMW12], are seldom evaluated in the context
of visualization systems. In general, the feedback process is
either simulated or obtained via oﬀ line and slow process (e.g.
Amazon’s Mechanical Turk for triplet in [WKKB15]). Thus
while speciﬁc frameworks that enable user feedback have
been deﬁned by the ML community, the practical relevance
of the recent ones in the context of interactive visualization
remains untested.

2.4. Comparison to another classiﬁcation

framework

A recent paper by Sacha et al. [SZS∗16] overlaps with this
STAR Report. It focuses on the speciﬁc area of dimensionality
reduction and how these techniques integrate with interactive
visualization in visual analytics systems. The paper builds
around a systematic analysis of visualization literature, which

reveals seven common interaction scenarios. The evaluation
leads to the identiﬁcation of future research opportunities.

The current paper provides a signiﬁcantly broader survey
of machine learning methods coupled with interaction, while
Sacha et al. [SZS∗16] probe deeper in one important area.
In addition to dimension reduction, the current paper deals
with ML methods for clustering, classiﬁcation, and regression.
There is some overlap in the literature covered in the two
papers. However, the literature reviewed in the current paper
cites ML methods that are already coupled with interactive
visualization systems plus those that are not yet (but it
would be beneﬁcial if they were); Sacha et al. deal mostly
with ML methods that are already coupled with interactive
visualizations.

The two papers complement each other with Sacha’s deeper
analysis in DR strengthening the wider analysis in the cur-
rent paper, and vice versa. The human-in-the-loop process
model in [SZS∗16] has similarities with the use of the human-
machine interaction loop in the current paper; they also share
a common origin. The classiﬁcations used in Sacha et al’s
structured analysis are diﬀerent than those in the current
paper’s taxonomy, although one could be mapped into the
other, with modiﬁcations. However, there are also multiple
similarities; in particular, classiﬁcation according to “modify
parameters and computation domain” and “deﬁne analytical
expectations” in Sections 3.2 and 3.3 of the current paper
map to various interaction scenarios in Sacha et al. [SZS∗16].
For example, the ﬁrst classiﬁcation maps to data manipula-
tion, DR parameter tuning, and DR type selection scenarios
in Sacha et al’s model. The second classiﬁcation, in permit-
ting the user to tell the system (based on results it gives)
expectations that are consistent with domain knowledge,
maps to feature selection and emphasis and deﬁning con-
straints scenarios. The current paper then goes beyond DR,
including for each classiﬁcation a discussion of clustering,
classiﬁcation, and regression methods. This broadens and
strengthens the discussion from Sacha et al. [SZS∗16].

3. Categorization of Machine Learning Techniques

Currently used in Visual Analytics

The visual analytic community has developed systems that
leverage speciﬁc machine learning techniques. In this sec-
tion, we give an overview of the existing ways that machine
learning has been integrated into VA applications from two
transversal perspectives: the types of ML algorithms and the
so-called interaction intent. We pay special attention to the
“interaction intent” as described below, because this focuses
on human-in-the-loop aspects that are central to VA systems.
There are also other papers where the main role of visu-
alization is on communicating the results of computations
to improve comprehension [TJHH14] that are not directly
covered in this section. Some of the most signiﬁcant of these
papers, referring to VA systems, are described in Section 4.

Along the ﬁrst perspective, we consider the diﬀerent types
of ML algorithms that have been considered within visual an-
alytics literature. Although one might think of several other

submitted to COMPUTER GRAPHICS Forum (6/2018).

Endert et al. / Integrating Machine Learning into Visual Analytics

7

possible ways to categorize the algorithms [Alp14, FHT01],
here we adopt a high-level task-oriented taxonomy and cate-
gorize the algorithms under the following headings: dimension
reduction, clustering, classiﬁcation, regression/correlation
analysis. We observe that ML algorithms to tackle these
tasks are frequently adopted in visual analytics applications
since these analytical tasks often require the joint capabilities
of computation and user expertise. To brieﬂy summarize:
i) dimension reduction methods help analysts to distill the
information in high-dimensional data so that conventional vi-
sualization methods can be employed and important features
are identiﬁed ii) clustering methods help to identify groups
of similar instances which can be done both in a supervised
or unsupervised manner iii) classiﬁcation methods are often
supervised and help to build models to associate labels to
data instances, and ﬁnally iv) regression/correlation analysis
methods help to investigate relations between features in
the data and to understand/generate causal links to explain
phenomena.

Within the domain of visualisation, we initiated our survey

starting with publications from the following resources:

Journals: IEEE Transactions on Visualization and Com-
puter Graphics, Computer Graphics Forum, IEEE Computer
Graphics and Applications, Information Visualization

Conferences: IEEE Visual Analytics Science and Technol-
ogy (partially published as a special issue of IEEE TVCG),
IEEE Symposium on Information Visualization (InfoVis)
(published as a special issue of IEEE TVCG since 2006),
IEEE Paciﬁc Visualization Symposium (PaciﬁcVis), EuroVis
workshop on Visual Analytics (EuroVA)

Within the domain of machine learning, we initiated our
survey starting with publications from the following re-
sources:

Journals: Journal of Machine Learning Research, Neuro-
computing, IEEE Transactions on Knowledge and Data En-
gineering

Along the second perspective, we focus on the user side of
the process. We name this aspect as interaction intent and
categorize the actions taken by users within visual analysis
in terms of the methods through which the analyst tries to
improve the ML result.

Conferences: International Conference on Machine Learn-
ing (ICML), ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining, European Sympo-
sium on Artiﬁcial Neural Networks, Computational Intelli-
gence and Machine Learning (ESANN)

This perspective of our taxonomy resonates with the “user
intent” categories suggested by Yi et al. [YaKSJ07] for low-
level interactions within InfoVis applications. Our focus,
however, is targeted on higher-level analytical intents within
the narrower scope of visual analytics applications that in-
volve ML methods. With this motivation in mind, we suggest
two broad categories for “intents”: modify parameters and
computation domain and deﬁne analytical expectations. Table
1 shows the organization of literature along the dimensions
of algorithm type vs the two categories of user intent. Here
we survey the existing literature within the scope of this
characterization.

3.1. Review Methodology

The literature summarized and categorized in this section
are taken from impactful ML and visualization conferences
and journals. They were chosen and categorized based on
discussions the authors had at the Dagstuhl Seminar titled,
“Bridging Machine Learning with Information Visualization
(15101)” [KMRV15], and later reﬁned through a more exten-
sive literature review.

Within this report, we review existing literature on the
integration of machine learning and visualisation from three
diﬀerent perspectives – models and frameworks, techniques,
and application areas. When identifying the relevant works
in these domains, we follow a structured methodology and
identiﬁed the diﬀerent scopes of investigation for these three
diﬀerent perspectives. One important note to make is, due
to our focus on the integration of the two ﬁelds, we scanned
resources from both the visualisation and machine learning
domain.

submitted to COMPUTER GRAPHICS Forum (6/2018).

We then scanned the relevant papers identiﬁed in the
above resources and performed a backward and forward
literature investigation using Google Scholar. In producing
the taxonomy of works within Section 3, we labelled the
publication both in terms of the analytical task and the
integration strategy incorporated.

3.2. Modify parameters and computation domain

Here we list techniques where interaction has been instru-
mental in modifying the parameters of an algorithm, deﬁning
the measures used in the computations, or even changing
the algorithm used. Another common form of interaction
here is to enable users to modify the computational domain
to which the algorithm is applied. Such operations are of-
ten facilitated through interactive visual representations of
data points and data variables where analysts can select
subsets of data and run the algorithms on these selections
within the visual analysis cycle to observe the changes in
the results and to reﬁne the models iteratively. The types
of techniques described in this section can be considered as
following a “direct manipulation” [Shn83] approach where
the analysts explicitly interact with the algorithm before
or during the computation and observe how results change
through visualization.

Dimension Reduction One class of algorithms that is
widely incorporated in such explicit modiﬁcation strategy
is dimension reduction. Since high-dimensional spaces are
often cognitively challenging to comprehend, combinations of
visualization and dimension reduction methods have demon-
strated several beneﬁts. Johansson and Johansson [JJ09]
enable the user to interactively reduce the dimensionality

8

Endert et al. / Integrating Machine Learning into Visual Analytics

Dimension
Reduction

Clustering

Modify Parameters &
Computation Domain
[JJ09], [FJA∗11], [FWG09], [SDMT16],
[WM04], [NM13], [TFH11], [TLLH12],
[JBS08], [ADT∗13], [JZF∗09]
[Kan12], [RPN∗08], [SBTK08], [RK04],
[SS02], [LSS∗12], [LSP∗10], [TLS∗14],
[TPRH11a], [AW12], [RPN∗08], [HSCW13],
[TPRH11b], [PTRV13], [HHE∗13], [WTP∗99],
[YNM∗13], [SGG∗14]

Deﬁne
Analytical Expectations
[EHM∗11],
[EBN13], [BLBC12],
[HBM∗13], [GNRM08], [IHG13],
[PZS∗15], [KCPE16], [KKW∗16]
[HOG∗12], [CP13], [BDW08], [CCM08],
[KK08]
[BBM04], [ABV14], [KKP05],

[KP11],

Classiﬁcation [PES∗06], [MK08], [MBD∗11], [vdEvW11],
[CLKP10],

[KPB14], [AAB∗10], [AAR∗09],
[KGL∗15]
[PBK10], [MP13], [MME∗12], [TLLH12],
[KLG∗16]

Regression

[Set09], [SK10], [BKSS14], [PSPM15]

[MGJH08], [MGS∗14] [LKT∗14] [YKJ16]

Table 1: In Section 3, we review the existing literature in visual analytics following a 2D categorization that organizes the
literature along two perspectives: Algorithm Type (rows) and Interaction Intent (columns).

of a data set with the help of quality metrics. The visually
guided variable ordering and ﬁltering reduces the complexity
of the data and provides the user a comprehensive control
over the whole process. The authors later use this methodol-
ogy in the analysis of high-dimensional data sets involving
microbial populations [FJA∗11]. An earlier work that merges
visualization and machine learning approaches is by Fuchs
et al. [FWG09]. The authors utilize machine learning tech-
niques within the visual analysis process to interactively
narrow down the search space and assist the user in iden-
tifying plausible hypotheses. In a recent paper, Stahnke et
al. [SDMT16] devised a probing technique using interactive
methods through which analysts can modify the parameters
of a multi-dimensional scaling projection. The visualization
plays a key role here to display the diﬀerent dimension contri-
butions to the projections and to communicate the underlying
relations that make up the clusters displayed on top of the
projection results.

In MDSteer [WM04], an embedding is guided by user in-
teraction leading to an adapted multidimensional scaling of
multivariate data sets. Such a mechanism enables the analyst
to steer the computational resources accordingly to areas
where more precision is needed. This technique is an early
and good example of how a deep involvement of the user
within the computational process has the potential to lead to
more precise results. Nam and Mueller [NM13] provide the
user with an interface where a high-dimensional projection
method can be steered according to user input. They provide
“key” computational results to guide the user to other relevant
results through visual guidance and interaction. Turkay et
al. introduce the dual-analysis approach [TFH11] to support
analysis processes where computational methods such as
dimension reduction [TLLH12] are used. The authors incor-
porate several statistical measures to inform analysts on the
relevance and importance of variables. They provide several

perspectives on the characteristics of the dimensions that
can be interactively recomputed so that analysts are able
to make multi-criteria decisions whilst using computational
methods. J¨anicke et al. [JBS08] utilize a two-dimensional
projection method where the analysis is performed on a pro-
jected 2D space called the attribute cloud. The resulting
point cloud is then used as the medium for interaction where
the user is able to brush and link the selections to other
views of the data. In these last group of examples, the capa-
bility to run the algorithms on user-deﬁned subsets of the
data through visually represented rich information is the key
mechanism to facilitate better-informed, more reliable data
analysis processes.

Clustering Clustering is one of the most popular algorithms
that have been integrated within visual analytics applications.
Since visual representations are highly critical in interpreting
and comprehending the characteristics of clusters produced
by the algorithms, direct modiﬁcation of clustering algo-
rithms are often facilitated through interactive interfaces
that display new results “on-demand”. gCluto [RK04] is an
interactive clustering and visualization system where the au-
thors incorporate a wide range of clustering algorithms. This
is an early example where multiple clustering algorithms can
be run on-the-ﬂy with varying parameters and results can be
visually inspected. In Hierarchical Clustering Explorer [SS02],
Seo and Shneiderman describe the use of an interactive dendo-
gram coupled with a colored heatmap to represent clustering
information within a coordinated multiple view system.

Other examples include work accomplished using the Ca-
leydo software for pathway analysis and associated experi-
mental data by Lex et al. [LSS∗12, LSP∗10]. In their tech-
niques, the authors enable analysts to investigate multiple
runs of clustering algorithms and utilize linked, integrated
visualizations to support the interpretation and validation

submitted to COMPUTER GRAPHICS Forum (6/2018).

Endert et al. / Integrating Machine Learning into Visual Analytics

9

of clusters. Along the same lines, Turkay et al. present an
interactive system that addresses both the generation and
evaluation stages within the clustering process and provides
interactive control to users to reﬁne grouping criteria through
investigations of measures of clustering quality [TPRH11a].
In a follow-up work [TLS∗14], within the domain of clustering
high-dimensional data sets, integrated statistical computa-
tions are shown to be useful to characterize the complex
groupings that analysts encounter in such data sets. Figure 7
demonstrates how the authors incorporated statistical analy-
sis results to indicate important features for data groups. In
this work, the most discriminative features (indicated with
red dots as opposed to blue ones that are less important)
for the clustering result of a high-dimensional data set are
represented as integrated linked views. The user is able to
select these features in one clustering result (e.g., within the
clustering result in the right-most column in Figure 7) and
observe whether the same features are represented in others,
e.g., in the left-most column.

Schreck et al. [SBTK08] propose a framework to interac-
tively monitor and control Kohonen maps to cluster trajec-
tory data. The authors state the importance of integrating
the expert within the clustering process for achieving good
results. Kandogan [Kan12] discusses how clusters can be
found and annotated through an image-based technique. His
technique involves the use of “just-in-time” clustering and
annotation, and the principal role for visualisation and inter-
action is to aid the interpretation of the structures observed,
and provide a deeper insight into why and how particular
structures are formed.

An important role for visualization is to get the user
engaged in progressive and iterative generation of clus-
ters [RPN∗08]. In such approaches, the user is presented
with content that is built step-by-step and gains additional
insight in each iteration to decide whether to continue, alter,
or terminate the current calculations. Such levels of inter-
activity, of course, require the solutions to be responsive
and capable of returning results within acceptable delays.
Ahmed and Weaver [AW12] address this problem through
forward-caching expected interaction possibilities and pro-
viding users with clustering results without breaking the
responsive analytical ﬂow.

Visual analytics applications that involve clustering al-
gorithms within the analysis of complex dynamic networks
have also been developed [HSCW13]. The use of visualisation
is in particular critical with such dynamic relational data
sets due to the limitations in interpreting the algorithmic
results; well-designed combinations of visual summaries can
assist analysts in this respect. In the domain of molecular
dynamics simulation, there are some examples of tight inte-
grations of interactive visualizations, clustering algorithms,
and statistics to support the validity of the resulting struc-
tures [TPRH11b], [PTRV13].

Classiﬁcation Being a relevant and widely utilized tech-
nique, classiﬁcation algorithms have also found their place

submitted to COMPUTER GRAPHICS Forum (6/2018).

within visual analytics applications. Common roles for inter-
active visualization are ﬁltering the feature space, iteratively
observing and ﬁxing problems, and when the classiﬁcation
tasks involve multiple mediums such as space, time and
abstract features, providing multiple perspectives to the al-
gorithmic results.

A conceptual framework on how classiﬁcation tasks can
be supported by interactive visualizations is presented by
May and Kohlhammer [MK08]. Their approach improved the
classiﬁcation of data using decision trees in an interactive
manner. They proposed the use of a technique called KVMaps
to inform users on classiﬁcation quality thus enabling the it-
erative reﬁnement of the results. The authors later proposed
a technique called SmartStripes [MBD∗11] where they inves-
tigated the relations between diﬀerent subsets of features and
entities. Interactive visual representations have been used to
help create and understand the underlying structures within
decision trees [vdEvW11]. The authors not only presented
the overall structure of decision trees, but also provided in-
tuitive visual representations of attribute importance within
the diﬀerent levels of the tree. Such interactive visualizations
are critical in unraveling the computed information hidden
within the layers and can be quite instrumental in increasing
the trust in such computational models. Similar insights can
be gained on other models (additive ones, e.g. naive Bayes,
in [PES∗06] and more general ones in [SK10]) by explaining
individual classiﬁcation. In these papers, the authors display
the contribution of features to the classiﬁcation made by
the model and enable what-if scenarios, such “how would
the classiﬁcation change if this particular feature was set to
another value?”

In iVisClassiﬁer by Choo et al. [CLKP10], the authors
improve classiﬁcation performance through interactive visu-
alizations. Their technique supports a user-driven classiﬁ-
cation process by reducing the search space, e.g., through
recomputing Latent Dirichlet Allocation (LDA) [BNJ03] with
a user-selected subset of data deﬁned through ﬁltering in
additional coordinated views. Klemm et al. [KGL∗15] investi-
gate the use of interactive visualisation to compare multiple
decision trees in investigating relations within non-image
and image based features for a medical application. They
visualise the quality aspects of classiﬁers to infer observations
on the predictive power of the features.

Krause et al. [KPB14] address the important process of
feature selection within model building for classiﬁcation pur-
poses. Through visual representations of cross-validation runs
for feature ranking with various algorithms, their method
supports the decisions made while including or excluding
particular features from a classiﬁcation model (see Figure 8).
Their approach enables users to be part of the predictive
model building process and, as also demonstrated by the
authors, leads to better performing/easier to interpret mod-
els. Their methodology is based on producing glyphs for the
features of a data set to represent how important each one
is within a number of classiﬁcation models. In addition, the
glyphs are also used as elements for visual selections and

10

Endert et al. / Integrating Machine Learning into Visual Analytics

Figure 7: Visualization of clustering results, together with
associated on-the-ﬂy computations to identify discriminating
features of groups, are used here to aid analysts in interpreting
the clusters and reﬁning them further [TLS∗14].

enable analysts to interactively apply modelling on subsets
of features.

Classiﬁcation of spatio-temporal patterns is one of the
complex tasks that requires the involvement of user input
and eﬃcient algorithms due to the complex nature of struc-
tures found in such data sets. Andrienko et al. [AAB∗10]
investigate how self organizing maps (SOMs) are integrated
into the visual analysis process. They integrate a SOM ma-
trix where the user can interactively modify the parameters
and observe the changes in the results in various visual repre-
sentations, e.g., where space is represented in time, and the
time is represented in space. Again involving spatio-temporal
data, an interactive process where a clustering algorithm
assists users to pick relevant subsets in building classiﬁers
has shown to be eﬀective in categorizing large collections of
trajectories [AAR∗09].

Regression Identifying the multivariate relations within
data variables, in particular when their numbers are high,
is one of the critical tasks in most data analysis routines.
In order to evaluate to what degree observed relations can
be attributed to underlying phenomena and to build causal
interpretations, visual analytics approaches have shown good
potential. Visualization has shown to be eﬀective in validat-
ing predictive models through interactive means [PBK10].
The authors visually relate several n-dimensional func-
tions to known models through integrated visualizations
within a model building process. They observed that such
a visualization-powered approach not only speeds up model
building but also increases the trust and conﬁdence in the
results. M¨uhlbacher and Piringer [MP13] discuss how the
process of building regression models can beneﬁt from inte-
grating domain knowledge. Berger et al. [BPFG11] introduce

Figure 8: Visual summaries to indicate the relevance of
features over cross-validation runs support analysts in making
informed decisions whilst selecting features for a classiﬁcation
model [KPB14].

an interactive approach that enables the investigation of
the parameter space with respect to multiple target values.
Malik et al. [MME∗12] describe a framework for interactive
auto-correlation. This is an example where the correlation
analysis is tightly coupled with the interactive elements in
the visualization solution. Correlation analysis has been in-
tegrated as an internal mechanism to investigate how well
lower-dimensional projections relate to the data that they
represent [TLLH12]. The use of relational representations
here supports analysts to evaluate how local projection mod-
els behave in preserving the correlative structures in the data.
In a recent paper, Klemm et al. [KLG∗16] demonstrates the
use of visualisation to show all combinations of several inde-
pendent features with a speciﬁc target feature. The authors
demonstrate how the use of template regression models, inter-
actively modiﬁable formulas and according visual representa-
tions help experts to derive plausible statistical explanations
for diﬀerent target diseases in epidemiological studies.

3.3. Deﬁne analytical expectations

Unlike the papers in the previous category where the user
explicitly modiﬁes the parameters and the settings of an
algorithm, the works we review under this section follow a
diﬀerent strategy and involve users in communicating ex-
pected results to the computational method. In these types of
interactive methods, the user often observes the output of an
algorithm and tell the machine which aspect of the output
is inconsistent with the existing knowledge, i.e., correcting
the algorithm. Furthermore, analysts can also communicate
examples of relevant, domain-knowledge informed relations
to be preserved in the ﬁnal result. Since this is a relatively
recent approach to facilitate the interaction between the user
and the algorithms, the number of works in this category
is not as high as the previous section. In the following, we
review such works again under a categorization of diﬀerent
ML algorithm types involved. Notice that integrating user
knowledge in this way in unsupervised learning contexts
falls into the general semi-supervised framework, which is a

submitted to COMPUTER GRAPHICS Forum (6/2018).

Endert et al. / Integrating Machine Learning into Visual Analytics

11

principled way in ML for making unsupervised problems less
ill-posed.

Dimension Reduction Dimension reduction algorithms
are suitable candidates for such approaches due to the often
“unsupervised” nature of the algorithms and the possibility
that errors and losses within the reduction phase are high,
in particular with datasets with high numbers of dimen-
sions. As one of the early works along these lines, Endert
et al. [EHM∗11] introduce observation level interactions to
assist computational analysis tools to deliver more inter-
pretable/reliable results. The authors describe such oper-
ations as enabling the direct manipulation for visual ana-
lytics [EBN13]. In this line of work, the underlying idea is
to provide mechanisms to users to reﬂect their knowledge
about the data through interactions that directly modify
computational results. One typical interaction is through
moving observations in a projection such that the modi-
ﬁed version is more similar to the expectation of the an-
alyst [EHM∗11, BLBC12]. This line of research has been
expanded to focus on the interpretability of linear [KCPE16]
and non-linear DR models [KKW∗16]. Hu et al. [HBM∗13]
complemented such visualization level interaction methods
with further interaction mechanisms. The authors aim to
understand users’ interaction intent better and give them
mechanisms to also highlight preferences on unmoved points.

In their Model-Driven Visual Analytics system, Garg et
al. [GNRM08] suggest the use of a ”pattern painting” mech-
anism that enables analysts to paint interesting structures in
the visualization which are then turned into logical rules that
can be fed into a projection algorithm to build an eﬀective
model.

An interesting supervised point of view has been proposed
in [IHG13] on the dimension reduction steering. The main
idea is to introduce an information theoretic criterion that
evaluates the uncertainty in the representation, considering
that the original high dimensional points are noisy. Given
this criterion, the authors apply an active learning approach
to select points that are maximally informative: if the user
can move one of those points to its desired position, the
uncertainty of the representation will be maximally reduced
(compared to the reduction expected with other points). The
experimental evaluation shows that the optimal points tend
to be more uniformly distributed over the projected data
set than with other selection methods, possibly reducing
some of the drawbacks of active learning summarized in
e.g. [ACKK14].

Clustering There are a number of works where user knowl-
edge is incorporated to feed a clustering algorithm with
expected results. Hossain et al. makes use of a scattergather
technique to iteratively break up or merge clusters to gen-
erate groupings that meet analysts’ expectations [HOG∗12].
(See Figure 9.) In their technique, the expert iteratively intro-
duces constraints on a number of required relations and the
algorithms take these constraints into consideration to gener-
ate more eﬀective groupings. The users state whether clusters

submitted to COMPUTER GRAPHICS Forum (6/2018).

Figure 9: Scatter Gather [HOG∗12] is a technique to interac-
tively gather feedback from analysts in response to algorithmic
output and reﬁne user-generated constraints to improve the
clustering.

in the current segmentation should be broken up further or
brought back together. Upon inspection of a clustering result,
the user interactively constructs a scatter gather constraint
matrix which represents a preferred clustering setting from
her perspective. The algorithm then considers this input
along with the clustering result to come up with an “op-
timized” result. In a number of papers, the user has been
involved even further to modify clustering results. In order
to support a topic modeling task through clustering, Choo
et al. [CP13] enable users to interactively work on topic
clusters through operations such as splitting, merging and
also reﬁning clusters by pointing to example instances or
keywords.

More generally, clustering is one of the ﬁrst tasks of ma-
chine learning to include ways to take into account expert
knowledge, originally in the form of contiguity constraints
(see [Mur85] for an early survey): the expert speciﬁes a prior
neighborhood structure on data points (for instance related
to geographical proximity) and the clusters are supposed to
respect this structure (according to some notion of agree-
ment). While the original methodology falls typically into
the oﬄine slow steering category, it has been extended to
more general and possibly online steering based on two main
paradigms for constraints clustering [BDW08]: the pairwise
paradigm (with must-link /cannot-link constraints) and the
triplet paradigm (with constraints of the form x must be
closer to y than to z).

An early example of the pairwise paradigm is provided
by [CCM08]. The authors describe a document clustering
method that takes into account feedback of the form: this
document should not belong to this cluster, this document

12

Endert et al. / Integrating Machine Learning into Visual Analytics

should be in this cluster, those two documents should be
(or should not be) in the same cluster (this mixes pointwise
constraints, with pairwise ones). Active learning has been
integrated into this paradigm in [BBM04]. A variation over
the pairwise approach which consists in issuing merge and/or
split requests at the cluster level has been proposed and
studied in [ABV14].

Constraints based on triplet are more recent and were
proposed in the context of clustering by [KKP05,KK08]. The
main advantage of specifying triplet based constraints over
pairwise ones is that they allow relative qualitative feedback
rather than binary ones. They are also known to be more
stable than pairwise comparisons [KG90].

Classiﬁcation Classiﬁcation tasks are suitable for methods
where users communicate known/expected/wrong classiﬁ-
cation results back to the algorithm. The ideas employed
under this section show parallels to the Active Learning
methodologies develop in the ML literature [Set09] where
the algorithms have capabilities to query the user for inter-
mediate guidance during the learning process. In their visual
classiﬁcation methodology, Paiva et al. [PSPM15] demon-
strates that eﬀective classiﬁcation models can be built when
users’ interactive input, for instance, to select wrongly la-
beled instances, can be employed to update the classiﬁcation
model. Along the similar lines, Behrisch et al. [BKSS14]
demonstrate how users’ feedback on the relevance of fea-
tures in classiﬁcation tasks can be incorporated into decision
making processes. They model their process in an iterative
dialogue between the user and the algorithm and name these
stages as relevance feedback and model learning. This work
serves as a good example of how user feedback might lead to
better performing, ﬁt-for-purpose classiﬁcation models.

Regression Although examples in this category are limited
in numbers, deﬁning the “expected” has shown great poten-
tial to support interactive visual steering within the context
of ensemble simulation analysis [MGJH08, MGS∗14]. In their
steerable computational simulation approach, Matkovic et
al. [MGJH08] demonstrate how a domain expert (an engineer)
can interactively deﬁne and reﬁne desired simulation outputs
while designing an injection system. Their three-level steering
process enables the expert to deﬁne desired output values
through selections in multiple views of simulation outputs.
The expert then moves on to visually explore the control
variables of the simulation and assess whether they are feasi-
ble and reﬁne/re-run the simulation models accordingly. The
authors went on to incorporate a regression model within
this process to further optimise the simulation results based
on users’ interactive inputs [MGS∗14]. With this addition
to the workﬂow, the experts again indicate desired output
characteristics visually and a regression model followed by
an optimization supports the process to quickly converge to
eﬀective simulation parameters. The critical role that the
users play in these examples is to express their expert knowl-
edge to identify and communicate suitable solutions to the
algorithmic processes which in turn try and optimize for
those.

4. Application Domains

The integration of ML techniques into VA systems has been
exempliﬁed in diﬀerent domains, described below. Each of
these domains present unique and important challenges, thus
diﬀerent combinations of interactive visualizations and ML
techniques are used. Some of these techniques are related to,
but go beyond the classiﬁcations in Section 3. For instance,
dimension reduction, clustering, etc. since they must be
closely embedded in the VA system and can be attached
to higher level meanings. However, most are relevant to the
Deﬁne Analytical Expectations category in Table 1. The
examples given in this section generally make use of one or
more technique categories in Section 3, depending on the
particular domain for which the applications are designed
for.

4.1. Text Analytics and Topic Modeling

Text corpora are frequently analyzed using visual analytic
systems. Text is a data format that lends itself nicely to
speciﬁc computational processes, as well as human reasoning.
Various text analytics methods have seen a lot of use in visual
analytics systems over the past 6-7 years. A main reason is
that these methods have proved useful in organizing large,
unstructured text collections around meaningful topics or
concepts. The text collections considered have been diverse
including research publications, Wikipedia entries, streaming
social media such as Twitter, Facebook entries, patents,
technical reports, and other types.

Visual analytic tools have been used to support informa-
tion foraging by representing high-dimensional information,
such as text, in an easily comprehensible two-dimensional
view. In such views, the primary representation is one where
information that is relatively closer to other information is
more similar (a visualization method borrowed from cartogra-
phy [Sku02]). These applications allow users to ﬁnd relevant
information and gain new insights into topics or trends within
the data. An early example of combining machine learning
with visual analytics for analyzing text is a system called IN-
SPIRE [WTP∗99]. One of the views of the system, the Galaxy
View shown in Figure 10, displays documents clustered by
similarity. Using dimension reduction techniques, this view
encodes relative similarity as distance (documents near each
other are more similar). The high-dimensional representa-
tion of the text documents is created by keyword extraction
from each document (deﬁning a dimension), and weightings
on the keywords determined computationally using popular
methods such as TF-IDF, etc. [RECC10].

Visual analytic tools have also been used to support syn-
thesis by enabling users to externalize their insights during
an investigation. In a spatial workspace where users can
manually manipulate the location of information, users build
spatial structures to capture their synthesis of the infor-
mation over time - a process referred to as “incremental
formalism” [SM99, SHA∗01]. Andrews et al. found that intel-
ligence analysts can make use of such spatial structures as

submitted to COMPUTER GRAPHICS Forum (6/2018).

Endert et al. / Integrating Machine Learning into Visual Analytics

13

Figure 10: IN-SPIRE [WTP∗99], a VA system for text corpora. IN-SPIRE combines computational metrics with interactive
visualizations.

a means to externalize insights during sensemaking, manu-
ally placing relevant documents in clusters on a large, high-
resolution display [AEN10]. Additionally, they found that the
large display workspace promoted a more spatially-oriented
analysis. Tools, such as I2 Analyst’s Notebook [i2], Jigsaw’s
“Tablet view” [SGL08], nSpace2 [EKHW08, WSP∗06], An-
alyst’s Workspace [AN12], and others have also found it
helpful to provide users with a workspace where spatial rep-
resentations of information can be manually organized.

More recently, researchers have developed techniques such
as Latent Semantic Analysis (LSA) for extracting and repre-
senting the contextual meaning of words [LD97]. LSA pro-
duces a concept space that could then be used for document
classiﬁcation and clustering. Also, probabilistic topic models
have emerged as a powerful technique for ﬁnding semantically
meaningful topics in an unstructured text collection [BL09].
Researchers from the knowledge discovery and visualization
communities have developed tools and techniques to support
visualization and exploration of large text corpora based
on both LSA (e.g., [DWS∗12, CDS09]) and topic models
(e.g., [IYU08, LZP∗09, WLS∗10, OST∗10]).

The Latent Dirichlet Allocation (LDA) model of Blei et
al. [BNJ03], which represents documents as combinations
of topics that are generated, in the unsupervised case, au-
tomatically has proved particularly useful when integrated
in a visual analytics system. The LDA model postulates a
latent topical structure in which each document is character-
ized as a distribution over topics and most prominent words
for each topic are determined based on this distribution.
Each topic is then described by a list of leading keywords
in ranked order. When combined with VA techniques, LDA
provides meaningful, usable topics in a variety of situations
(e.g., [GS04, ZC07, DWCR11]). Recent developments in the
ML community provide ways to reﬁne and improve topic

submitted to COMPUTER GRAPHICS Forum (6/2018).

models by integrating user feedback, e.g. moving words from
one topic to another [HBGSS14].

There have been extensions of LDA-based techniques and
other text analytics by investigating texts in the combina-
tion ¡topic, time, location, people¿. This permits the anal-
ysis of the ebb and ﬂow of topics in time and according
to location [DWCR11, DWS∗12, LYK∗12]. Time-sensitivity
is revealed not only in topics but in keyword distribu-
tions [DWS∗12]. Lately there has been work to add peo-
ple and demographic analysis as well [DCE∗15]. Combining
topic, time, and location analysis leads to identiﬁcation of
events, deﬁned as “meaningful occurrences in space and
time” [KBK11, DWS∗12, CDW∗16, LYK∗12]. Here the topic
analysis can greatly help in pinpointing the meaning. In
addition, combining topic modeling with named entity ex-
traction methods, such as lingpipe [20008], can greatly en-
hance the time, location, and even people structure since
these quantities can be automatically extracted from the text
content [MJR∗11, CDW∗16].

At this point,

it is worthwhile to describe a visual
analytics system that combines all these characteristics.
VAiRoma [CDW∗16] (shown in Figure 11) creates a nar-
rative that tells the whole 3,000 year history of Rome, the
Empire, and the state of Italy derived from a collection of
189,000 Wikipedia articles. The articles are selected from the
nearly 5M English language article collection in Wikipedia
using a short list of keyword, but otherwise the initial topic
modeling and named entity extraction are done automati-
cally. The interface for VAiRoma is displayed in Figure 11.
The individual topics are depicted as color-coded streams in
the timeline view (A). The circular topic view in (C) pro-
vides a compact way of depicting topics, the weights of their
contributions for a given time range, and topic keywords.
The navigable map view in (B) provides immediate updates

14

Endert et al. / Integrating Machine Learning into Visual Analytics

of geographic distribution of articles (based on locating the
geographic entities in the text) in terms of hotspots for a
selected time range and topic. The window (f) lists article
titles for selected geographic view, time range, and topic. In
Figure 11, one can clearly see event peaks for selected topics
having to do with Roman government and military battles in
the period from 500 BC to 500 AD. The interlinked windows
in the interface plus key topics and event peaks permit a user
to quickly peruse the main events in ancient Roman history,
including the rise of Christianity and the Catholic church,
trade with India and the Far East, and other events that one
might not ﬁnd in looking narrowly at, say, just the history
of the Roman Empire. In this case, the user can focus from
thousands of articles to a few hundred articles overall, which
she can then quickly peruse. See the VAiRoma article for
more details.

VAiRoma shows the power of the overall model depicted
in Figure 3. Though it is not complete w.r.t. this model (no
current VA system is), it provides an integrated approach
to data handling, interactive visualization, ML (in this case
topic modeling) combined with other techniques, and ex-
ploration and knowledge building techniques. It shows the
power of an integrated approach. The approach is general
and is now being applied to large, heterogeneous collections
of climate change documents. In addition, full text journal
article collections are being analyzed using extensions of the
topic modeling and entity extraction methods. This shows
that once ¡topic, time, location, people¿ features and event
signatures can be extracted, analyses based on these ana-
lytics products can integrate a wide range of heterogeneous
collections.

4.2. Multimedia Visual Analytics

Visual analytic applications have also been developed to
allow people to explore multimedia (i.e., images, video, au-
dio). For example, iVisClassiﬁer shows how facial expression
features can be incrementally explored and classiﬁed by
a combination of image feature-detection algorithms and
user feedback [CLKP10]. Through interactively adding and
removing images from classiﬁers, the model learns the fa-
cial expressions that are interesting (and similar) to the
user. It combines analytic models such as feature extraction
and classiﬁcation with visual analytic approaches. Multi-
Facet is another example of visually analyzing multimedia
data [HHE∗13]. MultiFacet presents facets of each data type
to users as interactive ﬁlters. Thus, the process of interac-
tively selecting attributes of diﬀerent data types helps create
groups of conceptually interesting and related information.

As image and video data is often combined with text data
(or textual metadata attached to the images or videos), fus-
ing the feature space between these datatypes is an open
challenge. Automated approaches are error-prone, and of-
ten require user intervention and guidance when semantic
concepts and relationship need to maintained across data
types [CBN∗12]. Similarly, an example of a much more spe-
ciﬁc application is given in [BM13] where the authors present

a steering mechanism for source separation in a single mono-
phonic recording. The user can annotate a standard time-
frequency display to roughly deﬁne the diﬀerent sources.
Errors made by the algorithm can be annotated to improve
further the separation.

4.3. Streaming Data: Finance, Cyber Security,

Social Media

Streaming data is a growing area of interest for visual ana-
lytics. Data are no longer isolated and static, but instead are
part of a sensor-laden ecosystem that senses and stores data
at increasing frequencies. Thus, visual analytic systems that
integrate machine learning models have great potential. Ex-
amples of domains that generate streaming data include the
ﬁnancial industry, cyber security, social media, and others.

In ﬁnance, for example, FinVis is a visual analytics sys-
tem that helps people view and plan their personal ﬁnance
portfolio [RSE09]. The system incorporates uncertainty and
risk models to compute metrics about a person’s portfolio,
and uses interactive visualizations to show these results to
users. Similarly, Ziegler et al. presented a visual analytic sys-
tem to help model a user’s individual preferences for short,
medium, and long-term stock performance [ZNK08] and later
extended their approach to real-time market data [ZJGK10].
Figure 12 is an example of how visualisations can provide
an in-depth understanding of the groupings (clusterings) of
ﬁnancial time series. Here, ﬁnancial market data for assets
in 3 countries and 28 market sectors from 2006 and 2009 are
depicted. The red bars indicate the crash of the stock market
in 2008 and the visualisation enables the user to identify the
overall changes but also notice subtle variations such as the
lack of a response in some countries for particular sectors.

Cyber security is a domain fraught with fast data streams
and alerts. Examples of machine learning techniques often
incorporated into systems that support this domain include
sequence and pattern-based modeling, rule-based alerting,
and others [BEK14]. People in charge of the safety and relia-
bility of large networks analyze large amounts of streaming
data and alerts throughout their day, thus the temporal com-
ponent of making a decision from the analysis is emphasized.
For example, Fisher et al. presented Event Browser, a vi-
sual analytic system for analyzing and monitoring network
events [FMK12]. Their work emphasizes how diﬀerent tasks
of the analyst have to happen at diﬀerent time scales. That
is, some tasks are “real-time”, while others can be taken
“oﬄine” and performed for a longer duration of time. The
persistent updating of new data into the oﬄine tasks presents
challenges.

Social media data can also be analyzed using visual an-
alytic systems. For example, Storylines [ZC07] and Even-
tRiver [LYK∗12] are two examples of how visual analytic
applications can help people understand the evolution of
events, topics, and themes from news sources and social
media feeds. In these systems, similar machine learning tech-
niques are used as for text. However, the temporality of the
data is more directly emphasized and taken into account.

submitted to COMPUTER GRAPHICS Forum (6/2018).

Endert et al. / Integrating Machine Learning into Visual Analytics

15

Figure 11: Overview of VAiRoma Interface. The interface has three main views: Timeline view (A), Geographic view (B)
and Topic view (C). A user-generated annotation is shown in the Timeline view.

Lu et al. [LKT∗14] showed how appropriate social media
analysis could have predictive power, in their case predicting
movie box oﬃce grosses from early word of mouth discus-
sion on Twitter, YouTube, and IMDB. A dictionary-based
sentiment analysis was used along with analytics from the
R statistical computing environment and the Weka machine
learning workbench. This permitted a choice of modeling in
terms of multivariate regression, support vector machines,
and neural networks. The paper promoted an integrated vi-
sual analytics approach where the interactive visualizations,
based on D3, permitted users to investigate comments and
sentiment, classify similar movies, and follow trends and
identify features. The user could then improve a base line
regression model based on trends and features identiﬁed in
the visaulizations. Results of the use cases were positive
with several of the non-expert participants being able to
outperform experts in predicting opening weekend grosses
for 4 ﬁlms, according to the criteria set up by the authors.
The paper has the usual limitation of supervised learning
approaches in that a training dataset must ﬁrst be collected
and analyzed as a preliminary step, but it does successfully
allow for improvement of the analytic model within the VA
environment. Also, like many papers dealing with more com-
plex analysis, it deﬁnes a process for best use of the system;
this appears to be an important and eﬀective approach for
VA + ML systems.

Yeon et al. [YKJ16] covered similar ground in their identi-
ﬁcation and analysis of interesting past abnormal events as
a precursor for predicting future events. Here, as in Lu et al.
and in other papers using ML, context and analytic power
is obtained from combining multiple sources (in this case
social media and news media). Yeon et al. identify contextual
pattern in these past events, which permit them to make
predictions for future events in similar contexts. An interac-

submitted to COMPUTER GRAPHICS Forum (6/2018).

Figure 12: Aggregated visual representations and clustering
have been used in supporting the real-time analysis of temporal
sector-based market data [ZJGK10].

tive interface involving spatio-temporal depiction of events
plus identiﬁcation of other features permits the choosing of
interesting events and speciﬁcation of their contexts. Trends
for the unfolding of future events and possible unfolding story
lines can then be created. The authors evaluated their VA
system with three use cases.

4.4. Biological Data

Biology, and in particular, bio-informatics are ﬁelds that are
increasingly becoming data-rich and the use of visualisation
empowered analysis methods are proving highly useful and
eﬀective [GOB∗10]. Although most computational analysis
solutions only incorporate visualization as a communication
medium and do not make use of interaction, there are a num-
ber of examples where VA and ML approaches operate in
integration. Within the context of epigenomic data analysis,
Younesy et al. [YNM∗13] present how a number of ill-deﬁned
patterns and characteristics within the data can be identiﬁed
and analysed through the help of interactive visualizations

16

Endert et al. / Integrating Machine Learning into Visual Analytics

and integrated clustering modules. They demonstrate how
user-deﬁned constraints can be utilised to steer clustering
algorithms where the results are compared visually. Grottel
et al. [GRVE07] discuss how interactive visual representa-
tions can be instrumental in interpreting dynamic clusters
within molecular simulations. In addition to these, interac-
tive visualisations have been shown to support bi-cluster
analysis [SGG∗14]. The authors utilize an interactive layout
where fuzzy bi-clusters are investigated for multi-tissue type
analysis. Biclustering is an algorithmic technique to solve for
coordinated relationships computed from high-dimensional
data representations [MO04], and has been used in other
domains, including text analysis [SNR14, SMNR16, FSB∗13].

In addition to the above methods where the focus is mainly
on investigating clusters, there are also works where in-
teractively speciﬁed high-dimensional data projections are
utilised to characterize and compare diﬀerent cancer sub-
types [ADT∗13]. In their tool called viSNE, the authors
demonstrate how user-driven, locally applied projections
preserve particular relations and they argue that such meth-
ods are instrumental in interpreting any multi-dimensional
single-cell technology generated data.

5. Embedding Steerable ML Algorithms into

Visual Analytics

As discussed above at several points and categorized in Sec-
tion 3, one area of research that has been recently attracting
much interest in the machine learning and data visualization
communities is the development of interactive approaches
binding visualizations to steerable ML algorithms. This goes
beyond typical interactive ML methods in that it places
interaction at the same level as visualization and ML, thus
producing a powerful extension of visual analytics. As ex-
plained in [Van05], [PSCO09], interaction provides feedback
in the visualization process, allowing the user to manipulate
the parameters that deﬁne a visualization on the basis of
the knowledge acquired in previous iterations. In particu-
lar, low latency interaction with large update rates of the
visual display provides higher levels of user involvement in
the analysis [EMJ∗11], triggering low level attention and
processing mechanisms (such as tracking moving items),
where the user’s senso-motor actions have immediate ef-
fects in the displayed information. Despite interaction mech-
anisms having extensively been discussed in the visualiza-
tion literature [Van05], [PSCO09], the relationships between
these parameters and the resulting visualization are in most
cases of a simple nature, including changes of scale, displace-
ments, brushing, etc., specially for low latency interaction.
As pointed out in [VL13], hardly ever are complex interac-
tions or transformations based on intelligent data analysis
undertaken at this level. This fact is certainly surprising,
especially considering that ML is a mature discipline and the
power of today’s hardware, as well as programming languages
and libraries make it possible to use algorithms (or adapted
versions of them) as intermediates between the user actions
and the visualization, even at low latency levels.

The DR algorithms discussed in Section 3, which con-
struct a mapping from a high dimensional input space onto
a typically 2D or 3D visualization space, would be partic-
ularly useful for extended VA approaches. To build such
mappings, DR algorithms seek to preserve neighborhood
relationships among the items in both spaces, resulting in
representations that follow the so called “spatialization prin-
ciple” (based on the cartographic principle where closeness
≈ similarity [Sku02]). Placing similar items in close positions
results in highly intuitive arrangements of items in a visual
map that serves as a basis for developing insightful visual-
izations of high dimensional elements [Ves99, KP11, EBN13].
Moreover, the connection that DR mappings make between
something that can be “seen” and a high dimensional feature
space suggests using the visual map as a canvas where classi-
cal interaction mechanisms (zoom, pan, brushing & linking,
etc.) can be used to explore high dimensional data.

However, interaction can go far beyond this point by al-
lowing the user to steer the DR algorithm through the vi-
sualization by direct modiﬁcation of its parameters or by
making transformations on the input data. As discussed in
Section 3, this idea has been explicitly formulated in [CP13]
as iteration-level interactive visualization, which aims at vi-
sualizing intermediate results at various iterations and let-
ting the users interact with those results in real time. In a
slightly more formal way, as shown in [DCV16], an interac-
tive DR algorithm –the argument can be extended to other
ML algorithms– can be considered as a dynamically evolving
system, driven by a context that includes the input data and
the algorithm’s parameters

˙y = f (y, u),

v = g(y)

(1)

where y is the internal state of the algorithm, v is the outcome
of the algorithm (e.g. a visualization), which depends on
the internal state, and u = {x, w} is a context vector that
contains the input data x and the algorithm parameters w.
In a general framework, the user will steer the algorithm
by manipulating w based on his/her knowledge acquired
from the visualization v. Under a ﬁxed context u0 –i.e. no
changes in the input data or the algorithm parameters–, the
internal state y in model (1) will keep on changing until it
reaches convergence to a steady state condition 0 = f (y0, u0).
Changes in the algorithms parameters w or in the input
data x will make the internal state evolve to a new steady
state condition 0 = f (y1, u1), and hence result in a new
visualization v1. For a continuous f (·) –typically for non-
convex algorithms, based on gradient descent approaches–
the representation v(t) will smoothly change, resulting in
animated transitions that provide a continuous feedback to
the user. Despite the fact that this behavior opens a broad
spectrum of novel and advanced user interaction modes and
applications, this is still a rather unexplored topic.

Many possibilities may arise from this approach, all based

on changes in diﬀerent elements of the context vector u:
• One fundamental subset of parameters that conveys a
great deal of user insight are the input data metrics, which

submitted to COMPUTER GRAPHICS Forum (6/2018).

(cid:107)a(cid:107)Ω =(cid:80)

(cid:80)

Endert et al. / Integrating Machine Learning into Visual Analytics

17

r

can be expressed as a weight matrix Ω = (ωrs) being
s arωrsas, whose parameters are included
in w. Prior knowledge on the relevance of features can
be easily considered allowing user-driven modiﬁcations in
the diagonal elements of ωii ⊂ w. An example related to
this idea is the iPCA [JZF∗09], an interactive tool that
visualizes the results of PCA analysis using multiple coor-
dinated views and a rich set of user interactions, including
modiﬁcation of dimension contributions. A similar idea on
the stochastic neighbor embedding algorithm (SNE) was
also proposed in [DCP∗14].
• The user might also have insight on the similarities be-
tween items. In [BLBC12], a system called dis-function was
developed, featuring DR visualization that allows the user
to modify the distance matrix Dij = (cid:107)ai − aj(cid:107)Ω between
items i, j, by moving points in the visualization based
on his/her understanding of their similarity, and see new
results after a recomputation of the projections with the
new metrics.
• Also, prior knowledge on class information can be inserted
by the user, suggesting techniques to increase the similar-
ity of items belonging to the same class. In [PZS∗15] a
method is proposed to allow the user to include prior class
knowledge in the DR projections by extending the original
dataset with transformations of the original feature space
based on his existing class knowledge.
• Finally, the input data x in model (1) may change with
time (x = x(t)), suggesting the use of iDR on streaming
data to provide live visualizations v(t) that convey time
varying information; in this case, user interaction is possi-
ble through timeline sliders, making it possible to explore
how input data items and their relationships evolve in time
by moving back and forth in time.

These cases imply a substantially more advanced kind of
feedback to the user than traditional interaction mechanisms.
Placing these capabilities in a visual analytics framework
greatly empowers them. As described in Figures 2 and 3,
such a framework supports analytic reasoning, the discov-
ery of much deeper insights, and the creation of actionable
knowledge. The mere fact of being part of sensemaking and
knowledge feedback loops (a virtuous cycle) suggests that
there is huge potential and a broad spectrum of possibilities
in the integration of ML algorithms discussed in this paper,
where even the simplest ones may have multiplicative eﬀects.
For certain types of analysis, such as following animated tran-
sitions, this sort of interaction mechanism must be achieved
in a ﬂuid manner, with low latencies and fast update rates.
However, this is not necessarily required for all knowledge
generation and synthesis activities, as discussed next.

Levels of Interactive Response A long-recognized up-
per threshold for latency in WIMP and mobile interfaces
is 0.1 second. Faced with higher latencies, users start to
lose the connection between their actions and the visual re-
sponse, commit more typing or selection errors, and become
frustrated [HB11]. This limit has also been discussed as an
upper threshold for coherent animations (though completely

submitted to COMPUTER GRAPHICS Forum (6/2018).

smooth animations would require a lower latency) and for
a range of interactions in immersive VR. However, the de-
tailed eﬀects of particular latency thresholds depend on the
task. For embedded analytics tools in VA systems, such as
steerable ML methods, it is useful to deﬁne a wider range of
interactive responses [RF16]:
• Real-time Regime: ¡ 0.1 second. Interactions such as mov-
ing a time slider to control an animation of time-dependent
behavior or changing the weighting factors of leading di-
mensions in an interactive PCA tool [JZF∗09] to reveal
changes in the projected surface fall into this regime. Such
interactions can be employed for rapid exploration and
spotting of trends.
• Direct Manipulation Regime: 0.1 to 2-3 seconds. Analytic
reasoning tends to involve more complicated interlinking
of rich visualizations with ML methods. For example, the
VAiRoma geographic window shows multiple hierarchical
hotspot clusters (Figure 11) when a time range and topic
are selected, but there is a delay of 2-3 seconds before the
result is displayed. The user must peruse this distribution
and its areas of concentration, which can take several
seconds or more. During interface evaluation the delay was
not noted and does not seem to hinder the user’s reasoning
process [CDW∗16], perhaps because the user is thinking
about the selection when it is made, and what it may
mean, which then ﬂows into her reasoning process once
the result appears. The same seems to be true when the
user makes a selection of a geographic region or a topic and
experiences a similar delay until updates in the timeline
or other linked windows appear.
• Batch Regime: 10 seconds or more. Here the cognitive ﬂow
of human reasoning is interrupted. To minimize eﬀects of
this interruption, the best analytics at this level of response
might be those that launch a new reasoning direction (e.g.,
recalculation of textual topics based on a revised set of
keywords).

These levels of response are related to performance timings
from enactive cognition [GSFS06], suggesting that this model
can be applied here. An important conclusion of this discus-
sion is that it is not necessary to have real-time response
for certain interactive ML algorithms; delays up to 2-3 sec-
onds and perhaps more might be digestible by the user. This
could substantially reduce the burden of interactive response
for ML algorithms. Of course, further user studies of these
algorithms in action should be carried out.

6. Open Challenges and Opportunities for ML and

VA

Collaboration between ML and VA can beneﬁt and drive
innovation in both disciplines. Advances in ML can be used
by VA researchers to create more advanced applications for
data analysis. This includes the optimization of currently
integrated techniques, but also the discovery of additional
techniques that ﬁt into the broad range of analytic tasks
covered by visual analytic applications [AES05, LPP∗06].
Similarly, as advances are made in VA applications, the user

18

Endert et al. / Integrating Machine Learning into Visual Analytics

requirements and needs can drive new ML algorithms and
techniques.

Below, we list a collection of current challenge and oppor-

tunities at the intersection of ML and VA.

6.1. Creating and Training Models from User

Interaction Data

ML models are typically built and modiﬁed based on ample
training data that contain positive and negative ground truth
examples. While many domains and tasks can be solved with
ample training data, there exist scenarios, as discussed in this
paper, where not enough training data is available. For these
cases, it becomes important to incorporate user feedback
into the computation in order to guide and parametrize the
computational model being used. This raises the challenges
of how to incorporate user feedback into computation in an
eﬀective and expressive, yet usable manner?

The concept of interactive machine learning has taken into
account user feedback to steer and train these models. For
example, users can provide positive or negative feedback to
give support for or against suggestions or classiﬁcations made
by the model. The models adjust over time based on this
input.

However, there is the ability to look beyond labeling, or
conﬁrming and refuting suggestions as way to incorporate
user feedback [ECNZ15] - what about the remaining user
interaction that people perform during visual data explo-
ration? User interaction logs contain rich information about
the process and interests of the user. Examples of the kinds
of inferences that can be made from the user interaction
logs are shown in more detail earlier in the report. Thus,
the opportunity exists for ML techniques to leverage the
real-time user interaction data generated from the analysts
using the system to steer the computation.

Systems that take into account a broader set of user inter-
actions enable people more expressivity in conveying their
mental model, preferences, and subject matter expertise. Fur-
ther, taking into account the broader set of user interaction
allows users of the system to stay more engaged in the act
of visual data exploration, as opposed to actively training
the model and system.

Figure 13 shows a model for how multiple types of user
input can be incorporated into the machine learning mod-
els driving visual analytic techniques. As is shown in this
model, two broad types of models can be created from user
interaction: Data models and User Models. In general, data
models refer to weighted data items and attributes. These
can be weighted computationally, or via user feedback. Fur-
ther, these weights can be computed based on inferences
on the user interaction (i.e., to approximate user interest
of focus). User models typically refer to computational ap-
proximations of the state of the user (e.g., cognitive load,
personality traits [BOZ∗14], etc.)

In addition to steering existing models (such as dimension

Figure 13: A model from [ECNZ15] showing how multiple
types of user input can be used to steer machine learning
models in VA.

reduction models, topic models, etc.), such user feedback can
indicate the need for novel models to be created. By focusing
on the user interaction, new discoveries can be made about
the processes and analytic tasks of people during data analy-
sis. This continued study, or science of, interaction [PSCO09]
can lead to advances in the machine learning community in
the way of new algorithms or techniques that model analytic
tasks or processes of people.

6.2. Balancing Human and Machine Eﬀort,

Responsibility, and Tasks

For mixed-initiative systems, it is a common notion that
there exists a balance of eﬀort between the user and the
machine [Hor99]. This eﬀort can be divided by decomposing
the larger task into sub-tasks that are either better suited
to the person, or more quickly performed by the system.
Similarly, these tasks often break down into being more well-
deﬁned and quantitative (i.e., solved by computation), or
subjective and less formally deﬁned (and thus needing input
from the user). For example, a mixed-initiative visual analytic
system for grouping and clustering can take into account the
exemplar data items that are grouped by the user, generate a
data model from those examples, and organize the remaining
data points [DFB11].

However, there remains the need for generalizable empirical
evidence to inform researchers about how to balance this
eﬀort between the user and the machine. It is not clear the
extent to which tasks should be divided, or co-completed.
Typical data analysis sessions involve many user tasks and
sub-tasks [AES05], and dividing the eﬀort of these tasks
between the user and the system is challenging.

It is also unclear exactly how to measure the amount of ef-
fort expended by both the user and the system. For example,
in a visual analytic system that helps people cluster docu-
ments, Endert et al. used a measure of how many documents
were moved and grouped by the user and how many were
automatically grouped by the system [EFN12a]. However,

submitted to COMPUTER GRAPHICS Forum (6/2018).

Endert et al. / Integrating Machine Learning into Visual Analytics

19

there exist opportunities to consider additional metrics for
the balance of eﬀort in mixed-initiative systems that can
drive the possibility of novel evaluations of eﬀectiveness.

6.3. Complex Computation Systems can lead to

Automation Surprise

By coupling machine learning with visual analytics systems,
we can develop complex systems made up of many inter-
related and inter-dependent “black boxes” of automated com-
ponents for data analysis, knowledge discovery and extraction.
Complex systems will typically comprise many instances of
known and hidden inter-dependencies between components
and yield outputs that are emergent where the interactions
among agents and individual units may be deterministic.
The global behaviour of the system as a whole may conform
with rules that are only sometimes deducible from knowledge
of the interactions and topology of the system. This makes
it diﬃcult to know exactly which inputs contribute to an
observed output, and the extent of each factor’s contribu-
tions [SS11, Orm]. Sarter and Woods [SWB97] observed that
interactions between these tightly coupled automated “black
boxes” can create consequences and automation surprises
that arise from a lack of awareness of system state and the
state of the world. This creates potential for error, compla-
cency from trusting the technology, placing new demands on
attention, coordination and workload.

At the risk of saying the obvious, an approach proposed
by Norman [Nor86] to address some of the problems of
controlling complex systems is based on observability and
feedback. They are crucial for ﬁguring out how a system
works, and they help us aﬃrm the mental models that drive
our thinking and analysis of a problem or a device. Poor
observability of automated advanced intelligent processes
makes it diﬃcult to evaluate if outcomes from the automated
computations are within the bounds of normal or acceptable
behavior, or whether our instructions to the system were
correctly executed or what else was included in the execution
that was not intended. Good mapping between designed
action and desired action helps us anticipate and learn how
to interact with the system. Good mapping also helps us see
the connection between what the system was instructed to
do, and the outcome of carrying out that instruction.

One of the major challenges then, is for visual analytics
designers to create designs that “... facilitate the discovery
of meaningfulness of the situation ... not as a property of the
mind, but rather as a property of the situation or functional
problems that operators are trying to solve ... [by] develop-
ing representations that specify the meaningful properties
of a work domain ... so that operators can discover these
meaningful properties and can guide their actions appropri-
ately” [BF11].

To create such a design, there is a need to have a conception
of the analytical thinking and reasoning process that extends
beyond the information handling and manipulation aspects
that are frequently described. A focus group study with 20

submitted to COMPUTER GRAPHICS Forum (6/2018).

Figure 14: Characterizing the thinking terrain of ana-
lysts [Won14].

intelligence analysts [WV12], think-aloud studies with 6 an-
alysts performing a simulated intelligence task [RAWC14],
and think-aloud studies with 6 librarians carrying out a
surrogate task of creating explanations from a literature
review task [KAW∗13] provide insight into this analytical
thinking and reasoning process. The results of these studies
indicate that analyst make use of the various inference mak-
ing strategies described in Section 2.1 - induction, deduction
and adduction - depending upon what data they have, the
rules for interpreting the data, and premise they are starting
with and the conclusions they would make or would like to
make. Furthermore, very often they would test the validity of
the propositions they arrive at by practicing critical thinking
- where they attempt to assess the quality and validity of
their thinking and the data they use, the criteria they use for
forming judgments, and so forth. In fact, critical thinking is
so important that many intelligence analysis training schools
have introduced it into their training.

One thing else that is observed to happen alongside all
of this is somewhat more subtle: Analysts are constantly
trying to explain the situation, sometimes re-constructing
the situation from pieces of data and from inferential claims;
and then carrying out searches or further analysis to ﬁnd
necessary data back the claims. This process of explana-
tion is crucial to making sense and how it is used to link
data, context and inferences. It often starts oﬀ as a highly
tentative explanation that is based on very weak data or
hunches. The analyst then explores this possibility, making
conjectures, suppositions and inferential claims, from which
they then connect with further data (testing their relevance
and signiﬁcance), elaborate, question, and often reframe and
discard, their ideas, and eventually building up the story
so that it eventually becomes robust enough to withstand
interrogation.

We see a progression - not necessarily in a linear manner
- where explanations reﬂect tentative, creative and playful,
and generative thinking, and then transitions towards think-
ing strategies that are more critical, evaluative, deliberate
and ﬁnal (see Figure 14 for an illustration depicting this

20

Endert et al. / Integrating Machine Learning into Visual Analytics

discussion). One can assume a continuum where at one end
we have a tentative explanation we call a “loose story” that
accounts for the data, and at the other end the loose story
has evolved into a strong and more formal argument such
that it is rigorous and able to withstand interrogation, say,
in a court of law.

At the “formal argument” end of the continuum, there is
much lower uncertainty. The analyst is more deﬁnite about
what the data and their relationships mean, and very likely
has become more committed to a particular path of investiga-
tion. At this end, the emphasis is on verifying that the data
used to construct the conclusions, the claims being made
based on the data, and the conclusions themselves, are valid.

The combined machine learning and visual analytics tools
to be built should ﬂuidly link the generative, creative, play-
ful and tentative exploration activities that encourage the
exploration of alternatives, appreciation of the context, and
the avoidance of pre-mature commitment, with the more
evaluative, critical inquiry that leads to a deliberate, ﬁnal
and rigorous explanation. This is the notion of the design
principle of ﬂuidity and rigour.

6.4. Visualizing Intermediate Results and

Computational Process

Many kinds of ML algorithms undergo a continuous con-
vergence process towards the ﬁnal solution. In general, only
this ﬁnal solution is rendered into a visualization, which may
incorporate classical interaction mechanisms (zoom, pan,
brushing, focus&context, etc.). This convergence is often
done within a ﬁxed context, that includes the training set,
the algorithm parameters and the cost function. These ele-
ments often convey a large amount of insight for the user,
but since they remain ﬁxed during convergence users are
deprived of the beneﬁts of interaction. What if the user could
steer these ﬁxed elements “during” convergence?.

A promising topic, involving innovation by both VA and
ML communities, is rendering visualizations of the intermedi-
ate results during convergence, allowing the user to tunesteer
the ML algorithms by changing these elements. Designing ad
hoc ML algorithms with this approach in mind that pave the
way for new and useful kinds of interaction mechanisms opens
new and exciting research paths. There has been some prior
work on this topic. For example, Stolper et al. developed a
system for progressive visual analytics, where intermediate
results of a sequence-mining algorithm running on medical
treatment events can be shown to clinicians [SPG14]. Their
work gave analysts the ability to see broader results sooner
to help decide if the entire computation needed to be ex-
ecuted. Similarly, systems to show partial query results of
large datasets [FPDs12] and partial dimension reduction and
clustering results [TKBH17] have been recently developed..
These works raise important questions about the tradeoﬀ
between accuracy and execution time of these algorithms,
and also about how to incorporate user feedback into com-
putation during runtime.

6.5. Enhancing Trust and Interpretability

A key element of the visualization approach is its ability
to generate trust in the user. Unlike pure machine learn-
ing techniques, in a data visualization the user “sees” the
data and information as a part of the analysis. When the
visualization is interactive, the user will be part of the loop
and involved in driving the visualization. In such a context,
the development of a mental model goes hand in hand with
the visualization, as everything is part of the process. This
tight involvement of the user in the development of the visu-
alization based on the results of previous iterations, along
with the highly visual component of human thinking, can
make this approach generate a great amount of trust in the
user. However, such “trust” can have diﬀerent meanings at
diﬀerent levels of cognition. An apparently trustable result
at an intuitive level can arouse suspicions at a higher cog-
nitive level, demanding methods for statistical conﬁrmation
of the results. On a broad view, two diﬀerent levels can be
identiﬁed:

1. A “qualitative level”, that would make heavy use of percep-
tion visualization principles along with interaction mech-
anisms to present data in an intuitive way. The commu-
nication in both senses (from and to the interface) will
typically seek to: a) adapt to individual’s perception mech-
anism so that the information throughput and knowledge
increment on the user is maximized; and b) in a higher
level, to adapt to the human cognitive process so that data
and information is presented in a way that is intuitive
to the user. The means to carry out this approach would
rely on classical visualization methods (adequate use of
visual encodings and spatial layouts) and on interaction
techniques, including brushing, linking, coordinated views,
animated transitions, etc., but also in much more powerful
approaches such as user-driven steering of ML algorithms
(such as DR, clustering, etc.) resulting in the reconﬁgu-
ration of the visualization on the basis of changes in the
context such as time varying data or changes in the user
focus on diﬀerent types of analysis.

2. A “quantitative level” is, however, needed to provide sound
statistical validation of the former visualization results.
Taken in an isolated way, this level would lack insight.
However, its outcomes are supposed to be trustworthy so
the user can consider them as deﬁnite validations. Quanti-
tative approaches –mainly belonging to the realm of ML–
are in essence deterministic, which makes them less prone
to human errors and reproducible. This helps to stan-
dardize decisions and provides congruence, accurateness,
uniformity and coherence in the results.
However, quantitative approaches tend to avoid the need
for user intervention by trying to automate the process.
In general they do not look for human feedback but un-
dertake as many human tasks as possible in the process,
automating it to the maximum possible extent, aiming to
avoid any kind of human subjectivity and seeking rigor
(statistical, mathematical). But many problems in real
life are built on sparse bits of knowledge coming from
diverse domains. Moreover, such knowledge is often made

submitted to COMPUTER GRAPHICS Forum (6/2018).

Endert et al. / Integrating Machine Learning into Visual Analytics

21

of vague or imprecise mental models. Purely quantitative
approaches cannot operate with such small, diverse and
“fuzzy” bricks; they need solid foundations to be operative.

The previous division is only conceptual. Both approaches
can (and should) be combined. For instance, a statistical
validation of one or more facts can be displayed on top of the
qualitative visualization by making use of visual encodings
and text labels. We encourage visual analytics designers to
seek eﬃcient combinations between qualitative and quan-
titative approaches, looking for concurrent visualization of
actual problem data and sophisticated computed features,
both coexisting in the same representation. The mere fact of
representing statistical validations sharing the same layout
and structure as the original data in a same visualization
allows the user to internalize that quantitative information
allowing her to connect it to its domain knowledge, with an
unquestionable positive eﬀect on trust and conﬁdence in the
results.

6.6. Beyond Current Methods

Currently, many of the applications of machine learning in vi-
sual analytics relate to dimensionality reduction. In addition,
as discussed in Section 4, there are a diﬀerent sort of ML
methods based on Bayesian inferencing and including topic
modeling and textual analytics approaches. These are becom-
ing more prominent. While these applications are undeniably
an important use of machine learning, we contend that con-
sideration of the role of the user opens up several new ﬁelds
of study where machine learning can play an important role.
First amongst these is the role of machine learning in creating
a computational model for the user’s analytical process. This
complements cognitive task analysis and aims to model how
domain expert users use visual analytics to tackle important
tasks, and how they reason about the problem. This will
enable better system design to support expert strategies and
provide support to less-trained users.

Every user interaction has two primary functions: i) to
communicate a direct explicit intent from the user to the
analytical system and receive an appropriate response (e.g.
if the user requests a zoom into a particular area, the system
should create that zoomed-in visual display), and ii) to carry
out an indirect implicit piece of analytical reasoning.

The point is that every user choice in the visual analytics
frame is equivalent to a statistical choice in the mathematical
frame: we need users to make appropriate choices that do
not invalidate the (implied) statistical analysis that they are
carrying out. Motivated by the analysis of how users carry out
visual analytics, particularly the concepts of sense-making
and knowledge generation, the ﬁrst step to understanding
the details of this process is to compile a complete log of
users’ analytical process and the information that they record.
This is the base dataset that can be used for traceability,
responsibility and provenance: providing an argued case for
others (such as collaborators or managers) to critique and use
to make decisions. However, beyond this use, the database is

submitted to COMPUTER GRAPHICS Forum (6/2018).

also a resource to mine in order to clarify the decisions that
are made in the course of visual analytics, leading to the
potential to develop adaptable interfaces and a greater depth
of understanding of users’ mental models, which can then
be used to guide other, perhaps less skilled or experienced,
users.

It would not be feasible (nor practically useful) to track
every single change in a visualisation. It is essential that
the process involves minimal interruption to cognitive ﬂow
(so as to avoid damaging the very process we are trying to
understand). However, it would be helpful to prompt the
user for feedback (preferably in visual ways), in the form of
annotations, at certain key points of the analysis. We propose
using machine learning (e.g. to look for breakpoints in the
way information is displayed) as cues for these prompts. The
process model can also learn from user interaction (with
appropriate additional guidance). For example, if the user
‘undoes’ a particular action, it could mean “I don’t want this:
my choice was wrong” or “The visualisation is useful, but it
is a dead end and I need to back-track”. Other simple user
interactions that can connect to reasoning processes include
brushing data points (which corresponds to selecting and
labelling a subset of data) and linking (which corresponds
to hypothesising correlations between variables and data
points).

As a complement to this database of successful analytic
practice, what many users need is a way of avoiding bad
practice (or errors). A catalogue of ‘typical’errors that is
searchable (using case-based reasoning tools) could be crowd-
sourced from teachers (and their students!) or training
courses.

How can machine learning aid the understanding of user
processes? At the simplest level, user interactions are a linear
sequence of actions: discovering the underlying sequence and
the transitions between items is relatively straight-forward,
since a Markov (or hidden Markov) model can easily be
trained to uncover this structure. However, an unstructured
and unannotated sequential list does not contain enough
structure to infer the analytical process. Firstly, we need to
understand the reasons why a user has made choices (which
requires annotations). Secondly, it is clear that the analytical
process is not a simple sequence of logical choices leading
inexorably to a goal. Instead, the process involves exploratory
analysis – trying a range of options and assessing which is
the most successful – and back-tracking when results show
that a particular line of inquiry is fruitless. These transform
what is, in terms of a graphical model, a one-dimensional
structure, into a tree or directed acyclic graph.

The theory of Bayesian belief networks (BBNs) is rele-
vant here. There are two aspects of the model that can be
learned: the conditional probability tables (CPTs) for the
links from all the parents of a particular node; and the struc-
ture of the network (the presence or absence of directed links)
which represents the conditional (in)dependence of variables.
Learning the CPTs for a given network structure is straight-
forward: with suitably chosen Bayesian priors (a Dirichlet

22

Endert et al. / Integrating Machine Learning into Visual Analytics

distribution), it is a matter of counting co-occurrences of
value pairs in a dataset [SDLC93]. Learning the structure of
a BBN is much more complex: in fact, the general case is NP-
hard [Chi96]. Some special cases (such as trees) are tractable,
but in this domain it is preferable to ﬁx the structure based
on our understanding of the users’ analytical process. Models
for this process, such as CRISP-DM [WH00] (used in data
mining) or those drawn from the infovis community (such
as the semantic interaction pipeline), are currently rather
high-level, and a more detailed task analysis is necessary
before the requisite level of detail for a full computational
model can be achieved.

Once a computational user model for the analytic process
is established, there are a number of other ways machine
learning and visual analytics can be brought into dialogue.

1. Semi-automated report generation. Machine learning can
be used to infer links and relations between concepts, data,
and analytical results, while frequentist or Bayesian statis-
tical analysis can be used to attach a statistical signiﬁcance
to each ﬁnding. This could be presented to the user as a
checklist of automatically discovered analytical ﬁndings
(or hints) that the user can accept or reject.

2. Annotations can be categorised using automated topic
analysis (for example by Natural Language Processing that
uses probabilistic graphical models [LHE10]). The value
of this is to link annotations and ﬁnd common approaches
to tasks.

3. Model-based layout. The goal

is to provide a semi-
automated way of modifying the layout of visual infor-
mation. One aspect of this is related to the steerable DR
discussed in Section 5. This can be extended to learning
the criteria that analysts use: for example, how the user
selects principal components.

4. Extreme value theory [DHF07] to identify low-frequency
(but potentially high-value) data points or variables. Re-
cent research in this area supports the automated identiﬁ-
cation of outliers even in the multivariate case.

5. Integrated prior knowledge and data. Often the expert
user will have a great deal of prior cognitive knowledge
embodied in a computational model of a physical system
(e.g. geochemists supporting hydrocarbon exploration; me-
teorologists). Machine learning can be used to generate an
emulator, a technique for model reduction that reduces the
exceptionally high computational burden imposed by many
physical models, while retaining the key features of the
original model and allowing much greater user interaction
for tasks such as sensitivity analysis and control [CO10].

It is clear from the discussion throughout this paper that
there are barriers to the closer integration of machine learning
and visual analytics. One of the main technical barriers is
that the current software tools are strongly divided between
the research communities. Visualization tools are strong
at close control over the form and layout of information,
and user interaction: Some tend to be written as bespoke
integrated tools, such as Tableau (http://www.tableau.com),
Orange (orange.biolab.si) and JMP (www.jpm.com). On the
other hand, the most advanced machine-learning tools are

often written as libraries in numerical or statistical languages
(such as Matlab, e.g. [Nab02] and R), as well, as in high level
general purpose languages, like Java (with Weka, a widely
used collection of ML algorithms for data mining tasks, or
the Stanford NLP tools with advanced ML algorithms for
natural language processing) or Python (with powerful and
widely adopted data analysis and ML libraries like scipy,
scikit-learn, pandas, etc.); all of them focus on supporting
the (often) challenging task of learning complex models from
data but provide limited graphical display and interaction.
The best solution to this problem, short of reimplementing
large toolkits in other languages is to take a client-server
approach: a backend server running a good mathematical
package for the machine-learning components complemented
by web services and html+js clients, able to take advantage
of the huge and growing spectrum of javascript libraries and
frameworks (such as d3js) to provide interactive information
visualisation.

7. Conclusions

This paper provides a comprehensive survey of machine learn-
ing methods, and visual analytics systems that eﬀectively
integrate machine learning. Based on this survey, we present
a set of opportunities that oﬀer a rich set of ideas to further
the integration between these two scientiﬁc areas. Among
these are formalizing and establishing steerable ML, gener-
ally providing coupled interaction and visualization methods
that oﬀer substantially more advanced user feedback. There
is the opportunity to better determine how tasks should be
divided between humans and machines, perhaps in a dynamic
manner, including determining metrics for a balance of eﬀort
between these two components. The paper shows how recent
models and frameworks could be used to develop consider-
ably more powerful visual analytic systems with integrated
machine learning. The summary and discussion presented
in this paper seeks to excite and challenge researchers from
the two disciplines to work together to tackle the challenges
raised, ultimately creating more impactful systems to help
people gain insight into data.

8. Acknowledgments

The authors would like to acknowledge that much of the
content and inspiration for this paper originated during a
Dagstuhl Seminar titled, “Bridging Machine Learning with
Information Visualization (15101)” [KMRV15]. In addition,
funding for the authors was provided in part by the Analysis
in Motion Initiative at PNNL, Spanish Ministry of Economy
& Competitivity and FEDER funds, under grant DPI2015-
69891-C2-2-R

9. Author Bios

Alex Endert is an Assistant Professor in the School of
Interactive Computing at Georgia Tech, where he directs
the Visual Analytics Lab. In 2013, his work on Semantic
Interaction was awarded the IEEE VGTC VPG Pioneers

submitted to COMPUTER GRAPHICS Forum (6/2018).

Endert et al. / Integrating Machine Learning into Visual Analytics

23

Group Doctoral Dissertation Award, and the Virginia Tech
CS Best Dissertation Award.

William Ribarsky is the Bank of America Endowed Chair
and Director of the Charlotte Visualization Center at UNC
Charlotte. He is one of the founders of the ﬁeld of visual
analytics and was Chair of the IEEE Visualization Analytics
Science and Technology (VAST) Steering Committee until
October, 2015.

Cagatay Turkay is a Lecturer (Assistant Prof.) at the De-
partment of Computer Science at City, University of London.
He carries out his research at the giCentre and develops
methods where interactive visualisations and computational
tools are used in tandem for informed analysis processes.

William Wong is a professor of Human-Computer Inter-
action at Middlesex University, London. He is the head of
the Interaction Design Centre. His research interest include
investigating the problems of visual analytics in sense-making
domains with high information density, such as intelligence
analysis, ﬁnancial systemic risk analysis, and low literacy
users.

Ian Nabney is a Professor at Aston University. He is Di-
rector of the System Analytics Research Institute. His re-
search interests are in machine learning, particularly in data
visualisation, time series, and Bayesian methods. His appli-
cation interests are broad, and include condition monitoring,
biomedical engineering, and urban science.

Ignacio D´ıaz Blanco is an associate professor at the De-
partment of Electrical Engineering at the University of
Oviedo. He researches in intelligent data analysis, data visual-
ization, control and signal processing to understand, diagnose
and optimize processes and complex systems.

Fabrice Rossi is a Professor at Paris 1 Panth´eon Sorbonne
University. He is a member of the SAMM research group and
the head of the statistical learning team of this group. His
research interests include machine learning and data analysis.
He is particularly interested in interpretable systems.

References

[20008] Alias-i. 2008. LingPipe 4.0.1, 2008. URL: http://

alias-i.com/lingpipe. 13

[AAB∗10] Andrienko G., Andrienko N., Bremm S., Schreck
T., Von Landesberger T., Bak P., Keim D.: Space-in-time
and time-in-space self-organizing maps for exploring spatiotem-
poral patterns. In Computer Graphics Forum (2010), vol. 29,
Wiley Online Library, pp. 913–922. 8, 10

[AAR∗09] Andrienko G., Andrienko N., Rinzivillo S., Nanni
M., Pedreschi D., Giannotti F.: Interactive visual clustering
of large collections of trajectories. In Visual Analytics Science
and Technology, 2009. VAST 2009. IEEE Symposium on (2009),
IEEE, pp. 3–10. 8, 10

[ABV14] Awasthi P., Balcan M., Voevodski K.: Local algo-
rithms for interactive clustering. In Proceedings of The 31st
International Conference on Machine Learning (2014), Xing
E. P., Jebara T., (Eds.), vol. 32 of JMLR Proceedings, JMLR.org,
pp. 550–558. 8, 12

submitted to COMPUTER GRAPHICS Forum (6/2018).

[ACKK14] Amershi S., Cakmak M., Knox W. B., Kulesza
T.: Power to the people: The role of humans in interactive
machine learning. AI Magazine 35, 4 (2014), 105–120. 5, 11

[ADT∗13] Amir E.-a. D., Davis K. L., Tadmor M. D., Si-
monds E. F., Levine J. H., Bendall S. C., Shenfeld D. K.,
Krishnaswamy S., Nolan G. P., Pe’er D.: visne enables
visualization of high dimensional single-cell data and reveals
phenotypic heterogeneity of leukemia. Nature biotechnology 31,
6 (2013), 545–552. 8, 16

[AEN10] Andrews C., Endert A., North C.: Space to think:
large high-resolution displays for sensemaking. In Proceedings
of the SIGCHI Conference on Human Factors in Computing
Systems (2010), ACM, pp. 55–64. 13

[AES05] Amar R., Eagan J., Stasko J.: Low-level components
of analytic activity in information visualization. In IEEE Sym-
posium on Information Visualization, 2005. INFOVIS 2005
(2005), pp. 111–117. doi:10.1109/INFVIS.2005.1532136. 17,
18

[Alp14] Alpaydin E.: Introduction to machine learning. MIT

press, 2014. 7

[AN12] Andrews C., North C.: Analyst’s Workspace: An
embodied sensemaking environment for large, high-resolution
displays. In 2012 IEEE Conference on Visual Analytics Science
and Technology (VAST) (2012), pp. 123–131. doi:10.1109/
VAST.2012.6400559. 13

[Anc12] Ancona D.: Framing and acting in the unknown. S.
Snook, N. Nohria, & R. Khurana, The Handbook for Teaching
Leadership (2012), 3–19. 2

[AW12] Ahmed Z., Weaver C.: An Adaptive Parameter Space-
Filling Algorithm for Highly Interactive Cluster Exploration.
In Procedings of IEEE Symposium on Visual Analytics Science
and Technology (VAST) (2012). 8, 9

[BBM04] Basu S., Banerjee A., Mooney R. J.: Active
semi-supervision for pairwise constrained clustering.
In
Proceedings of the 2004 SIAM International Conference on
Data Mining (2004), pp. 333–344. URL: http://epubs.siam.
org/doi/abs/10.1137/1.9781611972740.31,
arXiv:http:
//epubs.siam.org/doi/pdf/10.1137/1.9781611972740.31,
doi:10.1137/1.9781611972740.31. 8, 12

[BDW08] Basu S., Davidson I., Wagstaff K.: Constrained
clustering: Advances in algorithms, theory, and applications.
CRC Press, 2008. 8, 11

[BEK14] Best D. M., Endert A., Kidwell D.: 7 Key Chal-
lenges for Visualization in Cyber Network Defense. In Pro-
ceedings of the Eleventh Workshop on Visualization for Cyber
Security (New York, NY, USA, 2014), VizSec ’14, ACM, pp. 33–
40. doi:10.1145/2671491.2671497. 14

[BF11] Bennett K. B., Flach J. M.: Display and interface

design: Subtle science, exact art. CRC Press, 2011. 19

[BH12] Balcan M. F., Hanneke S.: Robust interactive learning.
In Proceedings of the 25th Annual Conference on Learning
Theory (COLT) (Edinburgh, Scotland, June 2012), vol. 23 of
JMLR Workshop and Conference Proceedings. 5

[BKSS14] Behrisch M., Korkmaz F., Shao L., Schreck T.:
Feedback-driven interactive exploration of large multidimen-
sional data supported by visual classiﬁer. In Visual Analytics
Science and Technology (VAST), 2014 IEEE Conference on
(2014), IEEE, pp. 43–52. 8, 12

[BL09] Blei D., Lafferty J.: Text mining: Theory and appli-

cations, chapter topic models, 2009. 13

[BLBC12] Brown E. T., Liu J., Brodley C. E., Chang R.:
Dis-function: Learning distance functions interactively. In Vi-
sual Analytics Science and Technology (VAST), 2012 IEEE
Conference on (2012), IEEE, pp. 83–92. 8, 11, 17

24

Endert et al. / Integrating Machine Learning into Visual Analytics

[BM13] Bryan N. J., Mysore G. J.: An eﬃcient posterior
regularized latent variable model for interactive sound source
separation. In Proceedings of The 30th International Conference
on Machine Learning (ICML) (Atlanta, Georgia, USA, 2013),
Dasgupta S., McAllester D., (Eds.), vol. 28 of JMLR Workshop
and Conference Proceedings. 14

[BNJ03] Blei D. M., Ng A. Y., Jordan M. I.: Latent dirichlet
allocation. the Journal of machine Learning research 3 (2003),
993–1022. 9, 13

[BOZ∗14] Brown E. T., Ottley A., Zhao H., Lin Q., Sou-
venir R., Endert A., Chang R.: Finding Waldo: Learning
about Users from their Interactions. 18

[BPFG11] Berger W., Piringer H., Filzmoser P., Gr¨oller
E.: Uncertainty-aware exploration of continuous parameter
spaces using multivariate prediction. Computer Graphics Forum
30, 3 (2011), 911–920. 10

[CBN∗12] Choo J., Bohn S., Nakamura G., White A. M.,
Park H.: Heterogeneous data fusion via space alignment using
nonmetric multidimensional scaling. In SDM (2012), SIAM,
pp. 177–188. 14

[CCM08] Cohn D., Caruana R., McCallum A.:

Semi-
supervised clustering with user feedback. In Constrained Clus-
tering: Advances in Algorithms, Theory, and Applications, Basu
S., Davidson I., Wagstaﬀ K., (Eds.). CRC Press, 2008, ch. 2,
pp. 17–32. 8, 11

[CDS09] Crossno P. J., Dunlavy D. M., Shead T. M.:
Lsaview: a tool for visual exploration of latent semantic model-
ing. In Visual Analytics Science and Technology, 2009. VAST
2009. IEEE Symposium on (2009), IEEE, pp. 83–90. 13

[CDW∗16] Cho I., Dou W., Wang D. X., Sauda E., Ribarsky
W.: Vairoma: A visual analytics system for making sense of
places, times, and events in roman history. Visualization and
Computer Graphics, IEEE Transactions on 22, 1 (2016), 210–
219. 4, 13, 17

[Chi96] Chickering D. M.: Learning bayesian networks is np-
complete. In Learning from data. Springer, 1996, pp. 121–130.
22

[Chr06] Chris N.: Toward Measuring Visualization Insight. 6–9.

doi:10.1109/MCG.2006.70. 2

[CLKP10] Choo J., Lee H., Kihm J., Park H.: ivisclassiﬁer:
An interactive visual analytics system for classiﬁcation based
on supervised dimension reduction. In Visual Analytics Science
and Technology (VAST), 2010 IEEE Symposium on (2010),
IEEE, pp. 27–34. 8, 9, 14

[CMS99] Card S. K., Mackinlay J. D., Shneiderman B.:
Readings in information visualization: using vision to think.
Morgan Kaufmann Publishers Inc., 1999. 2

[CO10] Conti S., OHagan A.: Bayesian emulation of com-
plex multi-output and dynamic computer models. Journal of
statistical planning and inference 140, 3 (2010), 640–651. 22

[CP13] Choo J., Park H.: Customizing Computational Meth-
ods for Visual Analytics with Big Data. Computer Graphics
and Applications, IEEE 33, 4 (2013), 22–28. doi:10.1109/MCG.
2013.39. 8, 11, 16

[DCE∗15] Dou W., Cho I., ElTayeby O., Choo J., Wang X.,
Ribarsky W.: Demographicvis: Analyzing demographic infor-
mation based on user generated content. In Visual Analytics
Science and Technology (VAST), 2015 IEEE Conference on
(2015), IEEE, pp. 57–64. 13

[DCP∗14] D´ıaz I., Cuadrado A. A., P´erez D., Garc´ıa F. J.,
Verleysen M.: Interactive Dimensionality Reduction for Vi-
sual Analytics. In European Symposium on Artiﬁcial Neural
Networks, Computational Intelligence and Machine Learning
(Bruges, Belgium, 2014). 17

[DCV16] D´ıaz I., Cuadrado A. A., Verleysen M.: A state-
space model on interactive dimensionality reduction. In Euro-
pean Symposium on Artiﬁcial Neural Networks, Computational
Intelligence and Machine Learning (Bruges, Belgium, April
2016), Verleysen M., (Ed.), pp. 647–652. 16

[DFB11] Drucker S. M., Fisher D., Basu S.: Helping users
sort faster with adaptive machine learning recommendations.
Springer-Verlag, pp. 187–203. 18

[DHF07] De Haan L., Ferreira A.: Extreme value theory: an

introduction. Springer Science & Business Media, 2007. 22

[DWCR11] Dou W., Wang X., Chang R., Ribarsky W.: Par-
alleltopics: A probabilistic approach to exploring document col-
lections. In Visual Analytics Science and Technology (VAST),
2011 IEEE Conference on (2011), IEEE, pp. 231–240. 13

[DWS∗12] Dou W., Wang X., Skau D., Ribarsky W., Zhou
M. X.: Leadline: Interactive visual analysis of text data through
event identiﬁcation and exploration. In Visual Analytics Science
and Technology (VAST), 2012 IEEE Conference on (2012),
IEEE, pp. 93–102. 13

[EBN13] Endert A., Bradel L., North C.: Beyond Con-
trol Panels: Direct Manipulation for Visual Analytics. IEEE
Computer Graphics and Applications 33, 4 (2013), 6–13. doi:
10.1109/MCG.2013.53. 8, 11, 16

[ECNZ15] Endert A., Chang R., North C., Zhou M.: Seman-
tic Interaction: Coupling Cognition and Computation through
Usable Interactive Analytics. IEEE Computer Graphics and Ap-
plications 35, 4 (July 2015), 94–99. doi:10.1109/MCG.2015.91.
18

[EFN12a] Endert A., Fiaux P., North C.: Semantic Interac-
tion for Sensemaking: Inferring Analytical Reasoning for Model
Steering. Visualization and Computer Graphics, IEEE Trans-
actions on 18 (2012), 2879–2888. 12. doi:10.1109/tvcg.2012.
260. 18

[EFN12b] Endert A., Fiaux P., North C.: Semantic interac-
tion for visual text analytics. In Proceedings of the SIGCHI
Conference on Human Factors in Computing Systems (2012),
ACM, pp. 473–482. 4, 5

[EHM∗11] Endert A., Han C., Maiti D., House L., Leman
S. C., North C.: Observation-level Interaction with Statistical
Models for Visual Analytics. In IEEE VAST (2011), pp. 121–
130. 8, 11

[EHR∗14] Endert A., Hossain M. S., Ramakrishnan N.,
North C., Fiaux P., Andrews C.: The human is the
loop: new directions for visual analytics. Journal of Intel-
ligent Information Systems (Jan. 2014), 1–25. doi:10.1007/
s10844-014-0304-9. 5

[EKHW08] Eccles R., Kapler T., Harper R., Wright W.:
Stories in GeoTime. Information Visualization 7 (2008), 3–17.
1. doi:10.1145/1391107.1391109. 13

[EMJ∗11] Elmqvist N., Moere A. V., Jetter H.-C., Cernea
D., Reiterer H., Jankun-Kelly T.: Fluid interaction for in-
formation visualization. Information Visualization 10, 4 (2011),
327–340. 16

[EPT∗05] Elm W., Potter S., Tittle J., Woods D., Gross-
man J., Patterson E.: Finding decision support requirements
for eﬀective intelligence analysis tools. In Proceedings of the Hu-
man Factors and Ergonomics Society Annual Meeting (2005),
vol. 49, SAGE Publications, pp. 297–301. 2

[FHT01] Friedman J., Hastie T., Tibshirani R.: The elements
of statistical learning, vol. 1. Springer series in statistics Springer,
Berlin, 2001. 7

[FJA∗11] Fernstad S., Johansson J., Adams S., Shaw J.,
Taylor D.: Visual exploration of microbial populations. In
Biological Data Visualization (BioVis), 2011 IEEE Symposium
on (2011), pp. 127 –134. 8

submitted to COMPUTER GRAPHICS Forum (6/2018).

Endert et al. / Integrating Machine Learning into Visual Analytics

25
[HBM∗13] Hu X., Bradel L., Maiti D., House L., North C.,
Leman S.: Semantics of directly manipulating spatializations.
Visualization and Computer Graphics, IEEE Transactions on
19, 12 (2013), 2052–2059. 8, 11

[FMK12] Fischer F., Mansmann F., Keim D. A.: Real-
time visual analytics for event data streams. In Proceedings
of the 27th Annual ACM Symposium on Applied Comput-
ing (New York, NY, USA, 2012), SAC ’12, ACM, pp. 801–
806. URL: http://doi.acm.org/10.1145/2245276.2245432,
doi:10.1145/2245276.2245432. 14

[FOJ03] Fails J. A., Olsen Jr D. R.:

Interactive machine
learning. In Proceedings of the 8th international conference on
Intelligent user interfaces (2003), ACM, pp. 39–45. 5, 6

[FP07] Fu W.-T., Pirolli P.: Snif-act: A cognitive model of
user navigation on the world wide web. Human–Computer
Interaction 22, 4 (2007), 355–412. 4

[FPDs12] Fisher D., Popov I., Drucker S., schraefel m.:
Trust Me, I’M Partially Right: Incremental Visualization Lets
Analysts Explore Large Datasets Faster. In Proceedings of the
SIGCHI Conference on Human Factors in Computing Systems
(New York, NY, USA, 2012), CHI ’12, ACM, pp. 1673–1682.
doi:10.1145/2207676.2208294. 20

[FSB∗13] Fiaux P., Sun M., Bradel L., North C., Ramakr-
ishnan N., Endert A.: Bixplorer: Visual Analytics with Bi-
clusters. Computer 46, 8 (2013), 90–94. 16

[FWG09] Fuchs R., Waser J., Gr¨oller M. E.: Visual hu-
man+machine learning. IEEE TVCG 15, 6 (2009), 1327–1334.
8

[GB11] Guillory A., Bilmes J.: Simultaneous learning and
covering with adversarial noise.
In Proceedings of the 28th
International Conference on Machine Learning (ICML-11)
(New York, NY, USA, June 2011), Getoor L., Scheﬀer T., (Eds.),
ICML ’11, ACM, pp. 369–376. 5

[GNRM08] Garg S., Nam J. E., Ramakrishnan I., Mueller
K.: Model-driven visual analytics. In Visual Analytics Science
and Technology, 2008. VAST’08. IEEE Symposium on (2008),
IEEE, pp. 19–26. 8, 11

[GOB∗10] Gehlenborg N., O’Donoghue S., Baliga N., Goes-
mann A., Hibbs M., Kitano H., Kohlbacher O., Neuweger
H., Schneider R., Tenenbaum D., et al.: Visualization of
omics data for systems biology. Nature methods 7 (2010),
S56–S68. 15

[GRF09] Green T. M., Ribarsky W., Fisher B.: Building
and applying a human cognition model for visual analytics.
Information Visualization 8 (2009), 1–13. 1. doi:10.1057/
palgrave.ivs.2008.28. 4

[GRVE07] Grottel S., Reina G., Vrabec J., Ertl T.: Visual
veriﬁcation and analysis of cluster detection for molecular dy-
namics. IEEE Transactions on Visualization and Computer
Graphics 13, 6 (2007), 1624–1631. doi:http://dx.doi.org/10.
1109/TVCG.2007.70614. 16

[GS04] Griffiths T. L., Steyvers M.: Finding scientiﬁc topics.
Proceedings of the National Academy of Sciences 101, suppl 1
(2004), 5228–5235. 13

[GSFS06] Gray W. D., Sims C. R., Fu W.-T., Schoelles M. J.:
The soft constraints hypothesis: a rational analysis approach
to resource allocation for interactive behavior. Psychological
review 113, 3 (2006), 461. 17

[GWHR01] Gahegan M., Wachowicz M., Harrower M.,
Rhyne T.-M.: The integration of geographic visualization
with knowledge discovery in databases and geocomputation.
Cartography and Geographic Information Science 28, 1 (2001),
29–44. 3

[HB11] Hoober S., Berkman E.: Designing mobile interfaces.

” O’Reilly Media, Inc.”, 2011. 17

[HBGSS14] Hu Y., Boyd-Graber J., Satinoff B., Smith A.:
Interactive topic modeling. Machine Learning 95, 3 (2014),
423–469. doi:10.1007/s10994-013-5413-0. 13

submitted to COMPUTER GRAPHICS Forum (6/2018).

[Hee06] Heer J.: prefuse manual, 2006. URL: http://prefuse.

org. 4

[HHE∗13] Henry M. J., Hampton S., Endert A., Roberts
I., Payne D.: MultiFacet: A Faceted Interface for Browsing
Large Multimedia Collections. In 2013 IEEE International
Symposium on Multimedia (ISM) (Dec. 2013), pp. 347–350.
doi:10.1109/ISM.2013.66. 8, 14

[HOG∗12] Hossain M. S., Ojili P. K. R., Grimm C., M¨uller
R., Watson L. T., Ramakrishnan N.: Scatter/gather clus-
tering: Flexibly incorporating user feedback to steer clustering
results. Visualization and Computer Graphics, IEEE Transac-
tions on 18, 12 (2012), 2829–2838. 8, 11

[Hor99] Horvitz E.: Principles of Mixed-initiative User Inter-
faces. In Proceedings of the SIGCHI Conference on Human
Factors in Computing Systems (New York, NY, USA, 1999),
CHI ’99, ACM, pp. 159–166. doi:10.1145/302979.303030. 18
[HSCW13] Hadlak S., Schumann H., Cap C. H., Wollenberg
T.: Supporting the visual analysis of dynamic networks by
clustering associated temporal attributes. Visualization and
Computer Graphics, IEEE Transactions on 19, 12 (2013), 2267–
2276. 8, 9

[i2]

i2 Analyst’s Notebook. URL: http://www.i2inc.com/

products/analysts_notebook/. 13

[IHG13]

Iwata T., Houlsby N., Ghahramani Z.: Active
learning for interactive visualization.
In Proceedings of the
Sixteenth International Conference on Artiﬁcial Intelligence
and Statistics, AISTATS 2013 (Scottsdale, AZ, USA, April
2013), vol. 31 of JMLR Proceedings, JMLR.org, pp. 342–
350.
URL: http://dblp.uni-trier.de/db/conf/aistats/
aistats2013.html#IwataHG13. 8, 11

[IYU08]

Iwata T., Yamada T., Ueda N.: Probabilistic latent
semantic visualization: topic model for visualizing documents. In
Proceedings of the 14th ACM SIGKDD international conference
on Knowledge discovery and data mining (2008), ACM, pp. 363–
371. 13

[JBS08]

J¨anicke H., B¨ottinger M., Scheuermann G.: Brush-
ing of attribute clouds for the visualization of multivariate data.
IEEE Transactions on Visualization and Computer Graphics
(2008), 1459–1466. 8

[JJ09]

Johansson S., Johansson J.: Interactive dimensionality
reduction through user-deﬁned combinations of quality metrics.
Visualization and Computer Graphics, IEEE Transactions on
15, 6 (2009), 993–1000. 7, 8

[JZF∗09]

Jeong D. H., Ziemkiewicz C., Fisher B., Ribarsky
W., Chang R.: iPCA: An Interactive System for PCA-based
Visual Analytics. Computer Graphics Forum 28, 3 (2009),
767–774. doi:10.1111/j.1467-8659.2009.01475.x. 8, 17

[Kan12] Kandogan E.: Just-in-time annotation of clusters,
outliers, and trends in point-based data visualizations.
In
Visual Analytics Science and Technology (VAST), 2012 IEEE
Conference on (2012), IEEE, pp. 73–82. 8, 9

[KAW∗13] Kodagoda N., Attfield S., Wong B., Rooney C.,
Choudhury S.: Using interactive visual reasoning to support
sense-making: Implications for design. Visualization and Com-
puter Graphics, IEEE Transactions on 19, 12 (2013), 2217–2226.
19

[KBK11] Krstaji´c M., Bertini E., Keim D. A.: Cloudlines:
Compact display of event episodes in multiple time-series. Vi-
sualization and Computer Graphics, IEEE Transactions on 17,
12 (2011), 2432–2439. 13

26

Endert et al. / Integrating Machine Learning into Visual Analytics

[KCPE16] Kim H., Choo J., Park H., Endert A.: Interaxis:
Steering scatterplot axes via observation-level interaction. Vi-
sualization and Computer Graphics, IEEE Transactions on 22,
1 (Jan 2016), 131–140. doi:10.1109/TVCG.2015.2467615. 8, 11
[Kei02] Keim D. A.: Information visualization and visual data
mining. Visualization and Computer Graphics, IEEE Transac-
tions on 8 (2002), 1–8. 1. 1

[KG90] Kendall M., Gibbons J. D.: Rank correlation methods.

Oxford University Press, 1990. 12

[KGL∗15] Klemm P., Glaer S., Lawonn K., Rak M., Vlzke
H., Hegenscheid K., Preim B.: Interactive visual analysis of
lumbar back pain - what the lumbar spine tells about your life. In
Proceedings of the 6th International Conference on Information
Visualization Theory and Applications (VISIGRAPP 2015)
(2015), pp. 85–92. doi:10.5220/0005235500850092. 8, 9

[KK08] Kumar N., Kummamuru K.: Semisupervised clustering
with metric learning using relative comparisons. IEEE Trans-
actions on Knowledge and Data Engineering 20, 4 (April 2008),
496–503. doi:10.1109/TKDE.2007.190715. 8, 12

[KKP05] Kumar N., Kummamuru K., Paranjpe D.: Semi-
supervised clustering with metric learning using relative com-
parisons.
In Fifth IEEE International Conference on Data
Mining (ICDM’05) (Nov 2005). doi:10.1109/ICDM.2005.128.
8, 12

[KKW∗16] Kwon B. C., Kim H., Wall E., Choo J., Park H.,
Endert A.: Axisketcher: Interactive nonlinear axis mapping
of visualizations through user drawings. IEEE transactions on
visualization and computer graphics (2016). 8, 11

[KLG∗16] Klemm P., Lawonn K., Glaßer S., Niemann U.,
Hegenscheid K., Volzke H., Preim B.: 3d regression heat map
analysis of population study data. Visualization and Computer
Graphics, IEEE Transactions on 22, 1 (2016), 81–90. 8, 10

[KMH06a] Klein G., Moon B., Hoffman R.: Making Sense
of Sensemaking 1: Alternative Perspectives. IEEE Intelligent
Systems 21, 4 (2006), 70–73. doi:10.1109/MIS.2006.75. 3

[KMH06b] Klein G., Moon B., Hoffman R.: Making Sense
of Sensemaking 2: A Macrocognitive Model. IEEE Intelligent
Systems 21, 5 (2006), 88–92. doi:10.1109/MIS.2006.100. 3

[KMRV15] Keim D. A., Munzner T., Rossi F., Verleysen
M. (Eds.):. Bridging Information Visualization with Machine
Learning (Dagstuhl Seminar 15101) (Dagstuhl, Germany, 2015),
vol. 5, Schloss Dagstuhl–Leibniz-Zentrum fuer Informatik. URL:
http://drops.dagstuhl.de/opus/volltexte/2015/5266, doi:
http://dx.doi.org/10.4230/DagRep.5.3.1. 1, 7, 22

[KMSZ06] Keim D. A., Mansmann F., Schneidewind J.,
Ziegler H.: Challenges in Visual Data Analysis. IEEE Com-
puter Society. doi:10.1109/iv.2006.31. 1

[KP11] Kaski S., Peltonen J.: Dimensionality reduction for
data visualization. IEEE Signal Processing Magazine 28, 2
(2011), 100–104. doi:10.1109/MSP.2010.940003. 8, 16

[KPB14] Krause J., Perer A., Bertini E.: Infuse: interactive
feature selection for predictive modeling of high dimensional
data. Visualization and Computer Graphics, IEEE Transac-
tions on 20, 12 (2014), 1614–1623. 8, 9, 10

[KS11] Kang Y.-a., Stasko J.: Characterizing the intelligence
analysis process: Informing visual analytics design through
a longitudinal ﬁeld study.
In Visual Analytics Science and
Technology (VAST), 2011 IEEE Conference on (2011), IEEE,
pp. 21–30. 3

[KSF∗08] Kerren A., Stasko J., Fekete J.-D., North
C., Keim D., Andrienko G., G¨org C., Kohlhammer J.,
Melanc¸on G.: Visual Analytics: Deﬁnition, Process, and
Challenges.
In Information Visualization, vol. 4950 of Lec-
ture Notes in Computer Science. Springer Berlin / Heidelberg,
2008, pp. 154–175. doi:10.1007/978-3-540-70956-5_7. 1

[LD97] Landauer T. K., Dumais S. T.: A solution to plato’s
problem: The latent semantic analysis theory of acquisition, in-
duction, and representation of knowledge. Psychological review
104, 2 (1997), 211. 13

[LHE10] Lin C., He Y., Everson R.: A comparative study
of bayesian models for unsupervised sentiment detection. In
Proceedings of the Fourteenth Conference on Computational
Natural Language Learning (2010), Association for computa-
tional linguistics, pp. 144–152. 22

[LHM∗11] Leman S. C., House L., Maiti D., Endert A.,
North C.: A Bi-directional Visualization Pipeline that En-
ables Visual to Parametric Interation (V2PI). Tech. rep., 2011.
FODAVA-10-41. 5

[LI57] Lonergan B. J., Insight A.: A study of human under-

standing. New York 298 (1957). 2

[LKT∗14] Lu Y., Kr¨uger R., Thom D., Wang F., Koch S.,
Ertl T., Maciejewski R.: Integrating predictive analytics and
social media. In 2014 IEEE Conference on Visual Analytics
Science and Technology (VAST) (Oct 2014), pp. 193–202. doi:
10.1109/VAST.2014.7042495. 8, 15

[LPP∗06] Lee B., Plaisant C., Parr C. S., Fekete J.-D.,
Henry N.: Task taxonomy for graph visualization. In Proceed-
ings of the 2006 AVI workshop on BEyond time and errors:
novel evaluation methods for information visualization (2006),
ACM, pp. 1–5. 17

[LSP∗10] Lex A., Streit M., Partl C., Kashofer K., Schmal-
stieg D.: Comparative analysis of multidimensional, quantita-
tive data. IEEE Transactions on Visualization and Computer
Graphics (Proceedings Visualization / Information Visualiza-
tion 2010) 16, 6 (2010), 1027–1035. 8

[LSS∗12] Lex A., Streit M., Schulz H.-J., Partl C., Schmal-
stieg D., Park P. J., Gehlenborg N.: StratomeX: visual
analysis of large-scale heterogeneous genomics data for cancer
subtype characterization. Computer Graphics Forum (EuroVis
’12) 31, 3 (2012), 1175?1184. doi:10.1111/j.1467-8659.2012.
03110.x. 8

[LYK∗12] Luo D., Yang J., Krstajic M., Ribarsky W., Keim
D.: Eventriver: Visually exploring text collections with tempo-
ral references. Visualization and Computer Graphics, IEEE
Transactions on 18, 1 (2012), 93–105. 13, 14

[LZP∗09] Liu S., Zhou M. X., Pan S., Qian W., Cai W.,
Lian X.: Interactive, topic-based visual text summarization
and analysis. In Proceedings of the 18th ACM conference on
Information and knowledge management (2009), ACM, pp. 543–
552. 13

[MBD∗11] May T., Bannach A., Davey J., Ruppert T.,
Kohlhammer J.: Guiding feature subset selection with an inter-
active visualization. In Visual Analytics Science and Technology
(VAST), 2011 IEEE Conference on (2011), IEEE, pp. 111–120.
8, 9

[MGJH08] Matkovi´c K., Graˇcanin D., Jelovi´c M., Hauser
H.: Interactive visual steering-rapid visual prototyping of a
common rail injection system. Visualization and Computer
Graphics, IEEE Transactions on 14, 6 (2008), 1699–1706. 8, 12
[MGS∗14] Matkovic K., Gracanin D., Splechtna R.,
Jelovic M., Stehno B., Hauser H., Purgathofer W.: Vi-
sual analytics for complex engineering systems: Hybrid visual
steering of simulation ensembles. Visualization and Computer
Graphics, IEEE Transactions on 20, 12 (2014), 1803–1812. 8,
12

[MJR∗11] MacEachren A. M., Jaiswal A., Robinson A. C.,
Pezanowski S., Savelyev A., Mitra P., Zhang X., Blanford
J.: Senseplace2: Geotwitter analytics support for situational
awareness. In Visual Analytics Science and Technology (VAST),
2011 IEEE Conference on (2011), IEEE, pp. 181–190. 13

submitted to COMPUTER GRAPHICS Forum (6/2018).

Endert et al. / Integrating Machine Learning into Visual Analytics

27

(http://serc.carleton.edu/nagtworkshops/complexsystems/introduction.html).
19

[MK08] May T., Kohlhammer J.: Towards closing the analysis
gap: Visual generation of decision supporting schemes from
raw data. In Computer Graphics Forum (2008), vol. 27, Wiley
Online Library, pp. 911–918. 8, 9

[MME∗12] Malik A., Maciejewski R., Elmqvist N., Jang Y.,
Ebert D. S., Huang W.: A correlative analysis process in a
visual analytics environment. In Visual Analytics Science and
Technology (VAST), 2012 IEEE Conference on (2012), IEEE,
pp. 33–42. 8, 10

[MO04] Madeira S. C., Oliveira A. L.: Biclustering algorithms
for biological data analysis: a survey. IEEE/ACM Transactions
on Computational Biology and Bioinformatics (TCBB) 1, 1
(2004), 24–45. 16

[MP13] Muhlbacher T., Piringer H.: A partition-based frame-
work for building and validating regression models. Visualiza-
tion and Computer Graphics, IEEE Transactions on 19, 12
(2013), 1962–1971. 8, 10

[Mur85] Murtagh F.: A survey of algorithms for contiguity-
constrained clustering and related problems. The computer
journal 28, 1 (1985), 82–88. 11

[NM13] Nam J., Mueller K.: Tripadvisorn-d: A tourism-
inspired high-dimensional space exploration framework with
overview and detail. Visualization and Computer Graphics,
IEEE Transactions on 19, 2 (2013), 291–305. 8

[Nor86] Norman D. A.: Cognitive engineering. User centered
system design: New perspectives on human-computer interac-
tion 3161 (1986). 19

[Orm] Ormand C.: What constitutes a complex system?

[OST∗10] Oesterling P., Scheuermann G., Teresniak S.,
Heyer G., Koch S., Ertl T., Weber G. H.: Two-stage
framework for a topology-based projection and visualization
of classiﬁed document collections. In Visual Analytics Science
and Technology (VAST), 2010 IEEE Symposium on (2010),
IEEE, pp. 91–98. 13

[PBK10] Piringer H., Berger W., Krasser J.: Hypermoval:
Interactive visual validation of regression models for real-time
simulation. In Proceedings of the 12th Eurographics / IEEE
- VGTC Conference on Visualization (Aire-la-Ville, Switzer-
land, Switzerland, 2010), EuroVis’10, Eurographics Association,
pp. 983–992. URL: http://dx.doi.org/10.1111/j.1467-8659.
2009.01684.x, doi:10.1111/j.1467-8659.2009.01684.x. 8, 10
[PC05] Pirolli P., Card S.: The sensemaking process and
leverage points for analyst technology as identiﬁed through cog-
nitive task analysis. In Proceedings of International Conference
on Intelligence Analysis (2005), vol. 5, pp. 2–4. 2

[PES∗06] Poulin B., Eisner R., Szafron D., Lu P., Greiner
R., Wishart D. S., Fyshe A., Pearcy B., Macdonell C., An-
vik J.: Visual explanation of evidence with additive classiﬁers.
In Proceedings, The Twenty-First National Conference on Ar-
tiﬁcial Intelligence and the Eighteenth Innovative Applications
of Artiﬁcial Intelligence Conference, July 16-20, 2006, (Boston,
Massachusetts, USA, July 2006), AAAI Press, pp. 1822–1829.
URL: http://www.aaai.org/Library/AAAI/2006/aaai06-301.
php. 8, 9

[PSCO09] Pike W. A., Stasko J., Chang R., O’Connell
T. A.: The science of interaction. Information Visualization 8,
4 (2009), 263–274. 16, 18

[PSPM15] Paiva J. G. S., Schwartz W. R., Pedrini H.,
Minghim R.: An approach to supporting incremental visual
data classiﬁcation. Visualization and Computer Graphics, IEEE
Transactions on 21, 1 (2015), 4–17. 8, 12

[PTH13] Porter R., Theiler J., Hush D.: Interactive ma-

submitted to COMPUTER GRAPHICS Forum (6/2018).

chine learning in data exploitation. Computing in Sci-
ence and Engineering 15, 5 (2013), 12–20. doi:http://doi.
ieeecomputersociety.org/10.1109/MCSE.2013.74. 5

[PTRV13] Parulek J., Turkay C., Reuter N., Viola I.: Vi-
sual cavity analysis in molecular simulations. BMC Bioinfor-
matics 14, 19 (2013), 1–15. 8, 9

[PZS∗15] P´erez D., Zhang L., Schaefer M., Schreck T.,
Keim D., D´ıaz I.: Interactive feature space extension for multi-
dimensional data projection. Neurocomputing 150, Part (2015),
611–626.
URL: http://www.sciencedirect.com/science/
article/pii/S0925231214012879, doi:http://dx.doi.org/10.
1016/j.neucom.2014.09.061. 8, 17

[RAWC14] Rooney C., Attfield S., Wong B. W., Choudhury
S.: Invisque as a tool for intelligence analysis: the construction
of explanatory narratives. International Journal of Human-
Computer Interaction 30, 9 (2014), 703–717. 19

[RECC10] Rose S., Engel D., Cramer N., Cowley W.: Au-
tomatic Keyword Extraction from Individual Documents. John
Wiley & Sons, Ltd, pp. 1–20. doi:10.1002/9780470689646.ch1.
12

[RF16] Ribarsky W., Fisher B.: The human-computer system:
Towards an operational model for problem-solving. In Hawaii
International Conference on Systems Science (HICSS 2016)
(2016). 3, 17

[RK04] Rasmussen M., Karypis G.: gCLUTO–An Interactive
Clustering, Visualization, and Analysis System., University of
Minnesota, Department of Computer Science and Engineering,
CSE. Tech. rep., UMN Technical Report: TR, 2004. 8

[RPN∗08] Rinzivillo S., Pedreschi D., Nanni M., Giannotti
F., Andrienko N., Andrienko G.: Visually driven analy-
sis of movement data by progressive clustering. Information
Visualization 7, 3 (2008), 225–239. 8, 9

[RSE09] Rudolph S., Savikhin A., Ebert D. S.: Finvis: Ap-
plied visual analytics for personal ﬁnancial planning. In Visual
Analytics Science and Technology, 2009. VAST 2009. IEEE
Symposium on (2009), IEEE, pp. 195–202. 14

[RSPC93] Russell D. M., Stefik M. J., Pirolli P., Card
S. K.: The cost structure of sensemaking. In Proceedings of the
INTERACT’93 and CHI’93 conference on Human factors in
computing systems (1993), ACM, pp. 269–276. 2

[SBTK08]

Schreck T., Bernard J., Tekusova T., Kohlham-
mer J.: Visual cluster analysis of trajectory data with interac-
tive Kohonen Maps. In IEEE Symposium on Visual Analytics
Science and Technology, 2008. VAST’08 (2008), pp. 3–10. 8, 9

[SDLC93]

Spiegelhalter D. J., Dawid A. P., Lauritzen S. L.,
Cowell R. G.: Bayesian analysis in expert systems. Statistical
science (1993), 219–247. 22

[SDMT16]

Stahnke J., Dork M., Muller B., Thom A.: Prob-
ing projections: Interaction techniques for interpreting arrange-
ments and errors of dimensionality reductions. Visualization
and Computer Graphics, IEEE Transactions on 22, 1 (2016),
629–638. 8

[Set09]

Settles B.: Active Learning Literature Survey. Com-
puter Sciences Technical Report 1648, University of Wisconsin–
Madison, 2009. 5, 8, 12

[SGG∗14]

Streit M., Gratzl S., Gillhofer M., Mayr A.,
Mitterecker A., Hochreiter S.: Furby: fuzzy force-directed
bicluster visualization. BMC bioinformatics 15, Suppl 6 (2014),
S4. 8, 16

[SGL08]

Stasko J., Goerg C., Liu Z.: Jigsaw: supporting
investigative analysis through interactive visualization.
In-
formation Visualization 7 (2008), 118–132. 2. doi:10.1145/
1466620.1466622. 13

Endert et al. / Integrating Machine Learning into Visual Analytics

28
[SHA∗01]

Shipman F., Hsieh H., Airhart R., Maloor P.,
Moore J. M., Shah D.: Emergent Structure in Analytic
Workspaces: Design and Use of the Visual Knowledge Builder.
pp. 132–139. 12

[She00]

Shearer C.: The crisp-dm model: the new blueprint for
data mining. Journal of data warehousing 5, 4 (2000), 13–22. 5
Shneiderman B.: Direct Manipulation: A Step Beyond
Programming Languages. Computer 16, 8 (1983), 57–69. doi:
10.1109/MC.1983.1654471. 4, 7

[Shn83]

[SK10]

Strumbelj E., Kononenko I.:

An eﬃcient ex-
planation of
individual classiﬁcations using game theory.
Journal of Machine Learning Research 11 (2010), 1–18.
URL: http://doi.acm.org/10.1145/1756006.1756007, doi:
10.1145/1756006.1756007. 8, 9

[Sku02]

Skupin A.: A Cartographic Approach to Visualizing
Conference Abstracts. IEEE Computer Graphics and Applica-
tions 22 (2002), 50–58. doi:10.1109/38.974518. 12, 16

[SM99]

Shipman F., Marshall C.: Formality Considered Harm-
ful: Experiences, Emerging Themes, and Directions on the Use
of Formal Representations in Interactive Systems. Comput.
Supported Coop. Work 8 (1999), 333–352. 4. doi:10.1023/A:
1008716330212. 12

[SMNR16]

Sun M., Mi P., North C., Ramakrishnan N.: Biset:
Semantic edge bundling with biclusters for sensemaking. IEEE
transactions on visualization and computer graphics 22, 1
(2016), 310–319. 16

[SNR14]

Sun M., North C., Ramakrishnan N.: A ﬁve-level
design framework for bicluster visualizations. IEEE transactions
on visualization and computer graphics 20, 12 (2014), 1713–1722.
16

[SPG14]

Stolper C. D., Perer A., Gotz D.: Progressive visual
analytics: User-driven visual exploration of in-progress analytics.
Visualization and Computer Graphics, IEEE Transactions on
20, 12 (2014), 1653–1662. 20

[SS02]

Seo J., Shneiderman B.: Interactively exploring hierar-
chical clustering results. IEEE Computer 35, 7 (2002), 80–86.
8

[SS11]

Satinover J., Sornette D.: Taming manias: On the
origins, inevitability, prediction and regulation of bubbles and
crashes, chapter of the book “governance and control of ﬁnan-
cial systems: A resilience engineering perspective,”. published
by Ashgate Publishing Group in their Resilience Engineering
Perspectives series (2011). 19

[SSS∗14]

Sacha D., Stoffel A., Stoffel F., Kwon B. C.,
Ellis G., Keim D. A.: Knowledge generation model for vi-
sual analytics. Visualization and Computer Graphics, IEEE
Transactions on 20, 12 (2014), 1604–1613. 3, 4

[SWB97]

Sarter N. B., Woods D. D., Billings C. E.: Au-
tomation surprises. Handbook of human factors and ergonomics
2 (1997), 1926–1943. 19

[SZS∗16]

Sacha D., Zhang L., Sedlmair M., Lee J. A., Pel-
tonen J., Weiskopf D., North S. C., Keim D. A.: Visual
interaction with dimensionality reduction: A structured liter-
ature analysis. IEEE Trans. on Visualization and Computer
Graphics (2016). 6

[TC05] Thomas J. J., Cook K. A.: Illuminating the path: The
research and development agenda for visual analytics. IEEE
Computer Society Press, 2005. 1

[TFH11] Turkay C., Filzmoser P., Hauser H.: Brushing
dimensions-a dual visual analysis model for high-dimensional
data. Visualization and Computer Graphics, IEEE Transac-
tions on 17, 12 (2011), 2591–2599. 8

[TJHH14] Turkay C., Jeanquartier F., Holzinger A.,
Hauser H.: On computationally-enhanced visual analysis of

heterogeneous data and its application in biomedical informat-
ics. In Interactive Knowledge Discovery and Data Mining in
Biomedical Informatics. Springer, 2014, pp. 117–140. 6

[TKBH17] Turkay C., Kaya E., Balcisoy S., Hauser H.:
Designing progressive and interactive analytics processes for
high-dimensional data analysis. IEEE Transactions on Visual-
ization & Computer Graphics 23, 1 (2017), 131–140. 20

[TLLH12] Turkay C., Lundervold A., Lundervold A.,
Hauser H.: Representative factor generation for the inter-
active visual analysis of high-dimensional data. Visualization
and Computer Graphics, IEEE Transactions on 18, 12 (2012),
2621–2630. 8, 10

[TLS∗14] Turkay C., Lex A., Streit M., Pfister H., Hauser
H.: Characterizing cancer subtypes using dual analysis in
caleydo stratomex. IEEE Computer Graphics and Applications
34, 2 (2014), 38–47. doi:http://doi.ieeecomputersociety.
org/10.1109/MCG.2014.1. 8, 9, 10

[TPRH11a] Turkay C., Parulek J., Reuter N., Hauser H.:
Integrating cluster formation and cluster evaluation in inter-
active visual analysis. In Proceedings of the 27th Spring Con-
ference on Computer Graphics (2011), ACM, pp. 77–86. 8,
9

[TPRH11b] Turkay C., Parulek J., Reuter N., Hauser
H.:
Interactive visual analysis of temporal cluster struc-
tures. Computer Graphics Forum 30, 3 (2011), 711–720. URL:
http://dx.doi.org/10.1111/j.1467-8659.2011.01920.x. 8, 9
[Van05] Van Wijk J. J.: The value of visualization. In 16th
IEEE Visualization 2005 (VIS 2005) (2005), IEEE Computer
Society, p. 11. doi:10.1109/VIS.2005.102. 4, 16

[vdEvW11]

van den Elzen S., van Wijk J. J.: Baobabview:
Interactive construction and analysis of decision trees. In Vi-
sual Analytics Science and Technology (VAST), 2011 IEEE
Conference on (2011), IEEE, pp. 151–160. 8, 9

[vdMW12]

van der Maaten L., Weinberger K.: Stochastic
triplet embedding. In 2012 IEEE International Workshop on
Machine Learning for Signal Processing (Sept 2012), pp. 1–6.
doi:10.1109/MLSP.2012.6349720. 6

[Ves99] Vesanto J.: SOM-based data visualization methods.
Intelligent Data Analysis 3, 2 (1999), 111–126. doi:10.3233/
IDA-1999-3203. 16

[VL13] Verleysen M., Lee J. A.: Nonlinear Dimensionality
Reduction for Visualization. In Neural Information Processing
(2013), Springer, pp. 617–622. 16

[Wei95] Weick K. E.: Sensemaking in organizations, vol. 3.

Sage, 1995. 2

[WH00] Wirth R., Hipp J.: Crisp-dm: Towards a standard
process model for data mining. In Proceedings of the 4th Inter-
national Conference on the Practical Applications of Knowledge
Discovery and Data Mining (2000), Citeseer, pp. 29–39. 22

[WKKB15] Wilber M. J., Kwak I. S., Kriegman D., Be-
longie S.: Learning concept embeddings with combined
human-machine expertise. In 2015 IEEE International Con-
ference on Computer Vision (ICCV) (Dec 2015), pp. 981–989.
doi:10.1109/ICCV.2015.118. 6

[WLS∗10] Wei F., Liu S., Song Y., Pan S., Zhou M. X., Qian
W., Shi L., Tan L., Zhang Q.: Tiara: a visual exploratory text
analytic system. In Proceedings of the 16th ACM SIGKDD in-
ternational conference on Knowledge discovery and data mining
(2010), ACM, pp. 153–162. 13

[WM04] Williams M., Munzner T.: Steerable, progressive mul-
tidimensional scaling. In Proceedings of the IEEE Symposium
on Information Visualization (Washington, DC, USA, 2004),
IEEE Computer Society, pp. 57–64. 8

submitted to COMPUTER GRAPHICS Forum (6/2018).

Endert et al. / Integrating Machine Learning into Visual Analytics

29

[Won14] Wong B.: How analysts think (?): Early observations.
In Intelligence and Security Informatics Conference (JISIC),
2014 IEEE Joint (2014), IEEE, pp. 296–299. 19

[WSO05] Weick K. E., Sutcliffe K. M., Obstfeld D.: Orga-
nizing and the process of sensemaking. Organization science
16, 4 (2005), 409–421. 2

[WSP∗06] Wright W., Schroh D., Proulx P., Skaburskis
A., Cort B.: The Sandbox for analysis: concepts and methods.
ACM, pp. 801–810. doi:10.1145/1124772.1124890. 13

[WTP∗99] Wise J. A., Thomas J. J., Pennock K., Lantrip
D., Pottier M., Schur A., Crow V.: Visualizing the non-
visual: spatial analysis and interaction with information for text
documents. Morgan Kaufmann Publishers Inc., pp. 442–450. 8,
12, 13

[WV12] Wong B. W., Varga M.: Black holes, keyholes and
brown worms: Challenges in sense making. In Proceedings of
the Human Factors and Ergonomics Society Annual Meeting
(2012), vol. 56, SAGE Publications, pp. 287–291. 19

[YaKSJ07] Yi J. S., ah Kang Y., Stasko J. T., Jacko J. A.:
Toward a deeper understanding of the role of interaction in in-
formation visualization. Visualization and Computer Graphics,
IEEE Transactions on 13, 6 (2007), 1224–1231. 7

[YKJ16] Yeon H., Kim S., Jang Y.: Predictive visual ana-
lytics of event evolution for user-created context. Journal of
Visualization (2016), 1–16. 8, 15

[YNM∗13] Younesy H., Nielsen C. B., M¨oller T., Alder O.,
Cullum R., Lorincz M. C., Karimi M. M., Jones S. J.: An
interactive analysis and exploration tool for epigenomic data.
In Computer Graphics Forum (2013), vol. 32, Wiley Online
Library, pp. 91–100. 8, 15

[ZC07] Zhu W., Chen C.: Storylines: Visual exploration and
analysis in latent semantic spaces. Computers & Graphics 31,
3 (2007), 338–349. 13, 14

[ZJGK10] Ziegler H., Jenny M., Gruse T., Keim D. A.: Vi-
sual market sector analysis for ﬁnancial time series data. In
Visual Analytics Science and Technology (VAST), 2010 IEEE
Symposium on (2010), IEEE, pp. 83–90. 14, 15

[ZNK08] Ziegler H., Nietzschmann T., Keim D. A.: Visual
analytics on the ﬁnancial market: Pixel-based analysis and
comparison of long-term investments. In Information Visualisa-
tion, 2008. IV’08. 12th International Conference (2008), IEEE,
pp. 287–295. 14

submitted to COMPUTER GRAPHICS Forum (6/2018).

","{""0"":{""0"":""sacha*"",""1"":""turkay"",""2"":""de\ufb01ne*"",""3"":""chang"",""4"":""wang""},""1"":{""0"":""ieee*"",""1"":""ribarsky"",""2"":""hauser*"",""3"":""e\ufb00ort*"",""4"":""jmlr*""},""10"":{""0"":""users*"",""1"":""people*"",""2"":""section*"",""3"":""topics*"",""4"":""articles*""},""11"":{""0"":""conference*"",""1"":""proceedings*"",""2"":""paper"",""3"":""symposium*"",""4"":""papers*""},""2"":{""0"":""modify"",""1"":""describe*"",""2"":""select"",""3"":""improve"",""4"":""produce*""},""3"":{""0"":""high*"",""1"":""vast*"",""2"":""similar*"",""3"":""relevant*"",""4"":""tentative*""},""4"":{""0"":""integrated"",""1"":""discussed*"",""2"":""called"",""3"":""advanced"",""4"":""found""},""5"":{""0"":""interaction*"",""1"":""feedback"",""2"":""example"",""3"":""input*"",""4"":""sense""},""6"":{""0"":""figure*"",""1"":""domain*"",""2"":""frame*"",""3"":""image*"",""4"":""images*""},""7"":{""0"":""human"",""1"":""analytic*"",""2"":""science"",""3"":""technology"",""4"":""sensemaking*""},""8"":{""0"":""models"",""1"":""systems*"",""2"":""methods*"",""3"":""techniques"",""4"":""parameters""},""9"":{""0"":""clustering*"",""1"":""algorithms"",""2"":""algorithm*"",""3"":""computation*"",""4"":""unsupervised*""},""pos"":{""0"":1,""1"":2,""2"":3,""3"":4,""4"":5}}",2017,{},False,False,journalArticle,False,7YWBXAWZ,[],self.user,"{""C"":{""0"":6.5629629242,""1"":14.8634416215,""10"":5.7932293569,""100"":5.12799709,""101"":6.4818835444,""102"":8.4998027061,""103"":8.1200798211,""104"":12.895963532,""105"":4.6521841149,""106"":5.2140729366,""107"":7.1654424535,""108"":4.7169087154,""109"":5.5043231692,""11"":7.5549367986,""110"":4.8717033784,""111"":7.4873567669,""112"":6.5312948119,""113"":6.4882100908,""114"":4.4526322428,""115"":8.1579479047,""116"":6.0178035686,""117"":4.5120068905,""118"":4.8732850637,""119"":5.6016054639,""12"":7.3244657343,""120"":8.545241529,""121"":6.9311711739,""122"":6.4765615713,""123"":9.2755882614,""124"":5.1354540743,""125"":4.8491449138,""126"":9.0949453849,""127"":7.6157696637,""128"":6.9313324974,""129"":6.1683552814,""13"":5.3362740712,""130"":7.1220839605,""131"":5.466340642,""132"":7.6544555541,""133"":6.7588895325,""134"":5.8911589999,""135"":6.468017519,""136"":7.2182823989,""137"":4.7848867976,""138"":4.6460884945,""139"":7.0561829743,""14"":8.2156615479,""140"":8.3394776793,""141"":5.443446406,""142"":5.8917716259,""143"":6.6387795771,""144"":6.4865639042,""145"":8.2436161752,""146"":5.9208792099,""147"":5.0072564669,""148"":4.6621787298,""149"":6.4933113113,""15"":4.452736206,""150"":5.7228392262,""151"":4.7482861029,""152"":4.7413054135,""153"":4.8252920244,""154"":6.5193252317,""155"":6.5751316377,""156"":5.2245914069,""157"":6.4964712001,""158"":6.4995705781,""159"":6.1567547748,""16"":7.9652810032,""160"":4.7170331639,""161"":5.8854222545,""162"":6.287264498,""163"":6.214736498,""164"":4.8664510627,""165"":4.7896785127,""166"":4.5810976905,""167"":4.6365455367,""168"":4.5035899249,""169"":4.6094213523,""17"":4.9345718652,""170"":4.4450679383,""171"":4.7129159026,""172"":4.5017036238,""173"":4.5244143668,""174"":4.635200241,""175"":4.6055215195,""176"":4.6324871121,""177"":4.5661430717,""178"":4.4669176275,""179"":4.6910339984,""18"":8.3156873334,""180"":4.6542924859,""181"":4.7307336911,""19"":29.533534567,""2"":14.4105852368,""20"":7.7569084703,""21"":11.7729738086,""22"":14.6752022069,""23"":13.2392877177,""24"":8.7046943689,""25"":4.8771625127,""26"":15.6541332881,""27"":8.2909559101,""28"":7.9833832679,""29"":31.6033360753,""3"":79.73414091,""30"":19.8224191465,""31"":12.2489974492,""32"":7.1586074418,""33"":6.3077353367,""34"":7.9742548424,""35"":11.7902396052,""36"":4.9345729905,""37"":12.2215829708,""38"":11.2600811669,""39"":23.5318919255,""4"":11.68001603,""40"":4.8824734039,""41"":7.9149702083,""42"":4.6603072686,""43"":7.7481558042,""44"":5.1588784211,""45"":4.5910889654,""46"":5.4520880528,""47"":8.4561357722,""48"":6.3780992491,""49"":5.6624196895,""5"":5.3341458644,""50"":11.017570604,""51"":11.5878697523,""52"":17.8292611591,""53"":4.771930723,""54"":5.7340346553,""55"":6.4534125135,""56"":9.8220750101,""57"":4.8212518087,""58"":4.6398647909,""59"":9.7521808197,""6"":12.0861515723,""60"":8.0683908593,""61"":5.5467615272,""62"":9.1700516217,""63"":5.7103143908,""64"":12.1163350082,""65"":5.8870201495,""66"":9.118413991,""67"":4.5007652581,""68"":5.6885281663,""69"":6.8056660783,""7"":9.88115466,""70"":9.1998088865,""71"":12.8764235977,""72"":5.6307838954,""73"":6.6973152615,""74"":9.4204784785,""75"":5.5140070598,""76"":4.5078238463,""77"":4.8051172898,""78"":10.9430864466,""79"":8.2595427706,""8"":10.2685531435,""80"":7.7738905442,""81"":7.5876930496,""82"":4.6079473526,""83"":6.4514562031,""84"":5.5891139262,""85"":6.3000737023,""86"":7.7831981235,""87"":4.930488996,""88"":4.7062078012,""89"":6.6252168073,""9"":11.1908477173,""90"":4.9790494683,""91"":11.8595327076,""92"":5.8369694808,""93"":4.9081985332,""94"":7.2681280302,""95"":5.3655876912,""96"":4.4822632611,""97"":7.270948808,""98"":7.9067417663,""99"":4.8385599707},""Unnamed: 0"":{""0"":0,""1"":1,""10"":11,""100"":107,""101"":108,""102"":109,""103"":110,""104"":112,""105"":113,""106"":114,""107"":115,""108"":116,""109"":117,""11"":12,""110"":118,""111"":119,""112"":120,""113"":121,""114"":122,""115"":123,""116"":124,""117"":125,""118"":126,""119"":127,""12"":13,""120"":128,""121"":129,""122"":130,""123"":131,""124"":132,""125"":133,""126"":134,""127"":136,""128"":137,""129"":138,""13"":14,""130"":139,""131"":140,""132"":141,""133"":142,""134"":143,""135"":144,""136"":145,""137"":146,""138"":147,""139"":148,""14"":15,""140"":149,""141"":150,""142"":151,""143"":152,""144"":153,""145"":154,""146"":155,""147"":157,""148"":162,""149"":163,""15"":16,""150"":164,""151"":165,""152"":166,""153"":167,""154"":169,""155"":170,""156"":171,""157"":172,""158"":173,""159"":174,""16"":17,""160"":175,""161"":176,""162"":177,""163"":178,""164"":179,""165"":180,""166"":181,""167"":182,""168"":183,""169"":184,""17"":18,""170"":185,""171"":186,""172"":187,""173"":188,""174"":189,""175"":190,""176"":191,""177"":192,""178"":193,""179"":194,""18"":19,""180"":195,""181"":198,""19"":21,""2"":2,""20"":22,""21"":23,""22"":24,""23"":25,""24"":26,""25"":27,""26"":28,""27"":30,""28"":31,""29"":32,""3"":3,""30"":33,""31"":34,""32"":35,""33"":36,""34"":37,""35"":38,""36"":39,""37"":40,""38"":41,""39"":42,""4"":4,""40"":43,""41"":44,""42"":45,""43"":46,""44"":47,""45"":49,""46"":50,""47"":52,""48"":53,""49"":54,""5"":5,""50"":55,""51"":56,""52"":57,""53"":58,""54"":59,""55"":60,""56"":61,""57"":62,""58"":63,""59"":64,""6"":6,""60"":65,""61"":66,""62"":67,""63"":68,""64"":69,""65"":70,""66"":71,""67"":72,""68"":73,""69"":74,""7"":7,""70"":75,""71"":76,""72"":77,""73"":78,""74"":79,""75"":81,""76"":82,""77"":83,""78"":84,""79"":86,""8"":8,""80"":87,""81"":88,""82"":89,""83"":90,""84"":91,""85"":92,""86"":93,""87"":94,""88"":95,""89"":96,""9"":10,""90"":97,""91"":98,""92"":99,""93"":100,""94"":101,""95"":102,""96"":103,""97"":104,""98"":105,""99"":106},""count"":{""0"":486,""1"":386,""10"":116,""100"":18,""101"":18,""102"":18,""103"":18,""104"":18,""105"":16,""106"":16,""107"":16,""108"":16,""109"":16,""11"":110,""110"":16,""111"":16,""112"":14,""113"":14,""114"":14,""115"":14,""116"":14,""117"":12,""118"":12,""119"":12,""12"":108,""120"":12,""121"":12,""122"":12,""123"":12,""124"":12,""125"":12,""126"":12,""127"":12,""128"":12,""129"":12,""13"":108,""130"":12,""131"":12,""132"":10,""133"":10,""134"":10,""135"":10,""136"":10,""137"":10,""138"":10,""139"":10,""14"":104,""140"":10,""141"":10,""142"":10,""143"":10,""144"":10,""145"":10,""146"":10,""147"":10,""148"":8,""149"":8,""15"":96,""150"":8,""151"":8,""152"":8,""153"":8,""154"":8,""155"":8,""156"":8,""157"":8,""158"":8,""159"":8,""16"":94,""160"":8,""161"":8,""162"":8,""163"":8,""164"":8,""165"":8,""166"":6,""167"":6,""168"":6,""169"":6,""17"":94,""170"":6,""171"":6,""172"":6,""173"":6,""174"":6,""175"":6,""176"":6,""177"":6,""178"":6,""179"":6,""18"":92,""180"":6,""181"":6,""19"":88,""2"":308,""20"":82,""21"":82,""22"":76,""23"":74,""24"":72,""25"":72,""26"":72,""27"":70,""28"":68,""29"":64,""3"":222,""30"":58,""31"":58,""32"":56,""33"":54,""34"":54,""35"":54,""36"":52,""37"":52,""38"":52,""39"":52,""4"":220,""40"":50,""41"":50,""42"":50,""43"":50,""44"":48,""45"":46,""46"":46,""47"":42,""48"":42,""49"":42,""5"":194,""50"":42,""51"":42,""52"":40,""53"":38,""54"":36,""55"":36,""56"":36,""57"":34,""58"":34,""59"":34,""6"":186,""60"":34,""61"":34,""62"":34,""63"":34,""64"":32,""65"":32,""66"":32,""67"":32,""68"":32,""69"":30,""7"":162,""70"":30,""71"":30,""72"":28,""73"":28,""74"":28,""75"":26,""76"":26,""77"":26,""78"":26,""79"":24,""8"":146,""80"":24,""81"":24,""82"":24,""83"":24,""84"":24,""85"":22,""86"":22,""87"":22,""88"":22,""89"":22,""9"":126,""90"":22,""91"":22,""92"":20,""93"":20,""94"":20,""95"":20,""96"":20,""97"":20,""98"":20,""99"":18},""exemplar"":{""0"":null,""1"":null,""10"":null,""100"":null,""101"":""*"",""102"":null,""103"":null,""104"":""*"",""105"":null,""106"":""*"",""107"":null,""108"":null,""109"":""*"",""11"":""*"",""110"":""*"",""111"":null,""112"":null,""113"":null,""114"":null,""115"":""*"",""116"":null,""117"":null,""118"":null,""119"":null,""12"":null,""120"":null,""121"":null,""122"":null,""123"":null,""124"":null,""125"":null,""126"":null,""127"":""*"",""128"":null,""129"":null,""13"":null,""130"":null,""131"":null,""132"":""*"",""133"":null,""134"":""*"",""135"":null,""136"":""*"",""137"":""*"",""138"":""*"",""139"":null,""14"":""*"",""140"":""*"",""141"":null,""142"":null,""143"":""*"",""144"":null,""145"":null,""146"":null,""147"":null,""148"":null,""149"":null,""15"":null,""150"":null,""151"":""*"",""152"":""*"",""153"":null,""154"":null,""155"":null,""156"":null,""157"":null,""158"":""*"",""159"":null,""16"":null,""160"":null,""161"":""*"",""162"":""*"",""163"":""*"",""164"":null,""165"":""*"",""166"":""*"",""167"":null,""168"":""*"",""169"":null,""17"":""*"",""170"":null,""171"":null,""172"":null,""173"":""*"",""174"":null,""175"":null,""176"":""*"",""177"":null,""178"":null,""179"":null,""18"":null,""180"":""*"",""181"":null,""19"":""*"",""2"":null,""20"":""*"",""21"":null,""22"":null,""23"":""*"",""24"":null,""25"":""*"",""26"":null,""27"":null,""28"":null,""29"":""*"",""3"":""*"",""30"":null,""31"":""*"",""32"":null,""33"":null,""34"":""*"",""35"":null,""36"":""*"",""37"":null,""38"":null,""39"":""*"",""4"":null,""40"":""*"",""41"":null,""42"":null,""43"":null,""44"":null,""45"":""*"",""46"":null,""47"":null,""48"":null,""49"":""*"",""5"":null,""50"":null,""51"":""*"",""52"":null,""53"":null,""54"":null,""55"":""*"",""56"":null,""57"":""*"",""58"":""*"",""59"":""*"",""6"":null,""60"":null,""61"":null,""62"":""*"",""63"":null,""64"":null,""65"":""*"",""66"":""*"",""67"":null,""68"":null,""69"":""*"",""7"":""*"",""70"":""*"",""71"":""*"",""72"":null,""73"":null,""74"":null,""75"":null,""76"":""*"",""77"":null,""78"":null,""79"":null,""8"":null,""80"":""*"",""81"":null,""82"":""*"",""83"":null,""84"":null,""85"":""*"",""86"":null,""87"":null,""88"":null,""89"":null,""9"":""*"",""90"":null,""91"":null,""92"":null,""93"":null,""94"":""*"",""95"":""*"",""96"":null,""97"":null,""98"":null,""99"":null},""pos"":{""0"":1,""1"":2,""10"":7,""100"":38,""101"":6,""102"":2,""103"":11,""104"":3,""105"":39,""106"":11,""107"":40,""108"":4,""109"":12,""11"":2,""110"":13,""111"":41,""112"":42,""113"":4,""114"":43,""115"":4,""116"":6,""117"":13,""118"":44,""119"":14,""12"":8,""120"":45,""121"":5,""122"":46,""123"":47,""124"":48,""125"":14,""126"":49,""127"":5,""128"":50,""129"":4,""13"":2,""130"":51,""131"":12,""132"":5,""133"":52,""134"":6,""135"":53,""136"":6,""137"":4,""138"":7,""139"":15,""14"":1,""140"":5,""141"":54,""142"":55,""143"":13,""144"":56,""145"":57,""146"":5,""147"":58,""148"":59,""149"":15,""15"":9,""150"":60,""151"":8,""152"":7,""153"":8,""154"":16,""155"":61,""156"":9,""157"":16,""158"":5,""159"":62,""16"":1,""160"":63,""161"":6,""162"":7,""163"":6,""164"":64,""165"":8,""166"":17,""167"":65,""168"":10,""169"":66,""17"":3,""170"":17,""171"":67,""172"":7,""173"":8,""174"":68,""175"":69,""176"":5,""177"":70,""178"":7,""179"":71,""18"":2,""180"":11,""181"":72,""19"":1,""2"":3,""20"":2,""21"":4,""22"":3,""23"":1,""24"":10,""25"":1,""26"":11,""27"":12,""28"":3,""29"":2,""3"":1,""30"":13,""31"":3,""32"":14,""33"":15,""34"":2,""35"":16,""36"":2,""37"":17,""38"":4,""39"":2,""4"":4,""40"":3,""41"":5,""42"":18,""43"":19,""44"":3,""45"":5,""46"":20,""47"":21,""48"":6,""49"":7,""5"":5,""50"":22,""51"":4,""52"":23,""53"":24,""54"":5,""55"":6,""56"":7,""57"":6,""58"":4,""59"":3,""6"":1,""60"":25,""61"":1,""62"":4,""63"":26,""64"":27,""65"":4,""66"":8,""67"":28,""68"":29,""69"":8,""7"":1,""70"":3,""71"":1,""72"":7,""73"":30,""74"":31,""75"":32,""76"":2,""77"":9,""78"":33,""79"":9,""8"":6,""80"":4,""81"":8,""82"":5,""83"":1,""84"":9,""85"":2,""86"":10,""87"":3,""88"":2,""89"":34,""9"":1,""90"":35,""91"":36,""92"":10,""93"":11,""94"":5,""95"":3,""96"":37,""97"":12,""98"":10,""99"":3},""sigma_nor"":{""0"":1.290720119,""1"":1.7405861978,""10"":1.5014831128,""100"":1.9038806643,""101"":2.1633655153,""102"":2.5501183713,""103"":2.4773409712,""104"":3.3926832207,""105"":1.8389044785,""106"":1.9508840265,""107"":2.3397749744,""108"":1.8518035276,""109"":2.0087283697,""11"":1.6738208773,""110"":1.8826527557,""111"":2.4039296931,""112"":2.2577806367,""113"":2.2488238216,""114"":1.8256507348,""115"":2.5959429974,""116"":2.1510317473,""117"":1.8666465298,""118"":1.9452781514,""119"":2.1037959316,""12"":1.6582542934,""120"":2.7444736536,""121"":2.3931738002,""122"":2.294228741,""123"":2.9034324618,""124"":2.0023388208,""125"":1.940024086,""126"":2.8641158262,""127"":2.542175576,""128"":2.393208912,""129"":2.2271481307,""13"":1.4758387859,""130"":2.4347256655,""131"":2.0743557576,""132"":2.6150151829,""133"":2.4101050687,""134"":2.2115638577,""135"":2.3435520552,""136"":2.5152165205,""137"":1.9584430851,""138"":1.9266853191,""139"":2.478127338,""14"":1.752672073,""140"":2.7717517701,""141"":2.1091249123,""142"":2.2117040297,""143"":2.3826232929,""144"":2.3477955636,""145"":2.7498181647,""146"":2.2183639946,""147"":2.0093224097,""148"":1.9596788623,""149"":2.4020660199,""15"":1.4157032008,""150"":2.2159260543,""151"":1.980481723,""152"":1.9787952437,""153"":1.999085745,""154"":2.4083507774,""155"":2.421833164,""156"":2.0955533195,""157"":2.402829424,""158"":2.4035782093,""159"":2.3207566209,""16"":1.7629328825,""160"":1.97293126,""161"":2.2552048288,""162"":2.3522867385,""163"":2.3347645469,""164"":2.0090294433,""165"":1.9904818021,""166"":1.9587323359,""167"":1.9729300957,""168"":1.938885999,""169"":1.9659847825,""17"":1.4666368749,""170"":1.9239010868,""171"":1.9924851944,""172"":1.9384030001,""173"":1.9442182246,""174"":1.9725856245,""175"":1.9649862065,""176"":1.9718909112,""177"":1.9549031144,""178"":1.9294958333,""179"":1.9868821992,""18"":1.8048361687,""180"":1.9774743104,""181"":1.997047548,""19"":3.9581816533,""2"":1.8003979739,""20"":1.788599831,""21"":2.2062466234,""22"":2.5594974833,""23"":2.4215162831,""24"":1.9388495624,""25"":1.5169939099,""26"":2.7047896513,""27"":1.9041537493,""28"":1.8807045466,""29"":4.6459172259,""3"":6.2082777479,""30"":3.3767562695,""31"":2.4589711099,""32"":1.8544631493,""33"":1.7610610947,""34"":1.9693408688,""35"":2.4462584457,""36"":1.5984665693,""37"":2.524031558,""38"":2.4019056918,""39"":3.9606188564,""4"":1.7604539185,""40"":1.601191061,""41"":1.9928575168,""42"":1.5724968765,""43"":1.9713123642,""44"":1.647316532,""45"":1.582313635,""46"":1.6975042154,""47"":2.1401763295,""48"":1.8514134989,""49"":1.7519630546,""5"":1.3643426876,""50"":2.4961119275,""51"":2.5753603885,""52"":3.4913064006,""53"":1.6524575932,""54"":1.8080634688,""55"":1.9145272367,""56"":2.4130698289,""57"":1.6872006356,""58"":1.6597341169,""59"":2.4338662782,""6"":1.8519649873,""60"":2.17889848,""61"":1.7970609031,""62"":2.3457173978,""63"":1.8218268861,""64"":2.8338834331,""65"":1.8676681554,""66"":2.3688825215,""67"":1.6526492191,""68"":1.8368805021,""69"":2.0342251131,""7"":1.7413527565,""70"":2.4150736893,""71"":2.999931649,""72"":1.8681508618,""73"":2.0423851351,""74"":2.4872556558,""75"":1.8709322109,""76"":1.7018688731,""77"":1.7518214277,""78"":2.7831500555,""79"":2.3697906166,""8"":1.8088450046,""80"":2.285720467,""81"":2.2534882432,""82"":1.7376712597,""83"":2.0567968734,""84"":1.9075187681,""85"":2.0604971705,""86"":2.3255059366,""87"":1.8157759942,""88"":1.7757008111,""89"":2.1185946382,""9"":1.9443301936,""90"":1.8244529134,""91"":3.0538766537,""92"":2.0074324518,""93"":1.8357654972,""94"":2.2719569079,""95"":1.9203058287,""96"":1.7570388626,""97"":2.272478279,""98"":2.3899934114,""99"":1.8484073656},""topic"":{""0"":-1,""1"":-1,""10"":-1,""100"":-1,""101"":9,""102"":1,""103"":7,""104"":1,""105"":-1,""106"":8,""107"":-1,""108"":2,""109"":8,""11"":8,""110"":5,""111"":-1,""112"":-1,""113"":4,""114"":-1,""115"":1,""116"":11,""117"":8,""118"":-1,""119"":8,""12"":-1,""120"":-1,""121"":4,""122"":-1,""123"":-1,""124"":-1,""125"":5,""126"":-1,""127"":1,""128"":-1,""129"":0,""13"":9,""130"":-1,""131"":7,""132"":2,""133"":-1,""134"":2,""135"":-1,""136"":4,""137"":6,""138"":2,""139"":5,""14"":10,""140"":10,""141"":-1,""142"":-1,""143"":7,""144"":-1,""145"":-1,""146"":0,""147"":-1,""148"":-1,""149"":8,""15"":-1,""150"":-1,""151"":2,""152"":4,""153"":4,""154"":8,""155"":-1,""156"":4,""157"":5,""158"":3,""159"":-1,""16"":7,""160"":-1,""161"":0,""162"":0,""163"":1,""164"":-1,""165"":0,""166"":5,""167"":-1,""168"":4,""169"":-1,""17"":8,""170"":8,""171"":-1,""172"":11,""173"":11,""174"":-1,""175"":-1,""176"":6,""177"":-1,""178"":1,""179"":-1,""18"":5,""180"":4,""181"":-1,""19"":11,""2"":-1,""20"":7,""21"":8,""22"":7,""23"":6,""24"":-1,""25"":3,""26"":-1,""27"":-1,""28"":5,""29"":11,""3"":1,""30"":-1,""31"":9,""32"":-1,""33"":-1,""34"":10,""35"":-1,""36"":6,""37"":-1,""38"":7,""39"":3,""4"":-1,""40"":10,""41"":8,""42"":-1,""43"":-1,""44"":11,""45"":7,""46"":-1,""47"":-1,""48"":8,""49"":8,""5"":-1,""50"":-1,""51"":5,""52"":-1,""53"":-1,""54"":5,""55"":7,""56"":7,""57"":5,""58"":9,""59"":3,""6"":8,""60"":-1,""61"":4,""62"":11,""63"":-1,""64"":-1,""65"":10,""66"":8,""67"":-1,""68"":-1,""69"":7,""7"":5,""70"":6,""71"":0,""72"":5,""73"":-1,""74"":-1,""75"":-1,""76"":4,""77"":8,""78"":-1,""79"":7,""8"":-1,""80"":3,""81"":5,""82"":9,""83"":2,""84"":5,""85"":2,""86"":5,""87"":4,""88"":0,""89"":-1,""9"":9,""90"":-1,""91"":-1,""92"":7,""93"":5,""94"":11,""95"":0,""96"":-1,""97"":5,""98"":8,""99"":2},""vector"":{""0"":""[-9.040841   8.364594  -2.2379649 -5.1714263  0.6759651 -0.3802553\n  2.8790722  0.5629333  2.0267847  2.503615 ]"",""1"":""[-8.756873    8.4125185  -2.4025598  -4.864238    0.20568444 -0.19406661\n  2.4597244   0.40573263  0.5333231   2.6549327 ]"",""10"":""[-9.106954   7.9139733 -2.2088456 -5.29519    0.5578688 -0.5504351\n  2.945467   1.2722642  2.3695903  1.6198559]"",""100"":""[-10.143447    8.139201   -2.5096056  -5.2881594   0.6401436  -0.4753819\n   2.885758    0.7136773   1.728308    1.9365027]"",""101"":""[-9.394289    8.364976   -2.0085154  -5.289874    1.2225993   0.05555083\n  3.1257327   0.49796325  2.167306    2.54668   ]"",""102"":""[-7.0724583   5.6239433  -2.579372   -4.282203    0.56173927  1.1262223\n  5.169421    0.9780758   2.45862     2.3132935 ]"",""103"":""[-9.037453    7.6311455  -2.4509282  -5.2401943   0.61430675 -0.2120112\n  3.4353976   0.8573001   1.8316227   1.8262322 ]"",""104"":""[-6.927416    5.687547   -2.3032455  -4.208069    0.4152717   0.91729426\n  4.8937078   1.0002941   2.2861698   2.348121  ]"",""105"":""[-9.050601    9.314559   -2.3040235  -5.7160053   0.70056504 -0.45432806\n  2.253215    0.76417094  1.3595423   2.1585462 ]"",""106"":""[-9.641411    9.004989   -2.1125638  -5.5423026   0.9507066  -0.16925427\n  2.3391926   0.59086853  1.1736764   2.284038  ]"",""107"":""[-9.071354    8.74931    -1.9501548  -5.125195   -0.04548175 -0.6748734\n  1.5123874   1.8497417   1.2487478   1.5561962 ]"",""108"":""[-8.608557    8.438327   -1.6584501  -4.9042377  -0.57532257 -1.2430376\n  0.7499793   3.194814    1.545349    0.73626006]"",""109"":""[-9.40082    9.034077  -2.0335934 -5.6268225  1.133874  -0.0209015\n  2.4985054  0.5010155  1.2416049  2.3816817]"",""11"":""[-9.5027323e+00  8.9947691e+00 -2.0189049e+00 -5.5182371e+00\n  1.0827013e+00 -6.8130152e-04  2.4458923e+00  5.0620663e-01\n  1.1740092e+00  2.4564631e+00]"",""110"":""[-9.471372    8.692395   -2.252402   -5.256807    0.28708145 -0.8090469\n  2.142638    1.4202789   2.2221704   1.783121  ]"",""111"":""[-6.8045893   5.7195234  -2.0634205  -4.1170893   0.33341312  0.82715935\n  4.7633624   1.0862545   2.1770177   2.397996  ]"",""112"":""[-9.270489    8.714763   -2.05497    -5.163722    0.05459592 -0.82195634\n  1.7402419   1.6722757   1.7624103   1.6548986 ]"",""113"":""[-8.46232     8.132534   -1.9050359  -4.9450088  -0.5401498  -1.0603195\n  1.3610418   2.5592      1.5159059   0.91947883]"",""114"":""[-8.896292    7.91256    -2.2431753  -4.9682045   0.44010705 -0.04351797\n  2.9417338   1.0464069   1.3943788   2.044522  ]"",""115"":""[-7.236223    5.8232713  -2.6018636  -4.3817673   0.45056197  0.9146242\n  4.918736    0.89126825  2.3875268   2.3236437 ]"",""116"":""[-8.552812    7.6288733  -2.579688   -4.585282   -0.07342118 -0.36710986\n  3.0847368   0.77405703  1.472475    2.3903406 ]"",""117"":""[-9.423029    8.614966   -1.9689015  -5.4719663   1.0489857  -0.05445152\n  2.7028487   0.9590319   1.8429867   2.0310767 ]"",""118"":""[-9.0880995   8.725348   -1.947479   -5.1553106  -0.16146463 -0.8315773\n  1.435256    2.0373666   1.4846983   1.3589301 ]"",""119"":""[-10.129452     8.768085    -1.993174    -5.423333     0.99628973\n  -0.21918218   2.3801448    0.9174432    1.728221     2.0574799 ]"",""12"":""[-8.897737    8.657949   -2.1249313  -5.0383353   0.32416117 -0.42438737\n  2.2633429   1.0637406   1.671561    2.3298643 ]"",""120"":""[-9.395996    8.893326   -2.17473    -5.2640886   0.6695867  -0.1413241\n  2.3020515   0.49995586  0.86314565  2.5370553 ]"",""121"":""[-8.763521    8.616771   -1.8800477  -5.1020474  -0.7734018  -1.0798798\n  0.90404403  2.658521    1.3230891   0.7800773 ]"",""122"":""[-9.1707325   7.7899094  -2.5503867  -5.151259    0.50667685 -0.49252504\n  3.3130689   0.5659555   2.0097346   2.1823    ]"",""123"":""[-9.562699    8.263199   -2.5828366  -5.2139883   0.08487888 -0.7730327\n  2.341925    1.0583401   1.2766235   1.724229  ]"",""124"":""[-9.1599455   8.838557   -1.941159   -5.4241095   0.19554663 -0.54719776\n  1.752986    1.7801402   1.3178469   1.3997133 ]"",""125"":""[-9.092439    8.860398   -2.0876625  -5.074167    0.29900658 -0.36831507\n  1.9646115   1.0892451   1.2331383   2.2963245 ]"",""126"":""[-9.091884    8.440179   -2.2495232  -5.3462214   0.85654205 -0.3471259\n  3.0069518   0.5382118   2.2380419   2.4603617 ]"",""127"":""[-7.0354238   5.758559   -2.4252112  -4.270617    0.40152428  0.93252313\n  4.892207    0.9478561   2.3125055   2.3562763 ]"",""128"":""[-6.8314967   5.631979   -1.9187157  -3.9098074   0.25681522  0.8863104\n  4.937505    1.1442853   2.17493     2.4003835 ]"",""129"":""[-6.826628    5.450477   -2.1034033  -3.9336019   0.36503038  1.0606576\n  5.0216656   1.3064371   2.3469305   2.3912742 ]"",""13"":""[-9.2600565   8.520358   -2.1429563  -5.483681    1.1540468  -0.07943058\n  3.0914168   0.3815621   1.9997557   2.5127754 ]"",""130"":""[-9.099548    7.4908423  -2.549827   -5.135518    0.36513963 -0.27087834\n  3.3107078   0.9634876   1.5085658   1.6835854 ]"",""131"":""[-8.85936     7.481128   -2.4991226  -5.094263    0.40701708 -0.27792904\n  3.3967822   0.8134671   1.6303775   1.8969929 ]"",""132"":""[-8.665603   8.582039  -1.6156495 -4.9495683 -0.6176079 -1.2914544\n  0.6339141  3.268308   1.561208   0.6981637]"",""133"":""[-9.038179    9.247229   -2.2682695  -5.699596    0.71513885 -0.45604533\n  2.3073058   0.8294935   1.4651064   2.110448  ]"",""134"":""[-8.624052    8.550514   -1.607838   -4.9300117  -0.65443003 -1.2999557\n  0.5965696   3.315048    1.55997     0.64402336]"",""135"":""[-9.265644    8.751268   -2.1133342  -5.1196823   0.64123577 -0.10972685\n  2.3668447   0.46974483  0.974263    2.6827536 ]"",""136"":""[-8.634083    8.513406   -1.8837901  -5.077521   -0.89302987 -1.1616806\n  0.8588056   2.7928076   1.3328478   0.64533913]"",""137"":""[-10.012641     8.27006     -2.5783556   -5.183758     0.36621845\n  -0.44139203   2.5824163    0.79356176   1.1504719    1.9231888 ]"",""138"":""[-8.714501    8.65454    -1.5738779  -5.0110865  -0.62131155 -1.353638\n  0.6729134   3.217262    1.6092966   0.6944633 ]"",""139"":""[-9.0748415   8.612208   -2.1623886  -4.836868    0.4050902  -0.17268504\n  2.3310273   0.6170796   1.084684    2.711112  ]"",""14"":""[-8.828739    8.308518   -2.4094567  -4.851679    0.19095807 -0.13174401\n  2.5179398   0.48822758  0.5124075   2.571334  ]"",""140"":""[-8.750265    8.153759   -2.3755841  -4.6619406   0.01894791 -0.22387516\n  2.5532527   0.7311702   0.8624119   2.5386233 ]"",""141"":""[-9.115765    8.394854   -2.472264   -4.7280393   0.01728158 -0.5611668\n  2.4012692   0.7556458   1.316666    2.4920523 ]"",""142"":""[-9.82227     7.9980426  -2.4215674  -5.2510633   0.7853091  -0.33527103\n  3.1778967   0.64777976  2.0074208   2.090516  ]"",""143"":""[-9.116182    7.877749   -2.0262287  -5.242059    0.9329668  -0.17534482\n  3.2186139   1.0715789   2.469819    1.8723518 ]"",""144"":""[-9.122805    8.741752   -1.9374835  -5.301887    0.00954012 -0.6857861\n  1.6052371   1.9538583   1.4085437   1.310797  ]"",""145"":""[-8.738034    7.6162214  -2.435606   -4.837251    0.23998235 -0.0876359\n  3.1499496   0.85382116  1.1868893   2.1292632 ]"",""146"":""[-6.6328917   5.508721   -1.9427879  -3.9835627   0.36781612  1.0251701\n  5.0571733   1.0863332   2.2957373   2.4686174 ]"",""147"":""[-6.894731   5.688485  -2.4012287 -4.259168   0.5590174  1.2037455\n  5.1578627  1.0469668  2.3919744  2.3419065]"",""148"":""[-9.115113   9.250853  -2.225251  -5.641997   0.7739909 -0.3439148\n  2.2905128  0.7040353  1.3113632  2.2516217]"",""149"":""[-10.194561     8.664846    -2.076958    -5.3511243    0.8555248\n  -0.32203722   2.3710237    0.9929496    1.7777288    1.9821141 ]"",""15"":""[-9.373947    8.531546   -2.4615967  -5.4908214   0.27567786 -0.8448552\n  2.31491     1.0590373   1.5903465   1.6840407 ]"",""150"":""[-9.125074   7.997817  -2.4048429 -5.4528055  0.5019502 -0.6888589\n  2.944921   0.8492189  1.945509   1.780791 ]"",""151"":""[-8.6642275  8.608982  -1.6162468 -4.9758396 -0.675715  -1.3139389\n  0.6371347  3.2413068  1.5431267  0.6601154]"",""152"":""[-8.643786    8.461848   -1.8287044  -4.924952   -0.8854671  -1.0258338\n  0.9225242   2.716995    1.3697212   0.77180445]"",""153"":""[-8.734963    8.454535   -1.8346399  -4.9656415  -0.50904864 -1.126617\n  1.0915482   2.7374692   1.4654912   0.90812206]"",""154"":""[-9.981208    8.953195   -1.9841971  -5.476395    1.0712233  -0.11773983\n  2.3275971   0.71852136  1.4323933   2.248128  ]"",""155"":""[-9.219237    8.830618   -2.4652505  -5.4474783   0.34072635 -0.6814275\n  2.2466912   0.72608525  1.227753    2.0979133 ]"",""156"":""[-8.848178    8.643785   -1.8067614  -5.0492268  -0.6093805  -1.1177794\n  0.91998136  2.7377336   1.4141843   0.87371856]"",""157"":""[-9.150599    8.83254    -1.9797204  -5.1670947   0.4687385  -0.24338178\n  2.0613022   1.1451035   1.3082677   2.209018  ]"",""158"":""[-8.599625    8.240623   -1.8434752  -4.918678   -0.29015717 -0.9383512\n  1.4576824   2.4154897   1.5266358   1.181405  ]"",""159"":""[-9.453091    8.037731   -2.5421588  -4.8331113   0.19401501 -0.26393023\n  2.6953366   0.5100573   0.8319189   2.4282684 ]"",""16"":""[-8.872242    7.490903   -2.3360605  -5.169192    0.5824666  -0.35319898\n  3.4387403   1.0031643   2.2280838   1.7636324 ]"",""160"":""[-7.1443906   5.955628   -2.4237168  -4.349725    0.37798744  0.8105971\n  4.6319547   0.9525278   2.1270955   2.2637703 ]"",""161"":""[-6.77794    5.6169567 -2.1907933 -4.1289916  0.5197566  1.0478234\n  5.119495   1.1383997  2.4086955  2.359623 ]"",""162"":""[-6.6817408  5.5963106 -2.0211554 -4.0280585  0.508053   0.9853315\n  5.1245184  1.1464673  2.3675425  2.3521247]"",""163"":""[-7.101124    5.7351303  -2.4593453  -4.2765365   0.4762371   0.91101867\n  4.964723    0.98435074  2.3853042   2.3025837 ]"",""164"":""[-7.232293    5.7355704  -2.6947746  -4.345602    0.48155567  1.1116209\n  5.158102    0.8706012   2.489637    2.3752077 ]"",""165"":""[-6.6804852   5.547932   -1.9904244  -4.0728946   0.48806182  0.90868586\n  4.944809    1.190999    2.3587022   2.4681168 ]"",""166"":""[-9.377356    8.595711   -2.139879   -5.455394    0.4669026  -0.73350054\n  2.2507267   1.5722015   2.1968515   1.4530627 ]"",""167"":""[-9.936431    8.708532   -2.4008708  -5.2795863   0.50998455 -0.4599022\n  2.2995002   0.63807863  1.1095977   2.193814  ]"",""168"":""[-8.687946    8.536168   -1.9054472  -5.1069107  -0.83874357 -1.1582334\n  0.8842501   2.7564507   1.3142093   0.6853605 ]"",""169"":""[-9.065468   8.647426  -2.2975876 -5.650536   0.7375331 -0.5144283\n  2.729926   1.110228   2.2342021  1.7607754]"",""17"":""[-9.305271    8.897842   -1.9922272  -5.627445    1.1077838  -0.08690313\n  2.5922563   0.67941725  1.598738    2.2278593 ]"",""170"":""[-9.854399   8.484856  -1.9346291 -5.3524513  1.1814177 -0.0383464\n  2.820339   0.8566564  2.1469183  2.1815677]"",""171"":""[-9.154518    8.510759   -2.4132729  -5.5823216   0.6844602  -0.52778107\n  2.8506398   1.0026897   2.2263632   1.8174578 ]"",""172"":""[-8.6750727e+00  7.8157964e+00 -2.5094116e+00 -4.6402688e+00\n -8.4986268e-03 -2.7354693e-01  2.8914564e+00  6.8018639e-01\n  1.0926300e+00  2.4695849e+00]"",""173"":""[-8.572449    7.8394012  -2.560178   -4.574087   -0.11608914 -0.41566116\n  2.878854    0.7571457   1.3845222   2.470916  ]"",""174"":""[-9.495082    8.344393   -2.4544573  -5.1114216  -0.07538723 -0.8920578\n  2.0067747   1.3873429   1.3844324   1.6338544 ]"",""175"":""[-9.843904    8.2375965  -2.4781978  -5.3649526   0.59195054 -0.30850214\n  2.7665684   0.9736093   1.3791174   1.6907241 ]"",""176"":""[-9.736576    8.34945    -2.4700253  -5.0733995   0.36933514 -0.33272174\n  2.5080502   0.62621915  0.94343096  2.2307432 ]"",""177"":""[-9.121785    8.718354   -1.9355888  -5.1499925  -0.22776236 -0.90492857\n  1.3534546   2.1510465   1.5416492   1.2609813 ]"",""178"":""[-6.9607835   5.705323   -2.4506266  -4.275513    0.43754414  0.92183876\n  4.815839    0.92466086  2.1012414   2.1916165 ]"",""179"":""[-9.105867   8.701037  -2.339413  -5.57166    0.6082017 -0.6276545\n  2.5993197  1.0876667  2.230374   1.8494457]"",""18"":""[-9.481684    8.618618   -2.3519285  -5.2731304   0.22414123 -0.9931051\n  2.2807188   1.5416325   2.5824785   1.6550975 ]"",""180"":""[-8.646462    8.432445   -1.9644959  -5.04203    -0.7550678  -1.1799583\n  1.0167546   2.7429721   1.3187925   0.73035353]"",""181"":""[-9.023386    8.025105   -2.2746027  -5.381037    1.0518292  -0.04669392\n  3.4845426   0.4068364   2.1247852   2.403418  ]"",""19"":""[-8.431392    7.614035   -2.5958803  -4.447148   -0.19688448 -0.33394262\n  3.0486534   0.84165585  1.430105    2.4510858 ]"",""2"":""[-9.491928    7.9927006  -2.4145832  -5.3693705   0.8310711  -0.44119543\n  3.2911525   0.5271121   2.2326484   2.1494935 ]"",""20"":""[-9.135247    7.87029    -2.0324016  -5.253358    0.94433457 -0.18717709\n  3.2368808   1.072201    2.5139134   1.8615559 ]"",""21"":""[-9.260134    8.893567   -2.0459504  -5.6322556   1.0679909  -0.0747916\n  2.6342108   0.75273085  1.5871121   2.1649706 ]"",""22"":""[-8.856331    7.433166   -2.433991   -5.152363    0.51492375 -0.3398088\n  3.4922366   0.8621691   2.006945    1.839123  ]"",""23"":""[-10.314397     8.344344    -2.451122    -5.2863445    0.6439137\n  -0.42413586   2.653569     0.7898859    1.545782     1.9285902 ]"",""24"":""[-8.835961    8.949772   -2.3284268  -5.2889795   0.45267227 -0.45696166\n  2.4050674   0.61939645  1.3630925   2.473987  ]"",""25"":""[-8.571694   8.119994  -1.8736615 -4.7995043 -0.3395108 -0.9301465\n  1.4497032  2.5164673  1.4639171  1.1270915]"",""26"":""[-9.296834    8.375503   -1.853929   -5.020327    1.1050645   0.17340638\n  2.8702774   0.67100924  1.9576823   2.616054  ]"",""27"":""[-8.743226    7.9948783  -2.383623   -4.55232    -0.11665958 -0.3308889\n  2.5418649   0.9893353   1.0993577   2.3753314 ]"",""28"":""[-9.4589615   8.779484   -2.067911   -4.9464574   0.21431541 -0.4071705\n  1.7833143   1.2211225   1.1510363   2.2089868 ]"",""29"":""[-8.456703    7.7903104  -2.5709288  -4.4761133  -0.19749443 -0.35645732\n  2.9006953   0.74876124  1.307443    2.557961  ]"",""3"":""[-6.937626    5.8201966  -2.2630904  -4.237896    0.32605234  0.8908896\n  4.7000713   1.0076832   2.1091871   2.2872272 ]"",""30"":""[-8.816702    8.509358   -2.4057844  -4.8619494   0.20880531 -0.5079841\n  2.5769322   0.5945401   1.6044856   2.671664  ]"",""31"":""[-9.157305    8.304249   -2.201292   -5.517888    1.1880566  -0.05801463\n  3.3795779   0.35711697  2.242741    2.495284  ]"",""32"":""[-9.629673    8.141395   -2.532078   -4.887415    0.2182662  -0.3146602\n  2.5908527   0.6004313   0.86863047  2.31862   ]"",""33"":""[-9.640157    8.571218   -1.9573367  -5.366254    0.7094489  -0.44758072\n  2.3393056   1.4239506   2.1829538   1.6989219 ]"",""34"":""[-8.801164    8.276131   -2.396306   -4.8683634   0.17763045 -0.14004841\n  2.5190265   0.5775805   0.55938023  2.5028994 ]"",""35"":""[-8.814545    8.045436   -2.4227762  -4.816852    0.16496222 -0.109416\n  2.7030058   0.6218998   0.65081024  2.427685  ]"",""36"":""[-10.137251     8.238716    -2.4667108   -5.0928183    0.42492297\n  -0.42343894   2.5302706    0.7661116    1.2495767    2.0369973 ]"",""37"":""[-9.513383    8.740989   -2.3000734  -5.2987185   0.5889197  -0.16759902\n  2.3508468   0.66886795  0.7770415   2.2343078 ]"",""38"":""[-9.136161    7.7765336  -2.4928668  -5.3351407   0.603646   -0.41987932\n  3.3298917   0.74074423  1.9401382   1.8931861 ]"",""39"":""[-8.561127    7.990299   -1.9516312  -4.7875233  -0.29773948 -0.86516744\n  1.6208326   2.381251    1.4764965   1.1359037 ]"",""4"":""[-10.237928     8.509333    -2.2545514   -5.4036703    0.94118416\n  -0.2446852    2.7083733    0.73673123   1.6965123    2.0405948 ]"",""40"":""[-9.101305    8.282644   -2.355055   -4.6282196  -0.02256806 -0.42855108\n  2.3045087   0.9386181   1.1250772   2.4131014 ]"",""41"":""[-9.511532    8.976754   -2.1469996  -5.6211414   0.9433425  -0.38601565\n  2.444519    0.4207298   1.5446944   2.3815148 ]"",""42"":""[-9.272742    7.8196816  -2.522172   -5.4458847   0.53742415 -0.67613417\n  3.1986675   0.8455497   2.204137    1.7177409 ]"",""43"":""[-7.001776    5.543568   -2.6065211  -4.2360673   0.41881752  0.9792652\n  5.0396714   0.8005579   2.2509723   2.23492   ]"",""44"":""[-8.555283    7.6805916  -2.4513135  -4.589787    0.01783346 -0.12693374\n  2.992597    0.791409    1.084704    2.4312558 ]"",""45"":""[-8.977243    7.665728   -2.0986302  -5.208569    0.84596515 -0.20771585\n  3.3552654   1.1734484   2.5700774   1.7438692 ]"",""46"":""[-9.360299    7.9805207  -2.5233252  -5.498853    0.4245275  -0.79320973\n  2.8932464   0.861211    1.8720154   1.6489465 ]"",""47"":""[-9.128213    8.450719   -2.329859   -5.5961614   0.77918726 -0.4491838\n  2.9278517   1.0296558   2.292342    1.794432  ]"",""48"":""[-10.139477     8.88689     -2.0829926   -5.4397697    0.9157672\n  -0.32974514   2.2712066    0.74014366   1.5596864    2.179674  ]"",""49"":""[-9.265092    9.103279   -2.0566268  -5.651467    0.99122655 -0.09556525\n  2.4351606   0.76497513  1.3287505   2.1992393 ]"",""5"":""[-9.107137    7.684156   -2.3846667  -5.346438    0.8242386  -0.27867678\n  3.5543723   0.6592297   2.1939983   1.9841729 ]"",""50"":""[-9.263472    8.608635   -2.1454895  -4.925051    0.29243132 -0.20871972\n  2.107293    0.925062    0.86845064  2.376027  ]"",""51"":""[-9.463752    8.628829   -2.3052108  -5.2598577   0.29079625 -0.8941005\n  2.2645974   1.4190735   2.466555    1.7643517 ]"",""52"":""[-8.664445    8.027768   -2.080457   -4.8301163  -0.23513246 -0.62032884\n  1.8561937   1.9648335   1.2166562   1.3851523 ]"",""53"":""[-10.031156     8.737728    -2.142633    -5.1523867    0.44551557\n  -0.59170103   2.0060413    1.1606945    1.7112237    2.0083945 ]"",""54"":""[-9.95065     8.730909   -2.0587468  -5.223953    0.47780237 -0.57175803\n  1.9847071   1.3358723   1.7807649   1.8433659 ]"",""55"":""[-8.974378   7.609399  -2.2185445 -5.237978   0.7728461 -0.2837434\n  3.4299428  1.0086967  2.4207091  1.7956804]"",""56"":""[-8.663545    7.3759356  -2.479746   -4.8605533   0.22796468 -0.34015888\n  3.3676357   0.96878105  1.837049    1.938635  ]"",""57"":""[-9.641414   8.509942  -2.141138  -5.2332306  0.3154258 -0.77416\n  2.1321712  1.6156217  2.2022548  1.5477133]"",""58"":""[-9.274071    8.217207   -2.2650332  -5.427003    1.0382844  -0.20421813\n  3.2928047   0.44159424  2.1819596   2.3542373 ]"",""59"":""[-8.561626   8.166794  -1.8348768 -4.789414  -0.3566304 -0.9221538\n  1.3910632  2.5484164  1.4181529  1.1339186]"",""6"":""[-9.781605    8.860904   -2.127      -5.453507    1.0223627  -0.01651911\n  2.517556    0.48217016  1.1299993   2.3931713 ]"",""60"":""[-10.046396     8.385962    -2.2817059   -5.1997213    0.41853967\n  -0.569164     2.2898333    1.306663     1.7105821    1.6530313 ]"",""61"":""[-8.553136    8.258538   -1.9098351  -4.9131527  -0.6668342  -1.1155546\n  1.1658353   2.6990557   1.3981792   0.82624155]"",""62"":""[-8.475918    7.6795926  -2.5349817  -4.490344   -0.14149366 -0.2647776\n  2.9746168   0.8367307   1.2837102   2.4500713 ]"",""63"":""[-9.592456   8.674903  -2.0796413 -5.325042   1.0234833 -0.162976\n  2.7335384  0.4132955  1.8469197  2.6382673]"",""64"":""[-9.5678835   8.265106   -2.4375224  -5.122921    0.08753391 -0.70117533\n  2.2042797   1.2727542   1.3191227   1.6335316 ]"",""65"":""[-8.771572    8.348293   -2.3874457  -4.7528057   0.07483417 -0.31407702\n  2.4864616   0.6802914   0.9795135   2.5923505 ]"",""66"":""[-9.79737     8.99983    -2.0892432  -5.5630655   1.0041263  -0.21453324\n  2.3562403   0.5407916   1.3173171   2.3136177 ]"",""67"":""[-8.748805    7.706039   -2.4080515  -4.8601656   0.24464373 -0.14201167\n  3.0607264   0.84242535  1.2018895   2.1543398 ]"",""68"":""[-9.97066     8.399314   -2.120031   -5.3540387   1.142064   -0.09829171\n  2.9786167   0.63597167  2.0650387   2.2623312 ]"",""69"":""[-9.031842    7.775019   -2.2249336  -5.2856154   0.6503604  -0.44063675\n  3.1767256   1.155014    2.3962514   1.6795423 ]"",""7"":""[-9.529095    8.531693   -2.2619483  -5.2210546   0.28807372 -0.8620263\n  2.2573614   1.4696603   2.4242356   1.7067567 ]"",""70"":""[-10.124952     8.472015    -2.506142    -5.270046     0.44050038\n  -0.577832     2.4279268    0.7923763    1.3477982    1.947002  ]"",""71"":""[-6.7470803   5.5918894  -2.1420836  -4.0643797   0.43072265  0.993047\n  5.084612    1.1246773   2.3279011   2.2965925 ]"",""72"":""[-9.253798    8.906483   -2.1138332  -5.2831264   0.7271751  -0.06011058\n  2.2766764   0.60919774  0.8557843   2.455305  ]"",""73"":""[-9.458211    8.747134   -2.0745003  -5.636277    1.0903795  -0.13538936\n  2.7347486   0.84916484  1.8310963   2.0103548 ]"",""74"":""[-8.861671    8.373      -2.510455   -4.6942825  -0.05628272 -0.58316237\n  2.484816    0.74232733  1.4387031   2.5538287 ]"",""75"":""[-9.556486    8.187408   -2.3964725  -5.4476285   0.74798757 -0.1735513\n  2.9864194   1.0213457   1.6009136   1.666687  ]"",""76"":""[-8.533286   8.352648  -1.9161713 -5.0562944 -0.8443355 -1.1359792\n  1.0076511  2.6877367  1.3204293  0.694605 ]"",""77"":""[-9.735094    8.878096   -2.1701708  -5.6305847   0.8533383  -0.54223144\n  2.3558853   0.50211203  1.5637542   2.2188718 ]"",""78"":""[-7.271517   5.8085833 -2.6771019 -4.361511   0.4189128  1.0215268\n  5.0551763  0.8439828  2.4437973  2.389007 ]"",""79"":""[-8.764992    7.3715725  -2.483011   -4.9599876   0.3404636  -0.11220071\n  3.435729    0.923503    1.4885668   1.8830554 ]"",""8"":""[-9.129424    9.087909   -2.1939147  -5.681886    0.77223593 -0.45276368\n  2.386574    1.0048466   1.8079795   1.9585984 ]"",""80"":""[-8.593498    8.069048   -1.9904015  -4.829352   -0.39058357 -0.84814495\n  1.5923787   2.2828314   1.3793359   1.1781247 ]"",""81"":""[-9.690928    8.571197   -2.0407937  -5.348845    0.45901728 -0.6383833\n  2.121289    1.5660888   2.01084     1.5246319 ]"",""82"":""[-9.678469    8.421004   -2.0342371  -5.381275    1.1717567  -0.12119976\n  2.9960515   0.6893445   2.3210135   2.3091576 ]"",""83"":""[-8.598709    8.514362   -1.5510126  -4.9016466  -0.5936814  -1.3302509\n  0.53889453  3.3929932   1.6170855   0.6308401 ]"",""84"":""[-9.189867    8.832317   -2.0600665  -5.0290627   0.09882163 -0.6124715\n  1.7127336   1.4216478   1.444778    2.0443902 ]"",""85"":""[-8.627476   8.552977  -1.698304  -4.963429  -0.738545  -1.2410654\n  0.6648892  3.1768603  1.4814487  0.6453606]"",""86"":""[-9.46948     8.731655   -2.1752152  -5.090953    0.21819131 -0.6765788\n  1.977117    1.3684244   1.8623816   1.9666299 ]"",""87"":""[-8.686387    8.538581   -1.9292724  -5.1309633  -0.6885407  -1.2433919\n  0.88478225  2.86362     1.382674    0.697371  ]"",""88"":""[-6.9438686   5.6337447  -2.3386905  -4.146857    0.55379957  0.99240196\n  5.227301    1.1321232   2.5430384   2.3589392 ]"",""89"":""[-9.505509    8.068374   -2.3762667  -5.434966    0.93795633 -0.34763986\n  3.3218365   0.5102146   2.2190998   2.16092   ]"",""9"":""[-9.650506    8.496584   -2.0245814  -5.3048835   1.1635307  -0.10858316\n  2.9531593   0.506607    2.2488377   2.566692  ]"",""90"":""[-8.781864    7.561371   -2.598531   -4.784509    0.11994541 -0.44486588\n  3.2446377   0.722351    1.7030814   2.2324889 ]"",""91"":""[-8.88816     8.625449   -2.3232534  -4.911013    0.24446332 -0.31540143\n  2.3730252   0.5864152   1.0067784   2.6492896 ]"",""92"":""[-8.891418    7.7790303  -1.9867418  -5.1507177   0.93788487 -0.0821594\n  3.292492    1.2344966   2.649115    1.8335515 ]"",""93"":""[-9.128729    8.762401   -2.1574187  -5.0696115   0.36769426 -0.26101878\n  2.086509    0.8578198   0.87599003  2.3341424 ]"",""94"":""[-8.483593    7.733639   -2.4766161  -4.500328   -0.1026689  -0.16788307\n  2.9176052   0.7650927   1.0533133   2.55021   ]"",""95"":""[-6.8247175   5.7036953  -2.1314354  -4.164612    0.63525754  0.93263686\n  5.0112567   1.093555    2.4899795   2.3382232 ]"",""96"":""[-9.136436    8.25792    -2.2625873  -5.1079707   0.40509018 -0.11178537\n  2.5970895   0.87054443  0.89768255  2.129041  ]"",""97"":""[-9.403361   8.825375  -2.084742  -5.09257    0.2724926 -0.5404874\n  1.8803154  1.3158506  1.5850979  2.0674205]"",""98"":""[-9.955089   8.606095  -1.9271244 -5.366572   1.0445056 -0.1153805\n  2.540899   1.0019523  1.8816193  2.0347729]"",""99"":""[-8.74918     8.666819   -1.5170536  -5.0739646  -0.48158422 -1.4593726\n  0.6267608   3.3355558   1.7025541   0.7204285 ]""},""vocab_index"":{""0"":0,""1"":2,""10"":19,""100"":262,""101"":263,""102"":264,""103"":265,""104"":267,""105"":273,""106"":284,""107"":296,""108"":299,""109"":313,""11"":21,""110"":314,""111"":319,""112"":363,""113"":380,""114"":381,""115"":382,""116"":383,""117"":410,""118"":417,""119"":419,""12"":22,""120"":430,""121"":441,""122"":448,""123"":450,""124"":452,""125"":455,""126"":457,""127"":460,""128"":462,""129"":463,""13"":23,""130"":464,""131"":465,""132"":497,""133"":498,""134"":521,""135"":529,""136"":538,""137"":540,""138"":544,""139"":547,""14"":25,""140"":562,""141"":564,""142"":572,""143"":574,""144"":575,""145"":577,""146"":580,""147"":584,""148"":619,""149"":652,""15"":26,""150"":679,""151"":710,""152"":737,""153"":739,""154"":763,""155"":764,""156"":768,""157"":769,""158"":770,""159"":772,""16"":27,""160"":776,""161"":777,""162"":779,""163"":786,""164"":790,""165"":791,""166"":825,""167"":845,""168"":852,""169"":873,""17"":28,""170"":874,""171"":875,""172"":910,""173"":911,""174"":1010,""175"":1034,""176"":1049,""177"":1058,""178"":1083,""179"":1086,""18"":29,""180"":1096,""181"":1142,""19"":32,""2"":3,""20"":33,""21"":34,""22"":35,""23"":38,""24"":39,""25"":40,""26"":41,""27"":43,""28"":44,""29"":48,""3"":8,""30"":54,""31"":55,""32"":57,""33"":58,""34"":59,""35"":60,""36"":61,""37"":62,""38"":63,""39"":64,""4"":9,""40"":65,""41"":66,""42"":67,""43"":68,""44"":71,""45"":74,""46"":77,""47"":85,""48"":86,""49"":88,""5"":10,""50"":89,""51"":90,""52"":93,""53"":94,""54"":97,""55"":98,""56"":102,""57"":107,""58"":108,""59"":113,""6"":12,""60"":114,""61"":115,""62"":116,""63"":117,""64"":118,""65"":119,""66"":120,""67"":127,""68"":128,""69"":133,""7"":13,""70"":134,""71"":135,""72"":145,""73"":147,""74"":148,""75"":152,""76"":159,""77"":161,""78"":165,""79"":167,""8"":16,""80"":176,""81"":178,""82"":181,""83"":183,""84"":184,""85"":188,""86"":193,""87"":199,""88"":204,""89"":205,""9"":18,""90"":207,""91"":208,""92"":213,""93"":224,""94"":228,""95"":229,""96"":233,""97"":237,""98"":239,""99"":240},""word"":{""0"":""data"",""1"":""user"",""10"":""knowledge"",""100"":""projection"",""101"":""bayesian"",""102"":""ribarsky"",""103"":""engineering"",""104"":""hauser"",""105"":""stages"",""106"":""structures"",""107"":""generally"",""108"":""improve"",""109"":""mechanisms"",""11"":""systems"",""110"":""response"",""111"":""springer"",""112"":""expectations"",""113"":""advanced"",""114"":""study"",""115"":""e\ufb00ort"",""116"":""press"",""117"":""methodology"",""118"":""expected"",""119"":""paradigm"",""12"":""results"",""120"":""sets"",""121"":""found"",""122"":""streaming"",""123"":""location"",""124"":""helps"",""125"":""cases"",""126"":""latency"",""127"":""jmlr"",""128"":""york"",""129"":""chang"",""13"":""algorithms"",""130"":""park"",""131"":""society"",""132"":""produce"",""133"":""steps"",""134"":""observe"",""135"":""subsets"",""136"":""represented"",""137"":""image"",""138"":""demonstrate"",""139"":""category"",""14"":""users"",""140"":""articles"",""141"":""timeline"",""142"":""convergence"",""143"":""quantitative"",""144"":""trying"",""145"":""professor"",""146"":""wang"",""147"":""ramakrishnan"",""148"":""phases"",""149"":""metaphor"",""15"":""time"",""150"":""resources"",""151"":""introduce"",""152"":""analyzed"",""153"":""combining"",""154"":""regime"",""155"":""seconds"",""156"":""carrying"",""157"":""claims"",""158"":""tentative"",""159"":""annotations"",""16"":""human"",""160"":""sigchi"",""161"":""basu"",""162"":""siam"",""163"":""fiaux"",""164"":""streit"",""165"":""zhang"",""166"":""structuring"",""167"":""frames"",""168"":""placed"",""169"":""preparation"",""17"":""methods"",""170"":""generalization"",""171"":""deployment"",""172"":""journals"",""173"":""conferences"",""174"":""target"",""175"":""spire"",""176"":""images"",""177"":""predicting"",""178"":""e\ufb00ects"",""179"":""delay"",""18"":""feedback"",""180"":""grouped"",""181"":""aaai"",""19"":""conference"",""2"":""visualization"",""20"":""analytic"",""21"":""techniques"",""22"":""science"",""23"":""figure"",""24"":""tasks"",""25"":""high"",""26"":""classi\ufb01cation"",""27"":""topic"",""28"":""example"",""29"":""proceedings"",""3"":""ieee"",""30"":""transactions"",""31"":""algorithm"",""32"":""text"",""33"":""reasoning"",""34"":""people"",""35"":""authors"",""36"":""domain"",""37"":""features"",""38"":""technology"",""39"":""vast"",""4"":""model"",""40"":""section"",""41"":""parameters"",""42"":""exploration"",""43"":""di\ufb00erent"",""44"":""paper"",""45"":""sensemaking"",""46"":""space"",""47"":""training"",""48"":""framework"",""49"":""approaches"",""5"":""computer"",""50"":""examples"",""51"":""input"",""52"":""http"",""53"":""context"",""54"":""sense"",""55"":""cognitive"",""56"":""international"",""57"":""understanding"",""58"":""computation"",""59"":""similar"",""6"":""models"",""60"":""view"",""61"":""integrated"",""62"":""symposium"",""63"":""clusters"",""64"":""north"",""65"":""topics"",""66"":""frameworks"",""67"":""literature"",""68"":""regression"",""69"":""intelligence"",""7"":""interaction"",""70"":""frame"",""71"":""sacha"",""72"":""types"",""73"":""technique"",""74"":""events"",""75"":""design"",""76"":""discussed"",""77"":""constraints"",""78"":""keim"",""79"":""university"",""8"":""process"",""80"":""relevant"",""81"":""thinking"",""82"":""unsupervised"",""83"":""modify"",""84"":""result"",""85"":""describe"",""86"":""situation"",""87"":""called"",""88"":""turkay"",""89"":""simulation"",""9"":""clustering"",""90"":""media"",""91"":""items"",""92"":""speci\ufb01c"",""93"":""ones"",""94"":""papers"",""95"":""de\ufb01ne"",""96"":""works"",""97"":""case"",""98"":""theory"",""99"":""select""},""word*"":{""0"":""data"",""1"":""user"",""10"":""knowledge"",""100"":""projection"",""101"":""bayesian*"",""102"":""ribarsky"",""103"":""engineering"",""104"":""hauser*"",""105"":""stages"",""106"":""structures*"",""107"":""generally"",""108"":""improve"",""109"":""mechanisms*"",""11"":""systems*"",""110"":""response*"",""111"":""springer"",""112"":""expectations"",""113"":""advanced"",""114"":""study"",""115"":""e\ufb00ort*"",""116"":""press"",""117"":""methodology"",""118"":""expected"",""119"":""paradigm"",""12"":""results"",""120"":""sets"",""121"":""found"",""122"":""streaming"",""123"":""location"",""124"":""helps"",""125"":""cases"",""126"":""latency"",""127"":""jmlr*"",""128"":""york"",""129"":""chang"",""13"":""algorithms"",""130"":""park"",""131"":""society"",""132"":""produce*"",""133"":""steps"",""134"":""observe*"",""135"":""subsets"",""136"":""represented*"",""137"":""image*"",""138"":""demonstrate*"",""139"":""category"",""14"":""users*"",""140"":""articles*"",""141"":""timeline"",""142"":""convergence"",""143"":""quantitative*"",""144"":""trying"",""145"":""professor"",""146"":""wang"",""147"":""ramakrishnan"",""148"":""phases"",""149"":""metaphor"",""15"":""time"",""150"":""resources"",""151"":""introduce*"",""152"":""analyzed*"",""153"":""combining"",""154"":""regime"",""155"":""seconds"",""156"":""carrying"",""157"":""claims"",""158"":""tentative*"",""159"":""annotations"",""16"":""human"",""160"":""sigchi"",""161"":""basu*"",""162"":""siam*"",""163"":""fiaux*"",""164"":""streit"",""165"":""zhang*"",""166"":""structuring*"",""167"":""frames"",""168"":""placed*"",""169"":""preparation"",""17"":""methods*"",""170"":""generalization"",""171"":""deployment"",""172"":""journals"",""173"":""conferences*"",""174"":""target"",""175"":""spire"",""176"":""images*"",""177"":""predicting"",""178"":""e\ufb00ects"",""179"":""delay"",""18"":""feedback"",""180"":""grouped*"",""181"":""aaai"",""19"":""conference*"",""2"":""visualization"",""20"":""analytic*"",""21"":""techniques"",""22"":""science"",""23"":""figure*"",""24"":""tasks"",""25"":""high*"",""26"":""classi\ufb01cation"",""27"":""topic"",""28"":""example"",""29"":""proceedings*"",""3"":""ieee*"",""30"":""transactions"",""31"":""algorithm*"",""32"":""text"",""33"":""reasoning"",""34"":""people*"",""35"":""authors"",""36"":""domain*"",""37"":""features"",""38"":""technology"",""39"":""vast*"",""4"":""model"",""40"":""section*"",""41"":""parameters"",""42"":""exploration"",""43"":""di\ufb00erent"",""44"":""paper"",""45"":""sensemaking*"",""46"":""space"",""47"":""training"",""48"":""framework"",""49"":""approaches*"",""5"":""computer"",""50"":""examples"",""51"":""input*"",""52"":""http"",""53"":""context"",""54"":""sense"",""55"":""cognitive*"",""56"":""international"",""57"":""understanding*"",""58"":""computation*"",""59"":""similar*"",""6"":""models"",""60"":""view"",""61"":""integrated"",""62"":""symposium*"",""63"":""clusters"",""64"":""north"",""65"":""topics*"",""66"":""frameworks*"",""67"":""literature"",""68"":""regression"",""69"":""intelligence*"",""7"":""interaction*"",""70"":""frame*"",""71"":""sacha*"",""72"":""types"",""73"":""technique"",""74"":""events"",""75"":""design"",""76"":""discussed*"",""77"":""constraints"",""78"":""keim"",""79"":""university"",""8"":""process"",""80"":""relevant*"",""81"":""thinking"",""82"":""unsupervised*"",""83"":""modify"",""84"":""result"",""85"":""describe*"",""86"":""situation"",""87"":""called"",""88"":""turkay"",""89"":""simulation"",""9"":""clustering*"",""90"":""media"",""91"":""items"",""92"":""speci\ufb01c"",""93"":""ones"",""94"":""papers*"",""95"":""de\ufb01ne*"",""96"":""works"",""97"":""case"",""98"":""theory"",""99"":""select""},""x2D"":{""0"":9.0515346527,""1"":7.6703629494,""10"":9.6940498352,""100"":7.5187506676,""101"":8.7772226334,""102"":-21.8823947906,""103"":9.7630815506,""104"":-21.8436985016,""105"":6.3081755638,""106"":6.3803286552,""107"":3.756061554,""108"":-0.7720168233,""109"":6.3715543747,""11"":6.4843015671,""110"":4.0913324356,""111"":-22.0523204803,""112"":4.1524019241,""113"":2.1169111729,""114"":9.5539531708,""115"":-21.4882621765,""116"":9.3700466156,""117"":7.5500483513,""118"":3.5711975098,""119"":7.3319530487,""12"":5.7245326042,""120"":6.608830452,""121"":1.2401202917,""122"":9.4749450684,""123"":5.3333644867,""124"":4.0033173561,""125"":5.6099300385,""126"":9.0816936493,""127"":-21.6227626801,""128"":-22.3668575287,""129"":-22.6113872528,""13"":8.8710193634,""130"":9.7641468048,""131"":9.7829771042,""132"":-0.6884400249,""133"":6.3432812691,""134"":-0.7975405455,""135"":6.6776027679,""136"":1.0858533382,""137"":7.1971917152,""138"":-0.7309970856,""139"":6.7740445137,""14"":7.6377544403,""140"":7.6769285202,""141"":7.1093873978,""142"":9.0928459167,""143"":10.0911054611,""144"":3.7312700748,""145"":9.5122518539,""146"":-22.5403499603,""147"":-22.1570358276,""148"":6.1991758347,""149"":7.3155970573,""15"":5.1807117462,""150"":9.2380075455,""151"":-0.7220233679,""152"":1.2164862156,""153"":1.4496799707,""154"":6.9126939774,""155"":5.9707746506,""156"":1.2775346041,""157"":5.6076989174,""158"":2.3331522942,""159"":7.4156746864,""16"":10.0377502441,""160"":-21.45545578,""161"":-22.5303592682,""162"":-22.5549621582,""163"":-21.776102066,""164"":-21.8026695251,""165"":-22.5691776276,""166"":4.1440267563,""167"":6.9880332947,""168"":1.1034297943,""169"":8.7326450348,""17"":6.7895169258,""170"":8.0003871918,""171"":8.7559728622,""172"":8.8366127014,""173"":9.2484416962,""174"":4.8467674255,""175"":7.5129532814,""176"":7.1793551445,""177"":3.4426734447,""178"":-21.701631546,""179"":8.549038887,""18"":3.9458055496,""180"":1.2664740086,""181"":9.3004541397,""19"":9.2750492096,""2"":9.3438901901,""20"":10.0296831131,""21"":6.8581051826,""22"":9.8574361801,""23"":7.3247199059,""24"":6.1558632851,""25"":2.2301616669,""26"":8.7505283356,""27"":8.1271543503,""28"":5.4406485558,""29"":9.1584224701,""3"":-21.6811256409,""30"":6.9692177773,""31"":9.2135410309,""32"":7.3172364235,""33"":4.2228074074,""34"":7.5621666908,""35"":7.7204051018,""36"":7.1775403023,""37"":6.6897630692,""38"":9.4741029739,""39"":2.4007503986,""4"":7.4973649979,""40"":7.3769164085,""41"":6.6897859573,""42"":9.4472112656,""43"":-21.7986297607,""44"":9.1523942947,""45"":10.2422447205,""46"":9.2186279297,""47"":8.8028488159,""48"":7.0952534676,""49"":6.3173494339,""5"":9.7450437546,""50"":6.680118084,""51"":4.0103936195,""52"":2.5282053947,""53"":4.8062486649,""54"":4.5698595047,""55"":10.1971311569,""56"":9.8336496353,""57"":4.1785116196,""58"":9.2270278931,""59"":2.2428231239,""6"":6.236679554,""60"":4.7719583511,""61"":1.6138164997,""62"":9.2639865875,""63"":8.4223070145,""64"":5.0824589729,""65"":7.3124084473,""66"":6.6017045975,""67"":9.4944257736,""68"":8.2395267487,""69"":9.9713687897,""7"":3.9731144905,""70"":7.0491895676,""71"":-22.7294940948,""72"":6.6232948303,""73"":7.4787430763,""74"":7.1917877197,""75"":8.3565950394,""76"":1.1417156458,""77"":6.6694297791,""78"":-21.6810798645,""79"":9.8284101486,""8"":6.651289463,""80"":2.3971874714,""81"":4.2885203362,""82"":8.4131889343,""83"":-0.8722277284,""84"":4.8963274956,""85"":-0.6531454325,""86"":4.5385603905,""87"":1.0003042221,""88"":-22.2744922638,""89"":9.2284784317,""9"":8.537156105,""90"":9.7261915207,""91"":6.9774808884,""92"":10.2999601364,""93"":6.4176864624,""94"":9.1253395081,""95"":-22.4803543091,""96"":7.1749763489,""97"":5.0599784851,""98"":7.4658150673,""99"":-0.8311699629},""y2D"":{""0"":-2.7352759838,""1"":1.1056294441,""10"":-1.2974025011,""100"":-1.0209079981,""101"":-2.8854029179,""102"":5.7145323753,""103"":-0.3877326846,""104"":5.2207250595,""105"":-1.6886142492,""106"":-2.2851338387,""107"":1.3940948248,""108"":4.8227624893,""109"":-2.38352561,""11"":-2.2466919422,""110"":-0.1395801455,""111"":5.0183053017,""112"":0.9308156371,""113"":2.7012901306,""114"":0.784009397,""115"":5.4590158463,""116"":1.3079850674,""117"":-2.5422277451,""118"":1.5564180613,""119"":-1.9802937508,""12"":0.678869009,""120"":0.3423798382,""121"":3.3636324406,""122"":-0.9150748253,""123"":-0.2052102238,""124"":1.1509251595,""125"":0.6407004595,""126"":-2.6678276062,""127"":5.3234958649,""128"":4.8941273689,""129"":4.9794354439,""13"":-2.8939285278,""130"":0.241575703,""131"":0.170631513,""132"":4.7389149666,""133"":-1.6934548616,""134"":4.8465638161,""135"":0.5648310781,""136"":3.5117497444,""137"":-0.607842505,""138"":4.7819647789,""139"":0.8332203031,""14"":1.0824862719,""140"":1.3625904322,""141"":1.2233579159,""142"":-1.8916226625,""143"":-1.2519775629,""144"":1.3863344193,""145"":0.9278166294,""146"":4.9780254364,""147"":5.5334243774,""148"":-1.8279300928,""149"":-1.8251131773,""15"":-0.1777543426,""150"":-1.2007524967,""151"":4.7729668617,""152"":3.3894805908,""153"":3.2032341957,""154"":-2.1466653347,""155"":-0.0530050285,""156"":3.3381185532,""157"":0.6236153841,""158"":2.5332467556,""159"":0.7067090869,""16"":-0.6761838198,""160"":5.2916679382,""161"":5.2790985107,""162"":5.1105294228,""163"":5.5664691925,""164"":5.6791052818,""165"":5.1098704338,""166"":-0.4549786747,""167"":-0.4721687734,""168"":3.4956436157,""169"":-1.3942732811,""17"":-2.608604908,""170"":-2.6514670849,""171"":-1.4316956997,""172"":1.3862110376,""173"":1.3287324905,""174"":0.1401021183,""175"":-0.8028582335,""176"":0.0085047157,""177"":1.6669267416,""178"":5.2136349678,""179"":-1.4316183329,""18"":-0.1812445223,""180"":3.345815897,""181"":-2.5292992592,""19"":1.4616116285,""2"":-1.9735256433,""20"":-1.1046715975,""21"":-2.6394147873,""22"":-0.2200316638,""23"":-0.9640181065,""24"":0.2496120334,""25"":2.6251368523,""26"":-2.9787888527,""27"":1.4842374325,""28"":0.6844925284,""29"":1.5174877644,""3"":5.1000084877,""30"":1.2804672718,""31"":-2.6104850769,""32"":0.3654068708,""33"":-0.3975031674,""34"":1.0320806503,""35"":1.1277832985,""36"":-0.6345091462,""37"":0.2464823127,""38"":-0.7195884585,""39"":2.4664671421,""4"":-1.6436142921,""40"":1.1565355062,""41"":-2.5218081474,""42"":-1.1160174608,""43"":5.6401090622,""44"":1.2553460598,""45"":-1.1460542679,""46"":-1.210162878,""47"":-1.3702899218,""48"":-2.0059204102,""49"":-2.4580447674,""5"":-0.961121738,""50"":0.6668694615,""51"":-0.2030837089,""52"":2.3602538109,""53"":-0.3347754776,""54"":-0.1359342784,""55"":-0.9819591045,""56"":0.4294413328,""57"":-0.3397192657,""58"":-2.4744637012,""59"":2.6067416668,""6"":-2.2233457565,""60"":-0.4198436439,""61"":3.0659561157,""62"":1.4130711555,""63"":-2.8733186722,""64"":-0.0980296955,""65"":1.3127892017,""66"":-2.3820998669,""67"":0.9248541594,""68"":-2.7686681747,""69"":-1.1723847389,""7"":-0.2237019241,""70"":-0.7018550634,""71"":5.1306385994,""72"":0.4045979679,""73"":-2.5806014538,""74"":1.3591825962,""75"":-1.1751334667,""76"":3.4625976086,""77"":-2.2637996674,""78"":5.7593746185,""79"":0.3237522542,""8"":-1.703894496,""80"":2.4739573002,""81"":-0.4192903936,""82"":-2.7879636288,""83"":4.9212622643,""84"":0.6893744469,""85"":4.7075500488,""86"":0.2509405315,""87"":3.5933463573,""88"":5.5936880112,""89"":-2.197177887,""9"":-2.9639291763,""90"":0.6326318383,""91"":1.0718799829,""92"":-1.2162700891,""93"":0.6068301797,""94"":1.4335454702,""95"":5.3327307701,""96"":0.5520207286,""97"":0.5242167711,""98"":-2.1428778172,""99"":4.8790850639}}",False,False,False,http://arxiv.org/abs/1802.07954,,The State of the Art in Integrating Machine Learning into Visual Analytics,"[-5.23964226e-01  2.81508893e-01  6.66573763e-01 -9.85391855e-01
 -2.56551713e-01 -2.27034718e-01 -2.10777760e-01 -1.98817983e-01
  1.49133578e-01  2.35180687e-02 -5.59797347e-01 -8.72245550e-01
  8.54760930e-02  6.07881546e-01 -4.55387309e-02  9.74287271e-01
  1.79614663e-01 -6.87976852e-02 -5.27823627e-01  9.23682153e-02
  5.51582396e-01  6.50271773e-01 -4.59923642e-03  8.58994797e-02
 -2.64288168e-02  9.46411639e-02 -2.56728623e-02  1.80342108e-01
 -3.71261835e-02  5.48278153e-01  1.40253127e-01  2.35005870e-01
 -3.19567740e-01 -1.30218655e-01  3.61220777e-01 -2.46346891e-01
  3.23829949e-02 -5.34351051e-01  4.23739702e-01  1.32236376e-01
  3.81100953e-01 -3.09748411e-01 -1.34175390e-01 -1.43919528e-01
  4.15020168e-01  1.43788740e-01 -2.32099518e-01 -1.85230330e-01
 -3.27592671e-01 -1.63913339e-01 -8.36311162e-01 -1.75658181e-01
 -1.36943802e-01 -4.56633002e-01 -1.71315655e-01  4.75759000e-01
  1.44926503e-01 -3.22721332e-01 -3.73954684e-01 -1.54926717e-01
  1.77916810e-01 -5.11508226e-01  3.51037979e-01  5.06214559e-01
 -1.92710996e-01 -2.13298187e-01 -7.13536322e-01  6.68428242e-01
 -1.52965695e-01 -4.50229496e-02 -1.74346536e-01  5.96069992e-01
  2.70148993e-01  4.24738109e-01  1.82437912e-01 -2.43897438e-02
 -1.99712545e-01  1.23407096e-01 -1.04524001e-01 -7.67008364e-02
  1.18772611e-01  2.42790133e-01  5.17602146e-01 -1.02696106e-01
  2.48342574e-01  2.43494645e-01  1.49012372e-01 -4.60720569e-01
 -3.17282587e-01  1.64838433e-01 -1.79372042e-01  1.64577156e-01
 -1.00005344e-01 -8.12355801e-02 -2.20539626e-02  1.08688049e-01
 -5.36157310e-01 -4.12724137e-01  7.46886209e-02 -4.28225517e-01
  1.33268178e-01  9.92671400e-02  3.48123789e-01 -2.93887794e-01
 -4.22756225e-01  1.05744287e-01  9.07455087e-02 -2.17818111e-01
 -1.31141722e-01  2.95919865e-01  6.27743155e-02  3.33817840e-01
  5.48490435e-02 -2.02600896e-01 -1.28561452e-01 -7.65456855e-02
  2.23395154e-02 -1.46046698e-01  3.88868079e-02  5.78314185e-01
 -2.14662910e-01 -4.89291072e-01  4.27803129e-01 -1.77283436e-01
 -1.99560020e-02 -2.15093911e-01  9.14365351e-02 -1.32544726e-01
 -2.51628786e-01  4.81891453e-01 -3.27827305e-01  3.13712321e-02
 -4.05015573e-02 -1.44856736e-01 -2.35693771e-02  8.46246630e-02
 -3.55252534e-01  1.02589495e-01 -2.16640174e-01 -2.61403859e-01
  2.87526269e-02 -2.98469245e-01 -1.45117193e-01 -3.61916989e-01
 -2.45309874e-01  3.92248705e-02 -2.68084168e-01  1.45796999e-01
  2.60152578e-01  1.41476974e-01 -3.48864198e-01  1.34082645e-01
 -4.35801558e-02  7.57904574e-02 -3.69410783e-01 -1.89514905e-01
 -7.40569904e-02  3.17750424e-01 -3.09273630e-01 -2.49147732e-02
  5.36555231e-01  6.30565137e-02  2.94160455e-01  4.30839628e-01
  2.08418310e-01  6.55441999e-01  2.45062396e-01  4.00522463e-02
 -3.00612390e-01 -3.49429309e-01 -5.39320707e-01 -5.66782355e-01
 -1.06021814e-01  1.26046836e-01  5.15276611e-01 -8.92709941e-02
  5.30864373e-02  9.08295438e-02  1.24058351e-01 -3.29132378e-02
 -6.31323755e-01 -3.43162835e-01 -3.85968238e-01 -4.78082478e-01
  5.14140546e-01  1.07735299e-01  4.40890670e-01 -1.30551174e-01
 -1.17271550e-01  2.35707745e-01 -1.67622209e-01 -2.10903466e-01
  3.82188529e-01 -3.93822372e-01  1.96620956e-01 -4.32202190e-01
  2.30481833e-01 -4.31248695e-01 -2.13874266e-01 -3.35136771e-01
  3.09470952e-01  6.66836798e-02  1.42917037e-01  2.22218812e-01
 -4.93851416e-02  3.24829072e-01 -2.41943344e-01  2.99485445e-01
 -7.18911290e-01  1.57180458e-01 -2.94196993e-01  3.37228924e-01
  4.42806333e-02 -5.57889380e-02  4.00503069e-01 -2.05086455e-01
  3.71804833e-01 -4.37169343e-01  3.35572839e-01 -4.06677753e-01
 -1.53685674e-01 -2.64994502e-01 -6.62125945e-02  4.50890034e-01
 -2.15261683e-01  1.28631604e+00  6.23868704e-01 -1.25334993e-01
  8.55100930e-01 -2.25820199e-01 -2.30654255e-01 -3.10871989e-01
  6.44973993e-01  1.00862645e-01  1.78967759e-01  7.41554976e-01
 -3.80045474e-01 -2.31788438e-02 -7.92501718e-02 -3.39979768e-01
  2.59924591e-01 -1.21431611e-01  4.89381284e-01  2.37721145e-01
  2.09715068e-01  1.48313880e-01  2.38445640e-01 -2.76138872e-01
  2.75584739e-02  1.55959800e-01 -2.70766169e-01  4.43108022e-01
 -1.82678610e-01 -7.53271997e-01 -1.67991966e-01 -1.60762534e-01
  2.17404664e-01 -6.48247898e-01  7.06144795e-02 -1.30098552e-01
 -1.25341653e-03 -7.25556552e-01  2.13634908e-01  1.92413479e-01
 -2.54987758e-02  1.97043628e-01 -4.58479598e-02 -1.23590559e-01
  5.05980730e-01 -1.44087374e-01 -2.32095897e-01  2.39860207e-01
 -1.54721141e-01  4.22752388e-02 -3.27123344e-01 -3.82647127e-01
  4.13001060e-01 -9.91465300e-02  7.26496428e-02 -2.07599312e-01
 -5.33858910e-02  3.57829407e-02  1.23119220e-01  2.25544184e-01
 -4.29836690e-01  1.72828674e-01 -1.68236583e-01 -1.73704147e-01
  3.04238766e-01 -4.38137144e-01 -1.79706350e-01  5.07237762e-02
 -1.24127284e-01 -6.40254319e-02  4.89723802e-01  9.39423442e-02
 -3.58327419e-01  8.17922279e-02  2.89242029e-01 -1.92891985e-01
 -3.96596491e-01  6.81268454e-01 -1.53021723e-01  2.34074324e-01
 -2.26299495e-01  2.39717141e-01 -2.83048660e-01  2.24953055e-01
 -9.55965900e+00 -3.26184869e-01 -5.29035985e-01 -3.88136595e-01
  4.10589784e-01  2.61218771e-02  1.02659255e-01 -9.88808349e-02
  1.70447260e-01 -4.68093902e-01  1.76087648e-01 -1.84174001e-01
  7.39852041e-02  7.52830207e-02  3.93544197e-01 -7.87267983e-02
  1.58761337e-01  4.98840287e-02 -7.76641518e-02  7.77701020e-01
 -1.66150004e-01  2.23785378e-02  5.52256286e-01 -2.61990372e-02
  5.81886292e-01 -3.13131064e-01 -4.26746488e-01 -1.57518983e-01
 -2.98811615e-01 -1.15554571e-01 -1.78149313e-01 -5.27316689e-01
 -4.99211878e-01  1.02665317e+00  1.84482634e-01 -2.09081396e-01
 -1.50221765e-01 -6.64799333e-01 -2.98571110e-01  5.14290094e-01
  1.54581740e-01 -3.97706211e-01 -3.75588298e-01  7.24223197e-01
  4.26675916e-01 -2.12119445e-01  2.39561215e-01 -1.90061927e-01
  1.77135281e-02  2.87277043e-01  2.57547289e-01  2.87362665e-01
 -1.88309044e-01 -7.90518403e-01  1.89678267e-01  4.36642766e-01
  4.49269870e-03  1.41814366e-01 -2.49696597e-01 -3.02586794e-01
  7.84282327e-01 -1.35621831e-01 -5.29788099e-02  2.85459775e-02
 -3.91014516e-01  4.09683108e-01 -1.60962254e-01 -2.66813457e-01
 -1.02556601e-01 -4.10475552e-01  4.49678004e-02  7.76434183e-01
  4.34542418e-01 -7.59495974e-01 -2.99200892e-01 -3.55669975e-01
 -2.92761415e-01  4.44798768e-01  5.54740392e-02  4.86050844e-02
 -3.35376292e-01 -6.07965827e-01 -4.77135628e-01  3.63427162e-01
 -4.06406313e-01  5.33807576e-01  1.01984933e-01 -3.96018296e-01
 -4.42590535e-01 -6.05433524e-01 -2.68701524e-01  1.43462375e-01
  3.06308925e-01  2.65811354e-01 -8.39905534e-03 -4.35767710e-01
  4.92057562e-01 -2.99901515e-01  4.38241839e-01 -1.82732090e-01
 -8.16730037e-02  4.24215764e-01  2.43655257e-02 -5.12507021e-01
 -3.44753802e-01  5.69858365e-02 -6.83472872e-01 -3.66527408e-01
  1.13325775e-01 -4.87903744e-01  7.32436538e-01 -4.04957049e-02
 -2.48963028e-01 -4.49140817e-01  1.29205678e-02  1.34930881e-02
 -1.46889821e-01  2.65406668e-01 -3.75550359e-01 -5.56513667e-01
 -9.37409997e-01  6.29909575e-01 -7.96953499e-01 -5.48088789e-01
 -3.35731477e-01  9.43059683e-01 -2.17085658e-03 -2.96271205e-01
 -5.66492975e-01 -1.20836064e-01 -1.31117851e-01 -1.81297921e-02
 -9.02875885e-02 -3.01316172e-01 -9.19586942e-02  1.41912550e-01
  1.01876423e-01 -1.06493108e-01 -1.39581725e-01  2.62901902e-01
  6.19345963e-01  3.25816303e-01  3.90080184e-01  2.54986584e-01
  2.26306573e-01 -1.45748436e-01  5.13162076e-01  3.90106022e-01
  1.93945002e-02  4.99099463e-01  3.59910540e-02 -2.33065695e-01
  3.61607462e-01 -2.19571188e-01 -1.90972045e-01  4.29253429e-01
  5.75033545e-01 -2.41912439e-01 -2.93951392e-01 -2.02615604e-01
  6.00074351e-01  8.12181551e-03 -3.77485842e-01  3.81501727e-02
  2.17113286e-01  9.19816047e-02  8.83364230e-02  1.23076886e-01
  7.49533176e-02 -4.34124351e-01 -4.27169502e-01  3.98960203e-01
  2.91740686e-01 -2.37171695e-01 -5.57853103e-01  2.96869844e-01
 -2.13059336e-02  3.94480713e-02  4.25190032e-02  1.33307621e-01
  1.76614165e-01 -2.27752090e-01 -1.46520615e-01 -8.94313306e-02
  1.77822232e-01 -1.49553627e-01 -1.70293212e-01 -2.62246847e-01
  2.81793505e-01  3.19161445e-01 -2.06438601e-01 -2.34121725e-01
  1.06673412e-01  2.80010756e-02 -3.46911401e-01 -3.04690927e-01
  6.83418214e-01  1.63052157e-01 -1.22205399e-01  6.00618303e-01
  1.21309392e-01  1.66041926e-01  3.14331561e-01  1.42287195e-01
 -1.42237633e-01 -4.58858490e-01  1.31869480e-01 -3.31860259e-02
 -1.54387876e-01 -1.53031394e-01  5.92132866e-01 -5.46810329e-01
 -2.38277148e-02  7.29745701e-02  4.16898839e-02  1.00100033e-01
 -3.63426507e-01 -3.53125036e-02 -4.03574675e-01 -2.04858512e-01
 -1.70002460e-01 -1.98747769e-01 -7.64899179e-02 -3.13934833e-01
  1.60239339e-01 -1.50535535e-02 -1.01195477e-01 -2.01075479e-01
 -4.30460095e-01 -1.84994876e-01 -8.32313448e-02 -1.01161921e+00
  3.98436300e-02 -1.12623274e-01  5.32438755e-01 -4.92272556e-01
 -9.25465345e-01 -6.93403110e-02  1.94601282e-01  1.10847019e-01
 -5.90241492e-01 -5.79771101e-01 -3.96311939e-01 -5.44776022e-01
  1.76663473e-01 -8.09422880e-02  3.76974978e-02 -4.66229469e-02
 -1.67913392e-01 -4.30099629e-02 -7.89205804e-02 -4.14653659e-01
 -3.92336428e-01 -1.56575009e-01  1.86101586e-01 -1.37412980e-01
 -1.03705905e-01 -2.74009984e-02  1.85791954e-01  1.74668014e-01
 -1.59731403e-01  1.03084713e-01  7.88198933e-02 -2.07448788e-02
  3.77328545e-02  4.86046113e-02 -2.14750007e-01  4.11011815e-01
  1.24518365e-01 -3.98334682e-01 -5.02772391e-01 -2.57178664e-01
 -2.47953847e-01 -1.20947599e-01  3.82166862e-01  4.13671643e-01
 -5.58675826e-01 -3.51239175e-01  2.45103106e-01  2.56873131e-01
  2.26684362e-01  4.14245963e-01  3.95684540e-01  1.17614508e-01
  5.43429613e-01 -7.17738748e-01 -6.69055581e-01  2.00835988e-01
 -2.30919555e-01  1.73622489e-01  3.59937966e-01  4.55577672e-01
 -8.36378455e-01 -3.12445045e-01 -4.13484335e-01  3.21610004e-01
  2.60214657e-01  2.56886389e-02 -3.66930738e-02  5.71676791e-01
  5.96651658e-02 -1.28646642e-01 -5.06651821e-03 -3.16539705e-01
  2.31163487e-01  9.89775062e-02 -1.94003016e-01  7.87535012e-02
 -3.86998147e-01  3.59436125e-01 -5.30833721e-01 -5.53425729e-01
  3.83564591e-01  2.49742851e-01  9.78392665e-04 -9.57245469e-01
  4.01588716e-02 -3.55831295e-01 -3.78310271e-02 -2.17594966e-01
  1.72300518e-01  7.59472668e-01  1.12404478e+00  3.56161535e-01
  2.23236352e-01 -3.16593528e-01  1.79567486e-01  2.06549466e-01
 -2.45311484e-01 -2.42484566e-02  5.54913163e-01  2.54061043e-01
  9.65516642e-02  4.22723681e-01  3.14511687e-01 -2.18213156e-01
 -1.94706231e-01 -3.55480224e-01  2.18585536e-01  2.27336019e-01
 -2.49298438e-01  3.81775498e-01  5.07443666e-01 -3.05543065e-01
  9.40053165e-02  7.66215771e-02 -2.62566924e-01  3.64391766e-02
  8.63697901e-02  1.99420631e-01 -4.20475751e-02  6.97903149e-03
  1.36761978e-01 -8.03747866e-03 -1.36034220e-01  2.29102634e-02
  3.37429225e-01 -1.02403343e-01  1.00099951e-01  7.00102150e-01
 -8.75083134e-02  2.88979501e-01  5.52688539e-01 -3.95348996e-01
 -1.26114756e-01 -4.89261607e-03  2.98605412e-01  6.66801855e-02
 -1.81796074e-01 -2.67905414e-01  3.40566784e-02 -8.87003720e-01
  3.41946304e-01  8.04884195e-01  2.90766329e-01 -1.85931683e-01
 -4.94150311e-01  1.66109025e-01 -2.58792520e-01  3.45502675e-01
 -5.62887907e-01 -3.25008124e-01  1.82897836e-01 -8.60421777e-01
  1.21805802e-01 -6.41103029e-01  5.01170933e-01  2.95778304e-01
  3.45975021e-03  8.00635815e-02 -4.11520004e-01 -4.31523293e-01
 -3.64398807e-02 -6.14868343e-01 -7.26065045e-05 -2.03567177e-01
 -1.83769107e-01  4.89716262e-01  7.73899317e-01 -1.88083738e-01
  1.60246283e-01  3.38667601e-01 -4.86174405e-01 -2.78638870e-01
  4.00583409e-02 -6.64173961e-02 -1.49622604e-01  1.05921400e+00
 -3.47786069e-01 -3.53335500e-01 -1.69463813e-01  3.63297343e-01
 -5.67981135e-03  4.16036308e-01  5.66772282e-01 -9.94435847e-02
 -1.70715109e-01 -1.07011640e+00 -6.71786904e-01  1.44038633e-01
 -1.96712628e-01 -6.69246376e-01 -3.25881094e-01 -3.60194743e-01
 -4.02261317e-01 -5.69726944e-01 -3.67397107e-02 -3.03039163e-01
  4.95876908e-01  8.93633142e-02  3.15187991e-01  1.11352079e-01
 -1.92059129e-01  1.14860766e-01 -1.59152284e-01 -2.29692787e-01
 -3.01852196e-01 -4.05924976e-01 -3.12278032e-01 -1.13452308e-01
 -3.89918387e-02  1.60467640e-01 -2.06628554e-02  4.71505433e-01
 -3.33762854e-01  2.72708923e-01 -4.60788846e-01 -9.70027372e-02
 -4.14567709e-01  1.64482400e-01  4.93671715e-01  3.29934150e-01
 -4.38134700e-01 -5.73407233e-01  1.53601974e-01 -1.97809085e-01
 -2.16027007e-01 -1.72029778e-01  3.33525389e-01  5.74347854e-01]",7YWBXAWZ,False,False,"[8.135104179382324, -1.4771913290023804]"
5LF32UEH,LA89FIC5,"Big Text Visual Analytics in Sensemaking 

Lauren Bradel, Nathan Wycoff, Leanna House, Chris North 

Department of Computer Science and Department of Statistics, Virginia Tech 

Blacksburg, Virginia, USA 

{lbradel1, nathw95, lhouse, north}@vt.edu 

 
 

iterate  between  foraging  for 

Abstract—  Learning  from  text  data  often  involves  a  loop  of 
tasks  that 
information  and 
synthesizing  it  in  incremental  hypotheses.  Past  research  has 
shown the advantages of using spatial workspaces as a means for 
synthesizing  information  through  externalizing  hypotheses  and 
creating  spatial  schemas.  However,  spatializing  the  entirety  of 
datasets  becomes  prohibitive  as  the  number  of  documents 
available  to  the  analysts  grows,  particularly  when  only  a  small 
subset are relevant to the tasks at hand. To address this issue, we 
applied  the  multi-model  semantic  interaction  (MSI)  technique, 
which leverages user interactions to aid in the display layout (as 
was seen in previous semantic interaction work), forage for new, 
relevant  documents  as  implied  by  the  interactions,  and  place 
them  in  context  of  the  user’s  existing  spatial  layout.  Thus,  this 
approach  cleanly  embeds  visual  analytics  of  big  text  collections 
directly into the human sensemaking process. 

Keywords—sensemaking, interaction design, visual analytics 

I.   INTRODUCTION 

While professional analysts are undoubtedly inundated with 
“too  much  data,”  it  is  crucial  to  remember  that  this  problem 
plagues everyday users as well. In this paper, we consider the 
challenge  of  exploratory  data  analysis  using  large  document 
collections such as scientific literature, news, or the world-wide 
web.  Unfortunately,  users  are  notoriously  bad  at  formulating 
explicit  queries  in  such  tasks  [31].  We  applied  multi-model 
semantic interaction [13] to this problem to allow the system to 
passively 
interpreting  user 
interactions, filter returned web results to those which are most 
relevant to the user’s interests, spatially arrange them according 
to similarity, and visually indicate document and text saliency. 
All of this is done in a single spatial workspace, thus placing 
foraged  information  in  context  of  the  existing  spatial  layout, 
allowing the user to continue synthesizing documents without 
the need to context switch. 

construct  queries 

through 

Take,  for  example,  a  researcher  conducting  a  literature 
review on a new research topic. This researcher likely does not 
know  the  taxonomy  of  this  topic,  which  could  easily  span 
multiple  sub-fields,  all  of  which  may  use  slightly  different 
language  in  describing  similar  topics.  In  such  a  case,  it  is 
difficult  to  easily  gain  a  comprehensive  understanding  of  the 
topic  through  explicit  querying.  How  can  the  researcher  be 
confident that she has not overlooked important papers that fall 
in  the  intersection  between  known  components  of  the  topic? 
We propose that multi-model semantic interaction takes steps 
to alleviate this concern. Instead of repeatedly typing queries, 
reading  abstracts,  and  curating  results  for  later  synthesis,  the 
researcher  can  conduct  all  foraging  actions  directly  from  her 

synthesis space. For example, if she finds two highly relevant 
papers  that  are  from  different  aspects  of  her  topic,  she  can 
overlap these two documents in order to retrieve any relevant 
papers  that combine  aspects of  both  papers. This  can  help  to 
“fill  in  the  gaps”  in  the  researcher’s  literature  review  and 
hopefully allow her to avoid missing crucial information. 

task 

Another  common  exploratory  data  analysis 

is 
investigating  current  events  in  the  news.  In  order  to  gain  a 
comprehensive understanding of a particular topic, users must 
frequently consider multiple sources for information, not only 
to fill in knowledge gaps, but also due to the differing opinions 
of individual journalists. For example, a user may be interested 
in tracking political candidates for an upcoming election. They 
may begin their analysis by searching for a specific candidate’s 
name.  This  query  could  return  articles  from  major  news 
networks, opinion pieces, local news outlets, personal blogs, or 
satirical news websites. The user is then tasked with injecting 
feedback to steer the underlying user interest model to create a 
subset  of  documents  that  cover  various  aspects  of  the 
candidate, their campaign, as well as comparisons to additional 
political candidates. While a literature review may be focused 
enough to pull from specific digital libraries with standardized 
formatting (e.g. IEEE, ACM), exploring a news topic requires 
pulling  articles  from  a  wider  number  of  sources  with  varied 
formatting  and  advertisements.    This  presents  additional 
challenges in terms of article parsing. 

These  scenarios  demonstrate  an  opportunity  for  big  data 
text  analytics.  Previous  work  has  shown  that  users  leverage 
implicit query formation to retrieve relevant information [13], 
but this technique has not been applied to such a large scale of 
data. Dealing with vastly different levels of data scale (e.g. a 
small  curated  working  set  of  documents  vs.  the  internet) 
presents a set of research challenges in terms of performance, 
model  coordination,  interaction  design,  and  visual  encodings. 
We  discuss  these  challenges  and  present  an  extension  to  our 
existing  visual  analytics  tool  prototype,  StarSPIRE  [13],  that 
enables  these  aforementioned  scenarios  to  be  performed 
through integration with external web search services such as 
Bing and IEEE Xplore. 

We present a method to integrate information retrieval with 
information  synthesis  by  presenting  foraged  results  from 
external  search  services  in  context  of  the  user’s  current 
analytical state via a spatial “near = similar” metaphor. Other 
systems  tend  to  treat  information  retrieval  as  a  separate  task, 
but  we  intend  to  remove  the  intermediary  steps  to  create  a 
cohesive  and  integrated  sensemaking  environment  that  does 
not  force  users  out  of  their  “cognitive  zone”  [29]  of 

978-1-4673-7343-2/15/$31.00 ©2015 IEEEinformation synthesis. Instead of exiting their synthesis space 
to  execute  a  query  from  external  data  sources,  judge  results, 
and  import  them  to  a  workspace,  these  actions  can  be  done 
directly  and  automatically  from  the  spatial  workspace  with 
results being placed within the existing schema [Figure 1].  

 

Figure  1.  StarSPIRE:  analyst's  workspace  during  a  literature 
review task. 

Furthermore,  working  within  a  spatial  metaphor  allows 
users  to  directly  manipulate  data  at  vastly  different  levels  of 
scale [21]. The user is able to focus on a small working set of 
documents while having the entirety of large external sources 
at their fingertips. We present a means to steer the underlying 
models  at  these  varying  levels  of  scale  while  addressing  the 
challenges associated with this undertaking. 

Finally,  we  present  an  updated  visualization  pipeline  and 
the associated implementation of StarSPIRE that addresses the 
multi-scale nature of these exploratory data analysis tasks. We 
discuss the system architecture, model coordination, interaction 
mapping,  and  visual  encodings.  A  critical  component  of  this 
work  is  the  connection  to  existing  external  search  services, 
enabling visual analytics methods such as semantic interaction 
to  exploit  the  benefits  of  successful  information  retrieval 
systems. Through this work, we have achieved near-real-time 
big  data  analytics  for  text-based  sensemaking  in  exploratory 
data analysis tasks. 

II.  RELATED WORK 

A.  Spatializations for Sensemaking 

is 

typically  achieved 

Prior research  has  highlighted  the  utility  of  spatializations 
for  text  analysis  [3,  5,  12,  23,  26,  35,  42, 49,  54,  55].  Large 
spatial  workspaces  have  been  found  beneficial  in  affording  a 
flexible workspace that allows users to externalize knowledge 
and  create  semantic  schemas  [4].  However,  this  knowledge 
externalization 
through  parametric 
interactions  (e.g.  [36]),  many  of  which  require  users  to  go 
outside  the  spatial  metaphor  by  manipulating  control  panels 
[21]. Furthermore, parametric interaction does not easily scale 
to big data problems. In unstructured text data, dimensions map 
to the terms or entities contained in the documents. Thus, the 
dimensionality of the data grows extremely large as the number 
of  documents  increases.  Aside  from  navigating  through  the 
flood  of  dimensions,  altering  multiple  models  becomes 
extremely  tedious.  If  multiple  models  are  used  for  layout 
and/or retrieval, the user must update the dimensional weights 
or parameters for each model and potentially at multiple levels 

of scale. To remove this redundancy, we contain the interaction 
within  the  spatial  metaphor  and  translate  interactions  into 
parametric feedback. 

For  tools  that  allow  users  to  stay  within  the  spatial 
metaphor, parametric interaction is still common. For example, 
Dust & Magnet allows users to manipulate spatial landmarks to 
adjust  the  spatialization  of  multi-variate data.  However,  these 
landmarks are attributes of the data, not points themselves. The 
users  only  have  control  over  the  parameters  in  the  space. 
Similarly, VIBE allows users to designate keywords as spatial 
landmarks  [42].  In  MSSI,  users  can  designate  specific  data 
points as spatial landmarks. These landmarks attract other data 
points  (e.g.  documents)  based  on  the  high-dimensional  data 
instead  of  a  single  attribute  or  dimension.  For  text  data,  this 
enables users to focus more on the high-level semantics of the 
document  contents  rather  than  merely  on  specific  individual 
keywords. 

Systems exist which allow users to directly manipulate data 
points  and  interpret  this  feedback  via  a  dimensionality 
reduction algorithm to generate a new view that better reflects 
the  user’s  understanding  of  the  data  [15,  24,  34].  These 
methods inherently suffer from scalability issues. Users expect 
a  quick  interaction-feedback  loop  in  order  to  remain  in  their 
“cognitive zone” [29], but calculations on thousands, let alone 
millions, of data points take from minutes to hours to complete. 
It is more practical to break the problem into multiple levels of 
scale  and  perform  dimensionality  reduction  on  a  subset  of  a 
much larger data set, using information retrieval techniques to 
add additional information to the workspace. 

B.  Semantic Interaction 

Semantic interaction serves as means for analysts to work 
with data within a spatialization instead of altering algorithms 
or the raw data [20, 21].  The concept of direct manipulation 
for  visual analytics  is  an evolution of direct  manipulation  for 
information  visualization  [46].  This  is  particularly  important 
when the analyst is a non-expert in the layout algorithm(s). 

Semantic interaction can be viewed as a form of visual-to-
parametric  interaction  (V2PI)  [34].  This  type  of  interaction 
involves mapping user interactions to algorithmic parameters. 
For example, in [34], users are presented with a MDS layout 
and  are  able  to  impart  feedback  on  the  layout  (through 
highlighting  or  moving  data  points),  which  then  iterates  to 
generate  a  new  spatialization  that  better  matches  the  user’s 
understanding  of  the  relationships  within  the  data.  Similarly, 
two-
interaction  on  a 
DisFunction  [15]  converts  user 
the  high-
dimensional  spatialization 
feedback  on 
into 
dimensional  data,  generating  a  spatialization 
that  better 
matches the meaning imparted by the user. 

Typograph  [22]  uses  varying  levels  of  data  abstraction  to 
visualize  large  text  corpora.  Users  can  drill  down  to  see  the 
details  of  documents  at  different  levels  of  detail.  The  MSI 
technique implemented in StarSPIRE, in comparison, addresses 
the  scalability  challenge  by  constantly  updating  a  small 
working set of documents. Documents in StarSPIRE are either 
open or closed, whereas Typograph extracts topics, keywords, 
and document snippets. 

While current forms of semantic interactions have shown to 
be successful, they are limited in the number of data items they 
can  handle  simultaneously  (typically  less  than  1000).  Thus, 
semantic  interaction  alone  is  not  adequate  for  tackling  the 
challenge of big data.   

It  is  not  practical  to  display  thousands  or  millions  of 
documents using any of the above models. In addition to a poor 
interaction-feedback loop time, the user  would not be able to 
distinguish the points. Instead, many researchers have turned to 
topic modeling to give the user an overview of the topics and 
their distribution in the dataset. This can be a good method for 
establishing a starting point for analysis in addition to gaining 
an  overview  of  the  data.  However,  through  an  informal 
requirements  analysis  done  with  intelligence  analysts,  we 
found that they frequently have a specific topic to research or 
even a handful of “starting point” documents. 

Therefore,  we  found  it  to  be  more  practical  to  store  the 
initial  data  in  a  database  and  use  information  retrieval 
algorithms to fetch additional documents for the user. Similarly 
to how semantic interaction helps to steer the layout model, it 
can be used to steer information retrieval models by changing 
either the model itself, input parameters, or both. A multitude 
of information retrieval algorithms and models exist that could 
be  used  in  a  semantic  interaction  context.  Latent  Dirichlet 
Allocation  (LDA)  uses  probabilistic  topic  modeling  to  group 
similar documents [11]. Latent Semantic Indexing (LSI) uses a 
method similar to principle component analysis to reduce the 
high dimensional data (in this case, the term-document matrix), 
and then constructs a query into the lower-dimensional space 
using a set of terms [33]. Additional potential models include 
probabilistic  relevance  model,  Bayesian  logistic  regression, 
boolean models, and vector space models [25]. 

C.  Information Retrieval 

The  information  retrieval  aspect  of  this  work  is  closely 
related  to  content-based  recommendation  systems  [6,  43]. 
These systems track user interests to build a profile of a user 
and  their  interests  in  order  to  query  for  additional  relevant 
items.  The  data  involved  is  often  high-dimensional,  typically 
from facets of an item or associated metadata (e.g. item type, 
category,  production  information,  genre).  However,  these 
systems  typically  rely  on  pre-defined  characteristics,  whereas 
we  are  operating  on  unstructured  text  data  models  that  are 
capable of having entities added or removed dynamically. 

from 

differ 

systems,  which 

Additionally,  this  work  is  closely  related  to  query-by-
example 
context-based 
recommendation  systems  (e.g.  [47,  48])  in  that  query-by-
example  systems  use  a  set  of  user-defined  query  objects 
whereas recommendation systems aggregate recommendations 
over  all  (or  a  recent  selection  of)  user  selections.  Query  by 
example  systems  have  enjoyed  a  wide  implementation  across 
data  types  [38],  from  unstructured  text  documents  [8],  to 
multimedia [16, 30], to musical selections [28]. 

Systems  such  as  Adaptive  Information  Retrieval  [10]  use 
relevance  feedback  to  augment  future  retrieval  requests  to 
return results that are better tuned to the user(s). Other systems 
use  visualizations  to  construct  queries  (e.g.  geographical  and 
temporal  bounding  [2],  expressive  constructors  [19,  37], 

dynamic control panels [50], dynamic query interfaces [1, 27, 
47]). However, these mechanisms still often fail to place results 
in context of existing retrieved results, which is important for 
maintaining situational awareness [7, 52]. 

Attempts have been made to visualize information retrieval 
results  (e.g.  term  distribution  charts  [32],  self-organizing 
semantic maps [39], hierarchies [17], collages [18], word trees 
[53]),  but  these  techniques  have  not  been  widely  adopted. 
Information retrieval results are typically visualized as a ranked 
list  of  results  [40,  41].  Presenting  results  in  this  format  is 
suitable for targeted queries where the user may view a handful 
of  results  at  most  (e.g.  a  web  search  for  a  specific  culinary 
recipe). However, when the user is presented with hundreds of 
viable  documents  worth  reading  (e.g.  an  intelligence  analysis 
task)  that  relate  in  complicated,  intricate,  and  fuzzy  ways,  a 
linear list becomes less than ideal [14]. 

Work by Ruotsalo et al. has demonstrated the use of direct 
manipulation  to  influence  information  retrieval  algorithms 
[44]. User interactions within a radial topic spatializations were 
used to infer possible user intent to tune search results, working 
on  the  principle  that  searches  evolve  incrementally  [51], 
similarly  to  the  incremental  formalism  seen  in  sensemaking 
and  spatial  organization 
these 
interactions  did  not  replace  the  need  for  conducting  explicit 
searches, but that the users in the condition that allowed for the 
use of the spatial interface performed better than those who did 
not have this technique available. 

[45].  They 

found 

that 

Other  systems  provide  mechanisms  for  visualizing  search 
results  beyond  the  typical  ranked  list  (e.g.  term  distribution 
charts  [32],  self-organizing  semantic  maps  [39]),  but  these 
methods  do  not  provide  the  nuanced  spatial  interactions  that 
the Ruotsalo system does. While ranked lists are well-suited to 
narrow  and  specific  searches,  they  may  not  be  as  well  suited 
for  exploratory  data  analysis.  For  example,  conducting  a 
literature review requires exploring multiple facets of a topic. 
A  simple  ranked  list  of  results  does  not  yield  insight  into 
documents that are mixtures of different topics. 

III.  RESEARCH CHALLENGES 

Creating an analytical tool that facilitates exploratory data 
analysis  across  multiple  models  operating  at  vastly  different 
scales  of  data  comes  with  a  substantial  set  of  research 
challenges.  These  include  system  architecture  considerations, 
interaction and visualization design, and data scale concerns. 

A.  Performance 

Dealing  with  information  retrieval  requests  on  big  data 
inevitably  requires researchers  to address performance  issues, 
particularly in terms of performance and result accuracy. 

1)  Speed 
A  quick  interaction-feedback  loop  is  critical  for  keeping 
users  engaged  in  their  analysis.  As  such,  the  coordinated 
models  (information  retrieval,  document  relevance,  and 
visualization)  ought  to  be  optimized  to  maintain  real-time 
interaction. Several avenues could be chosen and/or combined 
to facilitate this. As this research is concerned primarily with 
interaction and visualization design, multiple external existing 

 
 
 
 
 
 
 

Figure 2. Visualization pipeline indicating web integration for big data analytics, controlled through a single spatialization. 

retrieval APIs were leveraged in this extension to StarSPIRE. 
Additionally,  web  scraping  and  entity  extraction  can  be done 
progressively to give the user an approximate set of document 
results while processing the remainder in the background. 

2)  Accuracy 
Precision  and  recall  are 

important  aspects  of  any 
information retrieval task. The quality of retrieved documents 
can  be  evaluated  objectively  as  well  as  subjectively.  The 
information  retrieval  model  is  primarily  responsible  for  the 
objective  quality  of  retrieved  results.  However,  these  results 
can  be  tuned  to  the  user’s  interests  to  provide  subjectively 
better results. Using the user’s interest model, the retrieval and 
data  relevance  models  can  be  adjusted  to  execute  nuanced 
queries and filter in documents that the user is more likely to 
find pertinent to their analysis. It is important to consider how 
these  two  notions  of  data  relevance  (user’s  opinion  and  web 
search  opinion)  compliment  or  contrast  each  other.  Systems 
can  gain  insight  into  the  user’s  perception  of  the  quality  of 
results through relevance feedback. The downside of exploiting 
existing  external  retrieval  engines  is  the  limited  API  for 
specification  of  user  interest.  Thus,  we  use  a  multi-level 
approach  that  follows  the  retrieval  with  a  more  detailed 
relevance analysis based on the user model. 

B.  Data Storage 

When  dealing  with  data  on  a  very  large  scale,  it  is 
important to consider how the data and retrieved results should 
be stored. Possible storage options include web hosting, cloud 
architectures,  databases,  or  local  memory.  These  obviously 
have varying limitations in terms of the amount of data that can 
be stored and associated retrieval speeds. For this extension to 
StarSPIRE,  the  source  dataset  is  left  on  the  web  (existing 
websites able to be accessed by a search engine) while a small 
working  set  of  documents  is  stored  in  local  memory.  This 
enables us to exploit the cached storage methods used by major 
search  engines.  Previous 
iterations  of  StarSPIRE  have 
connected to existing databases containing tens of thousands of 
documents  while  also  maintaining  a  working  subset  in 
memory.  Ultimately,  the  design  decision  for  data  storage 
should  appropriately  match  the  intended  dataset  in  order  to 
ensure optimal retrieval speeds. 

C.  Interactions 

Interactions  must  be  carefully  designed  to  best  match  the 
user’s  current  analytical  reasoning  process.  This  task  grows 
complicated  when  interpreting  interactions  across  multiple 
models. For example, how can the system differentiate between 

searching  on  the  existing  set  of  documents  displayed  in  the 
workspace and searching over the entire external dataset? How 
would  such  an  intention  be  detected?  This  is  a  difficult 
question  to  answer,  particularly  because  there  are  individual 
differences between users and what strategies they employ in a 
spatial  document  analysis  tool.  We  chose  to  search  all  data 
repositories  simultaneously  unless  explicitly  specified  by  the 
user. The user is given the option to toggle external databases 
on and off if they wish to restrict their interactions to what is 
currently on the display. 

Previous  work  with  StarSPIRE  has  tested  when  to  launch 
information  retrieval  requests.  We  first  required  users  to 
explicitly  request  additional  information  via  a  query  button, 
then altered the interface to execute such requests after every 
interaction. Continually interpreting and acting on interactions 
removes the need for users to step out of their synthesis process 
to explicitly forage for information. 

D.  Visual Encodings 

Extensive work has been done to tune the visual encodings 
in  StarSPIRE,  but  adding  large-scale  information  retrieval 
introduces new aspects of feedback that may be of interest to 
the user. Such facets include, but are not limited to, the novelty, 
recentness, and relevance of the retrieved results. Currently, all 
previously  mentioned  encodings  are  carried  over  into  this 
iteration  of  StarSPIRE.  It  is  important  to  consider  how  this 
visual  feedback  can  be 
integrated  with  existing  visual 
encodings in a manner that clearly conveys system feedback to 
users in an easy to interpret manner. 

E.  Foraging and Synthesis Integration 

In  order  to  keep  users  focused  on  their  sensemaking  task 
and avoid context switching, it is important to enable foraging 
and  synthesis  actions  in  the  same  workspace.  If  this  is 
successfully accomplished, synthesis actions (e.g. highlighting) 
can drive information foraging and foraging actions can drive 
information  synthesis  (e.g.  clustering  documents).  We  have 
chosen  a  spatial  layout  where  document  proximity  indicates 
similarity and documents are visually encoded to indicate data 
relevance. As new documents are added to the workspace, they 
are  mapped  to  the  current  visual  encodings  and  arranged 
according  to  their  similarity  to  existing  documents  in  the 
workspace. Thus, new documents are placed in context of the 
documents already in the workspace. 

Thought  must  be  given  to  how  new  documents  are 
presented to  the  user, particularly  to  how  users  are alerted to 

their  presence.  StarSPIRE  picks  random  initial  positions  for 
documents, which then move according to the weighted force-
directed layout to a stable state. We have found that this strikes 
a balance between blatantly interrupting the user and slipping 
in  unseen.  Other  mechanisms  for  keeping  foraging  and 
synthesis in context of one another should be investigated. 

Additionally,  foraging  actions  (e.g.  information  retrieval, 
entity  extraction,  relevancy  evaluation)  should  not  interfere 
with  the  user  conducting  synthesis  actions.  Ideally,  foraging 
actions  should  be  done  in  the  background  without  the  user 
having to wait for the system to process query requests.  

IV.  SYSTEM DESCRIPTION 

layout,  document 

StarSPIRE  [13]  is  a  visual  analytics  tool  prototype  that  
provides  users  with  a  spatial  workspace  to  view  and  arrange 
documents, facilitated by a modified force-directed layout. All 
interactions are interpreted and processed sequentially through 
a  series  of  models: 
relevancy,  and 
information  retrieval  [Figure  2].  Within  documents,  extracted 
terms are underlined and highlighted according to the feedback 
users  have  given  the  system  through  natural  actions  such  as 
highlighting text, writing notes, or moving documents [Figure 
3].  The  layout  algorithm  places  similar  documents  closer  to 
each  other  and  emphasizes  terms  with  large  weights  and 
entities 
[Figure  4]. 
Documents  are  arranged  using  a  node-link  diagram  and 
documents  can  be  shown  as  closed  nodes  or  as  open  text 
windows.  To  avoid  a  cluttered  workspace,  edges  linking 
documents  (based  on  entity  co-occurrence)  are  only  shown 
radiating  from  the  currently  selected  node  or  document.  We 
constructed  the  set  of  interactions  available  through  working 
with  and  observing  real-world  analysts  who  offered  usability 
feedback in informal and formal test settings. 

that  co-occur  between  documents 

StarSPIRE implements the Bing Search API and the IEEE 
Xplore digital library in order to expand its corpus to include 
innumerably many documents from the internet. The Bing API 
allows the client to send a query, and receive either JSON or 
XML  representation  of  the  Search  Engine  Results  Page 
(SERP).  IEEE  Xplore  is  programmatically  accessed,  and  its 
HTML parsed in accordance with its terms of use. The goal of 
access  to  these  sources  is  to  gather  relevant  text  from  web 
pages rich with images, colors and video. Future work includes 
the integration of multimedia content, but this work is limited 
to the text content of each page. 

Queries 

slated 

for 

execution  by 

the  StarSPIRE 
Webscraping Module (WM) can be created as a result of either 
implicit or explicit interactions by the user. Explicit interaction 
can  include  use  of  the  search  feature  to  type  a  query,  for 
example “Computer Science”. Alternatively, a query can result 
from  implicit  action,  such  as  a  user  “combining”  two 
documents  by  dragging  them  together.  For  example,  if  two 
documents on the subject of the murder of Nemtsov, a Russian 
political  leader,  were  combined,  the  query  sent  to  the  WM 
might  look  like  “Russia  Putin  Nemtsov  Murder  Opposition”. 
These two kinds of interaction are treated the same by the WM. 
In the case of Bing, part of the query indicates which source 
type should be searched for (i.e. full web, news, shopping).  

the  WM  performance  with  News 

If Bing results are requested by the user, the WM will then 
send  the  query  to  Bing  servers  and  receive  the  SERP  JSON. 
Currently, 
sources 
considerably outperforms the full web. Next, the SERP JSON 
is  parsed  to  store  information  about  each  news  article, 
including its title and URL. The HTML is extracted from the 
URL  and  parsed  for  content.  If  the  URL  returned  from  Bing 
leads  to  anything  other  than  a  standard  web  page  (i.e.  PDF, 
PowerPoint), it is ignored. Parsing of such documents remains 
as  future  work.  The  process  of  parsing  the  HTML  into  plain 
text  is  considerably  more  reliable  for  News  articles,  as  they 
tend to be more similarly and simply structured. 

If IEEE Xplore results are requested by the user, the WM 
will  subsequently  navigate  to  the  results  page  of  the  relevant 
query  on  Xplore.  This  approach  was  taken  as  a  proof  of 
concept  for  connecting  to  specific  digital  library  search 
services through its generic search UI. It will extract and parse 
HTML from the URLs of each of the links on the results page. 
As with Bing, weights on tokens are not implemented for this 
source.  Next,  relevant  information  is  extracted  from  the 
HTML.  This  process  is  more  accurate  with  the  IEEE  source 
than with the Bing source, as each page on Xplore has the same 
HTML  architecture,  while  Bing  has  the  potential  to  return 
documents from vastly different web sites with each query. As 
such, a tailor-made parsing system is used for Xplore HTML.  
When the text is successfully extracted from the HTML, the 
text is then parsed for entities. New entities are attached to the 
document  in  which  they  were  found,  and  then  the  rest  of 
known documents are searched for the new entities in order to 
relate them to one another. Whether the user requested Bing or 
IEEE,  the  information  stored  about  the  online  documents  is 
transferred into the main data structure for StarSPIRE, which 
the system subsequently processes before it is displayed to the 
user. These documents are analyzed for relevance to the user 
by StarSPIRE’s relevancy  model to create the working set of 
documents shown in the spatial workspace. This means that the 
documents  are 
first  gathered  using  Microsoft’s/IEEE’s 
relevancy  scheme,  and  then  filtered  to  a  subset  according  to 
what StarSPIRE believes the user is interested in through the 
relevancy  model.    Finally,  documents  are  positioned  on  the 
screen where they fit in with the existing spatial layout model, 
placing the search results in context. The document nodes take 
on visual encodings based on the current user interest model. 

The retrieval model differs considerably from the relevancy 
model. The information retrieval model is implemented by the 
external  search  service  (such  as  Bing  or  IEEE  Xplore)  and 
operates as a black box, using a set of unknown heuristics to 
rank the retrieved results. Conversely, the relevancy  model is 
directly controlled by StarSPIRE and is constantly tuned to the 
user’s  current  interests.  By  sorting  the  results  retrieved  from 
the black box by StarSPIRE’s internal relevancy model, we can 
attempt  to  balance  what  the  external  system  deems  to  be 
relevant and what the user is interested in. It is likely that these 
two  models  will  have  different  rankings  of  the  top  relevant 
results. This combination of models may also serve to relieve 
the  cognitive 
issue  previously  observed  with 
StarSPIRE  by  retrieving  results  that  an  outside  source  (e.g. 
web-based  search  engine)  believes  to  be  relevant  instead  of 
only honing in on the user’s narrow focus. In practice, we have 

tunneling 

observed that the relevancy model naturally limits the number 
of  documents  displayed  to  a  few  hundred  by  pruning  off 
documents that fall below the current relevance threshold. 

documents  were  selected  as  being  highly  relevant  and  worth 
citing in this paper. These documents were then rearranged by 
overarching topic to make re-finding by topic easier [Figure 4]. 

V.  USE CASES 

Using  StarSPIRE,  we  successfully  completed  the  two 
scenarios mentioned in the introduction: literature review and 
investigative journalism. 

A.  Literature Review 

Given that this paper is situated at the intersection of visual 
analytics, information visualization, and information retrieval, 
we  used  StarSPIRE  to  find  additional  related  work  regarding 
information  retrieval  from  the  information  visualization  and 
visual  analytics  communities.  This  is  quite  a  broad  task, 
making it a good example of exploratory data analysis. In order 
to  ensure  that  the  analysis  would  not  be  biased  by  recently 
published  papers  at  conferences  the  analyst  had  attended,  we 
restricted the dataset to paper abstracts from 1995 to 2009 from 
the  IEEE  Information  Visualization  (InfoVis)  and  Visual 
Analytics Science and Technology (VAST) conferences. This 
resulted in 454 unique paper abstracts, which  were processed 
with LingPipe [9] to extract entities. 

 

Figure 4. Final spatial layout with labeled clusters 

B.  Investigative Journalism 

The  investigative  reporting  scenario  linked  StarSPIRE  to 
the  Bing  web  search  engine.  While  StarSPIRE  is  capable  of 
searching the entire web for potential documents with Bing, the 
scope  of  this  task  was  limited  to  news  articles.  The  web 
documents  are  labeled  with  the  webpage  title.  As  such,  it  is 
typically possible to eliminate clearly irrelevant documents. 

For this task, we chose to select a current and controversial 
topic: police brutality and the ensuing protests. This topic was 
chosen because it has passionate and opinionated reporters on 
both  sides  and  has  received  an  overwhelming  amount  of 
national  coverage.  This  analysis  began  with  a  search  for 
“police  brutality,”  which  returned  articles  that  appear  to  be 
about recent incidents in the United States. The most relevant 
article is opened automatically by the system. 

 

Figure 3. Zoomed in document from the literature review 

scenario. 

The analysis began with a simple query for “retrieval.” This 
search resulted in finding multiple relevant paper abstracts that 
served  as  starting  points  for  further  investigation.  As  the 
spatialization evolved, notes were added to documents to make 
connections  based  on  common  themes.  This  helped  to  link 
paper  abstracts  that  used  slightly  different  terminology  to 
describe similar concepts, such as “iterative query refinement” 
and  “visual  query  language”  [Figure  3].  After  75  minutes  of 
analysis,  a  final  set  of 
thirteen  previously  unidentified 

 

Figure 5. Retrieval results from overlapping two documents. 
The  protests  in  Baltimore  seem  interesting,  particularly 
because they are the most recent focus in the news. A second 
document  with  a  seemingly  relevant  title  is  opened,  which 
results  in  other  documents  changing  in  size  to  reflect  the 
changes  in  document  relevance.  These  documents  are  then 
overlapped  to  search  for  information  that  matches  the  terms 
that co-occur between the documents. The result is a number of 
documents  about  Baltimore  protests,  many  of  which  contain 
the  name  Freddie  Gray.  We  highlight  the  name  in  order  to 

indicate  our  interest  to  the  system,  which  retrieves  additional 
documents. This results in many highly relevant documents to 
analyze which were previously unknown [Figure 5]. 

VI.  DISCUSSION 

The use cases presented here demonstrate how a semantic 
interaction  tool  can  be  used  to  complete  real-world  tasks  in 
real-time,  allowing  the  user  and  computer  to  jointly  curate, 
arrange,  and  analyze 
large  document  collections  while 
preserving the context of previously completed actions. 

A.  Use Case Performance 

Approximately  half  of  the  relevant  documents  retrieved 
from both use cases came from implicitly constructed queries. 
The remaining half came from explicit searching or query by 
example.  In  both  use  case  scenarios,  interesting  documents 
were obtained that did not match any of the initial search terms, 
showing  that  users  are  able  to  explore  previously  unknown 
regions of the information space. These results show extensive 
promise  for applying  semantic  interaction  to exploratory  data 
analysis tasks. However, more extensive studies are needed to 
quantitatively  and  qualitatively  evaluate  the  design  decisions 
made in the development of this extension. 

B.  Limitations 

There are several limitations to this system that should be 
noted. Currently, all documents are parsed for entities at once, 
which  can  delay  the  time  needed  to  import  documents.  The 
retrieval,  relevancy  ranking,  and  parsing  process  should  be 
improved to stream in results or prioritize the very top retrieved 
documents.  Additionally,  using  outside  algorithms 
for 
information retrieval limits the amount of model steering that 
can  be  done  at  the  information  retrieval  level.  Furthermore, 
web-based  information  retrieval  does  not  directly  translate  to 
protected  databases  containing  millions  of  documents. 
Additional algorithms will be needed to access such datasets. 

C.  Applications 

In this instance, we exploited the search engines for Bing 
and  IEEE  Digital  Library.  A  previous  version  of  StarSPIRE 
connected with an existing document  modeling and matching 
system connected to a large database of approximately 13,000 
documents.  In  all  of  these  instances,  StarSPIRE  must  be 
adapted  to  work  with  the  existing  APIs.  For  example,  the 
database search could place emphasis on different search terms 
by  repeating  the  terms  in  the  search  query.  StarSPIRE 
converted the existing entity weighting scheme to this format 
by linearly increasing query term frequency as the term weight 
increased  quadratically.  With  Bing  and  IEEE,  StarSPIRE 
creates  a  query  string  by  ordering  the  search  terms  by  their 
associated  weight.  These  modifications  demonstrate  how  we 
can take advantage of existing recommendation systems while 
still using the user’s interest model as input for these systems. 
By  using  such  existing  tools,  we  are  able  to  leverage  their 
strengths, such as filtering out duplicate articles so that the user 
can focus on broader aspects of the topic of interest. However, 
it  may  be  advisable  to  cast  an  even  wider  net  for  potential 
results  when  using  external  services,  since  the  retrieval 

algorithms  themselves  are  unknown.  By  collecting  a  larger 
sample of potentially relevant results, we can lower the risk of 
missing important documents. This work could be extended to 
cache  the  additional  potential  results  in  StarSPIRE’s  local 
database.  They  could  then  be  added  to  the  workspace  if 
deemed  relevant  during  future  interactions  without  requiring 
additional external queries. 
could 

additional 
recommender systems, both on the small and large scale. For 
example, a team of analysts could be linked such that they co-
create a model of their interests in the data. 

Future  work 

leveraging 

explore 

VII. CONCLUSION 

The  endeavor  to  create  a  system  in  which  foraged  results 
are  placed  in  context  of  an  information  synthesis  space  has 
raised many research challenges. We have addressed several of 
them in terms of design decisions explored and made, although 
many  remain  as  open  research  questions.  Through  this  work, 
we  have  enabled  users  to  perform  common  exploratory  data 
analysis  tasks  while  having  access  to  a  nearly  unlimited 
amount  of  data,  while  keeping  interactions  and  feedback  in 
context of the user’s current analytical state. We have been able 
to successfully complete these tasks, allowing StarSPIRE to be 
used  in  real-world  applications  while  maintaining  a  quick 
interaction-feedback loop. 

ACKNOWLEDGMENTS 

This  research  was  supported  in  part  by  NSF  grants  IIS-

1218346 and IIS-1447416. 

REFERENCES 

1.  Ahlberg,  C.  and  Wistrand,  E.,  IVEE:  An  information  visualization  and 
1995. 

Information  Visualization, 

in 

exploration 
Proceedings., (1995), IEEE, 66-73. 

environment. 

2.  Alper, N. and Stein, C., Geospatial metadata querying and visualization 
on  the  WWW  using  Java  TM  applets.  in  Information  Visualization'96, 
Proceedings IEEE Symposium on, (1996), IEEE, 77-84, 128. 

3.  Alsakran,  J.,  Chen,  Y.,  Zhao,  Y.,  Yang,  J.  and  Luo,  D.  STREAMIT: 
Dynamic  visualization  and  interactive  exploration  of  text  streams  IEEE 
Pacific Visualization Symposium, 2011. 

4.  Andrews,  C.,  Endert,  A.  and  North,  C.  Space  to  think:  large  high-
the  SIGCHI 

resolution  displays  for  sensemaking  Proceedings  of 
conference on human factors in computing systems, ACM, 2010, 55-64. 

5.  Andrews,  C.  and  North,  C.  Analyst’s  Workspace:  An  Embodied 
Sensemaking  Environment  For  Large,  High-Resolution  Displays  IEEE 
visual analytics science and technology, IEEE, 2012, 123-131. 

6.  Ansari, A., Essegaier, S. and Kohli, R. Internet recommendation systems. 

Journal of Marketing research, 37 (3). 363-375. 

7.  Bahrami,  A.,  Yuan,  J.,  Smart,  P.R.  and  Shadbolt,  N.R.,  Context  aware 
information  retrieval  for  enhanced  situation  awareness.  in  Military 
Communications Conference, 2007. MILCOM 2007. IEEE, (2007), IEEE, 
1-6. 

8.  Baldonado,  M.Q.W.  and  Winograd,  T.,  SenseMaker:  an  information-
exploration  interface  supporting  the  contextual  evolution  of  a  user's 
interests.  in  Proceedings  of  the  ACM  SIGCHI  Conference  on  Human 
factors in computing systems, (1997), ACM, 11-18. 

9.  Baldwin,  B.  and  Carpenter,  B.  LingPipe.  Available  from  World  Wide 

Web: http://alias-i. com/lingpipe. 

10.  Belew,  R.K.,  Adaptive  information  retrieval:  Using  a  connectionist 
representation  to  retrieve  and  learn  about  documents.  in  ACM  SIGIR 
Forum, (1989), ACM, 11-20. 

11.  Blei,  D.M.,  Ng,  A.Y.  and  Jordan,  M.I.  Latent  dirichlet  allocation.  J. 

Mach. Learn. Res., 3. 993-1022. 

34.  Hu,  X.,  Bradel,  L.,  Maiti,  D.,  House,  L.  and  North,  C.  Semantics  of 
Directly  Manipulating  Spatializations.  Visualization  and  Computer 
Graphics, IEEE Transactions on, 19 (12). 2052-2059. 

35.  i2. Analyst Notebook, 2007. 
36.  Jeong,  D.H.,  Ziemkiewicz,  C.,  Fisher,  B.,  Ribarsky,  W.  and  Chang, R., 
iPCA:  An  Interactive  System  for  PCA‚Äêbased  Visual  Analytics.  in 
Computer Graphics Forum, (2009), Wiley Online Library, 767-774. 

37.  Koch,  S.,  Bosch,  H.,  Giereth,  M.  and  Ertl,  T.,  Iterative  integration  of 
visual  insights  during  patent  search  and  analysis.  in  Visual  Analytics 
Science and Technology, 2009. VAST 2009. IEEE Symposium on, (2009), 
IEEE, 203-210. 

38.  Lew, M.S., Sebe, N., Djeraba, C. and Jain, R. Content-based multimedia 
information retrieval: State of the art and challenges. ACM Transactions 
on  Multimedia  Computing,  Communications,  and  Applications 
(TOMCCAP), 2 (1). 1-19. 

39.  Lin, X., Soergel, D. and Marchionini, G., A self-organizing semantic map 
for information retrieval. in Proceedings of the 14th annual international 
ACM  SIGIR  conference  on  Research  and  development  in  information 
retrieval, (1991), ACM, 262-269. 

40.  Maron,  M.E.  and  Kuhns,  J.L.  On  relevance,  probabilistic  indexing  and 

information retrieval. Journal of the ACM (JACM), 7 (3). 216-244. 

41.  Masui, T., LensBar-visualization for browsing and filtering large lists of 
data. in Information Visualization, 1998. Proceedings. IEEE Symposium 
on, (1998), IEEE, 113-120, 159. 

42.  Olsen, K.A., Korfhage, R.R., Sochats, K.M., Spring, M.B. and Williams, 
J.G.  Visualization  of  a  document  collection:  The  VIBE  system. 
Information Processing & Management, 29 (1). 69-81. 

43.  Pazzani, M.J. and Billsus, D. Content-based recommendation systems. in 

The adaptive web, Springer, 2007, 325-341. 

44.  Ruotsalo, T., Peltonen, J., Eugster, M., Głowacka, D., Konyushkova, K., 
Athukorala, K., Kosunen, I., Reijonen, A., Myllymäki, P. and Jacucci, G., 
Directing  exploratory  search  with 
in 
Proceedings of the 22nd ACM international conference on Conference on 
information & knowledge management, (2013), ACM, 1759-1764. 

intent  modeling. 

interactive 

45.  Shipman,  F.M.  and  Marshall,  C.C.  Formality  Considered  Harmful: 
Experiences,  Emerging  Themes,  and  Directions  on  the  Use  of  Formal 
Representations in Interactive Systems. Computer Supported Cooperative 
Work (CSCW), 8 (4). 333-352. 

46.  Shneiderman, B. Direct manipulation. B. Shneiderman. 
47.  Shneiderman,  B.  Dynamic  queries  for  visual  information  seeking. 

Software, IEEE, 11 (6). 70-77. 

48.  Shrinivasan,  Y.B.,  Gotz,  D.  and  Lu,  J.,  Connecting  the  dots  in  visual 
analysis. in Visual Analytics Science and Technology, 2009. VAST 2009. 
IEEE Symposium on, (2009), IEEE, 123-130. 

49.  Stasko, J., Görg, C. and Liu, Z. Jigsaw: supporting investigative analysis 
through  interactive  visualization.  Information  visualization,  7  (2).  118-
132. 

50.  Tanin,  E.,  Beigel,  R.  and  Shneiderman,  B.,  Design  and  evaluation  of 
incremental data structures and algorithms for dynamic query interfaces. 
in  Information  Visualization,  1997.  Proceedings.,  IEEE  Symposium  on, 
(1997), IEEE, 81-86. 

51.  Teevan,  J.,  Dumais,  S.T.  and  Horvitz,  E.,  Personalizing  search  via 
automated analysis of interests and activities. in Proceedings of the 28th 
annual 
international  ACM  SIGIR  conference  on  Research  and 
development in information retrieval, (2005), ACM, 449-456. 

52.  Tesone, D.R. and Goodall, J.R., Balancing interactive data management 
of massive data with situational awareness through smart aggregation. in 
Visual  Analytics  Science  and  Technology,  2007.  VAST  2007.  IEEE 
Symposium on, (2007), IEEE, 67-74. 

53.  Wattenberg,  M.  and  Viégas,  F.B.  The  word  tree,  an  interactive  visual 
concordance.  Visualization and  Computer  Graphics,  IEEE  Transactions 
on, 14 (6). 1221-1228. 

54.  Wise, J.A., Thomas, J.J., Pennock, K., Lantrip, D., Pottier, M., Schur, A. 
and Crow, V., Visualizing the non-visual: spatial analysis and interaction 
with  information  from  text  documents.  in  Information  Visualization, 
1995. Proceedings., (1995), IEEE, 51-58. 

55.  Wright,  W.,  Schroh,  D.,  Proulx,  P.,  Skaburskis,  A.  and  Cort,  B.,  The 
Sandbox  for  analysis:  concepts  and  methods.  in  Proceedings  of  the 
SIGCHI  conference  on  Human  Factors  in  computing  systems,  (2006), 
ACM, 801-810. 

26.  Fiaux, P., Sun, M., Bradel, L., North, C., Ramakrishnan, N. and Endert, 

A. Bixplorer: Visual analytics with biclusters. Computer (8). 90-94. 

27.  Fishkin,  K.  and  Stone,  M.C.,  Enhanced  dynamic  queries  via  movable 
filters.  in  Proceedings  of  the  SIGCHI  conference  on  Human  factors  in 
computing systems, (1995), ACM Press/Addison-Wesley Publishing Co., 
415-420. 

28.  Ghias,  A.,  Logan,  J.,  Chamberlin,  D.  and  Smith,  B.C.,  Query  by 
humming:  musical  information  retrieval  in  an  audio  database.  in 
Proceedings  of  the  third  ACM  international  conference  on  Multimedia, 
(1995), ACM, 231-236. 

29.  Green, T.M., Ribarsky, W. and Fisher, B. Building and applying a human 
cognition model for visual analytics. Information visualization, 8 (1). 1-
13. 

30.  Gupta,  A.  and  Jain,  R.  Visual  information  retrieval.  Communications of 

the ACM, 40 (5). 70-79. 

31.  Hearst, M. Search user interfaces. Cambridge University Press, 2009. 
32.  Hearst, M.A., TileBars: visualization of term distribution information in 
full text information access. in Proceedings of the SIGCHI conference on 
Human  factors  in  computing  systems,  (1995),  ACM  Press/Addison-
Wesley Publishing Co., 59-66. 

33.  Hofmann, T., Probabilistic latent semantic indexing. in Proceedings of the 
22nd  annual  international  ACM  SIGIR  conference  on  Research  and 
development in information retrieval, (1999), ACM, 50-57. 

 

12.  Bradel, L., Endert, A., Koch, K., Andrews, C. and North, C. Large high 
resolution  displays  for  co-located  collaborative  sensemaking:  Display 
usage  and  territoriality.  International  Journal  of  Human-Computer 
Studies, 71 (11). 1078-1088. 

13.  Bradel,  L.,  North,  C.,  House,  L.  and  Leman,  S.,  Multi-model  semantic 
interaction  for  text  analytics.  in  IEEE  Conference  on  Visual  Analytics 
Science and Technology (VAST), 2014, (2014), IEEE, 163-172. 

14.  Bradel,  L.,  Self,  J.Z.,  Endert,  A.,  Hossain,  M.S.,  North,  C.  and 
Ramakrishnan,  N.,  How  analysts  cognitively  ""connect  the  dots"".  in 
Intelligence  and  Security  Informatics  (ISI),  2013  IEEE  International 
Conference on, (2013), 24-26. 

15.  Brown, E.T., Liu, J., Brodley, C.E. and Chang, R., Dis-function: Learning 
in  Visual  Analytics  Science  and 

distance  functions 
Technology (VAST), 2012 IEEE Conference on, (2012), IEEE, 83-92. 

interactively. 

16.  Burtner,  R.,  Bohn,  S.  and  Payne,  D.,  Interactive  visual  comparison  of 
multimedia  data  through  type-specific  views.  in  IS&T/SPIE  Electronic 
Imaging, (2013), International Society for Optics and Photonics, 86540M-
86540M-86515. 

17.  Clarkson,  E.,  Desai,  K.  and  Foley,  J.D.  Resultmaps:  Visualization  for 
IEEE 

interfaces.  Visualization  and  Computer  Graphics, 

search 
Transactions on, 15 (6). 1057-1064. 

18.  Derthick,  M.,  Christel,  M.G.,  Hauptmann,  A.G.  and  Wactlar,  H.D., 
Constant  density  displays  using  diversity  sampling.  in  Information 
Visualization, 2003. INFOVIS 2003. IEEE Symposium on, (2003), IEEE, 
137-144. 

19.  Derthick,  M.,  Roth,  S.F.  and  Kolojejchick,  J.,  Coordinating  declarative 
queries  with  a  direct  manipulation  data  exploration  environment.  in 
Information  Visualization,  1997.  Proceedings.,  IEEE  Symposium  on, 
(1997), IEEE, 65-72. 

20.  Endert, A. Semantic Interaction for Visual Analytics: Inferring Analytical 
Reasoning  for  Model  Steering,  Virginia  Polytechnic  Institute  and  State 
University, 2012. 

21.  Endert,  A.,  Bradel,  L.  and  North,  C.  Beyond  control  panels:  Direct 
manipulation for visual analytics. Computer Graphics and Applications, 
IEEE, 33 (4). 6-13. 

22.  Endert, A., Burtner, R., Cramer, N., Perko, R., Hampton, S. and Cook, K., 
Typograph: Multiscale spatial exploration of text documents. in Big Data, 
2013 IEEE International Conference on, (2013), IEEE, 17-24. 

23.  Endert, A., Fox, S., Maiti, D., Leman, S. and North, C. The semantics of 
clustering:  analysis  of  user-generated  spatializations  of  text  documents 
Proceedings  of  the  International  Working  Conference  on  Advanced 
Visual Interfaces, ACM, Capri Island, Italy, 2012, 555-562. 

24.  Endert,  A.,  Han,  C.,  Maiti,  D.,  House,  L.,  Leman,  S.  and  North,  C., 
Observation-level interaction with statistical models for visual analytics. 
in  Visual  Analytics  Science  and  Technology  (VAST),  2011  IEEE 
Conference on, (2011), IEEE, 121-130. 

25.  Faloutsos,  C.  and  Oard,  D.W.  A  survey  of  information  retrieval  and 

filtering methods. 

 

","{""0"":{""0"":""relevant"",""1"":""better"",""2"":""previously"",""3"":""parsed"",""4"":""present*"",""5"":""ranked"",""6"":""list"",""7"":""extracted*""},""1"":{""0"":""ieee"",""1"":""starspire"",""2"":""endert*"",""3"":""xplore*"",""4"":""bradel*"",""5"":""sigchi"",""6"":""sigir"",""7"":""shneiderman""},""2"":{""0"":""conference*"",""1"":""proceedings*"",""2"":""news"",""3"":""symposium"",""4"":""paper"",""5"":""searches*"",""6"":""protests*"",""7"":""press*""},""3"":{""0"":""users"",""1"":""systems"",""2"":""models"",""3"":""points*"",""4"":""levels*"",""5"":""landmarks*"",""6"":""factors*"",""7"":""parameters""},""4"":{""0"":""visual*"",""1"":""visualization*"",""2"":""semantic"",""3"":""computer*"",""4"":""human"",""5"":""technology"",""6"":""interactive*"",""7"":""dimensional""},""pos"":{""0"":1,""1"":2,""2"":3,""3"":4,""4"":5,""5"":6,""6"":7,""7"":8}}",2015,{},False,False,conferencePaper,False,5LF32UEH,[],self.user,"{""C"":{""0"":5.2829467587,""1"":21.9364589709,""10"":4.4029175451,""11"":20.4399745578,""12"":4.2959639656,""13"":18.9528902553,""14"":7.8957323084,""15"":4.540647381,""16"":9.4578063384,""17"":5.8268656534,""18"":4.0710061323,""19"":9.1513177532,""2"":9.3241201309,""20"":12.266249797,""21"":4.9882406927,""22"":9.7449593415,""23"":9.4522789341,""24"":5.6446135149,""25"":4.1117874245,""26"":4.3734066511,""27"":12.1983636385,""28"":4.4840331294,""29"":8.9714279947,""3"":7.7388982224,""30"":4.932380517,""31"":4.1302032024,""32"":7.9584340477,""33"":8.6303777299,""34"":5.2906712996,""35"":5.1843084805,""36"":4.2816235706,""37"":8.9679586953,""38"":7.0275833976,""39"":8.0080080796,""4"":6.7513075998,""40"":6.9051210333,""41"":7.0178546143,""42"":8.3873237491,""43"":4.1572345754,""44"":4.3137285251,""45"":4.490710474,""46"":5.6035286555,""47"":5.6260475485,""48"":5.1720835983,""49"":5.9184105094,""5"":5.8459645511,""50"":4.6739629296,""51"":5.9340646026,""52"":5.9314089509,""53"":6.2696800854,""54"":4.9688669147,""55"":4.4533106894,""56"":4.043343399,""57"":6.4661212972,""58"":4.4750399689,""59"":4.4704075783,""6"":8.1442125864,""60"":4.513001334,""61"":4.5273501828,""62"":4.1875922096,""63"":4.2195272037,""64"":4.1060627129,""65"":4.1803483332,""66"":4.4749546825,""67"":4.1304471921,""68"":4.456013966,""7"":8.1937954344,""8"":5.1167862662,""9"":4.8215755626},""Unnamed: 0"":{""0"":0,""1"":1,""10"":10,""11"":11,""12"":12,""13"":14,""14"":15,""15"":17,""16"":18,""17"":19,""18"":20,""19"":21,""2"":2,""20"":22,""21"":23,""22"":24,""23"":25,""24"":26,""25"":27,""26"":28,""27"":29,""28"":30,""29"":31,""3"":3,""30"":32,""31"":33,""32"":34,""33"":35,""34"":36,""35"":37,""36"":38,""37"":39,""38"":40,""39"":41,""4"":4,""40"":42,""41"":43,""42"":44,""43"":45,""44"":46,""45"":47,""46"":48,""47"":49,""48"":50,""49"":51,""5"":5,""50"":52,""51"":53,""52"":54,""53"":55,""54"":56,""55"":57,""56"":58,""57"":59,""58"":60,""59"":61,""6"":6,""60"":62,""61"":63,""62"":64,""63"":65,""64"":66,""65"":67,""66"":68,""67"":69,""68"":70,""7"":7,""8"":8,""9"":9},""count"":{""0"":134,""1"":100,""10"":36,""11"":36,""12"":34,""13"":34,""14"":32,""15"":26,""16"":24,""17"":24,""18"":22,""19"":20,""2"":84,""20"":20,""21"":18,""22"":18,""23"":18,""24"":16,""25"":16,""26"":16,""27"":16,""28"":16,""29"":16,""3"":82,""30"":14,""31"":14,""32"":14,""33"":14,""34"":12,""35"":12,""36"":12,""37"":12,""38"":12,""39"":10,""4"":62,""40"":10,""41"":10,""42"":10,""43"":10,""44"":10,""45"":10,""46"":10,""47"":10,""48"":10,""49"":8,""5"":60,""50"":8,""51"":8,""52"":8,""53"":8,""54"":8,""55"":8,""56"":8,""57"":8,""58"":6,""59"":6,""6"":60,""60"":6,""61"":6,""62"":6,""63"":6,""64"":6,""65"":6,""66"":6,""67"":6,""68"":6,""7"":52,""8"":44,""9"":42},""exemplar"":{""0"":null,""1"":null,""10"":null,""11"":""*"",""12"":null,""13"":""*"",""14"":null,""15"":null,""16"":null,""17"":null,""18"":""*"",""19"":null,""2"":null,""20"":null,""21"":null,""22"":null,""23"":""*"",""24"":null,""25"":""*"",""26"":""*"",""27"":null,""28"":null,""29"":""*"",""3"":""*"",""30"":""*"",""31"":null,""32"":""*"",""33"":null,""34"":null,""35"":null,""36"":null,""37"":null,""38"":null,""39"":null,""4"":null,""40"":null,""41"":null,""42"":""*"",""43"":null,""44"":null,""45"":null,""46"":null,""47"":""*"",""48"":""*"",""49"":""*"",""5"":null,""50"":null,""51"":null,""52"":null,""53"":null,""54"":""*"",""55"":null,""56"":null,""57"":null,""58"":""*"",""59"":null,""6"":""*"",""60"":null,""61"":null,""62"":null,""63"":""*"",""64"":""*"",""65"":""*"",""66"":""*"",""67"":null,""68"":""*"",""7"":null,""8"":null,""9"":null},""pos"":{""0"":1,""1"":1,""10"":3,""11"":1,""12"":3,""13"":2,""14"":4,""15"":5,""16"":6,""17"":3,""18"":4,""19"":7,""2"":2,""20"":8,""21"":9,""22"":4,""23"":3,""24"":5,""25"":4,""26"":4,""27"":10,""28"":6,""29"":7,""3"":1,""30"":5,""31"":5,""32"":5,""33"":8,""34"":2,""35"":11,""36"":3,""37"":12,""38"":9,""39"":13,""4"":2,""40"":10,""41"":14,""42"":6,""43"":15,""44"":4,""45"":11,""46"":6,""47"":7,""48"":12,""49"":5,""5"":1,""50"":8,""51"":6,""52"":7,""53"":13,""54"":8,""55"":7,""56"":9,""57"":8,""58"":6,""59"":16,""6"":2,""60"":14,""61"":9,""62"":17,""63"":9,""64"":10,""65"":7,""66"":11,""67"":15,""68"":8,""7"":2,""8"":3,""9"":1},""sigma_nor"":{""0"":1.427511678,""1"":3.0700888745,""10"":1.611065825,""11"":3.9844576332,""12"":1.6076589541,""13"":3.8270831765,""14"":2.1792350646,""15"":1.7073840281,""16"":2.5772192906,""17"":1.9486754275,""18"":1.6622012233,""19"":2.6200313664,""2"":1.9415461364,""20"":3.1957717027,""21"":1.8770950592,""22"":2.7887641476,""23"":2.7326692427,""24"":2.0366870137,""25"":1.7312081251,""26"":1.7833465582,""27"":3.3427923288,""28"":1.8053934517,""29"":2.6996921623,""3"":1.7867268729,""30"":1.9253848512,""31"":1.7586214672,""32"":2.5544663745,""33"":2.6941556929,""34"":2.0361216038,""35"":2.0129719049,""36"":1.8165039656,""37"":2.8364773746,""38"":2.4141577678,""39"":2.69590982,""4"":1.7709496523,""40"":2.4435635886,""41"":2.469357612,""42"":2.7826991971,""43"":1.8148330269,""44"":1.8506396479,""45"":1.8911340285,""46"":2.1457525548,""47"":2.1509049934,""48"":2.0470357055,""49"":2.2631745304,""5"":1.6735007065,""50"":1.9625258318,""51"":2.2669564356,""52"":2.2663148511,""53"":2.3480384834,""54"":2.0337723036,""55"":1.9092179948,""56"":1.810173138,""57"":2.3954971274,""58"":1.9315756084,""59"":1.9303894565,""6"":1.9479440353,""60"":1.9412958478,""61"":1.9449699582,""62"":1.8579728536,""63"":1.8661500039,""64"":1.8370967278,""65"":1.8561180148,""66"":1.9315537703,""67"":1.8433405227,""68"":1.9267038841,""7"":2.0124391304,""8"":1.6640801648,""9"":1.6351198098},""topic"":{""0"":-1,""1"":1,""10"":3,""11"":2,""12"":-1,""13"":2,""14"":-1,""15"":-1,""16"":-1,""17"":2,""18"":4,""19"":-1,""2"":-1,""20"":-1,""21"":-1,""22"":2,""23"":1,""24"":4,""25"":1,""26"":3,""27"":-1,""28"":4,""29"":4,""3"":4,""30"":1,""31"":2,""32"":3,""33"":4,""34"":0,""35"":-1,""36"":0,""37"":-1,""38"":4,""39"":-1,""4"":1,""40"":4,""41"":-1,""42"":3,""43"":-1,""44"":0,""45"":4,""46"":1,""47"":3,""48"":4,""49"":0,""5"":3,""50"":3,""51"":0,""52"":0,""53"":4,""54"":0,""55"":1,""56"":3,""57"":1,""58"":2,""59"":-1,""6"":4,""60"":4,""61"":0,""62"":-1,""63"":1,""64"":0,""65"":2,""66"":0,""67"":4,""68"":2,""7"":3,""8"":4,""9"":0},""vector"":{""0"":""[ 1.6581979   0.17374866 -6.167487    2.5144126   4.5655003   0.83883727\n  1.2661163   3.3621807  -2.37891    -2.2630277 ]"",""1"":""[ 1.5575029   0.41917834 -6.3227053   1.541034    3.283877    1.312957\n  0.09812711  2.9021146  -2.88573    -2.018072  ]"",""10"":""[ 1.6020993  -0.13151969 -6.1212335   3.1370099   4.8125014   1.0413672\n  1.4174685   3.4057786  -2.2657087  -2.5429292 ]"",""11"":""[ 1.2130046  0.8226246 -5.711724   1.8294218  4.0899324  0.803333\n  1.0340164  3.7164505 -2.913991  -1.8957864]"",""12"":""[ 1.5380253   0.48913053 -6.1353183   1.952223    3.9042034   1.5096416\n  1.2084682   3.7838447  -3.1523528  -1.9359316 ]"",""13"":""[ 1.2397925  0.5844099 -5.615889   1.9130888  4.322219   0.7733355\n  1.0447532  3.933621  -3.060099  -2.0160642]"",""14"":""[ 1.5471289  -0.20304222 -6.025822    2.4157894   4.5652328   1.0757817\n  0.8531868   3.8729386  -3.1779761  -2.4126818 ]"",""15"":""[ 1.4934167   0.34912613 -6.4017234   2.478223    3.9273486   1.441276\n  1.2974708   3.0765522  -2.3230019  -2.0860016 ]"",""16"":""[ 1.5475558  -0.77854145 -6.180152    3.0221324   4.66086     1.5789379\n  1.1360873   3.5079396  -2.6492288  -2.5151024 ]"",""17"":""[ 1.0282154   0.40023023 -5.565271    2.0332658   4.2254896   1.1103972\n  1.2778889   3.8656719  -2.8467417  -1.8484987 ]"",""18"":""[ 1.118929    0.11127976 -5.5542      2.4586945   4.1106153   1.0794647\n  1.2100025   2.8099833  -1.5522492  -1.9374129 ]"",""19"":""[ 1.3405021  -0.40033367 -6.075868    2.5420742   3.9601305   2.041002\n  1.0312186   3.5946493  -2.8512278  -1.9352075 ]"",""2"":""[ 1.5781604  -0.01516782 -6.1399083   2.3940878   4.656387    0.98960346\n  1.2440279   3.9305573  -3.091718   -2.3679013 ]"",""20"":""[ 0.8484683  -0.08175191 -5.473718    2.5061915   4.178486    1.4354851\n  1.1746073   3.3894384  -2.247459   -1.8594743 ]"",""21"":""[ 0.9483771   0.3182613  -5.968059    3.0421417   4.0226      1.0730929\n  0.51490396  2.6713946  -1.936757   -2.0613334 ]"",""22"":""[ 1.4022468  0.8432762 -5.909773   1.7766494  3.8997273  0.9245173\n  0.8827552  3.5652914 -2.9580932 -1.9530606]"",""23"":""[ 1.3294446   0.6895874  -6.589781    2.0355859   3.2449002   1.0913962\n -0.13795881  2.5719533  -2.820553   -2.230415  ]"",""24"":""[ 0.9047742 -0.0373429 -5.500595   2.633263   4.1379848  1.328692\n  1.1742445  3.0389988 -1.8099736 -1.8885095]"",""25"":""[ 1.431078    0.7840676  -6.341737    1.6361414   3.1865203   1.0118905\n -0.14267386  2.7296846  -2.881772   -2.1386585 ]"",""26"":""[ 1.7340448  -0.48378488 -6.271832    3.0358808   4.8121758   1.3823118\n  1.3890119   3.7505417  -2.8185084  -2.617349  ]"",""27"":""[ 1.5746577  -0.03257647 -6.365751    1.8476975   3.5196023   1.6529408\n  0.5512602   3.0044985  -2.6535833  -1.9833381 ]"",""28"":""[ 1.1139338   0.27123126 -5.571903    2.7078507   4.311388    1.030737\n  1.2944422   3.116959   -1.8457816  -2.0453217 ]"",""29"":""[ 0.98139    0.1958034 -5.8688207  2.753018   3.8031375  1.272237\n  0.814439   2.477299  -1.6045401 -2.0006108]"",""3"":""[ 1.0985093  -0.10044271 -6.0146213   2.9254947   3.8490524   1.6005219\n  0.94396955  2.5180478  -1.5522511  -1.9011271 ]"",""30"":""[ 1.293161    0.736549   -6.589566    1.9632931   3.143263    1.0715581\n -0.17650105  2.5030773  -2.7828426  -2.1798868 ]"",""31"":""[ 1.34882     0.80082005 -5.9931765   1.9766855   4.032683    0.88783437\n  1.0768362   3.5086691  -2.7839878  -1.9532373 ]"",""32"":""[ 1.6253115 -0.2859879 -6.0883985  3.1517797  4.946339   1.1533823\n  1.5431066  3.7003508 -2.5557706 -2.604929 ]"",""33"":""[ 1.1633521  -0.22741818 -6.2022076   2.8545299   3.8034377   1.6025397\n  0.7803106   2.4960368  -1.7447369  -2.1151555 ]"",""34"":""[ 1.4157033 -0.9295125 -5.930032   2.3260274  3.9538305  2.6172113\n  1.225207   3.900949  -3.1308148 -1.8884367]"",""35"":""[ 1.7275445   0.33219627 -6.4138837   2.238982    4.088847    1.4423195\n  1.3792605   3.5660572  -2.8793306  -2.158686  ]"",""36"":""[ 1.742146  -0.7916643 -6.2036057  2.170118   4.131436   2.4937656\n  1.4004428  4.1506863 -3.5125904 -2.1245587]"",""37"":""[ 1.752616    0.23761685 -6.2975388   2.0962303   4.071314    1.5625697\n  1.2880306   3.7868445  -3.158193   -2.165859  ]"",""38"":""[ 1.1723807   0.18624774 -5.667159    2.6205409   4.229383    0.86684597\n  0.98929197  2.7640507  -1.6157264  -2.0118616 ]"",""39"":""[ 1.7384641  0.5859689 -6.30983    2.2628608  4.1934123  1.048675\n  1.2258887  3.4635866 -2.7543235 -2.2186308]"",""4"":""[ 1.2607332   0.48669726 -6.519136    2.0780756   3.16704     1.1870257\n -0.08342449  2.4684541  -2.62403    -2.1539555 ]"",""40"":""[ 1.4525276   0.05192357 -6.1875935   3.190323    4.1623716   1.4557871\n  1.024395    2.8166068  -1.8000519  -2.0917072 ]"",""41"":""[ 1.382118   -0.13391733 -6.456858    2.6368566   3.7744935   1.442163\n  0.6863901   2.5562506  -2.048481   -2.3044915 ]"",""42"":""[ 1.6972361 -0.5965957 -6.380303   3.041011   4.678895   1.343253\n  1.206904   3.3826497 -2.5215147 -2.5929577]"",""43"":""[ 1.3606305  -0.17191544 -5.7418075   2.1115878   4.423147    1.3932569\n  1.2273222   4.2139597  -3.3139138  -2.0905077 ]"",""44"":""[ 1.2923186 -0.7841943 -6.245893   1.9898506  3.7453067  2.134066\n  0.6067681  3.7508595 -3.4172761 -2.0099256]"",""45"":""[ 0.93573594  0.40343678 -5.8831205   3.0186372   4.0238924   1.1144321\n  0.8793845   2.6597903  -1.7108026  -2.0492322 ]"",""46"":""[ 1.457155    0.86643666 -6.130914    1.6040511   3.4450314   0.93905836\n  0.23964396  2.985397   -2.8139012  -2.0285234 ]"",""47"":""[ 1.748142  -0.2810508 -6.269104   3.0645924  4.9156156  1.0522602\n  1.3957434  3.6113265 -2.6182234 -2.6977518]"",""48"":""[ 1.2011051   0.09333205 -5.946088    2.590704    3.8566682   1.3806984\n  1.06373     2.6084862  -1.6262391  -1.9745214 ]"",""49"":""[ 1.5106614 -0.8021346 -6.152686   2.0815141  3.971674   2.6078851\n  1.1478215  4.0297346 -3.5041764 -1.9908756]"",""5"":""[ 1.7686461   0.12632646 -5.9978786   2.8533459   4.9091587   0.9516951\n  1.5559794   3.7825167  -2.6466954  -2.555308  ]"",""50"":""[ 1.7204709  -0.24915755 -6.4085445   2.7656074   4.589064    1.1049396\n  1.2384984   3.3801773  -2.535142   -2.5179155 ]"",""51"":""[ 1.2663434 -0.7009483 -6.194993   2.0652287  3.9822304  2.0026562\n  0.9624861  4.172151  -3.6573484 -2.0679865]"",""52"":""[ 1.5138929 -0.4005489 -6.2484083  2.0511668  4.039352   2.013341\n  1.2262564  4.1416345 -3.5726945 -2.0845509]"",""53"":""[ 1.2579012  -0.04123609 -5.749842    2.89441     4.6320844   0.7643941\n  0.9972633   2.9994292  -1.8172117  -2.16095   ]"",""54"":""[ 1.32391    -0.8955037  -6.1477275   2.0242727   3.924198    2.274138\n  0.86197376  4.0631385  -3.6007452  -2.026964  ]"",""55"":""[ 1.4356841   0.87186724 -6.0586343   1.5773491   3.5432231   0.89154625\n  0.35373947  3.131617   -2.9028833  -1.9926108 ]"",""56"":""[ 1.4785749  0.15952   -5.8516283  2.5349262  4.7584176  0.7421495\n  1.2634616  3.7325795 -2.6640406 -2.3222718]"",""57"":""[ 1.4483495   0.87778664 -6.19986     1.8481674   3.4764574   0.9359969\n  0.26350182  2.7945912  -2.5778093  -2.113205  ]"",""58"":""[ 1.3874029  -0.09846891 -5.8231993   2.25432     4.5605664   1.0671829\n  1.0570419   4.060772   -3.202195   -2.2315261 ]"",""59"":""[ 1.2661916  -0.36749232 -5.944819    2.6643271   4.1003175   1.856666\n  1.1881288   3.425746   -2.4830287  -1.9926177 ]"",""6"":""[ 1.2602109  0.3029411 -6.1626344  2.9207425  3.945012   1.2985872\n  1.065965   2.562394  -1.6052212 -2.0423858]"",""60"":""[ 1.2491512  -0.12694305 -5.8144846   2.8499017   4.377802    1.0055966\n  0.96043885  2.786818   -1.6497731  -2.0598798 ]"",""61"":""[ 1.6281677 -0.6569338 -6.239319   2.1048863  4.0174766  2.3067036\n  1.3333778  4.143944  -3.5454133 -2.067244 ]"",""62"":""[ 1.536411    0.02370049 -6.450059    1.8358313   3.4572902   1.5521919\n  0.24769975  3.017041   -2.9401324  -2.0959864 ]"",""63"":""[ 1.3838981   0.58997303 -6.4883833   1.8075615   3.165048    1.1312828\n -0.09446537  2.7090557  -2.8839657  -2.156958  ]"",""64"":""[ 1.3950055 -0.8372258 -5.8777046  2.0726702  4.094258   2.265248\n  1.1457016  4.2745204 -3.5557137 -1.976014 ]"",""65"":""[ 1.2090101   0.20334816 -5.627979    2.0431437   4.401175    1.0539488\n  1.1724204   4.0728235  -3.132696   -2.020437  ]"",""66"":""[ 1.3748745 -0.9586909 -5.8841887  2.1821032  3.9596808  2.4809566\n  1.2019738  4.138436  -3.3763483 -1.8791225]"",""67"":""[ 1.1706115  -0.01037541 -5.657349    2.9667737   4.6674504   0.94688606\n  1.2006633   3.3013833  -2.0695927  -2.212035  ]"",""68"":""[ 1.0885371   0.65762275 -5.6370873   1.9445175   4.135963    0.93017346\n  1.1564522   3.740577   -2.8247912  -1.8515327 ]"",""7"":""[ 1.4371439  -0.15526919 -5.778498    3.042126    4.935406    0.9521829\n  1.4720908   3.5730886  -2.3280668  -2.4697013 ]"",""8"":""[ 1.1793461  -0.24159278 -6.1039243   2.9840996   3.8856914   1.6502292\n  0.6496075   2.6697302  -1.8509012  -1.9111503 ]"",""9"":""[ 1.3991964 -0.6572142 -6.0312624  2.196179   3.8488877  2.5282168\n  1.2232741  3.967028  -3.2944791 -1.8248858]""},""vocab_index"":{""0"":2,""1"":5,""10"":27,""11"":28,""12"":29,""13"":32,""14"":36,""15"":42,""16"":46,""17"":47,""18"":53,""19"":63,""2"":6,""20"":64,""21"":65,""22"":71,""23"":72,""24"":74,""25"":82,""26"":84,""27"":87,""28"":88,""29"":89,""3"":7,""30"":90,""31"":94,""32"":95,""33"":97,""34"":116,""35"":125,""36"":126,""37"":127,""38"":128,""39"":135,""4"":10,""40"":146,""41"":153,""42"":154,""43"":162,""44"":165,""45"":166,""46"":167,""47"":168,""48"":169,""49"":187,""5"":11,""50"":193,""51"":203,""52"":204,""53"":207,""54"":213,""55"":221,""56"":222,""57"":223,""58"":305,""59"":310,""6"":13,""60"":312,""61"":317,""62"":319,""63"":320,""64"":321,""65"":326,""66"":327,""67"":335,""68"":336,""7"":18,""8"":20,""9"":21},""word"":{""0"":""data"",""1"":""ieee"",""10"":""models"",""11"":""conference"",""12"":""topic"",""13"":""proceedings"",""14"":""bing"",""15"":""synthesis"",""16"":""north"",""17"":""news"",""18"":""computer"",""19"":""relevancy"",""2"":""results"",""20"":""international"",""21"":""foraging"",""22"":""symposium"",""23"":""endert"",""24"":""human"",""25"":""xplore"",""26"":""points"",""27"":""html"",""28"":""technology"",""29"":""interactive"",""3"":""visual"",""30"":""bradel"",""31"":""paper"",""32"":""levels"",""33"":""dimensional"",""34"":""better"",""35"":""source"",""36"":""previously"",""37"":""page"",""38"":""computing"",""39"":""researcher"",""4"":""starspire"",""40"":""metaphor"",""41"":""parametric"",""42"":""landmarks"",""43"":""requests"",""44"":""parsed"",""45"":""exploration"",""46"":""sigchi"",""47"":""factors"",""48"":""graphics"",""49"":""present"",""5"":""users"",""50"":""parameters"",""51"":""ranked"",""52"":""list"",""53"":""storage"",""54"":""extracted"",""55"":""sigir"",""56"":""transactions"",""57"":""shneiderman"",""58"":""searches"",""59"":""quality"",""6"":""visualization"",""60"":""memory"",""61"":""explicitly"",""62"":""json"",""63"":""serp"",""64"":""requested"",""65"":""protests"",""66"":""needed"",""67"":""management"",""68"":""press"",""7"":""systems"",""8"":""semantic"",""9"":""relevant""},""word*"":{""0"":""data"",""1"":""ieee"",""10"":""models"",""11"":""conference*"",""12"":""topic"",""13"":""proceedings*"",""14"":""bing"",""15"":""synthesis"",""16"":""north"",""17"":""news"",""18"":""computer*"",""19"":""relevancy"",""2"":""results"",""20"":""international"",""21"":""foraging"",""22"":""symposium"",""23"":""endert*"",""24"":""human"",""25"":""xplore*"",""26"":""points*"",""27"":""html"",""28"":""technology"",""29"":""interactive*"",""3"":""visual*"",""30"":""bradel*"",""31"":""paper"",""32"":""levels*"",""33"":""dimensional"",""34"":""better"",""35"":""source"",""36"":""previously"",""37"":""page"",""38"":""computing"",""39"":""researcher"",""4"":""starspire"",""40"":""metaphor"",""41"":""parametric"",""42"":""landmarks*"",""43"":""requests"",""44"":""parsed"",""45"":""exploration"",""46"":""sigchi"",""47"":""factors*"",""48"":""graphics*"",""49"":""present*"",""5"":""users"",""50"":""parameters"",""51"":""ranked"",""52"":""list"",""53"":""storage"",""54"":""extracted*"",""55"":""sigir"",""56"":""transactions"",""57"":""shneiderman"",""58"":""searches*"",""59"":""quality"",""6"":""visualization*"",""60"":""memory"",""61"":""explicitly"",""62"":""json"",""63"":""serp*"",""64"":""requested*"",""65"":""protests*"",""66"":""needed*"",""67"":""management"",""68"":""press*"",""7"":""systems"",""8"":""semantic"",""9"":""relevant""},""x2D"":{""0"":-3.2428131104,""1"":4.6093320847,""10"":-4.0288686752,""11"":-1.9093375206,""12"":-2.5859045982,""13"":-1.6791934967,""14"":-2.3834731579,""15"":-3.2301316261,""16"":-4.1953630447,""17"":-2.0514001846,""18"":-6.4280028343,""19"":-5.2847175598,""2"":-2.6022267342,""20"":-6.1903829575,""21"":-6.6107215881,""22"":-2.2510251999,""23"":4.3842220306,""24"":-6.5486984253,""25"":4.6691770554,""26"":-3.8046088219,""27"":4.5374464989,""28"":-6.2392401695,""29"":-6.8859004974,""3"":-6.9414653778,""30"":4.2804350853,""31"":-2.1679592133,""32"":-3.6159176826,""33"":-6.8841385841,""34"":-5.8229622841,""35"":-3.0740072727,""36"":-5.3065624237,""37"":-2.7596549988,""38"":-6.1076245308,""39"":-2.8391897678,""4"":4.7597799301,""40"":-6.299715519,""41"":-6.637052536,""42"":-3.9647755623,""43"":-2.1439828873,""44"":-5.2352852821,""45"":-6.3333129883,""46"":5.0483107567,""47"":-3.6383671761,""48"":-6.7137136459,""49"":-5.5325031281,""5"":-3.3320095539,""50"":-3.4724977016,""51"":-5.2577166557,""52"":-4.8503289223,""53"":-5.7793741226,""54"":-5.1457576752,""55"":5.0052690506,""56"":-2.9025251865,""57"":4.8637003899,""58"":-2.1277937889,""59"":-4.5757193565,""6"":-6.3080487251,""60"":-6.0336613655,""61"":-5.1235957146,""62"":4.4910206795,""63"":4.4585280418,""64"":-5.4047789574,""65"":-1.914785862,""66"":-5.8201065063,""67"":-5.5745482445,""68"":-1.8122153282,""7"":-3.8856947422,""8"":-6.8259363174,""9"":-5.9919338226},""y2D"":{""0"":1.8680409193,""1"":-2.5314569473,""10"":2.626850605,""11"":-0.2416167706,""12"":0.0683711618,""13"":0.1257805079,""14"":1.5451062918,""15"":0.8720558882,""16"":1.9979462624,""17"":0.2479375452,""18"":4.8840122223,""19"":-1.5027346611,""2"":1.5048844814,""20"":4.4997324944,""21"":5.6048145294,""22"":-0.2565226555,""23"":-2.9556660652,""24"":4.9481892586,""25"":-2.973749876,""26"":2.3343117237,""27"":-2.0345542431,""28"":4.8309612274,""29"":5.4597373009,""3"":6.1169099808,""30"":-2.6945054531,""31"":-0.01224415,""32"":2.6910293102,""33"":6.0458025932,""34"":-2.0026011467,""35"":0.5205321908,""36"":-1.9219121933,""37"":0.3978314102,""38"":5.1781182289,""39"":0.6509208679,""4"":-2.6849761009,""40"":5.8928589821,""41"":6.231692791,""42"":2.4102201462,""43"":0.9447427988,""44"":-2.7444989681,""45"":5.5752410889,""46"":-2.6642327309,""47"":2.7085177898,""48"":5.7501935959,""49"":-2.0674865246,""5"":2.6963357925,""50"":2.1418325901,""51"":-2.4263396263,""52"":-2.1901600361,""53"":4.9096693993,""54"":-2.4965851307,""55"":-2.2235777378,""56"":2.0455095768,""57"":-2.3148906231,""58"":1.0879145861,""59"":1.3095047474,""6"":5.9543056488,""60"":5.2343893051,""61"":-1.9636611938,""62"":-2.2208533287,""63"":-2.6109912395,""64"":-2.2716095448,""65"":0.6333202124,""66"":-2.2320280075,""67"":4.5947470665,""68"":-0.0180959944,""7"":2.8063180447,""8"":5.8552136421,""9"":-2.0340909958}}",False,False,False,http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7314287,,Big Text Visual Analytics in Sensemaking,"[ 1.93838060e-01 -2.36958116e-01 -6.35862350e-02 -1.10433914e-01
  9.76979375e-01 -4.45786752e-02 -4.05752137e-02 -1.70622766e-01
 -2.69927830e-01 -2.46505201e-01  2.04788953e-01 -3.42705071e-01
  3.30440670e-01  3.85387689e-02 -2.86182582e-01  1.11548483e+00
 -3.05858314e-01 -9.97210816e-02 -4.27069850e-02  1.07523605e-01
  3.21803451e-01 -7.78839365e-02  1.38473749e-01  6.75754368e-01
  2.08469003e-01  9.76462066e-02 -1.47210270e-01  6.80037141e-02
 -2.71787345e-01  3.89766783e-01  5.72028756e-01  4.67541933e-01
 -9.24397558e-02 -6.18570089e-01  1.39166877e-01 -2.73591906e-01
 -3.04214239e-01 -1.60733655e-01  4.08636272e-01  6.59984827e-01
 -5.69393933e-01 -4.21704799e-01 -1.49850383e-01 -2.45753750e-01
  3.40229005e-01  1.81992054e-01 -3.27247590e-01 -3.82863343e-01
 -7.93098733e-02 -5.03161371e-01 -1.36307919e+00 -6.04283273e-01
 -7.71444887e-02 -7.03895092e-01 -9.26806312e-03  5.41934967e-01
 -2.42299363e-01 -6.63563490e-01  1.75712124e-01  1.49576709e-01
 -3.96391422e-01 -2.07124442e-01 -2.38020197e-01  1.30990176e-02
  1.27362326e-01 -4.51130152e-01  1.37271941e-01  5.01481593e-02
 -3.78737628e-01  2.18870550e-01  1.55655339e-01  8.89233202e-02
  7.47291073e-02  4.93681341e-01 -4.04879987e-01  2.01285779e-01
 -3.59877646e-02  3.16802382e-01  5.10730267e-01 -3.77209097e-01
 -1.86858326e-01 -1.88692153e-01  2.24847943e-01  1.53919645e-02
  6.41963780e-01  8.20728779e-01 -9.96533781e-02  4.57566828e-01
 -4.88012671e-01  3.97663385e-01 -2.85560936e-01 -3.53067764e-03
 -1.57710359e-01  3.94314915e-01  7.26202726e-01 -5.08477807e-01
 -5.82162797e-01 -4.48710546e-02  8.80596321e-03  8.39253888e-02
  3.70173901e-01 -6.27725720e-01  1.04565546e-01 -2.07287312e-01
 -2.13865619e-02 -1.25579685e-01 -1.80179074e-01 -5.81818879e-01
 -2.66067743e-01  7.33409375e-02  1.53648585e-01  1.09589063e-01
 -3.55950519e-02 -5.41340351e-01 -2.09879011e-01  3.17278534e-01
  3.58546935e-02  6.33325279e-02  8.34440589e-02  1.91118315e-01
  1.06978871e-01  6.36513531e-01  1.38904259e-01  3.63894850e-01
  2.09986880e-01 -3.14731710e-02 -6.10380918e-02  2.33298913e-01
  4.00822341e-01  1.50746003e-01  3.89596939e-01 -5.02794646e-02
  2.59136241e-02 -2.27561548e-01 -2.25816607e-01  6.71879888e-01
 -4.23255533e-01  1.78718418e-01  1.58257693e-01  9.84415561e-02
 -4.29599464e-01 -8.13055217e-01  1.59397319e-01  7.68069327e-02
  2.38877997e-01 -3.82272005e-01 -1.21395737e-01  2.15932384e-01
 -3.43138725e-01  4.32250798e-01 -4.18903798e-01  5.98102927e-01
 -8.40956450e-01 -4.34877053e-02 -1.02725849e-01 -2.62788028e-01
 -2.26794049e-01  4.26061377e-02  1.91802084e-01  2.25075021e-01
 -2.45708600e-01  3.60286385e-02  4.90550026e-02  1.69487461e-01
 -1.26992032e-01 -1.84476990e-02 -6.52379543e-02  1.70784995e-01
 -1.88649192e-01 -1.69193178e-01  3.33413482e-01 -2.28606299e-01
  1.07863083e-01  1.00980494e-02  6.46702349e-01  2.01467663e-01
 -1.45406857e-01  2.40411028e-01 -2.89079621e-02  1.00009906e+00
 -3.98092657e-01 -1.24311179e-01 -6.61220104e-02 -6.72038853e-01
  4.66505140e-01 -1.80475023e-02  1.19675808e-02 -5.60834825e-01
  2.69483238e-01  1.66551098e-01 -2.56386250e-01 -2.23975912e-01
  1.22812063e-01 -1.25167623e-01  2.64733464e-01 -1.86777577e-01
  1.39646575e-01  1.25706285e-01 -2.35732555e-01 -1.41926289e-01
 -4.52659756e-01 -4.12037849e-01 -3.66930693e-01  3.12564731e-01
 -2.26336271e-01  1.83630481e-01 -2.81690598e-01 -7.73930132e-01
 -8.29758883e-01  5.00082299e-02 -2.11887553e-01  6.47688925e-01
 -3.69997472e-01  5.19234955e-01  1.12358920e-01  1.74198166e-01
  1.08642690e-01 -2.04394192e-01  3.33775014e-01  4.52071317e-02
  3.78158182e-01 -3.21407408e-01  2.15147406e-01  1.33315012e-01
 -1.80350214e-01  1.93118727e+00  7.95509014e-03 -3.47129524e-01
  5.13749599e-01  9.04186368e-02  1.77768782e-01  8.97109136e-03
  5.03389001e-01 -6.11369193e-01  3.81165773e-01  2.18301386e-01
 -1.56408742e-01 -3.81116480e-01  1.54098436e-01 -2.18987063e-01
 -2.63502568e-01  4.83094066e-01  2.04213068e-01  1.19247854e-01
 -1.97556391e-02  3.44846427e-01  2.54061133e-01 -1.21479489e-01
 -2.57035375e-01 -7.10065849e-03 -8.58628079e-02  2.51689225e-01
 -8.51144195e-01 -4.43919986e-01 -3.99898067e-02 -2.95936018e-01
 -1.92594707e-01 -2.94153243e-01 -9.17132497e-02  2.02082932e-01
  6.65997148e-01  2.32862815e-01  8.79442245e-02  1.60653237e-02
 -1.87197030e-01 -4.56159234e-01 -7.41308331e-02 -1.89708292e-01
  7.14390099e-01  2.79992133e-01  1.86029077e-01 -5.93516789e-02
  1.00191809e-01  4.40005869e-01 -1.81592926e-01 -1.43234402e-01
  3.76738042e-01 -4.17098135e-01 -8.68884921e-02 -6.88541114e-01
  2.62191951e-01  5.16521275e-01 -3.97215709e-02  6.90378845e-02
 -7.58632720e-01 -1.88991979e-01  4.29438293e-01  4.61579077e-02
  1.73504546e-01 -1.22236855e-01  1.62695535e-02  2.74845898e-01
 -3.86454225e-01 -3.10692906e-01  4.37367558e-01  4.20306981e-01
  2.41971426e-02 -2.07063213e-01 -5.87451816e-01 -4.58255410e-01
  6.39183149e-02  1.67532176e-01  3.13458323e-01 -2.20843732e-01
  2.51689702e-01  2.51108199e-01 -2.71716923e-01 -5.88308334e-01
 -8.67099571e+00 -3.73804092e-01 -2.79475033e-01  6.54908866e-02
 -1.76448226e-01 -1.86370730e-01  1.49851087e-02 -7.86814615e-02
 -8.42518434e-02  4.84034032e-01 -1.07027590e-01 -1.02558948e-01
 -3.18329841e-01  3.36600393e-02 -1.42940938e-01 -1.19483136e-01
  6.11312807e-01  6.25367016e-02 -2.03072324e-01  9.07732725e-01
 -1.45194173e-01 -2.25374788e-01  2.76844233e-01 -2.35804990e-01
  8.93821716e-02 -1.95707932e-01 -4.17969704e-01  8.56980905e-02
 -2.33617246e-01 -4.54453439e-01 -3.21729302e-01 -4.52785850e-01
 -4.69209820e-01  1.22321463e+00 -3.25543493e-01  2.32553314e-02
 -2.17443600e-01 -5.26597738e-01  1.46358028e-01  2.39871725e-01
  7.94434547e-02 -2.12405294e-01 -6.84263781e-02 -2.82795012e-01
  9.77518380e-01 -1.87455863e-02  2.91884840e-01  3.38074327e-01
 -6.37270927e-01 -1.57442987e-01 -1.70974329e-01 -2.44067669e-01
  3.15167248e-01 -2.63755888e-01 -8.43400881e-02 -1.91149101e-01
  4.49264556e-01  5.12474597e-01 -1.77999005e-01 -4.73234445e-01
  1.10628471e-01 -4.42581028e-01 -2.74056226e-01  2.88221061e-01
  2.54608449e-02  2.60291602e-02 -8.26907516e-01 -6.44298315e-01
  6.94826692e-02 -3.61924142e-01 -3.47802281e-01  4.17989820e-01
  1.19021215e-01 -1.40679944e+00 -5.67955792e-01 -2.63602108e-01
  4.10700113e-01 -8.20562840e-02 -4.70595807e-01 -5.32757998e-01
 -6.58913791e-01 -3.42229843e-01  1.11659974e-01 -2.34295160e-01
 -5.00905752e-01  1.25788018e-01 -1.44778520e-01 -2.94947147e-01
 -6.17261946e-01  4.69406158e-01 -1.78112254e-01  3.58270258e-02
  4.26390767e-01  1.76957384e-01 -2.52582580e-01 -2.84479577e-02
  6.71516061e-01 -1.39950395e-01  3.90467048e-01  4.54015583e-02
 -6.98745698e-02 -6.22613318e-02 -6.46328703e-02 -1.33212477e-01
 -5.21238074e-02  1.46526605e-01 -3.87013674e-01  1.46148294e-01
  2.75611699e-01  1.58847764e-01 -3.42487037e-01  2.58864582e-01
 -4.64059472e-01 -1.64561555e-01 -4.05182540e-01  1.12484328e-01
 -3.09450865e-01  4.62179303e-01 -4.66025844e-02 -3.76105309e-01
 -6.07353985e-01  1.63468301e-01 -3.81815553e-01 -5.10143191e-02
  7.96586156e-01 -3.38380523e-02  3.15794721e-02  3.61954987e-01
 -2.51167059e-01  1.69210017e-01  8.75674002e-03 -5.63144803e-01
 -2.54401237e-01  4.84828092e-02  1.14841841e-01 -7.10564032e-02
 -8.14927369e-02 -6.52329087e-01 -9.41284716e-01  4.30006415e-01
  5.59323490e-01  1.25509351e-01  4.52474207e-01  1.95510253e-01
  8.11790451e-02 -3.38782549e-01  9.76372436e-02  1.56184524e-01
 -3.96246910e-01  2.25591645e-01 -3.60095799e-01 -6.71471179e-01
  2.55166620e-01 -1.99196279e-01  6.18664026e-01  3.00365426e-02
  1.92966715e-01 -2.19839349e-01 -1.34947956e-01 -5.67591190e-01
  4.76938635e-02 -6.09500967e-02  3.42036486e-02 -1.35395512e-01
 -3.20074074e-02 -1.02191187e-01 -4.55629796e-01  4.76479769e-01
  8.95749182e-02 -7.09764302e-01 -4.19557653e-02  3.48878764e-02
 -1.20336019e-01 -1.69385836e-01 -2.81876683e-01  4.84469414e-01
  3.18944633e-01 -1.29869580e-01 -4.18464214e-01  5.72647691e-01
  2.94053853e-01  5.03567636e-01  1.99895903e-01  3.11558008e-01
  5.78609705e-01  7.63556302e-01  4.09415960e-01  1.29051164e-01
  2.73553133e-01  1.56720072e-01 -3.35713118e-01  2.06479371e-01
 -9.77812186e-02  2.33530954e-01 -2.08238557e-01 -6.24371946e-01
  4.10326123e-01 -8.32061708e-01 -1.22900181e-01  1.36380836e-01
  1.42116193e-02 -1.54108051e-02 -4.96059775e-01  6.29974544e-01
 -2.17872873e-01 -3.50761145e-01  2.18776092e-01  2.46364295e-01
 -3.56118053e-01  1.79820612e-01 -3.29326600e-01  2.35131197e-02
  1.35371432e-01 -2.09654212e-01  2.13006765e-01 -8.00431818e-02
 -1.56312004e-01 -3.92743766e-01 -8.99216831e-01  1.97971269e-01
 -5.04651666e-01  1.17938511e-01  2.20041737e-01  2.14455321e-01
  1.23515636e-01  2.73530534e-03  1.23470984e-01 -2.48684026e-02
 -4.82227296e-01  9.94245559e-02  3.80787738e-02 -1.67678928e+00
  1.62392735e-01  3.16479169e-02 -1.00100458e-01 -3.76059175e-01
 -6.08900309e-01  1.04725733e-01 -1.86549187e-01 -2.45389268e-01
  2.93962717e-01 -3.37640464e-01 -2.08029047e-01 -1.38644159e-01
 -2.06842765e-01 -2.03110650e-01 -5.33393800e-01  3.34023982e-02
 -1.35473236e-01 -1.76027849e-01  3.54940265e-01 -8.52789283e-02
  2.36222476e-01 -7.69260347e-01  4.59976554e-01 -1.48602366e-01
  4.99308109e-02 -7.10783362e-01 -9.81854647e-02 -1.03297345e-01
 -1.12986065e-01 -3.17286640e-01 -3.69430035e-02  3.27768847e-02
 -7.48407841e-01 -1.71409786e-01 -5.13314307e-02 -2.35364348e-01
 -3.43978196e-01 -4.54501718e-01 -1.29676864e-01 -1.49284482e-01
 -3.04005593e-01  5.76152861e-01 -5.26382625e-01  1.03645166e-02
 -5.16972601e-01 -3.71322073e-02  2.21535206e-01 -4.62500572e-01
  7.05061436e-01 -1.28261477e-01  2.14461952e-01  5.94742119e-01
  3.90909791e-01 -2.91285157e-01  9.72014219e-02  1.06789500e-01
 -2.13976741e-01 -6.90528005e-02  6.34101689e-01  1.60192221e-01
 -5.13076186e-01 -1.84823424e-01 -1.71135459e-02  6.22520387e-01
  8.07703257e-01  3.71599793e-01  7.25922883e-02  2.75310539e-02
 -2.42004339e-02  2.58840948e-01  3.78776163e-01  5.96789837e-01
  2.37481683e-01 -1.87204301e-01 -3.23681682e-01 -9.05698180e-01
 -9.68596898e-03 -5.74243903e-01 -2.90785711e-02  1.14760138e-01
  7.06066847e-01  3.32836024e-02  3.37764323e-02 -2.97225565e-01
 -2.14112803e-01  5.23878708e-02  2.88129658e-01  9.13613886e-02
 -6.43789291e-01  4.57919717e-01  7.08789349e-01 -3.37549299e-01
 -6.67931288e-02  5.14201224e-01 -3.59744906e-01 -1.93581715e-01
 -6.45794272e-01  4.10172701e-01  6.04500994e-02  3.00473958e-01
 -1.36717066e-01 -9.88081396e-02  5.77672601e-01 -2.16238454e-01
  3.34306479e-01 -1.50920078e-01  1.47484511e-01  2.87678689e-01
 -1.36634633e-01  4.40187186e-01  5.30122332e-02  4.14215118e-01
  1.63301200e-01 -2.31408179e-01 -1.12831205e-01  5.37211776e-01
  1.21183127e-01 -9.03313756e-02  1.40006021e-01 -4.71143387e-02
  4.12589908e-01  3.89434919e-02  8.67495611e-02 -3.22754622e-01
  5.15712023e-01 -2.64277756e-01 -2.48589851e-02  7.42829740e-01
  3.70970726e-01 -1.85120925e-01  1.35265648e-01 -7.95013249e-01
 -5.78467965e-01 -2.11248826e-02  5.30302227e-01  1.91539470e-02
  3.23910981e-01  2.56619812e-03  3.47664148e-01  3.73174757e-01
  3.04194003e-01 -9.83514041e-02  1.86029151e-01  2.91573524e-01
  2.90438205e-01 -5.15671015e-01  6.96355253e-02 -7.47335181e-02
 -1.32742850e-02 -5.46875477e-01 -2.58715361e-01  2.61354744e-01
 -6.52077794e-01 -2.06013292e-01 -2.07039699e-01  3.61834675e-01
 -8.96022096e-02 -2.30843686e-02 -6.37495816e-01  5.41727066e-01
  5.29723585e-01  2.26001516e-02 -2.39169940e-01 -8.66612792e-02
  1.62702292e-01  2.72729039e-01  3.72175351e-02  5.50206415e-02
 -8.67441446e-02  4.90896851e-02 -3.16800147e-01  3.95010382e-01
 -8.43571573e-02  4.44345437e-02 -2.82200128e-01  5.28831124e-01
 -5.23950815e-01 -4.22202259e-01  3.52313012e-01  3.63024443e-01
 -8.25581104e-02  3.83226037e-01 -4.68786322e-02  3.54126275e-01
  4.71701801e-01  8.57546255e-02 -1.95183337e-01  2.87647601e-02
 -3.40487361e-01 -5.02235711e-01  4.05227840e-01 -2.96263039e-01
 -6.00564666e-03  5.24332523e-01 -3.71312976e-01 -3.94150466e-01
  1.51402041e-01 -4.74837981e-02  1.38243765e-01  1.90828070e-01
 -3.59573007e-01  3.17706279e-02 -1.58833355e-01  1.67476028e-01
 -2.89078742e-01  3.17229003e-01  1.41090285e-02  1.07416794e-01
 -5.53195059e-01  2.10340649e-01 -3.72629881e-01 -5.26381694e-02
  2.64636487e-01  3.05742681e-01 -2.22507209e-01  3.06025650e-02
 -2.70550195e-02 -4.18427050e-01 -7.88163126e-01 -1.04720093e-01
 -4.48016822e-01 -3.61311883e-01  5.38471751e-02  2.07247064e-01
 -1.83032557e-01 -8.06673244e-02 -1.76952437e-01 -1.01116545e-01]",5LF32UEH,False,False,"[9.91289234161377, -1.544219732284546]"
RH3V72Q4,V5ELHVXQ,"5. Immersive Human-Centered Computational

Analytics

Wolfgang Stuerzlinger1, Tim Dwyer2, Steven Drucker3, Carsten Görg4, Chris

North5, and Gerik Scheuermann6

1 School of Interactive Arts + Technology (SIAT), Simon Fraser University, Canada

w.s@sfu.ca

2 Monash University, Australia

tim.dwyer@monash.edu
3 Microsoft Research, USA
sdrucker@microsoft.com

4 University of Colorado, USA
carsten.goerg@ucdenver.edu

5 Virginia Tech, USA

north@vt.edu

6 Leipzig University, Germany

scheuermann@informatik.uni-leipzig.de

Abstract. In this chapter we seek to elevate the role of the human
in human-machine cooperative analysis through a careful consideration
of immersive design principles. We consider both strategic immersion
through more accessible systems as well as enhanced understanding and
control through immersive interfaces that enable rapid workﬂows. We
extend the classic sensemaking loop from visual analytics to incorporate
multiple views, scenarios, people, and computational agents. We consider
both sides of machine/human collaboration: allowing the human to more
ﬂuidly control the machine process; and also allowing the human to
understand the results, derive insights and continue the analytic cycle.
We also consider system and algorithmic implications of enabling real-
time control and feedback in immersive human-centered computational
analytics.

Keywords: human-in-the-loop analytics, visual analytics, data visualization

5.1.

Introduction

In Chapter 4, we reviewed the basic tasks that immersive analytics systems need
to support. The tasks considered in that chapter were mostly ‘low-level’ in the
sense that each task corresponded to a single conceptual action supporting data
analysis. These types of tasks were categorized in Heer and Shneiderman’s task
taxonomy for information visualization [24] as data and view speciﬁcation and
view manipulation tasks. However, we also reviewed the third category of tasks
from this taxonomy on so-called process and provenance. These latter tasks were

5. Immersive Human-Centered Computational Analytics

145

still fairly ﬁnely grained in terms of corresponding to concrete actions but they
related to “doing things” with insights gleaned from the data (e. g. record, share,
annotate, guide) rather than tasks required to make these individual insights
in the ﬁrst place. Thus, these process and provenance tasks were required to
support a full workﬂow around data analytics – not simply identifying particular
features of data, but making sense of data in a more holistic way. We review these
‘traditional views’ of the analytics process in Section 5.2.. This chapter focuses
squarely on this more holistic process or workﬂow, also known as the sensemaking
loop of visual analytics [44], and the various ways in which human immersion can
play a role in this loop, and the way that that immersion can be supported by
machine guidance. The sense-making loop is considered again brieﬂy in Chapter
9 of this book along with a model for the Immersive Analytics process as part of
a broader discussion of a general design framework for immersive analytics.

Also in Chapter 4, we described the opportunities for visualization researchers
and designers to take advantage of the diﬀerent kinds of immersion and increased
user presence aﬀorded by natural user interfaces and immersive display tech-
nologies. We described how spatial and sensory-motoric immersion can help to
increase the engagement of the users in their data analysis tasks.

In this chapter, in considering more broadly the higher-level concerns of the
data analytics process, the type of immersion we are seeking could be more
accurately described as Strategic Immersion. This follows a concept from game
design that—compared to other types of immersion—is more closely related to
high-level problem solving, or literally, a game player’s strategy for succeeding in
the game [1].

Another aspect of the data analytics workﬂow that we begin to consider
in this chapter, is the integration of automatic processes, such as machine
optimization and learning, into the workﬂow. Thus, we consider the role of a user
in a larger-scale collaborative analytics process, which includes both other people
and machine assistance. It is timely to consider this now because, in addition to
the rapidly emerging display and interaction technologies described throughout
this book, we are also in the midst of a step-change in the capability of machine
learning (ML). We want to make sure that the rapid advances in deep-learning,
for instance, do not close the door on interaction.

We can summarize the various considerations of this chapter as follows:

– To leverage the advantages of immersive environments for problem-solving

tasks in Visual Analytics (VA) (Section 5.2.).

– We want to elevate the role of the human in human-machine cooperative
analysis (over perhaps the ML or DataMining Human in the Loop perspective)
(Section 5.3.).

– How do the above considerations aﬀect algorithm/system/platform design

and what are the challenges for the future? (Section 5.4.).

146

Stuerzlinger et al.

5.2. Analytics Process
In this section, we discuss the analytics process, including models for how people
analyze data. Then we analyze which parts of this process can be augmented by
immersive technologies. We also discuss how human collaborators and automatic
“intelligent” processing can be integrated into the immersive analytics process.
Finally, we develop an overview of the requirements for keeping an analytics
system responsive enough to be used in an interactive immersive environment.

5.2.1. Example Scenario for Immersive Analytics Processes
To date, there are few compelling examples of systems that use immersion for
information seeking analytical activities. An intriguing scenario proposed as a
demonstration game for the Microsoft Hololens is the Fragments game (see Figure
1), which explores many aspects of immersive analytics. In the scenario, the user
plays a detective that examines multiple crime scenes and gathers evidence to
inform subsequent search criteria. Diﬀerent ‘lenses’ can be used so that diﬀerent
aspects of the real world are highlighted – in the case of the game, x-ray lenses for
seeing inside or underneath the surface of objects, infrared for exploring heat and
recently manipulated objects, or audio lenses that play certain sounds triggered
by examining objects in the environment.

This information is then used to ﬁlter both map-based geographic visualiza-
tions and lists of facts. Hypotheses can be formed and tested within the scenario
and when a hypothesis is conﬁrmed, the user moves on to deeper challenges. The
scenario exempliﬁes many potential immersive visual analytics activities: gather-
ing evidence, forming hypotheses, reﬁning queries, and organizing information. It
further shows how the system can facilitate both manual interaction—where the
user is completely controlling the exploration based on their gaze—and automated
interaction, where the system takes a combination of observations and generates
a model of the results that is visualized for appropriate subsequent actions.

5.2.2. Sensemaking as the Analytics Process
There are several diﬀerent models that help describe the way by which humans
understand and process information. Depicted below are two models (from among
many) that are commonly cited in the visual analytics literature. Speciﬁcally, in
Figure 2 we have one of the earliest (1999) attempt at a visualization “reference
model” by Card et al. [5] and then in Figure 3, the more recent (2005) and
sophisticated Sensemaking Loop by Pirolli and Card [44]. Both of these models
incorporate stages for taking in data, transforming the data into a representation
convenient for interaction, and an iterative process by which we reﬁne through
successive interactions.

We have chosen to use the Pirolli-Card Sensemaking Loop (Figure 3) as a
basis for this chapter in part because of its wide popularity, and in part because it
breaks down the process in a more ﬁne-grained fashion than many other models.
For each of the stages, we can explore how that stage might be transformed by

5. Immersive Human-Centered Computational Analytics

147

Fig. 1: The Hololens Fragments game allows deeper exploration of a scene using
alternate ’lenses’. Courtesy Microsoft - used with permission.

Raw
Data

Data
Tables

Visual

Structures

Views

Data

Transformations

Visual

Mappings

View

Transformations

Fig. 2: The traditional reference model for visualisation, after Card et al. [5]

148

Stuerzlinger et al.

Fig. 3: Pirolli and Card’s sensemaking loop (courtesy Jie Liu, 2017).

immersive capabilities. In particular, the Pirolli-Card model has a series of steps
for both:
Creating a model (bottom-up) where those steps involve ﬁnding information,
extracting meaning, schematizing, building a case, and subsequently communi-
cating that information.
Evaluating the model (top-down) where those steps involve re-evaluation,
ﬁnding supporting evidence, ﬁnding relations in the information or ﬁnding basic
information itself.

Each stage can loop back down or move upwards in the chain.

5.2.3. Tasks in the Analytic Process
In Chapter 4 we described three categories of tasks that need to be supported
by immersive analytics systems. Here we describe how those tasks ﬁt into the
Sensemaking Loop model.

The ﬁrst two categories of tasks, data/view speciﬁcation and view manipulation,
describe fairly low-level operations that mostly fall within the “foraging” portion
of the Pirolli and Card model. The last category, process and provenance, goes
beyond most traditional visualization task taxonomies as it addresses typical
issues that are more related to supporting the analysis process in general, and
not tasks speciﬁcally related to interactive visualization. As described below, the
process and provenance tasks are more the domain of the “sensemaking” portion
of the Pirolli and Card model.
Record: Provenance research is mostly interpreted as the development of meth-
ods and tools to improve awareness of the history of changes and advances

5. Immersive Human-Centered Computational Analytics

149

throughout the analysis process by the user of the visual analytics tool. Quite
recently, Ragen et al. [45] published an excellent paper on the characteri-
zation of provenance in visualization and data analysis. They distinguish
between various provenance types, such as provenance of data, visualization,
or interaction, and present an organizational framework for clarifying the
type of provenance information capture and the purpose for which it will be
used. That article also surveys the most important provenance approaches
like [23, 51]. Providing and analyzing history data is especially important
for cases in which various analysts collaborate and work together. Simply
revisiting old snapshots of an analytic session or replaying every single event
that happened during such a session is usually not suﬃcient to reveal the
same insights that an analyst might have had during the initial analysis. Thus,
keeping track of the reasoning involved during a collaborative process and
using this information later to review and reﬂect upon it can be a challenging
task. For instance, analysts should have the possibility to quickly review
changes performed on a visual representation and get an idea of the most
interesting regions according to the user history without the need to replay
every single action that was performed by previous users.

Share: Collaboration is an important aspect in practice, but still not very well
researched or supported by visualization tools. “A VA system has to support
discussions, dissemination of results, or interactions of several analysts at
the same place and the same time (co-located) or at diﬀerent places and not
necessarily at the same time (distributed). Sharing views or publication of
visualizations are examples of important requirements for eﬃcient collabora-
tion between many analysts.” [30]. Isenberg et al. [28] provide an excellent
overview of deﬁnitions, tasks and examples for collaborative visualization
(also see 8). They also provide an excellent summary of ongoing challenges
in this ﬁeld. A recent visualization system that supports the distributed
(synchronous and asynchronous) analysis of networks is OnGraX [59]. It even
makes data-aware annotations available as discussed in the next item.

Annotate: Pointing to interesting elements or giving comments to individual
graphical features or patterns discovered within a visualization are impor-
tant for any analytical process and also for potential discussions within a
collaborative setting. As a visualization is not a static image or diagram,
such annotations must be stable/persistent with respect to the represented
data as well as to the actual visible graphical elements. Both can and will
change over the period a visual analysis is performed. An example of such a
dynamic situation is the analysis of a social network where network nodes
might appear/disappear, and the layout may change due to a reconﬁguration
by the analyst (e. g., by using another layout algorithm). In consequence,
annotations should be viewable in their historical context. Thus, it should be
possible for analysts to review old visualization states where the annotation
took place (cf. the provenance and history discussion above). As an example,
the OnGraX network visualization system [59] makes it possible to link
textual annotations and chat messages to speciﬁc network elements. Those
annotations are permanently tracked and stored in a database.

150

Stuerzlinger et al.

Guide: Analytics processes are typically non-linear, i. e., the representation of
workﬂows is challenging. Guiding the user through workﬂows for shared
activities would be clearly beneﬁcial, for instance. The ﬁrst approach to a
more detailed characterization schema for guidance in visual analytics has
been recently proposed by Ceneda et al. [8]. Another related conceptual
approach for guidance was proposed by Streit et al. [53], but there the
authors only focus on previously deﬁned workﬂow-driven approaches for
concrete biomedical use cases. Besides the previously mentioned works, there
is only a little work done to understand or deﬁne the process of user guidance
in general, and there are also only a few practical realizations. Guidance
provided by the VA system can be based on several inputs (individually used
or all together), such as the input data itself, interaction when using the VA
system, user/domain knowledge, or it may even be based on emotion tracking
or similar sources [9]. The exact way in which a system supports guidance
and to what extent (more proposing or more decisive) can be varied too.

5.2.4. The Analytics Process in an Immersive Environment
We now discuss the potential for integrating the analytic process with immersive
environments. In particular, we examine speciﬁc components of the sensemaking
process that could be enhanced by immersive technologies.

The ﬁrst half of Pirolli and Card’s sensemaking process is about foraging
for information. We can envision using attributes of both Augmented Reality
(AR) and Virtual Reality (VR) technologies to help ﬁnd and access appropriate
information on an as-needed basis. In an AR setting, we can associate information
sources with objects in the real world by taking advantage of their spatial context
(see Chapter 7). In an application on a factory ﬂoor, for example, simply looking
at a particular machine could provide usage and maintenance statistics associated
with that machine. Traﬃc patterns throughout the factory could be shown by
patterns superimposed on the ﬂoor. In a VR setting, we can use models in a
fashion similar to icons to represent data sources, but those models could have
additional semantic meaning associated with them–so that a model of an engine
might serve as a gateway for information about emissions, maintenance, power
output, etc. This type of semantic association could entail both advantages and
disadvantages for the sensemaking process: on the positive side, it could help
remind people what is available; but, on the negative side, more abstract measures
and data might be diﬃcult to associate with concrete representations.

The second half of the sensemaking process is about synthesizing information–
organizing collected information, formulating hypotheses and arranging sup-
porting and contradictory evidence. It has been shown that space (a physical
interaction space or relatively large display space) can play an important role in
this process and assist in task completion by allowing greater space for organiza-
tion [2]. Analysts can use the space to organize and structure not only collected
information but also their analytical workﬂow and thought processes.

As a simple example of combining these two portions of the sensemaking
process, an immersive environment can serve as a huge canvas where information

5. Immersive Human-Centered Computational Analytics

151

can be accessed relative to the user. Furthermore, as a user moves around
the space, information can be organized using spatial position and relative
proximity between data representations to imply a relationship between them.
Another potential advantage of immersion is the possibility to provide a physical
instantiation of the ‘memory palace’ mnemonic device so that parts of a complex
model can be compartmentalized to diﬀerent spatial locations–virtual in the case
of VR or physical in the case of AR.

5.2.5. Support for Analytics Steps in Immersive Environments
Next, we discuss how well speciﬁc types of interactions in the various steps of
the sensemaking process may be supported by immersive environments. In the
following, bold numbers refer to the individual steps in Pirolli and Card’s
Sensemaking Loop model in Figure 3.

The sensemaking loop contains a variety of diﬀerent search processes (see
steps 2,3,6,9,12). These could be supported through easier visual access to
large amounts of information, e. g., by rotating the head. As long as the cost of
navigation is small, say due to a one-to-one mapping between user and viewpoint,
accessing large amounts of information through physical navigation is beneﬁcial [2].
Yet, if navigation becomes challenging, e. g., in large-scale environments or due to
the use of more complex interaction schemes for navigation, the cost of navigation
can become a bottleneck. Given strong spatial memory, we can re-ﬁnd information
more easily when it has been associated with a spatial position. Furthermore,
automated search can reveal information ‘in-context’ by highlighting the results
while preserving their spatial positions, reinforcing spatial memory. There are
still obstacles in using immersive environments for search. One notable example is
that current resolutions in both VR and AR are extremely limited in comparison
to the real world. Experiments with foveated displays may assist, but especially
when working with textual data, we need large, high-resolution displays for
eﬀective interaction.

For schematizing (steps 8,10), it is possible to use the immersive environment
to bridge the gap between data embedded in the real world and abstract data, for
example, by augmenting a real-world scene with an abstract data display. This
can help to create stronger associations, that further support visual search. This
can also support aspects of distributed cognition, enabling analysts to readily
oﬄoad cognitive activities into the environment.

Sensemaking tasks that are focused on data manipulation (steps 8,11,10,13)
rather than data retrieval may be harder to accomplish in immersive environments
as detailed interaction (especially with textual information) may pose more
usability challenges (at least with current technologies). Whereas, interacting
with large amounts of information may be made easier by exploiting greater
degrees of freedom. Pointing and selecting data objects in immersive environments
is often not as eﬃcient as on the desktop. Thus, the trade-oﬀ between input
modalities is diﬀerent in immersive environments. Speech, gesture, and other
input modalities might counterbalance the shortcomings of interactions in other
modalities. Some interactions are easier because they are naturally supported

152

Stuerzlinger et al.

(e. g.panning head). Others might become more diﬃcult (e. g.selection), and
require the use of gestures or voice (see Chapter 4).

The presentation of analysis results at the end of the sensemaking loop (step
16) can be augmented through immersive environments, including overlaying
results on the real world. However, a potential downside is that the potential for
deception might be even stronger than in more abstract representations since
abstraction might require more veriﬁcation of the substance of the arguments.
Early experiments with augmented presentation techniques in which gestures and
speech trigger 3D visual animations are promising in helping to convey complex
concepts. One current diﬃculty is in the complexity of authoring such experiences.
Another diﬃculty is in viewing them. Do viewers need for themselves to be in a
virtual environment? How do diﬀering viewpoints aﬀect the presentation?

IA Support

Sensemaking Step

1. External Data Sources

2. Search & Filter

3. Search for Information

4. Shoebox

5. Read & Extract

6. Search for Relations

7. Evidence File
8. Schematize

9. Search for Evidence

10. Schema
11. Build Case

12. Search for Support

13. Hypotheses
14. Tell Story
15. Reevaluate
16. Presentation

−
∼
+
+
+
+
+
+
+
+
−
+
−
−
∼
+

Comments

not well suported

ﬁltering not well supported

visual search

large display space

access to much information

visual search

large display space

easy to organize with more space

visual search

distributed cognition

interaction-heavy

visual search

interaction-heavy

storytelling not well supported

comparisons easier
immersive displays

Table 1: Summary of support of sensemaking activities through immersive ana-
lytics systems. ‘+’ indidates good, ‘∼’ partial, and ‘−’ little or no support.

In Table 1 we list all steps in the sensemaking process and deﬁned how well
they are supported by current immersive systems. Steps that rely mostly on visual
perception or scanning (e. g., steps 3,6,9,12,15,16) and/or can beneﬁt from
large interactive display spaces to organize information (e. g., steps 4,5,7,8,9)
are already reasonably well supported by immersive systems. On the other hand,
steps that are interaction-heavy, potentially require substantial amounts of text
to be entered, or require the user to externalize complex thoughts “through”
the system (e. g., steps 1,11,13,14) are less well supported. This highlights the
potential need for complementary methods to support such steps.

5. Immersive Human-Centered Computational Analytics

153

Moreover, the fact that some steps are better supported than others also
poses the question of whether immersion is needed for all parts of an analysis
process? Given that current systems do not support all sensemaking steps well,
we believe that it is prudent to support easy, rapid and seamless switching in and
out of immersion. An illustrative example is that an analyst may want to switch
out of an immersive system to write up a page of a report about the insights
gained from the current immersive session in a word processor and then go back
into the immersive system to hunt for additional insights. Similarly, switching
out of the immersive system to ask a colleague to bounce ideas around for the
exact formulation of a hypothesis. Or someone who has to engage with a long,
complex text document and (due to individual preferences) wants to read it on
a tablet in a more comfortable setting. All these scenarios point out that the
transition into and out of, or between diﬀerent forms of, immersive analytics
systems needs to be well supported, too.

Overall, some parts become easier, some parts are harder in immersive envi-
ronments. Thus, there is no clear win-win situation, but there are many trade-oﬀs
that post challenges to user interface and system designers. Interestingly, the
diﬃculties identiﬁed here match, at least to some degree, the challenges that
occur in other types of visual analytics systems. This highlights again major
avenues for future work.

Below we discuss a new lens on the Pirolli-Card model, which incorporates
automatic processes into the sensemaking process. In general, collaboration is
an essential component of data analytics, and we discuss this in the following
section.

5.3. Collaboration between Humans and Automated

Processes

In this subsection, we discuss how immersive analytics systems can assist with
sensemaking at larger scales. In particular, we target situations where multiple
people are working together and are assisted by multiple automatic processes.
The (potentially inﬁnite) space available in immersive environments provides an
appropriate “canvas” for all intermediate results in such a collaboration.

At this point, we consider an extended sensemaking loop, where multiple
people interact with an evolving (intermediate) set of computationally gener-
ated/reﬁned and human-mediated analysis results and insights. Much of the
work discussed in the Chapter 8, such as maintaining awareness, applies to both
human and machine actors. Here we discuss only aspects that are central to
immersive analytics.

A tenet of successful collaborations is that the actions of any single actor (be
they humans or algorithms) should never destroy other actors’ work (without
their consent). This means that multiple, potentially parallel, analyses and/or
scenarios need to co-exist and the system needs to support them and their
management. Moreover, it should be possible to merge advances of work on a
given analysis/scenario into other analyses/scenarios to avoid re-doing of work.

154

Stuerzlinger et al.

While source-code control systems are a traditional way to handle branching and
merging of text documents, the visual nature of immersive analytics makes it
necessary to explore graphical user interfaces for branching and merging. Here
it is important to point out that structured code documents are fundamentally
diﬀerent from free-ﬂowing text or graphical content and that source-code control
systems are not necessarily the best way to handle such content. A recent
exploration in this direction presented a graphical user interface for parallel work
in the domain of generative design [58] and these ideas seem directly applicable
to immersive analytics.

One of the primary reasons for sensemaking tools is to help people deal with
more information than can comfortably be managed by an individual. Thus, it
seems intuitive (and is also supported by research [2, 19]) that larger displays
can enhance people’s sensemaking abilities.

Maintaining awareness of the activities of others in the system (both human
and automated) is a challenge. With multiple actors, it becomes necessary to
keep track of who did and modiﬁed what, i. e., maintaining provenance of data
and annotations about the data need to be supported

An interesting facet of the challenge to maintain awareness is that changes by
other actors can impact an individual’s sensemaking activities. In the foraging
loop, either another individual or the computer can augment the search for
information based on the currently gathered information. When new information
is thus retrieved, this information can be added at the appropriate level of
abstraction. For example, new raw data could be added to the shoebox, new
relational data could be inserted into the evidence ﬁle, or a strong correlation
could be added as a potential hypothesis. The system can use visual cues such as
spatial organization or representation to help distinguish such new information
from previously examined information. As more of the models are built, the
system could automatically ﬂag information that supports or contradicts any
given conclusion–again using spatial or visual representation to help distinguish
the material.

As we scale a system to deal with more people and more automated processes,
the challenge of maintaining awareness of the activities of others increases. While
this is not unique to immersive environments, we can use certain aspects of
immersive environments to help manage that scale. In particular, we can move
from overviews of the data to focal areas while maintaining context. We can use
visual attributes in diﬀerent ways to show who (or what) has contributed new
information or what information may have changed since last viewed.

Just as we change the level of detail at which we might observe the information,
we can choose to have private views of the information in addition to a shared
view. In this way, we can locally modify information without destroying the work
of others. This poses yet more challenges with respect to version control of the
information, rolling the system back to previous organizations and models of the
data.

5. Immersive Human-Centered Computational Analytics

155

5.3.1. Human-in-the-loop Analytics
Immersive analytics seeks to broaden the bandwidth of communication between
machine and human through more complete engagement of human sensorial
perception (in the machine-to-human direction) and more ﬂuid interaction (in the
human-to-machine direction). We have discussed in previous sections and chapters
the challenges involved in designing improved multisensory displays and more
natural and expressive interaction devices and techniques. However, even assuming
these challenges can be met to create a higher-bandwidth communication channel
between machine and human, there remain a number of technical challenges in
order to create completely immersive data analytics experiences. In particular,
we focus in this section on the algorithmic and system architecture requirements
that must be met to:
1. open algorithms to the possibility of human-in-the-loop control;
2. ensure responsiveness of algorithms in the face of the dynamic changes to

parameters or the underlying data.
These challenges can arise in scenarios such as:

– large quantities of data, i. e. scalability;
– data changing in real-time, e. g. from streaming data feeds;
– prediction and optimization that can deal with uncertainty;
– synchronizing and scheduling long-running processes.

These challenges are not unique to immersive analytics scenarios and progress
has been made in these areas in a number of ﬁelds, such as data mining. However,
it is arguable that the focus on user-engagement in immersive analytics systems
and the potential for this higher-bandwidth communication channel, make these
requirements for interactive data analysis systems more pressing than ever. Thus,
this section provides a survey of the state-of-the-art in the area of design patterns
and issues involved in engineering algorithms to be responsive.

Immersive Algorithms (Live feedback and control) The research ﬁeld of
Human-Computer Interaction has long recognized the importance of minimizing
delay. For example, in 1968 Miller described this not only as an “operational
need” (the computer has to respond to a command before the plane crashes
into the mountain) but also as a “psychological need” [38]. Card et al. later
quantiﬁed the desirable limits on delay in an information visualization system [6],
identifying three distinct time constants that a system must meet:
Perceptual processing - 0.1 second was the time they considered acceptable

for a screen refresh.

Immediate response - 1 second was nominated as about the time a human
takes to acknowledge (not necessarily answer) a question. This was therefore
suggested as a reasonable upper limit on the time an automated agent in an
information visualization system might reasonably take to respond.

156

Stuerzlinger et al.

Unit task - 10 seconds was considered a reasonable time limit on completing

a basic task or operation in the system.
These three basic time constants have become “rules-of-thumb” for user inter-
face design [40, Chapter 5] and lore around acceptable latency for asynchronous
interfaces, for example in web design [41]. However, advances in technology have
arguably made some of these time limits seem generous. For example, predictive
interfaces such as autocomplete (originally conceived as an accessibility feature
for keyboards [15]) are now an integral part of both web and desktop search and
routinely oﬀer results to queries in signiﬁcantly less than a second.

Similarly, advances in display and interaction hardware have shown that users
of multitouch displays not only perceive but can be adversely aﬀected by latencies
of signiﬁcantly less than 0.1 seconds [39]. In VR, latencies of more than about
20 milliseconds, from tracking of head-position movement to re-rendering the
view, not only ruin immersion but can make users ill [7].

This section describes what conditions analytics algorithms have to fulﬁll to
allow for immersive analytics. A potential metaphor is that immersive analytics
means human and machine co-processing. We survey classes of data analysis and
data production algorithms and name necessary requirements as well as enhancing
properties for data analytics. Furthermore, we give examples of algorithms that
are close to fulﬁlling the minimal requirements of immersive analytics. Typical
requirements are:
(1) Immediate, or seemingly immediate, feedback in the sense that there is no
human impression of latency. This includes situations where the human
triggers the rerun of an analysis of a larger subset of the data or reruns a
simulation that may necessarily take time, but where the human still needs
feedback indicating the status of the computation.

(2) Possibilities for the human to control, steer or interfere with the algorithm.
(3) Allowance for human reasoning about the algorithmic results, e. g.allow for
human co-processing. This requires mechanisms for the human to look behind
the curtain, i. e. any black box method must allow for human inspection on
request if the human questions the computer.
While a complete fulﬁllment of these requirements provides an open challenge,
in many cases there are algorithmic developments in recent years heading in the
right direction. Some examples by ﬁeld:
Data Mining: There already exist data mining algorithms that support stream-
ing results. As an example, there is work on data stream clustering, for example,
Silva et al. [50]. However, taking the human back into the loop is an open
challenge.
Clustering: Other classes of clustering algorithms allow users to manually
steer the clustering process. Such algorithms use strategies like semi-supervised
clustering where must-link and cannot-link constraints are added by the user
as in BoostCluster [32]. Another class of such algorithms are subspace search
and grouping of similar subspaces that incorporate the user into the clustering,
see [54].

5. Immersive Human-Centered Computational Analytics

157

Optimization: Optimization and operations research are discovering the impor-
tance of human-in-the-loop operation, recognizing that not every optimization
problem can be completely modeled and then solved in isolation [37]. In multi-
objective optimization, strategies like exploring Pareto frontiers allow for human
co-processing [55]. Goodwin et al. [22] explore requirements for visual proﬁling of
Constraint Programming solvers. Liu et al. [31] explore the relationship between
interactive optimization and visual analytics, proposing a “problem-solving loop”
for optimization, analogous to the sensemaking loop.
Text Analytics: Interactive topic modeling enables users to view and reﬁne
analyses of large document collections [11]. Some existing systems allow the user
to deﬁne relations between documents spatially to the machine so algorithms can
take this into account to incrementally update topic models, for example [20].
Dimension Reduction: With respect to dimension reduction techniques, there
are ideas like probing [52] allowing human analysts to gain an understanding of
the projections using interaction, or direct manipulation of the projection output
to explore projection parameter spaces [17].
Scientiﬁc Simulation: For ﬂow simulations, there are some methods that
allow the interactive study of particle traces including interactive seeding of
additional particles [48]. In similar scientiﬁc contexts, some feature detection
systems allow for interactive feature deﬁnition [16]. While this has been explored
for point-based feature detection, this may also be beneﬁcial for particle-based
feature extraction [47]. Even topological data analysis algorithms have important
parameters with respect to simpliﬁcation and interactive presentation, as well as
further inspection [25]. Here, immersive interaction opens the way for a deeper
human understanding of structural data properties.
Information Theory: There are also ideas to use information theory to ﬁnd
unusual data, e. g.by measuring entropy [29]. However, methods that allow the
human to indicate which part of the data has highly informative content are
missing to date.

Some general questions have not been addressed appropriately, for example,

how can an algorithm explain to the human how its conclusions are reached?

5.4. Challenges

From the extended sensemaking loop we identify some aspects that can be
improved through immersive design principles. In the following we identify some
examples for existing paths through–and potential for new extensions of–the
sensemaking loop.

5.4.1. The Role of Alternatives
Good analysis practice considers alternative explanations for any given obser-
vation, often in the form of more or less explicit hypotheses. Another form of
alternatives occurs in the visual analytics process through diﬀerent views of the
same data, including comparisons and multi-scale views. Yet, such alternatives

158

Stuerzlinger et al.

are not just a part of the process to arrive at insights, they can also play a
central role to enable collaborative work between humans while also integrating
algorithmic assistance.

Consider a group working asynchronously together. To avoid the potential
for destruction of each other’s work, it is necessary that any visual analytics
system can support parallel, independent alternative views and interactions. If
multiple people work independently on the same content, such as a dashboard,
it is appropriate for the system to support such parallel work, e. g., by keeping
people aware of other changes. But as network connections cannot always be
taken as granted, the support for post hoc integration of changes (aka post hoc
merging), is also highly beneﬁcial.

Full support for asynchronous work also enables more seamless integration
of machine assistance. A notable issue here is that machine processes can take
indeterminate amounts of time to ﬁnish. Having (multiple) humans wait on a
machine is not appropriate for modern workﬂows, especially if the results provided
by the algorithmic assistance are not part of the core thread of work, such as
speculative machine optimization building on human-derived results. This can be
addressed by supporting alternatives and thus alternative threads of work as ﬁrst-
class citizens directly in the system [35]. Then one could start an ensemble solver,
any form of optimization process, or some system that automatically explores the
solution space, and be assured that the results of that computation are, once they
are available, easily integrated into the whole workﬂow as a separate alternative
or have the option to merge these results (wholly or partially) into the work by
humans or other algorithms, as appropriate or needed.

5.4.2. Human Control of Computational Analytical Processes

Immersive analytics oﬀers new opportunities for human-centered interactive
analytics. By focusing on the sensemaking loop, we make clear that human
sensemaking tasks are the central considerations around which computational
analytics can be designed and situated [20]. Immersive analytics whole-heartedly
takes this point of view by immersing the user in the sensemaking process
and contextualizing computational support in the immersive sensemaking space.
This leads to new challenges in the design of immersive interactive controls for
computational analytics.

The large physical and/or virtual spaces oﬀered by immersive environments
can be exploited to support the synthesis portion of sensemaking, such as schema-
tizing, by giving analysts “space to think” [2] (Figure 4). Analysts use the space
to interactively externalize cognitive schemas by organizing information into
series, clusters, and other spatial structures. Over time, analysts “incrementally
formalize” their hypotheses via course- or ﬁne-grained adjustments to these
spatial structures [49]. These immersive interactions can be exploited as human-
in-the-loop feedback for computational analytics and semi-supervised machine
learning algorithms that support the sensemaking process, such as user-guided
dimension reduction for spatialization of text corpora [18].

5. Immersive Human-Centered Computational Analytics

159

Fig. 4: Space to think: An analyst is immersed in a large sensemaking space,
organizing a schema of textual data in collaboration with machine learning
algorithms [2,4].

A key challenge is designing immersive interactions that provide relevant
input to computational analytics and designing computational analytics that
appropriately support such user feedback [35]. One of the principles of Semantic
Interaction [18] is to exploit existing cognitive operations that sensemakers
naturally apply in physical environments, such as organizing and annotating, and
re-casting these cognitive-level interactions into low-level feedback required by
computational algorithms. Since these interactions are likely to be incremental
in nature, it is important that the algorithms are designed such that they (1) do
not require complete speciﬁcation of all parameters up front, and (2) support
incremental model learning [49].

Immersive environments oﬀer opportunities for rich, multi-modal interactions,
through many kinds of input devices and tracking many kinds of human analytic
behaviors, to control computation. Subtle cues can be recognized and used to
steer computational analytics. For example, big data computation can be steered
onto areas of human focus of attention in the space, such as via gaze tracking, to
provide just-in-time results [26]. Multiple degrees of freedom in the interaction
space can oﬀer more ﬂuent control for parallel input. This enables the possibil-
ity for more eﬃciently steering multidimensional parameter spaces of complex
analytics, manipulating multiple parameters and constraints for ensembles, or si-
multaneously specifying operations and target data. Immersive analytics can also
support interaction with larger amounts of data at multiple levels of scale, such
as manipulating many data objects via multi-touch [42] or physical-navigation
aware cone-casting [43] methods. Multiple input devices can be used to exploit
the most appropriate interactive aﬀordances for each sensemaking task [13]. These
complex interactions, such as simultaneously controlling several parameters, are
typically a skill that requires training and thus create new usability challenges.
However, immersive environments also pose some diﬃculties for user input to
computation. Immersive environments may have less precise input controls that
would need to be supplemented with computational support. Also, text input in
immersive systems is a notable challenge. Text input is useful for many tasks that
cannot easily be solved when using pointing, such as annotating, formulating

160

Stuerzlinger et al.

a hypothesis, or building a case. Speech recognition is a potential solution, but
error recovery (after either the speech recognizer or the human makes a mistake)
typically requires a surprisingly large amount of time with speech recognition.
Another design challenge is supporting transitions into and out of the immer-
sive environment or between forms of immersive environments. For example, a
user takes oﬀ an HMD to sketch on a tablet for designing a new computationally-
generated visualization and then goes back into the HMD to see how the ﬁnal
result looks. Such transitions might be necessary due to the limited display
resolution of the HMD or the limited tracking of pen-based input in an HMD
environment. Similar transitions need to be considered for transitioning between
individual and collaborative sensemaking tasks.

A ﬁnal challenge is recording interaction history for provenance purposes,
such as computational checkpointing. This is already a challenge in current visual
analytics systems but becomes an even bigger challenge in immersive analytics
systems due to the need to consider the current viewpoint and/or location in space
of the users at any given time. For augmented reality applications, provenance
systems may also need to take snapshots of how the world looked at each point
in time, for example, to determine if a given person or object was present.

5.4.3. Computational Output in Immersive Analytics
There are a number of challenges and opportunities that arise in embedding
computational analytical results in interactive immersive environments in ways
that support the collaborative sensemaking process.

Holistic approach to the collaborative sensemaking loop: Rather than
treating each step in the sensemaking process as a distinct tool, immersive analyt-
ics seeks to integrate the processes in a common space with common operations.
A holistic approach can help to better support the many interconnections between
the looping steps of the sensemaking process. This is important because analysts
make many rapid iterations through portions of the sensemaking loop during the
course of an analysis. This is exacerbated by the presence of multiple collaborating
human and computational agents, each potentially working at diﬀerent stages
within the sensemaking loop. For example, in the sensemaking concept of “dual
search”, analysts must seek to simultaneously ﬁnd hypotheses that explain the
given evidence and also ﬁnd evidence that supports their hypotheses [44]. An
integrated approach can help analysts to more eﬃciently propose, and conﬁrm
or refute hypotheses.

A challenge for immersive analytics is the design of such uniﬁed spaces, and
the design of the visual representations, interactive links, and computational
processes that connect the steps of the sensemaking process. Designs should
seek to minimize breaks in immersion across task boundaries. For example, with
“synthesis driven foraging” (e. g.Starspire [4], as in Figure 4), human interactions
in the later synthesis-oriented stages of sensemaking, such as schematizing and
hypotheses generation, can automatically drive computational re-foraging for
supporting evidence in the earlier stages of sensemaking. Results would then be
immediately visualized for their impact on the hypotheses and enable further

5. Immersive Human-Centered Computational Analytics

161

synthesis operations by the analysts. A particular opportunity with the holistic
approach is overcoming conﬁrmation bias. Since human analysts frequently suﬀer
this problem, computational agents can be utilized to speciﬁcally seek and display
refuting information.

Embedding users in computational workﬂows: An important oppor-
tunity in immersive analytics is to exploit the large physical and/or virtual
spaces oﬀered by immersion to visually represent complex analytical workﬂows,
along with concomitant parameters and results at each stage. Increasingly com-
plex computational analytic workﬂows lead to an overload of human short-term
memory and diﬃculties in human understanding of the results. As an initial
solution, visualization researchers have explored the use of visual representa-
tions of computational workﬂows, such as iconic representations of process steps
(e. g.VisTrails [3]). This is particularly important in human-in-the-loop analytics,
where the computational workﬂows are designed to reﬂect the steps of the human
sensemaking loop.

A challenge of immersive analytics is the design of representations that vi-
sually embed the user and the computational results directly into the workﬂow
representation. This approach can simultaneously represent the parameters and
full outputs of multiple stages of the workﬂow, potentially enabling the user to
navigate and compare results along the computational pipeline, thus support-
ing rapid progress through the sensemaking loop [46]. Multiple users can be
simultaneously embedded to analyze diﬀerent portions of the workﬂow while
maintaining awareness of each other, similar to analogous physical organizations
of collaborative human activity such as air traﬃc control [33].

With these methods, immersive analytics can help to open the analytical
black-box by enabling users to see inside the workﬂow, participate in various
steps of the workﬂow, and directly relate inputs to process to outputs. Such
an introspection capability could lead to better user control of computational
analytics and increased trust in algorithmically generated results [12]. Additional
opportunities arise in annotating and examining the provenance of process and
results, such as visualizing which source data contributed to certain output results
throughout the entire analytical workﬂow [45].

Contextualizing computational feedback in human sensemaking: To
support human sensemaking, computational analytic results can be contextualized
directly within the human sensemaking process. Previously we have described
how sensemakers exploit immersive spaces to externalize their cognitive process
and construct organized schemas of information. Supervised learning algorithms
can use such input to compute relevant results, and then display these results
directly in connection to the inputs. A principle of Semantic Interaction [18] is to
represent computational feedback within the context of the cognitive constructs
in the immersive space. This can help analysts to better connect computational
results to their own cognitive work than if the results were displayed separately
elsewhere. The resulting space is a blending of computational and human-created
schemas, representing a collaborative eﬀort between cognition and computation.

162

Stuerzlinger et al.

Immersive environments provide meaningful space for such computational
enrichment of the user input. In a sense, the large spaces oﬀered by immersive
environments provide a form of common ground between cognition and compu-
tation. The principles of spatial and distributed cognition emphasize the role
of the physical spatial environment in human cognition [27]. Meanwhile, many
data analytic methods exploit spatial metaphors such as distance metrics and
triangle inequalities. Thus, space oﬀers a rich medium for interaction between
the computer and human.

A challenge is designing visual representations that re-cast computational
output into task-oriented elements in the human sensemaking process. For exam-
ple, in StarSpire [4], the user interest model that is learned by the computational
algorithms in the form of keyword weights is visualized to the user by highlighting
those keywords directly in the documents that they are reading with a color
brightness that is proportional to their weight in the model. This explicitly
supports the human sensemaking task of foraging for relevant information in the
documents, but also implicitly gives the user feedback about the model state.

Managing user attention: A particular challenge in immersive analytics
is managing users’ attention in the immersive space in the presence of new or
changing information that results from computational processes. For example,
computational processes can be used to suggest regions of particular interest in
a large space of results (e. g.Voyager [57]), to ﬁnd latent connections between
spatially distant information on the display (e. g.VisLink [14]), or to progressively
reﬁne streaming data or large computations on big data (e. g. [21]).

When small or non-obvious changes take place, such as new computational
results appearing out of the user’s current viewing frustum, the notiﬁcation
problem arises [36]. The question is how to alert users to the new information
in a clear and yet unobtrusive fashion. Immersive environments can exploit
additional human embodied resources such as peripheral vision or soniﬁcation to
subtly notify users of changes [26].

At the other end of the spectrum, when very large changes take place, such
as a complete re-organization of the space based on the results of a dimension
reduction algorithm, can be overwhelming and disorienting to an immersed user.
This leads to the need for methods analogous to “smooth and eﬃcient zoom and
pan” [56] that attempts to minimize optical ﬂow during navigation by zooming
out before signiﬁcant panning, making use of the larger frame of reference.
Similarly, incremental approaches such as incremental learning algorithms or
animated force-directed layouts, combined with landmark persistence, can help
users maintain orientation while exploring new results (e. g.ForceSpire [18]).

Representing sensemakers: In immersive analytics, actors in the sense-
making process can be visually represented in the sensemaking space to make
the collaboration more clear. A challenge is creating avatars or other forms of
representations of both human and computational agents, enabling collaborators
to see what part of the data or sensemaking process activities others are working
on and potentially share perspectives [34]. With augmented reality, actors might
be represented physically. For example, “Be the Data” [10] enables collaborating

5. Immersive Human-Centered Computational Analytics

163

students to take on the perspectives of individual data points as they are ma-
nipulated by dimension reduction algorithms, and directly visualize distances
between points as distances between people in the space.

5.5. Conclusion

In this chapter, we discussed higher-level concerns of the sensemaking process
around data, corresponding to Strategic Immersion, similar to high-level problem-
solving in games [1], and analyzed how immersive environments can help here.
We also looked at how immersive environments can help with the integration
of automatic processes, such as machine optimization and learning, into the
analytics workﬂow and the user’s role in a large-scale collaborative analytics
process with both other people and machine assistance. This is a natural step in
the integration of interactive data analytics capabilities with modern machine
learning methods. Such integration also satisﬁes the growing need to be able to
explain data analytics results to others. Consider having to defend the choices
made–by human or algorithmic data analyst–to a superior or a judge. Finally,
we also looked at some of the technical requirements associated with doing data
analytics in immersive environments.

There are a variety of avenues for future research. These include:

– Can–and if so, how can–immersive environments enable users to think about,
and deal with, more complex problems than is currently possible on desktop
platforms. This is especially a challenge when one considers that it may be
necessary to employ multiple actors, both human and automatic, working
together to solve such problems.

– How can we use immersion to amplify human intelligence, intuition, and
creativity? Speciﬁcally, this targets the higher-level process and provenance
tasks described in Section 5.2., schematization and hypothesis generation
(and testing). These high-level cognitive processes remain relatively poorly
understood and thus this is a signiﬁcant research challenge.

– How can immersion be used to advance human collaboration with com-
putational processes? In particular, what new opportunities do immersive
environments provide to enable human interaction with the inputs and out-
puts of computational analytics?

– Many of the current limitations for immersive analytics are technological.
Research needs to provide an understanding of human capabilities for under-
standing analytics, given future technological capabilities. For example, by
lifting the arbitrary limitation imposed by the display space of current desk-
top environments, can we imagine or prototype environments that overcome
those limitations in order to discover where the next challenges lie?

– How can we minimize artiﬁcial breaks in immersion/engagement–especially
across task boundaries? And if we require users to break their immersion,
e. g.when switching from an HMD to keyboard input and back, how can we
keep their engagement intact?

164

Stuerzlinger et al.

– One of the premises of this chapter has been that ideas from game design
which promote immersion, engagement, and ﬂow, can be beneﬁcially brought
to data analytics and sensemaking. Are there additional opportunities in this
vein? For example, another potential avenue of future work is to explore the
gamiﬁcation of the immersive analytics process.

– A ﬁnal future consideration is the evaluation of sensemaking activities in
immersive analytics environments. There are opportunities for evaluation
of immersive systems, for example, in many such systems gesture control
and immersive rendering necessitate head and body position tracking. Thus,
we can collect a fairly complete model of user interaction which could be
further enriched with other biometric data collection, e. g. pulse-rate, aﬀective
measures or even cortisol levels. With such a complete model we can study
peoples’ patterns of interaction during sensemaking and ultimately better
understand this complex activity.

Acknowledgements

Dwyer acknowledges support by the Australian Research Council Discovery
Scheme, project DP180100755.

References

the

E.:

and

1. Adams,
ernism
//www.gamasutra.com/view/feature/130531/the_designers_notebook_.php

notebook:
immersion(2004),

designer’s
types
of

The
3

Postmod-
http:

2. Andrews, C., Endert, A., North, C.: Space to think: large high-resolution displays
for sensemaking. In: Proceedings of the SIGCHI Conference on Human Factors in
Computing Systems. pp. 55–64. ACM (2010)

3. Bavoil, L., Callahan, S.P., Crossno, P.J., Freire, J., Scheidegger, C.E., Silva, C.T.,
Vo, H.T.: Vistrails: enabling interactive multiple-view visualizations. In: VIS 05.
IEEE Visualization, 2005. pp. 135–142(Oct 2005) doi: 10.1109/VISUAL.2005.
1532788

4. Bradel, L., North, C., House, L., Leman, S.: Multi-model semantic interaction
for text analytics. In: 2014 IEEE Conference on Visual Analytics Science and
Technology (VAST). pp. 163–172(Oct 2014) doi: 10.1109/VAST.2014.7042492

5. Card, S.K., Mackinlay, J.D., Shneiderman, B.: Readings in information visualiza-

tion: using vision to think. Morgan Kaufmann (1999)

6. Card, S.K., Robertson, G.G., Mackinlay, J.D.: The information visualizer, an
information workspace. In: Proceedings of the SIGCHI Conference on Human
Factors in Computing Systems. pp. 181–186. ACM (1991)

7. Carmack,

J.:

Latency

mitigation

strategies(2013),

https:

//www.twentymilliseconds.com/post/latency-mitigation-strategies/

8. Ceneda, D., Gschwandtner, T., May, T., Miksch, S., Schulz, H.J., Streit,
M., Tominski, C.: Characterizing guidance in visual analytics. IEEE Trans-
actions on Visualization and Computer Graphics 23(1), 111–120(Jan 2017),
https://doi.org/10.1109/TVCG.2016.2598468 doi: 10.1109/TVCG.2016.2598468

5. Immersive Human-Centered Computational Analytics

165

9. Cernea, D., Ebert, A., Kerren, A.: A study of emotion-triggered adaptation
methods for interactive visualization. In: UMAP 2013 Extended Proceedings:
Late-Breaking Results, Project Papers and Workshop Proceedings of the 21st
Conference on User Modeling, Adaptation, and Personalization. CEUR workshop
proceedings, vol. 997, pp. 9–16. CEUR-WS.org (2013)

10. Chen, X., Self, J.Z., House, L., North, C.: Be the data: a new approach for
immersive analytics. In: IEEE Virtual Reality Workshop on Immersive Analytics
(2016)

11. Choo, J., Lee, C., Reddy, C.K., Park, H.: Utopian: User-driven topic modeling
based on interactive nonnegative matrix factorization. IEEE Transactions on
Visualization and Computer Graphics 19(12), 1992–2001 (Dec 2013)

12. Chuang, J., Ramage, D., Manning, C., Heer, J.: Interpretation and trust: Designing
model-driven visualizations for text analysis. In: Proceedings of the SIGCHI
Conference on Human Factors in Computing Systems. pp. 443–452. ACM (2012)
13. Chung, H., North, C., Joshi, S., Chen, J.: Four considerations for supporting
visual analysis in display ecologies. In: 2015 IEEE Conference on Visual Analytics
Science and Technology (VAST). pp. 33–40 (Oct 2015)

14. Collins, C., Carpendale, S.: Vislink: Revealing relationships amongst visualizations.
IEEE Transactions on Visualization and Computer Graphics 13(6), 1192–1199(Nov
2007) doi: 10.1109/TVCG.2007.70521

15. Darragh, J.J., Witten, I.H.: Adaptive predictive text generation and the reactive

keyboard. Interacting with Computers 3(1), 27–50 (1991)

16. Doleisch, H.: SimVis: Interactive visual analysis of large and time-dependent 3d
simulation data. In: Proceedings of the 39th Conference on Winter Simulation:
40 years! The best is yet to come. pp. 712–720. IEEE Press (2007)

17. Endert, A., Han, C., Maiti, D., House, L., Leman, S., North, C.: Observation-level
interaction with statistical models for visual analytics. In: 2011 IEEE Conference
on Visual Analytics Science and Technology (VAST). pp. 121–130 (Oct 2011)

18. Endert, A., Fiaux, P., North, C.: Semantic interaction for sensemaking: inferring
analytical reasoning for model steering. IEEE Transactions on Visualization and
Computer Graphics 18(12), 2879–2888 (2012)

19. Endert, A., Fox, S., Maiti, D., North, C.: The semantics of clustering: analysis of
user-generated spatializations of text documents. In: Proceedings of the Interna-
tional Working Conference on Advanced Visual Interfaces. pp. 555–562. ACM
(2012)

20. Endert, A., Hossain, M.S., Ramakrishnan, N., North, C., Fiaux, P., Andrews, C.:
The human is the loop: new directions for visual analytics. Journal of intelligent
information systems 43(3), 411–435 (2014)

21. Fisher, D., Popov, I., Drucker, S., schraefel, m.: Trust me, I’m partially right:
Incremental visualization lets analysts explore large datasets faster. In: Proceedings
of the SIGCHI Conference on Human Factors in Computing Systems. pp. 1673–
1682. ACM (2012)

22. Goodwin, S., Mears, C., Dwyer, T., de la Banda, M.G., Tack, G., Wallace, M.: What
do constraint programming users want to see? Exploring the role of visualisation in
proﬁling of models and search. IEEE Transactions on Visualization and Computer
Graphics 23(1), 281–290 (2017)

23. Heer, J., Mackinlay, J., Stolte, C., Agrawala, M.: Graphical histories for visu-
alization: Supporting analysis, communication, and evaluation. IEEE Transac-
tions on Visualization and Computer Graphics 14(6), 1189–1196(Nov 2008),
http://dx.doi.org/10.1109/TVCG.2008.137 doi: 10.1109/TVCG.2008.137

166

Stuerzlinger et al.

24. Heer,

J., Shneiderman, B.:

visual
sis. Communications
2012),
//doi.acm.org/10.1145/2133806.2133821 doi: 10.1145/2133806.2133821

Interactive dynamics

for
45–54(Apr

the ACM 55(4),

of

analy-
http:

25. Heine, C., Leitte, H., Hlawitschka, M., Iuricich, F., De Floriani, L., Scheuermann,
G., Hagen, H., Garth, C.: A survey of topology-based methods in visualization.
Computer Graphics Forum 35(3), 643–667 (2016)

26. Heun, V., von Kapri, A., Maes, P.: Perifoveal display: Combining foveal and
peripheral vision in one visualization. In: Proceedings of the 2012 ACM Conference
on Ubiquitous Computing. pp. 1150–1155. UbiComp ’12, ACM (2012)

27. Hollan, J., Hutchins, E., Kirsh, D.: Distributed cognition: Toward a new foundation
for human-computer interaction research. ACM Transactions on Computer-Human
Interaction 7(2), 174–196 (Jun 2000)

28. Isenberg, P., Elmqvist, N., Scholtz, J., Cernea, D., Ma, K.L., Hagen, H.: Collabo-
rative visualization: Deﬁnition, challenges, and research agenda. Information Visu-
alization 10(4), 310–326(Oct 2011), http://dx.doi.org/10.1177/1473871611412817
doi: 10.1177/1473871611412817

29. Jänicke, H., Böttinger, M., Tricoche, X., Scheuermann, G.: Automatic detection
and visualization of distinctive structures in 3D unsteady multi-ﬁelds. Computer
Graphics Forum 27(3), 767–774 (2008)

30. Kerren, A., Schreiber, F.: Toward the role of interaction in visual analytics.
In: Proceedings of the Winter Simulation Conference. pp. 420:1–420:13. WSC
’12, Winter Simulation Conference(2012), http://dl.acm.org/citation.cfm?id=
2429759.2430303

31. Liu, J., Dwyer, T., Marriott, K., Millar, J., Haworth, A.: Understanding the
relationship between interactive optimisation and visual analytics in the context
of prostate brachytherapy. IEEE Transactions on Visualization and Computer
Graphics 24(1), 319–329 (2018)

32. Liu, Y., Jin, R., Jain, A.K.: Boostcluster: Boosting clustering by pairwise con-
straints. In: Proceedings of the 13th ACM SIGKDD international conference on
Knowledge discovery and data mining. pp. 450–459. ACM (2007)

33. MacKay, W.E.: Is paper safer? The role of paper ﬂight strips in air traﬃc control.

ACM Transactions on Computer Human Interaction 6(4), 311–340 (Dec 1999)

34. Mahyar, N., Tory, M.: Supporting communication and coordination in collaborative
sensemaking. IEEE Transactions on Visualization and Computer Graphics 20(12),
1633–1642(Dec 2014) doi: 10.1109/TVCG.2014.2346573

35. Makonin, S., McVeigh, D., Stuerzlinger, W., Tran, K., Popowich, F.: Mixed-
initiative for big data: The intersection of human+ visual analytics+ prediction.
In: 2016 49th Hawaii International Conference on System Sciences (HICSS). pp.
1427–1436. IEEE (2016)

36. McCrickard, D.S., Chewar, C.M., Somervell, J.P., Ndiwalana, A.: A model for
notiﬁcation systems evaluation—assessing user goals for multitasking activity.
ACM Transactions on Computer-Human Interaction (TOCHI) 10(4), 312–338
(2003)

37. Meignan, D., Knust, S., Frayret, J.M., Pesant, G., Gaud, N.: A review and taxon-
omy of interactive optimization methods in operations research. ACM Transactions
on Interactive Intelligent Systems (TiiS) 5(3), 17 (2015)

38. Miller, R.B.: Response time in man-computer conversational transactions. In:
Proceedings of the December 9-11, 1968, Fall Joint Computer Conference, part I.
pp. 267–277. ACM (1968)

5. Immersive Human-Centered Computational Analytics

167

39. Ng, A., Lepinski, J., Wigdor, D., Sanders, S., Dietz, P.: Designing for low-latency
direct-touch input. In: Proceedings of the 25th annual ACM symposium on User
interface software and technology. pp. 453–464. ACM (2012)

40. Nielsen, J.: Usability engineering. Elsevier (1994)
41. Nielsen,

J.: Web-based

application

response

time(2014),

https:

//www.nngroup.com/articles/response-times-3-important-limits/

42. North, C., Dwyer, T., Lee, B., Fisher, D., Isenberg, P., Robertson, G., Inkpen, K.:
Understanding multi-touch manipulation for surface computing. In: Proceedings
of the 12th IFIP TC 13 International Conference on Human-Computer Interaction:
Part II (INTERACT). pp. 236–249. Springer-Verlag (2009)

43. Peck, S.M., North, C., Bowman, D.: A multiscale interaction technique for large,
high-resolution displays. In: 2009 IEEE Symposium on 3D User Interfaces. pp.
31–38 (March 2009)

44. Pirolli, P., Card, S.: The sensemaking process and leverage points for analyst
technology as identiﬁed through cognitive task analysis. In: Proceedings of Inter-
national Conference on Intelligence Analysis. vol. 5, pp. 2–4 (2005)

45. Ragan, E.D., Endert, A., Sanyal, J., Chen, J.: Characterizing provenance in visu-
alization and data analysis: An organizational framework of provenance types and
purposes. IEEE Transactions on Visualization and Computer Graphics 22(1), 31–
40(Jan 2016), https://doi.org/10.1109/TVCG.2015.2467551 doi: 10.1109/TVCG.
2015.2467551

46. Ragan, E.D., Sowndararajan, A., Kopper, R., Bowman, D.A.: The eﬀects of
higher levels of immersion on procedure memorization performance and implica-
tions for educational virtual environments. Presence: Teleoperators and Virtual
Environments 19(6), 527–543 (2010)

47. Salzbrunn, T., Garth, C., Scheuermann, G., Meyer, J.: Pathline predicates and

unsteady ﬂow structures. The Visual Computer 24(12), 1039–1051 (2008)

48. Sauer, F., Zhang, Y., Wang, W., Ethier, S., Ma, K.L.: Visualization techniques
for studying large-scale ﬂow ﬁelds from fusion simulations. IEEE Computing in
Science and Engineering 18(2), 68–77 (March/April 2016)

49. Shipman, F.M., Marshall, C.C.: Formality considered harmful: Experiences, emerg-
ing themes, and directions on the use of formal representations in interactive
systems. Computer Supported Cooperative Work (CSCW) 8(4), 333–352 (1999)
50. Silva, J.A., Faria, E.R., Barros, R.C., Hruschka, E.R., de Carvalho, A.C., Gama,
J.: Data stream clustering: A survey. ACM Computing Surveys (CSUR) 46(1),
13 (2013)

51. Simmhan, Y.L., Plale, B., Gannon, D., Marru, S.: Performance evaluation of
the karma provenance framework for scientiﬁc workﬂows. In: Moreau, L., Fos-
ter, I. (eds.) Provenance and Annotation of Data: International Provenance and
Annotation Workshop, IPAW 2006, Chicago, IL, USA, May 3-5, 2006, Revised Se-
lected Papers, pp. 222–236. Springer Berlin Heidelberg, Berlin, Heidelberg(2006),
http://dx.doi.org/10.1007/11890850_23 doi: 10.1007/11890850_23

52. Stahnke, J., Dörk, M., Müller, B., Thom, A.: Probing projections: Interaction
techniques for interpreting arrangements and errors of dimensionality reductions.
IEEE Transactions on Visualization and Computer Graphics 22(1), 629–638
(2016)

53. Streit, M., Schulz, H.J., Lex, A., Schmalstieg, D., Schumann, H.: Model-
driven design for the visual analysis of heterogeneous data. IEEE Transac-
tions on Visualization and Computer Graphics 18(6), 998–1010(June 2012),
https://doi.org/10.1109/TVCG.2011.108 doi: 10.1109/TVCG.2011.108

168

Stuerzlinger et al.

54. Tatu, A., Maaß, F., Färber, I., Bertini, E., Schreck, T., Seidl, T., Keim, D.:
Subspace search and visualization to make sense of alternative clusterings in
high-dimensional data. In: IEEE Conference on Visual Analytics Science and
Technology (VAST). pp. 63–72. IEEE (2012)

55. Thieke, C., Küfer, K.H., Monz, M., Scherrer, A., Alonso, F., Oelfke, U., Huber, P.E.,
Debus, J., Bortfeld, T.: A new concept for interactive radiotherapy planning with
multicriteria optimization: ﬁrst clinical evaluation. Radiotherapy and Oncology
85(2), 292–298 (2007)

56. Van Wijk, J.J., Nuij, W.A.A.: Smooth and eﬃcient zooming and panning. In:
Proceedings of the Ninth Annual IEEE Conference on Information Visualization.
pp. 15–22. INFOVIS’03, IEEE Computer Society (2003)

57. Wongsuphasawat, K., Moritz, D., Anand, A., Mackinlay, J., Howe, B., Heer, J.:
Voyager: Exploratory analysis via faceted browsing of visualization recommenda-
tions. IEEE Transactions on Visualization and Computer Graphics 22(1), 649–658
(2016)

58. Zaman, L., Stuerzlinger, W., Neugebauer, C., Woodbury, R., Elkhaldi, M., Shireen,
N., Terry, M.: Gem-ni: A system for creating and managing alternatives in gen-
erative design. In: Proceedings of the 33rd Annual ACM Conference on Human
Factors in Computing Systems. pp. 1201–1210. ACM (2015)

59. Zimmer, B., Kerren, A.: Ongrax: A web-based system for the collaborative vi-
sual analysis of graphs. Journal of Graph Algorithms and Applications 21(1),
5–27(2017), http://dx.doi.org/10.7155/jgaa.00399 doi: 10.7155/jgaa.00399

","{""0"":{""0"":""sensemaking*"",""1"":""pirolli*"",""2"":""endert*"",""3"":""\ufb01nding*"",""4"":""sigchi*"",""5"":""speci\ufb01c""},""1"":{""0"":""data"",""1"":""information"",""2"":""process"",""3"":""results"",""4"":""loop"",""5"":""environments""},""2"":{""0"":""immersive"",""1"":""human"",""2"":""computational*"",""3"":""visualization*"",""4"":""computer"",""5"":""conference""},""3"":{""0"":""supported*"",""1"":""allow*"",""2"":""discuss"",""3"":""exploit*"",""4"":""related"",""5"":""describe*""},""4"":{""0"":""easier"",""1"":""parallel"",""2"":""vast*"",""3"":""excellent*"",""4"":""heavy*"",""5"":""immediate*""},""pos"":{""0"":1,""1"":2,""2"":3,""3"":4,""4"":5,""5"":6}}",2018,{},False,False,bookSection,False,RH3V72Q4,[],self.user,"{""C"":{""0"":7.6319854713,""1"":4.5714242215,""10"":11.4765663326,""11"":4.4952805946,""12"":5.359710377,""13"":4.8195142212,""14"":12.99364669,""15"":10.9749032753,""16"":5.8515876302,""17"":28.1978840021,""18"":8.2490418857,""19"":12.7210746875,""2"":6.6692558739,""20"":6.4121928366,""21"":4.2185353472,""22"":3.8897274651,""23"":22.7995078273,""24"":3.8338536297,""25"":10.6459751653,""26"":19.2345318669,""27"":8.6455704252,""28"":3.7829976824,""29"":3.6363570724,""3"":4.9264105821,""30"":3.8669140225,""31"":15.4303296442,""32"":16.1343851572,""33"":4.8080236443,""34"":8.4953409619,""35"":4.4632735275,""36"":4.4065449477,""37"":5.1065985255,""38"":4.6736824789,""39"":11.1320519984,""4"":4.8440721602,""40"":13.7004813947,""41"":4.5551451585,""42"":8.5537288859,""43"":5.2229447274,""44"":6.058874351,""45"":3.6459523963,""46"":3.9402191861,""47"":3.9563133626,""48"":5.239780208,""49"":6.1376826729,""5"":6.1097629534,""50"":4.5985926088,""51"":5.6688282585,""52"":3.8074949921,""53"":4.6283771194,""54"":6.3101487905,""55"":6.4239420663,""56"":4.8912686131,""57"":4.0458610535,""58"":6.5524436892,""59"":4.0583207745,""6"":8.7312288618,""60"":3.6606096803,""61"":4.4535777154,""62"":4.010211225,""63"":4.3838429952,""64"":4.4735344948,""65"":4.6769719067,""66"":6.5731106598,""67"":4.3838276293,""68"":6.0484143451,""69"":6.6050112396,""7"":5.7865261758,""70"":3.7337775181,""71"":4.8176401435,""72"":4.5209478348,""73"":4.685273075,""74"":4.7706291194,""75"":5.0563491522,""76"":5.2075207418,""77"":3.83053145,""78"":5.2935212973,""79"":4.2084847586,""8"":10.0787463014,""80"":4.3054199469,""81"":4.3523002205,""82"":3.7482970634,""83"":4.7078402189,""84"":4.5541167438,""85"":4.6321622225,""86"":4.3640501392,""87"":4.2746103141,""88"":4.6419871078,""89"":3.8910472643,""9"":4.2004377636,""90"":3.7831185283},""Unnamed: 0"":{""0"":0,""1"":1,""10"":10,""11"":11,""12"":12,""13"":13,""14"":14,""15"":15,""16"":16,""17"":17,""18"":18,""19"":19,""2"":2,""20"":20,""21"":21,""22"":22,""23"":23,""24"":25,""25"":26,""26"":27,""27"":28,""28"":29,""29"":30,""3"":3,""30"":31,""31"":32,""32"":33,""33"":34,""34"":36,""35"":37,""36"":38,""37"":39,""38"":40,""39"":42,""4"":4,""40"":43,""41"":44,""42"":45,""43"":47,""44"":48,""45"":49,""46"":50,""47"":52,""48"":53,""49"":54,""5"":5,""50"":55,""51"":56,""52"":57,""53"":58,""54"":59,""55"":60,""56"":61,""57"":62,""58"":63,""59"":64,""6"":6,""60"":65,""61"":66,""62"":67,""63"":68,""64"":69,""65"":70,""66"":71,""67"":72,""68"":73,""69"":74,""7"":7,""70"":75,""71"":76,""72"":77,""73"":78,""74"":79,""75"":80,""76"":81,""77"":82,""78"":87,""79"":90,""8"":8,""80"":91,""81"":92,""82"":93,""83"":94,""84"":95,""85"":96,""86"":97,""87"":98,""88"":99,""89"":100,""9"":9,""90"":101},""count"":{""0"":218,""1"":218,""10"":68,""11"":66,""12"":66,""13"":62,""14"":62,""15"":58,""16"":52,""17"":50,""18"":48,""19"":46,""2"":196,""20"":44,""21"":42,""22"":42,""23"":42,""24"":36,""25"":36,""26"":36,""27"":32,""28"":32,""29"":30,""3"":176,""30"":30,""31"":28,""32"":28,""33"":26,""34"":22,""35"":22,""36"":20,""37"":20,""38"":20,""39"":20,""4"":134,""40"":18,""41"":18,""42"":18,""43"":16,""44"":16,""45"":16,""46"":16,""47"":14,""48"":14,""49"":14,""5"":120,""50"":12,""51"":12,""52"":12,""53"":12,""54"":12,""55"":12,""56"":10,""57"":10,""58"":10,""59"":10,""6"":118,""60"":10,""61"":10,""62"":10,""63"":10,""64"":10,""65"":10,""66"":8,""67"":8,""68"":8,""69"":8,""7"":104,""70"":8,""71"":8,""72"":8,""73"":8,""74"":8,""75"":8,""76"":8,""77"":8,""78"":8,""79"":6,""8"":84,""80"":6,""81"":6,""82"":6,""83"":6,""84"":6,""85"":6,""86"":6,""87"":6,""88"":6,""89"":6,""9"":74,""90"":6},""exemplar"":{""0"":null,""1"":null,""10"":null,""11"":null,""12"":null,""13"":null,""14"":null,""15"":null,""16"":null,""17"":null,""18"":null,""19"":""*"",""2"":null,""20"":""*"",""21"":null,""22"":null,""23"":null,""24"":null,""25"":null,""26"":null,""27"":""*"",""28"":null,""29"":null,""3"":null,""30"":null,""31"":null,""32"":null,""33"":""*"",""34"":null,""35"":null,""36"":null,""37"":""*"",""38"":null,""39"":null,""4"":""*"",""40"":""*"",""41"":null,""42"":""*"",""43"":null,""44"":null,""45"":null,""46"":null,""47"":null,""48"":null,""49"":null,""5"":null,""50"":null,""51"":null,""52"":null,""53"":""*"",""54"":""*"",""55"":""*"",""56"":null,""57"":null,""58"":null,""59"":null,""6"":null,""60"":null,""61"":null,""62"":null,""63"":""*"",""64"":""*"",""65"":null,""66"":null,""67"":null,""68"":null,""69"":""*"",""7"":""*"",""70"":null,""71"":null,""72"":null,""73"":null,""74"":null,""75"":null,""76"":""*"",""77"":null,""78"":null,""79"":""*"",""8"":""*"",""80"":""*"",""81"":""*"",""82"":null,""83"":null,""84"":""*"",""85"":null,""86"":null,""87"":""*"",""88"":""*"",""89"":null,""9"":null,""90"":null},""pos"":{""0"":1,""1"":1,""10"":2,""11"":5,""12"":6,""13"":3,""14"":4,""15"":5,""16"":5,""17"":6,""18"":7,""19"":7,""2"":2,""20"":8,""21"":8,""22"":9,""23"":6,""24"":10,""25"":9,""26"":7,""27"":1,""28"":10,""29"":8,""3"":1,""30"":11,""31"":9,""32"":11,""33"":12,""34"":12,""35"":13,""36"":10,""37"":2,""38"":14,""39"":15,""4"":1,""40"":2,""41"":11,""42"":12,""43"":13,""44"":3,""45"":16,""46"":17,""47"":13,""48"":14,""49"":18,""5"":2,""50"":15,""51"":16,""52"":19,""53"":14,""54"":4,""55"":3,""56"":5,""57"":17,""58"":1,""59"":15,""6"":3,""60"":2,""61"":20,""62"":18,""63"":16,""64"":3,""65"":21,""66"":17,""67"":22,""68"":19,""69"":4,""7"":3,""70"":23,""71"":20,""72"":24,""73"":25,""74"":21,""75"":26,""76"":5,""77"":27,""78"":28,""79"":6,""8"":4,""80"":4,""81"":7,""82"":6,""83"":22,""84"":5,""85"":29,""86"":18,""87"":6,""88"":23,""89"":30,""9"":4,""90"":31},""sigma_nor"":{""0"":1.4966752674,""1"":1.2947529981,""10"":2.2755748496,""11"":1.4924875512,""12"":1.5914966793,""13"":1.5435402963,""14"":2.505793414,""15"":2.3045699988,""16"":1.7149418653,""17"":4.6125262163,""18"":2.0533952504,""19"":2.6700009366,""2"":1.455276696,""20"":1.8406429487,""21"":1.5513216679,""22"":1.5056307025,""23"":4.1333235478,""24"":1.5268476524,""25"":2.535002293,""26"":3.8060590775,""27"":2.2955407997,""28"":1.5413178748,""29"":1.5300668739,""3"":1.351362363,""30"":1.5667427505,""31"":3.4690571141,""32"":3.5840753916,""33"":1.7523097662,""34"":2.452753585,""35"":1.7322926444,""36"":1.7430436657,""37"":1.8724362421,""38"":1.7924193342,""39"":2.9861352122,""4"":1.3910736048,""40"":3.5468765041,""41"":1.7940882976,""42"":2.560453822,""43"":1.9526520971,""44"":2.11924559,""45"":1.6383712615,""46"":1.6970160696,""47"":1.722471781,""48"":1.9892896909,""49"":2.1759532263,""5"":1.5215676305,""50"":1.8854917741,""51"":2.1184268663,""52"":1.7133106323,""53"":1.8919743257,""54"":2.2580092632,""55"":2.2827761892,""56"":1.9827837919,""57"":1.789350192,""58"":2.3628691974,""59"":1.7922010402,""6"":1.7564223577,""60"":1.7012026953,""61"":1.8826378622,""62"":1.7811933278,""63"":1.8666821994,""64"":1.8872040761,""65"":1.9337516028,""66"":2.4213449117,""67"":1.8924314367,""68"":2.2945824295,""69"":2.4290518396,""7"":1.5259046631,""70"":1.7353844681,""71"":1.997237111,""72"":1.9255585945,""73"":1.9652582736,""74"":1.9858796192,""75"":2.0549073207,""76"":2.0914291818,""77"":1.7587594533,""78"":2.1122062362,""79"":1.8633225184,""8"":2.0191762267,""80"":1.8881433655,""81"":1.900147346,""82"":1.7454886477,""83"":1.9911855346,""84"":1.9518236997,""85"":1.9718077213,""86"":1.9031559844,""87"":1.8802543708,""88"":1.9743234432,""89"":1.7820407087,""9"":1.4373508456,""90"":1.7544048965},""topic"":{""0"":2,""1"":-1,""10"":-1,""11"":1,""12"":1,""13"":-1,""14"":-1,""15"":2,""16"":-1,""17"":-1,""18"":-1,""19"":1,""2"":2,""20"":1,""21"":-1,""22"":1,""23"":2,""24"":1,""25"":-1,""26"":2,""27"":3,""28"":-1,""29"":2,""3"":1,""30"":-1,""31"":2,""32"":1,""33"":1,""34"":-1,""35"":-1,""36"":2,""37"":0,""38"":-1,""39"":-1,""4"":0,""40"":3,""41"":2,""42"":2,""43"":2,""44"":3,""45"":-1,""46"":-1,""47"":1,""48"":1,""49"":-1,""5"":1,""50"":1,""51"":1,""52"":-1,""53"":2,""54"":3,""55"":0,""56"":3,""57"":1,""58"":4,""59"":2,""6"":1,""60"":4,""61"":-1,""62"":1,""63"":2,""64"":4,""65"":-1,""66"":2,""67"":-1,""68"":1,""69"":0,""7"":2,""70"":-1,""71"":1,""72"":-1,""73"":-1,""74"":1,""75"":-1,""76"":0,""77"":-1,""78"":-1,""79"":3,""8"":2,""80"":4,""81"":3,""82"":0,""83"":1,""84"":4,""85"":-1,""86"":2,""87"":4,""88"":1,""89"":-1,""9"":1,""90"":-1},""vector"":{""0"":""[-0.6763126   1.951808    3.9429712   1.8709763   0.0154823  -5.8279777\n -1.8994974   1.5480869  -0.41136387  6.9593487 ]"",""1"":""[-0.70462185  2.0481582   3.9584985   1.5856047  -0.02914136 -6.3372483\n -1.0013151   1.7477515  -0.14441976  7.1170278 ]"",""10"":""[ 0.02279639  1.2693326   4.400291    1.5338012  -0.73473316 -5.695035\n -0.8108117   2.0337775  -0.9045741   6.7884226 ]"",""11"":""[ 0.17639899  1.2067419   4.3512363   1.4187199  -0.782969   -5.6764774\n -0.61764425  1.8356788  -0.76978105  6.77026   ]"",""12"":""[-0.57249427  1.7108629   4.722499    1.7449518  -0.68039584 -5.4050207\n -0.6150137   2.1757016  -0.6226346   6.945027  ]"",""13"":""[ 0.47924975  0.42495233  4.237213    1.2678357  -1.2122655  -4.2865777\n -0.65096354  0.878239   -1.2405477   6.901356  ]"",""14"":""[-0.50646096  1.5690651   3.9968557   1.5363606  -0.3525797  -5.3533216\n -1.7716706   2.054842   -1.0450121   7.1913414 ]"",""15"":""[-5.5578417e-01  1.2094651e+00  3.4181304e+00  1.8331871e+00\n  4.6365988e-03 -5.8995109e+00 -1.7614270e+00  1.9669091e+00\n -9.3379688e-01  6.6808677e+00]"",""16"":""[-0.31201303  1.1669405   3.889272    1.726676   -0.47350752 -5.6461782\n -1.3680676   2.21694    -1.0064683   6.70889   ]"",""17"":""[-0.8587394   1.0490001   2.94994     1.5198631   0.3818076  -5.3740206\n -1.5576681   1.1797663  -0.51747054  6.8575277 ]"",""18"":""[-0.7439132   1.8580797   4.0391397   1.6460606  -0.12666653 -6.1476684\n -1.0907965   2.0715518  -0.5220165   7.0571847 ]"",""19"":""[-0.30994454  1.3144537   4.3360767   1.646141   -0.8400824  -5.138431\n -0.33118004  2.054531   -0.45356774  6.8139296 ]"",""2"":""[-0.4331223   1.2464417   3.4769506   1.6165316  -0.21030101 -5.224373\n -2.2170446   1.8170263  -1.2411178   7.100304  ]"",""20"":""[-0.5585554   1.6261041   4.3763723   1.7765183  -0.6776203  -5.283018\n -0.41172394  2.1594956  -0.41325778  6.9403744 ]"",""21"":""[ 0.11667341  0.79736215  4.004586    1.355754   -0.90892607 -4.8320136\n -1.1483463   1.864174   -1.1083423   6.8489137 ]"",""22"":""[-0.21517205  1.6651413   4.231288    1.287246   -0.3956065  -6.1284986\n -0.22866923  1.3797158   0.04310499  6.869945  ]"",""23"":""[-0.38086247  0.9150156   3.3964148   1.7084715  -0.41530085 -5.704442\n -1.1964111   1.6547414  -0.2560358   6.372331  ]"",""24"":""[-0.77603555  1.9277986   4.2744336   1.4122816  -0.24059837 -6.094939\n -0.34840906  1.6766132   0.08086272  7.0845675 ]"",""25"":""[ 0.34228876  0.6085101   4.220788    1.4565817  -1.1544057  -4.661173\n -0.77399224  1.3767241  -1.1600065   6.783149  ]"",""26"":""[-0.31525716  0.9589691   3.6046596   1.7252976  -0.57947075 -5.6165385\n -0.9878763   1.8068373  -0.28832     6.4031897 ]"",""27"":""[ 0.5043904   0.31478179  4.1077785   1.1758671  -1.1581466  -3.9780986\n -0.7293365   0.7165302  -1.2628498   6.9447293 ]"",""28"":""[ 0.06644408  1.3599156   4.306251    1.2444977  -0.67655265 -5.7358365\n -0.2905715   1.5093807  -0.37858245  6.899848  ]"",""29"":""[-0.7198446   1.8540999   3.7231517   1.5621942   0.04431385 -5.529958\n -1.9682388   1.5899943  -0.75841445  7.3519554 ]"",""3"":""[-0.13828121  1.7454866   4.066003    1.3810165  -0.42218354 -6.211723\n -0.68235904  1.6956043  -0.29544052  7.0724773 ]"",""30"":""[-0.28824785  1.1417713   3.8690405   2.0309236  -0.42782947 -5.7790236\n -1.3594548   1.99052    -0.7628119   6.425131  ]"",""31"":""[-0.55250806  1.4463855   3.6035206   1.889511   -0.0462993  -6.0462375\n -1.6432873   1.8007861  -0.5957617   6.666439  ]"",""32"":""[-0.42228672  1.8537788   4.290298    1.8749151  -0.55209726 -5.943393\n -0.43002653  2.1542637  -0.3031562   6.8222766 ]"",""33"":""[-0.49716085  1.8045768   4.618497    1.7408997  -0.6551718  -5.662529\n -0.26066777  2.1066601  -0.3746537   6.8874016 ]"",""34"":""[ 0.10122655  0.5667748   3.6528769   1.0970656  -0.67118657 -4.461031\n -1.1489502   1.478747   -0.9298692   6.8501782 ]"",""35"":""[ 0.12003047  0.6689639   3.635762    1.2565356  -0.6694346  -4.282202\n -1.5729162   1.2903142  -1.2356538   7.063261  ]"",""36"":""[-0.8192645   1.3915472   3.4325578   1.8608587  -0.10877971 -5.4033036\n -1.8664372   2.0804775  -0.9667638   6.961211  ]"",""37"":""[-1.1462685  1.6689583  3.223488   1.561487   0.5499397 -5.596948\n -1.6698579  1.1582508 -0.2603892  7.1907606]"",""38"":""[-0.42339924  1.3879633   3.5897434   1.5186313  -0.19217056 -5.1065645\n -2.183367    1.6099838  -1.1681602   7.2642703 ]"",""39"":""[-0.9556728   1.0852121   2.9191155   1.6387712   0.35002714 -5.513009\n -1.6178743   1.2925072  -0.40196124  6.760719  ]"",""4"":""[-1.1268737  1.8329806  3.405661   1.5771759  0.4359518 -5.4891076\n -1.7616229  1.2920043 -0.3866885  7.3243823]"",""40"":""[ 0.5730723   0.16860501  4.1128397   1.1263827  -1.1552     -4.1845436\n -0.44510904  0.77069885 -1.1731225   6.7283564 ]"",""41"":""[-0.8463724   1.9397485   3.659427    1.61023     0.16381826 -5.9452744\n -1.6683108   1.6647745  -0.5251992   7.248572  ]"",""42"":""[-0.76379716  1.4920487   3.4630227   1.7821443   0.02316242 -5.8610277\n -1.863386    2.1038013  -0.9591737   6.9494157 ]"",""43"":""[-0.4006882   1.1458119   3.7348816   2.0166373  -0.34298888 -5.7639527\n -1.4150046   1.8712654  -0.63197345  6.415989  ]"",""44"":""[ 0.5263183   0.1558837   3.8500853   1.0297914  -0.8760933  -4.130188\n -0.6480979   0.61141676 -1.063334    6.7201705 ]"",""45"":""[-0.6682713  1.7901264  4.437317   1.5838363 -0.4481139 -5.4044595\n -1.1573815  2.1432893 -0.7626922  7.179414 ]"",""46"":""[ 0.42801052  0.42533544  3.874525    0.98533696 -0.87880105 -4.262791\n -0.8999833   1.0906886  -1.042689    6.812121  ]"",""47"":""[-0.74499667  1.8778886   4.618693    1.4079082  -0.41773444 -5.846844\n -0.1915433   1.8626908  -0.1243699   7.087696  ]"",""48"":""[-0.3873425   1.7464032   4.606067    1.3617024  -0.532106   -5.768926\n -0.38291278  1.8664861  -0.45031297  7.1027193 ]"",""49"":""[-0.29634905  0.64965564  3.2990592   1.1612937  -0.11867972 -4.501108\n -1.1717879   0.8950735  -0.7428776   6.972468  ]"",""5"":""[-0.06743532  1.4429864   4.2161884   1.2223148  -0.5366828  -5.869351\n -0.27786666  1.4158762  -0.21369277  6.9197187 ]"",""50"":""[-0.26239124  1.2822012   4.4396834   1.7963607  -0.79633856 -5.3055024\n -0.72607285  2.0266356  -0.7233637   6.707936  ]"",""51"":""[-0.2626301   1.8141912   4.2267528   1.387105   -0.28983083 -6.2839446\n -0.39484867  1.52973    -0.08224916  6.9482746 ]"",""52"":""[ 0.29532862  0.55950814  4.168403    1.4550856  -1.0801264  -4.2008686\n -0.82112575  1.2368703  -1.2273923   6.923868  ]"",""53"":""[-7.6492494e-01  1.6928895e+00  3.6480494e+00  1.7718043e+00\n  2.5023320e-03 -6.1056275e+00 -1.5797226e+00  2.0576816e+00\n -7.5191307e-01  6.9680643e+00]"",""54"":""[ 0.60756063  0.05479418  3.9994519   1.1615304  -1.0493094  -4.1181555\n -0.4289569   0.7517244  -1.1737293   6.6421347 ]"",""55"":""[-1.0949775   1.5836383   3.2352986   1.4620473   0.47544786 -5.484292\n -1.5352302   1.0917093  -0.2047997   7.193998  ]"",""56"":""[ 0.33679658  0.30134386  3.6955624   1.0474513  -0.7385165  -4.05962\n -1.0233103   0.8312449  -1.1216447   6.908303  ]"",""57"":""[-0.8922745   1.8058696   4.3598886   1.5753101  -0.31378445 -5.839934\n -0.57226276  2.0989504  -0.20914623  7.046867  ]"",""58"":""[ 0.35329834  0.30713952  3.660498    1.0534941  -0.77702016 -4.006818\n -1.3981148   0.89084667 -1.2844898   7.0776587 ]"",""59"":""[-0.32140213  1.1242353   3.626186    1.7204149  -0.42624226 -5.8906612\n -1.048967    1.5746214  -0.19838461  6.4441986 ]"",""6"":""[ 2.9963364e-03  1.0338384e+00  4.2849016e+00  1.5688711e+00\n -9.4596100e-01 -5.1961946e+00 -4.7509381e-01  1.9084853e+00\n -6.8298137e-01  6.6960626e+00]"",""60"":""[ 0.3203849   0.33866698  3.6668391   1.108559   -0.7517404  -4.1163263\n -1.1529313   1.1597002  -1.1616901   6.886147  ]"",""61"":""[ 0.41914177  0.3989862   4.1157665   1.3526387  -0.98511404 -4.4193807\n -0.3649586   1.0946463  -0.97097063  6.6710887 ]"",""62"":""[-0.63895273  1.6927702   4.4375625   1.4267124  -0.4901953  -5.627645\n -0.22551927  1.7626386  -0.13647422  7.035515  ]"",""63"":""[-0.5894593   1.2975547   3.4411285   1.7372807  -0.12518652 -5.634763\n -2.0097551   2.0317636  -1.0504965   6.9038653 ]"",""64"":""[ 0.11003719  0.51850116  3.4801464   1.1382555  -0.5430141  -4.11873\n -1.7369175   1.0890856  -1.2749957   7.164364  ]"",""65"":""[-0.6540023   0.98375934  3.2223153   1.2708076   0.18192615 -4.815551\n -1.253779    0.91853267 -0.54738563  7.066404  ]"",""66"":""[-0.4927245   1.0366836   3.418373    1.6621133  -0.31741706 -5.326894\n -1.8241616   2.0439801  -1.0000789   6.7877736 ]"",""67"":""[-0.7547729   1.0590736   3.0751934   1.6582886   0.25504965 -5.5870605\n -1.6400945   1.5069835  -0.7022637   6.7426906 ]"",""68"":""[-0.8312526   1.7855068   4.5208564   1.5779161  -0.41236806 -5.726717\n -0.542534    2.1745634  -0.348568    7.034793  ]"",""69"":""[-1.1393708   1.8699579   3.498951    1.454938    0.40703952 -5.4501643\n -1.4344575   1.210436   -0.23944329  7.380248  ]"",""7"":""[-0.82180786  1.8204764   3.5976927   1.6975621   0.12999909 -5.964643\n -1.8399391   1.8534949  -0.75810105  7.1621275 ]"",""70"":""[ 0.10060132  0.8103398   4.2304835   1.5189826  -0.978168   -4.6130958\n -0.79197216  1.6000319  -1.0228907   6.8502784 ]"",""71"":""[-5.4388726e-01  1.7269937e+00  4.2460489e+00  1.3314538e+00\n -3.2404444e-01 -5.9896998e+00 -3.1218365e-01  1.5310317e+00\n -1.5555277e-03  6.9943838e+00]"",""72"":""[ 0.10835978  0.7536126   3.9707923   1.1972768  -0.82395166 -4.6385136\n -0.753303    1.6250569  -0.78603363  6.844245  ]"",""73"":""[ 0.49617746  0.24275978  4.040688    1.2920011  -1.1263671  -3.7573473\n -0.6769821   0.7390186  -1.2848831   6.95081   ]"",""74"":""[-0.60192734  1.644913    3.8358262   1.6276929  -0.15247302 -6.158673\n -1.0114405   1.617977   -0.2318473   6.805776  ]"",""75"":""[ 0.4519965   0.34319422  3.9399996   1.178623   -0.9626919  -4.297087\n -0.8111429   1.3635489  -1.1340317   6.7269387 ]"",""76"":""[-0.9449615   1.2420163   3.0255709   1.5353141   0.41083026 -5.4929895\n -1.5437962   1.1300464  -0.32348228  6.9152813 ]"",""77"":""[-0.3479591   0.85600054  3.4109159   1.5886304  -0.47246513 -5.594475\n -1.161152    1.648879   -0.2890185   6.462026  ]"",""78"":""[-0.17657417  0.9547667   3.5038085   1.4268701  -0.42130938 -4.7033243\n -1.9705662   1.4785291  -1.2117099   7.112802  ]"",""79"":""[ 0.5171829   0.12806402  3.9533637   1.2230427  -0.96938217 -4.0622644\n -0.38998604  0.70858604 -1.0803595   6.6793013 ]"",""8"":""[-0.7176588   1.8786901   3.704741    1.7548233   0.10444425 -6.1969466\n -1.6212705   1.645227   -0.3803749   6.9719963 ]"",""80"":""[ 0.26361698  0.38813943  3.5612934   1.0716971  -0.67510355 -3.981705\n -1.6116186   0.91279364 -1.3307352   7.180039  ]"",""81"":""[ 0.502795    0.2046382   3.9883606   1.2543117  -1.06939    -3.8196282\n -0.64375424  0.7846334  -1.2345136   6.8895845 ]"",""82"":""[-1.0379312   1.8126171   3.5847378   1.4463464   0.2711238  -5.241937\n -1.5127043   1.3039567  -0.44104043  7.4244933 ]"",""83"":""[-0.94971     1.8977878   4.339499    1.5261246  -0.20667847 -5.549995\n -0.56680393  1.8725568  -0.22374219  7.190155  ]"",""84"":""[ 0.31249896  0.41090474  3.6161907   1.0301936  -0.7363561  -4.1557655\n -1.6378386   1.1026641  -1.2760832   7.086104  ]"",""85"":""[-0.04179882  1.6155868   4.2641497   1.4860089  -0.4929029  -6.1867604\n -0.7294876   1.8566179  -0.55869293  6.8970523 ]"",""86"":""[-0.62397116  1.7730128   3.964391    1.538743   -0.17304249 -5.6988344\n -1.7016804   2.0251663  -0.8907187   7.2372584 ]"",""87"":""[ 0.20764905  0.680924    3.6717105   1.1350489  -0.689981   -4.218953\n -1.7151532   1.0598875  -1.310526    7.186016  ]"",""88"":""[-0.34800452  1.5074934   4.6313124   1.6935129  -0.8426393  -5.3408537\n -0.259747    2.1204026  -0.51527536  6.808987  ]"",""89"":""[-0.31340927  0.9201684   3.6620586   1.5276006  -0.56742036 -5.1623397\n -1.4583085   2.0598295  -0.8744003   6.718535  ]"",""9"":""[-0.2876731   1.44666     3.9481602   1.4853595  -0.5618014  -5.875254\n -0.52571505  1.7172801  -0.08241895  6.8435736 ]"",""90"":""[-0.05232577  0.669026    3.650864    1.2889432  -0.6992267  -4.7827053\n -1.2918983   1.8133092  -0.896927    6.7465243 ]""},""vocab_index"":{""0"":0,""1"":1,""10"":13,""11"":14,""12"":15,""13"":18,""14"":19,""15"":20,""16"":22,""17"":26,""18"":27,""19"":29,""2"":2,""20"":30,""21"":31,""22"":32,""23"":34,""24"":40,""25"":41,""26"":42,""27"":48,""28"":50,""29"":53,""3"":3,""30"":54,""31"":59,""32"":60,""33"":67,""34"":74,""35"":78,""36"":84,""37"":89,""38"":91,""39"":95,""4"":4,""40"":104,""41"":105,""42"":106,""43"":115,""44"":117,""45"":122,""46"":123,""47"":143,""48"":145,""49"":147,""5"":5,""50"":159,""51"":174,""52"":184,""53"":190,""54"":191,""55"":192,""56"":199,""57"":205,""58"":222,""59"":224,""6"":6,""60"":230,""61"":237,""62"":240,""63"":241,""64"":242,""65"":243,""66"":244,""67"":245,""68"":265,""69"":271,""7"":7,""70"":280,""71"":288,""72"":302,""73"":304,""74"":311,""75"":312,""76"":313,""77"":315,""78"":320,""79"":352,""8"":10,""80"":366,""81"":377,""82"":390,""83"":408,""84"":411,""85"":424,""86"":428,""87"":435,""88"":460,""89"":474,""9"":12,""90"":479},""word"":{""0"":""immersive"",""1"":""analytics"",""10"":""system"",""11"":""loop"",""12"":""environments"",""13"":""support"",""14"":""space"",""15"":""computer"",""16"":""machine"",""17"":""ieee"",""18"":""algorithms"",""19"":""steps"",""2"":""human"",""20"":""tasks"",""21"":""time"",""22"":""provenance"",""23"":""conference"",""24"":""analysts"",""25"":""challenge"",""26"":""proceedings"",""27"":""supported"",""28"":""input"",""29"":""spatial"",""3"":""data"",""30"":""card"",""31"":""graphics"",""32"":""transactions"",""33"":""interactions"",""34"":""north"",""35"":""current"",""36"":""learning"",""37"":""pirolli"",""38"":""physical"",""39"":""tvcg"",""4"":""sensemaking"",""40"":""allow"",""41"":""clustering"",""42"":""computing"",""43"":""game"",""44"":""discuss"",""45"":""spaces"",""46"":""directly"",""47"":""actors"",""48"":""parameters"",""49"":""http"",""5"":""information"",""50"":""scenario"",""51"":""annotations"",""52"":""maintaining"",""53"":""computation"",""54"":""exploit"",""55"":""endert"",""56"":""related"",""57"":""technologies"",""58"":""easier"",""59"":""presentation"",""6"":""process"",""60"":""parallel"",""61"":""form"",""62"":""factors"",""63"":""science"",""64"":""vast"",""65"":""https"",""66"":""university"",""67"":""microsoft"",""68"":""lenses"",""69"":""\ufb01nding"",""7"":""computational"",""70"":""setting"",""71"":""sources"",""72"":""direction"",""73"":""added"",""74"":""synthesis"",""75"":""simultaneously"",""76"":""sigchi"",""77"":""workshop"",""78"":""international"",""79"":""describe"",""8"":""visualization"",""80"":""excellent"",""81"":""performed"",""82"":""speci\ufb01c"",""83"":""modalities"",""84"":""heavy"",""85"":""code"",""86"":""bandwidth"",""87"":""immediate"",""88"":""transitions"",""89"":""house"",""9"":""results"",""90"":""winter""},""word*"":{""0"":""immersive"",""1"":""analytics"",""10"":""system"",""11"":""loop"",""12"":""environments"",""13"":""support"",""14"":""space"",""15"":""computer"",""16"":""machine"",""17"":""ieee"",""18"":""algorithms"",""19"":""steps*"",""2"":""human"",""20"":""tasks*"",""21"":""time"",""22"":""provenance"",""23"":""conference"",""24"":""analysts"",""25"":""challenge"",""26"":""proceedings"",""27"":""supported*"",""28"":""input"",""29"":""spatial"",""3"":""data"",""30"":""card"",""31"":""graphics"",""32"":""transactions"",""33"":""interactions*"",""34"":""north"",""35"":""current"",""36"":""learning"",""37"":""pirolli*"",""38"":""physical"",""39"":""tvcg"",""4"":""sensemaking*"",""40"":""allow*"",""41"":""clustering"",""42"":""computing*"",""43"":""game"",""44"":""discuss"",""45"":""spaces"",""46"":""directly"",""47"":""actors"",""48"":""parameters"",""49"":""http"",""5"":""information"",""50"":""scenario"",""51"":""annotations"",""52"":""maintaining"",""53"":""computation*"",""54"":""exploit*"",""55"":""endert*"",""56"":""related"",""57"":""technologies"",""58"":""easier"",""59"":""presentation"",""6"":""process"",""60"":""parallel"",""61"":""form"",""62"":""factors"",""63"":""science*"",""64"":""vast*"",""65"":""https"",""66"":""university"",""67"":""microsoft"",""68"":""lenses"",""69"":""\ufb01nding*"",""7"":""computational*"",""70"":""setting"",""71"":""sources"",""72"":""direction"",""73"":""added"",""74"":""synthesis"",""75"":""simultaneously"",""76"":""sigchi*"",""77"":""workshop"",""78"":""international"",""79"":""describe*"",""8"":""visualization*"",""80"":""excellent*"",""81"":""performed*"",""82"":""speci\ufb01c"",""83"":""modalities"",""84"":""heavy*"",""85"":""code"",""86"":""bandwidth"",""87"":""immediate*"",""88"":""transitions*"",""89"":""house"",""9"":""results"",""90"":""winter""},""x2D"":{""0"":-0.6495525241,""1"":0.6211301684,""10"":2.5309414864,""11"":2.4064891338,""12"":3.3639252186,""13"":-8.5654649734,""14"":-1.822049737,""15"":-1.8099110126,""16"":-2.5121996403,""17"":-0.9325124025,""18"":0.3727017045,""19"":3.1173508167,""2"":-2.4471242428,""20"":3.264800787,""21"":-7.6476049423,""22"":1.4859154224,""23"":-3.0319883823,""24"":1.9149632454,""25"":-8.1757144928,""26"":-2.7819640636,""27"":-8.3250570297,""28"":1.7878029346,""29"":-0.8875645399,""3"":1.1536289454,""30"":-2.4473404884,""31"":-1.5229078531,""32"":3.079400301,""33"":2.8926978111,""34"":-7.3379535675,""35"":-6.4699363708,""36"":-1.8696957827,""37"":-0.6069731116,""38"":-2.2755386829,""39"":-1.0368720293,""4"":-0.2984873354,""40"":-8.4813833237,""41"":-0.6993786693,""42"":-1.4939335585,""43"":-2.6416330338,""44"":-8.0966968536,""45"":2.9351758957,""46"":-7.7274694443,""47"":2.2922227383,""48"":2.4287414551,""49"":-6.7263073921,""5"":1.5844027996,""50"":3.0857026577,""51"":1.4172506332,""52"":-8.2474088669,""53"":-1.1107828617,""54"":-8.3235006332,""55"":-0.3585272133,""56"":-7.3720917702,""57"":2.6659054756,""58"":-6.9303703308,""59"":-2.9371159077,""6"":2.8841764927,""60"":-7.1814889908,""61"":-8.4430751801,""62"":2.2514543533,""63"":-1.8964101076,""64"":-6.3993468285,""65"":-0.5940403938,""66"":-2.4466626644,""67"":-1.1981683969,""68"":2.7232444286,""69"":-0.1519872993,""7"":-0.8100346923,""70"":-7.8838734627,""71"":1.7285231352,""72"":-7.7507281303,""73"":-8.1435289383,""74"":0.3712555766,""75"":-7.9665393829,""76"":-0.8274036646,""77"":-2.7763268948,""78"":-5.8611264229,""79"":-8.2197475433,""8"":-0.5784314871,""80"":-6.6399869919,""81"":-8.1285161972,""82"":-0.3297910392,""83"":2.5358483791,""84"":-6.5530662537,""85"":1.832077384,""86"":-1.3193875551,""87"":-6.5132961273,""88"":3.1146330833,""89"":-2.8448836803,""9"":1.2418016195,""90"":-7.4469003677},""y2D"":{""0"":-0.6019663811,""1"":0.9946367145,""10"":3.2063157558,""11"":3.1913239956,""12"":2.5622694492,""13"":-3.2886915207,""14"":-0.9604676366,""15"":-0.3537210524,""16"":-0.2357504964,""17"":-2.2555410862,""18"":0.7824300528,""19"":3.016784668,""2"":-0.9812073708,""20"":2.5399768353,""21"":-2.0700275898,""22"":2.0930492878,""23"":0.3029585183,""24"":1.67659235,""25"":-2.5811769962,""26"":0.219657138,""27"":-3.8858616352,""28"":2.8554241657,""29"":-0.9472879767,""3"":2.376819849,""30"":0.2920641005,""31"":-0.1171447411,""32"":2.104726553,""33"":2.4188218117,""34"":-2.4682743549,""35"":-2.684961319,""36"":-0.8787977695,""37"":-1.8806091547,""38"":-1.116232872,""39"":-2.1449987888,""4"":-1.6690397263,""40"":-3.5720951557,""41"":-0.8977909684,""42"":-0.6147729158,""43"":0.2850407064,""44"":-3.5646164417,""45"":2.0004210472,""46"":-3.1306843758,""47"":1.7553297281,""48"":2.306261301,""49"":-2.4020142555,""5"":2.4402067661,""50"":3.0649209023,""51"":1.9320230484,""52"":-2.8199415207,""53"":-0.3176847696,""54"":-3.839789629,""55"":-2.0793225765,""56"":-3.3071982861,""57"":1.7473756075,""58"":-3.2174594402,""59"":0.1122802496,""6"":3.2482059002,""60"":-3.0426058769,""61"":-3.1791379452,""62"":1.9993380308,""63"":-0.5591195822,""64"":-2.9443466663,""65"":-2.4201877117,""66"":-0.6617667079,""67"":-2.0487935543,""68"":1.8500258923,""69"":-1.8248924017,""7"":-0.6454096437,""70"":-2.2796344757,""71"":2.0003278255,""72"":-2.3208231926,""73"":-3.8789820671,""74"":1.1591387987,""75"":-3.0394923687,""76"":-2.1882214546,""77"":0.1247166619,""78"":-2.3281009197,""79"":-3.6207818985,""8"":-0.2939190269,""80"":-2.9451899529,""81"":-3.6335954666,""82"":-1.7375423908,""83"":1.6961170435,""84"":-2.9905102253,""85"":2.6171481609,""86"":-0.8787397742,""87"":-2.8305950165,""88"":2.8320844173,""89"":-0.4047909975,""9"":2.4210717678,""90"":-2.1071462631}}",False,False,False,http://link.springer.com/10.1007/978-3-030-01388-2_5,,Immersive Human-Centered Computational Analytics,"[-2.67257690e-01 -6.49262741e-02 -1.79466665e-01 -2.55799681e-01
  4.15149450e-01 -2.32936740e-01 -1.39207080e-01 -1.66550562e-01
 -1.30302131e-01 -2.44927689e-01 -1.13161802e-01 -2.60183334e-01
 -6.91779405e-02  5.97566813e-02 -1.59970060e-01  7.62711167e-01
 -6.07189387e-02 -1.63406387e-01 -1.32742584e-01  4.31260467e-01
  2.27175802e-01  2.14438081e-01  2.13511512e-01  6.90064847e-01
  1.97895065e-01 -7.67268287e-03 -2.45045066e-01  2.22741693e-01
 -3.09265912e-01  3.01822960e-01  3.43892753e-01  5.46048522e-01
  1.77915871e-01 -3.56323153e-01 -2.81601283e-03  4.54955129e-03
 -4.29053575e-01 -2.34449655e-01 -1.71528272e-02  6.71156168e-01
 -7.46874630e-01 -8.03842172e-02 -5.02409458e-01 -8.52248073e-02
  1.31920218e-01  1.60304978e-02 -2.13176653e-01 -1.59678489e-01
 -7.84852728e-02 -6.24772906e-01 -1.55299878e+00 -7.92969838e-02
 -2.98360102e-02 -4.64011729e-01 -9.17235315e-02  4.05143231e-01
  2.27933675e-01 -4.90377396e-01  4.69311118e-01  4.88231331e-02
 -1.21758312e-01 -2.18172610e-01 -7.00365752e-02 -2.71505434e-02
  3.18246275e-01 -3.19079369e-01  1.53297946e-01  8.59482959e-02
 -3.68693709e-01  1.87327877e-01 -1.87734932e-01 -1.33976281e-01
 -6.69435635e-02  5.13209701e-01 -1.22845888e-01 -3.27456504e-01
  1.32835776e-01  2.31533825e-01  9.77655426e-02  8.64766445e-03
 -6.09901786e-01  1.78533301e-01  1.06327564e-01  7.91167766e-02
  4.56119955e-01  5.62704861e-01  2.21363485e-01  3.23831409e-01
 -3.94636691e-01  3.17587763e-01 -5.92628121e-01 -1.02026975e-02
 -3.65453720e-01  1.69366688e-01  5.85130870e-01  4.69465787e-03
 -5.37558496e-01  8.68995562e-02 -2.77940720e-01  5.74959293e-02
  2.55662531e-01 -7.46289015e-01  6.87618554e-02  3.01641575e-03
  6.92264810e-02 -2.20978618e-01  6.88635856e-02 -4.67437059e-01
 -3.45790505e-01  3.23569804e-01 -2.32497215e-01  2.22110525e-01
  6.58015087e-02 -4.88355517e-01 -2.32591778e-01  2.01966822e-01
  1.86820686e-01  8.37438777e-02  2.33277604e-02  3.61549765e-01
 -9.56546143e-02  4.96625662e-01  1.32691413e-01  5.55703223e-01
  1.68182790e-01  1.38827786e-01 -1.06267355e-01  2.24089533e-01
  2.68278331e-01  1.93780676e-01  5.42951167e-01  2.24826217e-01
  3.91894691e-02 -1.02549106e-01 -4.52242345e-01  3.06289703e-01
  1.33848712e-01 -1.32658571e-01 -4.99777570e-02 -1.73428319e-02
 -3.71201813e-01 -6.34718478e-01  2.17275351e-01  2.61793137e-01
  1.54541045e-01 -1.92148671e-01 -5.00210047e-01  2.98010886e-01
  3.10486276e-02  2.88064092e-01 -3.49713087e-01  2.79494852e-01
 -6.52061701e-01 -1.55697614e-01 -1.21216334e-01  1.72542766e-01
 -4.79618907e-01 -1.56838410e-02  2.01180384e-01  2.94267416e-01
 -8.54548514e-02 -4.00427636e-03  1.06943222e-02  2.77769119e-01
  1.62473977e-01 -3.45416367e-02 -2.17102140e-01  4.03337210e-01
 -1.49040282e-01 -2.84563035e-01  1.10330552e-01 -4.52794850e-01
  2.75369555e-01  1.20121790e-02  6.86456144e-01  8.07393268e-02
 -3.30933519e-02  8.13804716e-02  2.48871446e-01  4.48660702e-01
 -4.30389702e-01 -7.53347948e-02 -1.06556848e-01 -5.91903746e-01
  6.00297153e-01  1.44159883e-01  3.79858941e-01 -4.26066220e-01
  2.93150932e-01 -1.52283432e-02 -5.53540945e-01 -5.57022333e-01
  2.65380163e-02 -2.06896052e-01  8.00961331e-02 -3.60692620e-01
  4.74489406e-02 -3.24284315e-01 -2.66667932e-01 -2.84546554e-01
 -3.73576462e-01 -2.91206390e-01 -9.88265350e-02  2.73554236e-01
 -2.55744815e-01  3.05414107e-02 -5.75818658e-01 -6.26449645e-01
 -7.40027845e-01 -2.90923864e-02  9.13030505e-02  6.26844347e-01
 -6.68396771e-01  3.43960464e-01  2.07560360e-01  4.53206487e-02
  2.17248365e-01 -3.45170870e-02  2.84139186e-01  2.23406721e-02
  1.87345728e-01 -4.72229958e-01 -7.41747171e-02  6.29078686e-01
  1.43053547e-01  1.78910708e+00  1.05353668e-01 -1.60646424e-01
  5.63783288e-01  1.64408721e-02  1.49969801e-01 -4.39855486e-01
  8.40211809e-01 -6.68613672e-01  2.32874990e-01  2.47293472e-01
 -2.93719798e-01 -2.39853024e-01  3.27878654e-01 -2.19817102e-01
  1.51146855e-02  2.18709812e-01  3.18349719e-01 -2.85902731e-02
 -2.54925247e-02 -2.54985124e-01  3.26963723e-01  6.89031631e-02
 -5.01878798e-01 -9.58194807e-02 -2.54588246e-01  3.53972465e-01
 -4.01423812e-01 -6.73339248e-01  2.16900229e-01  2.91094966e-02
 -1.44423679e-01 -4.74532664e-01 -2.68957734e-01  3.47955585e-01
  7.39822149e-01 -8.62326324e-02  3.34285319e-01 -2.89345443e-01
  1.54477134e-01 -5.95412314e-01  1.15950750e-02  1.99889362e-01
  9.18808699e-01  7.41960764e-01 -1.00540012e-01 -2.13438332e-01
 -1.93582445e-01  6.54104769e-01 -4.44159806e-01 -5.68034112e-01
  6.24477193e-02 -4.29224372e-01  1.47089899e-01 -2.91489035e-01
  3.60858828e-01  1.90904811e-01 -2.30730116e-01  1.77543372e-01
 -5.85737228e-01  5.56645878e-02  7.84259066e-02 -9.57190096e-02
  7.97950998e-02 -3.40193778e-01 -3.45730513e-01  2.70947754e-01
 -6.06387913e-01 -3.18881601e-01  4.51634675e-01  3.46794724e-01
  1.87932640e-01 -1.06918722e-01 -2.80382156e-01 -3.46867383e-01
 -3.30197066e-01  3.68500173e-01  5.58812991e-02  2.17417330e-02
 -3.80580872e-02 -2.30408888e-02 -2.85794109e-01 -4.31053758e-01
 -7.84738016e+00 -2.25022182e-01 -3.53387296e-01 -2.28543058e-01
  2.53375232e-01  1.89987987e-01  1.25676230e-01  7.81372488e-02
 -1.02657191e-01  8.06321204e-02 -1.52473927e-01 -5.11130750e-01
 -2.05279216e-01  1.12253197e-01  7.15076327e-02 -2.81841040e-01
  2.35118479e-01 -1.70229167e-01  1.00236960e-01  4.51296419e-01
  1.05852664e-01 -4.57880110e-01  1.21175453e-01 -1.45078406e-01
  1.63848042e-01 -2.41144434e-01 -3.93456846e-01  5.01372628e-02
 -4.15748954e-01 -8.90712500e-01  8.04676116e-02 -4.54139352e-01
 -3.58622253e-01  1.15639806e+00 -9.08503085e-02 -2.71646380e-01
 -2.82632172e-01 -2.37068787e-01  1.43564925e-01  2.21986219e-01
  2.87910849e-01 -3.49398375e-01 -9.12802219e-02  1.50669977e-01
  9.60979164e-01 -1.06456071e-01  5.80777265e-02  4.06589687e-01
 -4.66270536e-01  3.47351842e-02  1.59459654e-02 -1.06644772e-01
  5.54381430e-01 -3.34309995e-01  3.25133681e-01 -1.84658170e-01
  3.31512302e-01  7.34817684e-01 -1.69806540e-01 -4.17408114e-03
  5.16011775e-01 -3.28905374e-01 -4.25486952e-01 -8.77303183e-02
 -1.06794327e-01  2.06489146e-01 -7.70955563e-01 -6.18504107e-01
  4.01196480e-02 -3.91387016e-01 -4.05235529e-01  5.84126115e-01
  2.64450192e-01 -9.84538555e-01 -1.13338731e-01 -2.50640303e-01
  9.94712263e-02 -2.86148041e-01 -4.45477486e-01 -1.37820184e-01
 -4.12487060e-01 -5.66816330e-01  8.76170844e-02  6.29204139e-02
 -1.76128343e-01  3.64093125e-01 -3.44017118e-01 -9.44993123e-02
 -1.18500546e-01  3.06773961e-01 -1.60886243e-01  3.52997184e-01
  7.38199413e-01  2.76373088e-01 -9.04399082e-02  4.42608446e-02
  6.74092531e-01  1.03316590e-01  9.17590261e-02  2.29510710e-01
 -1.78971812e-01 -1.46386951e-01 -1.19461566e-01 -2.69321889e-01
 -3.10580909e-01  7.60373324e-02 -6.06522083e-01 -7.28714243e-02
  5.40133342e-02  1.28400296e-01 -1.52699456e-01  4.37242001e-01
 -3.70605588e-01 -4.02663410e-01  1.93952411e-01 -1.56313270e-01
 -3.04428667e-01  4.64610100e-01 -2.88602170e-02 -4.33406949e-01
 -6.38340473e-01  2.52087265e-01 -3.74960780e-01 -5.17480411e-02
  5.92970610e-01  2.25313708e-01  2.56595671e-01  4.93793905e-01
 -4.66020197e-01 -2.66551733e-01  1.47026271e-01 -4.15570855e-01
  2.06991196e-01  3.03719521e-01  3.10657471e-01 -2.19652802e-01
  2.40235448e-01 -3.28534037e-01 -7.71356046e-01  2.62781709e-01
  5.75209379e-01  6.00309595e-02  5.66194475e-01  1.02488482e-02
  1.43213123e-01  2.02864166e-02  1.10051863e-01  2.75486201e-01
 -2.16541171e-01  3.76819968e-01 -4.02082860e-01 -6.22486174e-01
  1.36913583e-01 -1.15938589e-01  4.87903446e-01  2.38491237e-01
  3.96323115e-01 -2.51547992e-01  1.45943254e-01 -4.92754132e-01
  3.83757621e-01 -3.18481252e-02  1.25638470e-01 -3.08284372e-01
 -1.27056375e-01  6.02521710e-02 -1.76099956e-01  3.02429914e-01
  3.47364336e-01 -5.74934661e-01 -3.79950434e-01 -1.22422159e-01
  3.98205400e-01 -2.74721663e-02 -1.92405343e-01  6.72397092e-02
  5.18812656e-01 -7.53490105e-02 -3.32738072e-01  6.12149179e-01
  2.61819005e-01  4.22295600e-01  1.18625335e-01  4.34990466e-01
  3.66850942e-01  3.77689183e-01  4.94403206e-02 -4.41704877e-02
 -1.25163980e-02  7.03226626e-02 -7.82479763e-01  2.80978650e-01
  6.99499920e-02 -2.70103425e-01 -1.20977871e-01 -4.70086873e-01
  5.44308364e-01 -4.97006595e-01 -3.87462862e-02 -2.12841555e-01
 -2.54372209e-01 -3.36507261e-01 -6.32553324e-02  2.44484916e-01
 -2.16101125e-01 -2.69811392e-01 -1.50856599e-02  4.20002282e-01
 -4.62838560e-01 -1.47923529e-01 -3.88654888e-01 -2.79301763e-01
 -3.99942063e-02 -4.32983369e-01 -8.44520479e-02  1.04294673e-01
 -3.79247636e-01 -1.89060479e-01 -7.82542288e-01  5.94876826e-01
 -2.23813042e-01 -3.52277048e-02  2.57043600e-01 -4.24422584e-02
 -1.04915891e-02 -1.63950086e-01 -1.60212651e-01  1.31660968e-01
 -4.37878996e-01 -6.02225401e-02 -8.04862007e-02 -1.77718699e+00
  1.42447054e-01 -6.13153428e-02  1.85787529e-01 -5.67904830e-01
 -2.34462187e-01  3.98552507e-01  1.06906297e-03 -3.05041462e-01
  1.63986862e-01 -3.03973793e-03 -2.61036992e-01 -7.73805305e-02
 -1.91959932e-01 -1.65814042e-01 -2.63468146e-01 -1.12378575e-01
 -4.42186266e-01  2.82979719e-02  1.60337180e-01 -2.86481559e-01
 -9.76167992e-02 -5.73591530e-01  4.85383123e-01 -3.13793659e-01
  3.62952985e-02 -5.34934223e-01 -1.21077500e-01 -4.79428880e-02
 -6.24741435e-01 -8.09030607e-02 -3.59471500e-01 -9.43906680e-02
 -3.70641351e-01 -1.09573774e-01 -1.70929909e-01 -2.13128421e-02
  1.68032229e-01 -3.93192828e-01 -2.22905781e-02 -4.31255430e-01
 -2.72905916e-01  1.15487918e-01 -5.59075058e-01  9.30216387e-02
 -1.65697381e-01 -1.29473686e-01 -1.41858652e-01 -6.74555719e-01
  3.47737968e-01 -2.62370110e-01  3.58287245e-01 -6.44880533e-02
  5.24292707e-01 -3.05133730e-01 -4.53518294e-02  1.40136734e-01
 -6.79536611e-02  9.42678750e-02  2.60070562e-01 -6.90983655e-03
 -4.35857683e-01  1.27174601e-01 -5.84667563e-01  4.07833546e-01
  8.86500597e-01  3.18170965e-01 -4.08770055e-01  3.23707491e-01
  2.59626627e-01  3.08421969e-01  4.20957297e-01  5.63722849e-01
  7.14145750e-02  1.23983242e-01 -2.38933742e-01 -4.58758384e-01
  9.00060013e-02 -8.26072514e-01 -4.69784141e-01 -4.16079104e-01
  6.27429247e-01 -1.49601281e-01 -2.84297410e-02 -4.50399697e-01
 -1.91777162e-02  1.82310849e-01  5.30385077e-01 -1.10407427e-01
 -4.92029369e-01  2.39378318e-01  5.40765941e-01 -7.51074627e-02
  1.99294776e-01  1.94658458e-01 -5.16942367e-02 -1.60692394e-01
 -3.76007438e-01  5.67722857e-01  2.11990312e-01  2.13815570e-01
  7.17723668e-02  2.30654672e-01  2.28560016e-01  8.82135332e-02
  3.01967323e-01 -1.54586226e-01 -8.26641545e-02  2.79639632e-01
 -1.51149556e-01  3.15305650e-01 -1.86514720e-01  3.68991852e-01
  1.40619576e-01 -6.66453913e-02  9.15471911e-02  6.39506996e-01
  1.64179534e-01  1.42501771e-01 -5.76779712e-03 -3.82314436e-02
  3.11709642e-01  2.69654959e-01 -2.74563819e-01 -1.13414906e-01
  1.84922129e-01 -2.73980200e-01 -3.39640081e-01  6.14630640e-01
  1.37873262e-01 -8.95432383e-02  1.81663856e-01 -5.67986071e-01
 -4.31029469e-01  4.68488410e-02  6.24380350e-01 -3.30903567e-02
  4.32316422e-01 -1.14534922e-01  1.20107822e-01  4.33757097e-01
 -1.73287302e-01 -1.10102490e-01  3.81901592e-01 -2.78785340e-02
 -2.00587258e-01 -4.62853670e-01 -1.19410893e-02 -4.44470346e-03
 -7.21592009e-02 -1.65253371e-01 -1.73851028e-01  2.38598332e-01
 -4.89763349e-01 -2.21588120e-01 -1.56672195e-01  2.12136358e-01
  1.21850938e-01 -2.20725745e-01 -1.12179510e-01  7.30162784e-02
  5.20380914e-01 -1.11842267e-01 -3.68330806e-01  1.13258734e-01
  1.27198234e-01 -2.10516065e-01  5.04484415e-01 -1.13207504e-01
  2.71789491e-01  1.25757575e-01 -6.03681862e-01  1.04918107e-01
 -2.54256964e-01  1.24318898e-01 -9.53821018e-02  1.64409727e-01
 -5.45992672e-01 -4.25073922e-01  4.25307155e-01  4.46762681e-01
  3.07449717e-02  2.25665241e-01  2.67529368e-01  3.57603908e-01
  2.00369820e-01 -1.65149435e-01 -1.49060085e-01 -4.22194377e-02
 -1.34996444e-01 -5.35349965e-01  5.26252091e-01 -4.64325100e-01
 -8.04733932e-02  4.58205372e-01  1.87540799e-01 -4.98354495e-01
 -5.74060865e-02 -9.84750092e-02  3.26721281e-01  3.15417796e-01
 -5.03790915e-01 -1.58051774e-01 -1.32760912e-01  1.79885954e-01
 -3.45095724e-01 -4.69280705e-02 -2.82086939e-01  9.40897390e-02
 -1.10324800e-01  6.32291496e-01 -4.28889617e-02 -2.32441977e-01
  2.28708968e-01  3.11602056e-01 -1.85618043e-01 -6.55538321e-01
 -4.00558829e-01 -3.87066543e-01 -5.09539545e-01  5.83182797e-02
 -3.33502173e-01 -2.57526159e-01 -2.18556792e-01  2.59245425e-01
 -2.18328834e-01 -2.48362869e-01  8.70629326e-02 -1.34104446e-01]",RH3V72Q4,False,False,"[7.918971061706543, -1.1443785429000854]"
4DZQWUEH,ZZ688LP8,"ModelSpace: Visualizing the Trails of Data Models in Visual Analytics

Systems

Eli T. Brown*
DePaul University

Sriram Yarlagadda†

DePaul University

Kristin A. Cook‡

Paciﬁc Northwest National Lab

Remco Chang§
Tufts University

Alex Endert¶

Georgia Institute of Technology

Figure 1: The ModelSpace prototype tool.

ABSTRACT
User interactions with visualization systems have been shown to
encode a great deal of information about the the users’ thinking
processes, and analyzing their interaction trails can teach us more
about the users, their approach, and how they arrived at insights.
This deeper understanding is critical to improving their experience
and outcomes, and there are tools available to visualize logs of inter-
actions. It can be difﬁcult to determine the structurally interesting
parts of interaction data, though, like what set of button clicks con-
stitutes an action that matters. In the case of visual analytics systems
that use machine learning models, there is a convenient marker of
when the user has signiﬁcantly altered the state of the system via
interaction: when the model is updated based on new information.
We present a method for numerical analytic provenance using high-
dimensional visualization to show and compare the trails of these
sequences of model states of the system. We evaluate this approach

*e-mail: eli.t.brown@depaul.edu
†e-mail: syarlag1@mail.depaul.edu
‡e-mail: Kris.Cook@pnnl.gov
§e-mail: remco@cs.tufts.edu
¶e-mail: endert@gatech.edu

with a prototype tool, ModelSpace, applied to two case studies on
experimental data from model-steering visual analytics tools. Mod-
elSpace reveals individual user’s progress, the relationships between
their paths, and the characteristics of certain regions of the space of
possible models.
Index Terms:
Visualization design and evaluation methods

Human-centered computing—Visualization—

1 INTRODUCTION
Visual analytics facilitates discovery and analytical reasoning via
the combination of data analytic models and interactive visualiza-
tions [45]. Because such systems provide tight connections between
the user, the visual interface, and the underlying analytics, the user’s
interactions within visual analytics systems have been found to con-
tain a great deal of information about the users’ thinking processes,
their approaches, and how they arrive at insights [17]. The design
of automated and semi-automated methods for recovering such in-
formation by analyzing the user’s interaction history and analysis
trails – commonly referred to analytic provenance – has become an
increasingly important research topic in the visualization community
due to its importance in training and veriﬁcation, and to its role in
the development of mixed-initiative systems [39, 40].

However, many existing tools in analytic provenance only go so
far as to show a record of the user’s interactions (e.g., [24,27,30,42]).
They seldom contain methods of visualizing the intermediate soft-

ware states or data models typically generated behind-the-scenes by
visual analytics systems. For visual analytics, this often entails the
sequence of different parameters assigned to the analytic models to
show speciﬁc aspects of the data to foster exploration and analysis.
In addition, they rarely communicate the logical link between the
interactions and the resulting models. Many methods of understand-
ing a user’s analytic provenance typically involve a tedious manual
reading of the logs as in Dou et al. [17], or building a system that
codes its own interactions into a taxonomy so manual review is more
convenient [23, 27]. Generally, the effort required to synthesize and
analyze these logs is a bottleneck to studying analytic provenance.
More recently there are visual analytics systems that help to dis-
cover patterns within logs by enabling grouping or searching of user
actions [13, 25, 51].

In this paper we propose an alternate, visual approach to analytic
provenance that is designed for the growing number of systems
using machine learning (though it may be ﬂexible enough to be
used more broadly), but automatic enough not to require manually
processing full logs. We create a mathematical representation of
users’ progress in using software, introducing numerical analytic
provenance. By creating a vector space to represent software states
(possibly extracted from logs), we can visualize users’ processes of
using an analytic tool. Each software state corresponds to some view
of the data delivered to the user in response to some input or controls.
Conveniently, systems that leverage machine learning build models
as users interact that can easily be converted to vectors. Therefore,
visualizing sequences of these models means seeing the progress of
users through their analytic process. By gathering these and creating
a vector representation, we can visualize the user’s progress through
the space of possible states, i.e. the provenance of their analysis.

We have implemented the numerical analytic provenance ap-
proach in a prototype tool called ModelSpace. This tool visualizes
the analytic trail of a user by creating a spatial layout of the vi-
sual system states, using their vector form. A given user’s trail is
connected with a line and color-coded, providing a connected scatter-
plot [26], where the points represent states and the lines connecting
the points represent the transitions between the states through time
(similar to Time Curves [3]).

With such a compact representation, ModelSpace can visualize
multiple users’ analysis trails, or multiple analysis trails of the same
user in the same canvas. In this way, we visualize how users in-
crementally interact with and change the analytic models in visual
analytics systems. Further, the model spatialization provides a base-
line structure that we annotate with data about interactions between
state changes. In this view, analytic trails can be quickly compared
and analyzed. For example, when two trails include adjacent states,
it may signify that these two investigations came to similar inquiries,
reﬂected by the similar models the users were considering. Mod-
elSpace provides features to deepen the exploration, like the ability
to highlight visual elements with a keyword search over the interac-
tion details.

We tested our prototype on data collected from experiments with
two visual analytics systems: (1) Dis-Function [9], an interactive
tool for learning models about high-dimensional numerical data
by simply performing iterative tweaks to a data visualization, and
(2) Doc-Function [8], a tool that allows sense-making of text cor-
pora through manipulation of keyword spatializations based on their
perception of keyword relationships. The authors of those works
provided the interaction logs and other data collected during the
evaluation experiments of those software prototypes. Our Mod-
elSpace implementation parses the logs (with a custom function per
application), extracts the states, and provides an interactive visual-
ization that makes it possible to explore a wide collection of facets
of the participants’ analytic provenance and develop insights into
how different users explored the data.

While, we performed our experiments on two visual analytics

systems with machine learning back-ends that lent their internal state
well to numerical analytic provenance, we posit that the use of Mod-
elSpace can be extended to other, non-visual-analytics platforms.
Recommender systems, for example, are not analytics systems, but
export models at each step of user interaction that could be visu-
alized and compared with numerical analytic provenance. In the
Discussion, we explore an application to a system that uses a visual
interface but has no back-end machine learning model. We also
discuss the limitations of our approach and current prototype, and
describe areas for future improvement. Overall, our contributions in
this work are that we:

• Present the concept of numerical analytic provenance, a novel
approach to studying analytic provenance in visual analytic
systems by visualizing the changes to their state as users in-
teract via the proxy of changes to their underlying machine
learning models.

• Provide a prototype tool to illustrate this concept that extracts
models from user study software logs and creates an interactive
spatialization with features to explore the analytic trails of
users in detail.

• Evaluate our tool and this concept with two case studies on

visual analytics systems.

2 RELATED WORK
Analytic provenance in the visual analytics community broadly
includes consideration for the history of how an analyst progressed
through the various stages of his or her analytic process [16, 22, 38–
40, 50]. Because visual analytics leverages human reasoning with
a computational system, understanding how users build knowledge
and insight can have implications for evaluating tools, as well as
identifying ways to enhance collaboration between the user and the
computer [39]. There are multiple stages to effectively analyze user
interaction histories to gain such an understanding about the user,
including the most applicable to this work: encoding the interaction
data and recovering semantic meaning behind the user’s actions
[19, 38].

The ﬁeld of analytic provenance offers many examples of how to
capture and encode this type of data [4, 14, 17, 23, 27, 33, 42]. One
problem is that the desired level of granularity for understanding
users’ provenance is vastly different from the level at which standard
computer software directly represents and logs interaction [23]. On
one end, we seek to ﬁnd patterns in semantic intentions of users,
e.g. instances where two people may have a differently expressed
high-level intention or strategy. On the other end, we have a wealth
of recorded low-level system events like mouse movements and
clicks.

One method to get semantic details from low level information is
to carefully code the interaction data by hand [42]. In fact, it has been
shown that process and strategy can be recovered this way [17], but
the process is tedious and slow. Another solution is to build software
with an organization scheme for interactions in mind. Systems
taking this approach can provide powerful tools for users to examine
their own analytic provenance trail in real time, and even organize it
into useful, human-readable categories. Examples include VisTrails,
HARVEST, CzSaw, and Graphical Histories [4,12,23,27,32], which
capture sequences of states and visualize them for the user to use for
navigation through the analytic process. For example, showing users
a series of thumbnails of previous visualization states helps them
recall aspects of their process and return to a previous state quickly
if they decide to go back [27]. An additional layer of complexity
can be added to show branching [18, 43]. However, the concepts
in these works are built to work with speciﬁc software and while
the concepts may generalize, the automation does not. There are
a number of survey papers that provide a deeper set of examples

from the broad spectrum of work in analytic provenance research
(see [15, 22, 40]), but the central problem of gaining deep insight
from low-level interactions remains a theme.

Recently, there are visual analytics tools to help with generic
log data. Han et al. [25] process logs and present the user with an
interface for organizing low-level tasks and building up higer-level
ones. Zgraggen et al. [51] present a visual query language that can
work over event sequences captured from logs to give a user the
search capability empowered by regular expressions in text data.
Chen et al. [13] provide a visual analytics system for sequence data
that includes the use of the minimum description length (MDL)
principle to help group interaction patterns automatically.

In this paper, we take a different approach to managing this
challenge. We focus on the case where there is a software state that
encodes the semantics of the user’s sensemaking, and the state can
be converted into a high-dimensional vector without direct human
involvement per state. We call this approach numerical analytic
provenance and detail it in Section 3. Speciﬁcally, it is intended for
the case when the system being studied uses machine learning as
part of an interactive system, and the changing, underlying machine
learning models can be represented as a vector. The idea behind a
numerical representation of the state of a visualization system was
previously suggested by van Wijk [48] and adopted as the basis of
the P-Set model by Jankun-Kelly et al. [29]. Our use of numerical
analytic provenance extends these works and demonstrates how such
an encoding can be applied to the visualization and analysis of users’
interaction trails with visual analytics systems. The main savings is
that the vectors can be created as the software runs or by processing
log ﬁles with scripts as opposed to by hand.

To gain insight from this mathematical representation, we use
visualization for the high-dimensional space, projecting the state
vectors into a 2D space as dots (e.g. using Multidimensional Scaling
(MDS) [34]). These dots are connected by lines to show sequences,
as in connected scatterplots [26]. By using this compact represen-
tation, we have room to connect additional interaction information,
e.g. annotating with what a user did that caused her to land at a given
state. Our visualization is also similar to Time Curves [3] and the
Dynamic Network approach [46]. By using computational models
as software states and encoding them as vectors, we position them in
space and show progression through that space over time with lines.

3 NUMERICAL ANALYTIC PROVENANCE
There have been multiple approaches to analytic provenance, but
one critical problem is that in seeking to understand how people use
software, it becomes necessary to follow their trail through a wide
array of possible interactions. With increasingly complex software,
the task of capturing and analyzing exactly what a user has done in
a way that can be efﬁciently understood is still a challenge. Previ-
ous work in analytic provenance has involved numerous methods
for capturing the broad spectrum of interactions and a variety of
encodings [4, 17, 23, 33, 42] to make it possible to analyze these
interaction streams. While some work has sought to automatically
encode and analyze interaction streams, most of the efforts have
involved coding by hand for different types of interaction [17,23]. A
methods of automatically encoding and analyzing user interactions
was proposed in Brown et al.’s work to learn models about users
based on their interaction data [10], but the technique compares
models of users, not their analytic provenance.

3.1 Vector Space of Models
Instead of manually coding user interactions into a human-readable
format before beginning to build an understanding, we propose au-
tomatically encoding a numerical representation of changes to the
internal state that the analytic software undergoes during the analysis
process. We refer to this concept as numerical analytic provenance,
and the encoded states as the state models. Deciding how to encode

Figure 2: This ﬁgure illustrates how the series of models created
by a user’s interaction trail can be represented by vectors and thus
visualized for examination. Each dot represents a state model vector
Θt
u that speciﬁes the internal state of a system for one user, u, at one
timestep, t.

the state in a general way is an open problem as a solution would
require solving the same problems that are left unsolved by other
provenance systems, namely automatically extracting meaningful
tasks and actions from low-level event data. We focus on systems
that use machine learning back-ends to aid the analytic process and
when possible, simply use the vector representation of the machine
learning model as a state. We assume the interaction that causes the
model to be updated is a signiﬁcant action and the model update
a signiﬁcant change to the display, making these events good piv-
ots for a visualization of the user’s process. These states are also
straightforward to extract from a log if they have been included, in
contrast to actual user intent or high-level action. The technique
presented in this paper visualizes the model sequences in the space
of possible models by creating a visual layout such that more similar
models are drawn nearer to each other. Because our representation
consists of vectors, we can use high-dimensional data visualization
techniques to calculate a projection, and the resulting visualization
shows the interactions performed by different users in context of
each other and in context of the broad spectrum of possible software
states.

Figure 2 illustrates the concept of projecting three users’ analytic
trails from their high-dimensional vector representation down to
a 2D visualization. Using this projection approach, it becomes
immediately apparent when users’ paths become close to each other,
and when similar models pack together indicating an interesting
region of the overall state space. Further, this technique becomes
more illuminating when we use the layout of the state models as
a canvas to decorate with a wide array of other information. We
provide context to the provenance by connecting the dots with lines
that represent all the interactions that led to a state change, i.e.
creating a connected scatterplot. Annotating the lines with these
data integrates the interactions and their effects in one view.

Applying this technique for visualizing multiple users’ numerical
analytic provenance has a wide range of uses. By visualizing all the
users’ interaction histories together, we can compare their analytic
processes to build an understanding of how and when they differ. For
researchers or developers conducting experiments to evaluate ana-
lytic systems, this makes it possible to explore the trails of individual

Θ�10Θ�30Θ�20Θ�33Θ�32Θ�31Θ�34Θ�21Θ�22Θ�23Θ�24Θ�11Θ�12Θ�13Θ�14users and the relationships between their analytic processes. The
analysis can reveal if there are areas of the model space that users
always retreat from, or if different types of users pursue broadly
different trajectories. For managers of multiple analysts, this not
only allows oversight of progress, but has the potential to mitigate
bias by alerting the manager when analysts are converging on one
area of the model space. Additionally, if deployed as a provenance
tool as part of a single user’s interface (e.g. as in [12, 23, 27]), this
technique could help the user understand not just what states she or
he has seen, but also how they relate to each other.

3.2 Example Model States of Visual Analytic Systems
While any visualization can be represented by its internal state [48]
to apply our proposed numerical analytic provenance approach, the
use of a high-dimensional numeric vector to represent the state
can have special implications for visual analytics systems. These
systems often incorporate machine learning techniques or other data
models to assist the user in exploring and analyzing data. Since
machine learning and data models are mathematical in nature, they
can often trivially be compactly represented as a high dimensional
vector that can be used to represent the state of a user’s analysis or
exploration.

One type of visual analytics system that tightly couples a user’s
interactions with an underlying data model is model-steering vi-
sual analytics. These analytic systems capture user interactions
with a data visualization and build a data model that encapsulates
the changing data understanding of the user [19] . For example,
ForceSPIRE [19] is an interactive visual tool for text analytics. The
user is provided a visual layout of a set of documents and interacts
with them via search, moving documents relative to each other, and
highlighting text. Based on these interactions, the system learns
a model that characterizes the relative importance of the different
words that appear in the documents. Each model update triggers a
layout update and users iteratively reﬁne the model through several
interactive steps, leaving behind a trail of models about the words in
the text corpus. Other examples use model-steering for such domains
as ranking [49], grouping Facebook friends [1], high-dimensional
numerical data [9, 20, 35, 41], and network alarm triage [2, 21].

Conveniently, these models can also be considered state models,
as they include the software state important to generating the visu-
alization. By applying the numerical analytic provenance concept,
we can visualize the relationships between the different data models
the user constructed, each one showing the actual data features that
were important to the user at the given time. We can annotate lines
connecting these models with all the interactions between updates,
indicating perhaps what documents were read and what words were
highlighted. The process of exploring the analytic provenance is
simpliﬁed, and the possibilities for discovery are broadened.

4 MODELSPACE
In order to evaluate the numerical analytic provenance concept expli-
cated by the previous section, we built a prototype interactive visual
system, ModelSpace (see Figure 3), that enables analysis of user
trails through the space of possible state models. In the following
subsections, we describe the implementation and features of this pro-
totype, beginning with the data required as input. We then describe
the mechanism for computing a layout and the interactive tools that
make analysis possible.

The ModelSpace prototype interface has been implemented for
the web, using JavaScript with D3 [5], HTML, and CSS. The back-
end software is responsible for processing log ﬁles, computing the
projection, and serving the front-end with code and display data.
It is implemented in Python 2.7 and uses the popular Numerical
Python [47] and Scikit-Learn [11] packages for computation, and
the Bottle [28] micro-framework for serving ﬁles.

4.1 Data for ModelSpace
Though the concept of numerical analytic provenance could be ap-
plied to a streaming context, with models updating the interface as
they became available, our prototype is built to extract user inter-
actions and model states from logs. For any given application, a
function is needed that processes the logs to gather models and any
accompanying information about user interactions between them.
This can involve merging multiple records, e.g. log ﬁles from the
software itself and digitized notes from an experimenter (as in the
Doc-Function case study presented in Section 5.2). The only abso-
lute requirement is that the extracted models can each be represented
as a vector, whether explicitly exported or constructed from the logs.
Both of our case studies produce internal models based on certain
interactions, so our log processing simply extracts the times at which
a model update was performed and captures the user input that
caused the update and resulting model. The models created by these
steps are represented by dots in the visualization in ModelSpace. The
logs can include other actions performed between model updates,
such as searching for words in documents in a text-analysis system.
These non-model-generating interactions are all captured as they
will be used in ModelSpace to annotate the lines that connect the
dots, representing the actions taken between model updates.

When model changes can be reverted, i.e. with an undo feature,
we keep track not only of the model update but the fact that it repre-
sents a reversion. The ability to backup in analysis is an effective
tool for the user to expresses intention, informing us that the last
model we saw could be a false step. ModelSpace represents this
important contextual information with a curved line pointing back
to the preceding dot.

Finally, it should be noted that while parsing a log ﬁle is sufﬁcient
for some applications, others will have more sophisticated data
available and a more complex function for integrating it. In the Doc-
Function case study below, for example, there were not only logs
from the software itself, but notes from the experiment administrator
about when each participant described certain insights. Information
like this can be digitized with timestamps and merged at the time the
logs are processed so that the visualization can reﬂect observations
of participants along with the state models.

Overall, the prototype is designed to demonstrate the numerical
analytic provenance concept speciﬁcally with two examples. While
we made choices speciﬁc to those examples, we also sought to keep
the visual representations and tools generic enough that they could
be adapted to a wide range of data.

4.2 Calculating the Layout
When state models come to ModelSpace, they are vectors, gen-
erally in a high dimensional space that reﬂects the complexity of
the analytic software. In order to visualize these high-dimensional
states, we create a spatialization of these vectors that can be viewed
in two dimensions. Since the desired view groups the states to-
gether based on their similarity, we use a Multidimensional Scaling
(MDS), which is a type of projection of points into low-dimensional
space (two-dimensions for our visual purpose) that optimizes for
preserving the pairwise distances between points across the high-
and low-dimensional spaces. This implies two useful features of
the spatialization: ﬁrst, similar models will be shown as dots that
are close to each other, resulting in groups of similar models, and
second, regions of the space of models will be reﬂected as regions
in the projection. Other projections can achieve this result as well,
but we chose MDS using Euclidean distance calculations because in
comparison to other projections such as principal component anal-
ysis (PCA) [31] and t-distributed Stochastic Neighbor Embedding
(t-SNE) [37] or alternative parameters to MDS, we found the results
easiest to read. Note that any dimension reduction technique pro-
duces projection errors because generally high dimensional spaces
inherently include information that cannot be represented with fewer

Figure 3: ModelSpace, our prototype system for analyzing interaction trails. In this image we see a layout of all the models that have been
created during the experiment described in the Dis-Function case study. Each model is represented by a dot, and we connect the dots for each
user, representing the time between changes to the model. In this image, the width of the lines are varied by the number of points moved during
the corresponding interaction and the dots are shaded by the accuracy values of the models. The legend in the bottom right of the visualization
shows the move count and accuracy scores to which the line width and dot shadings respectively are mapped. In addition, two selected dots
(models by User 6) are highlighted in blue for a feature on the left panel showing which data features they have in common. The top ﬁve
features of these models are also displayed in the two Info Boxes on the right.

dimensions. There are techniques to interpret errors (e.g., [7, 44]).
Incorporating these techniques is out of the scope of this paper but
will be an important future work for this project.

Calculating a spatialization of the states means that we can draw a
scatterplot with a dot for each state, in which the more similar states
are shown closer together. To show connections between states,
i.e. those that occurred in sequence for a single user, we connect the
dots with lines. This results in a connected scatterplot. ModelSpace
is ﬂexible enough to incorporate other techniques of generating a
connected scatterplot as long as the points in the plot represent the
states of the system and states are connected based on the order
in which the states were created. As described below, additional
information can be added to this baseline visualization by mapping
interaction data to lines and dots.

4.3 ModelSpace Prototype Features
Figure 3 shows ModelSpace, the prototype interactive visualization
tool we created to demonstrate numerical analytic provenance, as
described in Section 3. We have designed the ModelSpace prototype
to make possible an extensive analysis of interaction history data
with a straightforward but powerful selection of tools. In the ﬁgure,
the dots represent state models achieved by some participant at
some point in the analysis task. The lines connect the models and
represent order of the of the model updates. The arrows on the lines
indicate the direction of progress from one state to the next. All the
participants start with the same unweighted model in the example
shown, so all the user lines begin at the same point. The layout of
the models makes a clear comparison between the trails of different
users and different user groups possible, but to ﬁnd patterns in the
models and interactions, some additional features are provided.

First, we make the rich interaction data available as annotations to
the dots and lines, visible when the mouse cursor is over the element.

In Figure 8, showing ModelSpace for one of the case studies, the
orange rectangle is the mouse-over text for one dot, displaying the
top ten most signiﬁcant keywords that correspond to that model. In
addition, the layout view supports panning and zooming. With a
state model that includes human-readable features, as in the case of
a model-steering system where the model features are dimensions
of the original data, this provides insight into what was emphasized
to the user at the point in their analysis corresponding to the model.
When applicable, other information can be included here. For exam-
ple, in one of our case studies, the experiment used data with known
ground-truth, so the accuracy of the user model relative to the ground
truth can be shown here to show how similar this user’s provenance
had progressed toward some possible notion of optimum.

To make comparison between different users and user groups
possible, there is a User Selection Panel [A] at the bottom of the
screen. The check boxes enable the users lines and dots in the view,
and the group selection boxes at the top of the panel toggle the entire
group as a whole. These groups could be used to group the users by
any helpful categories. The view can be further customized with the
Display Options Panel [B]. First, the same user groups can be used
to color the lines and dots with the Color by Group option, making
comparison of group behavior much simpler. To simplify the view,
the dots or lines can be hidden. For example, in studying regions of
the space by what the models have in common, the lines may be a
distraction. This menu also controls mappings of data features to the
display. Depending on the data available for the speciﬁc application,
ModelSpace can map size and gray-scale shade of the dots and lines
to data. For example, in Figure 3, the dots are shaded to the accuracy
of the corresponding model. A legend is automatically added to the
bottom to show the upper and lower bounds of the data mapping for
whichever options are active.

When exploring the data, users will look at the information

available as mouseover text for numerous models and lines. The
mouseover modality alone makes it difﬁcult to compare information.
There are two Info Boxes [C] along the right side that persist the in-
formation associated with last two visual elements (dots or lines) to
be clicked. The Clear Info Boxes button empties both boxes. When
trying to compare the contents of multiple elements, seeing two
alongside each other could be insufﬁcient. The Shared Keywords
[D] feature automatically detects what features different models
have in common. The user can click on multiple dots, which are
then colored blue to show they are being included in this comparison.
The shared keywords box shows the keywords that the annotations
for the selected dots have in common. For a model-steering system,
i.e. in our case studies, the annotations of a dot include the names
of the most important dimensions of the original data at that time.
Therefore the shared keyword list shows the salient features of the
data that are emphasized across the selected set of models. This
feature can be used, for example, to discover what makes models
that are shown close together actually similar to each other. Another
usage would be to see what shared features were being shown to
users at diverging points in their analysis.

Finally, there is a search feature, exercised by the Color by
Search [E] box on the left side. The search accepts a string and
highlights dots and lines that fulﬁll the query until Dismiss is clicked.
This can be used to help ﬁnd regions of interest or to look for ele-
ments that correspond to known entities in the analysis, as in Figure
6(c). For dots, this means highlighting models where the keyword
was an important feature. Lines will be highlighted when the cor-
responding interaction sequences involved the search terms. For
example, the user might have been reading lots of documents related
to a certain word before updating the system about its importance.
Searching for that word would show other times when users read
such documents and when it was important to other models.

5 CASE STUDIES
In this section, we demonstrate the capability of ModelSpace by
using it to examine users’ analytic trails from two different case
studies to study their numerical analytic provenance. In both cases,
the participants used a model-steering visual analytics system whose
states can be easily converted to the high-dimensional vector rep-
resentation used by the proposed ModelSpace approach. In these
applications, as a user interacts with the system, the interactions are
used by a machine-learning back-end to learn a new data model,
which then updates the view so the user can iteratively improve
it. Conveniently, creation of a new data model from user feedback
represents an important state in the analytics, and the model’s vector
representation is straightforward.

We cover each case study separately, ﬁrst brieﬂy describing the
application and the experiment from which the data are collected,
then explaining the mapping to ModelSpace and the application-
speciﬁc features added. Finally, we discuss the insights gained by
applying this technique.

5.1 Dis-Function
Dis-Function (Figure 5) is a prototype system that allows users to
leverage their knowledge about data to build a machine learning
model without having to understand the underlying algorithm. In
this system, a user interacts directly with a visual representation of
the data, speciﬁcally a two-dimensional layout of high-dimensional
data.The layout is directly dependent on the model, so by providing
feedback on the layout, the user (a data domain expert) causes
the machine learning algorithm to update the model so that it is
more consistent with the user’s expectation. The newly regenerated
model is used to create a new layout and the process can continue,
iteratively improving the model, until the user is satisﬁed [9]. The
model being learned at each step is a vector of weights, one for each
data feature, and thus can be directly used in ModelSpace.

5.1.1 The Experiment
For this case study we used the experimental data from the authors
of Dis-Function. Their participants include ten university engineer-
ing students (6 male, 4 female) at varying degree levels of study –
ﬁve undergrads, one masters, and four Ph.D.s1 The participants ap-
plied Dis-Function’s model-steering technology to the Wine dataset
from the UCI Machine Learning Repository [36]. These data have
178 instances, each representing one individual wine, and there are
thirteen features, each representing a chemical component. The
authors augmented the dataset with ten synthetic noise features (gen-
erated uniformly at random). Since the participants were not experts
in the chemical composition of wine, Brown et al. provided them
with labels that classiﬁed each data point as a certain type of wine
by coloring the points in the display. The task, then, was to use
Dis-Function by providing feedback to make the visualization more
closely group the points with the same label, removing the inﬂuence
of the noise.

5.1.2 The ModelSpace
As the experiment participants interacted with the system, Dis-
Function logged all the interactions that produced model updates,
and the updated models. These data were straightforward to extract
and comprise a convenient set of state models for our application
of ModelSpace. As seen in the legend at the bottom left of Figure
3, each user’s trail is represented by a different color. All the users
start with the same initial model in the experiment, and thus all the
user lines begin at the same place in ModelSpace.

Because the experiment with Dis-Function uses labeled data, we
can actually calculate for each model produced by each user at each
step, the accuracy of the model at predicting the given classes of the
data. We apply the k-nearest-neighbor algorithm with k = 3 to make
predictions with the Dis-Function models and use ten-fold cross
validation to calculate accuracy scores. These accuracy scores are
visible when the mouse cursor is over a dot, along with the names
of the variables that had the highest contribution to the model at
that point. When the mouse cursor is on top of a line, an annotation
reveals which data points the user manipulated to cause the model
update that happened during the period that the line represents. The
same information used in the mouseover annotations can also be
mapped to the color and size of the dots and lines, i.e. dots can be
shaded or sized to reﬂect the accuracy of the corresponding model,
and lines can be shaded or sized to reﬂect the number of manipulated
data points.

5.1.3 Results
By exploring the ModelSpace generated for Dis-Function and in-
teracting with its various features, we were able to capture some
interesting trends. There is a clear indication that the higher accu-
racies are focused in one area of the visualization as seen in Figure
4(a), where the dots have been colored based on the model accuracy.
The black ellipse shows the region with the strongest models. All
the participants moved in directions of higher accuracy, but for some
(labeled Users 5, 10, 11), the ﬁnal model is not the most accurate
one in the interaction trail. This can be seen in Figure 3 in which
the dots are shaded with the accuracy values of the corresponding
models. Following these users’ lines from start to ﬁnish shows this
non-monotonic progression. This outcome is not unexpected as the
experiment participants were unable to see the accuracy values as
they interacted with Dis-Function.

Another pattern is clear in Figure 4(b), in which each line’s width
is mapped to the number of points manipulated during that interac-
tion period. Participants who travelled a shorter path overall, i.e.,
those who use fewer iterations to reach the ﬁnal model, move more

1The user IDs shown in ModelSpace end at 11 but skip 3 due to one

planned participant who was unable to participate.

(a)

(b)

(c)

Figure 4: Views demonstrating features of the ModelSpace for Dis-Function. In (a), the dots are shaded by the accuracies of the models to
which they correspond (higher accuracies are darker). The area marked by the ellipse contains the higher-accuracy models. In (b), the lines are
colored according to group membership, and their widths encode the number of points involved in the corresponding model update. In (c), the
dots representing models that emphasize noise features are colored black. The rest of the dots are colored based on the users to whom they
correspond.

undergraduate and Ph.D. students’ trails are moving mostly toward
two separate directions. This suggests that these two groups are
taking different approaches to interacting with Dis-Function.

Through these results we are able to gain a better understanding of
the participants in the Dis-Function experiment, and the behaviours
associated with different groups. ModelSpace also clearly under-
scores that through interactions with Dis-Function, all the users were
able to improve their models to attain higher accuracies and reduce
the signiﬁcance of the noise features. While this was known from the
publication about Dis-Function, the authors of that paper were not
able to do such in-depth analysis about the patterns of interactions
that lead to these results.

5.2 Doc-Function
Doc-Function [8] (Figure 7) is a visual analytic tool designed to
enable sensemaking of text corpora through manipulation of a key-
word spatialization. The spatial layout of the keywords encodes
the similarity between keywords with respect to the documents in
which they co-occur. Doc-Function allows users to manipulate the
spatialization of keywords extracted from documents to perform
model-steering without having to understand how the new model is
generated. Based on the user’s evolving understanding and knowl-
edge of the documents in the corpus, the user can move the words
relative to each other to reﬂect the correct relationships and group-
ings. Making changes causes an update to a model that reﬂects
the relative importance of the documents in the corpus, triggering
creation of a new corresponding spatial layout. In this way, Doc-
Function is similar to Dis-Function, except it is designed for text.
There are a number of differences in the technology, but with respect
to ModelSpace, the main difference is that Doc-Function, taking
advantage of the properties of text data, supports a wider variety of
interactions and thus exports richer logs.

5.2.1 The Experiment
In order to visualize the numerical analytic provenance of the users
of this tool, we obtained data from an experiment that was run
to evaluate Doc-Function. The Doc-Function authors conducted
an experiment with 13 participants at a national laboratory (name
withheld for anonymous review) from four different job categories:
professional analysts (2), scientists and engineers (5), interns (5),
and administrative staff (1). The experiment used a data set designed

Figure 5: The Dis-Function prototype. The user interacts directly
with the visualization in (A) by moving the datapoints based on
domain-knowledge. The options in (B) allow the user to undo a
move and recalculate the layout after interaction. Based on how the
points are moved, the underlying metric is updated, and through
(C) and (D) the user is able to visualize the impact of the metric to
the data. (E) displays the original data with the selected datapoint
highlighted.

points during each iteration. Figure 4(b) also reveals another pattern
with the point manipulations. Almost all the users are manipulating
an increasing number of points as they are getting closer to the ﬁnal
model.

Applying the search feature, we can highlight all models that
have the word “noise” in the name of one of their most salient
variables. For these data, that variable name indicates one of the
noise features added for the experiment. Figure 4(c) shows that in
fact these noise features were diminished in importance after the ﬁrst
few interactions with the Dis-Function system. This helps showcase
the effectiveness of Dis-Function at removing that artiﬁcial noise for
its users.

Finally, we can investigate performance differences between
groups of users. The participant group can be used to color the
dots and lines. In Figure 4(b), we use this feature to see that the

(a)

(b)

(c)

Figure 6: Views demonstrating various features of the ModelSpace for Doc-Function. In (a), some lines and dots are colored black to indicate
the corresponding interactions and models reference the word “Aryan”. In (b), the lines are colored by the user groups and the widths of the
lines are mapped to the number of searches made. Note that the “Interns”, colored in red, show an analysis trajectory that is distinctively
different from the others. In (c), the lines are shaded to reﬂect how many documents were read and the dots are colored for the individual users.

Figure 7: The Doc-Function prototype. The user interacts with a pro-
jection of keywords (A) by moving them around into a spatialization
that better represents his understanding of the similarity between
the words. These interactions cause changes to a machine learning
back-end. The pop-up window (B) allows the user to search for a list
of documents that contain one or more words and right column (C)
displays the documents that contain a particular word upon mouse-
over. The buttons on the top (D) allow the user to perform actions
like undoing a move and highlighting all the keywords that belong
to a document. These features assist the user make more informed
movements of the keywords.

Figure 8: ModelSpace for Doc-Function. In this view, the thickness
of a line encodes the time spent by the user during that interaction.
Additionally, two points have been selected (marked in blue) and
their shared keywords are displayed in the Shared Keywords box on
the left panel. Note that this ﬁgure shows only the data display. The
rest of the interface is cropped for efﬁciency but is nearly identical
to what can be seen in Figure 3.

for intelligence training. The 49 documents of the corpus contain a
ﬁctitious terrorist threat that each experiment participant was tasked
to discover. Participants were encouraged to discuss their process in
this think-aloud study, and given as much time as desired (typically
just under an hour). Full details of the study are available elsewhere
[8].

5.2.2 The ModelSpace
Just as with Dis-Function, we constructed a ModelSpace for the Doc-
Function experiment by extracting the various data models about
documents generated by the users with their interactions. Figure 8
shows the ModelSpace built for Doc-Function. The dots represent
the models and the lines are annotated with information about the
interactions that resulted in the models. All these elements are
colored by default to show which user they represent.

The Doc-Function system has a richer interaction set than Dis-
Function, and the logs reﬂect this diversity. The data include records
of viewing documents, using the text search feature, performing
model updates, and using the undo and reset functions. We loaded
these interactions into ModelSpace as annotations to the lines and
thus, rather than showing only model updates, we are able to show
all types of interactions by participants that led them to model up-
dates. In addition, we took advantage of the detailed notes from the
experiment administrator by digitizing them to sets of observations
with timestamps, and incorporating them into the annotations as
well. The annotations include not only what interactions the user
performed, but a distilled version of their think-aloud commentary
about their insights and process.

Beyond annotating the visual elements with the collected data,
we enable the other features to use this information as well. The
search feature can be applied to both the set of salient data features
associated with the dots, and the full set of information annotating
the lines, as in Figure 6(a). The shade and thickness of the lines
can also be mapped to the number of documents read, the number
of word searches made, time spent during the interactions, and the
number of words moved. This rich set of available information
is simple to incorporate in ModelSpace, and makes it possible to
explore the analytic provenance of the participants in much deeper
detail.

5.2.3 Results
Just as with Dis-Function, the ModelSpace of Doc-Function reveals
a number of interesting insights. By using the ModelSpace search
feature to highlight dots and lines that contained keywords, we
saw that the words such as “Aryan” were nearly ubiquitous across
the models and interactions (see Figure 6(a)). We examined the
differences between our participant groups, as seen in Figure 6(b),
by mapping color to group identity (rather than individual user). It
becomes visually apparent that the interns (colored in red) moved
in a direction with their model building that diverged from other
participant groups. This ﬁgure also shows that the interns stand
out as using lower overall numbers of searches. In fact, we can
see by switching options in the left panel, that interns moved fewer
keywords in their model-updates, and read fewer documents2.

Looking in more detail at how many documents the participants
read, we ﬁnd that there is a trend of having higher read counts in
the beginning and lower read counts as the users approach their
ﬁnal models. This can be seen in in Figure 6(c), where the lines
are shaded based on the read count. The starting lines for each
participant appear darker than the lines before the ﬁnal model.

Through ModelSpace, we were able to gain some interesting
insights about the users’ behavior and their approach to the analysis
task. This would have been difﬁcult to accomplish with manual
inspection of logs and interaction trails.

2We cannot guarantee the documents were read in full, but this indicates

the user was able to see their content.

6 DISCUSSION
In the process of making and using the ModelSpace tool, we have
investigated several possibilities and revealed areas for future work
that we will discuss in this section. First, we discuss other uses for
ModelSpace beyond analysis of experimental data. Next we describe
application areas beyond model-steering analytics, including some
preliminary results with interaction data from a visual search task.
We then discuss the complexities of the step of projecting the set
of models in more detail. Finally, we discuss future directions and
implications of this work.

6.1 Uses of Numerical Analytic Provenance
ModelSpace can be used in other applications besides model-
steering visual analytics systems, because the requirement for the
input is simply that there be some software state that can be extracted
and converted to a vector. For people tasked with understanding how
people use software, this broad applicability is an exciting prospect
because existing methods for analyzing the results of experiments
evaluating software can be cumbersome. Aside from analyzing
the results of experiments, this technique could be more broadly
applied to help users understand their own analytic provenance. Sim-
ilarly to the usefulness of undo history in a web browser or more
sophisticated analogs in previous analytics research [4, 23, 27], this
technology could be used to show users not only their interaction
history, but a visualization of their trails with context and ability to
move back and forth between their most useful state models. Visual-
izing for the user the space of states created during their work could
be a transformational way to make this helpful general mechanism
stronger.

Even as the visualization of this space could be useful to individ-
ual users, it could also help managers overseeing multiple analysts.
Someone responsible for the efforts of a team trying to ﬁnd a threat
in a massive corpus of text data could use a ModelSpace-like tool
to view the ongoing progress of analysts and make sure they were
covering different areas of the possible model space, helping to
mitigate bias, which is a subtle and difﬁcult problem facing such
efforts today. Another relevant domain from interactive machine
learning is recommender systems. When evaluating the quality of
a recommender system, researchers use statistical measures. But
with a tool like ModelSpace, it would be possible to gain a deeper
understanding of how different users implicitly and iteratively create
models of what they like through their ratings, comments, purchases,
and other interactions.

6.2 Application Areas
Though the case studies were both performed with model-steering
visual analytics systems, we believe this technology lends itself to a
wider array of applications. As one test of alternative applications,
we applied ModelSpace to a collection of data from an experiment
with an image search task. The “Finding Waldo” study by Brown et
al. [10] included collecting data about how a set of participants found
a drawing of a certain person in a large hand-drawn image using a
search tool that provided basic navigation controls. In that work,
the authors created multiple encodings of interaction sequences
collected from a study of users performing the search task. They
showed that the users could be distinguished into groups by perfor-
mance and other factors by applying machine learning. We apply
ModelSpace to the state space encoding of that work, which char-
acterizes a participant’s interactions up to time t by the sum of all
states of the software they have encountered by that time. States in
this case are the states of the visual search window and thus encode
the zoom level and where the user’s view is centered. ModelSpace
can use these state vectors directly, and we visualize the projection
in Figure 9. Because there is no contextual interaction information
available from this application, we include these results only in the
Discussion as a way of demonstrating the wider applicability of the

beneﬁts and limits of this approach will require others to apply it to
their own problems and evaluate it for their purposes, and we look
forward to seeing the results of such applications.

7 CONCLUSION
In this paper, we have discussed a novel approach to analyzing
user interaction trails with interactive machine learning systems.
Numerical analytic provenance makes it possible to study analytic
provenance by constructing state models from the logs of interac-
tive systems, particularly when certain crucial interactions produce
a new model. Vectors representing models are shown in a layout
that reﬂects their similarity, creating a backdrop for an interactive
visualization annotated with the full spectrum of available interac-
tion information. To showcase this concept, we have provided an
implementation, ModelSpace, with an array of features for explor-
ing analytic provenance in a visualization of the state models. We
applied ModelSpace to two case studies of model-steering visual
analytics systems using logs generated from their original evaluation
experiments. Additionally, we provided an example application of
ModelSpace to a non-visual analytic system, showing how to apply
the vectorization principle for interactions with an image search tool.
The case studies demonstrated the effectiveness and wide applica-
bility of ModelSpace and of numerical analytic provenance concept
by making it possible to explore the interaction data from those
experiments and reveal patterns that would have been difﬁcult to
discover without such a tool.

ACKNOWLEDGMENTS
The research described in this document was sponsored in part by the
U.S. Department of Defense (DOD) through Paciﬁc Northwest Na-
tional Laboratory (PNNL). The views and conclusions contained in
this document are those of the authors and should not be interpreted
as representing the ofﬁcial policies, either expressed or implied, of
the U.S. Government.

REFERENCES
[1] S. Amershi, J. Fogarty, and D. Weld. Regroup: Interactive machine
learning for on-demand group creation in social networks. In Pro-
ceedings of the SIGCHI Conference on Human Factors in Computing
Systems, pp. 21–30. ACM, 2012.

[2] S. Amershi, B. Lee, A. Kapoor, R. Mahajan, and B. Christian. Human-
guided machine learning for fast and accurate network alarm triage. In
Proceedings of the International Joint Conference on Artiﬁcal Intelli-
gence (IJCAI), pp. 2564–2569, 2011.

[3] B. Bach, C. Shi, N. Heulot, T. Madhyastha, T. Grabowski, and P. Drag-
icevic. Time curves: Folding time to visualize patterns of temporal
evolution in data. IEEE transactions on visualization and computer
graphics, 22(1):559–568, 2016.

[4] L. Bavoil, S. P. Callahan, P. J. Crossno, J. Freire, C. E. Scheidegger,
C. T. Silva, and H. T. Vo. Vistrails: Enabling interactive multiple-view
visualizations. In Visualization, 2005. VIS 05. IEEE, pp. 135–142.
IEEE, 2005.

[5] M. Bostock, V. Ogievetsky, and J. Heer. D3: Data-driven documents.

IEEE Trans. Visualization & Comp. Graphics (Proc. InfoVis), 2011.

[6] L. Bradel, C. North, and L. House. Multi-model semantic interaction
for text analytics. In Visual Analytics Science and Technology (VAST),
2014 IEEE Conference on, pp. 163–172. IEEE, 2014.

[7] M. Brehmer, M. Sedlmair, S. Ingram, and T. Munzner. Visualizing
dimensionally-reduced data: Interviews with analysts and a character-
ization of task sequences. In Proceedings of the Fifth Workshop on
Beyond Time and Errors: Novel Evaluation Methods for Visualization,
pp. 1–8. ACM, 2014.

[8] E. T. Brown. Learning from Users’ Interactions with Visual Analytics

Systems. PhD thesis, TUFTS UNIVERSITY, 2015.

[9] E. T. Brown, J. Liu, C. E. Brodley, and R. Chang. Dis-function:
Learning distance functions interactively. In Proceedings of the IEEE
Conference on Visual Analytics Science and Technology (VAST), pp.
83–92. IEEE, 2012.

Figure 9: ModelSpace of the directional vectors of users after inter-
acting with a state space system to locate the drawing of a certain
person. The blue lines represent the fast group of users and the
yellow lines represent the slow group of users.

technique. In the ﬁgure, the groups of participants with the fastest
and slowest completion times are highlighted by color, and we can
see how different their trails are through the space of models at a
glance. The faster users have covered a broader area of the model
space than the slower users. Further, this application showcases
a much larger sample of states, showing how the compactness of
representation is useful as experiment sizes grow.

6.3 Future Work
In this section we provide a number of suggestions to future users
of this technology. First, we believe it is possible that a projection
method outside the scope of this work could be a better ﬁt to this
type of data. To our knowledge, there is no automatic method for
selecting the ideal projection for this task, so the user could be given
a choice.

The current version of ModelSpace makes it possible to review a
signiﬁcant amount of information, but statistical and model-building
tools within ModelSpace could strengthen conclusions of the analy-
sis. For example, after discovering a pattern in the main visualization,
e.g. a connection between the number of interactions performed be-
fore generating a model and the model’s likelihood of including
some particular variable, there could be a feature to test the hypoth-
esis by calculating a correlation between those occurrences in the
data. Perhaps, after discovering interesting comparisons between
two groups of models, the user could indicate the groups, and the sys-
tem would respond with an automatic categorization of what model
features differentiate them. Finally, with analytics software getting
increasingly complex, the ModelSpace concept could be adapted
for more sophisticated types of models, as in the multi-model text
analytics of StarSPIRE [6].

We believe this numerical form of analytic provenance opens up
new avenues for using visualization to explore users’ interaction
patterns. Unlike traditional visualizations of interaction logs, the
use of ModelSpace allows immediate comparison of the analysis
trails between multiple participants. A thorough examination of the

[10] E. T. Brown, A. Ottley, H. Zhao, Q. Lin, R. Souvenir, A. Endert, and
R. Chang. Finding waldo: Learning about users from their interactions.
2014.

[11] L. Buitinck, G. Louppe, M. Blondel, F. Pedregosa, A. Mueller,
O. Grisel, V. Niculae, P. Prettenhofer, A. Gramfort, J. Grobler, R. Lay-
ton, J. VanderPlas, A. Joly, B. Holt, and G. Varoquaux. API design for
machine learning software: experiences from the scikit-learn project.
In ECML PKDD Workshop: Languages for Data Mining and Machine
Learning, pp. 108–122, 2013.

[12] S. P. Callahan, J. Freire, E. Santos, C. E. Scheidegger, C. T. Silva,
and H. T. Vo. Vistrails: visualization meets data management. In
Proceedings of the 2006 ACM SIGMOD international conference on
Management of data, pp. 745–747. ACM, 2006.

[13] Y. Chen, P. Xu, and L. Ren. Sequence synopsis: Optimize visual
summary of temporal event data. IEEE transactions on visualization
and computer graphics, 24(1):45–55, 2018.

[14] P. Cowley, L. Nowell, and J. Scholtz. Glass box: An instrumented
infrastructure for supporting human interaction with information. In
System Sciences, 2005. HICSS’05. Proceedings of the 38th Annual
Hawaii International Conference on, pp. 296c–296c. IEEE, 2005.

[15] S. M. S. da Cruz, M. L. M. Campos, and M. Mattoso. Towards a
taxonomy of provenance in scientiﬁc workﬂow management systems.
In Services-I, 2009 World Conference on, pp. 259–266. IEEE, 2009.

[16] S. B. Davidson and J. Freire. Provenance and scientiﬁc workﬂows:
challenges and opportunities. In Proceedings of the 2008 ACM SIG-
MOD international conference on Management of data, pp. 1345–1350.
ACM, 2008.

[17] W. Dou, D. H. Jeong, F. Stukes, W. Ribarsky, H. R. Lipford, and
R. Chang. Recovering reasoning processes from user interactions.
IEEE Computer Graphics and Applications, (3):52–61, 2009.

[18] C. Dunne, N. Henry Riche, B. Lee, R. Metoyer, and G. Robertson.
GraphTrail: Analyzing large multivariate, heterogeneous networks
while supporting exploration history. In Proceedings of the SIGCHI
conference on human factors in computing systems, pp. 1663–1672.
ACM, 2012.

[19] A. Endert, P. Fiaux, and C. North. Semantic interaction for visual
text analytics. In Proceedings of the SIGCHI Conference on Human
Factors in Computing Systems, pp. 473–482. ACM, 2012.

[20] A. Endert, C. Han, D. Maiti, L. House, S. Leman, and C. North.
Observation-level interaction with statistical models for visual ana-
lytics. In Visual Analytics Science and Technology (VAST), 2011 IEEE
Conference on, pp. 121–130. IEEE, 2011.

[21] J. Fogarty, D. Tan, A. Kapoor, and S. Winder. Cueﬂik: interactive con-
cept learning in image search. In Proceedings of the sigchi conference
on human factors in computing systems, pp. 29–38. ACM, 2008.

[22] J. Freire, D. Koop, E. Santos, and C. T. Silva. Provenance for com-
putational tasks: A survey. Computing in Science & Engineering,
10(3):11–21, 2008.

[23] D. Gotz and M. X. Zhou. Characterizing users’ visual analytic activity
for insight provenance. Information Visualization, 8(1):42–55, 2009.
[24] T. Grossman, J. Matejka, and G. Fitzmaurice. Chronicle: capture,
exploration, and playback of document workﬂow histories. In Proceed-
ings of the 23nd annual ACM symposium on User interface software
and technology, pp. 143–152. ACM, 2010.

[25] Y. Han, G. D. Abowd, and J. Stasko. Flexible organization, exploration,
and analysis of visualization application interaction events using visual
analytics.

[26] S. Haroz, R. Kosara, and S. L. Franconeri. The connected scatterplot
for presenting paired time series. IEEE transactions on visualization
and computer graphics, 22(9):2174–2186, 2016.

[27] J. Heer, J. Mackinlay, C. Stolte, and M. Agrawala. Graphical histories
for visualization: Supporting analysis, communication, and evalua-
tion. Visualization and Computer Graphics, IEEE Transactions on,
14(6):1189–1196, 2008.

[28] M. Hellkamp. Python bottle. http://bottlepy.org/, 2016 (ac-

cessed September 21, 2016).

[29] T. Jankun-Kelly, K.-L. Ma, and M. Gertz. A model and framework for
visualization exploration. Visualization and Computer Graphics, IEEE
Transactions on, 13(2):357–369, 2007.

[30] D. H. Jeong, W. Dou, H. R. Lipford, F. Stukes, R. Chang, and W. Rib-

1978.

[35] S. Leman, L. House, D. Maiti, A. Endert, and C. North. Visual to

parametric interaction (v2pi). PLoS ONE, 8(3):e50474, 2013.

[36] M. Lichman. UCI machine learning repository, 2013.
[37] L. v. d. Maaten and G. Hinton. Visualizing data using t-sne. Journal of

Machine Learning Research, 9(Nov):2579–2605, 2008.

arsky. Evaluating the relationship between user interaction and ﬁnan-
cial visual analysis. In Visual Analytics Science and Technology, 2008.
VAST’08. IEEE Symposium on, pp. 83–90. IEEE, 2008.

[31] I. Jolliffe. Principal component analysis. Wiley Online Library, 2002.
[32] N. Kadivar, V. Chen, D. Dunsmuir, E. Lee, C. Qian, J. Dill, C. Shaw,
and R. Woodbury. Capturing and supporting the analysis process. In
Visual Analytics Science and Technology, 2009. VAST 2009. IEEE
Symposium on, pp. 131–138. IEEE, 2009.

[33] M. Kreuseler, T. Nocke, and H. Schumann. A history mechanism for
visual data mining. In Information Visualization, 2004. INFOVIS 2004.
IEEE Symposium on, pp. 49–56. IEEE, 2004.

[34] J. B. Kruskal and M. Wish. Multidimensional scaling, vol. 11. Sage,

[38] C. North, R. Chang, A. Endert, W. Dou, R. May, B. Pike, and G. Fink.
Analytic provenance: process+ interaction+ insight. In Proceedings of
the 2011 annual conference extended abstracts on Human factors in
computing systems, pp. 33–36. ACM, 2011.

[39] W. A. Pike, J. Stasko, R. Chang, and T. A. O’Connell. The science of

interaction. Information Visualization, 8(4):263–274, 2009.

[40] E. D. Ragan, A. Endert, J. Sanyal, and J. Chen. Characterizing prove-
nance in visualization and data analysis: an organizational framework
of provenance types and purposes. IEEE transactions on visualization
and computer graphics, 22(1):31–40, 2016.

[41] J. Z. Self, L. House, S. Leman, and C. North. Andromeda: Observation-
level and parametric interaction for exploratory data analysis. Technical
report, Technical report, Department of Computer Science, Virginia
Tech, Blacksburg, Virginia, 2015.

[42] Y. B. Shrinivasan and J. J. van Wijk. Supporting the analytical reason-
ing process in information visualization. In Proceedings of the SIGCHI
conference on human factors in computing systems, pp. 1237–1246.
ACM, 2008.

[43] A. Singh, L. Bradel, A. Endert, R. Kincaid, C. Andrews, and C. North.
Supporting the cyber analytic process using visual history on large
displays. In Proceedings of the 8th International Symposium on Visual-
ization for Cyber Security, p. 3. ACM, 2011.

[44] J. Stahnke, M. D¨ork, B. M¨uller, and A. Thom. Probing projections: In-
teraction techniques for interpreting arrangements and errors of dimen-
sionality reductions. IEEE transactions on visualization and computer
graphics, 22(1):629–638, 2016.

[45] J. J. Thomas and K. A. Cook. Illuminating the path: The research
and development agenda for visual analytics. IEEE Computer Society
Press, 2005.

[46] S. van den Elzen, D. Holten, J. Blaas, and J. J. van Wijk. Reducing
snapshots to points: A visual analytics approach to dynamic network
exploration. IEEE transactions on visualization and computer graphics,
22(1):1–10, 2016.

[47] S. Van Der Walt, S. C. Colbert, and G. Varoquaux. The numpy array: a
structure for efﬁcient numerical computation. Computing in Science &
Engineering, 13(2):22–30, 2011.

[48] J. J. Van Wijk. The value of visualization. In VIS 05. IEEE Visualization,

2005., pp. 79–86. IEEE, 2005.

[49] E. Wall, S. Das, R. Chawla, B. Kalidindi, E. Brown, and A. Endert.
Podium: Ranking data using mixed-initiative visual analytics. IEEE
Transactions on Visualization and Computer Graphics, 2017.

[50] K. Xu, S. Attﬁeld, T. Jankun-Kelly, A. Wheat, P. H. Nguyen, and
N. Selvaraj. Analytic provenance for sensemaking: A research agenda.
IEEE computer graphics and applications, 35(3):56–64, 2015.

[51] E. Zgraggen, S. Drucker, D. Fisher, R. DeLine, and R. DeLine.
(s—qu)eries: Visual regular expressions for querying and exploring
event sequences. ACM - Association for Computing Machinery, April
2015.

","{""0"":{""0"":""ieee*"",""1"":""conference*"",""2"":""sigchi*"",""3"":""symposium*"",""4"":""depaul*""},""1"":{""0"":""high"",""1"":""level"",""2"":""shows"",""3"":""read*"",""4"":""colored""},""2"":{""0"":""visualization"",""1"":""analytics"",""2"":""software*"",""3"":""space"",""4"":""computer*""},""3"":{""0"":""function*"",""1"":""figure*"",""2"":""work*"",""3"":""feature*"",""4"":""results""},""4"":{""0"":""users"",""1"":""lines*"",""2"":""systems*"",""3"":""points*"",""4"":""groups*""},""5"":{""0"":""logs*"",""1"":""documents*"",""2"":""keywords*"",""3"":""words*"",""4"":""transactions""},""pos"":{""0"":1,""1"":2,""2"":3,""3"":4,""4"":5}}",2018,{},False,False,journalArticle,False,4DZQWUEH,[],self.user,"{""C"":{""0"":6.4467759151,""1"":5.0750518983,""10"":17.5306788416,""11"":6.0515656567,""12"":4.5107490771,""13"":37.2942482974,""14"":4.6022678384,""15"":7.9707390113,""16"":4.0268900794,""17"":5.2835937436,""18"":8.66056412,""19"":8.3605252748,""2"":5.020616892,""20"":5.2548801712,""21"":6.3401412241,""22"":6.5316297225,""23"":5.0999619996,""24"":6.3547069132,""25"":10.4224077487,""26"":12.1182302088,""27"":16.4101772966,""28"":5.987475151,""29"":4.3026359666,""3"":11.6896257251,""30"":14.2835437311,""31"":4.1347207939,""32"":4.3969490586,""33"":13.7823668913,""34"":13.113207019,""35"":4.0960568619,""36"":5.5920740547,""37"":5.7040699754,""38"":10.2276386123,""39"":8.1424057922,""4"":4.174977967,""40"":5.5746082226,""41"":4.9472157657,""42"":4.8495920226,""43"":9.4575675894,""44"":9.9034374731,""45"":6.3878219118,""46"":4.7740985491,""47"":10.4082121702,""48"":8.8363510116,""49"":4.9271143491,""5"":9.6800126209,""50"":5.3175895237,""51"":6.4830913153,""52"":6.3380376565,""53"":7.6958957184,""54"":10.351199848,""55"":4.8638800606,""56"":8.5261341887,""57"":5.1108916744,""58"":5.7754330627,""59"":6.5530936935,""6"":15.4210960039,""60"":7.9123665961,""61"":6.0251089617,""62"":5.1160294563,""63"":6.4360857112,""64"":4.7616166881,""65"":4.7459431569,""66"":5.5509072965,""67"":7.1637980509,""68"":6.2114700874,""69"":4.8042201227,""7"":8.177932034,""70"":5.1096752391,""71"":6.5352339968,""72"":4.6552756966,""73"":6.3713027744,""74"":4.2287033668,""75"":4.1292102209,""76"":4.0626098871,""77"":4.3619523589,""78"":4.4687307723,""8"":6.2641604504,""9"":16.4011312156},""Unnamed: 0"":{""0"":0,""1"":1,""10"":10,""11"":11,""12"":12,""13"":13,""14"":14,""15"":15,""16"":16,""17"":17,""18"":18,""19"":19,""2"":2,""20"":20,""21"":21,""22"":22,""23"":23,""24"":24,""25"":25,""26"":26,""27"":27,""28"":28,""29"":29,""3"":3,""30"":30,""31"":31,""32"":32,""33"":33,""34"":34,""35"":35,""36"":36,""37"":37,""38"":38,""39"":39,""4"":4,""40"":40,""41"":41,""42"":42,""43"":43,""44"":44,""45"":45,""46"":46,""47"":47,""48"":48,""49"":49,""5"":5,""50"":50,""51"":51,""52"":52,""53"":54,""54"":55,""55"":56,""56"":57,""57"":58,""58"":59,""59"":60,""6"":6,""60"":62,""61"":63,""62"":64,""63"":65,""64"":66,""65"":67,""66"":68,""67"":69,""68"":70,""69"":73,""7"":7,""70"":74,""71"":75,""72"":76,""73"":77,""74"":79,""75"":80,""76"":81,""77"":82,""78"":83,""8"":8,""9"":9},""count"":{""0"":176,""1"":138,""10"":72,""11"":64,""12"":62,""13"":62,""14"":60,""15"":54,""16"":48,""17"":48,""18"":42,""19"":40,""2"":136,""20"":36,""21"":34,""22"":34,""23"":34,""24"":32,""25"":30,""26"":28,""27"":28,""28"":26,""29"":26,""3"":118,""30"":26,""31"":24,""32"":24,""33"":24,""34"":24,""35"":22,""36"":22,""37"":22,""38"":22,""39"":20,""4"":108,""40"":20,""41"":18,""42"":18,""43"":18,""44"":18,""45"":16,""46"":16,""47"":16,""48"":16,""49"":14,""5"":90,""50"":14,""51"":14,""52"":14,""53"":14,""54"":12,""55"":12,""56"":12,""57"":12,""58"":12,""59"":12,""6"":90,""60"":12,""61"":10,""62"":10,""63"":10,""64"":10,""65"":10,""66"":10,""67"":10,""68"":8,""69"":8,""7"":86,""70"":8,""71"":8,""72"":8,""73"":8,""74"":6,""75"":6,""76"":6,""77"":6,""78"":6,""8"":84,""9"":80},""exemplar"":{""0"":null,""1"":null,""10"":null,""11"":null,""12"":""*"",""13"":""*"",""14"":null,""15"":""*"",""16"":""*"",""17"":null,""18"":""*"",""19"":null,""2"":null,""20"":""*"",""21"":null,""22"":null,""23"":""*"",""24"":""*"",""25"":""*"",""26"":""*"",""27"":""*"",""28"":null,""29"":""*"",""3"":null,""30"":null,""31"":""*"",""32"":""*"",""33"":null,""34"":""*"",""35"":null,""36"":""*"",""37"":null,""38"":null,""39"":null,""4"":null,""40"":null,""41"":""*"",""42"":""*"",""43"":null,""44"":null,""45"":null,""46"":null,""47"":null,""48"":null,""49"":null,""5"":null,""50"":""*"",""51"":null,""52"":""*"",""53"":null,""54"":null,""55"":null,""56"":null,""57"":null,""58"":null,""59"":""*"",""6"":""*"",""60"":""*"",""61"":null,""62"":null,""63"":null,""64"":""*"",""65"":null,""66"":null,""67"":""*"",""68"":""*"",""69"":null,""7"":""*"",""70"":""*"",""71"":null,""72"":null,""73"":null,""74"":null,""75"":""*"",""76"":null,""77"":""*"",""78"":null,""8"":null,""9"":""*""},""pos"":{""0"":1,""1"":1,""10"":5,""11"":6,""12"":2,""13"":1,""14"":7,""15"":3,""16"":1,""17"":4,""18"":2,""19"":8,""2"":2,""20"":4,""21"":1,""22"":9,""23"":3,""24"":5,""25"":5,""26"":3,""27"":2,""28"":2,""29"":4,""3"":3,""30"":10,""31"":6,""32"":7,""33"":11,""34"":8,""35"":3,""36"":4,""37"":5,""38"":5,""39"":12,""4"":1,""40"":13,""41"":6,""42"":4,""43"":5,""44"":9,""45"":7,""46"":8,""47"":14,""48"":9,""49"":15,""5"":2,""50"":6,""51"":16,""52"":6,""53"":10,""54"":17,""55"":7,""56"":18,""57"":19,""58"":11,""59"":12,""6"":1,""60"":13,""61"":20,""62"":21,""63"":22,""64"":3,""65"":23,""66"":14,""67"":4,""68"":5,""69"":10,""7"":2,""70"":15,""71"":11,""72"":24,""73"":12,""74"":13,""75"":6,""76"":14,""77"":16,""78"":25,""8"":4,""9"":3},""sigma_nor"":{""0"":1.4624135227,""1"":1.4048252975,""10"":2.9116151929,""11"":1.67948052,""12"":1.5071926809,""13"":5.366443122,""14"":1.5249857244,""15"":1.9689014641,""16"":1.4985618203,""17"":1.6637053861,""18"":2.1685835821,""19"":2.1487976299,""2"":1.4030223359,""20"":1.7371513727,""21"":1.9171983782,""22"":1.9461945131,""23"":1.7294043103,""24"":1.940210017,""25"":2.6095587611,""26"":2.92797482,""27"":3.6291302719,""28"":1.9504864062,""29"":1.6673923013,""3"":2.0169914349,""30"":3.3444284098,""31"":1.6557520891,""32"":1.7011458261,""33"":3.3258341076,""34"":3.2099973678,""35"":1.6666773568,""36"":1.9339898389,""37"":1.9540015792,""38"":2.7622853115,""39"":2.4335517567,""4"":1.3692904978,""40"":1.9589395932,""41"":1.8692322528,""42"":1.8505217603,""43"":2.7336828624,""44"":2.8191379461,""45"":2.1848019737,""46"":1.8632009633,""47"":2.9860307337,""48"":2.6727724961,""49"":1.9242900758,""5"":1.9487515196,""50"":2.0054653476,""51"":2.2477596874,""52"":2.2176047097,""53"":2.4998876929,""54"":3.1375376181,""55"":1.9432311674,""56"":2.7403149713,""57"":1.9969928534,""58"":2.1416292329,""59"":2.3108858361,""6"":2.5212192471,""60"":2.606729428,""61"":2.2422122982,""62"":2.0342102294,""63"":2.3362458933,""64"":1.9531187643,""65"":1.9495325797,""66"":2.1337125171,""67"":2.5027502213,""68"":2.333975408,""69"":1.9939949401,""7"":1.8151596271,""70"":2.0677904817,""71"":2.4121942093,""72"":1.9580111441,""73"":2.3725897217,""74"":1.8684996165,""75"":1.8430237887,""76"":1.8259703663,""77"":1.902618835,""78"":1.9299601,""8"":1.6267612063,""9"":2.7061192773},""topic"":{""0"":-1,""1"":4,""10"":-1,""11"":-1,""12"":3,""13"":0,""14"":-1,""15"":2,""16"":5,""17"":2,""18"":5,""19"":-1,""2"":-1,""20"":4,""21"":1,""22"":-1,""23"":3,""24"":4,""25"":2,""26"":5,""27"":0,""28"":1,""29"":3,""3"":-1,""30"":-1,""31"":2,""32"":2,""33"":-1,""34"":2,""35"":1,""36"":1,""37"":3,""38"":1,""39"":-1,""4"":2,""40"":-1,""41"":1,""42"":5,""43"":5,""44"":2,""45"":1,""46"":1,""47"":-1,""48"":1,""49"":-1,""5"":2,""50"":5,""51"":-1,""52"":4,""53"":1,""54"":-1,""55"":4,""56"":-1,""57"":-1,""58"":1,""59"":1,""6"":3,""60"":1,""61"":-1,""62"":-1,""63"":-1,""64"":0,""65"":-1,""66"":1,""67"":0,""68"":0,""69"":2,""7"":4,""70"":1,""71"":2,""72"":-1,""73"":2,""74"":2,""75"":3,""76"":2,""77"":1,""78"":-1,""8"":-1,""9"":4},""vector"":{""0"":""[ 1.2348217   1.5294578  -0.25606734 -1.2243673  -3.165208    1.9977219\n  1.314608    0.11853004  1.743843   -0.95267653]"",""1"":""[ 1.4454055  1.2920462 -0.9944749 -0.660421  -3.226034   1.9897597\n  0.4549783  0.3203068  1.4691557 -1.2526677]"",""10"":""[ 1.6824716   1.6235716  -0.7006505  -1.392214   -3.6417663   2.2935772\n  0.25314805  0.3099651   1.0467976  -0.8133689 ]"",""11"":""[ 1.2476904   1.3933829  -0.54560626 -1.2984945  -3.2511492   2.248792\n  0.5476783   0.47542948  1.1068952  -1.1746223 ]"",""12"":""[ 1.1513911   1.3493657  -0.19698009 -1.4888074  -3.43422     2.172513\n  1.465724    0.14479393  1.5364869  -1.0383372 ]"",""13"":""[ 1.3223897   1.2372546  -1.3230757  -1.7924638  -3.866295    0.33312398\n  0.91346407  0.167644    2.3026912  -0.5863156 ]"",""14"":""[ 1.2757555   1.3793136  -0.1496075  -0.9643844  -3.2106948   2.298796\n  0.7930395   0.09362616  1.38756    -0.87708604]"",""15"":""[ 1.2880462   1.3396487  -1.5550249  -0.8411083  -4.0362415   1.1194593\n  0.4929752   0.28084525  2.0556016  -0.7462794 ]"",""16"":""[ 1.939401    1.1124923  -1.5050192  -0.92602414 -3.739273    1.477029\n  0.4365868  -0.01537526  1.4399904  -0.68699247]"",""17"":""[ 1.4028018   2.0593925  -1.3062162  -1.1720083  -3.7237782   1.1662936\n  0.39399534  0.446768    2.1352928  -0.85850435]"",""18"":""[ 2.1068852   0.82500744 -1.2335654  -0.93615824 -3.6350868   1.6692455\n  0.6318461  -0.20480393  1.3091333  -0.7471024 ]"",""19"":""[ 1.2190248   1.0485473  -0.63750637 -1.2332923  -3.8137202   1.4132488\n  1.6721488  -0.15483479  1.9629987  -0.8332056 ]"",""2"":""[ 0.9059156   1.6785364  -0.75787574 -1.2092423  -4.238378    0.917869\n  0.95713913  0.1034831   2.353211   -0.36831832]"",""20"":""[ 1.568929    1.680477   -0.45629084 -1.4292413  -3.35688     2.2299886\n  0.5789974   0.2880769   1.3585596  -1.2875923 ]"",""21"":""[ 0.79505974  1.9840039   0.00628943 -2.5417566  -3.9917006   1.9478581\n  0.60850734  0.82536113  1.1028091  -1.1749811 ]"",""22"":""[ 1.4851997   2.2292736  -0.71331364 -1.2929456  -3.4865863   1.5134933\n  0.47684872  0.3416855   2.0679164  -0.8834835 ]"",""23"":""[ 0.9647596   1.0699384  -0.42754    -1.3764877  -3.7507408   1.8443803\n  1.6375616   0.08273156  1.7010213  -0.9787769 ]"",""24"":""[ 1.4417135   1.4615356  -0.7282696  -0.8916272  -3.1429534   2.1347487\n  0.46288645  0.34783897  1.376373   -1.2423363 ]"",""25"":""[ 1.3991945   1.6451386  -1.7114452  -1.1754715  -4.0440335   0.8476247\n  0.3817037   0.40836596  2.139295   -0.76750535]"",""26"":""[ 1.8267913   0.9835167  -0.83015174 -0.89414924 -3.8318465   1.7673764\n  0.7421214  -0.208423    1.6123616  -0.4807052 ]"",""27"":""[ 1.626782    1.1259847  -1.4251281  -1.6620421  -3.837257    0.34453937\n  1.0581325  -0.05744368  2.2165732  -0.9178988 ]"",""28"":""[ 0.9646619   1.8608224  -0.40990818 -2.0143278  -3.7483888   1.8880532\n  0.6615131   0.6347747   1.4425333  -1.3956192 ]"",""29"":""[ 0.7068305   1.3800217   0.05459697 -1.492526   -3.6838279   1.9453325\n  1.3210291   0.16663721  1.6714     -0.81222004]"",""3"":""[ 1.5398685   1.8241681  -0.5628183  -1.139899   -3.0413682   1.7394054\n  0.90493923  0.16394722  1.8845012  -0.97706664]"",""30"":""[ 1.4964777   1.4691821  -0.62452096 -1.4348831  -4.07435     1.7971146\n  0.97470057  0.07194129  1.9933107  -1.4803044 ]"",""31"":""[ 1.0914824   1.5050799  -1.5419025  -1.1019843  -3.976913    0.90722966\n  0.54724836  0.42702585  2.140278   -1.0601418 ]"",""32"":""[ 1.2103268   1.6813136  -1.5389752  -1.1608644  -4.122798    0.68225855\n  0.5729827   0.34151733  2.4032063  -0.7071114 ]"",""33"":""[ 1.7667464   0.8978344  -1.3516275  -1.3336818  -3.7046266   0.83269507\n  0.9609185  -0.14694007  1.856183   -1.0314806 ]"",""34"":""[ 1.3484962   1.7302675  -1.4186442  -1.0786351  -4.156565    0.95645577\n  0.3159499   0.32640514  2.2239487  -0.52233875]"",""35"":""[ 0.9816704   1.1697801   0.25212967 -1.6660042  -3.598293    2.426401\n  1.1617247   0.14421353  1.0285095  -0.7381223 ]"",""36"":""[ 0.758851    1.2191379   0.39203092 -2.0492795  -3.9117787   2.2751915\n  1.4087937   0.2045929   1.0975577  -0.57423174]"",""37"":""[ 1.5764126   0.89513    -0.56395715 -1.1316302  -3.6305492   1.8685141\n  1.2467436  -0.18058737  1.5671998  -1.0485883 ]"",""38"":""[ 1.0180328   1.5303909   0.04938738 -2.1493907  -4.02382     2.319481\n  0.6908042   0.44289023  0.74509627 -0.4559344 ]"",""39"":""[ 1.3531499   1.4498613  -0.5602528  -1.8693714  -3.808757    0.7119679\n  1.2855482  -0.07834192  2.114686   -0.46125948]"",""4"":""[ 1.1233034   1.73087    -1.3164678  -0.9714647  -4.308414    0.85248244\n  0.47019094  0.26907608  2.3825016  -0.4183654 ]"",""40"":""[ 0.85022366  1.1530254  -0.06689313 -1.5741019  -3.847586    1.9888434\n  1.5739938   0.08047376  1.6181132  -0.8383837 ]"",""41"":""[ 0.7405798   1.2596244   0.48123106 -2.1332822  -3.8950129   2.407036\n  1.2293755   0.2705246   0.8811885  -0.54103076]"",""42"":""[ 1.8635851   1.0457277  -0.72286654 -0.9960248  -3.6264002   2.0543723\n  0.6619301  -0.11254095  1.347245   -0.7357487 ]"",""43"":""[ 1.8718297   0.9127335  -1.3240854  -0.8719244  -3.6011267   1.4644789\n  0.6160298  -0.10142308  1.5053012  -0.8901034 ]"",""44"":""[ 0.9411627   1.5942154  -1.3741634  -1.4289021  -4.1374717   0.8275829\n  0.7069277   0.46245706  2.157316   -1.0191149 ]"",""45"":""[ 0.57167065  1.6689606   0.07277437 -2.4084835  -4.045031    1.8205892\n  0.9714449   0.57940376  1.283939   -0.8401265 ]"",""46"":""[ 0.9118852   1.559547    0.17178556 -2.2440166  -3.9633965   2.3727643\n  0.79175234  0.49578178  0.75989413 -0.6049725 ]"",""47"":""[ 1.3711687e+00  1.0542657e+00 -9.1054982e-01 -1.2023484e+00\n -4.1763735e+00  1.4982128e+00  1.0831538e+00 -7.9244032e-04\n  2.0594244e+00 -1.2439975e+00]"",""48"":""[ 0.63740104  1.1097289   0.47293913 -1.9037153  -3.9339447   2.529337\n  1.1494234   0.11276092  0.828799   -0.5935072 ]"",""49"":""[ 0.71722895  1.5429696  -0.5484986  -1.8583928  -3.9655693   1.2283728\n  1.1234981   0.37709218  2.0196223  -0.5473278 ]"",""5"":""[ 1.0435727   1.5234138  -1.2033299  -0.91847944 -4.2663965   0.82857835\n  0.7122951   0.13241434  2.3525949  -0.46879396]"",""50"":""[ 1.9691392   0.7921189  -1.0135175  -0.8368867  -3.6032546   1.6892508\n  0.7519323  -0.27420732  1.471515   -0.73969233]"",""51"":""[ 1.6198382   1.1289712  -0.7656346  -1.3028893  -3.988634    1.8659189\n  0.72651404  0.00977143  1.4448304  -0.6186927 ]"",""52"":""[ 1.5584176   1.688506   -0.51970345 -0.98754674 -3.1487384   2.0938768\n  0.5194101   0.20992766  1.5533094  -1.0668641 ]"",""53"":""[ 1.0286844   1.7563348  -0.14364654 -2.1453075  -3.6303275   2.1460254\n  0.74714017  0.60375607  1.1577457  -1.211358  ]"",""54"":""[ 1.7649624   1.4695152  -1.4039727  -1.0962257  -3.8419583   1.6745632\n  0.29862726  0.20803455  1.4127591  -0.6877607 ]"",""55"":""[ 1.5828533   1.1566982  -0.35917965 -1.1465641  -3.3526661   2.2330577\n  0.9098976  -0.00481059  1.3034505  -1.0217795 ]"",""56"":""[ 1.7569517   1.6230232  -1.2588981  -1.054378   -3.5941541   1.8320073\n  0.16984288  0.29078236  1.3407934  -0.81775504]"",""57"":""[ 1.1050876   1.7138878  -0.27544278 -1.8760438  -3.5928483   2.079792\n  0.85559064  0.4597141   1.4010993  -1.2933486 ]"",""58"":""[ 0.596183    1.4708751   0.53225666 -2.3564405  -3.9348142   2.2735128\n  1.0977223   0.42263487  0.88167614 -0.6386239 ]"",""59"":""[ 0.6461115   1.8148383   0.05185739 -2.450363   -3.9808009   2.0196118\n  0.75475454  0.71054137  1.1102847  -1.0010551 ]"",""6"":""[ 0.7131147   1.5889056  -0.23127688 -1.6903561  -3.9363163   1.4634838\n  1.2375201   0.23010206  1.9862615  -0.55341613]"",""60"":""[ 0.5966837   1.4706886   0.324321   -2.2496755  -3.8795059   2.109755\n  1.1222403   0.44907033  1.1310239  -0.79235464]"",""61"":""[ 1.5740228   2.0079503  -0.6372333  -1.1552935  -3.2737641   1.8504438\n  0.4831096   0.28866538  1.7753567  -0.9603371 ]"",""62"":""[ 1.1540724   1.5032554  -0.30799112 -1.8546288  -3.905156    0.9893999\n  1.319506   -0.03358072  1.9982874  -0.50756073]"",""63"":""[ 1.3019891   1.1789445  -0.94409865 -0.6912425  -3.305786    1.9552053\n  0.7413636   0.30873415  1.5373117  -1.2682194 ]"",""64"":""[ 1.5070685   1.1791397  -1.2188439  -1.8909154  -3.7188015   0.23458835\n  1.056828    0.00827971  2.2730954  -0.6574349 ]"",""65"":""[ 0.7150022   1.7352307  -0.6236089  -1.9525871  -3.963059    1.4363576\n  0.67509156  0.64324266  1.608707   -1.2930781 ]"",""66"":""[ 0.7143889   1.9269654   0.10382275 -2.6361454  -3.9329247   1.9997848\n  0.7216966   0.8257724   0.99433976 -1.022731  ]"",""67"":""[ 1.5732725   1.1837047  -1.3638914  -1.6174028  -3.7674203   0.4349702\n  1.0509303  -0.01923678  2.1748066  -0.9513876 ]"",""68"":""[ 1.5821173   1.3497614  -1.2557614  -1.6691074  -3.865962    0.33674762\n  1.0579121  -0.03445329  2.3357623  -0.6816307 ]"",""69"":""[ 1.4184233   1.9462583  -1.3019868  -1.2629093  -3.7468987   0.8632092\n  0.5994893   0.3154647   2.2988954  -0.75952935]"",""7"":""[ 1.7027993   1.6784607  -0.90816087 -1.1805203  -3.4604092   2.1839786\n  0.1971562   0.3331584   1.1815988  -0.9806932 ]"",""70"":""[ 0.61742926  1.7687223   0.27532983 -2.5127003  -3.9781477   2.0041895\n  0.85490566  0.6456239   1.0288568  -0.86632705]"",""71"":""[ 0.8158382   1.536327   -1.2508546  -1.6013843  -4.0867724   0.94809383\n  0.7147089   0.55745035  2.031691   -0.9419353 ]"",""72"":""[ 1.2352114   1.1542886  -0.7188806  -1.2011218  -3.9473917   1.1880106\n  1.5158395  -0.17349395  2.110108   -0.65405136]"",""73"":""[ 0.79245603  1.4819068  -1.0564364  -1.1975595  -3.9434128   1.1515828\n  0.6722735   0.41025287  1.943884   -1.2094868 ]"",""74"":""[ 0.7159754   1.3484435  -0.50657827 -1.3606237  -3.9473226   1.4974203\n  1.0263697   0.25420895  1.8702401  -1.1902431 ]"",""75"":""[ 1.3519539   0.8915117  -0.6496785  -1.170529   -3.9665146   1.7131765\n  1.359098   -0.11513591  1.8702778  -1.1370784 ]"",""76"":""[ 1.4172226   1.2806293  -1.2784108  -0.95237607 -4.1367087   1.1636271\n  0.76414764  0.08572129  2.190969   -0.6177683 ]"",""77"":""[ 0.7382814   1.2455535   0.37482762 -2.0454402  -4.011012    2.5212293\n  1.0162697   0.22277129  0.7329357  -0.52556056]"",""78"":""[ 1.6042401   1.6660609  -0.7188146  -1.2695646  -3.8236635   1.8313907\n  0.73295707  0.1382029   1.9591342  -1.4221454 ]"",""8"":""[ 0.8603685   1.5610461  -0.83927166 -1.9528692  -3.7946098   1.4973992\n  0.6236349   0.7149017   1.4242125  -1.1951753 ]"",""9"":""[ 1.3683012   1.5560479  -1.098874   -0.91767    -3.301856    1.7645056\n  0.28472215  0.42284775  1.5146242  -1.2551181 ]""},""vocab_index"":{""0"":2,""1"":4,""10"":17,""11"":19,""12"":20,""13"":22,""14"":24,""15"":27,""16"":29,""17"":30,""18"":36,""19"":38,""2"":5,""20"":42,""21"":46,""22"":47,""23"":48,""24"":52,""25"":55,""26"":58,""27"":59,""28"":67,""29"":68,""3"":7,""30"":69,""31"":70,""32"":74,""33"":78,""34"":79,""35"":82,""36"":83,""37"":84,""38"":85,""39"":86,""4"":9,""40"":93,""41"":98,""42"":102,""43"":105,""44"":106,""45"":126,""46"":127,""47"":128,""48"":129,""49"":130,""5"":12,""50"":149,""51"":150,""52"":151,""53"":153,""54"":157,""55"":171,""56"":186,""57"":187,""58"":188,""59"":189,""6"":13,""60"":191,""61"":230,""62"":233,""63"":234,""64"":235,""65"":236,""66"":237,""67"":238,""68"":239,""69"":247,""7"":14,""70"":300,""71"":306,""72"":308,""73"":310,""74"":407,""75"":420,""76"":422,""77"":425,""78"":431,""8"":15,""9"":16},""word"":{""0"":""model"",""1"":""users"",""10"":""dots"",""11"":""states"",""12"":""figure"",""13"":""ieee"",""14"":""features"",""15"":""software"",""16"":""logs"",""17"":""space"",""18"":""documents"",""19"":""experiment"",""2"":""analytic"",""20"":""points"",""21"":""high"",""22"":""dimensional"",""23"":""work"",""24"":""groups"",""25"":""computer"",""26"":""keywords"",""27"":""conference"",""28"":""level"",""29"":""feature"",""3"":""modelspace"",""30"":""accuracy"",""31"":""technology"",""32"":""computing"",""33"":""proceedings"",""34"":""graphics"",""35"":""shows"",""36"":""read"",""37"":""results"",""38"":""colored"",""39"":""endert"",""4"":""visualization"",""40"":""update"",""41"":""represented"",""42"":""words"",""43"":""transactions"",""44"":""science"",""45"":""corresponding"",""46"":""shaded"",""47"":""noise"",""48"":""able"",""49"":""chang"",""5"":""analytics"",""50"":""annotations"",""51"":""word"",""52"":""factors"",""53"":""north"",""54"":""mail"",""55"":""examples"",""56"":""boxes"",""57"":""point"",""58"":""shared"",""59"":""higher"",""6"":""function"",""60"":""supporting"",""61"":""dimensions"",""62"":""\ufb01nal"",""63"":""interns"",""64"":""sigchi"",""65"":""international"",""66"":""vast"",""67"":""symposium"",""68"":""depaul"",""69"":""elspace"",""7"":""lines"",""70"":""common"",""71"":""wine"",""72"":""freire"",""73"":""management"",""74"":""selection"",""75"":""feedback"",""76"":""algorithm"",""77"":""manipulated"",""78"":""accuracies"",""8"":""state"",""9"":""systems""},""word*"":{""0"":""model"",""1"":""users"",""10"":""dots"",""11"":""states"",""12"":""figure*"",""13"":""ieee*"",""14"":""features"",""15"":""software*"",""16"":""logs*"",""17"":""space"",""18"":""documents*"",""19"":""experiment"",""2"":""analytic"",""20"":""points*"",""21"":""high"",""22"":""dimensional"",""23"":""work*"",""24"":""groups*"",""25"":""computer*"",""26"":""keywords*"",""27"":""conference*"",""28"":""level"",""29"":""feature*"",""3"":""modelspace"",""30"":""accuracy"",""31"":""technology*"",""32"":""computing*"",""33"":""proceedings"",""34"":""graphics*"",""35"":""shows"",""36"":""read*"",""37"":""results"",""38"":""colored"",""39"":""endert"",""4"":""visualization"",""40"":""update"",""41"":""represented*"",""42"":""words*"",""43"":""transactions"",""44"":""science"",""45"":""corresponding"",""46"":""shaded"",""47"":""noise"",""48"":""able"",""49"":""chang"",""5"":""analytics"",""50"":""annotations*"",""51"":""word"",""52"":""factors*"",""53"":""north"",""54"":""mail"",""55"":""examples"",""56"":""boxes"",""57"":""point"",""58"":""shared"",""59"":""higher*"",""6"":""function*"",""60"":""supporting*"",""61"":""dimensions"",""62"":""\ufb01nal"",""63"":""interns"",""64"":""sigchi*"",""65"":""international"",""66"":""vast"",""67"":""symposium*"",""68"":""depaul*"",""69"":""elspace"",""7"":""lines*"",""70"":""common*"",""71"":""wine"",""72"":""freire"",""73"":""management"",""74"":""selection"",""75"":""feedback*"",""76"":""algorithm"",""77"":""manipulated*"",""78"":""accuracies"",""8"":""state"",""9"":""systems*""},""x2D"":{""0"":3.7892019749,""1"":4.2409830093,""10"":4.660194397,""11"":3.7360072136,""12"":3.7648997307,""13"":6.5819563866,""14"":4.2429323196,""15"":6.4049010277,""16"":6.0349698067,""17"":5.9801650047,""18"":5.6923766136,""19"":4.5263109207,""2"":5.4458870888,""20"":3.5097770691,""21"":2.562930584,""22"":3.7965295315,""23"":4.1372699738,""24"":3.9254307747,""25"":6.2348465919,""26"":5.609600544,""27"":6.6921744347,""28"":3.0285727978,""29"":3.7425310612,""3"":3.9223196507,""30"":4.3651614189,""31"":5.631922245,""32"":6.3557186127,""33"":6.4428954124,""34"":6.2322673798,""35"":1.149970293,""36"":1.4058936834,""37"":4.8509078026,""38"":1.9426115751,""39"":5.4855656624,""4"":6.0039181709,""40"":3.8098659515,""41"":1.3915294409,""42"":5.3486871719,""43"":5.9281888008,""44"":5.4331688881,""45"":2.3334870338,""46"":1.8320002556,""47"":4.8271093369,""48"":1.2527836561,""49"":4.6937565804,""5"":5.8918671608,""50"":5.8520860672,""51"":5.3633379936,""52"":3.926202774,""53"":2.7248833179,""54"":5.4955730438,""55"":4.5326113701,""56"":5.0013275146,""57"":2.849291563,""58"":1.5528491735,""59"":2.5506587029,""6"":4.294137001,""60"":2.0054347515,""61"":3.7522752285,""62"":4.8931155205,""63"":4.1143369675,""64"":6.4122471809,""65"":3.3994979858,""66"":2.5257406235,""67"":6.7027406693,""68"":6.4355568886,""69"":5.8673210144,""7"":4.4489941597,""70"":2.2025849819,""71"":5.2732839584,""72"":4.8523750305,""73"":5.1078424454,""74"":4.2154698372,""75"":4.6442022324,""76"":6.1876220703,""77"":1.3183225393,""78"":4.1718540192,""8"":3.3555440903,""9"":4.110311985},""y2D"":{""0"":-0.6966999173,""1"":1.2875647545,""10"":1.1028974056,""11"":1.314086318,""12"":-1.1747817993,""13"":-2.1097166538,""14"":0.2556427419,""15"":-3.435958147,""16"":0.717871964,""17"":-4.0999231339,""18"":0.6028572917,""19"":-1.4131375551,""2"":-2.9681425095,""20"":0.9993616939,""21"":-4.3014469147,""22"":0.3636069596,""23"":-1.3045341969,""24"":1.1964688301,""25"":-3.928789854,""26"":0.1964705586,""27"":-2.1977200508,""28"":-3.9660918713,""29"":-1.8854542971,""3"":0.4637036622,""30"":-0.6852126718,""31"":-3.8686728477,""32"":-3.9345881939,""33"":-1.8363910913,""34"":-3.7338931561,""35"":-4.7472262383,""36"":-4.3343143463,""37"":-0.3467769921,""38"":-5.0576367378,""39"":-2.1662540436,""4"":-3.5286743641,""40"":-1.5014723539,""41"":-4.6840782166,""42"":0.3511486053,""43"":0.5484104156,""44"":-3.8120093346,""45"":-4.5185875893,""46"":-4.8126745224,""47"":-1.0979553461,""48"":-4.652364254,""49"":-2.4732017517,""5"":-3.4180321693,""50"":0.3540486693,""51"":0.2586278319,""52"":0.8021765947,""53"":-4.1318354607,""54"":0.9043281078,""55"":0.3569475114,""56"":1.2108358145,""57"":-3.7005455494,""58"":-4.5412511826,""59"":-4.621008873,""6"":-2.2364454269,""60"":-4.8540372849,""61"":0.6732658148,""62"":-2.0709757805,""63"":1.0747131109,""64"":-2.3611760139,""65"":-3.5763297081,""66"":-4.6739611626,""67"":-2.23239851,""68"":-2.0315022469,""69"":-3.8574268818,""7"":1.4252638817,""70"":-4.6601276398,""71"":-3.7046077251,""72"":-1.6204656363,""73"":-3.5587465763,""74"":-1.9909440279,""75"":-0.9605562687,""76"":-3.1896071434,""77"":-5.0059323311,""78"":-0.0805997923,""8"":-3.5941472054,""9"":1.4098316431}}",False,False,False,,,ModelSpace: Visualizing the Trails of Data Models in Visual Analytics Systems,"[-1.33695051e-01 -1.75393626e-01 -1.52306985e-02 -3.01834643e-01
  8.31647873e-01  1.01228841e-01 -2.16602549e-01 -5.89859262e-02
 -4.37886894e-01 -2.55007416e-01  4.31278422e-02 -3.79516423e-01
 -5.36817871e-02  1.71157956e-01 -5.60012683e-02  5.79235017e-01
 -8.33108351e-02  1.42598137e-01 -2.39689257e-02 -6.10358827e-02
  8.18320215e-02  1.49345353e-01 -1.42324820e-01  4.48896050e-01
  3.78738105e-01  1.45488113e-01 -3.15403432e-01  1.21533558e-01
 -5.08104563e-01  2.06756875e-01 -5.43010943e-02  6.26473188e-01
 -1.15049295e-01 -2.59137481e-01 -5.45722470e-02  4.20631394e-02
 -3.79315346e-01 -1.98277682e-01  6.08481988e-02  7.42370009e-01
 -5.39463460e-01 -3.79540443e-01 -1.06804952e-01 -9.86679941e-02
 -2.89948992e-02 -1.61425188e-01 -4.26057726e-01 -4.76177663e-01
  1.78327441e-01 -5.03842235e-01 -1.18195617e+00  1.07090272e-01
 -5.26495464e-02 -4.28450942e-01 -9.89255905e-02  8.10617805e-01
  3.87540221e-01 -7.71344304e-01  2.59699047e-01  9.07098129e-02
 -1.91665500e-01 -8.46813694e-02 -6.13834150e-02  1.02183819e-01
  2.34734863e-01 -1.78989872e-01  1.06276751e-01  1.13865033e-01
 -5.42678654e-01  2.09195703e-01 -7.72193894e-02  4.99798432e-02
 -2.98204184e-01  3.09010208e-01 -6.38488293e-01  5.66850901e-02
  8.48521814e-02  5.87102830e-01 -2.90868044e-01  5.29540442e-02
 -4.64760512e-01  4.28672522e-01  6.72407523e-02  5.46673723e-02
  4.45623159e-01  6.39950752e-01 -2.88363993e-01  5.68902045e-02
 -3.40072811e-01 -7.10445344e-02 -5.69574535e-01 -3.46793830e-02
 -1.59281835e-01  1.87767655e-01  5.05909145e-01 -3.59301955e-01
 -4.28485006e-01 -3.79691310e-02 -2.17029139e-01 -9.45272222e-02
  2.91984916e-01 -8.04406226e-01  2.63417810e-01  2.05734327e-01
 -2.76691001e-02 -2.40676820e-01 -3.00082982e-01 -9.06150043e-02
 -4.91128743e-01 -2.08356783e-01 -8.31163395e-03 -4.89764772e-02
 -6.37898222e-02 -7.41202414e-01 -1.67304903e-01  1.69772804e-01
 -2.81322151e-02  2.29617074e-01  1.62748322e-01  1.66678682e-01
 -2.20777586e-01  3.17059070e-01 -1.18974112e-02  6.36992812e-01
  9.62539390e-03  2.66794652e-01  3.29200597e-03  1.01167172e-01
  6.25029147e-01  4.21075135e-01  6.14021957e-01  4.38157469e-01
  2.05882072e-01 -1.19494334e-01 -3.84012088e-02  3.75354588e-01
 -2.03302085e-01 -3.43165882e-02 -1.24088198e-01  4.71038483e-02
 -2.69973397e-01 -5.88727057e-01  3.62458527e-01  1.61587358e-01
  3.50684673e-01 -1.16091728e-01  5.34456819e-02  2.54863739e-01
 -1.63998693e-01  3.20866287e-01 -9.26492661e-02  4.83043104e-01
 -7.54758239e-01  1.83382720e-01 -1.07023366e-01  2.75203258e-01
 -5.48528016e-01  3.07061315e-01  2.68983562e-02  1.79230943e-01
 -2.83367988e-02  2.35550031e-02 -4.71553467e-02  4.30505574e-01
  1.47932336e-01 -4.07302260e-01 -1.28196934e-02  1.51243255e-01
 -6.20188750e-02 -1.19786844e-01 -9.47845951e-02 -5.24340451e-01
  2.13488601e-02  3.41236770e-01  2.99853802e-01  3.97051245e-01
  2.04722583e-01  3.59163098e-02  4.38409984e-01  5.97678602e-01
 -4.61978078e-01  9.27645788e-02  1.12881728e-01 -7.50341713e-01
  1.59557685e-01  2.14699075e-01  5.74489355e-01 -6.78108811e-01
  5.79422832e-01  3.61342728e-02 -4.65275735e-01 -3.50732803e-01
 -5.39888859e-01 -4.35284972e-01  1.87893465e-01 -1.87326774e-01
 -2.70483524e-01 -5.79725988e-02 -1.38726756e-01 -4.92005587e-01
  6.48842752e-02 -1.28661275e-01  1.61087871e-01 -4.01710778e-01
 -1.27509534e-01 -1.01108119e-01 -4.63948220e-01 -6.91310167e-01
 -7.59393334e-01  5.80629744e-02 -4.78000224e-01  2.04363823e-01
 -1.75508894e-02  2.85452306e-01  1.46519274e-01  3.43430936e-01
 -2.01133080e-02 -1.04948826e-01  4.66840602e-02  4.00141515e-02
  5.39338946e-01 -3.36011738e-01 -4.04495448e-02  2.09508806e-01
 -1.28991276e-01  1.48002028e+00  2.90273100e-01 -4.95132715e-01
  8.90061438e-01 -1.00968510e-01  3.40609729e-01  4.61318679e-02
  3.49390477e-01 -6.22663319e-01  3.33393924e-02  1.88145004e-02
 -2.27205232e-01 -4.05746967e-01  3.30147356e-01 -2.88270935e-02
  2.98684575e-02  6.78590387e-02  1.86874822e-01  1.24577925e-01
 -3.91552933e-02 -2.56694019e-01  3.22116584e-01 -6.04256243e-02
 -1.83283687e-01 -1.53639942e-01 -1.99204370e-01  2.82142460e-01
 -6.61217332e-01 -4.31329727e-01 -2.33570024e-01  2.59538561e-01
 -7.37557337e-02 -2.05271188e-02 -2.81113923e-01  5.04802108e-01
  5.35431325e-01  1.10983714e-01 -6.48913682e-02 -6.33602515e-02
  4.38719511e-01 -5.32823861e-01 -8.74062926e-02 -1.99868500e-01
  8.10167134e-01  3.72737318e-01 -1.80767357e-01 -5.91335535e-01
  3.18544686e-01  5.46702683e-01 -4.37463611e-01 -4.78691638e-01
  5.11751138e-02 -3.65262866e-01 -3.48512679e-01  5.78759871e-02
  5.96401505e-02  1.56588987e-01 -2.99209148e-01  2.99550910e-02
 -2.48444900e-01 -1.58912286e-01  4.59662259e-01  2.69287765e-01
  2.15036511e-01 -8.65264982e-02 -3.54962766e-01  2.42672533e-01
 -3.77319992e-01 -2.52065688e-01  5.96796989e-01  5.14100075e-01
  7.07176551e-02 -2.98861116e-01 -2.08489805e-01 -1.80163845e-01
 -3.41491848e-01 -2.37145480e-02  1.48747906e-01  7.02714249e-02
 -1.09379664e-01  2.79379219e-01 -1.97200820e-01 -2.66584277e-01
 -7.97038507e+00 -1.35478258e-01  9.47466865e-02 -9.87104326e-02
 -1.74469333e-02 -6.99848635e-03  2.10638851e-01 -3.90123092e-02
 -2.36709192e-01  9.43121240e-02 -1.23423241e-01 -1.93900585e-01
 -6.02496028e-01  3.21623296e-01 -1.05547197e-01 -7.31277931e-03
  5.18687248e-01 -4.72032130e-02 -2.97351360e-01  5.67541361e-01
 -2.86810756e-01 -3.59799683e-01 -2.03363016e-01  1.28852829e-01
 -1.88627288e-01 -2.17831269e-01 -4.91414338e-01  2.12777555e-01
 -4.28159744e-01 -5.29622436e-01 -2.26376414e-01 -7.14716256e-01
 -3.33784014e-01  1.03795850e+00 -1.73625350e-01  1.17889240e-01
 -5.04277408e-01 -4.42074426e-02 -1.93201810e-01 -1.40019916e-02
  8.74850377e-02 -6.19390979e-02 -1.05926029e-01 -1.27816737e-01
  1.00430012e+00 -4.14565206e-01  4.51744258e-01  2.33495429e-01
  8.45650882e-02 -2.07930341e-01 -9.16494578e-02 -2.11371072e-02
  2.72882074e-01 -5.88440180e-01 -7.77884200e-02 -4.42138821e-01
  8.17838371e-01  4.70051080e-01 -1.37538567e-01 -2.51563191e-01
  8.07433546e-01 -4.01113927e-01 -3.03138942e-01  7.68896192e-02
 -1.86991543e-02 -1.20569445e-01 -9.93108392e-01 -6.88451707e-01
 -4.07480150e-01 -1.48665100e-01 -2.65457988e-01  6.28067613e-01
 -1.66117921e-01 -1.34908235e+00 -4.28446501e-01 -4.79583770e-01
  3.95355463e-01 -5.93566783e-02 -4.04211134e-01 -3.12212855e-01
 -5.36086082e-01 -5.18128216e-01  8.02381039e-02 -2.38832220e-01
 -3.17397475e-01 -8.26208889e-02 -2.69878477e-01 -2.17620239e-01
 -5.85372806e-01 -3.63140665e-02 -7.88641721e-02  5.14842391e-01
  4.24634784e-01  3.87018889e-01  3.40711683e-01  5.81366569e-02
  5.95389307e-01  1.83849409e-02 -1.13644423e-02  9.53802615e-02
  3.20960999e-01 -5.15292227e-01  2.01090530e-01 -1.36432983e-02
 -5.36427855e-01  7.72776157e-02 -3.44242394e-01 -1.37498707e-01
  4.35283482e-01  2.13032261e-01 -2.59103596e-01  2.04574868e-01
 -1.55647114e-01 -6.52773306e-02  8.50569829e-02  2.71067202e-01
 -2.18565121e-01  4.25968289e-01 -1.06813908e-01 -4.60693359e-01
 -5.65698922e-01  3.34936112e-01 -8.23620483e-02 -1.72097668e-01
  4.27408218e-01 -1.20590918e-01  1.96768552e-01  3.62199932e-01
 -1.28307551e-01 -6.11181021e-01  1.29569143e-01 -1.73160985e-01
  1.96869433e-01 -7.55777061e-02  4.07936543e-01 -4.44349885e-01
  2.47528285e-01 -8.69728923e-02 -5.09371817e-01  1.91416204e-01
  4.09640580e-01  6.38878524e-01  4.98978376e-01 -1.50682256e-01
  7.15083927e-02  4.61090319e-02 -4.64684814e-02  1.57761961e-01
 -1.79436758e-01  3.19022648e-02 -5.05469143e-01 -7.46908665e-01
 -1.75099120e-01  5.50729269e-03  4.13060635e-01  2.44352534e-01
  2.31423050e-01 -5.09415448e-01  1.21629544e-01 -4.84893084e-01
  2.24550664e-01  4.53404188e-01  1.51599273e-01 -9.58181694e-02
 -1.80550322e-01  3.08646381e-01 -3.04832965e-01  2.70965964e-01
  3.82714835e-03 -5.56667447e-01 -3.45039964e-01 -2.70253003e-01
  7.52016604e-01 -3.33870441e-01 -2.31838435e-01  5.14337346e-02
  4.81576234e-01  1.37864411e-01 -4.54268336e-01  5.62585533e-01
  2.21775055e-01  2.85250306e-01 -2.96849817e-01  2.03217104e-01
  4.13903654e-01  6.07860327e-01  2.70068944e-01 -6.62713358e-03
  1.00096263e-01  4.16138560e-01 -5.17094016e-01  1.72678828e-01
  5.87324463e-02 -3.30976367e-01 -2.88756818e-01 -5.90221405e-01
  3.40409935e-01 -5.90786457e-01  1.01755410e-01 -1.27441794e-01
 -2.66875505e-01 -7.40923062e-02 -3.46656144e-01  4.47731048e-01
 -4.15791810e-01 -1.88680246e-01  4.35058028e-02  5.02542675e-01
 -3.65343541e-01 -4.39657494e-02 -6.73244238e-01 -1.65138811e-01
 -2.87411481e-01 -5.13655305e-01  1.90245882e-01  1.06146120e-01
 -2.12662444e-01 -4.99768347e-01 -7.82316506e-01  3.02055806e-01
 -1.50408238e-01  1.23970203e-01  4.35510278e-01  2.51122355e-01
  3.64461243e-01  2.15854779e-01 -1.16265200e-01  1.00801557e-01
 -2.31135249e-01 -1.04274694e-02 -2.83383578e-01 -1.78582716e+00
 -1.97120950e-01  2.71785408e-01  2.58450389e-01 -2.43266180e-01
 -6.03045046e-01  3.15423235e-02 -2.58328170e-01 -2.34615982e-01
 -5.73661327e-02 -4.34775114e-01 -4.23814595e-01 -2.16541767e-01
 -3.73994596e-02 -9.64229032e-02 -2.27704942e-01  9.40036327e-02
 -4.07120705e-01 -8.02192092e-02 -5.45441918e-02 -1.11158371e-01
 -6.33668453e-02 -3.49763185e-01  3.56730700e-01  6.85762390e-02
  1.56261235e-01 -6.63585186e-01 -6.06359206e-02 -1.50553072e-02
 -6.23529613e-01 -4.92670923e-01 -1.87990308e-01  1.58467948e-01
 -1.40441582e-01 -4.47157472e-02 -7.86543339e-02 -9.70023721e-02
  3.25894654e-01 -2.57272959e-01 -3.57116848e-01 -2.89312840e-01
 -3.64068270e-01  3.48627508e-01 -2.23745391e-01 -9.55142900e-02
 -2.18517080e-01 -2.14919239e-01  7.53855705e-02 -4.24209833e-01
 -2.59323418e-01 -2.30193868e-01  3.36057663e-01  2.85323620e-01
  2.64965892e-01 -1.09509975e-01  8.72852877e-02  8.12545419e-02
  2.75190115e-01 -1.97927341e-01  3.70010547e-02  1.27273947e-01
 -1.56703144e-01  1.93238169e-01 -3.47770959e-01  3.81851494e-01
  1.00719738e+00  2.21575752e-01  3.95015150e-01  2.67985582e-01
  1.51073098e-01  4.39637214e-01  2.97405303e-01  3.21557313e-01
  4.07511890e-01 -2.80620426e-01  8.19513723e-02 -4.09024805e-01
  1.79334939e-01 -6.47497475e-01 -2.89916039e-01 -2.75546104e-01
  6.04259551e-01  3.99468869e-01 -3.44942629e-01 -4.01796922e-02
 -1.54288232e-01  5.39286509e-02  6.70640707e-01 -4.99014184e-02
 -7.00676858e-01  6.71757340e-01  2.55686343e-01  4.16113995e-02
  8.62746537e-02  6.47108376e-01 -1.67576924e-01 -3.69763136e-01
 -1.66785032e-01  2.56432235e-01 -1.21956617e-01  3.92952949e-01
  1.10776924e-01  5.55661470e-02  2.80233115e-01  5.32558598e-02
  9.92499813e-02 -2.98727900e-01  2.04933986e-01  2.89269388e-01
  3.65588009e-01  2.67008871e-01  1.12656234e-02  5.41937411e-01
 -2.29291856e-01  5.91031834e-02  3.20716128e-02  4.76979673e-01
 -3.48582238e-01  1.66117072e-01 -4.48695086e-02  2.17834294e-01
  3.20440680e-01  2.73221642e-01  1.17535919e-01 -2.45524228e-01
  3.18614572e-01  1.20168664e-01 -1.20063826e-01  5.44096112e-01
  1.92558691e-01  2.42915213e-01  1.31852031e-01 -1.03144681e+00
 -2.45334744e-01  3.12300008e-02  7.46262491e-01  3.27017695e-01
  2.18631282e-01 -3.47869784e-01  3.49571332e-02  6.46768630e-01
 -4.37864549e-02 -3.02068830e-01  4.89631474e-01  4.66027528e-01
 -3.84589493e-01 -2.09467977e-01 -4.82747890e-02  3.00838381e-01
 -1.02093905e-01 -9.99622419e-02 -1.58649385e-01  1.21738851e-01
 -3.92964214e-01 -4.79302645e-01 -2.58362353e-01  2.89961427e-01
  3.91103923e-01 -2.65881926e-01 -1.81677610e-01  4.29666698e-01
  3.55425417e-01  1.35120479e-02 -2.66854644e-01  5.09565324e-02
 -9.25946534e-02  1.59152925e-01  6.51118159e-01 -1.09536268e-01
 -4.39284556e-02 -2.91888118e-01 -4.59737420e-01  4.63778861e-02
 -4.75695997e-01 -4.78037819e-02  7.56726367e-03  1.58896431e-01
 -5.20874262e-01 -4.76797551e-01  1.06224209e-01  2.17829421e-01
 -8.80311430e-02  2.89702982e-01  8.81064013e-02  4.93882447e-01
 -5.71848713e-02  4.31995958e-01 -3.04197669e-01  5.20064346e-02
 -1.94487244e-01 -3.93407851e-01  3.84948432e-01 -1.76517889e-01
  1.29664645e-01  2.60214567e-01 -2.38304213e-01 -1.93700746e-01
 -2.65132517e-01  3.74084152e-02  4.53694224e-01  2.45908529e-01
 -2.69849777e-01  1.52383178e-01 -2.07676128e-01  2.79015210e-02
 -3.96570325e-01  5.26834667e-01  1.44389048e-01 -6.09380640e-02
 -4.54008281e-01  1.65693834e-01 -1.15671575e-01 -2.11849079e-01
  9.96719003e-02  4.26777691e-01  1.51197955e-01 -1.99523836e-01
 -1.88926652e-01 -1.42534912e-01 -2.78893828e-01 -1.60804426e-03
 -1.85169175e-01 -7.11040854e-01 -1.38063416e-01  2.23957840e-02
 -2.36906990e-01 -3.20820004e-01  6.09810129e-02  2.49297917e-01]",4DZQWUEH,False,False,"[7.10745906829834, 0.038787584751844406]"
8NYK2X9E,5QQKA7WG,"See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/328214585

Speculative Execution for Guided Visual Analytics

READS
204

Jürgen Bernard
Technische Universität Darmstadt

59 PUBLICATIONS   498 CITATIONS   

SEE PROFILE

Conference Paper · October 2018

CITATIONS
0

5 authors, including:

Fabian Sperrle
University of Konstanz

6 PUBLICATIONS   18 CITATIONS   

SEE PROFILE

Michael Sedlmair
University of Vienna

61 PUBLICATIONS   1,181 CITATIONS   

SEE PROFILE

Some of the authors of this publication are also working on these related projects:

VALID – Visual Analytics im Datenjournalismus View project

Visual-InterActive Labeling View project

All content following this page was uploaded by Fabian Sperrle on 11 October 2018.

The user has requested enhancement of the downloaded file.

Speculative Execution for Guided Visual Analytics
Michael Sedlmair‡
Fabian Sperrle*
University of Konstanz
University of Stuttgart

Technische Universit¨at Darmstadt

J¨urgen Bernard†

Daniel Keim§

University of Konstanz

Mennatallah El-Assady¶

University of Konstanz

University of Ontario Institute of Technology

Figure 1: Speculative Execution for Visual Analytics. A model optimization process deﬁnes a path through the model state space
(shown with only three dimensions here for simplicity). Speculative Execution proactively and automatically computes alternative
model states in sandboxes and presents them using delta-visualizations, comparing them to the current model. Speculative
Execution can be triggered either through user interaction or model quality metrics.

ABSTRACT
We propose the concept of Speculative Execution for Visual Ana-
lytics and discuss its effectiveness for model exploration and opti-
mization. Speculative Execution enables the automatic generation
of alternative, competing model conﬁgurations that do not alter the
current model state unless explicitly conﬁrmed by the user. These
alternatives are computed based on either user interactions or model
quality measures and can be explored using delta-visualizations. By
automatically proposing modeling alternatives, systems employing
Speculative Execution can shorten the gap between users and mod-
els, reduce the conﬁrmation bias and speed up optimization pro-
cesses. In this paper, we have assembled ﬁve application scenarios
showcasing the potential of Speculative Execution, as well as a po-
tential for further research.
Index Terms: Human-centered computing—Visual Analytics—
Speculative Execution—SpecEx;

*e-mail: fabian.sperrle@uni-konstanz.de
†juergen.bernard@gris.tu-darmstadt.de
‡michael.sedlmair@visus.uni-stuttgart.de
§e-mail: daniel.keim@uni-konstanz.de
¶e-mail: mennatallah.el-assady@uni-konstanz.de

1 INTRODUCTION
In many disciplines, domain experts have to create and validate mul-
tiple possible solutions to a current situation. With the identiﬁcation
of a best possible outcome, a solution can be pursued. In politics,
simulations and anticipations have been an integral part of success-
ful campaigns for a long time: politicians and their advisers prepare
for different, likely outcomes of an event or a meeting. This allows
them to be prepared for different situations that might come up and
ensures that they can react in a fast, yet precise way. Similarly, politi-
cians and involved policy analysts create, analyze, and compare al-
ternative solutions before a policy is to be implemented [25]. Al-
though most of the potential solutions will not be needed in the end,
their preparation is imperative to guarantee a systematic and timely
decision process. In the world of computers, CPUs, for instance,
pre-compute conditional code blocks before the outcome of the con-
dition is known in order to avoid waiting and doing nothing. Simi-
larly, multiple pages are fetched from disk or from memory, even
when only one has been requested. All of these examples employ
Speculative Execution, the principle of preparing or precomputing
the result of a task at a time when it is not needed, but its calculation
is easier or cheaper thanks to synergy effects or idling resources.

We propose to apply Speculative Execution as a concept for Vi-
sual Analytics, as well. There, it can simplify user interactions and
propose parameter changes. It is inspired by the human-in-the-loop
concept that has become increasingly popular in Visual Analytics
over the last years. It integrates human decision-making into the anal-
ysis process to obtain results that are based on semantic understand-

ing and ﬁt the user’s expected mental model. More recently, Endert
et al. proposed a pattern named “the human is the loop” [14]. They
call for new directions of Visual Analytics that focus on recognizing
the user’s work process and “seamlessly ﬁtting analytics into that
existing interactive process” [14]. Speculative execution picks up
this idea and proposes that systems learn the users’ goals from their
interactions and provide optimizations that help to reach this goal
faster. Additionally, Endert et al. also argue that “implicit steering is
perhaps the ultimate form of in-context input”. As Speculative Exe-
cution is aimed at understanding the users’ intentions and executing
them in the model, it can remove the need for unnecessary, explicit in-
teractions, which are instead performed automatically by the system.
In addition to reducing the gap between users and machine learn-
ing models, Speculative Execution can also be helpful for model
optimization and model understanding. As a consequence of the in-
creasing complexity of (machine learning) models, interactions with
model visualizations are important to foster model-understanding
and trust-building [22]. However, these interactions are not always
straight-forward. For example, Lee et al. have found that even “seem-
ingly small changes can have unexpectedly large consequences” [21]
on the output of the popular topic model LDA [4]. This often leads
to users being cautious when interacting with models in fear of
“breaking something” [9]. To avoid potentially worsening the cur-
rent model, Speculative Execution provides isolated computation
environments. In those, changes can be applied speculatively. In
combination with a delta-visualization between two model states,
this allows users to preview the model changes introduced by their
interaction in a focused manner.

We deem Speculative Execution (SpecEx) particularly beneﬁcial
for the typical Visual Analytics (VA) scenarios. First, it provides the
means for effective model optimization and reﬁnement towards the
users’ tasks and data. Second, it can help prevent conﬁrmation bias
by showing potential modeling alternatives. Finally, it is well-suited
for mixed-initiative user-guidance. However, SpecEx has not yet
been formally introduced to VA. We demonstrate the applicability
of SpecEx for guided Visual Analytics in ﬁve usage scenarios in
Sect. 4. These scenarios also highlight that SpecEx integrates well
with existing VA concepts that will be introduced in Sect. 2.

The contributions of this paper are (1) the introduction of the con-
cept of Speculative Execution to Visual Analytics; (2) an illustration
of the value of Speculative Execution in ﬁve usage scenarios; (3) de-
sign considerations and an implementation model for Speculative
Execution; (4) the identiﬁcation of open research questions for efﬁ-
cient application of Speculative Execution.

2 BACKGROUND
SpecEx as a concept is broadly applicable in many VA scenarios.
We discuss related VA techniques here, and present derived usage
scenarios in Sect. 4.

Van den Elzen and van Wijk have introduced a visual exploration
technique called “Small Multiples, Large Singles” [33] that is simi-
lar to Speculative Execution. Starting from a “large single” visualiza-
tion a small multiples visualization shows alternative models, model
parameters, visual mappings, or visualization techniques to the user.
Following an alternating sequence of large singles and small mul-
tiples, users can either use the tool to explore the data space or to
adjust both the model and visualization for their use case. While the
approach focuses on the navigation-support provided with the small
multiples (e.g., by trial-and-error), the SpecEx concept also incorpo-
rates the suggestion of next step that may be meaningful to succeed
in some task.

SpecEx integrates well with the concept of provenance tracking.
Systems like AVOCADO [32], VisTrails [6] or SenseMap [23] fo-
cus on visualizing the provenance of results during or after an analy-
sis session. Some systems also give users the possibility to revert
to a previously seen model conﬁguration. SpecEx enables a more

straightforward comparison of two model states, as they can both be
instantiated in isolated environments at the same time. Combined
with a delta-visualization this provides a powerful tool for under-
standing how speciﬁc interactions have inﬂuenced the model build-
ing process.

If Speculative Execution is based on quality metrics instead of
user interactions, it becomes an alternative to Visual Parameter
Space Analysis, e.g., conducted by Sedlmair et al. [28]. In this case,
sandboxes would be created with different parameter conﬁgurations
following the speculation dimensions presented in Sect. 5.2. How-
ever, as SpecEx is an interactive, mixed-initiative approach, the ex-
ploration of the search space and computation of alternative models
can be more restricted to those in which users are interested. Also,
this interactivity allows Speculative Execution to modify the param-
eter sampling methods, focusing on parameter ranges that seem to
be relevant to the users in a given analysis session.

The concept of SpecEx pairs well with progressive computation.
As SpecEx observes user interactions with the system (see Sect. 5.1),
systems can observe which sandboxes users are most interested in,
and progressively reﬁne their models. This allows initial sandbox
models to be computed with a lower degree of detail, enabling
the computation of more sandboxes with the same resources. The
necessary details can then be computed once they are necessary.

3 SPECULATIVE EXECUTION AS A VA CONCEPT
We ﬁrst deﬁne Speculative Execution and Computational Sandboxes,
as well as the Model Search Space. We then combine the introduced
concepts into an implementation model that can be applied to existing
Visual Analytics systems.

3.1 Deﬁnitions
All three of the important terms have previously been used in differ-
ent areas of computer science. We present related deﬁnitions that
are tailored towards the use of the terms in Visual Analytics.

Speculative Execution Typically, Speculative Execution de-
scribes a set of CPU optimization techniques like branch predic-
tion [39] or data prefetching [16] that can improve their performance.
In the context of Visual Analytics, we describe SpecEx as the proac-
tive computation of alternative, competing model states that are iso-
lated from the current model state and do not inﬂuence it. On the
one hand, such a proactive computation can be triggered by user in-
teraction. In this case, the computation completes the interaction
or performs similar operations. More detailed distinctions will be
made in Sect. 5.1. On the other hand, the computations can have
the goal of model optimization. They are then typically triggered by
model quality metrics and can, for example, be used to explore dif-
ferent parameter settings. Combining these two aspects, we deﬁne
SpecEx as follows:

Speculative Execution describes the proactive, near real-
time computation of competing model alternatives that do
not inﬂuence the current model state, explores the model
state search space, and is triggered by either interaction
or quality measures.

Comparing the differences between two competing model states,
users can decide whether any SpecEx was useful or not. If yes,
they can accept the proposed sandbox, or else reject it. Using these
two simple operations, users can steer how the model state space is
searched. Over time, SpecEx can learn from this user interaction and
rank proposed sandboxes higher if they conform to similar schemas
as sandboxes that have previously been accepted by the user. This
improves the quality of suggestions and facilitates the intended tasks
of model optimization and exploration further. Imagining model op-
timization as a “walk” through the model state space, SpecEx allows
users to “look to the left and right of the path”. This differentiates

model and, if available, a set of quality metrics computed by the
Model Quality Monitor. The Speculative Execution Component can
create model sandboxes and instantiate them with copies of the cur-
rent model. These sandboxes can either be visualized individually
or in a delta-view comparing them to a different model state; typi-
cally the “original” model from which the sandbox was started. The
Speculative Execution Component also constantly monitors the VA
workspace and tracks the users interactions, searching for patterns
and trying to determine the users intentions. The possible outcomes
of this process will be described in Sect. 5.1. Thus, any sandbox can
either be triggered by observed user interactions or, more simply,
by the Model Quality Monitor. This component combines multiple
metrics indicating the quality of the model, and employs different
strategies for combining these metric values into a “trigger-decision”.
This generic implementation model can be taken into account when
designing new Visual Analytics systems, or be retroﬁtted to existing
VA systems thanks to its modularity. It follows the architecture for
“human centered machine learning” presented by Sacha et al. [26].
Speculative interaction ties into the Validation & Interaction stage
of their proposed framework.

SpecEx can reuse existing techniques to determine the users inten-
tions [5,8], and employ them in sandboxes. The ranking and proposi-
tion of sandboxes to the user can be incrementally improved through-
out the analysis session. For example, a higher weight can be given
to those sandboxes that have been created according to a schema
that has often been accepted by the user in the past. However, such
adaptations to the weighting scheme have to be carefully considered
to avoid creating and conﬁrming biases in the user’s mental model.

4 USAGE SCENARIOS
To illustrate the idea of Speculative Execution in Visual Analytics,
we now discuss ﬁve usage scenarios in which SpecEx was either
already applied successfully, or that would build a valuable basis for
an extension towards SpecEx. The ﬁrst scenario reports the results
of the initial implementation of SpecEx for topic modeling. The
second and third scenario highlight the use of SpecEx for implicit
steering and user guidance, respectively. Scenario four exempliﬁes
the value of SpecEx for cooperative VA, and scenario ﬁve shows
that SpecEx can also be applied to visualization and is not limited to
VA. Except for scenario one, these usage scenarios are hypothetical
and have not been implemented yet. The small ﬁgures under each
usage scenario repeat the implementation architecture model from
Fig. 2. The individual components that that are “active” in each of
the scenarios have been coloured in blue, highlighting the versatility
of SpecEx. Different amounts of sandboxes have been coloured
throughout the examples and represent whether a small, medium or
large number of sandboxes are expected to be computed.

4.1 Model Optimization
Topic modeling is a popular technique to segment a text corpus
into thematically related clusters. Consequently, reﬁning the re-
sults of topic models and adapting them to a particular set of
users, data, and tasks, is an active area of research [10].
In
our recent work, we examined the optimization of the Incre-
mental Hierarchical Topic Model (IHTM) using SpecEx [11].
This model represents topics as a tree—
with leaf nodes being documents, and
inner nodes representing hierarchi-
cally ordered topics. This data struc-
ture can be explicitly manipulated
through various optimization strate-
gies that, for example, split or merge
topics, remove outliers, or compact the topic tree. In combination
with typical topic model quality metrics like the number and size
of topics, their coherence or pointwise mutual information, a sys-
tem can speculatively start the available optimization strategies in

Figure 2: Implementation architecture for Speculative Execution
in Visual Analytics. The Speculative Execution and Model Quality
Monitor components can be retroﬁtted to existing VA systems, to-
gether with one or multiple Model Delta Visualizations.

SpecEx from “normal” human-in-the-loop Visual Analytics that in-
corporates the user without necessarily focusing on exploration or
proposing modeling alternatives.

Sandboxes—isolated containers holding models— and the model
state search space—the theoretical, high-dimensional space of pos-
sible model conﬁgurations—will be introduced and deﬁned in the
following paragraphs.

Sandboxes In general, sandboxes are environments with lim-
ited connections to their respective outside world, enabling a sepa-
rated and encapsulated computation. In computer science, the term
sandbox is often used to describe shielded environments or local
working copies that are used to execute some task. Application
areas include virtual machines, software installation facilities, or
security-related environments. Sandboxes in visual analytics have
often been used in collaborative or multi-device environments to
show all users different and tailored views of the data [19]. “Sand-
box” is also the name of a visual sensemaking system introduced
by Wright et al. [36]. Additionally, “sandboxes” is a term often
used in relation with computer- and system-security: browsers use
JavaScript sandboxes [7, 18] and systems move suspect executables
to sandboxes [37].

Building upon these characterizations and examples, we adopt
the notion of sandboxes and describe them as isolated computation
environments that can be initialized with any model state. The result
of any sandbox computation should always be a valid model state,
such that any model can be replaced with a sandbox derived from
it easily. These sandboxes can help to explore different, alternative
hypotheses, which analysts often do to avoid conﬁrmation bias [17].
Search Space The search space for Speculative Execution
is deﬁned by all possible model states, given by the input data
and all parameters. SpecEx deﬁnes any number of these inputs
as speculation dimensions that can be modiﬁed before starting a
proactive computation. As a result, the Speculative Execution Space
is signiﬁcantly smaller than the entire model state space, as it does
typically not make sense to change all variables before launching a
computation. An elaboration on the different potential sizes of the
search space can be found in Sect. 5.3.

3.2 Implementation Model for VA with SpecEx
Having deﬁned the concepts of Speculative Execution, we now de-
scribe how it can be integrated into an existing VA workspace. The
result of such an integration is shown in Fig. 2. The central com-
ponent is the VA workspace itself with visualizations of both the

els are visualized in the labeling interfaces which closes the human-
centered feedback loop [3].

Observing these interactions such a system could understand
and learn the pattern in the users’ interaction. It could then ﬁnd
potentially misclassiﬁed data instances by using quality metrics
or assessing the spatial relationships of data instances in the high-
dimensional data space or the visual space, or both. In a series
of parallel sandboxes, the system could “auto-complete” different
interaction patterns the users have started, and present a list of
changes together with the re-trained alternative models. The user
can then inspect the list of instances which switched their prediction
of the machine learning model and accept or reject the sandbox.

If the system can detect and understand these semantic interac-
tions [14] as implicit steering commands, it can learn about the
user’s intuition (intents [38]). It can then apply this intuition to the
remaining data, removing the need for users to explicitly complete
their interaction pattern, reassigning even more instances.

4.3 User Guidance
Recent work in Visual Analytics has often focussed on measuring
and avoiding conﬁrmation bias [1, 34].
Speculative Execution can help to pre-
vent conﬁrmation bias by providing al-
ternative sandboxes, as well. A differ-
ent approach has been taken by Wall et
al. with their system PODIUM [35]. It
aims at making the users mental model
visible by letting them rank data according to their intuition and
preference. In their example with college football teams, users drag
and drop some teams that they have an opinion about to a new posi-
tion in the list. Additionally, users can indicate whether the model
should put more or less weight on individual features. The system
then learns feature weights from that ranking and reorders the list
according to the learned model. As a result, the relative differences
between teams ranked by the user can change. Here, Speculative
Execution could explore alternative feature weightings that lead to
a ranking that is closer to what the user originally expressed. The
system could then guide users and highlight that changing certain
feature weights would lead to the model more closely representing
their originally expressed order. Users can then verify the changes
and accept them, if they agree. Alternatively, this could lead to users
realizing that the proposed changes do not ﬁt their mental model.
As a result, they might start questioning the said model, exploring
the data further, and overcoming their biases. This scenario shows
that SpecEx can not only be used to speed up model optimization or
auto-complete user interactions. Instead, it can be used to explain
model changes by highlighting features with a high impact on the
current modeling situation.

(NISQ),

4.4 Cooperative Visual Analytics
Linguists are interested in classifying questions on whether they are
information-seeking (ISQ) or non-
information-seeking
i.e.,
rhetorical [31]. Their data consists of
transcripts of conversations or written
text. The task of an expert analyst is
to train a classiﬁer using a VA system.
Such a system might, for example, pro-
vide the context before and after the question, as well as information
on the respective speakers. This task is interesting for cooperative
analysis because discussions with linguists have shown that there is
frequent disagreement on whether a question is an ISQ or not, even
between experts. In current classiﬁer training systems, this would
lead to prolonged decisions on how to classify training data. With
Speculative Execution, disagreeing experts can create two sandboxes,
and each classify some training data according to their understand-

Figure 3: Example of two-dimensional SpecEx over time and differ-
ent optimization strategies. Three optimization strategies for an in-
cremental topic model are triggered in sandboxes and forecast over
the next ten document inserts. The resulting models are sorted ac-
cording to their quality, and presented to users as a diff with the cur-
rent model. Applying their domain knowledge, users select the best
model to continue the process with.

individual sandboxes whenever any (combination) of the metrics de-
clines. Once the sandbox computations are complete, the results can
be ranked according to their measured quality and be presented to
the user. We have implemented and successfully tested such a sys-
tem in our previous work [11]. The topic trees of two topic models
are merged into a single tree, and added, moved and removed topics
and documents are highlighted to help users see differences between
the two models and select a sandbox to continue the computation
with. This workﬂow is outlined in Fig. 3.

As the user observes the model building process of the IHTM
on the “20news” dataset, a document from the “atheism” group is
added to the “christian” topic, making it too broad and leading to
Speculative Execution. The user inspects the proposed optimization
leading to the highest measured quality improvement: merging the
two topics “mideast” and “baseball”. While this merge optimizes the
quality metrics, the user quickly rejects it, employing their semantic
understanding. Instead, they select a different sandbox in which the
erroneously combined “car” and “gun” topics have been split.

Using SpecEx the analysis system was able to integrate the user
into the model steering process seamlessly. Instead of deﬁning must-
link and cannot-link constraints to optimize topics, the user could
select from a set of prepared optimizations. Especially in topic
models, where often subtle semantic differences decide over the
quality or even correctness of a topic attribution, SpecEx can help to
achieve good results by exploring a wider area of the search space
instead of only a single model.

4.2 Implicit Steering
Our second example addresses the task of labeling datasets
which is increasingly supported with
VA techniques having the human in the
loop in interactive machine learning
settings. In their current state, these
VA systems support users in the label-
ing process with visual-interactive in-
terfaces showing data characteristics
as well as information about the current model state [3]. Example
labeling interfaces include scatterplots [2] in combination with di-
mensionality reduction [27], radvis-like visualizations [29], or list-
based interfaces [24], e.g., in combination with active learning mod-
els [30]. Interaction techniques that enable the assignment of labels
are based on simple item selection or drag-and-drop facility. Users
of the systems start by creating a small set of training data with some
labeling interactions, triggering the machine learning algorithm to
be re-trained in an iterative way. Intermediate results of the mod-

ing. If this task is executed on a large, collaborative touchscreen,
both experts can even train their model in parallel. After retraining
the respective models, the experts can compare which model cap-
tured the particularities of the current dataset better. In a provenance-
tracking view, they can compare which training decisions were most
important for making one of the classiﬁers more adapt to the data.
After a short discussion, the experts can now agree on a common
understanding of ISQ/NISQ that is suitable for the dataset.

4.5 Speculative Execution beyond Machine Learning
Speculative Execution can also be extended beyond machine
learning scenarios. One possible ex-
tension is towards visualization sys-
tems that focus on presenting data
without an underlying model. In this
scenario, we use the example of a sys-
tem visualizing geographical move-
ment data of cars on a map. The “en-
virocar” data set1 contains GPS tracks of driving cars and is anno-
tated with speed, the fuel consumption, rpm, et cetera. As it contains
about 1.7 million rows, it cannot be visualized on a map without
some preprocessing and aggregation. One such aggregation step is
the bundling of trajectories to avoid overplotting. Additionally, a
system may show a summary of the presented data in a detail panel.
Such information is, for example, useful to families searching for
a home in a quiet area without too much trafﬁc and with low emis-
sions. To make the interaction with the system more seamless, it
uses eye-tracking to determine regions that users are interested in.
Once such a region is determined, it zooms in and provides more de-
tail. In combination with SpecEx this zooming process is smoother.
While the system is still determining whether a user is interested in
a region or was only glimpsing at it, it can already precompute the
aggregations on the new level and prepare the detail panel. If the
zoom-in action is performed later, the data is already preprocessed
and can be displayed.

5 ASPECTS OF SPECULATIVE EXECUTION
Having shown the applicability of SpecEx in various VA scenarios,
we provide a list of theoretical considerations. They stem from both
our experience with implementing SpecEx for topic modeling and
the hypothetical usage scenarios. We conclude by providing design
principles for SpecEx.

5.1 Semantic Complexity of Interactions
User interaction can build the basis for relevant input for SpecEx.
Depending on the level of semantic complexity of such an interaction,
the goals of the Speculative Execution are different. We deﬁne
semantic complexity as the amount by which the mental model of
the user changes by performing this interaction. The different levels
will be described in the following.

L1: Start of Interaction Once the user has started an interac-
tion, the system can assess what the user is trying to achieve. It can
then try to predict how this interaction can be ﬁnished using extrapo-
lation techniques. The goal of Speculative Execution on this level is
to prepare the context of the interaction target. During a drag and
drop operation, for example, such computations could include the
search for relevant “drop targets”.

L2: Completion of Interaction Every interaction that was
completed can build a basis for similar interactions that may be
performed in future. Whenever an interaction has been ﬁnished, the
system can try to predict the next interaction on a similar level of
complexity that the user might want to perform. The goal of such
speculations is to guide the user in exploring the potential impact of
interactions. Also, Speculative Execution at this level could make

1https://old.datahub.io/dataset/envirocar, last accessed 7/15/2018

users aware of data points that might have been missed, for example
when removing outlier nodes.

L3: Repetition of Interactions In many cases, users combine
different low-level interactions to solve a higher-level intent [38].
As such, combinations of interactions are at the highest of the se-
mantical levels of speculation that we want to address. Tracking and
contextualizing of low-level interactions to make sense of user in-
tents builds the basis for the support of SpecEx at this level. Once a
user intent has been identiﬁed, the system can begin searching for
similar intents that users might have, and that could be solved with a
similar set of repeated low-level interactions.

To some extent, the goal on all levels of semantic complexity is
“User Intention Guessing”: the system needs to determine the im-
plicit interaction [14] that the user is trying to achieve by perform-
ing the explicit interactions. Once the user’s intention has been iden-
tiﬁed, appropriate optimizations, parameter changes, or additional
computations can be searched in a much more focused manner.

5.2 Dimensions of Speculation
Speculative Execution and sandboxes provide the theoretical frame-
work for an efﬁcient, mixed-initiative guidance approach to visual
analytics, extending the Visual Analytics pipeline by Keim et al. [20].
Whenever SpecEx is not proposing optimizations to complete user
interactions, it can target improvement in the measured model qual-
ity and prepare alternative models. Their usefulness depends on
the model-speciﬁc speculation dimensions. These speculation di-
mensions are deﬁned by parameters or properties of the underlying
model. In any computed sandbox, some of the possible specula-
tion dimensions may be altered with respect to the “original” model.
The following section highlights guidelines for the selection of spec-
ulation dimensions. Although SpecEx is not limited to those, we
present ﬁve distinct categories of dimensions here.

Temporal Dimensions Temporal dimensions include the actual
time as well as an iteration number, depending on the model. They
are especially interesting for incremental algorithms. Incremental
streaming models can build a buffer of events or data and “forecast”
the development of the model in any given sandbox. For iterative
algorithms, a sandbox can show the model development over the
next iterations. Progressive sandboxes can be continously reﬁned as
new data becomes available. This can allow users to pursue multiple
model alternatives in parallel, before deciding for one.

Optimization Strategies For various models, direct optimiza-
tions, manipulating the models’ underlying data structures, can be
conceived. Operations could include merging or splitting tree nodes,
changing values of matrices and vectors, or introducing a threshold.
These optimization strategies can be tailored towards known poten-
tial model issues and provide bespoke solutions for these problems,
without having to explore and change the model’s parameters. Such
strategies have been implemented in the system presented in 4.1 [11]
and provide sandboxes avoiding topic chaining or combining small,
overly speciﬁc topics into more easily understood generalized ones.
Utilizing bespoke optimization strategies incurs an additional im-
plementation cost for identifying potential model issues and devel-
oping possible solutions. However, it can directly address problems
that would be unintuitive, difﬁcult, or even impossible to change
through model parameter changes.

Model Parameters If no bespoke optimization strategies are
available, the sandboxes of SpecEx can perform a Visual Parameter
Space Analysis [28], creating different sandboxes for different pa-
rameter conﬁgurations. However, instead of sampling and precom-
puting the entire parameter space, the analysis can be focused on re-
gions of the search space that are similar to the users current model.
As soon as users start exploring new regions of the model state space,
new sandboxes can be created and prepared in the background.

Input Transformations If the preprocessing pipeline is inte-
grated into the Visual Analytics system, SpecEx sandboxes can uti-
lize these preprocessing algorithms to transform the underlying data.
Examples of such transformations include a stricter outlier-removal,
ﬁltering out stopwords from a collection of text documents, or intro-
ducing minimum and maximum-thresholds for time-series data.

Algorithm Modiﬁcations Ultimately, SpecEx sandboxes can
also explore modiﬁcations of the original model or any of its parts.
They can replace similarity functions, feature weighting schemes
or merging strategies, to name just a few. As this dimension is spe-
ciﬁc to the underlying model, it can be very effective and powerful.
As with any Input Transformations, the system needs to explicitly
inform the users of any changes made to these dimensions. Modiﬁ-
cations here might have an impact on the user’s mental model and
how well it ﬁts.

5.3 Towards Design Principles
In the following, we provide design considerations for effective
Speculative Execution in ﬁve areas.

Speculation Dimensions When performing speculative pa-
rameter space analysis or employing bespoke optimization strategies,
there is a trade-off between the number of sandboxes that are created
and their usefulness. As one goal of Speculative Execution is a more
guided exploration of the model state space, more sandboxes are ben-
eﬁcial: they lead to more model conﬁgurations being calculated and
presented to the user. However, in addition to the increased need for
computational resources, users cannot and will not inspect and com-
pare a large number of speculative sandboxes. In our ﬁrst implemen-
tation of Speculative Execution for the optimization of topic models,
we offered users the results of seven speculative optimization strate-
gies [11]. In the evaluation study, users often focused on the top-two
or top-three optimizations according to our provided ranking. One
possible reason is that model comparison is a difﬁcult task. It might
be alleviated by effective delta-visualizations, but users will remain
unable to compare all sandboxes that can be computed.

Runtime Depending on the level of semantic complexity of
an interaction triggering speculative execution different runtime re-
quirements apply. With increasing complexity of the performed in-
teractions, increasingly complex Speculative Executions are neces-
sary to support and guide the user. However, the runtime require-
ments for these more “complex” sandboxes triggered by L2 or even
L3 interactions are not as strict as for those triggered by L1 interac-
tions that need to be executed while the user is performing an inter-
action like dragging and dropping an object. Here, the aim should be
on focused and short computations of less than 500ms. As soon as
the user ends the interaction, the speculation becomes meaningless.
However, the resulting sandboxes for L2 and especially L3 interac-
tions are likely still useful after a couple of seconds. It is important
that such longer-running speculations do not block the user interface
as to not interrupt the analysis workﬂow.

Search Space Size As we have previously implemented
SpecEx for IHTM [11], an incremental topic model building a tree
structure, we elaborate on the size of the individual search- and
model-spaces using a concrete example. We consider a corpus con-
taining 280 documents (k) and a two-dimensional speculative execu-
tion with n = 7 optimization strategies and b = 10 additional docu-
ments being inserted into the model from the buffer during a spec-
ulation. Running the model without optimization will produce ex-
actly one topic-tree as its output. With SpecEx, we compute at most
(k/b)· n = 196 sandboxes. This allows us to involve the user in the
algorithmic decision-making process but is signiﬁcantly more scal-
able than considering all possible optimization paths (even consider-
ing the buffer), which would result in n(k/b) ≈ 1023 options. Even
though this would be an exponentially large search space, it is still

multiple orders of magnitude smaller than all possible trees an incre-
mental algorithm would consider (k! ≈ 10565), or all possible trees
with k nodes (k(k−2) ≈ 10680). This example shows that the Specu-
lative Execution reduces the factorial search space to a linear one.
This is due to the use of only two dimensions with a very limited
set of possible values. Here, careful considerations weighing search
space exploration against computation time are necessary. One inter-
esting area for future research is the formalization of a cost-beneﬁt
model for Speculative Execution that can be used as guidance when
selecting speculation dimensions.

Quality Metrics Whenever Speculative Execution is not trig-
gered by user interaction it needs quality metrics to trigger and as-
sess sandboxes. The user typically performs a multi-objective op-
timization of these metrics when trying to improve a model. As a
result, good consensus strategies between the used metrics are nec-
essary to sort the computed sandboxes before presenting them to the
user for exploration. Note that it is typically not possible to fully
automate this optimization process, as most quality metrics do not
capture (all) semantic details.

Delta-Visualization For an efﬁcient SpecEx, an effective delta-
visualization is necessary to highlight the differences between the
current model and a selected sandbox. This visualization needs to
be tailored to the underlying model, the visualization from which
the Speculative Execution was triggered, and the number of changes
introduced in the speculation. Gleicher et al. [15] introduced vari-
ous patterns for visual comparison. While different patterns are use-
ful in different situations, we argue that explicit encoding should
be present in comparative sandbox visualizations to help users to
quickly focus on the introduced changes that decide over accepting
or rejecting the proposed sandbox. For some tasks like labeling, a
list of elements with changed labels might be more useful than a
complex visualization trying to highlight the differences between
two dimensionality-reduction results.

5.4 Research Opportunities
With Speculative Execution being a novel concept in Visual Analyt-
ics, many interesting questions remain.

Mapping Interaction to Optimization Understanding the in-
tent of user interactions is paramount for effective Speculative Ex-
ecution. While systems using implicit steering exist today, it is an
open ﬁeld of research how interactions on the different levels of se-
mantic complexity can be understood and mapped to concrete goals
for a speculative sandbox. Endert et al. have already identiﬁed the
capturing of user interaction intentions as relevant future work [12].
In addition, they have elaborated on design considerations and conﬁ-
dence levels of captured interactions [13]. Further research should
investigate how such captured interactions can be generalized and
re-applied to complete the user’s semantic interactions.

Cost-Beneﬁt-Model As was alluded to in the previous section,
choosing the wrong (number of) speculation dimensions is detri-
mental to the usefulness of SpecEx. An information-theoretic cost-
model for Speculative Execution could deﬁne the size of the search
space, the number of visited states, the computation time and the
cognitive load on users. Such a cost-model would then allow in-
formed choices on the sandboxes SpecEx computes.

Interaction Design Speculative Execution constantly computes
alternative models that users might want to explore and needs to
present them for inspection. However, systems should not constantly
interrupt the analyst’s workﬂow for model-comparison. Further
research should be conducted to determine when and how to show
sandbox results, and when to refrain from interrupting the user.
Furthermore, research should investigate how different presentation
styles of SpecEx results impact the creation and conﬁrmation of
biases.

6 CONCLUSION
We have introduced Speculative Execution as a new methodology for
Visual Analytics. Based on a deﬁnition and formalization of SpecEx
for VA, we presented ﬁve possible usage scenarios that demonstrate
the applicability of SpecEx in VA. Finally, we characterized differ-
ent aspects of SpecEx in VA, showing that SpecEx is a multifaceted
concept that can support VA in different ways. The primary beneﬁts
of successfully adopting SpecEx into the VA processes are multi-
ple ways in which user guidance can be provided algorithmically,
conﬂated with visual-interactive interfaces. Next steps include the
implementation of Speculative Execution in several VA applications
to further demonstrate the applicability of SpecEx for guided VA.
Likewise, the elaboration of formerly discussed research opportuni-
ties will lead to new insights.

7 ACKNOWLEDGMENTS
This work has been funded in part by the Deutsche Forschungsge-
meinschaft (DFG) within the project “Visual Analytics and Linguis-
tics for Interpreting Deliberative Argumentation (VALIDA)”, Grant
Number 376714276, as part of the Priority Program “Robust Argu-
mentation Machines (RATIO)” (SPP-1999).

REFERENCES
[1] D. Arnott. Cognitive biases and decision support systems development:
a design science approach. Information Systems Journal, 16(1):55–78,
2006.

[2] J. Bernard, M. Hutter, M. Zeppelzauer, D. Fellner, and M. Sedlmair.
Comparing visual-interactive labeling with active learning: An experi-
mental study. IEEE Trans. on Visualization and Computer Graphics,
24(1):298–308, Jan 2018.

[3] J. Bernard, M. Zeppelzauer, M. Sedlmair, and W. Aigner. VIAL: a
uniﬁed process for visual interactive labeling. The Visual Computer,
pages 1–19, Mar 2018.

[4] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent Dirichlet Allocation.

Journal of Machine Learning Research, pages 993–1022, 2003.

[5] E. T. Brown, A. Ottley, H. Zhao, Q. Lin, R. Souvenir, A. Endert, and
R. Chang. Finding waldo: Learning about users from their interactions.
IEEE Trans. on Visualization and Computer Graphics, 20(12):1663–
1672, Dec 2014.

[6] S. P. Callahan, J. Freire, E. Santos, C. E. Scheidegger, C. T. Silva, and
H. T. Vo. Vistrails: visualization meets data management. In Proc.
ACM SIGMOD Int. Conf. on Management of Data, pages 745–747.
ACM, 2006.

[7] A. Dewald, T. Holz, and F. C. Freiling. Adsandbox: Sandboxing
javascript to ﬁght malicious websites. In Proc. ACM Symp. on Applied
Computing, pages 1859–1864. ACM, 2010.

[8] W. Dou, D. H. Jeong, F. Stukes, W. Ribarsky, H. R. Lipford, and
R. Chang. Recovering reasoning processes from user interactions.
IEEE Computer Graphics and Applications, 29(3):52–61, May 2009.
[9] M. El-Assady, R. Sevastjanova, D. Keim, and C. Collins. Thread-
Reconstructor: Modeling Reply-Chains to Untangle Conversational
Text through Visual Analytics. Computer Graphics Forum, 37(3):351–
365, 2018.

[10] M. El-Assady, R. Sevastjanova, F. Sperrle, D. A. Keim, and C. Collins.
Progressive Learning of Topic Modeling Parameters: A Visual Analyt-
ics Framework. IEEE Trans. on Visualization and Computer Graphics,
24(1):382–391, Jan. 2018.

[11] M. El-Assady, F. Sperrle, O. Deussen, D. Keim, and C. Collins. Vi-
sual Analytics for Topic Model Optimization based on User-Steerable
Speculative Execution. to appear, IEEE Trans. on Visualization and
Computer Graphics, 2018.

[12] A. Endert, R. Chang, C. North, and M. Zhou. Semantic interaction:
Coupling cognition and computation through usable interactive ana-
lytics. IEEE Computer Graphics and Applications, 35(4):94–99, July
2015.

[13] A. Endert, P. Fiaux, and C. North. Semantic interaction for visual
text analytics. In Proc. of the SIGCHI Conf. on Human Factors in
Computing Systems, pages 473–482. ACM, 2012.

[14] A. Endert, M. S. Hossain, N. Ramakrishnan, C. North, P. Fiaux, and
C. Andrews. The human is the loop: new directions for visual analytics.
Journal of intelligent information systems, 43(3):411–435, 2014.

[15] M. Gleicher, D. Albers, R. Walker, I. Jusuﬁ, C. D. Hansen, and J. C.
Roberts. Visual comparison for information visualization. Information
Visualization, 10(4):289–309, 2011.

[16] J. Gonz´alez and A. Gonz´alez. Speculative execution via address pre-
diction and data prefetching. In Proc. Int. Conf. on Supercomputing,
pages 196–203. ACM, 1997.

[17] R. J. Heuer. Psychology of intelligence analysis. 1999.
[18] L. Ingram and M. Walﬁsh. Treehouse: Javascript sandboxes to help web
developers help themselves. In USENIX Annual Technical Conference,
pages 153–164, 2012.

[19] W. Jentner, M. El-Assady, D. Sacha, D. J¨ackle, and F. Stoffel. Dyna-
mite: Dynamic Monitoring Interface for Task Ensembles. In IEEE
Conf. on Visual Analytics Science and Technology (VAST Challenge
MC1), 2016.

[20] D. Keim, G. Andrienko, J. D. Fekete, C. G¨org, J. Kohlhammer, and
G. Melanc¸on. Visual analytics: Deﬁnition, process, and challenges. In
Lecture Notes in Computer Science, pages 154–175, 2008.

[21] T. Y. Lee, A. Smith, K. Seppi, N. Elmqvist, J. Boyd-Graber, and L. Find-
later. The human touch: How non-expert users perceive, interpret, and
ﬁx topic models. Int. J. of Human-Computer Studies, 105:28–42, 9
2017.

[22] S. Liu, X. Wang, M. Liu, and J. Zhu. Towards better analysis of ma-
chine learning models: A visual analytics perspective. Visual Informat-
ics, 1(1):48–56, 3 2017.

[23] P. H. Nguyen, K. Xu, A. Bardill, B. Salman, K. Herd, and B. W. Wong.
Sensemap: Supporting browser-based online sensemaking through
analytic provenance. In IEEE Conf. on Visual Analytics Science and
Technology, pages 91–100. IEEE, 2016.

[24] C. Ritter, C. Altenhofen, M. Zeppelzauer, A. Kuijper, T. Schreck, and
J. Bernard. Personalized Visual-Interactive Music Classiﬁcation. In
EuroVis Workshop on Visual Analytics, 2018.

[25] T. Ruppert, J. Bernard, and J. Kohlhammer. Bridging knowledge gaps
in policy analysis with information visualization. In Conf. on Electronic
Government, volume 221 of LNI, pages 92–103, 2013.

[26] D. Sacha, M. Sedlmair, L. Zhang, J. A. Lee, J. Peltonen, D. Weiskopf,
S. C. North, and D. A. Keim. What you see is what you can change:
Human-centered machine learning by interactive visualization. Neu-
rocomputing, 268:164 – 175, 2017. Advances in artiﬁcial neural net-
works, machine learning and computational intelligence.

[27] D. Sacha, L. Zhang, M. Sedlmair, J. A. Lee, J. Peltonen, D. Weiskopf,
S. C. North, and D. A. Keim. Visual interaction with dimensionality re-
duction: A structured literature analysis. IEEE Trans. on Visualization
and Computer Graphics, 23(1):241–250, 2017.

[28] M. Sedlmair, C. Heinzl, S. Bruckner, H. Piringer, and T. M¨oller. Visual
parameter space analysis: A conceptual framework. IEEE Trans. on
Visualization and Computer Graphics, 20(12):2161–2170, 2014.

[29] C. Seifert and M. Granitzer. User-based active learning. In IEEE Int.

Conf. on Data Mining Workshop, pages 418–425, 2010.

[30] B. Settles. Active learning. Synthesis Lectures on Artiﬁcial Intelligence

and Machine Learning, 6(1):1–114, 2012.

[31] R. Sevastjanova, M. El-Assady, A. Hautli-Janisz, A.-L. Kalouli,
R. Kehlbeck, O. Deussen, D. Keim, and M. Butt. Mixed-initiative ac-
tive learning for generating linguistic insights in question classiﬁcation.
In Workshop on Data Systems for Interactive Analysis (DSIA) at IEEE
VIS, 2018.

[32] H. Stitz, S. Luger, M. Streit, and N. Gehlenborg. Avocado: visualiza-
tion of workﬂow–derived data provenance for reproducible biomedical
research. In Computer Graphics Forum, volume 35, pages 481–490.
Wiley Online Library, 2016.

[33] S. van den Elzen and J. J. van Wijk. Small multiples, large singles:
A new approach for visual data exploration. In Computer Graphics
Forum, volume 32, pages 191–200. Wiley Online Library, 2013.

[34] E. Wall, L. M. Blaha, L. Franklin, and A. Endert. Warning, bias may
occur: A proposed approach to detecting cognitive bias in interactive
visual analytics. In IEEE Conf. on Visual Analytics Science and Tech-
nology, 2017.

[35] E. Wall, S. Das, R. Chawla, B. Kalidindi, E. T. Brown, and A. Endert.

Podium: Ranking data using mixed-initiative visual analytics. IEEE
Trans. on Visualization and Computer Graphics, 24(1):288–297, 2018.
[36] W. Wright, D. Schroh, P. Proulx, A. Skaburskis, and B. Cort. The
sandbox for analysis: concepts and methods. In Proc. SIGCHI Conf.
on Human Factors in Computing Systems, pages 801–810. ACM, 2006.
[37] B. Yee, D. Sehr, G. Dardyk, J. B. Chen, R. Muth, T. Ormandy,
S. Okasaka, N. Narula, and N. Fullagar. Native client: A sandbox for
portable, untrusted x86 native code. In IEEE Symposium on Security
and Privacy, pages 79–93, May 2009.

[38] J. S. Yi, Y. a. Kang, and J. Stasko. Toward a deeper understanding of
the role of interaction in information visualization. IEEE Trans. on
Visualization and Computer Graphics, 13(6):1224–1231, Nov 2007.
[39] C. Zilles and G. Sohi. Execution-based prediction using speculative
slices. ACM SIGARCH Computer Architecture News, 29(2):2–13,
2001.

View publication stats
View publication stats

","{""0"":{""0"":""specex"",""1"":""ieee*"",""2"":""keim"",""3"":""sedlmair"",""4"":""endert"",""5"":""conf"",""6"":""bernard*"",""7"":""konstanz""},""1"":{""0"":""introduced"",""1"":""drop*"",""2"":""select*"",""3"":""propose"",""4"":""integrates"",""5"":""monitor"",""6"":""perform*"",""7"":""consider*""},""2"":{""0"":""model*"",""1"":""system"",""2"":""level"",""3"":""concept*"",""4"":""design*"",""5"":""bespoke*"",""6"":""component"",""7"":""complex""},""3"":{""0"":""learning"",""1"":""sect*"",""2"":""trans"",""3"":""publication*"",""4"":""citations*"",""5"":""publications"",""6"":""journal*"",""7"":""online""},""4"":{""0"":""sandboxes"",""1"":""analytics"",""2"":""visualization"",""3"":""scenarios*"",""4"":""strategies"",""5"":""topics*"",""6"":""scenario"",""7"":""environments*""},""pos"":{""0"":1,""1"":2,""2"":3,""3"":4,""4"":5,""5"":6,""6"":7,""7"":8}}",2018,{},False,False,journalArticle,False,8NYK2X9E,[],self.user,"{""C"":{""0"":12.9996915748,""1"":7.4321966368,""10"":4.4518232258,""11"":20.6055439698,""12"":3.3873966814,""13"":13.1431172522,""14"":3.3767992801,""15"":5.0506649208,""16"":15.3771387018,""17"":3.8425023733,""18"":13.0409833368,""19"":3.94131978,""2"":7.4246886342,""20"":4.8465147713,""21"":4.399836208,""22"":5.0895349446,""23"":5.9697522987,""24"":10.8771322522,""25"":6.8284685671,""26"":6.9331266484,""27"":8.7866378264,""28"":4.4585772719,""29"":11.7804381561,""3"":4.0797719879,""30"":10.5976024804,""31"":4.7084022385,""32"":4.6181227873,""33"":5.9935930425,""34"":4.22760227,""35"":4.4630392419,""36"":3.6986510544,""37"":4.2882269238,""38"":6.7546624775,""39"":3.7956792767,""4"":4.8707452937,""40"":3.8198594428,""41"":4.9327458076,""42"":5.3848905245,""43"":6.9357471778,""44"":6.5836246251,""45"":5.6736134552,""46"":6.3222462805,""47"":3.5207478641,""48"":6.0557501615,""49"":4.4346826022,""5"":3.938653108,""50"":5.6677333069,""51"":3.8193564266,""52"":4.653621674,""53"":4.653621674,""54"":3.8842498047,""55"":3.7673890114,""56"":4.6354718969,""57"":3.3489933737,""58"":3.7031903019,""59"":3.3716561769,""6"":6.12334069,""60"":4.5046452018,""61"":4.5097001709,""62"":4.6128763345,""63"":3.3796020568,""64"":3.9625620744,""65"":4.4645967383,""66"":4.6263659082,""67"":3.4876528047,""68"":4.46907306,""69"":3.6343560252,""7"":7.8491051668,""70"":3.7076071781,""71"":4.1659622217,""72"":4.5495450951,""73"":3.7051988371,""74"":3.8300366731,""75"":4.141066981,""76"":4.0241452039,""8"":5.2504501421,""9"":10.2321884011},""Unnamed: 0"":{""0"":0,""1"":1,""10"":10,""11"":11,""12"":12,""13"":13,""14"":14,""15"":15,""16"":16,""17"":17,""18"":18,""19"":19,""2"":2,""20"":20,""21"":22,""22"":23,""23"":24,""24"":25,""25"":26,""26"":27,""27"":28,""28"":29,""29"":30,""3"":3,""30"":31,""31"":32,""32"":33,""33"":34,""34"":35,""35"":36,""36"":37,""37"":38,""38"":40,""39"":41,""4"":4,""40"":42,""41"":43,""42"":44,""43"":45,""44"":46,""45"":47,""46"":49,""47"":50,""48"":51,""49"":52,""5"":5,""50"":53,""51"":54,""52"":55,""53"":56,""54"":57,""55"":58,""56"":59,""57"":60,""58"":61,""59"":62,""6"":6,""60"":63,""61"":64,""62"":65,""63"":66,""64"":67,""65"":68,""66"":69,""67"":70,""68"":71,""69"":72,""7"":7,""70"":73,""71"":74,""72"":76,""73"":77,""74"":78,""75"":79,""76"":80,""8"":8,""9"":9},""count"":{""0"":238,""1"":112,""10"":38,""11"":34,""12"":32,""13"":32,""14"":30,""15"":26,""16"":26,""17"":22,""18"":22,""19"":20,""2"":94,""20"":20,""21"":18,""22"":18,""23"":18,""24"":18,""25"":16,""26"":16,""27"":16,""28"":14,""29"":14,""3"":78,""30"":14,""31"":14,""32"":14,""33"":14,""34"":12,""35"":12,""36"":12,""37"":10,""38"":10,""39"":10,""4"":76,""40"":10,""41"":10,""42"":10,""43"":10,""44"":8,""45"":8,""46"":8,""47"":8,""48"":8,""49"":8,""5"":60,""50"":8,""51"":6,""52"":6,""53"":6,""54"":6,""55"":6,""56"":6,""57"":6,""58"":6,""59"":6,""6"":52,""60"":6,""61"":6,""62"":6,""63"":6,""64"":6,""65"":6,""66"":6,""67"":6,""68"":6,""69"":6,""7"":46,""70"":6,""71"":6,""72"":6,""73"":6,""74"":6,""75"":6,""76"":6,""8"":42,""9"":40},""exemplar"":{""0"":""*"",""1"":null,""10"":null,""11"":""*"",""12"":null,""13"":null,""14"":""*"",""15"":null,""16"":null,""17"":null,""18"":null,""19"":null,""2"":null,""20"":""*"",""21"":null,""22"":null,""23"":""*"",""24"":null,""25"":""*"",""26"":null,""27"":null,""28"":""*"",""29"":null,""3"":null,""30"":null,""31"":null,""32"":null,""33"":""*"",""34"":null,""35"":null,""36"":""*"",""37"":""*"",""38"":null,""39"":null,""4"":null,""40"":null,""41"":null,""42"":null,""43"":null,""44"":""*"",""45"":""*"",""46"":null,""47"":""*"",""48"":""*"",""49"":null,""5"":null,""50"":""*"",""51"":null,""52"":null,""53"":null,""54"":""*"",""55"":null,""56"":null,""57"":null,""58"":null,""59"":null,""6"":null,""60"":null,""61"":null,""62"":null,""63"":""*"",""64"":null,""65"":null,""66"":null,""67"":null,""68"":""*"",""69"":""*"",""7"":null,""70"":""*"",""71"":null,""72"":""*"",""73"":null,""74"":null,""75"":null,""76"":null,""8"":null,""9"":null},""pos"":{""0"":1,""1"":1,""10"":1,""11"":2,""12"":5,""13"":6,""14"":4,""15"":5,""16"":7,""17"":1,""18"":3,""19"":3,""2"":1,""20"":4,""21"":4,""22"":5,""23"":6,""24"":6,""25"":2,""26"":7,""27"":3,""28"":7,""29"":8,""3"":2,""30"":8,""31"":9,""32"":9,""33"":8,""34"":10,""35"":10,""36"":5,""37"":4,""38"":11,""39"":9,""4"":1,""40"":12,""41"":13,""42"":11,""43"":14,""44"":5,""45"":12,""46"":10,""47"":2,""48"":3,""49"":15,""5"":2,""50"":6,""51"":13,""52"":6,""53"":16,""54"":14,""55"":4,""56"":17,""57"":5,""58"":18,""59"":6,""6"":3,""60"":7,""61"":19,""62"":11,""63"":7,""64"":12,""65"":13,""66"":14,""67"":8,""68"":8,""69"":15,""7"":2,""70"":7,""71"":15,""72"":16,""73"":20,""74"":8,""75"":21,""76"":9,""8"":3,""9"":4},""sigma_nor"":{""0"":1.8161153155,""1"":1.6573040781,""10"":1.6061098134,""11"":4.0773361704,""12"":1.4799570768,""13"":2.9931453606,""14"":1.4887776846,""15"":1.7930794228,""16"":3.5281790563,""17"":1.6213715408,""18"":3.2649815138,""19"":1.6570549858,""2"":1.7100820963,""20"":1.82436434,""21"":1.764321902,""22"":1.8965090387,""23"":2.0652108292,""24"":3.0057555489,""25"":2.272619014,""26"":2.293476458,""27"":2.6628650913,""28"":1.8268866375,""29"":3.3490168153,""3"":1.4149091351,""30"":3.1031189615,""31"":1.8788223581,""32"":1.8600543046,""33"":2.145998659,""34"":1.8047463152,""35"":1.8559887988,""36"":1.6896209218,""37"":1.8448047502,""38"":2.4091378968,""39"":1.732107314,""4"":1.5045871947,""40"":1.7376398605,""41"":1.9922739875,""42"":2.0957270253,""43"":2.450571008,""44"":2.4238850026,""45"":2.2040334971,""46"":2.3607380606,""47"":1.6839181876,""48"":2.2963547048,""49"":1.9047175961,""5"":1.4457407374,""50"":2.2026128998,""51"":1.7636838317,""52"":1.9773025449,""53"":1.9773025449,""54"":1.7803001776,""55"":1.7503772576,""56"":1.9726551836,""57"":1.6432444985,""58"":1.7339387858,""59"":1.6490474477,""6"":1.7494587822,""60"":1.9391562091,""61"":1.9404505648,""62"":1.9668694519,""63"":1.6510820388,""64"":1.8003525127,""65"":1.9289015554,""66"":1.9703235396,""67"":1.6787490929,""68"":1.9300477449,""69"":1.7163133487,""7"":2.0181942099,""70"":1.7350697539,""71"":1.852434363,""72"":1.9506531011,""73"":1.7344530835,""74"":1.7664185741,""75"":1.8460597845,""76"":1.8161212492,""8"":1.6947159893,""9"":2.4141682341},""topic"":{""0"":2,""1"":0,""10"":3,""11"":0,""12"":-1,""13"":-1,""14"":4,""15"":4,""16"":-1,""17"":1,""18"":2,""19"":0,""2"":4,""20"":2,""21"":0,""22"":0,""23"":4,""24"":0,""25"":3,""26"":4,""27"":3,""28"":0,""29"":-1,""3"":4,""30"":0,""31"":0,""32"":-1,""33"":4,""34"":0,""35"":-1,""36"":2,""37"":3,""38"":-1,""39"":4,""4"":-1,""40"":-1,""41"":-1,""42"":0,""43"":-1,""44"":3,""45"":0,""46"":4,""47"":1,""48"":1,""49"":-1,""5"":-1,""50"":2,""51"":0,""52"":3,""53"":-1,""54"":0,""55"":1,""56"":-1,""57"":1,""58"":-1,""59"":1,""6"":4,""60"":2,""61"":-1,""62"":4,""63"":1,""64"":4,""65"":4,""66"":4,""67"":2,""68"":1,""69"":4,""7"":2,""70"":3,""71"":0,""72"":0,""73"":-1,""74"":3,""75"":-1,""76"":3,""8"":-1,""9"":-1},""vector"":{""0"":""[-1.7190285   4.2998285   8.725518   -1.5094131   2.1322963  -5.4669676\n -2.6036913  -3.5215628  -4.6895795   0.78956753]"",""1"":""[-0.80510545  3.96352     8.357683   -0.08503228  0.93118745 -5.8771935\n -1.7159812  -1.8377583  -2.5375245   0.34200847]"",""10"":""[-1.3352207   4.491427    8.674226   -0.8164384   1.7972256  -5.7349377\n -2.0098898  -3.177136   -3.5438614   0.68665963]"",""11"":""[-1.1304458   3.5475512   8.035601   -0.02408611  0.68117064 -5.714042\n -1.6783473  -1.9281197  -2.6921704   0.45111018]"",""12"":""[-1.834395   4.3533187  9.091856  -0.8234163  1.5024344 -5.397989\n -3.0843954 -3.4136088 -4.6669593  1.0707935]"",""13"":""[-1.9312218  5.022212   9.221042  -0.4304799  1.5677738 -6.583812\n -3.2431977 -2.8144383 -4.267619   0.6864173]"",""14"":""[-1.8179165   5.1115456   8.94588    -0.98544353  2.1000967  -6.212807\n -3.5982132  -3.2321675  -4.7034144   0.7722745 ]"",""15"":""[-1.4685625  5.044164   8.951046  -1.0189494  2.20844   -6.220498\n -3.4476004 -3.2570822 -4.263416   0.7076259]"",""16"":""[-1.6554049   4.446551    8.932283   -0.91506094  1.7312428  -6.304557\n -2.5748465  -2.7573142  -3.6901221   0.51801986]"",""17"":""[-1.270033   4.377535   9.324691  -1.2377703  2.182915  -4.7877407\n -3.5408082 -4.2842836 -4.7252274  1.5697856]"",""18"":""[-1.9098413  4.694976   8.6142235 -1.0004754  1.7476234 -5.678126\n -2.9102645 -3.473572  -4.627512   1.04209  ]"",""19"":""[-0.12923607  4.275624    8.396168    0.19380644  1.0546142  -5.5696716\n -1.5103426  -1.7706987  -2.3077557   0.05837436]"",""2"":""[-1.8390334   5.099286    9.247032   -0.52293265  1.7861371  -6.5089073\n -3.4292068  -2.8865104  -4.47323     0.6669603 ]"",""20"":""[-1.4658589  4.2615733  8.947712  -1.3813385  2.205376  -5.5406322\n -2.656554  -3.377995  -4.572325   0.6887311]"",""21"":""[-0.42585087  4.199675    8.286838    0.10272471  1.1344129  -5.71764\n -1.5132357  -1.9044385  -2.3120673   0.25463545]"",""22"":""[-0.1938045   4.334985    8.376975    0.24120605  1.0917372  -5.643619\n -1.4751511  -1.7340282  -2.238915    0.14000465]"",""23"":""[-1.75424    5.0179567  8.981271  -0.6911371  1.7563145 -6.536063\n -3.2269528 -2.8801274 -4.1083026  0.6364904]"",""24"":""[-1.1146023   3.744129    8.3131075  -0.17333555  0.715995   -5.8624377\n -1.8047374  -1.9193974  -2.8127987   0.4955372 ]"",""25"":""[-2.086148    4.750102    9.241997   -0.35636607  1.2702676  -6.2765284\n -2.5423965  -3.0151432  -4.2277145   0.85088193]"",""26"":""[-1.8852826  4.8231897  8.939636  -1.1979709  2.0718787 -5.982403\n -3.553749  -3.295137  -4.791171   0.7945167]"",""27"":""[-1.7074515   4.378068    8.732951   -0.1901174   1.0060651  -5.9756546\n -2.273701   -2.7785215  -3.8945076   0.93978584]"",""28"":""[-0.748074    3.757472    8.007739    0.12846483  0.7517037  -5.62911\n -1.4448777  -1.8648655  -2.4048252   0.1774474 ]"",""29"":""[-1.2823764   4.4107065   8.827034   -0.40004867  1.4350573  -5.775246\n -2.0902226  -2.749999   -3.467893    0.59714806]"",""3"":""[-1.7334889   4.3198357   8.455545   -1.3513848   1.9007648  -6.211022\n -2.750253   -2.7566776  -3.5855064   0.48402974]"",""30"":""[-6.3058782e-01  4.4458299e+00  8.3852196e+00 -4.6951720e-03\n  1.4604231e+00 -5.7727981e+00 -1.6739771e+00 -2.1931100e+00\n -2.4811440e+00  4.3916118e-01]"",""31"":""[-0.5686584   3.9889364   8.159253    0.13486785  0.9479616  -5.5737867\n -1.5266534  -1.9151223  -2.4380324   0.2161012 ]"",""32"":""[-1.2799067   4.3499813   9.1256895  -0.90009326  1.8461514  -5.137433\n -3.004541   -3.8147907  -4.4391522   1.2418147 ]"",""33"":""[-1.7189354  4.991756   8.940899  -1.0225277  2.048212  -6.3444486\n -3.6027455 -2.9733543 -4.3775654  0.5892277]"",""34"":""[-0.38044783  4.342702    8.432148    0.06563369  1.2334908  -5.726201\n -1.6255636  -1.9297307  -2.3933942   0.17342357]"",""35"":""[-1.2366163  4.0828867  8.975624  -1.1598121  1.9077995 -5.120894\n -2.9831393 -3.67693   -4.402431   1.11379  ]"",""36"":""[-1.4780931   4.2508173   8.820679   -1.3097522   2.0662174  -5.386384\n -2.270359   -3.5888615  -4.352495    0.82838583]"",""37"":""[-2.0534308   4.7161126   8.91329    -0.46684802  1.1953125  -6.189928\n -2.2238457  -3.06849    -3.8570154   0.86058474]"",""38"":""[-1.3457516   4.5167      8.500363   -1.0213935   1.921767   -5.517175\n -2.0708501  -3.3846653  -3.7807422   0.74833685]"",""39"":""[-1.8511747   4.9209514   8.723853   -0.97165704  1.8950549  -5.9538913\n -3.2220945  -3.3199532  -4.6346674   0.90238965]"",""4"":""[-1.9125243   4.144676    8.533453   -1.2887696   1.5902984  -6.062137\n -2.7253292  -2.8076918  -3.8842254   0.67064244]"",""40"":""[-1.2465059  4.714152   9.081129  -0.9414869  2.125052  -5.560177\n -3.1769483 -3.7846127 -4.342673   1.1165502]"",""41"":""[-1.5574297  4.572256   8.743329  -1.0253564  1.9285167 -5.534575\n -2.406529  -3.7123666 -4.327035   1.03447  ]"",""42"":""[-1.0499637   3.6912618   8.213383   -0.12613149  0.6977609  -5.851149\n -1.7031734  -1.8365476  -2.6599855   0.39191714]"",""43"":""[-1.6580873  4.192983   8.950636  -0.8969311  1.5188845 -5.266719\n -3.0462227 -3.3052747 -4.611388   1.0053473]"",""44"":""[-1.9230367   4.8561873   9.116846   -0.35814923  1.3844823  -6.5346828\n -2.777746   -2.7667212  -4.045548    0.70306903]"",""45"":""[-0.94102865  3.652449    7.960102    0.0447049   0.7039521  -5.60311\n -1.4946206  -1.9941336  -2.5618095   0.2595814 ]"",""46"":""[-2.0387578   4.816603    9.136047   -0.9344343   1.7431221  -6.184497\n -3.6120918  -3.095644   -4.582409    0.78123015]"",""47"":""[-1.7455578  4.4310575  9.211013  -1.312039   2.0765676 -4.8777633\n -3.810158  -4.2985744 -4.9106045  1.3959981]"",""48"":""[-1.5740706  4.2586193  9.309258  -1.4650625  2.0344036 -4.6862354\n -3.8055642 -4.4634933 -4.938161   1.5028288]"",""49"":""[-2.1012769  4.3219395  8.53175   -1.1696274  1.5920821 -6.192808\n -2.9216514 -2.8033495 -4.062801   0.673522 ]"",""5"":""[-1.3270644   4.2613015   9.033611   -1.1159056   2.0964572  -5.849324\n -2.4392784  -3.0800097  -4.188102    0.55995065]"",""50"":""[-1.2152989  4.227209   8.889139  -1.0750118  1.95528   -5.2055874\n -2.408418  -3.729746  -4.1616015  1.0221354]"",""51"":""[-0.3810838   4.4511614   8.324673    0.1600773   1.3851309  -5.5979033\n -1.6591657  -2.0625293  -2.4796228   0.27998695]"",""52"":""[-1.8303603   4.8335114   8.92655    -0.48107392  1.4494963  -6.4928675\n -2.673326   -2.815058   -3.899761    0.70721096]"",""53"":""[-2.0702837   4.3600335   8.509726   -1.1459651   1.5686897  -5.8395066\n -2.5088923  -3.2561483  -4.2639837   0.93125653]"",""54"":""[-0.90912867  3.773338    8.000708    0.04477436  0.81575763 -5.5258565\n -1.5220829  -2.144808   -2.6474888   0.30434385]"",""55"":""[-1.4858584  4.5317507  9.456535  -1.109678   2.005443  -4.777408\n -3.6533988 -4.267343  -4.8018937  1.5644331]"",""56"":""[-1.7026103   4.364944    9.092615   -0.54021776  1.3930471  -5.9881277\n -2.011298   -3.0426033  -3.8971446   0.7948221 ]"",""57"":""[-1.172699   4.2689185  9.178708  -1.3283367  2.2003055 -4.91975\n -3.3818822 -4.1673346 -4.63033    1.4536256]"",""58"":""[-1.9551607  4.610042   9.126237  -1.1302564  1.8546293 -5.6966243\n -3.610802  -3.44579   -4.8095245  0.9654298]"",""59"":""[-1.5452293  4.1803617  9.219252  -1.5421582  2.0919592 -4.6677604\n -3.7701366 -4.4713144 -4.900261   1.474927 ]"",""6"":""[-1.6278574   4.371745    8.638698   -1.2035908   1.8875731  -6.242238\n -2.6943715  -2.709207   -3.5550544   0.42130145]"",""60"":""[-1.7256771  4.299633   8.712142  -1.452769   1.9974809 -5.448005\n -2.9864507 -3.529814  -4.6426177  0.9086796]"",""61"":""[-1.4712012  4.398852   8.402644  -1.2445606  2.0568924 -5.9122863\n -2.3514943 -2.9892979 -3.5482311  0.4985143]"",""62"":""[-1.5589299   5.041317    9.059976   -0.71974725  2.0436478  -6.137111\n -3.314957   -3.1616743  -4.503625    0.75795597]"",""63"":""[-1.44795    4.2755876  9.25465   -1.4582406  2.1686463 -4.7559357\n -3.771317  -4.365699  -4.8832026  1.4971257]"",""64"":""[-1.56804    4.653586   8.798134  -1.1664476  2.017129  -6.4042315\n -3.1224527 -2.6821465 -3.7339609  0.3545947]"",""65"":""[-1.6693506  4.943723   8.862038  -1.0071441  1.9400468 -6.484198\n -3.5265253 -2.84381   -4.0176525  0.5198309]"",""66"":""[-1.7214342   4.480827    8.75334    -1.152874    1.7582061  -6.2626066\n -3.2949731  -2.6074045  -3.846162    0.42496988]"",""67"":""[-1.2702922   3.9900672   8.970635   -1.1881772   1.8913554  -5.188483\n -2.8360927  -3.4889157  -4.398191    0.95500875]"",""68"":""[-1.6400635  4.4494333  9.347246  -1.276309   2.0011604 -4.8548303\n -3.7891676 -4.266634  -4.9262705  1.4633068]"",""69"":""[-1.7203382   4.8585105   8.909573   -0.9616406   1.8652263  -6.476783\n -3.386571   -2.7905874  -4.0082583   0.51124465]"",""7"":""[-1.6985765  4.219834   8.996222  -1.2648944  1.9452746 -5.535071\n -2.9360816 -3.3007603 -4.738608   0.812003 ]"",""70"":""[-1.9403057   4.6907425   8.907858   -0.29861873  1.2197601  -6.33453\n -2.345942   -2.8670511  -4.0222077   0.8451729 ]"",""71"":""[-0.97779506  3.6306043   8.085549   -0.04797876  0.6935176  -5.4621553\n -1.6807432  -2.170469   -2.8096662   0.4724042 ]"",""72"":""[-0.7069522   3.7466288   8.0792055   0.06243204  0.7471265  -5.473729\n -1.5195274  -2.001312   -2.5814846   0.34950972]"",""73"":""[-1.5488197  4.373907   8.3495455 -1.2485745  1.9575837 -5.8772774\n -2.3537679 -3.0396276 -3.5508754  0.5907853]"",""74"":""[-1.6069235   4.4790983   8.883811   -0.47991446  1.4097984  -6.0003467\n -1.959613   -3.0395103  -3.6823893   0.7958174 ]"",""75"":""[-1.2671037  4.4798646  8.486946  -1.1620471  2.0122895 -5.4177256\n -2.083105  -3.326238  -3.9959118  0.6077142]"",""76"":""[-1.8998057   4.547427    8.691217   -0.33045325  1.1308924  -6.0908027\n -2.3645718  -2.9428973  -4.103744    0.99158037]"",""8"":""[-1.7271124  4.6637783  8.614403  -0.8362631  1.6787955 -5.5909843\n -2.3790174 -3.6646461 -4.24471    1.1444108]"",""9"":""[-1.381432   4.2629433  8.9147215 -0.8180505  1.7090292 -5.974179\n -2.2024927 -2.7536201 -3.5119984  0.4849441]""},""vocab_index"":{""0"":0,""1"":5,""10"":23,""11"":25,""12"":27,""13"":28,""14"":32,""15"":40,""16"":42,""17"":47,""18"":49,""19"":50,""2"":7,""20"":51,""21"":60,""22"":65,""23"":70,""24"":71,""25"":78,""26"":82,""27"":83,""28"":84,""29"":85,""3"":8,""30"":86,""31"":88,""32"":92,""33"":95,""34"":103,""35"":128,""36"":129,""37"":130,""38"":164,""39"":165,""4"":9,""40"":166,""41"":167,""42"":168,""43"":169,""44"":170,""45"":171,""46"":224,""47"":226,""48"":230,""49"":232,""5"":12,""50"":233,""51"":235,""52"":236,""53"":237,""54"":239,""55"":245,""56"":253,""57"":261,""58"":277,""59"":294,""6"":14,""60"":295,""61"":316,""62"":318,""63"":334,""64"":339,""65"":342,""66"":343,""67"":344,""68"":345,""69"":348,""7"":15,""70"":349,""71"":352,""72"":355,""73"":357,""74"":358,""75"":359,""76"":360,""8"":18,""9"":22},""word"":{""0"":""model"",""1"":""specex"",""10"":""learning"",""11"":""ieee"",""12"":""state"",""13"":""pages"",""14"":""scenarios"",""15"":""strategies"",""16"":""graphics"",""17"":""introduced"",""18"":""level"",""19"":""keim"",""2"":""sandboxes"",""20"":""concept"",""21"":""sedlmair"",""22"":""endert"",""23"":""topics"",""24"":""conf"",""25"":""sect"",""26"":""scenario"",""27"":""trans"",""28"":""bernard"",""29"":""university"",""3"":""analytics"",""30"":""konstanz"",""31"":""assady"",""32"":""existing"",""33"":""environments"",""34"":""sperrle"",""35"":""underlying"",""36"":""design"",""37"":""publication"",""38"":""training"",""39"":""levels"",""4"":""data"",""40"":""needs"",""41"":""cost"",""42"":""proc"",""43"":""north"",""44"":""citations"",""45"":""fabian"",""46"":""instances"",""47"":""drop"",""48"":""select"",""49"":""dataset"",""5"":""space"",""50"":""bespoke"",""51"":""darmstadt"",""52"":""publications"",""53"":""profile"",""54"":""michael"",""55"":""propose"",""56"":""mail"",""57"":""integrates"",""58"":""case"",""59"":""monitor"",""6"":""visualization"",""60"":""component"",""61"":""intuition"",""62"":""teams"",""63"":""perform"",""64"":""algorithms"",""65"":""transformations"",""66"":""runtime"",""67"":""complex"",""68"":""consider"",""69"":""applications"",""7"":""system"",""70"":""journal"",""71"":""chang"",""72"":""collins"",""73"":""intelligence"",""74"":""online"",""75"":""workshop"",""76"":""volume"",""8"":""quality"",""9"":""computer""},""word*"":{""0"":""model*"",""1"":""specex"",""10"":""learning"",""11"":""ieee*"",""12"":""state"",""13"":""pages"",""14"":""scenarios*"",""15"":""strategies"",""16"":""graphics"",""17"":""introduced"",""18"":""level"",""19"":""keim"",""2"":""sandboxes"",""20"":""concept*"",""21"":""sedlmair"",""22"":""endert"",""23"":""topics*"",""24"":""conf"",""25"":""sect*"",""26"":""scenario"",""27"":""trans"",""28"":""bernard*"",""29"":""university"",""3"":""analytics"",""30"":""konstanz"",""31"":""assady"",""32"":""existing"",""33"":""environments*"",""34"":""sperrle"",""35"":""underlying"",""36"":""design*"",""37"":""publication*"",""38"":""training"",""39"":""levels"",""4"":""data"",""40"":""needs"",""41"":""cost"",""42"":""proc"",""43"":""north"",""44"":""citations*"",""45"":""fabian*"",""46"":""instances"",""47"":""drop*"",""48"":""select*"",""49"":""dataset"",""5"":""space"",""50"":""bespoke*"",""51"":""darmstadt"",""52"":""publications"",""53"":""profile"",""54"":""michael*"",""55"":""propose"",""56"":""mail"",""57"":""integrates"",""58"":""case"",""59"":""monitor"",""6"":""visualization"",""60"":""component"",""61"":""intuition"",""62"":""teams"",""63"":""perform*"",""64"":""algorithms"",""65"":""transformations"",""66"":""runtime"",""67"":""complex"",""68"":""consider*"",""69"":""applications*"",""7"":""system"",""70"":""journal*"",""71"":""chang"",""72"":""collins*"",""73"":""intelligence"",""74"":""online"",""75"":""workshop"",""76"":""volume"",""8"":""quality"",""9"":""computer""},""x2D"":{""0"":6.7316980362,""1"":-10.5249214172,""10"":5.3127298355,""11"":-10.6820411682,""12"":7.1679987907,""13"":7.2503423691,""14"":8.4016551971,""15"":7.9305243492,""16"":5.8321800232,""17"":3.4920768738,""18"":7.1402349472,""19"":-11.3390436172,""2"":7.6470217705,""20"":6.3957290649,""21"":-11.2059364319,""22"":-11.1522302628,""23"":7.3534479141,""24"":-10.5589036942,""25"":4.9312114716,""26"":8.358962059,""27"":4.5813288689,""28"":-11.0367155075,""29"":4.8722176552,""3"":6.0607714653,""30"":-11.3229255676,""31"":-10.9114494324,""32"":6.4168057442,""33"":7.9653282166,""34"":-11.3483963013,""35"":6.370549202,""36"":6.0959849358,""37"":4.8410582542,""38"":5.5984210968,""39"":8.3831224442,""4"":6.3485369682,""40"":6.74700737,""41"":6.387629509,""42"":-10.7394218445,""43"":7.001180172,""44"":5.3977088928,""45"":-11.1583080292,""46"":8.1029853821,""47"":3.2124738693,""48"":3.5562939644,""49"":6.6091346741,""5"":5.9595031738,""50"":6.1120800972,""51"":-11.4711790085,""52"":5.4255862236,""53"":6.7038989067,""54"":-11.1359109879,""55"":3.1498374939,""56"":4.7319359779,""57"":3.808352232,""58"":8.311085701,""59"":3.5246520042,""6"":6.1915431023,""60"":6.7142782211,""61"":5.8642382622,""62"":8.1901216507,""63"":3.408741951,""64"":6.6273937225,""65"":7.4041113853,""66"":6.7098326683,""67"":6.4995779991,""68"":3.2893247604,""69"":7.2006578445,""7"":7.0657916069,""70"":4.9148478508,""71"":-10.903429985,""72"":-10.9100284576,""73"":5.7292532921,""74"":4.8202652931,""75"":5.8244504929,""76"":5.0352334976,""8"":6.5891551971,""9"":5.2677865028},""y2D"":{""0"":8.4995527267,""1"":4.3978071213,""10"":6.9984397888,""11"":5.0795049667,""12"":8.8520097733,""13"":5.0593557358,""14"":5.9613060951,""15"":5.7794685364,""16"":6.2386875153,""17"":11.4844293594,""18"":8.0004138947,""19"":3.6292390823,""2"":5.2536764145,""20"":8.6150856018,""21"":3.7892811298,""22"":3.8446576595,""23"":5.4137911797,""24"":4.8657755852,""25"":5.002240181,""26"":6.2961559296,""27"":5.4947328568,""28"":4.5645742416,""29"":6.342862606,""3"":6.4079465866,""30"":4.2523288727,""31"":4.1884131432,""32"":9.4806852341,""33"":5.7207093239,""34"":4.0374231339,""35"":9.3526182175,""36"":8.4463996887,""37"":5.2714910507,""38"":7.4779381752,""39"":6.3860497475,""4"":6.7080821991,""40"":9.5118150711,""41"":8.1963863373,""42"":4.9609494209,""43"":8.955945015,""44"":5.1709570885,""45"":4.6907157898,""46"":6.2133812904,""47"":11.0235977173,""48"":10.9650506973,""49"":6.5351009369,""5"":7.7951450348,""50"":8.8036909103,""51"":4.0201692581,""52"":5.2739825249,""53"":7.5228500366,""54"":4.8373317719,""55"":11.2906112671,""56"":5.7067289352,""57"":11.2648363113,""58"":6.6661891937,""59"":11.3920679092,""6"":6.4922924042,""60"":8.7481956482,""61"":6.9284462929,""62"":5.6624622345,""63"":11.0694684982,""64"":6.0096130371,""65"":5.7452282906,""66"":6.0534691811,""67"":9.0435667038,""68"":11.1281223297,""69"":5.7211275101,""7"":8.6979188919,""70"":5.2294363976,""71"":5.0373854637,""72"":4.6533498764,""73"":7.0454883575,""74"":5.9473781586,""75"":7.8794555664,""76"":5.3969640732,""8"":8.0049009323,""9"":6.5153970718}}",False,False,False,,,Speculative Execution for Guided Visual Analytics,"[-4.82807867e-03 -8.61385241e-02  7.45861456e-02 -2.65238464e-01
  5.09493798e-02 -8.32806945e-01  5.65917678e-02  7.38730669e-01
 -4.03962433e-01  2.27047061e-03 -6.87278509e-01 -2.03711689e-01
  4.34088707e-02  2.62720823e-01  3.10841743e-02  5.53030908e-01
 -6.81991100e-01  6.62546828e-02 -1.24628708e-01  4.29542631e-01
  6.85534656e-01  2.68023293e-02 -2.99007744e-02  2.16250673e-01
  6.99101686e-01  5.55054061e-02 -7.93231372e-03 -4.49131280e-01
 -8.84690881e-01 -2.70795703e-01  2.11816236e-01 -7.45382085e-02
  6.27837181e-02  2.95537487e-02 -5.84202290e-01 -7.08953917e-01
 -1.33176371e-01  1.37654133e-02  6.00967586e-01  4.81520504e-01
 -3.93820763e-01 -2.00682312e-01 -3.62562761e-02  7.62162209e-02
  1.93626553e-01  4.48046714e-01  1.50852904e-01 -1.67134017e-01
 -5.53881586e-01  1.33112267e-01 -4.61062044e-01 -4.09539878e-01
  7.34333754e-01  9.57196429e-02  6.51588440e-01  6.50047287e-02
  2.52850026e-01 -3.58068764e-01 -9.16881025e-01 -1.73193306e-01
 -3.48197073e-01  5.68658948e-01  3.53714347e-01 -2.39828661e-01
  8.18756163e-01 -3.70570943e-02  1.42186284e-01  4.84603852e-01
 -1.05902147e+00  1.27359614e-01 -6.69729039e-02  2.36808181e-01
 -1.50250062e-01  7.98813999e-01  2.80180097e-01  5.56048751e-01
  3.16660367e-02  6.77237630e-01  1.68513849e-01 -5.30812740e-01
 -1.88420251e-01  8.62459838e-02 -2.59140104e-01  9.88765880e-02
 -5.15950546e-02  2.34337747e-01 -3.52569483e-02 -1.67967588e-01
 -8.08617115e-01  7.56982446e-01 -4.33424294e-01  1.71447933e-01
  2.55431116e-01 -5.72116934e-02  9.47715998e-01 -5.70481956e-01
  3.12168151e-01  3.75944525e-02 -4.01636392e-01 -2.21256182e-01
  5.67790031e-01  1.06850885e-01  1.62628777e-02 -3.23463947e-01
 -5.30878425e-01  4.57554787e-01 -1.32949710e-01  3.47549357e-02
 -1.34877980e-01  3.04873973e-01 -2.38451734e-01  5.33794045e-01
 -1.90702081e-01 -9.39414620e-01 -3.44434023e-01  5.60093939e-01
  2.51744896e-01  1.23366356e-01 -1.25949532e-01  3.59850913e-01
  1.30076051e-01  2.00729564e-01  2.44145826e-01  1.28124803e-01
  3.91087770e-01 -1.45245463e-01  2.18142167e-01 -2.95833379e-01
  3.14511180e-01  2.01647133e-02  9.32160556e-01  2.89166927e-01
  1.37130037e-01 -3.79231066e-01  7.93809518e-02  1.20686568e-01
  1.55730948e-01 -4.03111815e-01 -2.81531036e-01  6.06083497e-02
  1.84306696e-01 -7.49115288e-01  1.59558117e-01 -5.97206473e-01
 -5.96615821e-02 -5.55747896e-02 -2.59019136e-01 -4.13725704e-01
 -3.04965824e-01  3.92155945e-02 -2.24585528e-04 -4.38505888e-01
 -1.81366503e-01  7.63192922e-02  8.07304308e-02  3.04611009e-02
  2.94934303e-01 -4.32409197e-02  3.54310632e-01 -5.44746339e-01
  3.73319745e-01  1.66738123e-01 -2.59485006e-01  4.67811078e-02
 -1.36798799e-01  2.39210889e-01 -3.41806293e-01 -1.63442567e-01
  6.75382689e-02 -4.18910421e-02 -4.42282520e-02 -3.12043071e-01
  6.71017528e-01 -1.60371706e-01  5.06690919e-01  6.69150233e-01
  4.11654674e-02  3.03277850e-01  3.23941469e-01  5.21854043e-01
 -7.10457623e-01 -1.37059122e-01 -1.35176465e-01 -8.07719827e-01
  7.77075887e-02  1.79079607e-01  6.61128461e-01 -1.11347161e-01
  3.85275871e-01  7.18700647e-01 -4.02320057e-01 -1.33341357e-01
  9.34245661e-02 -2.71581799e-01  5.44126093e-01 -2.12910607e-01
 -2.42982581e-01 -3.96178544e-01 -8.54851678e-03 -2.47237682e-01
  1.03165321e-01 -7.32845813e-02  2.96090722e-01  3.12328428e-01
 -4.71617520e-01 -1.92742780e-01 -2.10448191e-01 -5.55899322e-01
 -9.86969247e-02 -3.01046193e-01 -3.33043009e-01  4.47655797e-01
 -1.28824428e-01  2.44749054e-01 -2.60630816e-01  4.13286984e-01
 -9.72004980e-02 -1.78218573e-01 -6.45122603e-02  2.05185980e-01
  5.77756226e-01  3.34731251e-01  6.15696847e-01  1.55496776e-01
  2.50425160e-01  9.56627429e-01 -1.03581570e-01  3.04973200e-02
  8.21519136e-01  4.80271071e-01 -3.65763158e-01  9.42427069e-02
  3.95261765e-01  5.12290478e-01  4.45241809e-01  3.47159892e-01
 -4.30451989e-01 -2.72296458e-01  8.20266753e-02 -2.09089682e-01
 -1.02849118e-01  3.61723304e-01  3.05654883e-01  4.12190408e-01
  2.45785639e-01  2.93794245e-01 -3.24611694e-01 -1.26468748e-01
 -1.92341134e-01 -3.92457604e-01  1.98644787e-01  5.74928164e-01
 -5.81306934e-01 -5.29802918e-01 -3.69289011e-01  2.27942914e-02
 -5.69314659e-01 -2.43816972e-01 -1.88504174e-01  4.49024737e-01
  1.38334380e-02  2.87222862e-01 -2.05350995e-01 -2.76310205e-01
 -2.36702323e-01 -3.83555055e-01  4.31412935e-01 -2.85395831e-01
  3.59491736e-01 -8.74684080e-02 -4.33078110e-01 -3.95195812e-01
 -4.00222927e-01  7.70101070e-01  2.18475796e-02 -1.22317724e-01
  4.36140075e-02 -4.13016587e-01 -3.47970650e-02  4.88131911e-01
  1.54716402e-01 -1.35208175e-01 -1.41170353e-01 -9.79205128e-03
 -4.75846469e-01 -1.58137128e-01  3.01600546e-01  1.04096167e-01
 -2.13482782e-01  6.53660074e-02 -1.27654994e+00  1.92117542e-01
 -2.03269750e-01 -1.95738733e-01  9.67177749e-01  1.81522101e-01
  8.02537650e-02  1.29760697e-01 -6.29125774e-01 -3.08342963e-01
 -7.94899762e-02 -5.87742805e-01  1.62367299e-01  2.46902049e-01
 -5.43659888e-02  8.96648169e-01 -3.68689626e-01 -6.51547790e-01
 -3.51038551e+00 -5.20264730e-02 -6.88104987e-01 -1.14516936e-01
 -1.46631315e-01 -1.23049662e-01  1.92568570e-01 -4.54901785e-01
  6.91919997e-02 -6.55476153e-01 -1.26773104e-01 -1.96890756e-01
  1.53041035e-01  3.56500447e-01 -1.85702201e-02  6.07871413e-01
  3.43621761e-01  2.27791533e-01 -2.01869965e-01  2.32938766e-01
 -2.07579434e-01  9.66314226e-02 -1.21236257e-01 -5.13033569e-01
  2.31709704e-01  6.26890421e-01 -5.51503241e-01  2.99089521e-01
 -2.41478398e-01 -2.21074641e-01 -1.67594373e-01 -3.15406829e-01
 -4.22653854e-01  5.68803012e-01 -2.31200069e-01 -3.65235895e-01
 -2.34750286e-01 -7.89545476e-02 -3.73926125e-02 -2.36015305e-01
 -6.45323098e-02 -1.73201993e-01 -4.44249302e-01 -4.34449911e-01
  1.25168598e+00 -7.56209016e-01  3.12885307e-02  3.93695652e-01
 -1.60308369e-02  3.64222914e-01 -2.11582780e-01 -6.32641554e-01
  3.23893040e-01 -2.48482361e-01 -1.29847705e-01 -7.43490607e-02
  3.59180421e-01  7.05038071e-01 -3.21396679e-01 -4.88293350e-01
  8.30779433e-01 -3.17487836e-01  1.05182000e-01 -1.95747122e-01
 -4.15350765e-01 -3.81769866e-01 -6.26719534e-01 -8.76351953e-01
 -4.56025094e-01 -5.82419991e-01 -5.08567452e-01  1.21622038e+00
 -2.38706395e-01 -5.98835886e-01  4.16594595e-02 -7.13716507e-01
  3.08173716e-01  2.36231610e-01 -5.28701007e-01 -4.29196626e-01
 -1.84212089e-01  1.11816369e-01 -4.79254544e-01  1.70972526e-01
 -4.97557878e-01 -5.75097688e-02 -3.02165151e-01 -8.48741233e-01
 -1.03363979e+00 -4.44157958e-01 -1.65484026e-01  5.84891178e-02
  4.15627122e-01  3.69208343e-02 -1.28395945e-01 -5.76029718e-02
  1.00828135e+00  2.72620171e-01  2.40222469e-01 -1.37491703e-01
  5.30184805e-01  1.35106266e-01  7.63978660e-01 -2.83510029e-01
 -4.40495729e-01 -1.96559697e-01 -6.50500715e-01 -1.74017608e-01
 -7.23059699e-02 -4.40704495e-01 -1.57457560e-01 -5.87495416e-02
 -5.22917271e-01 -1.16691597e-01 -1.59817547e-01 -1.42052412e-01
  1.77694559e-02 -3.90788540e-02  5.05877733e-01 -2.37578824e-01
 -5.59696257e-01 -1.91217195e-02 -2.52243221e-01  1.93222746e-01
  6.74839735e-01 -3.05233657e-01  1.02689780e-01 -3.94957781e-01
 -1.42690778e-01  2.00537685e-03 -1.12522028e-01  9.32516307e-02
  2.28031799e-02  1.70652598e-01 -2.07178414e-01 -5.84790707e-01
  3.84107120e-02 -2.07459703e-01  2.12980464e-01  3.06420997e-02
  1.62108496e-01  7.93842852e-01 -4.35457468e-01 -2.59753078e-01
  3.57069932e-02  3.93642843e-01  1.18204176e-01  9.35276568e-01
 -3.53150100e-01 -8.64429548e-02 -4.41864580e-01 -5.18742085e-01
 -5.31650305e-01 -2.66440630e-01  2.90345430e-01 -1.60092413e-01
  5.84866405e-01  4.65802848e-01 -6.25697374e-01 -2.43277192e-01
 -1.80139631e-01 -2.64153093e-01 -1.02706939e-01  3.54371369e-01
 -1.69062078e-01 -1.90961361e-02  2.10934281e-01 -1.41037712e-02
  4.16007265e-02 -1.14192605e+00 -2.11822450e-01  7.40851045e-01
  5.40056944e-01 -2.24831924e-01  3.49095881e-01  2.23466262e-01
  1.57448456e-01 -2.66902298e-02  4.44087267e-01  1.93580896e-01
 -3.40307593e-01 -1.20996371e-01  2.20721468e-01 -8.53211209e-02
 -1.69268191e-01 -3.29327234e-03  7.07320422e-02  2.13284567e-01
  5.41981637e-01  6.76783502e-01 -3.74605834e-01  2.00123385e-01
 -1.18747197e-01 -4.73554254e-01 -5.28466888e-02 -8.91941249e-01
  2.75150061e-01 -8.05855393e-01 -1.62228629e-01  4.70194727e-01
 -1.14695504e-01  1.11612387e-01 -8.64349306e-01  3.20655048e-01
 -4.65650320e-01  2.81104833e-01 -2.63059974e-01 -6.00612834e-02
  2.36985281e-01  1.66942880e-01 -4.13758546e-01 -2.77607292e-01
  2.59074401e-02 -2.89062321e-01  4.36419517e-01  3.29669088e-01
 -4.22616154e-01  2.48785079e-01 -7.25029588e-01  1.77991852e-01
  2.09387049e-01  4.64813143e-01  8.35554361e-01 -2.89300948e-01
 -4.45003882e-02  4.12018687e-01  3.18360358e-01 -6.97605982e-02
 -4.85319704e-01 -1.43660933e-01 -7.35659525e-02 -5.13824940e-01
  1.45433191e-03 -6.57025218e-01 -5.14681816e-01 -4.87930387e-01
 -6.69326544e-01 -2.62477696e-01  3.66165817e-01 -7.83980131e-01
  8.47016424e-02 -3.18582773e-01 -4.31411892e-01 -3.28305334e-01
 -6.09805584e-01 -2.84042601e-02 -2.69754857e-01  2.08758876e-01
 -1.85582921e-01 -1.75886780e-01  5.77380136e-03 -4.72066224e-01
 -4.65889931e-01 -5.05387425e-01  6.73122048e-01 -4.52558547e-01
 -5.04614592e-01  5.74821932e-03  2.34881192e-01  1.36158122e-02
  1.42987296e-01  4.69902996e-03  1.15476854e-01  6.77212119e-01
 -2.80155003e-01 -2.62316108e-01 -1.28075272e-01 -1.68122929e-02
  1.85876787e-01 -7.57744551e-01 -4.31041181e-01  3.18389386e-01
 -1.88718855e-01  5.33591986e-01  5.26905417e-01  4.15468991e-01
 -1.29709855e-01 -4.10306156e-01 -2.38463953e-01 -4.84066427e-01
 -6.47237420e-01 -2.18262784e-02 -5.43672554e-02  2.58908421e-01
  3.32650065e-01 -5.43739140e-01 -4.44766395e-02  5.25625050e-01
  2.33677775e-01 -3.06648850e-01  2.31813043e-01  4.39937860e-01
 -3.59059200e-02  3.11726391e-01 -2.55930781e-01  4.96395648e-01
  8.85717154e-01  9.45108905e-02  1.60876483e-01  1.01465341e-02
 -2.88264006e-01  3.30905467e-01  5.28103232e-01  1.86871856e-01
  2.99794763e-01  8.77985954e-02 -9.80384126e-02 -1.72047123e-01
  1.78372920e-01 -1.42332658e-01 -1.71126015e-02  1.93106949e-01
  5.33847868e-01  1.03510702e+00  2.63376124e-02 -4.59289581e-01
 -1.12467301e+00 -2.10089982e-01 -3.45117658e-01 -4.33658183e-01
 -8.81664976e-02 -7.09965602e-02  4.65613544e-01  1.14505947e-01
 -3.98872972e-01 -2.13503897e-01 -2.91967094e-01  6.79572448e-02
  6.63679242e-02 -4.70747024e-01 -5.44190764e-01  3.71879429e-01
 -1.22445785e-01  3.42282444e-01 -8.03049877e-02 -9.11287367e-02
 -2.29008108e-01 -2.09376216e-01  3.76272082e-01  1.97706625e-01
 -3.87226254e-01  6.76212132e-01  4.99023318e-01  4.45841670e-01
 -1.85618475e-01  4.66886386e-02 -5.06873488e-01  8.65030065e-02
  8.38492140e-02 -1.74820691e-01 -1.64691031e-01  6.35989070e-01
 -2.88221408e-02  3.17995906e-01  2.79761493e-01 -7.62233436e-02
  8.97876024e-01  4.11468521e-02 -3.23707312e-02  2.76803613e-01
  1.83904156e-01  3.05075794e-01 -2.88079709e-01 -4.13086772e-01
 -1.06813088e-01  7.04837143e-02  5.87996244e-01 -4.30054277e-01
 -3.02108694e-02  5.59984386e-01  1.61514193e-01  2.87404895e-01
 -2.41535529e-01 -6.32007182e-01 -5.82342334e-02  1.92730308e-01
  1.85309872e-01 -2.36894548e-01 -6.11658454e-01 -1.29557192e-01
 -3.39324683e-01 -3.19251716e-01 -9.40820336e-01  2.06853058e-02
  5.34431219e-01 -4.40866083e-01  2.36593932e-01 -3.23668510e-01
 -1.54754043e-01 -9.54980552e-01 -5.85127294e-01  3.99205714e-01
  5.61174333e-01  2.54278421e-01 -1.35206223e-01  1.63861707e-01
  4.17191207e-01  3.13709617e-01  4.76647943e-01 -4.60819334e-01
 -3.97277981e-01 -2.60399789e-01 -3.15943897e-01  5.15812337e-01
  1.36000276e-01 -3.71035695e-01 -4.74426448e-02 -1.46497712e-01
 -2.92191833e-01 -2.52003908e-01 -4.10531741e-03  3.09309512e-01
 -1.07853577e-01  4.74447250e-01  2.45103657e-01  1.58585951e-01
  7.00568035e-02  2.33066559e-01 -7.38953426e-02  3.40585746e-02
  4.60049450e-01 -2.64215022e-01  1.80847403e-02  5.68304956e-01
  2.59241134e-01 -6.38725877e-01 -2.49869257e-01  6.55560791e-02
 -8.63580704e-02  1.75882608e-01 -5.15113592e-01 -1.59811944e-01
  1.75248474e-01  2.81650394e-01 -4.03691381e-02 -4.91932839e-01
  1.08118087e-01  2.78272510e-01  1.62656635e-01  1.93557143e-03
 -8.83211315e-01  1.01934411e-01  2.52588727e-02  4.82923836e-02
 -3.83217663e-01  3.85759652e-01  3.46991450e-01 -9.78647396e-02
 -7.75766596e-02 -2.19388872e-01 -1.76240936e-01  9.06260237e-02
 -7.66742229e-01 -7.32441545e-01 -1.41977668e-01  3.84469293e-02
 -1.35227963e-01 -4.88842130e-01 -2.55635440e-01  3.02160650e-01]",8NYK2X9E,False,False,"[6.565746784210205, 0.42536231875419617]"
LBDAM34S,GKXAWLGW,"The Effect of Semantic Interaction on Foraging in Text Analysis

John Wenskovitch*

Virginia Tech

Computer Science

Lauren Bradel†
Department of Defense

Michelle Dowling‡

Virginia Tech

Computer Science

Leanna House§

Virginia Tech

Statistics

Chris North¶
Virginia Tech

Computer Science

ABSTRACT
Completing text analysis tasks is a continuous sensemaking loop
of foraging for information and incrementally synthesizing it into
hypotheses. Past research has shown the advantages of using spa-
tial workspaces as a means for synthesizing information through
externalizing hypotheses and creating spatial schemas. However,
spatializing the entirety of datasets becomes prohibitive as the num-
ber of documents available to the analysts grows, particularly when
only a small subset are relevant to the task at hand. StarSPIRE is a
visual analytics tool designed to explore collections of documents,
leveraging users’ semantic interactions to steer (1) a synthesis model
that aids in document layout, and (2) a foraging model to automat-
ically retrieve new relevant information. In contrast to traditional
keyword search foraging (KSF), “semantic interaction foraging”
(SIF) occurs as a result of the user’s synthesis actions. To quantify
the value of semantic interaction foraging, we use StarSPIRE to
evaluate its utility for an intelligence analysis sensemaking task. Se-
mantic interaction foraging accounted for 26% of useful documents
found, and it also resulted in increased synthesis interactions and
improved sensemaking task performance by users in comparison to
only using keyword search.
Index Terms:
Human-centered computing—Visualization—
Empirical studies in visualization; Human-centered computing—
Visualization—Visual analytics

1 INTRODUCTION
Prior research has highlighted the utility of spatializations to support
the sensemaking process for text analysis [4–6, 11, 16, 21, 23, 30, 34,
48, 52, 53]. By providing a continuous physical workspace, analysts
can externalize their hypotheses and organize data into meaningful
schemas. However, manually arranging documents is a tedious
and time-consuming task. Analysts must read each document and
assess its relevance before deciding where the text belongs in an
incrementally evolving spatialization. This task is exacerbated in
realistic sensemaking scenarios because datasets are rarely small
enough to display in full, even on a large, high-resolution display.
Additionally, only a small subset of available documents is typically
relevant to the analyst’s sensemaking task. Analysts must then apply
a combination of searching for documents and organizing them
spatially. More speciﬁcally, analysts are tasked with two primary
challenges: foraging for relevant information, and synthesizing the
information into a coherent structure and narrative [10, 35].

These foraging and synthesizing tasks are combined in the visual
analytics tool StarSPIRE [12], which uses a spatial metaphor to serve
as a means of communicating with underlying document relevance
and spatial layout models. As the analyst synthesizes information,
StarSPIRE encodes their interactions in the workspace to update

*e-mail: jw87@vt.edu
†e-mail: lcbrade@nsa.gov
‡e-mail: dowlingm@vt.edu
§e-mail: lhouse@vt.edu
¶e-mail: north@cs.vt.edu

an underlying user model that captures the analyst’s interest foci
quantitatively. These are semantic interactions in the sense that
they directly reﬂect the analyst’s analytical thought process about
the meaning of the data (such as organizing documents, highlighting
and annotating text, etc.), rather than about manipulating model
parameters (e.g., sliders on keyword weights). The user model is
then used to support the foraging and synthesis processes.

To support the foraging process, the updated user model is used to
determine document relevance and to curate the working set of docu-
ments displayed in the workspace. Therefore, in addition to allowing
for traditional keyword search foraging (KSF) for documents (i.e.,
a user types in keywords and retrieves relevant documents), the
updated user model initiates semantic interaction foraging (SIF)
to automatically forage for documents that may be relevant to the
analyst. SIF displays new documents that the model infers may be
of interest to the analyst based on their prior synthesis actions. To
support the synthesis process, the updated user model is also used to
adjust the spatial layout, allowing the analyst to organize and visual-
ize the working set using a “proximity ≈ similarity” metaphor [20].
These two processes work together in a contextual manner. Syn-
thesis actions by the analyst within the spatial workspace (contextual
input) serve to initiate SIF algorithms, and the resulting newly-
foraged documents are automatically positioned within the space
(contextual output) by the synthesis layout algorithm.

This capability for SIF raises several research questions. Does SIF
retrieve useful relevant information? Does it retrieve information that
might not be found using KSF alone? How does it affect analysts’
interactions, sensemaking process, and analytic performance? To
evaluate the utility of semantic interaction foraging for sensemaking
tasks, in particular the translation of semantic interactions into SIF,
we conducted a comparative user study using a text dataset with
a known ground truth from the VAST 2007 Challenge [36]. For
foraging, the control condition offered only KSF. The experimental
condition also offered SIF in addition to KSF.

We found in this study that KSF and SIF are complementary
foraging techniques, each with beneﬁts and limitations regarding
the set of documents that each are best at retrieving. We found that
the introduction of SIF into StarSPIRE led to a boost in participant
comprehension of the scenario in the study dataset, led to an in-
crease in the number of user interactions with the workspace, and
led to the discovery of some relevant documents that were rarely
located by KSF alone. SIF shows clear effects on which documents
participants retrieved, how these documents were retrieved, how
the participants interacted with these documents, and the overall
information synthesis of the participants.

The contributions of this paper are:
• The design and results of a study to determine the effects of

SIF on the sensemaking process using StarSPIRE.

• An analysis of the study results to understand how SIF can

beneﬁt the exploration of large document collections.

• Reﬂections on using KSF and SIF in visual analytics systems.

2 RELATED WORK
2.1 Semantic Interaction
Previous work has demonstrated the success of semantic interaction
for manipulating underlying models (e.g., force-directed, multidi-
mensional scaling) to shield users from the complexity of these

algorithms [22]. By manipulating the data instead of altering model
parameters explicitly, users are able to maintain focus on their analy-
ses, thus staying in the “cognitive zone” [17, 26]. Similar techniques
have also been proposed in the user modeling community [2, 3].

Inspired by PNNL’s IN-SPIRE [37, 51], systems such as Force-
SPIRE [20] and StarSPIRE [12] allow users to directly manipulate
data points, which are then translated to parametric model feedback.
Dis-Function [14] and Andromeda [41] follow a similar approach
with quantitative data. These systems are limited by the size of
the datasets that can be analyzed. As the number of data points
and/or the data dimensionality increases, the execution time of the
spatial layout models increases to the point where a quick interaction-
feedback loop is no longer supported.

2.2 Visualizing and Interacting with Text
To visualize large text corpora, Typograph [19] uses varying levels
of data abstraction by utilizing extracted topics, keywords, and docu-
ment snippets. Users can drill down to see the documents at different
levels of detail. The multi-model semantic interaction technique in
StarSPIRE, in comparison, addresses the scalability challenge by
continually updating a small working set of documents. Documents
in StarSPIRE are either not present, iconiﬁed, or open. We previ-
ously presented a visualization pipeline that outlines how interac-
tions are captured, interpreted, and leveraged to compose a working
set of documents to visualize [12]. The multi-model visualization
pipeline demonstrates how models can be interchanged to best suit
the analyst’s needs [12]. This pipeline was previously demonstrated
using a display layout and a document relevance model, but could
easily be extended to include clustering [47], large-scale informa-
tion retrieval [25], or data streaming and sampling algorithms. For
example, Vizster combines a clustering algorithm and a graph layout
algorithm to visualize social networks [29].

Work by Ruotsalo et al. has demonstrated the use of direct ma-
nipulation to inﬂuence information retrieval algorithms [39]. User
interactions within a radial topic spatialization were used to infer
possible user intent and thereby tune search results, working on the
principle that searches evolve incrementally [44]. This is similar to
the incremental formalism seen in sensemaking and spatial organiza-
tion [43]. They found that these interactions did not replace the need
for conducting traditional keyword searches, but that the users in the
condition that allowed for the use of the spatial interface performed
better than those who did not have this technique available. These
results closely mimic the results of our user study – inferring user in-
terests through interactions in a spatialization does not replace KSF,
yet it augments the underlying models, allowing users to identify
more pertinent pieces of information.

2.3 Foraging for Text
Other systems provide mechanisms for visualizing search results
beyond the typical ranked list (e.g., term distribution charts [28], self-
organizing semantic maps [31]), but these methods have not received
widespread adoption and do not provide the nuanced spatial interac-
tions that Intent Radar does [39]. While ranked lists are well-suited
to narrow and speciﬁc searches, they may not be as well-suited for
complex sensemaking tasks. For example, conducting a literature
review requires exploring multiple facets of a topic. A simple ranked
list of results does not yield insight into documents that are mix-
tures of different topics. Thus, recommendation systems typically
separate foraging and synthesis, presenting results in a separate list.
However, StarSPIRE integrates recommendation systems into the
sensemaking process by placing recommendations in context with
the user’s current analytical workspace.

2.4 Recommendation Systems
Recommendation systems work by assigning a predicted “rating”
or “preference” score to individual items based on the relevance of

that item to an analyst [38]. StarSPIRE falls under the “content-
based ﬁltering” approach to recommendation systems, in which
these preference scores are determined by proﬁles of both the item
in question and the user exploring the collection of all items [15].

The foraging engine of StarSPIRE is also closely related to query-
by-example systems, which utilize a set of user-deﬁned query ob-
jects. Query-by-example systems can be found in the literature
across many types of data, including unstructured text documents [8],
multimedia [27, 40], and musical selections [24].

Our intent with this study was not to create a new algorithm for
a recommendation system; rather, we sought to evaluate the use of
semantic interaction techniques in support of document recommen-
dations. While the StarSPIRE foraging backend is relatively simple,
the weights applied to each category of semantic interaction allow
for ease of experimentation during the development of the system
and can be tuned to each scenario. In the future, these weights could
be learned either automatically or based on a large-scale study with
additional datasets. We assert that many recommendation systems
could be used as a foraging backend to StarSPIRE, which should
give even better performance than the heuristic system described in
Section 3 and Table 1.

3 STARSPIRE DESIGN
StarSPIRE is a visual analytics system prototype developed to
demonstrate semantic interaction with SIF. Many of the implemen-
tation details for StarSPIRE can be found in [12], though we brieﬂy
summarize the components relevant to the study here. In particular,
StarSPIRE contains the following concepts:

1. A working set of documents, extracted from a universal set
by an information retrieval model and relevance threshold,
representative of the foraging process. This model computes
the relevance of a document as a combination of the extracted
entities within each document and the term weights in the user
interest model. This relevance calculation combined with a
threshold serves as a ﬁlter for which documents are displayed
in the workspace.

2. A spatialization of the working set of documents, organized by
a spatial display layout model, representative of the synthesis
process. This model computes a weighted, force-directed
layout of the documents, with a document similarity function
of co-occurring terms weighted by the term weights in the user
interest model. The model places similar documents nearer
each other in the layout.

3. A high-dimensional user interest model, learned from the
user’s semantic interactions on the working set and spatial-
ization. The model consists of weights on terms to represent
the user’s interest level. The user model is input to the retrieval
and layout model algorithms.

4. SIF occurs as a result of semantic interactions that update the
user interest model, which is then input into the retrieval model,
thereby updating the current working set that is displayed on
screen by the layout model. In contrast, KSF bypasses the
interest model and directly manipulates the working set.

StarSPIRE (Fig. 1) provides users with a spatial workspace to
view and incrementally arrange documents in a large display space
(similar to the Analyst’s Workspace [6]). Documents are visualized
using a node-link diagram, and are shown as iconiﬁed nodes or as
open text windows. To avoid a cluttered workspace, edges linking
documents (based on term co-occurrence) are only shown radiating
from the currently selected node. We designed a set of semantic
interactions (some of which are listed in Table 1) by observing
real-world analysts who offered usability feedback in informal and
formal test settings to tune the parameters. This system is built
upon the foundation of ForceSPIRE [20], which implemented the

Table 1: StarSPIRE’s available semantic interactions and their associated parametric impact on the user interest model. Effects on the term
weights ranged from 15% to 40% depending on interaction.

Semantic Interaction
Open document
Minimize document
Remove document
Overlap documents (cluster)
Highlight text in document
Annotate document (notes)
Search (KSF)
Move or un/pin document

Effect on User Interest Model
Increase weight of terms in the document, and automatically pin.
Reduce weight of terms in the document.
Reduce weight of terms in the document; remove document from working set.
Increase weight of terms co-occurring in the overlapped documents.
Increase weight of highlighted terms, add terms to model (if not already present).
Increase weight of terms in the annotation, add terms to model (if not already present).
Increase weight of search terms, add terms to model (if not already present), adjust relevance threshold.
Adjust layout model constraints (layout model only; no effect on user interest model).

that operate solely on the layout without updating the user’s interest
model. Overall, the system was designed to reﬂect the incremental
nature of the human sensemaking process [35], such that semantic
interactions have an incremental effect on retrieval and layout.

3.3 Keyword Search and Semantic Interaction Foraging
StarSPIRE allows for two types of foraging: keyword search and
semantic interaction. The system explicitly searches for matching
documents when the user executes a keyword search. Executing
KSF in this manner serves a dual purpose. First, nodes are color
coded according to search hits, which can be used to identify relevant
documents already on the screen. Second, documents are foraged
from the database that are not currently displayed in the workspace.
StarSPIRE uses SIF when users highlight text, write annotations
on a document, or overlap documents. SIF ﬁrst determines which
term weights increased in the model as a result of the interaction.

synthesis portion of the process and provided the weighted, force-
directed spatial layout. StarSPIRE adds the foraging portion of the
process, enabling data retrieval beyond what is already displayed
in the workspace. StarSPIRE also enables a richer set of visual
encodings to reﬂect term weights and document relevance.

3.1 Visual Encodings
Nodes are encoded with node size and saturation to reﬂect docu-
ment relevance based on the underlying user interest model (Fig. 1).
These encodings are updated during semantic interactions to reﬂect
incremental and constantly evolving user sensemaking. Edges are
labeled with the top-weighted terms that co-occur in both documents,
and line thickness encodes the total weight of co-occurring terms to
reveal how much the documents have in common.

Terms are extracted from documents using LingPipe [9] and are
underlined in the documents. Based on the user interest model,
StarSPIRE automatically highlights text using a yellow gradient
saturation scale to indicate important terms. This allows for quick
skimming of documents to determine if they are worth further inves-
tigation. User-created highlights are shown in a distinct green color
to differentiate from system-generated highlights. Highlighting turns
plain text ﬁles into visual glyphs that make them easier to locate
again on a large, high-resolution display [11, 46].

StarSPIRE also provides visual cues to help users navigate the
workspace. Node outline color is used to indicate read or unread
status, and node hue is mapped to speciﬁc keyword searches (KSF)
the user has executed. Each node is labeled with the document title,
which can aid in choosing what documents to read as well as locating
previously read documents.

3.2 Semantic Interactions
The semantic interactions and their effect on the user model is
described in Table 1. These semantic interactions inﬂuence the
parameters of the user model, either increasing or decreasing the
weights of the associated terms. Additionally, terms can be added
or removed from the model through these interactions. In order
to allow users to change the course of their analysis without being
limited by initial paths of investigation, term weights slowly decay
over time to slightly emphasize more recent interactions.

The semantic interactions provide feedback to the user interest
model and thereby steer the underlying foraging and synthesis mod-
els. After each interaction, the system determines which documents
continue to meet the relevance threshold based on the updated user
interest model. The relevance threshold can also vary depending
on the interaction. For example, removing a document raises the
relevance threshold temporarily, allowing more irrelevant documents
to be pruned from the workspace. Conversely, explicitly executing
a search lowers the relevance threshold temporarily to allow more
documents to be added to the workspace. Moving nodes and pinning
them to ﬁxed locations in the spatialization are the only interactions

Figure 1: StarSPIRE visual encodings showing document relevance
(node size and saturation) and term importance (saturation of auto-
matic yellow highlighting of text).

Next, StarSPIRE uses these terms to search the repository of all
documents in the database that are not currently displayed in the
workspace. This forms a set of documents that are candidates for
addition to the workspace. These documents are then ranked in terms
of relevance by matching them to the user’s interest model. The
top n documents that surpass the relevance threshold are then added
into the workspace where they are laid out according to the current
display layout model, placing the search results in context of the
user’s current work. This eliminates the user’s need to swap views to
execute a query, review results, and add information to the synthesis
space. In this manner, synthesis-related actions are leveraged to
forage for information, while foraging actions aid in synthesizing
information by updating the visual encodings and spatial layout.

For example, when a user overlaps two documents that they think
are related, StarSPIRE increases the weight on the terms shared
between those two documents in the user interest model, inferring
their importance to the user. StarSPIRE then forages for additional
documents containing those terms, ranks the documents on relevance
to the user interest model, and adds the most relevant to the working
set and inserts them into the layout model shown on the screen.

KSF is the traditional method of obtaining potentially relevant
documents. Adding SIF functionality enables the system to passively
search for information as the analyst is synthesizing documents into
their workspace. Because it is based on the user interest model, SIF
utilizes many more search terms than are typically contained in KSF
queries. This allows for richer matching to ﬁnd new documents that
closely ﬁt the user’s perception of what is important, and can help to
overcome the difﬁculties users have in choosing good search terms.

4 STUDY DESIGN
The goal of this study is to quantify the impact, if any, of introducing
contextualized SIF into the sensemaking process. Speciﬁcally, how
does StarSPIRE with SIF compare to StarSPIRE without SIF? To ac-
complish this, we conducted a comparative user study with SIF+KSF
(referred to as the “SIF+KSF” group) as the test condition and only
KSF (referred to as the “KSF” group) as the control condition.

4.1 Task Description
To ensure that users would not be able to simply read all documents
in the dataset, and thus would have to forage for a small subset
of relevant documents, we chose the large VAST 2007 Challenge
dataset named Blue Iguanodon1 [36]. This dataset presents a law
enforcement/counterterrorism scenario composed of multiple latent
subplots within the overarching scenario of illegal exotic animal
sales. Participants were asked to explore these documents to investi-
gate the scenario. The documents themselves include news articles,
blog posts, photographs, hand-drawn comics, and spreadsheets. All
of the data, except for the spreadsheets, was used in this study. Be-
cause StarSPIRE does not currently contain support for images, all
images and comics were transcribed to describe their contents. This
resulted in 1486 documents. These documents were processed using
LingPipe [9] for entity extraction. After eliminating all entities that
only appeared a single time, 1440 entities remained in the term set.
The original Blue Iguanodon dataset does not contain a clear
starting point, but to aid the participants, we slightly modiﬁed the
task description to indicate a starting document for analysis: an
article describing an outbreak of a disease called “monkeypox” and
implying that chinchillas may be carriers of this disease. Their goal
was to identify the cause of this outbreak. The task is suitable for
students as well as professionals, requiring no specialized analytical
experience or domain knowledge. Also, there is a ground truth for
the task: the VAST 2007 Challenge has an associated scoring guide,
which enabled us to quantitatively evaluate the quality of analysis.

1In addition to the contest summary paper cited above, more information
about the 2007 VAST Challenge and the Blue Iguanodon dataset can be
found at http://www.cs.umd.edu/hcil/VASTcontest07/.

Participants used StarSPIRE on six 30” LCD panels, tiled in a
2x3 grid, on a 24-megapixel display system. This apparatus was
chosen to give users ample space to perform spatial synthesis, and
avoid the need to close documents purely for lack of space. Large
high-resolution displays have been shown to have many beneﬁts for
cognitively intensive sensemaking tasks [5, 7, 18].

Participants were given identical training on StarSPIRE with a
smaller dataset of 111 short text documents. After a demonstration
of the tool’s functionality, participants were instructed to solve an
analytical task in order to grow comfortable using StarSPIRE’s in-
terface. Participants were then given 75 minutes to complete the
sensemaking task, requiring participants to explore the 1486 docu-
ment set to identify the hidden plots regarding illicit activity. The
task required participants to sort out and synthesize relevant informa-
tion from many documents into a coherent hypothesized narrative.
All participants used the full allotted time. Although it was unlikely
to detect all of the interconnected subplots in this short time frame,
a reasonable and uniform time for analysis helped to prevent fatigue
and ensure quality analysis. To motivate participants, monetary
prizes in addition to the initial compensation were granted to the top
three performing participants.

After completing the 75-minute analytical session, participants
answered survey questions pertaining to the who, what, and where
of the plot, and described their overall hypothesis. All participants
had access to their ﬁnal workspace during the survey to be able to
reference their annotations and open documents. Next, the partic-
ipants drew and annotated their spatial organizational schema on
paper. Finally, users completed a survey to give feedback on their
analytical strategy, difﬁculties encountered, and how StarSPIRE
helped or hindered their analysis. The proctor conducted a brief
semi-structured interview for any remaining comments. Also, par-
ticipants were able to pause and ask questions at any point during
the sensemaking session. The entire session, from informed consent
to ﬁnal survey and interview, spanned approximately two hours.

We collected logs of all interactions performed by users as well
as snapshots of the underlying model parameter values, took screen-
shots every minute, and saved their ﬁnal workspaces so that they
could be loaded and examined at a later date.

4.2 Participants
We recruited 18 graduate and undergraduate students from vary-
ing academic backgrounds. Participant ages ranged from 18 to 42
(µ = 23, σ = 5.6). Twelve participants were male and six were
female. Twelve were computer science students, ﬁve from engineer-
ing disciplines, and one from mathematics. Six participants were
graduate students, and twelve were undergraduates. Each participant
was randomly assigned a condition (KSF or SIF+KSF, described in
the next subsection) such that each condition had an equal number
of participants.

Figure 2: A participant interacting with StarSPIRE.

4.3 Study Conditions
This study consisted of two conditions. The test condition is referred
to as the “SIF+KSF” group, in which participants had access to the
full StarSPIRE system. Participants assigned to this group could
use both semantic interaction foraging and keyword search foraging
when exploring the document collection. In other words, StarSPIRE
foraged for new documents to recommend to each participant based
on their explicit keyword searches, as well as by their interactions
in opening, minimizing, removing, overlapping, highlighting, and
annotating documents. The semantic interactions provided to these
participants are listed in Table 1.

The control condition is referred to as the “KSF” group. Partici-
pants assigned to this group could only forage for new documents
via explicit keyword searches that they typed into search boxes.
Participants still had the ability to perform the semantic interac-
tions listed in Table 1 that updated the user model, but automatic
foraging did not occur as a result of those actions. For example,
participants could still highlight phrases within the documents to
support their own synthesis process and to support the layout and
automatic highlighting, but StarSPIRE did not automatically forage
for documents related to those phrases or the updated model. The
StarSPIRE system was identical in both conditions, except that the
SIF functionality was turned off in the KSF condition. Participants
were unaware of the different conditions for the study, and no change
to the user interface was evident to the KSF participants.

5 STUDY RESULTS
Using a combination of log ﬁles, screenshots, solution sheets, sur-
veys, and interviews, we quantitatively and qualitatively evaluate
how SIF impacted the sensemaking process. Speciﬁcally, we ex-
amine (1) how well users performed, (2) how well they foraged for
relevant documents, (3) which relevant documents they discovered
and how they found them, (4) what interactions they performed, and
(5) what strategies they applied.

Each of the following subsections begins with a summary of the
research question addressed, followed by the study results and a
discussion of their signiﬁcance. We report both signiﬁcant and non-
signiﬁcant results, showing both conclusions drawn from this study
as well as directions for further investigation.

5.1 SIF+KSF Participants Averaged Higher Scores
In this subsection, we investigate how the introduction of SIF af-
fected the participant scores resulting from their exploration of the
Blue Iguanodon document collection. We found that SIF+KSF group
members exhibited signiﬁcantly higher average scores.

5.1.1 Results
Using the published scoring rules from the VAST 2007 Chal-
lenge [36], we computed a performance score for each participant.
Participant scores ranged from 1 to 17. The maximum possible
score was 58, although we did not expect participants to approach
this value given the time constraints of this study. No participants
identiﬁed any subplots outside of the plot indicated in the starting
document. The highest possible score considering only the initial
plot was 27. The scores were higher in the SIF+KSF group than in
the KSF group (SIF+KSF: µ = 8.0, σ = 5.4, min = 3, max = 17;
KSF: µ = 4.2, σ = 3.3, min = 1, max = 10). The individual scores
with their means are shown in Fig. 3.

Due to the small sample size (n = 9 for each group), we ﬁrst per-
formed two Shapiro-Wilk tests [42] for normality, to learn whether
or not the participant scores in each group were normally distributed.
The non-signiﬁcant outcomes of this test at the α = 0.05 level
(W = 0.064 for the SIF+KSF group, W = 0.229 for the KSF group)
indicated that the scores were approximately normally distributed.
Following this, we performed a t-test assuming unequal variance,
using the alternative hypothesis that the SIF+KSF scores would be

Figure 3: Score (left y-axis scale), precision, and recall (right y-axis
scale) of foraging performance by all participants. Mean group scores
are shown as blue diamonds. We found a statistically signiﬁcant
difference between conditions in score, but not in precision and recall.

higher than the KSF scores. At a signiﬁcance level of α = 0.05,
we found that the SIF+KSF group scores were signiﬁcantly higher
than the KSF group scores (t = 1.8045, d f = 13, p = 0.0471). This
process of non-signiﬁcant Shapiro-Wilk test preceding an unequal
variance t-test was used for all other inferential statistics presented
in the following subsections.

5.1.2 Discussion
The results from this section show that, on average, participants in
the SIF+KSF group understood the plot to a greater degree than
those in the KSF group. Though the p-value is near the α = 0.05
signiﬁcance threshold, this is due in part to the small sample size
of 9 participants in each group. The mean score for SIF+KSF par-
ticipants was nearly double that of the KSF participants. However,
we also note that the inclusion of SIF produced a higher variance in
scores than participants who were only afforded KSF. We suspect
that this is due in part to the variable number of semantic interactions
performed by SIF+KSF participants – both the choice and frequency
of semantic interactions used inﬂuences the set of documents that
are foraged, and thereby inﬂuences how well the participant under-
stands the plot. We discuss further explanations for the effect of the
inclusion of SIF on documents foraged in the next two subsections.

5.2 No Change to Precision and Recall between Groups
In this subsection, we investigate how the introduction of SIF af-
fected precision and recall scores for foraging performance. We
found no signiﬁcant difference in foraging precision and recall be-
tween the SIF+KSF and KSF groups.

5.2.1 Results
In evaluating the foraging performance of participants, we compute
precision, recall, and F-measure values for the relevant documents
found by each participant. These results are summarized in Table 2.
We compute precision to be the number of relevant documents found
divided by the total number of documents retrieved and recall as
the number of relevant documents found divided by the number of
relevant documents in the known solution. F-measure is computed
as 2∗ precision∗ recall/(precision + recall). In this scenario, there
were 33 documents relevant to the known solution. We used the
participant log ﬁles to identify which documents were retrieved into
the workspace in order to calculate precision, recall, and F-measure
(shown in Fig. 3).

The SIF+KSF group averaged a precision score of 0.14 (σ =
0.07), a recall score of 0.59 (σ = 0.13), and an F-measure of 0.21

Table 2: Scores, counts of documents retrieved, and precision-recall
statistics for each condition.

Score (out of 27)
Unique Relevant Docs Retrieved (out of 33)
Total Unique Docs Retrieved (out of 1486)
Precision
Recall
F-Measure

SIF+KSF

Avg.
8.0
19.3
178.0
0.14
0.59
0.21

KSF Avg.

All Avg.

4.6
18.1
145.2
0.14
0.55
0.21

6.1
18.7
161.6
0.14
0.57
0.21

(σ = 0.09). Similarly, the KSF group averaged a precision score of
0.14 (σ = 0.04), a recall score of 0.55 (σ = 0.06), and an F-measure
of 0.21 (σ = 0.05). It is noteworthy that both groups had very similar
precision, recall, and F-measure scores. This result is counter to
our initial hypothesis, which was that SIF would increase recall but
might penalize precision.

We did not observe a signiﬁcant difference between SIF+KSF
and KSF conditions in the total number of unique documents re-
trieved (t = 0.8681, d f = 12, p = 0.4024). Across conditions,
the number of unique documents retrieved ranged from 70 to
315 (µ = 162, σ = 80), which corresponds to 4.7% to 21.2% of
the entire dataset retrieved. The SIF+KSF participants retrieved
between 70 and 315 unique documents (µ = 178, σ = 102), and the
KSF condition participants retrieved between 90 and 239 documents
(µ = 145, σ = 50). Although these documents were imported into
the workspace, not all of them were read. This in and of itself is a
promising result. Participants were able to mentally ﬁlter out many
of the irrelevant documents in their synthesis phase.

5.2.2 Discussion
Because we are evaluating the inﬂuence of semantic interactions on
foraging, our computations of precision and recall used the number
of documents (and relevant documents) retrieved, rather than using a
similar measure such as number of documents opened or interacted
with. This choice allows us to measure what the system is giving the
analysts to read, rather than exploring what the analysts are focusing
on. It is certainly possible that altering these computations could
affect our non-signiﬁcant results.

Overall, it is interesting to note that the foraging results for the
SIF+KSF group consistently show a standard deviation twice that of
the KSF group. This is further evidence that SIF introduces greater
variability into the foraging process. The number of documents
retrieved from the dataset varied based on user analytical strategy.

5.3 SIF and KSF Serve Complementary Document For-

aging Roles

In this subsection, we investigate how the introduction of SIF affects
the set of relevant documents retrieved and how they were retrieved.
We found that KSF and SIF each have their own advantages towards
retrieving certain sets of documents, and that highlighting was the
primary semantic interaction used to retrieve documents.

Table 3: Quantity and percentage of relevant documents retrieved
using the various interaction methods for the two conditions.

Relevant Docs Retrieved (includes re-ﬁnds)
Total from SIF

SIF from Highlight
SIF from Annotate
SIF from Overlap

KSF from Search

SIF+KSF

22.4

5.8 (26%)
5.0 (22%)
0.2 (1%)
0.6 (3%)
16.7 (74%)

KSF
20.1

20.1 (100%)

5.3.1 Results
Document discovery results are summarized in Fig. 4. Of the
relevant documents in the collection, the “chinsurrection” docu-
ments were almost universally found by every KSF participant (one
KSF participant missed one of the documents). In contrast, some
SIF+KSF participants missed them. These documents are central to
the main plot of the investigation, which most of the participants at
least partially solved. All of these documents contain the name of
the central nefarious character, “Cesar Gil,” that most of the users
cited in their solutions. All KSF group users explicitly searched on
his name, but three of the SIF+KSF users did not, and consequently
some of those three missed a subset of these documents.

In contrast, the other relevant documents were found more often
by the SIF+KSF participants. In particular, three of these documents
were not found by any of KSF users, yet were found by 3/9 of the
SIF+KSF users. One of these documents contained supporting evi-
dence for the main plot described above, but did not identify Cesar
Gil by name. The other two documents contained information rele-
vant to a second subplot that interconnects with the main plot, about
another character named “rBear,” although none of the participants
succeeded in solving this plot. This character’s name was never
explicitly searched for by any of the participants, so it is likely this
information was retrieved through SIF, perhaps exploiting other key-
words in common between the two plots, such as “monkeypox” (a
highly weighted term in the ﬁnal states of many of the participants’
user interest models). This indicates that it was valuable to have the
SIF mechanism to expand the scope of investigation to this other
relevant but less obviously connected information, beyond keywords
on which users might not think to explicitly search.

The SIF+KSF group located some relevant documents through
their semantic interaction foraging ability, while the KSF group
used only the keyword search means. The percentages are shown
in Table 3. We examined the interaction logs of the participants in
the SIF+KSF condition to determine if they retrieved relevant docu-
ments via semantic interactions that executed SIF retrieval. Eight
out of nine SIF+KSF users retrieved new relevant documents using
SIF. Including re-ﬁnds (relevant documents that were located, re-
moved from the working set by the user, and then located again),
SIF accounted for 26% of the total number of relevant documents
retrieved by the SIF+KSF group. For individual SIF+KSF users, this
percentage ranged from 0% to 100%, demonstrating the wide variety
of user strategies. This also suggests that users succeeded in ﬁnding
useful information via SIF, information that might not have been
found through explicit KSF. By far, most of the SIF-retrieved rele-
vant documents were retrieved as a result of highlight interactions,
indicating the importance of this type of semantic interaction.

5.3.2 Discussion
From this analysis of foraging behavior, we can see beneﬁts of both
SIF and KSF. KSF is useful when speciﬁc terms of interest are
known; a keyword search for “Cesar Gil” added many of the “chin-
surrection” documents into the working set, indicating that KSF is
still valuable for foraging, especially for terms that are more obvious
targets of investigation. Simultaneously, KSF is limited when those
precise search terms are not present in other relevant documents. SIF,
in contrast, can locate documents related to the current direction of
exploration without the analyst knowing precisely what to search for,
but with the limitation that SIF may not locate all of the documents
that an analyst may be seeking. This limitation can be addressed by
more accurate learning and retrieval models in the future.

Interestingly, the SIF+KSF group earned higher analysis scores
on average, despite not ﬁnding all of the core “chinsurrection” doc-
uments. Instead, they earned higher scores by building up a more
complete plot with the supplemental documents they found through
SIF. The sensemaking process is boosted by SIF locating this broader
supplemental information, beyond the obvious core documents.

Figure 4: The difference between the number of SIF+KSF group participants and KSF group participants who found each relevant document.
Positive scores (above the horizontal axis) mean that more SIF+KSF participants found the document, while negative scores (below the horizontal
axis) mean that more KSF participants found the document. More SIF+KSF participants found a majority of the documents, but more KSF
participants found the core “chinsurrection” documents.

5.4 SIF+KSF Participants Performed More Synthesis In-

teractions

ious interactions (e.g., some preferred annotating over highlighting,
others preferred overlapping documents).

In this subsection, we investigate how the introduction of SIF af-
fected the number of semantic interactions performed by participants.
We observed signiﬁcant differences between study conditions in
terms of how much information users externalized to the workspace
via some synthesis-related actions, which may have contributed
to the potential trend of improved performance by the SIF+KSF
participants compared to the KSF participants.

5.4.1 Results
In order to track how users synthesized information, we once again
analyzed the interaction logs (Fig. 5). We identiﬁed the follow-
ing semantic interactions as being directly related to synthesis
through the externalization of the user’s thought processes: high-
lighting, annotating, and document overlapping (clustering). The
SIF+KSF condition participants performed signiﬁcantly more high-
lights (t = 2.3227, d f = 16, p = 0.0169) and signiﬁcantly more
annotations (t = 2.0809, d f = 9, p = 0.0336). There was no sig-
niﬁcant difference between the number of times that users clus-
tered documents by overlapping them (SIF+KSF µ = 15.6; KSF
µ = 11.2), nor was there a signiﬁcant difference in the number of
keyword searches performed by each group (SIF+KSF µ = 19.2;
KSF µ = 18.0). Users varied in their preferences for performing var-

Figure 5: The panels from left to right show the total number of
highlight, annotation, document overlap, and search interactions per-
formed by each participant. Means are shown as blue diamonds. The
highlight and annotation conditions are signiﬁcantly different, with the
SIF+KSF group performing more actions than the KSF group in both.
The overlap and search conditions are not signiﬁcantly different.

5.4.2 Discussion
We can infer from these results that the SIF+KSF users externalized
more of their understanding of the dataset and hypotheses about what
information was relevant. Overall, these participants provided more
feedback to the user model regarding their interests. This feedback
was not only used to retrieve documents, but also to augment the
spatialization in terms of document positioning, visual encodings,
and automatic text highlighting. This process serves to continually
give analysts visual feedback on what documents it believes will be
most relevant or interesting for the analyst to read. Therefore, the
system is more likely to indicate good documents on the display for
the user to open and read next based on their interests. Both study
conditions were provided with this relevance feedback based on
their underlying interest model, although the SIF+KSF participants
beneﬁted from this feature more than KSF participants.

Furthermore, user’s highlighting and annotating documents aids
in auto-highlighting of the text in open documents, making them
easier to skim. It also helps transform open documents into distin-
guishable visual glyphs that aids in re-ﬁnding information, making
analysts more efﬁcient in navigating the workspace and referencing
the workspace for ﬁlling out their ﬁnal solution reports [11, 46].

The signiﬁcant difference between study conditions may have
been a result of a positive-reinforcing feedback loop. As users made
highlights in documents or wrote notes, the system retrieved and
identiﬁed documents that it believed the users would be interested in.
This may have encouraged the users in the SIF+KSF condition to
continue performing these actions. Thus, synthesis-related actions
foraged for information, both on and off the screen, which led to
more data being interpreted and formulated into hypotheses. It is
interesting though that this did not seem to signiﬁcantly reduce their
use of search. This might suggest a possible design opportunity for
more clear visual connection between KSF and SIF.

5.5 Participants Exhibited a Variety of Strategies
In this subsection, we investigate the structure and layout of the
ﬁnal workspaces for both groups of participants. Overall, participant
strategies for use of the workspace mirrored previous results about
sensemaking with large display spaces [5, 7]. Users organized a
variety of spatial representations of the document collection as part
of their distributed cognitive process.

Figure 6: Final workspace of (left) user KSF #9 showing the spatial organization of documents, annotations, and search boxes that label the
space, and (right) user SIF+KSF #4 showing a large central pool of unopened documents, with opened documents arranged on the periphery.

5.5.1 Results
The ﬁnal screenshots of user workspaces shared a common artifact,
likely caused by a low relevance threshold that kept a high number
of documents on the display. Most participants’ ﬁnal workspaces
contained a central pool of unopened document nodes with docu-
ments arranged around the periphery of the display. The nodes in
the central pool represented weakly relevant information. Nodes
that were highly relevant to a speciﬁc cluster of documents were
positioned near the cluster.

Users were asked to sketch spatial representations of their ﬁnal
workspaces – how they perceived the space. Users adopted different
methods for labeling the space, even within their own drawings,
which would make automatic cluster detection and classiﬁcation
difﬁcult [21]. For example, users created speciﬁc tags for areas of
the display that directly matched extracted entities (e.g., monkeypox,
Cesar Gil), but they also tagged areas of the space with cognitively
meaningful labels (e.g., who, what, where). This behavior has been
previously observed, where users label their spatial workspaces in
fuzzy and complicated manners that would be difﬁcult to match by
another person or algorithm [13].

The number of open documents on the ﬁnal workspaces varied
greatly, from 2 to 35 (µ = 15.56, σ = 10.51). There was also sub-
stantial variance within each condition. The SIF+KSF condition
participants kept a range of 2 to 34 documents open on their ﬁnal
workspace (µ = 14.78, σ = 11.69). The KSF condition participants
ranged in keeping 3 to 35 documents open (µ = 16.33, σ = 9.84).
The lack of signiﬁcant difference implies that any trend in perfor-
mance between the conditions cannot be explained by the number
of open documents alone.

Interestingly, participants who had very few documents open on
their ﬁnal workspace still drew spatial schemas indicating where
they had opened and then minimized or closed documents. For
example, participant SIF+KSF #1 opened documents 57 times, but
only had two documents open on his ﬁnal workspace, neither of
which were relevant to the solution. In fact, participant SIF+KSF #1
did not have any relevant documents on his ﬁnal workspace, open or
closed. He preferred a neat and clutter-free workspace and deleted
documents after he had read and processed the information. For
reference, this participant retrieved 20 relevant documents and had
the second highest score. The highest scoring participant overall,
SIF+KSF #8, assumed quite the opposite strategy. She retrieved a
total of 310 documents, 28 of which were relevant. She also opened
documents 57 times, yet she kept 16 open on her ﬁnal workspace,
11 of which were relevant to the overall solution.

In the KSF condition, participants KSF #1 and KSF #2 had the
highest scores in their group. They also adopted differing strategies
in terms of keeping documents on the display. KSF #2 retrieved
117 documents, 21 of which were relevant. She had 15 documents
open on her ﬁnal workspace, 10 of which were relevant. KSF #1
retrieved 118 documents, 15 of which were relevant. He had 6 docu-

ments open on his ﬁnal workspace, but none were relevant. However,
three documents were opened and then minimized, indicating that
they were read.

5.5.2 Discussion
We found no correlation between any of these organizational strategy
metrics and user performance. This can be attributed to individual
differences in analytical strategies, such as user ability, the desire
to keep a neat workspace (or not minding having the display ﬁlled
with open and closed documents), or needing to focus on one or two
documents at a time so as not to get distracted. These preferences
were explained during the post-study surveys and semi-structured
interviews. We see that StarSPIRE supports a variety of analytical
strategies and user preferences without a particular strategy having
an adverse impact on sensemaking quality and performance. Our
results also replicate previous work that demonstrates how users
remember spatial locations of items on a large, physical workspace,
both during data analysis and after the fact when the display is
empty [5, 32].

6 DISCUSSION
We begin this section by summarizing the lessons learned from this
study, and discussing ways by which these lessons can be applied
beyond StarSPIRE and into visual analytics in general (Section 6.1).
Following this, we discuss two issues that surfaced through our ob-
servations of participants and analysis of the study data. The ﬁrst
was a sometimes overwhelming number of documents staying on
the display, which suggests a need to modify the relevance threshold
(Section 6.2). The second is the problem of cognitive tunneling,
which we noticed when no participants identiﬁed additional subplots
in the data (Section 6.3). We discuss these issues and suggest meth-
ods for alleviating the problems in future work. We also discuss
a feature that proved to be surprisingly important to the users, the
automatic text highlighting (Section 6.4). In addition, we discuss
the potential for tuning semantic interactions to individual users
(Section 6.5), and the limitations of our study (Section 6.6).

6.1 General Principles
Throughout the experimental results detailed in the previous section,
we saw that incorporating a “passive” foraging mechanism like
SIF that retrieves documents based on a learned user model can
recommend documents to analysts that they may not have found
via traditional keyword search means. The result of these document
recommendations is that analysts gain a better understanding of the
underlying plot in the document collection (evidenced by their higher
scores), and interact with the workspace more, leading to a feedback
cycle that continues to improve document recommendations with
each additional interaction. At the same time, the quality of the
documents recommended (measured by the foraging precision and
recall scores) is not reduced.

KSF and SIF represent independent, complementary mechanisms
for information retrieval, each with strengths and weaknesses. As
such, SIF should not be used by system designers as a replacement
for keyword search. Indeed, the inclusion of a search box can greatly
beneﬁt the usability of a visualization system as datasets increase in
size [1]. Rather, our ﬁndings suggest that implicit or passive search
mechanisms can be included in visualization systems to draw the
user’s attention to related objects that may not necessarily include
identical search terms.

Similarly, our ﬁndings suggest that interactions alone are sufﬁ-
cient to drive these search mechanisms, building a user model by
interpreting the interest of a user based on how they interact with
other documents. We noted previously (Section 2.4) that our learning
rules to generate a user model are relatively simple, and that more
thorough recommendation systems that follow an interaction-driven
approach could certainly outperform our ﬁndings. However, our
results show that even this simple approach can cause substantial
improvement. We additionally assert that existing visualization sys-
tems could make use of our simple approach of mapping interactions
to weight modiﬁcations, ultimately to the beneﬁt of a user.

For example, Andromeda [41] allows users to manipulate projec-
tions to learn a set of attribute weights that will best approximate the
user-provided projection. To use this mechanism, a user uses drag-
and-drop interactions to manipulate the current projection, dragging
observations to various positions in the workspace to communicate
desired similarity/dissimilarity relationships. The new weights are
not learned until the user has ﬁnished their repositioning interac-
tions and click an “Update Layout” button. With a StarSPIRE-like
approach, the system can begin to learn the user’s desired simi-
larity/dissimilarity goals while the user is still performing these
interactions. As the user moves more observations, Andromeda
could begin to recommend additional observations to reposition, and
could even recommend the positions to place the additional observa-
tions. Such suggestions could lead to better reprojection results as
the feedback from user to system is increased.

Similarly, Intent Radar [39] allows users to manipulate a pro-
jection of keywords centered about a “radar” display. Users can
reposition keywords closer to the center of the radar to indicate that
a particular keyword is more important to their interests. Using the
StarSPIRE approach, the system could learn from this sequence of
interactions, perhaps discovering documents that contain these key-
words and recommending other keywords within those documents.

6.2 Relevance Threshold
In this study, it appears that the relevance threshold may have been
set too low, causing too much irrelevant information to remain on
the display. This was observed during the pilot study, but we chose
to maintain this relevance threshold level so that the system would
not over-prune the workspace, which can be more problematic. As
a result, many users ended up with a central “pool” of data and
arranged their open documents on the perimeter.

Participants retrieved a widely varying number of documents (µ =
161.61, σ = 79.52). The number of documents removed also varied
greatly (µ = 31.50, σ = 20.34). This can be attributed to differences
in analytical strategies by the participants. During the post-study
interviews, it was revealed that some users (e.g., KSF #1) preferred
to keep a clutter-free workspace and keep as few documents open as
possible. Others (e.g., SIF+KSF #8) did not feel overwhelmed by the
excess information and preferred having a great deal of information
to pull from. These two participants earned the highest scores in
their groups. The data gathered in this study show that the variation
in clutter represented by the participants’ layouts did not correlate
with their performance; however, it is reasonable to assume that an
excessive amount of clutter would impact task performance.

In order to support these varied styles, it may be prudent to alter
the document relevance threshold to adapt to each user instead of

having static values based on interactions. The model could incre-
mentally learn from the interactions users perform and update as
needed. For example, if a user has a tendency to delete documents
from the workspace, the threshold for keeping documents should
be raised so that more are automatically pruned from the display.
An alternative to this strategy may be to begin with a more strict
threshold to only show closely-related documents. Then, once a
foraging saturation is reached, the threshold could be lowered incre-
mentally to bring in new documents. Likewise, if the system is able
to detect a large number of documents that are just under the current
relevance threshold, say related to a new subplot that has just been
encountered, the relevance threshold could be lowered to bring in
all of those new documents.

6.3 Cognitive Tunneling
While the Blue Iguanodon dataset contained multiple subplots, no
users branched out to identify any other plot aside from the main
plot mentioned in the starting document. Some participants pursued
alternative hypotheses for this subplot, but none correctly identiﬁed
adjacent subplots. Interestingly, a few participants read documents
containing information on different subplots, and one even executed
searches for relevant entities involved in a second subplot. However,
they did not include this information in their solution. Our instruc-
tions to the study participants did not indicate that there was only
a single plot within the dataset; we merely provided them with the
starting document and allowed them to begin exploring. Participants
may have implicitly assumed that they should focus on the speciﬁc
plot hinted at in the starting document, ignoring other interesting
threads that they uncovered in the data. This indicates that many of
the participants in both study conditions fell victim to a phenomenon
similar to cognitive tunneling [33] or satisfaction of search [45], in
which an analyst narrows their attention to target an initial discovery,
ignoring other possibilities.

One explanation for this issue is due to how information was
retrieved and synthesized by participants. Documents added to the
workspace were those containing terms that most closely matched
the user’s model for both study conditions. This could have led to
conﬁrmation bias and a tendency to ignore alternatives in the plot.
That said, conﬁrmation bias is a feature of participants, not retrieval
systems. For example, an analyst investigating the question “Do
chinchillas have monkeypox?” could initiate a search that returns in-
formation that both conﬁrms and refutes the question. The decision
to pursue one conclusion or the other occurs during the synthesis
process that follows the search. Indeed, results from Section 5.3
show that introducing SIF may work to alleviate the effects of con-
ﬁrmation bias, because SIF returns related documents that may not
be found through traditional keyword search. Our results show that
SIF presented participants with a broader set of documents, many
with more subtle ties to the currently investigated hypothesis.

This cognitive tunneling effect can also be attributed to each user
being provided with an explicit starting point in the analysis. While
this was intended to focus the investigation of the study participants
during a time-limited task and reducing the variation between users,
it also has the effect of limiting open-ended investigation within the
document set. The automatic and dynamic highlighting may further
inﬂuence this effect by “steering” the participants towards searching
for highlighted terms and missing potentially useful documents that
are not signiﬁcantly highlighted. Studies from the visual search
community have noted that prevalence [50] and detectability [49]
play signiﬁcant roles in target location.

One way to alleviate this problem is to introduce novel documents
to the workspace in addition to highly relevant documents. Ruotsalo
et al. achieved this by sampling from a distribution of documents
according to their relevance [39]. This allowed for closely related
documents to be shown as results, but also occasionally to show
novel documents. Again echoing the idea of detectability for visual

search, it is advantageous to visually indicate novel documents
within the spatialization to draw user focus to them. We noted that
participants tended to open large, bright documents, even if they
were in a cluster of many documents. How to integrate the notion of
veering away from the user’s model to highlight novel information
within the current multi-model semantic interaction pipeline remains
an open research challenge.

Another possibility is to provide large-scale overview spatializa-
tions of the full document collection. ForceSPIRE accomplished
this by simply displaying the entire document collection at start-up,
but therefore only worked for small document collections [20]. Star-
SPIRE abandoned that approach in order to handle larger document
collections, instead focusing on retrieval. This leads to opportunities
to integrate other types of overviews of large document collections,
such as sampling, clustering, and topic modeling [17].

6.4 Automatic Text Highlighting
According to user comments, the user-tuned automatic text high-
lighting (shown in the interface in Fig. 1) proved to be one of most
valuable features in StarSPIRE. This feature gave the users a subtle
yet salient visual representation of the underlying interest model.
The highlights had the potential to change with each interaction,
thus continuously representing the current underlying model’s state,
reﬂecting which terms the user interest model had placed the most
emphasis on. This visual feedback about the state of the model was
conveniently presented, in context, directly within the documents
and served as a form of “explainable AI”.

However, automatic highlighting proved to be much more useful
than merely giving feedback. Participants leveraged the automatic
highlighting to (1) determine which documents in a collection are
worth reading, and (2) determine which portions of a document
to focus on, particularly in longer documents. Thus, StarSPIRE
gave users feedback at multiple levels of data abstraction through
a visual metaphor that users found easy to interpret. At the graph
level (many documents), the node relevance size-encoding and text
highlighting served to guide users toward relevant documents to
read. They could quickly identify pertinent documents with a quick
glance at the highlighted terms. At the individual document level,
text highlighting directed users to portions of the document to read.
This was particularly useful to home in on speciﬁc paragraphs in
long documents, and to identify where multiple reports contain
similar information that the user has already read before, allowing
them to skip over that content. Further, no users complained about
the system recommending improper documents. The incremental
dynamics of the working set, layout, and visual encodings did not
appear to frustrate them. These features appeared to help direct the
user’s attention, but further research is necessary to measure any
increased analyst efﬁciency produced by auto-highlighting.

6.5 Tuning Semantic Interactions
Participants employed vastly different strategies in conducting their
analysis. For example, foraging performance was similar across the
participants, but how they went about foraging varied greatly. It is
not unreasonable to assume that users had different preferences in
terms of what interactions they performed. Currently, interactions
are interpreted the same way for all users. We may be able to tune
the impact of the interactions to better approximate the preferences
of each individual user, perhaps using machine learning methods to
tune the parameters of the semantic interactions.

For example, if a user repeatedly closes documents that were
retrieved as a result of highlighting sentences in a document, the
system could reduce the impact that highlighting has on extracted
entities. In this manner, we can attempt to avoid over-assuming the
intent of users. Instead, we can begin with a baseline interpretation
of interactions and incrementally tune these interpretations through
a meta-level semantic interaction learning process.

6.6 Limitations
Three noteworthy limitations to this study include the small number
of participants, the single document set used, and the short task time
duration. First, it is possible that we could have discovered stronger
signiﬁcance levels and more signiﬁcant results with additional par-
ticipants, reducing some of the variance in the participant scores
and behaviors. Additionally, using only the Blue Iguanodon set of
documents in this study limits the generalizability of our ﬁndings.
This is due to the large amount of noise in the document set (since
many documents are irrelevant to the main plot), as well as the short
average length of these documents. It is certainly possible that these
ﬁndings could differ with a collection of longer documents. Finally,
while supporting longer-term sensemaking sessions is certainly a
goal of this work, the current study focuses on short two hour ses-
sions. It would be interesting to see the value of SIF functionality in
multi-day scenarios.

An additional consideration in the study design is that, while the
KSF group did not have the advantage of SIF, they did have other
advantages associated with semantic interaction and the user interest
model, such as automatic highlighting, relevance-based node sizing,
etc. Most KSF-only systems would likely not include these features.
Thus, the actual difference between the experimental condition and
the control condition in this study was perhaps smaller than it would
be in a realistic setting. The results found in this study might actually
be ampliﬁed when comparing SIF to traditional KSF approaches.

7 CONCLUSIONS AND FUTURE WORK
We conducted a comparative user study with StarSPIRE to examine
the impact of SIF on the sensemaking process. The study showed
that foraging performance was similar between conditions. However,
the group afforded with SIF functionality performed signiﬁcantly
more synthesis-related semantic interactions. They externalized
more information (a process associated with synthesis) and injected
more feedback into the underlying user interest model. The system
was then able to forage and identify a broader set of relevant infor-
mation in the spatial workspace. This led to improved sensemaking
task performance, for foraging large textual information and syn-
thesizing a coherent and complete hypothesis narrative, as scored
against a known ground-truth solution. Participants in the SIF+KSF
condition retrieved 26% of their total relevant documents through
SIF on average. Executing traditional keyword searches retrieved
the remaining 74% of relevant documents. SIF and KSF proved to
be effective complementary retrieval techniques.

Based on this user study, participants were able to solve a portion
of the given sensemaking task while retrieving and reading only a
small portion of the overall dataset. However, there was not a clear
superior analytical strategy, which demonstrates that StarSPIRE
supports multiple avenues for sensemaking. We also identiﬁed
potential improvements for StarSPIRE and its underlying layout
and relevance models that inform the design of future semantic
interaction systems. The automatic text highlighting and node size
relevance encoding, both features enabled by semantic interactions
that learn a user interest model, were especially appreciated by users.
We intend to implement the identiﬁed changes, including altering
the relevance model to include novel documents in addition to the
documents that most closely match the current user interest model.
After these proposed changes are made, we plan to conduct a longi-
tudinal study to observe long-term usage of StarSPIRE on real-world
data. Example tasks include conducting an in-depth literature review
and learning about a current event in the news.

ACKNOWLEDGMENTS
This research was supported by NSF Grants IIS-1218346 and IIS-
1447416. The authors would like to recognize the role of comments
from reviewers and discussions with InfoVis Lab @ VT research
group members in improving this work.

REFERENCES

[1] J. Abello, F. V. Ham, and N. Krishnan. Ask-graphview: A large scale
graph visualization system. IEEE Transactions on Visualization and
Computer Graphics, 12(5):669–676, Sept 2006. doi: 10.1109/TVCG.
2006.120

[2] J.-w. Ahn and P. Brusilovsky. Adaptive visualization for exploratory
Information Processing & Management,

information retrieval.
49(5):1139–1164, 2013. doi: 10.1016/j.ipm.2013.01.007

[3] J.-w. Ahn, P. Brusilovsky, D. He, J. Grady, and Q. Li. Personalized web
exploration with task models. In Proceedings of the 17th International
Conference on World Wide Web, WWW ’08, pp. 1–10. ACM, New
York, NY, USA, 2008. doi: 10.1145/1367497.1367499

[4] J. Alsakran, Y. Chen, Y. Zhao, J. Yang, and D. Luo. Streamit: Dynamic
visualization and interactive exploration of text streams. In 2011 IEEE
Paciﬁc Visualization Symposium, pp. 131–138, March 2011. doi: 10.
1109/PACIFICVIS.2011.5742382

[5] C. Andrews, A. Endert, and C. North. Space to think: Large high-
resolution displays for sensemaking. In Proceedings of the SIGCHI
Conference on Human Factors in Computing Systems, CHI ’10, pp.
55–64. ACM, New York, NY, USA, 2010. doi: 10.1145/1753326.
1753336

[6] C. Andrews and C. North. Analyst’s workspace: An embodied sense-
making environment for large, high-resolution displays. In 2012 IEEE
Conference on Visual Analytics Science and Technology (VAST), pp.
123–131, Oct 2012. doi: 10.1109/VAST.2012.6400559

[7] C. Andrews and C. North. The impact of physical navigation on spatial
organization for sensemaking. IEEE Transactions on Visualization
and Computer Graphics, 19(12):2207–2216, Dec 2013. doi: 10.1109/
TVCG.2013.205

[8] M. Q. W. Baldonado and T. Winograd. Sensemaker: An information-
exploration interface supporting the contextual evolution of a user’s
interests. In Proceedings of the ACM SIGCHI Conference on Human
Factors in Computing Systems, CHI ’97, pp. 11–18. ACM, New York,
NY, USA, 1997. doi: 10.1145/258549.258563

[9] B. Baldwin and B. Carpenter. Lingpipe. Available from World Wide

Web: http://alias-i.com/lingpipe, 2003.

[10] E. A. Bier, S. K. Card, and J. W. Bodnar. Entity-based collaboration
tools for intelligence analysis. In 2008 IEEE Symposium on Visual
Analytics Science and Technology, pp. 99–106, Oct 2008. doi: 10.
1109/VAST.2008.4677362

[11] L. Bradel, A. Endert, K. Koch, C. Andrews, and C. North. Large high
resolution displays for co-located collaborative sensemaking: Display
usage and territoriality. International Journal of Human-Computer
Studies, 71(11):1078–1088, 2013. doi: 10.1016/j.ijhcs.2013.07.004

[12] L. Bradel, C. North, L. House, and S. Leman. Multi-model semantic
In 2014 IEEE Conference on Visual
interaction for text analytics.
Analytics Science and Technology (VAST), pp. 163–172, Oct 2014. doi:
10.1109/VAST.2014.7042492

[13] L. Bradel, J. Z. Self, A. Endert, M. S. Hossain, C. North, and N. Ra-
makrishnan. How analysts cognitively “connect the dots”. In 2013
IEEE International Conference on Intelligence and Security Informat-
ics, pp. 24–26, June 2013. doi: 10.1109/ISI.2013.6578780

[14] E. T. Brown, J. Liu, C. E. Brodley, and R. Chang. Dis-function:
Learning distance functions interactively. In 2012 IEEE Conference on
Visual Analytics Science and Technology (VAST), pp. 83–92, Oct 2012.
doi: 10.1109/VAST.2012.6400486

[15] P. Brusilovski, A. Kobsa, and W. Nejdl. The adaptive web: methods
and strategies of web personalization. Springer Science & Business
Media, 2007.

[16] G. Chin, Jr., O. A. Kuchar, and K. E. Wolf. Exploring the analytical
In Proceedings of the SIGCHI
processes of intelligence analysts.
Conference on Human Factors in Computing Systems, CHI ’09, pp.
11–20. ACM, New York, NY, USA, 2009. doi: 10.1145/1518701.
1518704

[17] A. Endert, L. Bradel, and C. North. Beyond control panels: Direct
manipulation for visual analytics. IEEE Computer Graphics and Ap-
plications, 33(4):6–13, July 2013. doi: 10.1109/MCG.2013.53

[18] A. Endert, L. Bradel, J. Zeitz, C. Andrews, and C. North. Designing
large high-resolution display workspaces. In Proceedings of the Inter-

national Working Conference on Advanced Visual Interfaces, AVI ’12,
pp. 58–65. ACM, New York, NY, USA, 2012. doi: 10.1145/2254556.
2254570

[19] A. Endert, R. Burtner, N. Cramer, R. Perko, S. Hampton, and K. Cook.
Typograph: Multiscale spatial exploration of text documents. In 2013
IEEE International Conference on Big Data, pp. 17–24, Oct 2013. doi:
10.1109/BigData.2013.6691709

[20] A. Endert, P. Fiaux, and C. North. Semantic interaction for sensemak-
ing: Inferring analytical reasoning for model steering. IEEE Trans-
actions on Visualization and Computer Graphics, 18(12):2879–2888,
Dec 2012. doi: 10.1109/TVCG.2012.260

[21] A. Endert, S. Fox, D. Maiti, S. Leman, and C. North. The semantics of
clustering: Analysis of user-generated spatializations of text documents.
In Proceedings of the International Working Conference on Advanced
Visual Interfaces, AVI ’12, pp. 555–562. ACM, New York, NY, USA,
2012. doi: 10.1145/2254556.2254660

[22] A. Endert, C. Han, D. Maiti, L. House, S. Leman, and C. North.
Observation-level interaction with statistical models for visual ana-
In 2011 IEEE Conference on Visual Analytics Science and
lytics.
Technology (VAST), pp. 121–130, Oct 2011. doi: 10.1109/VAST.2011.
6102449

[23] P. Fiaux, M. Sun, L. Bradel, C. North, N. Ramakrishnan, and A. Endert.
Bixplorer: Visual analytics with biclusters. Computer, 46(8):90–94,
August 2013. doi: 10.1109/MC.2013.269

[24] A. Ghias, J. Logan, D. Chamberlin, and B. C. Smith. Query by hum-
In Pro-
ming: Musical information retrieval in an audio database.
ceedings of the Third ACM International Conference on Multimedia,
MULTIMEDIA ’95, pp. 231–236. ACM, New York, NY, USA, 1995.
doi: 10.1145/217279.215273

[25] C. Gormley and Z. Tong. Elasticsearch: The Deﬁnitive Guide. O’Reilly

Media, Inc., 1st ed., 2015.

[26] T. M. Green, W. Ribarsky, and B. Fisher. Building and applying a
human cognition model for visual analytics. Information Visualization,
8(1):1–13, 2009. doi: 10.1057/ivs.2008.28

[27] A. Gupta and R. Jain. Visual information retrieval. Commun. ACM,

40(5):70–79, May 1997. doi: 10.1145/253769.253798

[28] M. A. Hearst. Tilebars: Visualization of term distribution information
in full text information access. In Proceedings of the SIGCHI Confer-
ence on Human Factors in Computing Systems, CHI ’95, pp. 59–66.
ACM Press/Addison-Wesley Publishing Co., New York, NY, USA,
1995. doi: 10.1145/223904.223912

[29] J. Heer and D. Boyd. Vizster: visualizing online social networks. In
IEEE Symposium on Information Visualization, pp. 32–39, Oct 2005.
doi: 10.1109/INFVIS.2005.1532126

[30] Y. Kang, C. Gorg, and J. Stasko. How can visual analytics assist
investigative analysis? design implications from an evaluation. IEEE
Transactions on Visualization and Computer Graphics, 17(5):570–583,
May 2011. doi: 10.1109/TVCG.2010.84

[31] X. Lin, D. Soergel, and G. Marchionini. A self-organizing semantic
In Proceedings of the 14th Annual
map for information retrieval.
International ACM SIGIR Conference on Research and Development
in Information Retrieval, SIGIR ’91, pp. 262–269. ACM, New York,
NY, USA, 1991. doi: 10.1145/122860.122887

[32] K. Logan. Spatial History: Using Spatial Memory to Recall Informa-

tion. PhD thesis, Virginia Tech, 2012.

[33] A. Mack and I. Rock. Inattentional blindness, vol. 33. MIT press

Cambridge, MA, 1998.

[34] K. A. Olsen, R. R. Korfhage, K. M. Sochats, M. B. Spring, and J. G.
Williams. Visualization of a document collection: The vibe system.
Information Processing & Management, 29(1):69–81, 1993. doi: 10.
1016/0306-4573(93)90024-8

[35] P. Pirolli and S. Card. The sensemaking process and leverage points
for analyst technology as identiﬁed through cognitive task analysis. In
Proceedings of international conference on intelligence analysis, vol. 5,
2005.

[36] C. Plaisant, G. Grinstein, J. Scholtz, M. Whiting, T. O’Connell,
S. Laskowski, L. Chien, A. Tat, W. Wright, C. Grg, Z. Liu, N. Parekh,
K. Singhal, and J. Stasko. Evaluating visual analytics at the 2007
vast symposium contest. IEEE Computer Graphics and Applications,
28(2):12–21, March 2008. doi: 10.1109/MCG.2008.27

[37] PNNL. In-spire visual document analysis, 2010.
[38] F. Ricci, L. Rokach, and B. Shapira. Introduction to recommender
In Recommender systems handbook, pp. 1–35.

systems handbook.
Springer, 2011.

[39] T. Ruotsalo, J. Peltonen, M. Eugster, D. Głowacka, K. Konyushkova,
K. Athukorala, I. Kosunen, A. Reijonen, P. Myllym¨aki, G. Jacucci,
and S. Kaski. Directing exploratory search with interactive intent
modeling. In Proceedings of the 22nd ACM International Conference
on Information & Knowledge Management, CIKM ’13, pp. 1759–1764.
ACM, New York, NY, USA, 2013. doi: 10.1145/2505515.2505644

[40] D. P. Russ Burtner, Shawn Bohn. Interactive visual comparison of
multimedia data through type-speciﬁc views, 2013. doi: 10.1117/12.
2004735

[41] J. Z. Self, R. Vinayagam, J. T. Fry, and C. North. Bridging the gap
between user intention and model parameters for data analytics. In SIG-
MOD 2016 Workshop on Human-In-the-Loop Data Analytics (HILDA
2016), p. 6, June 2016.

[42] S. S. Shapiro and M. B. Wilk. An analysis of variance test for normality

(complete samples). Biometrika, 52(3/4):591–611, 1965.

[43] F. M. Shipman and C. C. Marshall. Formality considered harmful:
Experiences, emerging themes, and directions on the use of formal rep-
resentations in interactive systems. Computer Supported Cooperative
Work (CSCW), 8(4):333–352, 1999. doi: 10.1023/A:1008716330212
[44] J. Teevan, S. T. Dumais, and E. Horvitz. Personalizing search via
automated analysis of interests and activities. In Proceedings of the
28th Annual International ACM SIGIR Conference on Research and
Development in Information Retrieval, SIGIR ’05, pp. 449–456. ACM,
New York, NY, USA, 2005. doi: 10.1145/1076034.1076111

[45] A. M. Treisman and G. Gelade. A feature-integration theory of atten-
tion. Cognitive Psychology, 12(1):97 – 136, 1980. doi: 10.1016/0010
-0285(80)90005-5

[46] K. Vogt, L. Bradel, C. Andrews, C. North, A. Endert, and D. Hutchings.
Co-located Collaborative Sensemaking on a Large High-Resolution
Display with Multiple Input Devices, pp. 589–604. Springer Berlin
Heidelberg, Berlin, Heidelberg, 2011. doi: 10.1007/978-3-642-23771
-3 44

[47] J. Wenskovitch and C. North. Observation-level interaction with clus-
In Proceedings of the
tering and dimension reduction algorithms.
2nd Workshop on Human-In-the-Loop Data Analytics, HILDA’17, pp.
14:1–14:6. ACM, New York, NY, USA, 2017. doi: 10.1145/3077257.
3077259

[48] J. A. Wise, J. J. Thomas, K. Pennock, D. Lantrip, M. Pottier, A. Schur,
and V. Crow. Visualizing the non-visual: spatial analysis and interaction
with information from text documents. In Proceedings of Visualization
1995 Conference, pp. 51–58, Oct 1995. doi: 10.1109/INFVIS.1995.
528686

[49] J. M. Wolfe and T. S. Horowitz. Five factors that guide attention in

visual search. Nature Human Behaviour, 1(3):0058, 2017.

[50] J. M. Wolfe and M. J. V. Wert. Varying target prevalence reveals
two dissociable decision criteria in visual search. Current Biology,
20(2):121 – 124, 2010. doi: 10.1016/j.cub.2009.11.066

[51] P. C. Wong, E. G. Hetzler, C. Posse, M. A. Whiting, S. Havre,
N. Cramer, A. R. Shah, M. Singhal, A. Turner, and J. Thomas. In-spire
infovis 2004 contest entry. In INFOVIS, vol. 4, pp. 51–52, 2004.

[52] W. Wright, D. Schroh, P. Proulx, A. Skaburskis, and B. Cort. The
sandbox for analysis: Concepts and methods. In Proceedings of the
SIGCHI Conference on Human Factors in Computing Systems, CHI
’06, pp. 801–810. ACM, New York, NY, USA, 2006. doi: 10.1145/
1124772.1124890

[53] J. S. Yi, R. Melton, J. Stasko, and J. A. Jacko. Dust & magnet: Multi-
variate information visualization using a magnet metaphor. Information
Visualization, 4(4):239–256, 2005. doi: 10.1057/palgrave.ivs.9500099

","{""0"":{""0"":""participants*"",""1"":""participant"",""2"":""conference"",""3"":""proceedings*""},""1"":{""0"":""starspire*"",""1"":""\ufb01nal*"",""2"":""ieee"",""3"":""signi\ufb01cant""},""2"":{""0"":""relevance*"",""1"":""precision*"",""2"":""clutter*"",""3"":""bias*""},""3"":{""0"":""vast*"",""1"":""automatic"",""2"":""international"",""3"":""higher""},""4"":{""0"":""number*"",""1"":""scores"",""2"":""threshold*"",""3"":""score*""},""5"":{""0"":""retrieved*"",""1"":""open"",""2"":""recall"",""3"":""displayed*""},""6"":{""0"":""visualization"",""1"":""analytics*"",""2"":""computer*"",""3"":""computing*""},""7"":{""0"":""model"",""1"":""interactions*"",""2"":""systems"",""3"":""conditions*""},""pos"":{""0"":1,""1"":2,""2"":3,""3"":4}}",2018,{},False,False,journalArticle,False,LBDAM34S,[],self.user,"{""C"":{""0"":16.9875217506,""1"":7.1451543549,""10"":6.6366257561,""11"":7.4453979328,""12"":8.8879059776,""13"":9.1034000164,""14"":9.8134101783,""15"":17.3396527338,""16"":8.0941509905,""17"":5.8504231457,""18"":13.3313930917,""19"":5.7707883783,""2"":28.9940517197,""20"":7.3274725848,""21"":9.4203435338,""22"":11.4798970635,""23"":12.0629689361,""24"":7.3959792362,""25"":6.3960451807,""26"":6.4354734863,""27"":8.4368630574,""28"":8.0329964393,""29"":10.6304932163,""3"":12.302561314,""30"":23.8867083616,""31"":18.5814458093,""32"":14.7290531238,""33"":7.6069847552,""34"":15.2771935531,""35"":7.6694325623,""36"":6.27055156,""37"":20.6232543054,""38"":7.047925716,""39"":17.0861363405,""4"":6.4328183042,""40"":5.8809968088,""41"":7.5464519195,""42"":6.2220439263,""43"":7.008198428,""44"":15.7290586377,""45"":4.6906851905,""46"":14.1184372869,""47"":6.3665823674,""48"":5.176114872,""49"":6.1730654472,""5"":5.5844577069,""50"":7.6698164349,""51"":12.6247152038,""52"":7.3940072544,""53"":6.4781703792,""54"":5.1451962852,""55"":4.8661938107,""56"":5.3071603265,""57"":5.1213009427,""58"":4.9082990129,""59"":6.1828665904,""6"":5.8125237982,""60"":5.0292468452,""61"":5.8686297479,""62"":7.3751803307,""63"":7.0307414804,""64"":6.5309617165,""65"":7.9207876655,""66"":8.5238755636,""67"":4.6888100866,""68"":8.3345388287,""69"":4.6524575694,""7"":7.2993758381,""70"":5.0626697649,""71"":6.1893245256,""72"":5.1661885883,""73"":5.1416672383,""74"":5.7670323239,""75"":6.4807762237,""76"":4.7993016318,""77"":4.762950461,""78"":4.9743100728,""79"":5.0280963374,""8"":13.0983490157,""80"":4.7191055717,""81"":4.5969532638,""82"":5.8857239179,""83"":4.5662170161,""84"":4.5723645015,""85"":4.6488158555,""86"":4.5722516666,""87"":4.5603134989,""88"":4.6222473971,""89"":4.622220721,""9"":6.0517623844},""Unnamed: 0"":{""0"":0,""1"":1,""10"":12,""11"":13,""12"":14,""13"":15,""14"":16,""15"":17,""16"":18,""17"":19,""18"":20,""19"":21,""2"":2,""20"":22,""21"":23,""22"":24,""23"":25,""24"":26,""25"":28,""26"":29,""27"":30,""28"":31,""29"":32,""3"":3,""30"":33,""31"":34,""32"":35,""33"":36,""34"":37,""35"":38,""36"":40,""37"":41,""38"":42,""39"":43,""4"":4,""40"":44,""41"":45,""42"":46,""43"":47,""44"":48,""45"":49,""46"":50,""47"":51,""48"":52,""49"":53,""5"":5,""50"":54,""51"":55,""52"":56,""53"":57,""54"":58,""55"":60,""56"":61,""57"":63,""58"":64,""59"":65,""6"":6,""60"":66,""61"":67,""62"":68,""63"":69,""64"":70,""65"":71,""66"":72,""67"":73,""68"":74,""69"":75,""7"":7,""70"":76,""71"":77,""72"":79,""73"":82,""74"":83,""75"":84,""76"":85,""77"":86,""78"":87,""79"":88,""8"":8,""80"":90,""81"":91,""82"":92,""83"":93,""84"":94,""85"":95,""86"":96,""87"":97,""88"":98,""89"":99,""9"":9},""count"":{""0"":412,""1"":198,""10"":94,""11"":90,""12"":90,""13"":84,""14"":74,""15"":74,""16"":68,""17"":68,""18"":66,""19"":60,""2"":182,""20"":54,""21"":54,""22"":50,""23"":46,""24"":46,""25"":42,""26"":40,""27"":40,""28"":40,""29"":38,""3"":154,""30"":38,""31"":36,""32"":34,""33"":34,""34"":34,""35"":34,""36"":30,""37"":30,""38"":28,""39"":28,""4"":122,""40"":26,""41"":26,""42"":26,""43"":26,""44"":26,""45"":24,""46"":22,""47"":20,""48"":20,""49"":20,""5"":120,""50"":20,""51"":20,""52"":18,""53"":16,""54"":16,""55"":14,""56"":14,""57"":12,""58"":12,""59"":12,""6"":116,""60"":12,""61"":12,""62"":12,""63"":12,""64"":12,""65"":12,""66"":10,""67"":10,""68"":10,""69"":10,""7"":110,""70"":10,""71"":10,""72"":10,""73"":8,""74"":8,""75"":8,""76"":8,""77"":8,""78"":8,""79"":8,""8"":104,""80"":8,""81"":8,""82"":8,""83"":6,""84"":6,""85"":6,""86"":6,""87"":6,""88"":6,""89"":6,""9"":104},""exemplar"":{""0"":null,""1"":null,""10"":null,""11"":null,""12"":null,""13"":null,""14"":null,""15"":null,""16"":""*"",""17"":null,""18"":""*"",""19"":null,""2"":""*"",""20"":""*"",""21"":null,""22"":null,""23"":null,""24"":null,""25"":null,""26"":null,""27"":""*"",""28"":""*"",""29"":null,""3"":null,""30"":null,""31"":""*"",""32"":null,""33"":null,""34"":""*"",""35"":""*"",""36"":""*"",""37"":null,""38"":null,""39"":""*"",""4"":null,""40"":""*"",""41"":null,""42"":null,""43"":""*"",""44"":null,""45"":null,""46"":""*"",""47"":""*"",""48"":null,""49"":null,""5"":null,""50"":null,""51"":null,""52"":null,""53"":""*"",""54"":null,""55"":""*"",""56"":null,""57"":""*"",""58"":null,""59"":""*"",""6"":null,""60"":""*"",""61"":null,""62"":""*"",""63"":null,""64"":""*"",""65"":null,""66"":null,""67"":null,""68"":""*"",""69"":null,""7"":null,""70"":null,""71"":null,""72"":null,""73"":""*"",""74"":null,""75"":null,""76"":null,""77"":""*"",""78"":null,""79"":null,""8"":""*"",""80"":null,""81"":""*"",""82"":null,""83"":null,""84"":""*"",""85"":null,""86"":null,""87"":""*"",""88"":""*"",""89"":""*"",""9"":""*""},""pos"":{""0"":1,""1"":2,""10"":7,""11"":8,""12"":9,""13"":10,""14"":11,""15"":12,""16"":1,""17"":13,""18"":1,""19"":14,""2"":1,""20"":1,""21"":2,""22"":3,""23"":1,""24"":2,""25"":2,""26"":15,""27"":2,""28"":3,""29"":3,""3"":1,""30"":3,""31"":2,""32"":16,""33"":17,""34"":2,""35"":4,""36"":1,""37"":3,""38"":4,""39"":4,""4"":3,""40"":3,""41"":18,""42"":19,""43"":4,""44"":5,""45"":2,""46"":6,""47"":5,""48"":20,""49"":6,""5"":4,""50"":7,""51"":3,""52"":4,""53"":7,""54"":21,""55"":4,""56"":22,""57"":4,""58"":23,""59"":5,""6"":5,""60"":5,""61"":6,""62"":5,""63"":8,""64"":5,""65"":6,""66"":24,""67"":9,""68"":6,""69"":7,""7"":6,""70"":10,""71"":25,""72"":11,""73"":8,""74"":26,""75"":27,""76"":9,""77"":3,""78"":28,""79"":6,""8"":1,""80"":12,""81"":5,""82"":6,""83"":8,""84"":7,""85"":10,""86"":7,""87"":7,""88"":8,""89"":4,""9"":2},""sigma_nor"":{""0"":1.8206547111,""1"":1.4859948898,""10"":1.6330374596,""11"":1.7259286295,""12"":1.8697672131,""13"":1.9188401621,""14"":2.0485008791,""15"":2.8679710368,""16"":1.8932257582,""17"":1.6395941914,""18"":2.5045486948,""19"":1.664523608,""2"":3.0762434405,""20"":1.8885067339,""21"":2.1500714423,""22"":2.4532907363,""23"":2.5819548694,""24"":1.9575718008,""25"":1.8539072559,""26"":1.8758574042,""27"":2.1596210539,""28"":2.1023595056,""29"":2.5007081537,""3"":1.9473453256,""30"":4.420051327,""31"":3.7094061132,""32"":3.1874888812,""33"":2.1090300872,""34"":3.2704910143,""35"":2.1184862428,""36"":1.949101702,""37"":4.2322597438,""38"":2.0996627358,""39"":3.7395585598,""4"":1.545713146,""40"":1.9325954458,""41"":2.2124325532,""42"":1.9898996855,""43"":2.1219928295,""44"":3.5873101948,""45"":1.7519938182,""46"":3.4575039601,""47"":2.1053220677,""48"":1.8852851146,""49"":2.0695538728,""5"":1.4756584417,""50"":2.346201936,""51"":3.2620277208,""52"":2.3381824537,""53"":2.2028076363,""54"":1.9371575098,""55"":1.9116254006,""56"":2.0032972381,""57"":1.9992584142,""58"":1.9528988819,""59"":2.2303064941,""6"":1.5031960091,""60"":1.9792229858,""61"":2.1619133436,""62"":2.4898116891,""63"":2.4148451195,""64"":2.3060688464,""65"":2.6085622604,""66"":2.8139429549,""67"":1.9364602392,""68"":2.7706217357,""69"":1.9281425962,""7"":1.6505704065,""70"":2.0220012575,""71"":2.2797856643,""72"":2.0456868969,""73"":2.0755194959,""74"":2.2266027574,""75"":2.3990376418,""76"":1.9928066716,""77"":1.984024516,""78"":2.0350873276,""79"":2.0480816639,""8"":2.2084862707,""80"":1.9734319373,""81"":1.9439209053,""82"":2.2552777083,""83"":1.9549220483,""84"":1.9564961495,""85"":1.9760719858,""86"":1.9564672575,""87"":1.9534104167,""88"":1.9692689697,""89"":1.9692621391,""9"":1.5506652955},""topic"":{""0"":-1,""1"":-1,""10"":-1,""11"":-1,""12"":-1,""13"":-1,""14"":-1,""15"":-1,""16"":2,""17"":-1,""18"":5,""19"":-1,""2"":0,""20"":4,""21"":4,""22"":7,""23"":6,""24"":5,""25"":0,""26"":-1,""27"":6,""28"":4,""29"":5,""3"":7,""30"":0,""31"":2,""32"":-1,""33"":-1,""34"":1,""35"":7,""36"":3,""37"":1,""38"":1,""39"":0,""4"":-1,""40"":6,""41"":-1,""42"":-1,""43"":4,""44"":1,""45"":3,""46"":1,""47"":4,""48"":-1,""49"":4,""5"":-1,""50"":4,""51"":3,""52"":3,""53"":1,""54"":-1,""55"":6,""56"":-1,""57"":5,""58"":-1,""59"":5,""6"":-1,""60"":3,""61"":5,""62"":6,""63"":1,""64"":7,""65"":6,""66"":-1,""67"":1,""68"":3,""69"":5,""7"":-1,""70"":1,""71"":-1,""72"":1,""73"":5,""74"":-1,""75"":-1,""76"":5,""77"":2,""78"":-1,""79"":7,""8"":1,""80"":1,""81"":0,""82"":0,""83"":4,""84"":0,""85"":5,""86"":7,""87"":3,""88"":7,""89"":2,""9"":7},""vector"":{""0"":""[-1.309895    4.348868   -5.413371    4.1473236   1.3671559  -2.5102408\n  4.411912    2.958645    3.825941   -0.03663104]"",""1"":""[-0.7278421   4.1455827  -5.464498    4.497583    1.9660257  -2.7829726\n  4.5507245   3.439431    4.278826   -0.53218526]"",""10"":""[-1.5106456   4.2771673  -5.948957    4.2322764   1.7045827  -2.9937294\n  4.100269    2.1977096   4.2418237  -0.24385627]"",""11"":""[-1.6285418   4.2006497  -5.9251895   4.3628016   1.3585624  -2.7341135\n  3.9317753   2.1186888   4.168484   -0.04351956]"",""12"":""[-1.5924107   4.135008   -6.063591    4.7121344   1.4258779  -2.9414167\n  3.6715112   2.3537729   4.4298124  -0.20060317]"",""13"":""[-0.25661957  4.238561   -6.2621465   4.0601964   1.4502195  -2.0843136\n  3.812235    3.3223917   3.7274427  -0.7591693 ]"",""14"":""[-1.1745414e+00  4.4752755e+00 -5.4695811e+00  3.8650346e+00\n  1.5635782e+00 -2.5550559e+00  4.5387726e+00  2.6533456e+00\n  3.6805842e+00  3.0906033e-03]"",""15"":""[-1.086087    4.0441008  -5.59908     5.2947836   1.3929452  -2.56127\n  4.024025    2.8720558   4.564464   -0.02123775]"",""16"":""[-0.8884558  4.3429375 -6.2768917  4.428778   0.9022206 -2.1506963\n  3.6431432  2.8868384  3.566476  -0.2962431]"",""17"":""[-1.3424865   4.280995   -5.753459    4.3438478   1.4409707  -2.7666426\n  4.3611674   2.3039486   3.9173613  -0.04714036]"",""18"":""[-0.8758376   3.803016   -6.663435    4.1484056   0.8283901  -1.4085819\n  2.3111403   1.9711591   4.1949043   0.08717814]"",""19"":""[-1.1113735   4.519424   -6.1961884   4.486688    0.9961996  -2.3409762\n  3.705762    2.886313    3.628716   -0.22426115]"",""2"":""[-1.2814128  4.3182764 -5.2880983  5.088623   1.6023971 -2.980692\n  4.6245003  3.193361   4.234172  -0.1444522]"",""20"":""[-0.81487083  3.725381   -6.0142508   5.0666504   1.0475706  -2.0963616\n  3.6156464   2.3466344   4.4958997   0.04769326]"",""21"":""[-0.89181167  3.879019   -6.047367    4.8633404   1.028642   -2.4809878\n  4.1008744   2.061415    3.932328   -0.0300137 ]"",""22"":""[-0.73675114  4.467297   -5.52953     3.9268327   1.9667366  -2.572117\n  4.5828347   3.0496604   3.8994238  -0.33749515]"",""23"":""[-0.16626239  4.271681   -6.0026784   4.0466313   1.7419828  -2.309873\n  4.2716317   3.4999342   3.8014808  -0.85168266]"",""24"":""[-1.0002006   3.8455238  -6.4623585   4.0182424   1.0703565  -1.831177\n  2.468241    2.4142735   4.0670323  -0.11494056]"",""25"":""[-1.2757556   4.2351985  -5.3901653   5.243103    1.4228482  -2.8810973\n  4.349798    3.1562612   4.2841096  -0.08178275]"",""26"":""[-1.2619509   4.1404486  -5.8486886   5.088254    1.322574   -2.563226\n  3.777335    2.5383554   4.5436354   0.01821359]"",""27"":""[-0.4047583  4.306139  -5.8340073  4.0072055  1.8394154 -2.453345\n  4.4093385  3.5003288  3.8579571 -0.8067148]"",""28"":""[-0.9665648   3.7816334  -6.1327734   5.032552    0.77160144 -2.2059536\n  3.450992    2.484655    4.002286   -0.02020977]"",""29"":""[-1.0306253  3.7997794 -6.496354   4.452475   0.8226474 -1.8124357\n  2.7382545  1.9926856  4.1980343  0.0237646]"",""3"":""[-0.59552926  4.3788924  -5.5306807   4.010085    2.1003087  -2.8237252\n  4.5021396   2.569384    4.0667057  -0.08903527]"",""30"":""[-1.6227157   4.19956    -5.2836933   5.244851    1.3376449  -3.129297\n  4.3388243   3.6037998   4.257413   -0.30061233]"",""31"":""[-0.5871586   4.104269   -6.4595566   4.450612    1.0219823  -2.0841854\n  3.7347467   2.5186417   3.874155   -0.41570982]"",""32"":""[-1.0283105   4.4082465  -5.981135    3.5009482   1.798725   -2.2779956\n  3.4061148   2.8520389   3.8118002  -0.23342912]"",""33"":""[-2.4703892e-03  4.2661548e+00 -5.7791920e+00  4.3305044e+00\n  2.0319245e+00 -2.7265203e+00  4.4226360e+00  2.4131930e+00\n  4.0601034e+00 -3.6984757e-02]"",""34"":""[-1.6394796   3.5701716  -6.4265194   4.324438    1.5903617  -3.181171\n  3.3709939   2.7355618   4.577357   -0.85172534]"",""35"":""[-1.174021    4.488503   -5.502402    4.003719    1.7308294  -2.6834958\n  4.6336446   2.5567272   3.7783322  -0.04409397]"",""36"":""[-0.8032572  4.3699236 -6.297094   3.6091533  1.3973366 -1.8763005\n  2.9636307  3.0739663  3.6410425 -0.3292311]"",""37"":""[-1.3087201  3.548269  -5.8352895  4.6763115  1.7556162 -3.2774758\n  3.9504285  3.7858264  4.619563  -1.0812632]"",""38"":""[-1.6462562   3.7109575  -6.434528    4.2103567   1.6202174  -3.046604\n  3.2713268   2.7794983   4.4711833  -0.83631104]"",""39"":""[-1.626687    4.357773   -5.3036547   5.1038094   1.3172398  -3.1000242\n  4.4178915   3.4216645   4.06687    -0.18504012]"",""4"":""[-0.924354    4.3540387  -5.3578405   4.4419465   1.9065163  -2.7770312\n  4.757285    3.2014792   4.1189585  -0.32623613]"",""40"":""[-0.38006407  4.266478   -5.7126026   4.002236    1.842907   -2.240622\n  4.19146     3.4850485   4.119442   -0.5624346 ]"",""41"":""[-0.43539044  4.3786554  -6.059266    3.7635012   1.6900523  -2.0601325\n  3.6722999   3.4068465   3.8180585  -0.5749691 ]"",""42"":""[-0.6618572   4.030143   -6.1529403   4.5677795   1.1512693  -2.1866739\n  4.162393    2.1849704   4.1134586  -0.12450677]"",""43"":""[-0.839337    3.7890315  -6.241572    4.9124055   0.93540376 -2.3961508\n  3.794586    2.0609548   4.0280714  -0.09300267]"",""44"":""[-1.0369631  3.6198883 -5.7838144  4.3471417  1.9431719 -3.0453749\n  4.0165744  3.8124466  4.5465074 -1.0172788]"",""45"":""[-0.4840045  4.1866045 -6.463666   3.8994877  1.2485323 -1.8025494\n  3.1621914  2.9805753  3.7074976 -0.5301618]"",""46"":""[-1.6034582   3.4448655  -6.258754    4.5994697   1.565552   -3.3798845\n  3.661545    3.0510454   4.604415   -0.88942283]"",""47"":""[-1.0120937   3.7240262  -5.8442335   5.0621843   0.8813955  -2.359254\n  3.6836596   2.4388385   4.0384703   0.12753324]"",""48"":""[-0.70903236  3.918619   -5.6428905   4.4208436   1.905633   -2.7731483\n  4.280553    3.6413765   4.35959    -0.79406804]"",""49"":""[-0.6402132   3.9814563  -6.1588364   4.6225696   1.0970546  -2.0746496\n  3.9641116   2.3112545   4.196883   -0.09714448]"",""5"":""[-1.5063822  4.067198  -5.6273174  4.472691   1.1638151 -2.4427397\n  3.6587029  2.5451167  4.208978   0.196308 ]"",""50"":""[-0.9139516   3.8348694  -6.448899    4.6419168   0.97331953 -2.183679\n  3.392254    2.078557    4.2289605  -0.17433825]"",""51"":""[-0.6376843   4.38488    -6.1686926   3.8694344   1.4754282  -2.0125325\n  3.413729    3.3413732   3.7654095  -0.48144513]"",""52"":""[-0.8665585   4.1849065  -6.3245497   3.590706    1.4595237  -1.8879105\n  2.8272302   2.8056338   3.7774246  -0.30093172]"",""53"":""[-1.6062472  3.4547036 -6.2874794  4.4708586  1.6906587 -3.359065\n  3.5615716  3.1029422  4.680824  -1.016641 ]"",""54"":""[-1.361391    4.0124273  -5.8873377   4.4320765   1.2306349  -2.3176818\n  3.3478549   2.2475429   4.295706    0.21659371]"",""55"":""[-0.43244922  4.1635747  -5.7349563   4.079647    1.828491   -2.3702087\n  4.2813272   3.5965338   4.1347575  -0.76589835]"",""56"":""[-1.3867259   4.323714   -5.7084956   4.9472456   1.1718694  -2.864541\n  4.006092    3.1559799   3.879088   -0.17907724]"",""57"":""[-9.1649705e-01  3.7455020e+00 -6.6088996e+00  4.1767750e+00\n  7.6609886e-01 -1.5246736e+00  2.1557775e+00  2.0324492e+00\n  4.1129689e+00  1.6159799e-03]"",""58"":""[-1.1836655   4.0100946  -5.7117057   4.9732447   1.0298756  -2.5888655\n  3.6370742   3.0428889   3.8648071  -0.01612872]"",""59"":""[-1.0906787  3.6126804 -6.553259   4.192457   0.8861551 -1.6212195\n  2.2169435  2.0639791  4.2164273 -0.0079569]"",""6"":""[-1.1600051  4.4992657 -5.722263   4.2552867  1.240325  -2.4813266\n  4.1688094  3.075824   3.6277993 -0.1629815]"",""60"":""[-0.7734232   4.405775   -6.186391    3.5280259   1.5438024  -1.9232148\n  3.0984786   3.033312    3.6455903  -0.30018944]"",""61"":""[-1.1424104e+00  3.7324023e+00 -6.3885093e+00  4.3748646e+00\n  9.8380506e-01 -1.9883150e+00  2.6702120e+00  2.1606965e+00\n  4.2886024e+00 -2.5714107e-03]"",""62"":""[-0.14694706  4.243466   -5.841827    4.0666347   1.7635915  -2.23367\n  4.2390738   3.389756    3.9441016  -0.6071151 ]"",""63"":""[-1.107373   3.5474436 -5.9080925  4.538031   1.907213  -3.1940606\n  4.055422   3.6323223  4.5917864 -1.0770192]"",""64"":""[-1.0684241   4.588868   -5.602196    4.070354    1.8521279  -2.608698\n  4.6894507   2.655723    3.778774   -0.17580537]"",""65"":""[-0.5621464  4.446794  -5.7296934  3.9258854  1.8151389 -2.4197176\n  4.3485847  3.3308997  3.8104594 -0.5310005]"",""66"":""[-0.8525632   3.883155   -5.8614254   4.4879246   1.3444605  -2.1932948\n  3.8493645   2.5530772   4.4755363  -0.05792315]"",""67"":""[-1.2898118  3.4222116 -6.048882   4.565461   1.6783857 -3.087332\n  3.5945399  3.411163   4.6881895 -0.99458  ]"",""68"":""[-0.71396965  4.3574266  -6.303954    3.7379644   1.293224   -1.8091474\n  3.0284653   3.0472693   3.6044548  -0.32530993]"",""69"":""[-1.0627304   3.8076057  -6.528888    4.120003    0.9988424  -1.5934942\n  2.3872335   2.1693158   4.0894814  -0.09823895]"",""7"":""[-1.0443151   4.3568997  -6.2589407   4.0446944   1.0478657  -1.9464014\n  3.055974    2.972202    3.613518   -0.18718275]"",""70"":""[-1.7256348  3.8021076 -6.2781086  4.391187   1.6394215 -3.1678612\n  3.4769707  2.7272348  4.533225  -0.7587983]"",""71"":""[-0.04570939  4.321128   -5.784909    4.2873387   2.0848286  -2.7496662\n  4.4136953   2.458683    4.0331473  -0.06860164]"",""72"":""[-1.5183896   3.7204607  -5.7278857   4.8402996   1.6379085  -3.4131527\n  4.105373    3.777111    4.512339   -0.94634414]"",""73"":""[-1.0365031   3.6791425  -6.597645    4.325083    0.7617203  -1.5173156\n  2.2967794   1.9519812   4.166373    0.00831608]"",""74"":""[-1.075682   4.2809505 -5.372904   4.699014   1.8295596 -2.9116955\n  4.751581   3.1093006  4.221016  -0.2975229]"",""75"":""[-1.4659889   4.1297226  -5.938755    4.7497854   1.367282   -2.7750704\n  3.786072    2.3597193   4.4234915  -0.04778951]"",""76"":""[-1.1431559   3.8157022  -6.2866654   4.497451    0.9450956  -1.9833689\n  2.853358    2.0876386   4.2425814   0.12321028]"",""77"":""[-0.67261946  4.2684236  -6.223048    4.550759    1.0856184  -2.2771266\n  3.8640962   3.1230998   3.693063   -0.5060617 ]"",""78"":""[-0.7610116  3.6672606 -6.139403   4.846717   0.9526159 -1.7979809\n  3.2281468  2.1949716  4.3923197  0.1307314]"",""79"":""[-0.60916454  4.448663   -5.607227    3.9622016   1.9551151  -2.4628553\n  4.442145    2.6631536   3.864735   -0.12695546]"",""8"":""[-1.6099032  3.5930815 -6.21671    4.3814883  1.7826574 -3.2461472\n  3.4638996  2.9946287  4.7570095 -1.0612851]"",""80"":""[-1.4152695  3.6308029 -5.9163175  4.577359   1.7336    -3.3529034\n  3.9532447  3.6670382  4.5569096 -1.0650301]"",""81"":""[-1.582658    4.1608176  -5.470568    5.1498604   1.4009092  -3.1836936\n  4.2621484   3.40216     4.2598276  -0.34295496]"",""82"":""[-1.4894438  3.8541186 -5.6354456  4.881897   1.5815736 -3.2818573\n  4.133846   3.654507   4.4150376 -0.778203 ]"",""83"":""[-1.166831    3.7775106  -5.8964934   4.967463    0.97656465 -2.2958455\n  3.4531176   2.402317    4.2818255   0.14507185]"",""84"":""[-1.5605488   4.2482653  -5.326242    5.267348    1.3086506  -3.0152776\n  4.3026495   3.3153336   4.244914   -0.11890919]"",""85"":""[-1.0070204   3.5674808  -6.5535665   4.3965025   0.8609921  -1.4101949\n  2.466292    1.9690095   4.2843795   0.05257241]"",""86"":""[-0.12174783  4.320618   -5.7541037   4.204255    2.0743806  -2.6607082\n  4.3727374   2.5506737   4.0291233  -0.12326684]"",""87"":""[-0.72627574  4.462846   -6.08045     3.6186335   1.5724481  -1.970923\n  3.335806    3.0748742   3.6312501  -0.29130054]"",""88"":""[-1.1976048   4.410885   -5.7284656   4.251727    1.7642382  -2.9302194\n  4.3024073   2.3495605   4.020724   -0.04884413]"",""89"":""[-1.062261    4.4768515  -6.1649175   4.5403476   1.0446484  -2.4361358\n  3.9391875   2.7322767   3.6571646  -0.22348094]"",""9"":""[-1.0692036  4.4903784 -5.602832   4.22969    1.9794827 -3.0057065\n  4.548061   2.528503   4.040675  -0.1391755]""},""vocab_index"":{""0"":0,""1"":1,""10"":13,""11"":15,""12"":16,""13"":17,""14"":19,""15"":20,""16"":21,""17"":22,""18"":24,""19"":27,""2"":2,""20"":31,""21"":32,""22"":36,""23"":39,""24"":41,""25"":45,""26"":46,""27"":47,""28"":50,""29"":53,""3"":3,""30"":54,""31"":55,""32"":56,""33"":58,""34"":59,""35"":60,""36"":66,""37"":69,""38"":72,""39"":73,""4"":4,""40"":74,""41"":76,""42"":80,""43"":83,""44"":84,""45"":88,""46"":93,""47"":101,""48"":102,""49"":103,""5"":5,""50"":105,""51"":106,""52"":117,""53"":120,""54"":132,""55"":142,""56"":163,""57"":172,""58"":192,""59"":195,""6"":6,""60"":197,""61"":199,""62"":200,""63"":201,""64"":202,""65"":203,""66"":217,""67"":219,""68"":264,""69"":267,""7"":7,""70"":271,""71"":272,""72"":274,""73"":331,""74"":333,""75"":338,""76"":352,""77"":355,""78"":356,""79"":360,""8"":9,""80"":362,""81"":364,""82"":366,""83"":429,""84"":468,""85"":495,""86"":496,""87"":505,""88"":520,""89"":522,""9"":10},""word"":{""0"":""documents"",""1"":""user"",""10"":""foraging"",""11"":""search"",""12"":""study"",""13"":""visual"",""14"":""terms"",""15"":""group"",""16"":""relevance"",""17"":""results"",""18"":""retrieved"",""19"":""interest"",""2"":""participants"",""20"":""number"",""21"":""scores"",""22"":""systems"",""23"":""visualization"",""24"":""open"",""25"":""participant"",""26"":""task"",""27"":""analytics"",""28"":""threshold"",""29"":""recall"",""3"":""model"",""30"":""conference"",""31"":""precision"",""32"":""north"",""33"":""plot"",""34"":""\ufb01nal"",""35"":""conditions"",""36"":""vast"",""37"":""ieee"",""38"":""signi\ufb01cant"",""39"":""proceedings"",""4"":""users"",""40"":""computer"",""41"":""human"",""42"":""weights"",""43"":""score"",""44"":""york"",""45"":""automatic"",""46"":""endert"",""47"":""table"",""48"":""node"",""49"":""weight"",""5"":""document"",""50"":""measure"",""51"":""international"",""52"":""higher"",""53"":""bradel"",""54"":""recommendation"",""55"":""computing"",""56"":""discussion"",""57"":""displayed"",""58"":""subsection"",""59"":""opened"",""6"":""information"",""60"":""central"",""61"":""begin"",""62"":""graphics"",""63"":""andrews"",""64"":""factors"",""65"":""technology"",""66"":""mail"",""67"":""re\ufb02ect"",""68"":""unique"",""69"":""preferred"",""7"":""relevant"",""70"":""\ufb01ndings"",""71"":""novel"",""72"":""sigchi"",""73"":""referred"",""74"":""students"",""75"":""survey"",""76"":""suggest"",""77"":""clutter"",""78"":""having"",""79"":""features"",""8"":""starspire"",""80"":""tvcg"",""81"":""symposium"",""82"":""sigir"",""83"":""list"",""84"":""session"",""85"":""missed"",""86"":""character"",""87"":""core"",""88"":""observations"",""89"":""bias"",""9"":""interactions""},""word*"":{""0"":""documents"",""1"":""user"",""10"":""foraging"",""11"":""search"",""12"":""study"",""13"":""visual"",""14"":""terms"",""15"":""group"",""16"":""relevance*"",""17"":""results"",""18"":""retrieved*"",""19"":""interest"",""2"":""participants*"",""20"":""number*"",""21"":""scores"",""22"":""systems"",""23"":""visualization"",""24"":""open"",""25"":""participant"",""26"":""task"",""27"":""analytics*"",""28"":""threshold*"",""29"":""recall"",""3"":""model"",""30"":""conference"",""31"":""precision*"",""32"":""north"",""33"":""plot"",""34"":""\ufb01nal*"",""35"":""conditions*"",""36"":""vast*"",""37"":""ieee"",""38"":""signi\ufb01cant"",""39"":""proceedings*"",""4"":""users"",""40"":""computer*"",""41"":""human"",""42"":""weights"",""43"":""score*"",""44"":""york"",""45"":""automatic"",""46"":""endert*"",""47"":""table*"",""48"":""node"",""49"":""weight"",""5"":""document"",""50"":""measure"",""51"":""international"",""52"":""higher"",""53"":""bradel*"",""54"":""recommendation"",""55"":""computing*"",""56"":""discussion"",""57"":""displayed*"",""58"":""subsection"",""59"":""opened*"",""6"":""information"",""60"":""central*"",""61"":""begin"",""62"":""graphics*"",""63"":""andrews"",""64"":""factors*"",""65"":""technology"",""66"":""mail"",""67"":""re\ufb02ect"",""68"":""unique*"",""69"":""preferred"",""7"":""relevant"",""70"":""\ufb01ndings"",""71"":""novel"",""72"":""sigchi"",""73"":""referred*"",""74"":""students"",""75"":""survey"",""76"":""suggest"",""77"":""clutter*"",""78"":""having"",""79"":""features"",""8"":""starspire*"",""80"":""tvcg"",""81"":""symposium*"",""82"":""sigir"",""83"":""list"",""84"":""session*"",""85"":""missed"",""86"":""character"",""87"":""core*"",""88"":""observations*"",""89"":""bias*"",""9"":""interactions*""},""x2D"":{""0"":-1.0294072628,""1"":-1.7874666452,""10"":-1.9500879049,""11"":-2.1143620014,""12"":-2.4240443707,""13"":-0.2169820964,""14"":-0.9960210323,""15"":-2.9685118198,""16"":-0.966131568,""17"":-1.6090447903,""18"":-3.1752843857,""19"":-1.0757193565,""2"":-3.1005072594,""20"":-2.6457107067,""21"":-1.8090398312,""22"":-1.3445928097,""23"":-0.8428298831,""24"":-3.0538144112,""25"":-3.1510403156,""26"":-2.8309698105,""27"":-0.8985799551,""28"":-2.3504037857,""29"":-2.8719201088,""3"":-1.2336579561,""30"":-3.5014760494,""31"":-1.3439434767,""32"":0.696410358,""33"":-0.9751917124,""34"":-5.4156336784,""35"":-1.2763274908,""36"":0.7222905159,""37"":-4.6473722458,""38"":-5.5308551788,""39"":-3.533135891,""4"":-1.700835228,""40"":-1.1191227436,""41"":0.0698652714,""42"":-1.6696954966,""43"":-1.9843372107,""44"":-4.2832970619,""45"":0.3459615409,""46"":-5.2789964676,""47"":-2.4006402493,""48"":-1.787361145,""49"":-1.8143955469,""5"":-2.5666246414,""50"":-2.2415959835,""51"":0.4300802946,""52"":0.9482858181,""53"":-5.3385591507,""54"":-2.6518335342,""55"":-1.0298435688,""56"":-3.0898544788,""57"":-3.3542022705,""58"":-2.1825675964,""59"":-3.5471038818,""6"":-1.024638176,""60"":0.7802447081,""61"":-3.0855162144,""62"":-0.8058369756,""63"":-4.4986867905,""64"":-1.136330843,""65"":-0.9623266459,""66"":-2.2133877277,""67"":-4.9089813232,""68"":0.8251232505,""69"":-3.3246991634,""7"":0.9114606977,""70"":-5.543513298,""71"":-0.8582052588,""72"":-4.679330349,""73"":-3.258554697,""74"":-2.1593677998,""75"":-2.4836790562,""76"":-2.808773756,""77"":-0.9336951375,""78"":-2.4929189682,""79"":-1.1359910965,""8"":-5.2335329056,""80"":-4.5924630165,""81"":-3.5961790085,""82"":-4.3321657181,""83"":-2.4998576641,""84"":-3.2900257111,""85"":-3.1927556992,""86"":-0.7864643335,""87"":0.6332725883,""88"":-1.5938934088,""89"":-1.2795329094,""9"":-1.5194325447},""y2D"":{""0"":5.0302343369,""1"":7.1562533379,""10"":4.7576627731,""11"":4.5213727951,""12"":4.325729847,""13"":8.3223781586,""14"":5.3031287193,""15"":4.3573384285,""16"":3.4819130898,""17"":4.9200205803,""18"":0.1865860373,""19"":3.8011767864,""2"":5.9841713905,""20"":2.7573888302,""21"":2.9187049866,""22"":6.1756253242,""23"":8.0380086899,""24"":0.699396193,""25"":5.5806722641,""26"":3.9712944031,""27"":7.797393322,""28"":2.5604193211,""29"":0.8824446201,""3"":6.0295100212,""30"":5.7295470238,""31"":3.0614356995,""32"":8.7230157852,""33"":6.4738020897,""34"":7.3541722298,""35"":5.5545969009,""36"":9.1326751709,""37"":7.350883007,""38"":7.1497945786,""39"":5.8879108429,""4"":6.5757575035,""40"":7.5617384911,""41"":8.5366315842,""42"":2.8192949295,""43"":2.5209443569,""44"":7.2399072647,""45"":8.965265274,""46"":7.5147547722,""47"":2.9233379364,""48"":7.4942293167,""49"":2.9063823223,""5"":3.6809492111,""50"":2.2526619434,""51"":8.8311510086,""52"":9.0164747238,""53"":7.5238733292,""54"":3.5208666325,""55"":7.7242822647,""56"":5.2150073051,""57"":0.3376468122,""58"":3.9554924965,""59"":0.6296694875,""6"":4.5322852135,""60"":8.9435777664,""61"":1.0362977982,""62"":7.7720623016,""63"":7.2066116333,""64"":5.6762661934,""65"":7.4312009811,""66"":3.1992068291,""67"":7.6818823814,""68"":9.1206998825,""69"":0.5441117287,""7"":9.1483774185,""70"":7.1790437698,""71"":6.3743929863,""72"":7.2998418808,""73"":0.3585163951,""74"":6.4387779236,""75"":4.094689846,""76"":1.2217921019,""77"":3.5246272087,""78"":2.2492747307,""79"":6.0408053398,""8"":7.3618917465,""80"":7.1139998436,""81"":5.8559474945,""82"":6.8077263832,""83"":3.0466525555,""84"":5.6430683136,""85"":0.4446195066,""86"":6.2468552589,""87"":8.8038721085,""88"":5.1142597198,""89"":3.5541849136,""9"":5.5471591949}}",False,False,False,,,The Effect of Semantic Interaction on Foraging in Text Analysis,"[-1.45751894e-01  1.33678719e-01 -3.43836755e-01 -1.53601632e-01
  5.48392773e-01  1.21827699e-01 -8.08329955e-02  2.11945176e-02
 -4.27286714e-01 -1.53181374e-01  2.63685733e-01 -4.01421301e-02
  2.57708192e-01 -6.53267950e-02 -1.32939160e-01  1.06138849e+00
 -1.07163996e-01 -1.07014440e-01 -3.04498702e-01 -1.62472874e-01
 -1.60116740e-02  1.28787398e-01  9.59094465e-02  5.80900013e-01
  2.95155019e-01 -9.93279368e-02  4.04280573e-02  2.69357383e-01
 -2.24033281e-01  3.26367348e-01  1.77799523e-01  5.66411495e-01
  2.40717754e-02 -2.69560397e-01  1.08536951e-01  1.71760142e-01
 -1.06098115e-01 -1.50262147e-01 -7.56618530e-02  6.79539621e-01
 -6.34221554e-01 -3.37381005e-01 -1.09766997e-01 -7.90370628e-02
  8.49591717e-02 -9.89233032e-02 -1.07811555e-01 -7.21351132e-02
  1.74521998e-01 -4.46858644e-01 -1.23230040e+00 -2.28294551e-01
  1.97116703e-01 -4.44077939e-01 -1.63508847e-01  6.40188575e-01
 -1.10448211e-01 -5.08806527e-01  2.90041983e-01 -1.13015920e-01
 -1.05747096e-01  1.11195020e-01 -2.33547911e-01  1.60470270e-02
  2.62907386e-01 -3.69167328e-01  3.29788476e-01  3.25976729e-01
 -5.27910769e-01 -3.60553488e-02 -2.41800711e-01  8.30552503e-02
 -4.09130245e-01  2.73011893e-01 -6.19251013e-01  1.57310918e-01
 -1.69886664e-01  3.17565054e-01 -1.11765660e-01 -1.77089989e-01
 -1.90362304e-01  1.49005324e-01  2.20252171e-01 -6.62041456e-02
  3.85028422e-01  7.55401552e-01  1.83723316e-01  4.34548229e-01
 -2.52598792e-01 -6.04946762e-02 -3.73781383e-01 -1.32609561e-01
 -4.30788994e-01  5.48978567e-01  5.79936206e-01 -1.46839157e-01
 -4.13273364e-01  1.35385683e-02 -2.00299799e-01  1.85602710e-01
  3.08153242e-01 -7.24241853e-01  1.80125460e-01  1.46365317e-03
 -8.15169588e-02 -2.84324259e-01  1.51007678e-02 -3.18561792e-01
 -9.41788778e-02  3.14899571e-02 -9.75939631e-02  1.85336947e-01
  1.74758866e-01 -5.67240238e-01 -2.02472940e-01  8.38100687e-02
 -2.89710611e-02  2.97114193e-01 -1.81340761e-02  1.26023814e-01
 -3.34996641e-01  2.81069934e-01 -3.72040160e-02  5.03645957e-01
 -7.91489333e-02 -1.61209777e-01 -3.05509120e-01  4.22316231e-02
  1.57036424e-01  1.46075949e-01  5.08746088e-01  7.62039721e-02
  6.57361895e-02 -4.34161462e-02 -3.72444868e-01  6.63127005e-01
 -1.39522878e-02  3.05610418e-01 -2.43697017e-01  2.64361322e-01
 -6.84831440e-01 -3.03717107e-01  3.84779334e-01 -8.07224289e-02
  3.59985709e-01 -1.35444537e-01  5.66594303e-04  3.33802402e-01
  1.96737498e-02  2.94125587e-01 -3.81469607e-01  2.38080412e-01
 -6.23150826e-01 -4.95333448e-02  2.67252065e-02  2.77342677e-01
 -1.97469726e-01  3.97871166e-01 -2.46120647e-01  1.03451788e-01
  1.30631204e-03 -1.94920525e-01  2.27163602e-02 -8.05447772e-02
  5.96487559e-02 -2.18183801e-01 -2.29532167e-01  5.18860638e-01
 -2.04796523e-01 -2.79664218e-01  3.12639534e-01 -2.54729688e-01
  4.79452670e-01 -9.17288885e-02  4.95100021e-02  1.54494748e-01
 -2.08226264e-01 -7.08536655e-02  2.01797232e-01  1.05902135e+00
 -3.99340600e-01 -1.64882123e-01 -1.14621058e-01 -3.73990029e-01
  4.59099501e-01 -9.54474788e-03  2.06298262e-01 -2.88595021e-01
  1.60360754e-01 -2.37927228e-01 -4.16207351e-02 -2.03538641e-01
 -4.79083836e-01 -3.97198528e-01  2.31199682e-01 -2.32832417e-01
 -1.55444771e-01  1.03045091e-01 -6.81083426e-02 -2.09218085e-01
 -3.14701170e-01 -2.82118350e-01  9.44180861e-02  9.51108932e-02
  1.33554963e-02  7.26704821e-02 -3.05317730e-01 -3.14637214e-01
 -1.01937735e+00  1.90272897e-01 -3.24921757e-01  5.07910252e-01
 -2.65999883e-01  4.17858690e-01  1.73333108e-01  1.03424303e-01
  1.57149106e-01  1.29981533e-01  3.69200796e-01  1.67480588e-01
  1.85232684e-01 -1.83650628e-01  6.60665780e-02  3.12704802e-01
  1.43650264e-01  1.54234731e+00  5.85880518e-01 -1.96196675e-01
  1.90433145e-01  2.79750168e-01  1.81574911e-01 -1.08453237e-01
  7.20603168e-01 -5.11273324e-01 -1.80201195e-02 -7.94481635e-02
 -3.82036209e-01  5.59640452e-02  2.05525249e-01 -2.66087532e-01
 -1.37450352e-01  3.92878979e-01  1.54810712e-01  2.79693007e-01
 -2.69418895e-01 -1.52870677e-02  3.58918011e-01 -7.39458352e-02
 -3.30866396e-01  1.41739905e-01 -1.79055125e-01  3.52161020e-01
 -3.57341319e-01 -1.92931712e-01 -1.10609904e-01  2.48672608e-02
 -5.02718389e-02 -3.19475025e-01 -2.02426434e-01  2.18110278e-01
  6.97560966e-01  2.07763419e-01 -1.44388646e-01 -5.84957078e-02
  9.32349861e-02 -4.84404325e-01 -4.68815267e-02 -3.07991743e-01
  6.76698148e-01  4.93047565e-01  1.17983580e-01 -6.21147275e-01
  8.71916860e-02  5.77437282e-01 -3.75996172e-01 -3.61753345e-01
  1.59814835e-01 -5.56466639e-01 -2.39390627e-01 -1.17652714e-01
  2.40163375e-02  5.24234056e-01 -2.72020791e-02 -2.38098949e-02
 -4.37496483e-01 -6.29292011e-01 -1.27064779e-01  2.78094769e-01
  2.21332029e-01 -6.48008108e-01 -1.19771965e-01  5.44329584e-01
 -2.12709710e-01 -4.04421508e-01  4.86099899e-01  6.21360123e-01
  1.66374460e-01 -1.46538883e-01 -3.23407948e-01 -4.33129162e-01
 -3.71388733e-01  1.90526783e-01  3.69272649e-01 -5.56661412e-02
  2.26822391e-01 -8.97944570e-02 -2.82780886e-01 -4.03957590e-02
 -9.43304729e+00 -1.70209602e-01  9.30009261e-02 -1.20974682e-01
  2.05404647e-02  5.53151928e-02  1.62696064e-01  1.35588050e-01
 -3.09666902e-01 -1.41741812e-01 -2.47317582e-01 -1.50972353e-02
 -3.91428441e-01  5.99689662e-01  1.21218689e-01 -4.18758899e-01
  2.78596550e-01 -5.25106370e-01 -2.98199743e-01  6.59032524e-01
 -4.33899015e-01 -3.37840497e-01 -1.93942025e-01  3.37534994e-02
 -1.91081330e-01 -1.27959654e-01 -4.49434102e-01  1.78848118e-01
 -3.19433123e-01 -6.42567515e-01 -2.15867713e-01 -3.18534940e-01
 -8.61646086e-02  8.00901473e-01 -3.10967356e-01 -4.29538041e-02
 -2.58711576e-01 -1.86706349e-01  2.80790210e-01  3.17622781e-01
 -9.63774770e-02 -2.94217557e-01 -1.65805057e-01 -3.04037601e-01
  9.16146159e-01  6.18775934e-02  2.75199622e-01  2.08182320e-01
 -3.42984021e-01 -2.89219826e-01  1.20993145e-01  1.92146860e-02
  4.44463462e-01 -1.76781580e-01  3.08489203e-01 -3.03362310e-01
  5.74056864e-01  7.36582696e-01  2.31206968e-01 -5.37018836e-01
  2.99342245e-01 -3.64253491e-01 -2.83087879e-01  1.34504303e-01
 -5.26672043e-02  6.23280033e-02 -1.06482577e+00 -6.74090981e-01
  1.95552006e-01 -1.24773093e-01 -2.58437663e-01  2.06951767e-01
 -3.22585702e-02 -1.22151363e+00 -5.87863147e-01 -7.05228031e-01
  2.92767268e-02 -3.35391432e-01 -1.35594279e-01  1.51622921e-01
 -5.38379073e-01 -4.40418899e-01 -2.49878485e-02 -2.82627851e-01
 -2.94790477e-01 -9.86252055e-02 -7.98220187e-02 -1.13842510e-01
 -8.49979222e-01 -1.86727941e-01 -7.04650655e-02  2.54408747e-01
  1.92221105e-01  3.56590688e-01  1.79922640e-01  2.37039208e-01
  5.61646283e-01  1.76694661e-01  1.73800856e-01 -6.53109625e-02
  6.94861561e-02 -2.48344272e-01  7.55057633e-02 -2.78097510e-01
  8.43034908e-02  4.18247312e-01 -4.50554937e-01  5.24132401e-02
  2.07892090e-01  9.59229171e-02 -2.26411521e-01  2.90879190e-01
  2.18209103e-02 -2.48133793e-01 -7.27459341e-02  2.31637090e-01
 -2.71023005e-01  2.37610161e-01 -2.72300690e-01 -2.07405344e-01
 -3.21396053e-01 -1.00318333e-02 -1.83076724e-01 -2.05186188e-01
  4.68506008e-01 -1.83673337e-01 -4.17041928e-02  1.52035281e-01
 -2.39216894e-01 -1.93473607e-01 -1.42517895e-01 -3.13188791e-01
 -5.51954135e-02  4.50346947e-01  1.42453536e-01  4.00223061e-02
 -7.47643635e-02 -3.72092247e-01 -8.01471770e-01  1.14629313e-01
  2.48531416e-01 -1.24212923e-02  3.59098047e-01 -1.81895927e-01
 -1.72620472e-02 -2.81590819e-01 -1.66600242e-01  2.06919134e-01
 -5.84098548e-02  1.62747368e-01 -4.40802932e-01 -4.78737563e-01
  1.85095981e-01  1.33646190e-01  8.57410192e-01 -1.03259332e-01
  4.53786999e-01 -2.89963663e-01  1.35713756e-01 -4.45405781e-01
  2.44600102e-01  1.46087538e-02 -1.14900418e-01  9.86341015e-02
 -4.01392281e-01  9.81288031e-02 -2.93259323e-01  1.68657348e-01
  9.47715268e-02 -4.21568066e-01 -3.58915776e-01 -1.36691749e-01
 -2.28451099e-03 -1.04265818e-02 -2.34132513e-01  1.45030171e-01
  4.22383487e-01 -8.89873058e-02 -6.62071943e-01  6.47565067e-01
  2.73462534e-01  1.29166007e-01 -7.86740184e-02 -2.44166851e-02
  2.39705503e-01  2.60299772e-01  4.43424821e-01  5.27954586e-02
  1.61278456e-01  1.41880482e-01 -5.75534344e-01  1.40173614e-01
  3.82393390e-01 -3.20449114e-01 -2.70287395e-01 -1.96517006e-01
  2.34718516e-01 -5.41029394e-01 -1.60335049e-01  1.07516319e-01
  2.17412543e-02 -4.27645296e-01 -1.02300927e-01  7.31301680e-02
 -2.05463290e-01 -2.67321467e-01 -1.43423006e-01  4.82164659e-02
 -5.53882957e-01 -3.07663858e-01 -5.30360699e-01 -1.36467502e-01
  5.69564663e-02 -3.16581786e-01  2.11059481e-01 -1.81073040e-01
 -5.30631244e-01 -6.60428166e-01 -8.55390012e-01  5.28638065e-01
 -4.40110207e-01  9.43637267e-02  1.65244907e-01  1.81737095e-01
 -1.15229271e-01 -3.13416362e-01  1.00408114e-01 -3.74472514e-02
 -2.31013849e-01 -7.38217831e-02  3.59524712e-02 -1.86517775e+00
  2.62294468e-02  4.09064174e-01 -1.33659795e-01 -5.94220281e-01
 -5.56045890e-01  2.30211854e-01 -7.41421059e-02 -2.12011293e-01
  3.87865901e-01 -1.93354934e-02 -1.71567261e-01 -2.36671031e-01
  1.45588279e-01 -2.97412485e-01  1.14921406e-01 -1.72321886e-01
 -1.14382125e-01 -1.20591067e-01  9.81952250e-02  2.48987507e-02
 -2.10411716e-02 -3.03622782e-01  3.99909586e-01 -2.61955410e-01
 -2.45186210e-01 -5.04520714e-01 -2.03876629e-01  1.44232973e-01
 -5.03450334e-01 -1.86189696e-01 -4.80918646e-01  1.77648529e-01
 -3.70335877e-01 -1.95822656e-01  2.60314047e-01  3.25328000e-02
 -1.97166968e-02 -3.09808344e-01 -1.12654893e-02 -6.09024227e-01
 -9.49430168e-02  5.77761412e-01 -3.09017271e-01 -2.12647796e-01
  1.70940191e-01  9.13780034e-02  3.41862291e-01 -5.27097464e-01
  9.83604342e-02 -2.35960901e-01  2.71695226e-01  1.42563164e-01
  3.34425747e-01 -5.52738547e-01 -1.79551512e-01  5.02900854e-02
  1.69887189e-02 -1.29468381e-01  2.91566551e-01  6.40322268e-02
 -4.16970670e-01 -2.44858012e-01 -3.19216490e-01  4.59729284e-01
  5.00930727e-01  3.08787733e-01  7.46754706e-02  3.15164864e-01
 -5.89181073e-02  3.95069979e-02  3.60438496e-01  1.51237205e-01
  4.65882480e-01 -4.49662358e-01 -2.07593992e-01 -4.48165745e-01
 -2.61059940e-01 -3.77133965e-01 -1.78888664e-01  3.27827372e-02
  5.02603710e-01  3.07091951e-01  9.94928926e-02 -5.48310317e-02
 -8.78666490e-02  7.48065561e-02  3.26161087e-01  1.24866828e-01
 -5.35362184e-01  3.17903638e-01  6.96156561e-01 -1.99252173e-01
  5.98731413e-02  5.21425962e-01 -1.39984665e-02 -1.52035564e-01
  6.20855577e-02  3.10261607e-01 -4.65554371e-02  3.06235075e-01
  6.49623796e-02  2.70178020e-01  4.45776790e-01  1.78991873e-02
 -2.54727125e-01 -3.16842318e-01  2.81635314e-01  4.84897703e-01
  2.25903228e-01  3.01471531e-01 -3.02494839e-02  7.80492008e-01
  1.89184874e-01 -2.72368401e-01 -1.14997283e-01  3.40380758e-01
 -4.27588187e-02  3.55339423e-02  5.18014282e-02 -9.93635282e-02
  3.01333934e-01 -3.66715670e-01  3.28482032e-01  1.22118711e-01
  1.27425641e-01  1.48365155e-01  3.40338126e-02  7.17379510e-01
  6.43144622e-02 -1.16126269e-01  2.72277266e-01 -8.59983623e-01
 -4.10506614e-02  7.51709342e-02  4.22863424e-01 -4.02520001e-02
  2.23688304e-01 -2.38508701e-01  4.28901911e-02  2.62910903e-01
  2.28167623e-01 -2.67675877e-01  3.89353186e-01  3.35654348e-01
 -1.37546584e-01 -4.82169747e-01  3.01114649e-01 -3.21126543e-02
 -1.22680776e-01 -1.37924477e-01 -2.06381708e-01  7.76836053e-02
 -5.43570518e-01 -1.54156983e-01 -2.59642094e-01  3.96047682e-01
 -1.27163187e-01 -3.76004815e-01 -3.10198754e-01  4.11957324e-01
  6.23623729e-01 -8.76171142e-02 -2.32450850e-02  1.26228416e-02
  1.20536909e-01 -2.80006528e-02  4.73259509e-01  2.53959838e-02
 -3.65155861e-02 -6.36993721e-02 -2.10020453e-01  7.74807343e-03
 -6.67460263e-02 -1.77488312e-01 -2.67911732e-01  2.51304239e-01
 -4.03422654e-01 -3.54085475e-01  1.03115931e-01  1.82772696e-01
 -7.63469189e-02  2.83479929e-01 -1.79962501e-01  2.88362861e-01
  3.97266418e-01 -2.64826655e-01 -1.13738798e-01 -1.11215785e-01
 -4.38337415e-01 -3.98107767e-02  4.01977628e-01 -5.37806638e-02
 -4.16458398e-02  7.72588730e-01 -1.18756564e-02 -3.79925162e-01
  3.02037746e-02 -1.16173208e-01  4.63514507e-01  5.98999798e-01
 -4.84820902e-01  1.04136139e-01 -3.46314721e-03  9.13876891e-02
 -3.97686094e-01  4.49220777e-01  2.55479753e-01 -2.41804481e-01
 -2.81387955e-01  1.83216631e-01 -2.81709373e-01 -2.11986497e-01
  2.35988230e-01  3.76187444e-01  1.08236589e-01 -2.54351497e-01
 -6.90509006e-02 -5.07082343e-01 -5.47927439e-01 -2.90455401e-01
 -2.00717703e-01 -1.00175645e-02  2.99257785e-01 -1.51035607e-01
 -2.15475768e-01 -2.05430165e-01 -2.02127606e-01  3.97858113e-01]",LBDAM34S,False,False,"[8.600603103637695, 0.2957907021045685]"
5EPFBH2Y,BY7WX7P3,"Beyond Control Panels
Direct Manipulation for Visual Analytics

Alex Endert
Pacific Northwest National Laboratory

Lauren Bradel and Chris North
Virginia Tech

To  tackle  the  onset  of  big  data,  visual  ana-

lytics  (VA)  seeks  to  marry  the  human  in-
tuition  of  visualization  with  mathematical 
models’ analytical horsepower. A critical question 
is, how will humans interact with and steer these 
complex mathematical models? Initially, users ap-
plied  direct  manipulation  to  such  models  in  the 
same way they applied it to simpler visualizations 
in  the  premodel  era—by  using  control  panels  to 
directly  manipulate  model  parameters.  However, 
opportunities  are  arising  for  direct  manipulation 
of  the  model  outputs,  where  the  users’  thought 
processes take place, rather than the inputs. Here 
we  present  this  new  agenda  for  direct  manipula-
tion for VA.

Direct Manipulation for  
Information Visualization
Direct  manipulation  specifies  three  principles  for 
interaction design for information visualization:1

 ■ continuous  representation  of  the  object  of  in-

terest,

 ■ physical  actions  or  labeled  button  presses  in-

stead of complex syntax, and

 ■ rapid  incremental  reversible  operations  whose 
impact on the object of interest is immediately 
visible.

Typically, these principles are applied through a con-
trol panel, containing visual widgets such as sliders, 
buttons, or query fields, coupled to the parameters 
of a visual representation in the main view. For ex-
ample,  in  Spotfire,  analysts  can  choose  attributes 

to  map  to  available  visual  encodings  (node  color, 
size,  shape,  and  so  on);  select  variables  for  the  x-, 
y-, and z-axes; and adjust sliders to filter by ranges 
on specific data dimensions (see Figure 1). We con-
tend that for VA, with the introduction of complex 
mathematical  models  behind  the  visualizations, 
direct-manipulation  interaction  has  the  opportu-
nity to evolve beyond the use of control panels.

Spatializations for Sensemaking
Spatializations create a visual representation of in-
formation in which data items’ relative proximity 
approximately depicts their similarity. (That is, the 
“near ≈ similar” metaphor holds true.) For exam-
ple,  in  Figure  2,  clusters  of  documents  represent 
themes  or  topics  of  interest.  Such  spatializations 
can be generated manually or computationally.

Manual Generation 
Analysts can leverage manually generated spatial lay-
outs to aid their analyses. For example, by organizing 
spatial  layouts,  they  can  externalize  their  insights 
about  a  dataset  on  the  basis  of  the  information’s 
positions.2  They  frequently  organize  such  layouts 
according  to  complex  schemas  using  mixed  meta-
phors,  often  organized  topically  according  to  the 
semantics relevant to their current analysis needs.

Analysts  use  tools  that  support  manually  con-
structing spatializations to visually synthesize hy-
potheses.3 That is, they directly manipulate spatial 
structures (often mixing clusters, timelines, con-
nections,  geography,  order  of  discovery,  process 
waypoints, and so on) that help reveal their sense-
making  process.  Such  informal  relationships  in 

6 

July/August 2013 

Published by the IEEE Computer Society 

0272-1716/13/$31.00 © 2013 IEEE

Visualization ViewpointsEditor:  Theresa-Marie RhyneFigure 1. Typical use of direct manipulation. The Spotfire scatterplot view can represent several dimensions 
of the data through spatial position and visual encodings; users manipulate it through buttons and sliders on 
control panels.

Figure 2. The In-Spire Galaxy View represents documents as dots. Each cluster of dots represents a group of 
similar documents.

the spatial layout are beneficial because they don’t 
require  analysts  to  overformalize  relationships 
too early in the process. This process of gradually 
increasing  relationships’  formality  is  called  incre-
mental formalism.4

Computational Generation 
Computationally  generated 
spatializations  are 
driven by the recent emphasis on big data and in-
volve complex mathematical models. These models, 
combined  with  user  intuition  and  visualizations, 

 

IEEE Computer Graphics and Applications 

7

directly adjust numerous model parameters, such 
as individual eigenvalues, eigenvectors, and other 
PCA  components.  In  this  way,  they  can  observe 
how the visualization changes. This lets them gain 
insight into a dataset, assuming they know enough 
about  the  underlying  PCA  model  to  understand 
the implications of changing model parameters.

The  straightforward  application  of  direct  ma-
nipulation suggests creating graphical controls for 
each parameter. This use of control panels might 
have  been  appropriate  for  early  information  vi-
sualizations  in  which  the  controls  mapped  natu-
rally to dimension filters and plot axes. However, 
it might be problematic for more complex models 
used in VA applications.

This  approach  has  three  fundamental  usabil-
ity  problems.  First,  many  analysts  aren’t  experts 
in  complex  mathematical  models  and  thus  don’t 
understand the meaning of the parameters for the 
interactive controls. Second, analysts think about 
and  understand  the  documents  at  the  semantic 
level,  yet  the  interactive  controls  for  the  models 
operate  at  the  lower  syntactic  level  of  the  model 
parameters. This creates a mismatch. Third, when 
analysts haven’t yet gained a good understanding 
of the documents and their insights are still infor-
mal, they don’t yet have a basis for expressing their 
inputs  into  the  formal  model  parameters.  These 
problems arise because the focus of direct manipu-
lation in the computationally generated spatializa-
tions  (the  model  parameters)  differs  significantly 
from  that  in  manually  generated  spatializations 
(the documents).

Suppose  an  analyst  recognizes  a  small  set  of 
documents  in  a  spatialization  that  she  believes 
are  related  to  a  semantic  topic  X  of  her  interest, 
but the current layout doesn’t reflect her hypoth-
esized similarity. She directly increases the weight 
of term X in the control panel (for example, by di-
rectly manipulating the layout parameters). How-
ever,  this  has  no  effect  because  X  doesn’t  appear 
in the documents.

Alternatively,  she  could  move  the  documents 
together herself (for example, by directly manipu-
lating  the  layout  output).  She  could  then  receive 
feedback from the models concerning other inter-
esting keywords that do relate to those documents. 
Also, the layout could be automatically updated to 
include other relevant documents. This would en-
able her to gain insight that helps to better formal-
ize her understanding of X.

This approach presents an opportunity to evolve 
the design of user interaction beyond control pan-
els  to  achieve  direct-manipulation  VA.  The  need 
exists  to  cooperatively  integrate  computationally 

Figure 3. iPCA (Interactive Principle Component 
Analysis) provides a dimension reduction algorithm 
that users manipulate through buttons and sliders in 
a control panel.8 (Source: Remco Chang; used with 
permission.)

form  the  basis  for  VA,  in  which  analysts  operate 
dynamic  tools  that  facilitate  analysis  and  sense-
making  of  large,  complex  datasets.5  Models  lever-
aged in VA tools include, but aren’t limited to, those 
for entity extraction, topic modeling, link analysis, 
dimensionality reduction, clustering, and labeling.
These models employ various distance metrics to 
measure the similarity between data objects. Ana-
lysts can use these metrics to spatialize data. For 
example, unstructured text can be represented as 
a “bag of words”—high-dimensional data in which 
each dimension is a unique keyword or phrase in 
the  text.  For  example,  in  In-Spire’s  Galaxy  View 
layout, nearby points represent similar documents 
(see Figure 2).6 This helps analysts recognize rela-
tionships  between  documents  and  between  clus-
ters of documents.

Designing User Interaction for Spatializations
For  computationally  generated  spatializations, 
the  question  arises  of  how  to  design  user  interac-
tion.  The  complex  statistical  models  that  com-
pute similarity using a combination of algorithms 
have  numerous  parameters  to  tune  on  the  basis 
of  the  analysis’s  context.  For  example,  for  visual 
text  analysis,  users  must  directly  adjust  keyword 
weights (measures of importance for each keyword 
and  how  much  it  influences  the  overall  layout), 
add  or  remove  documents  and  keywords,  or  pro-
vide more information on how to parse the docu-
ments for keyword entities upon import.

One such spatialization for streaming text data 
is  Streamit,  in  which  users  explore  a  dataset  by 
directly manipulating keyword weights.7 Similarly, 
iPCA (see Figure 3) is an interactive visualization 
tool that uses principal component analysis (PCA) 
to  reduce  high-dimensional  data  to  a  2D  plot.8 
Users  employ  sliders  and  other  visual  controls  to 

8 

July/August 2013

Visualization Viewpointsgenerated  spatializations  with  those  manually 
generated.  This  would  shift  the  focus  of  interac-
tion from control panels for model input param-
eters to direct manipulation of the model outputs 
as represented by the spatialization itself.

Direct Manipulation of Spatializations
A  trend  is  emerging  in  how  VA  systems  that  use 
complex statistical models handle interaction. This 
trend stems from letting users directly manipulate 
the  data  in  a  spatialization  to  guide  and  improve 
the  layout  according  to  their  interests  or  inter-
pretations. For example, to indicate that two data 
points in a spatialization differ more than is com-
putationally indicated, users can move them apart 
directly in the view. So, the model learns about the 
dissimilarity  and  updates  the  spatialization  to  re-
flect the desired structure of the data. Thus, users 
can  employ  familiar  direct-manipulation  interac-
tions within familiar spatialization metaphors, en-
abling  them  to  interact  with  complex,  unfamiliar 
mathematical models.

Within the spatial metaphor, we see three levels 
of  interactivity  that  motivate  this  emerging  con-
cept  of  direct-manipulation  VA.  These  levels  are 
based  on  the  extent  to  which  machine  learning 
steers the model.

The  first  level  is  direct  manipulation  of  spatial 
constraints. These interactions let users place (and 
move)  spatial  constraints  directly  in  the  spatial-
ization. For example, the Dust & Magnet tool lets 
users place a series of “magnets” representing spe-
cific  data  dimensions  or  keywords  in  the  spatial-
ization.9 Data objects rich in those dimensions are 
more  attracted  to  the  magnets.  Such  direct  ma-
nipulation enables users to guide the spatialization 
layout  by  placing  additional  query-like  attractors 
in the space.

The  second  level  is  direct  manipulation  of  pa-
rameter weighting. Such data-centric interactions 
leverage  metric-learning  techniques  to  adjust  the 
weighting  schema  of  the  dimensions  or  features 
used in distance metric calculations.10 Specifically, 
updates  to  the  weighting  scheme  reflect  the  fea-
tures  emphasized  by  the  user’s  interaction  (the 
weight  of  relevant  features  of  interest  increases, 
and  the  weight  of  other  features  decreases).  The 
weights are adjusted incrementally on the basis of 
heuristics associated with each type of interaction. 
For example, ForceSpire tightly couples several in-
teractions related to text analytics, such as reposi-
tioning documents, highlighting text, annotating, 
and searching, to the underlying dimension reduc-
tion  model.10  For  instance,  highlighting  a  phrase 
in  a  document  that  contains  a  set  of  keywords 

Figure 4. A ForceSpire spatialization’s progression. As 
the user gains insight, ForceSpire’s model learns to 
emphasize relevant features.

increases  those  keywords’  weight  in  the  distance 
metric.

interactions 

The third level is direct manipulation for model 
steering.  These 
leverage  machine 
learning to calculate the amount of change to each 
feature in the weighting schema. Basically, the VA 
application receives an updated spatial layout from 
the user and, given that layout, inverts the model 
to determine the updated model parameters. This 
might  require  an  optimization  search  process  to 
find the best overall fit. Then, the application can 
apply  the  updated  parameters  in  the  forward  ap-
plication of the model to show how the updated fit 
changes the layout. For example, observation-level 
interaction11  and  Dis-Function12  let  users  move 
groups of data points in a multidimensional-scaling 
layout closer together or farther apart to guide ma-
chine  learning  and  explore  alternative  structures 
in the data.

In summary, all these interactions let users in-
teract  directly  with  the  information  in  context. 
Over continuous use, the spatialization updates to 
reflect the incremental insights the user generated 
(see Figure 4). This creates a symbiotic relationship 
between  the  user’s  sensemaking  process  and  the 
system’s machine learning.

Opportunities and Challenges
The following areas provide opportunities and pose 
challenges for research on direct-manipulation VA.

 

IEEE Computer Graphics and Applications 

9

Data

Algorithm

Visualization

User

(a)

Hard data

Soft data

(b)

Algorithm
(project)

Algorithm
(interpret)

Spatialization

User

(perceive)

User

(interact)

Figure 5. Changing the visualization pipeline to support direct-
manipulation visual analytics. (a) In the traditional pipeline, users 
interact directly with the algorithm (the blue arrow) or data (the red 
arrow). (b) In the new, bidirectional pipeline, users interact directly 
with the spatial metaphor; interaction must be interpreted through the 
model (the purple arrows).

Model Steering
The steering of mathematical models has become 
a popular way to adapt those models’ visual output 
to  the  user’s  domain,  task,  and  workflow.  Users 
can augment the statistical determination of im-
portant  features  and  characteristics  in  a  dataset. 
Because  the  resulting  visualizations  include  the 
user’s domain expertise, they become more appli-
cable to the domain.

Figure 5 highlights the changes to the visualiza-
tion pipeline necessary to support such direct ma-
nipulation.  In  the  traditional  pipeline  (see  Figure 
5a), control panels directly adjust model input pa-
rameters. In the new pipeline (see Figure 5b), direct 
manipulation of the spatialization requires invert-
ing  the  model  to  interpret  the  action’s  intent,  as 
we mentioned before. The pipeline maps the inter-
action  backward  by  interpreting  the  actions  and 
adjusting the parameter data—for example, learn-
ing  dimension  weights.  There  are  many  possible 
approaches  to  this  interpretation  step.  Addition-
ally, using multiple models would further compli-
cate  the  pipeline,  necessitating  a  many-to-many 
mapping of interactions to models.

This  area  involves  two  main  challenges.  First, 
how  do  you  invert  models  and  map  interactions 
to the parameter-learning process? Second, how do 
you  incorporate  multiple  models  into  the  visual-
ization pipeline?

Feature Selection
A common stage of spatialization is feature selec-
tion. Features can be selected algorithmically from 
most  forms  of  data,  such  as  extracting  keywords 
from  text,  extracting  visual  and  audio  signatures 
from  images  and  sound,  and  so  on.  The  purpose 
is  to  represent  otherwise  unstructured  data  as 
high-dimensional.  For  example,  a  VA  application 
could use a number of natural-language-processing 

10 

July/August 2013

models to select keywords or key phrases from un-
structured text. These models determine keywords 
that are statistically more expressive than others, 
for that dataset. A frequent additional step selects 
features to optimize the signal-to-noise ratio.

This area involves two challenges. First, how do 
you  incorporate  users’  domain  expertise,  which 
includes features that might not be in the dataset? 
Second, how do you interactively combine features 
from different data types (for example, text, audio, 
and video)?

Feature Extraction
Another common stage of spatialization is feature 
extraction. A high-dimensional representation must 
be reduced to a low-dimensional spatialization. This 
process typically applies a weighting schema to the 
set  of  selected  dimensions  to  emphasize  each  di-
mension  differently  when  projecting  it  onto  the 
2D layout. Because the low-dimensional represen-
tations  are  inherently  ambiguous  representations 
of  high-dimensional  data,  interactions  in  these 
low-dimensional  spaces  can  also  be  ambiguous. 
Multiple  inferences  might  be  possible,  requiring 
assumptions or more user input.

The  challenge  here  is,  how  do  you  accurately 
interpret  the  interaction  in  the  spatialization 
and apply the high-dimensional representation or 
weighting scheme to it?

Mixed Metaphors
As  we  mentioned  before,  users  employ  different 
contexts  and  metaphors  to  refer  to  information 
in different regions of spatializations.2,13 Common 
metaphors include topical clusters, timelines, geo-
spatial  layouts,  social  networks,  and  process  his-
tory. Users frequently mix these metaphors in the 
same workspace as either separate areas or nested 
schemas.  These  metaphors  might  be  well  defined 
or ambiguous and might evolve.4

This  mixed-metaphor  use  of  spatializations 
poses  challenges  to  layout  and  clustering  models 
that  are  generally  designed  to  compute  one  type 
of  layout  across  the  entire  visualization.  So,  you 
might  need  to  combine  multiple  types  of  models 
in complex ways. For example, you could combine 
iCluster,  which  enables  direct  manipulation  of  a 
cluster  membership  model,14  with  ForceSpire  to 
enable  dynamic  layouts  of  clusters  in  space,  in 
much the same way analysts currently do manu-
ally.  The  space’s  continuity  and  flexibility  could 
represent probabilistic membership.

This area involves two challenges. First, how do 
you detect, interpret, compute, and visualize mixed 
models  that  represent  mixed  metaphors?  Second, 

Visualization ViewpointsTable 1. Using multiscale models to address big-data challenges for direct-manipulation visual analytics (VA).

Usage description

Data scale of manipulation 
(no. of data items)
Algorithms

Display

Level of scale

Database

Cloud

The system lays out the data 
according to the user’s spatial-
organization feedback.
<1 million

The system aggregates clusters 
of data in the layout according to 
the user’s grouping feedback.
<1 billion

The system uses the layout 
to query very large data and 
retrieve additional relevant data.
<1 trillion

Dimensionality reduction

Clustering

Information retrieval

Classification

Topic modeling
Clusters

Hierarchy

Containment

Sampling

Streaming
Salience

Depth

Visual salience = similarity

Visual aggregate = similarity
Grouping items

Piling
Cluster counts and contents

Deleting items

Searching
Object relevance

Visualization

Spatial layout

Visual proximity = similarity

Interaction

Moving items

Interactive feedback for 
machine learning

Similarities

Dimension weights

Centroid landmarks

Keyword dimensions and weights

Object weights

Labels

how  do  you  learn  which  model  best  captures  the 
user’s interaction, on the basis of the layout?

Multiscale Models
To support big data, VA can leverage multiple mod-
els  that  deal  with  information  at  multiple  scales 
(see Table 1). For small amounts of data, you could 
display all the data points on the screen by using 
dimensionality reduction (DR) models to organize 
space.  At  larger  scales,  cluster  models  can  aggre-
gate  data  into  fewer  groups  that  could  then  be 
fed to DR models. At even larger scales, informa-
tion retrieval (IR) algorithms become essential for 
streaming or sampling data to dynamically display 
only relevant data.

You can apply a consistent direct-manipulation 
approach  across  all  levels  of  scale  by  implement-
ing  a  system  of  mutual  learning  across  models. 
For example, the IR model can query for data rele-
vance based on the dimension weights that the DR 
model  learned.  Likewise,  the  IR  model  can  learn 
from  user  actions  such  as  placing  uninteresting 
data in the trash.

This  area  involves  two  challenges.  First,  how  do 
you coordinate direct manipulation to steer models 
across multiple levels of scales for big data? Second, 
how  do  you  enhance  algorithm  performance  to 
support real-time direct manipulation of big data?

Implicit and Explicit User Interaction
With  direct-manipulation  VA,  the  system  must 
infer user intentions from user interactions. How-

ever,  one  action  could  have  multiple  possible  in-
tentions.  For  example,  dragging  a  document  out 
of  a  cluster  might  indicate  that  it  didn’t  belong 
in that cluster, that the user is establishing a new 
cluster  with  new  nearby  documents,  or  nothing 
at  all.  More  implicit  or  explicit  user  input  might 
be needed to accurately represent the user’s actual 
reasoning process. The amount of approximate or 
specific input needed might vary.

These options imply the possibility of many pa-
rameters  for  the  interaction.  Too  much  explicit 
input might pull the analyst out of his or her cog-
nitive  zone.  Analysts  should  be  able  to  focus  on 
the task, not the tool, using interaction to support 
their reasoning process.

This area involves two challenges. First, how can 
the user interface balance explicit and implicit user 
interaction  for  model  feedback?  Second,  how  can 
users  easily  undo  or  revise  direct-manipulation 
interactions?

Multiparameter Interaction
Novel input modalities might offer more powerful 
ways for users to express their complex intentions. 
For  example,  multitouch  interfaces  can  provide 
richer  interaction  for  individuals  and  groups  by 
providing  more  simultaneous  input  points  with 
which to express parameters. For instance, in the 
machine-learning  step,  a  user  could  move  a  data 
point with one hand while specifying target data 
points with the other hand to indicate which simi-
larity  relationships  he  or  she  intends.  The  added 

 

IEEE Computer Graphics and Applications 

11

Table 2. The principles of direct manipulation for information visualization are recast for VA.

Direct manipulation for information visualization1 Direct-manipulation VA
Continuous visual representations of objects 
and actions

Physical actions or button presses instead of 
complex syntax

Rapid, incremental, and reversible actions with 
immediately visible effects

Spatializations provide a common ground between models and cognition.
Users are shielded from the complexity of underlying models and parameters.
Interactions occur in the visual representation.
Interactions are tightly coupled between the spatialization and the underlying models.
Models incrementally learn from interactions throughout the analytic process.
Visual feedback of the updated model is displayed in the visual metaphor.

bandwidth  of  these  multitouch  interactions  can 
more  accurately  define  such  manipulations’  ana-
lytical reasoning.

Large, high-resolution displays can provide more 
area with which to construct spatial relationships. 
They give the analyst real, meaningful space as a 
communication medium and as common ground 
between the human and model. For example, dis-
tances between documents can imply a similarity 
measure,  whereas  the  absolute  location  of  infor-
mation  can  serve  as  a  landmark  for  themes  and 
concepts.  Direct-manipulation  VA  might  be  the 
killer app for these novel hardware technologies.

This  area  involves  two  challenges.  First,  how 
much user input is needed to convey intention to 
the  models?  Second,  how  can  the  system  provide 
real-time visual feedback regarding the interpreted 
actions?

Bias
Model  steering  potentially  introduces  user  biases 
into  visualizations.  Researchers  have  attempted 
to  address  this  challenge.  For  example,  captur-
ing  interaction  data  over  time10  can  reveal  new 
keywords added to the model. The distribution of 
weight  between  these  user-derived  keywords  and 
those extracted from the data might indicate how 
much  the  user’s  domain  expertise  influences  the 
spatialization.

Furthermore,  the  temporal  history  of  keyword 
weighting  can  indicate  trends  in  the  analysis. 
Converging  trends  in  the  weighting  of  entities 
might indicate confirmation bias, whereas diverg-
ing weights might represent an analysis involving 
multiple hypotheses. In particular, it might be pos-
sible to quantify specific biases such as confirma-
tion  bias15  and  alert  users  to  them  in  real  time. 
Biases  are  also  opportunities  to  steer  algorithms 
toward  a  user’s  expression  of  interest,  but  down-
sides  such  as  overfitting  and  missing  other  inter-
esting  insights  could  occur.  Such  data  could  also 
be used to compare multiple analysts’ processes or 
support collaborative methods.

The  challenge  here  is,  how  do  you  illuminate 
the potential bias associated with introducing the 
user’s domain expertise into the model?

Direct  manipulation  is  familiar  to  informa-

tion  visualization  designers,  given  graphical 
controls over direct visual mappings (for example, 
x- and y- axes on scatterplots, dynamic queries of 
value  thresholds,  and  so  on).  However,  as  visual-
izations employ increasingly complex mathemati-
cal models, interaction designers face the challenge 
of maintaining the intrinsic principles that make 
direct  manipulation  successful,  while  adapting  it 
to  control  complex  model  parameters  that  might 
not  clearly  map  to  the  visual  representation.  As 
we  showed,  for  VA,  the  goal  of  providing  direct 
manipulation  isn’t  fully  realized  through  control 
panels for model parameters.

Direct  manipulation  of  the  visual  representa-
tion  itself  (see  Table  2)  will  enable  users  to  test 
hypotheses, discover relationships, and input their 
domain  expertise  into  the  calculations  used  to 
produce  the  view.  Tools  should  strive  to  strike  a 
balance  between  fully  automated  and  fully  man-
ual solutions. In other words, a balance must ex-
ist between cognition and computation in VA. By 
leveraging the information-rich medium of a spa-
tial layout as the primary communication method 
between  the  user  and  system,  researchers  will  be 
able  to  realize  direct-manipulation  VA.  We  hope 
that the research opportunities and challenges we 
presented will help establish a firm science of in-
teraction in VA. 

References
  1.  B. Shneiderman and C. Plaisant, Designing the User 
Interface:  Strategies  for  Effective  Human-Computer 
Interaction, 4th ed., Pearson, 2005.

  2.  C. Andrews, A. Endert, and C. North, “Space to Think: 
Large,  High-Resolution  Displays  for  Sensemaking,” 
Proc.  2010  ACM  Conf.  Human  Factors  in  Computing 
Systems (CHI 10), ACM, 2010, pp. 55–64.

  3.  W.  Wright  et  al.,  “The  Sandbox  for  Analysis: 
Concepts  and  Methods,”  Proc.  2006  ACM  Conf. 
Human Factors in Computing Systems (CHI 06), ACM, 
2006, pp. 801–810.

  4.  F. Shipman and C. Marshall, “Formality Considered 
Harmful:  Experiences,  Emerging  Themes,  and 
Directions on the Use of Formal Representations in 

12 

July/August 2013

Visualization ViewpointsInteractive Systems,” Computer Supported Cooperative 
Work, vol. 8, no. 4, 1999, pp. 333–352.

  5.  F.  Tyndiuk  et  al.,  “Cognitive  Comparison  of  3D 
Interaction  in  Front  of  Large  vs.  Small  Displays,” 
Proc.  2005  ACM  Symp.  Virtual  Reality  Software  and 
Technology (VAST 05), ACM, 2005, pp. 117–123.

  6.  J.A. Wise et al., “Visualizing the Non-visual: Spatial 
Analysis and Interaction with Information for Text 
Documents,”  Proc.  1995  IEEE  Symp.  Information 
Visualization (InfoVis 95), IEEE CS, 1999, p. 51.

  7.  J. Alsakran et al., “Streamit: Dynamic Visualization 
and  Interactive  Exploration  of  Text  Streams,”  Proc. 
2011 IEEE Pacific Visualization Symp. (PacificVis 11), 
IEEE, 2011, pp. 131–138.

  8.  D.H.  Jeong  et  al.,  “iPCA:  An  Interactive  System  for 
PCA-Based  Visual  Analytics,”  Computer  Graphics 
Forum, vol. 28, no. 3, 2009, pp. 767–774.

  9.  J.S. Yi et al., “Dust & Magnet: Multivariate Information 
Visualization Using a Magnet Metaphor,” Information 
Visualization, vol. 4, no. 4, 2005, pp. 239–256.

 10.  A.  Endert,  P.  Fiaux,  and  C.  North,  “Semantic 
Interaction  for  Sensemaking:  Inferring  Analytical 
IEEE  Trans. 
Reasoning 
Visualization and Computer Graphics, vol. 18, no. 12, 
2012, pp. 2879–2888.

for  Model  Steering,” 

 11.  A. Endert et al., “Observation-Level Interaction with 
Statistical  Models  for  Visual  Analytics,”  Proc.  2011 
IEEE  Conf.  Visual  Analytics  Science  and  Technology 

(VAST 11), IEEE, 2011, pp. 121–130.

 12.  E.T. Brown et al., “Dis-Function: Learning Distance 
Functions Interactively,” Proc. 2012 IEEE Conf. Visual 
Analytics  Science  and  Technology  (VAST  11),  IEEE, 
2012, pp. 83–92.

 13.  A.C.  Robinson,  “Design  for  Synthesis  in  Geo-
visualization,”  PhD  thesis,  Dept.  of  Geography, 
Pennsylvania State Univ., 2008.

 14.  S.  Drucker,  D.  Fisher,  and  S.  Basu,  “Helping  Users 
Sort  Faster  with  Adaptive  Machine  Learning 
Recommendations,”  Human-Computer  Interaction—
Interact  2011,  LNCS  6948,  Springer,  2011,  pp. 
187–203.

 15.  R.  Heuer,  Psychology  of  Intelligence  Analysis,  Center 

for the Study of Intelligence, 1999.

Alex  Endert  is  a  visualization  scientist  at  the  Pacific 
Northwest  National  Laboratory.  Contact  him  at  alex.
endert@pnnl.gov.

Lauren  Bradel  is  a  PhD  student  in  computer  science  at 
Virginia Tech. Contact her at lbradel1@vt.edu.

Chris North is an associate professor in Virginia Tech’s De-
partment of Computer Science. Contact him at north@vt.edu.

Contact  department  editor  Theresa-Marie  Rhyne  at 
theresamarierhyne@gmail.com.

Showcase Your 
Multimedia Content 
on Computing Now!

IEEE Computer Graphics and Applications 
seeks computer graphics-related 
multimedia content (videos, animations, 
simulations, podcasts, and so on) to 
feature on its Computing Now page, 
www.computer.org/portal/web/
computingnow/cga.

If you’re interested, contact us at 
cga@computer.org. All content will be 
reviewed for relevance and quality.

 

IEEE Computer Graphics and Applications 

13

","{""0"":{""0"":""data"",""1"":""user"",""2"":""layout"",""3"":""documents""},""1"":{""0"":""multiple*"",""1"":""real*"",""2"":""explicit*"",""3"":""understand""},""2"":{""0"":""generated*"",""1"":""involves*"",""2"":""interpret*"",""3"":""combine*""},""pos"":{""0"":1,""1"":2,""2"":3,""3"":4}}",2013,{},False,False,journalArticle,False,5EPFBH2Y,[],self.user,"{""C"":{""0"":5.0282623477,""1"":5.349099635,""10"":4.5276793335,""11"":3.4452372098,""12"":4.0261095229,""13"":6.1595471352,""14"":4.9666474339,""15"":6.723763564,""16"":9.9350281387,""17"":13.8182514528,""18"":3.183490046,""19"":5.5493690907,""2"":3.5940837673,""20"":3.3009613353,""21"":4.3289673682,""22"":10.2033859201,""23"":4.4084805522,""24"":3.355886182,""25"":3.2153034281,""26"":3.7299763927,""27"":4.2981221359,""28"":5.9902997004,""29"":7.8859009006,""3"":4.064332131,""30"":3.6287681121,""31"":5.9670232151,""32"":3.8991716633,""33"":6.0449743424,""34"":5.2928086853,""35"":4.4752215512,""36"":4.3727966696,""37"":3.6152329819,""38"":4.1306401521,""39"":3.7934224988,""4"":4.5470126547,""40"":4.1966064052,""41"":4.2471513341,""42"":3.6240462654,""43"":3.7106602552,""44"":4.193643331,""45"":4.032760243,""46"":4.2691682354,""47"":4.5161590738,""48"":4.4700243674,""49"":3.9363923817,""5"":4.5568464036,""50"":3.9363923817,""51"":4.515679335,""6"":4.2027171155,""7"":5.629679734,""8"":6.1445602847,""9"":6.1313223911},""Unnamed: 0"":{""0"":0,""1"":1,""10"":10,""11"":11,""12"":12,""13"":13,""14"":14,""15"":15,""16"":16,""17"":17,""18"":18,""19"":19,""2"":2,""20"":20,""21"":21,""22"":22,""23"":23,""24"":24,""25"":25,""26"":26,""27"":27,""28"":28,""29"":29,""3"":3,""30"":30,""31"":31,""32"":32,""33"":33,""34"":34,""35"":35,""36"":36,""37"":37,""38"":38,""39"":39,""4"":4,""40"":40,""41"":41,""42"":42,""43"":43,""44"":44,""45"":45,""46"":46,""47"":47,""48"":48,""49"":49,""5"":5,""50"":50,""51"":51,""6"":6,""7"":7,""8"":8,""9"":9},""count"":{""0"":98,""1"":72,""10"":24,""11"":22,""12"":22,""13"":20,""14"":18,""15"":18,""16"":18,""17"":18,""18"":16,""19"":14,""2"":42,""20"":14,""21"":14,""22"":14,""23"":12,""24"":12,""25"":10,""26"":10,""27"":10,""28"":10,""29"":10,""3"":38,""30"":8,""31"":8,""32"":8,""33"":8,""34"":8,""35"":8,""36"":6,""37"":6,""38"":6,""39"":6,""4"":36,""40"":6,""41"":6,""42"":6,""43"":6,""44"":6,""45"":6,""46"":6,""47"":6,""48"":6,""49"":6,""5"":32,""50"":6,""51"":6,""6"":32,""7"":28,""8"":26,""9"":26},""exemplar"":{""0"":null,""1"":null,""10"":null,""11"":null,""12"":null,""13"":""*"",""14"":""*"",""15"":null,""16"":null,""17"":null,""18"":null,""19"":null,""2"":null,""20"":null,""21"":null,""22"":null,""23"":null,""24"":""*"",""25"":null,""26"":null,""27"":null,""28"":""*"",""29"":null,""3"":null,""30"":""*"",""31"":null,""32"":""*"",""33"":""*"",""34"":null,""35"":""*"",""36"":null,""37"":null,""38"":null,""39"":""*"",""4"":null,""40"":""*"",""41"":""*"",""42"":null,""43"":null,""44"":null,""45"":null,""46"":null,""47"":null,""48"":null,""49"":""*"",""5"":null,""50"":null,""51"":null,""6"":""*"",""7"":null,""8"":null,""9"":null},""pos"":{""0"":1,""1"":2,""10"":8,""11"":9,""12"":10,""13"":1,""14"":1,""15"":4,""16"":11,""17"":12,""18"":13,""19"":14,""2"":3,""20"":15,""21"":16,""22"":5,""23"":6,""24"":2,""25"":17,""26"":7,""27"":18,""28"":19,""29"":8,""3"":4,""30"":3,""31"":20,""32"":2,""33"":3,""34"":9,""35"":21,""36"":4,""37"":22,""38"":23,""39"":4,""4"":1,""40"":5,""41"":6,""42"":24,""43"":10,""44"":11,""45"":12,""46"":25,""47"":7,""48"":13,""49"":26,""5"":2,""50"":14,""51"":27,""6"":5,""7"":3,""8"":6,""9"":7},""sigma_nor"":{""0"":1.4671879199,""1"":1.5690089813,""10"":1.7237762459,""11"":1.5503871047,""12"":1.6541789732,""13"":2.0670552508,""14"":1.8729565116,""15"":2.2097240564,""16"":2.8251925891,""17"":3.5694482241,""18"":1.5462065432,""19"":2.0536496383,""2"":1.4645482143,""20"":1.5862316757,""21"":1.7999422379,""22"":3.021165899,""23"":1.8441141865,""24"":1.6150186909,""25"":1.5993143334,""26"":1.7170741561,""27"":1.8470688257,""28"":2.2342477601,""29"":2.6679710691,""3"":1.5500056857,""30"":1.7100150257,""31"":2.2749189759,""32"":1.7753423862,""33"":2.2937513521,""34"":2.1120340748,""35"":1.9145114858,""36"":1.905395587,""37"":1.7114167767,""38"":1.8433899313,""39"":1.7570432911,""4"":1.6323910689,""40"":1.8602809934,""41"":1.8732233312,""42"":1.7136734718,""43"":1.735851513,""44"":1.8595222801,""45"":1.8183271826,""46"":1.8788608933,""47"":1.9421044064,""48"":1.930291333,""49"":1.793651603,""5"":1.6613478418,""50"":1.793651603,""51"":1.9419815663,""6"":1.6064196296,""7"":1.8679704801,""8"":1.9768805426,""9"":1.9746562534},""topic"":{""0"":0,""1"":0,""10"":0,""11"":0,""12"":0,""13"":1,""14"":2,""15"":-1,""16"":0,""17"":0,""18"":0,""19"":0,""2"":0,""20"":0,""21"":0,""22"":-1,""23"":-1,""24"":2,""25"":0,""26"":-1,""27"":0,""28"":0,""29"":-1,""3"":0,""30"":2,""31"":0,""32"":1,""33"":1,""34"":-1,""35"":0,""36"":1,""37"":0,""38"":0,""39"":2,""4"":-1,""40"":1,""41"":1,""42"":0,""43"":-1,""44"":-1,""45"":-1,""46"":0,""47"":1,""48"":-1,""49"":0,""5"":-1,""50"":-1,""51"":0,""6"":0,""7"":-1,""8"":0,""9"":0},""vector"":{""0"":""[ 3.6558616 -3.5898998  6.558663   2.3443215 -3.0271473 -3.545782\n  2.4264274 -1.6173316  3.450511   3.2073684]"",""1"":""[ 3.3168795 -3.5657575  6.5101314  2.1883264 -2.9914508 -3.4690697\n  2.9945393 -1.9273715  3.494893   3.4343588]"",""10"":""[ 3.976763  -3.68198    6.6528883  2.1304417 -3.165974  -3.241033\n  2.0498397 -2.1136086  3.3030622  2.8132932]"",""11"":""[ 3.3887558 -3.5129828  6.729741   1.8131224 -3.3166096 -3.6565657\n  2.7802854 -2.1964474  3.3085372  3.176813 ]"",""12"":""[ 4.1024027 -3.75416    7.002157   2.1698828 -2.9574268 -3.1195927\n  2.5222003 -2.7099295  3.0751908  3.3264048]"",""13"":""[ 5.071005  -4.2462635  5.6030393  1.5261096 -1.9191238 -3.0700824\n  1.3428835 -2.8909538  3.7434442  2.0148017]"",""14"":""[ 4.3325505  -3.82248     5.6687274   0.79795134 -2.426378   -3.522826\n  1.3906987  -3.015153    3.4566526   2.525716  ]"",""15"":""[ 4.614261  -4.04806    6.202717   2.0510612 -2.3915627 -2.9878101\n  1.4639816 -2.2285867  3.501822   2.6241844]"",""16"":""[ 3.9972036 -3.7677646  6.8085017  1.759555  -3.0867462 -3.2962477\n  2.3631697 -2.6899529  3.0839515  3.2537036]"",""17"":""[ 3.9056416 -3.6953843  6.4348516  2.622058  -2.9389486 -3.3050907\n  2.4575372 -1.9856225  3.2463167  3.4002879]"",""18"":""[ 3.8639188 -3.666448   6.8150034  2.403889  -2.385828  -2.9407268\n  2.1118574 -1.9813603  3.6539178  2.9236102]"",""19"":""[ 3.8881938 -3.7927306  7.0339894  2.548968  -3.0691977 -3.1379476\n  2.7067816 -2.4172916  3.5837033  2.816222 ]"",""2"":""[ 3.6723418 -3.6453452  6.503294   1.6359732 -3.0965052 -3.5171826\n  2.5931215 -2.4277472  3.122792   3.4172559]"",""20"":""[ 3.542677  -3.6166775  6.0214643  2.2733023 -3.0885983 -3.5100794\n  2.996459  -2.2729921  3.3390548  3.230856 ]"",""21"":""[ 3.9113345 -3.7468927  5.8674088  2.0874455 -2.880062  -3.4201016\n  2.6664002 -2.487911   3.3085604  3.0977373]"",""22"":""[ 3.1551266 -3.428119   6.3752103  2.6657624 -2.549979  -3.7420242\n  3.6744182 -2.3934245  4.210275   2.5105352]"",""23"":""[ 4.2665358 -3.8919468  5.998179   2.0509722 -2.3038702 -3.508115\n  2.738347  -2.4321198  4.0631924  2.3462098]"",""24"":""[ 4.400008  -3.8926034  5.68042    0.8058242 -2.6478534 -3.5186338\n  1.5860485 -3.2087421  3.2706258  2.5406613]"",""25"":""[ 4.245708  -3.8527904  5.771371   2.0494485 -2.5416574 -3.3323636\n  2.4783742 -2.6247609  3.390533   2.9195735]"",""26"":""[ 4.6399393 -4.011672   5.646521   1.7284334 -2.047598  -3.423345\n  2.3053253 -2.71151    3.9899607  2.2270803]"",""27"":""[ 4.006471  -4.0569386  6.2543907  2.7128634 -2.586327  -3.2566838\n  2.938942  -2.038668   4.086207   2.9128923]"",""28"":""[ 3.8179638 -3.71821    6.739431   2.7410927 -2.924922  -3.0370226\n  2.7890365 -2.4231114  3.366399   3.2419395]"",""29"":""[ 4.5671034 -3.9017901  5.451501   1.6749455 -2.3934028 -3.424816\n  2.370336  -3.022302   3.583046   2.3294091]"",""3"":""[ 3.764754  -3.5439112  6.8625646  2.089559  -3.2907538 -3.516999\n  2.7748775 -2.3532882  3.0170307  3.4579265]"",""30"":""[ 4.3090916  -3.9548783   5.9113383   0.92538226 -2.6443515  -3.3971558\n  1.5522587  -3.0579486   3.6304069   2.148999  ]"",""31"":""[ 4.2621155 -3.9804132  6.427179   2.1972225 -2.414543  -3.0173247\n  1.8171973 -2.0759468  3.4398687  3.12116  ]"",""32"":""[ 4.9719205 -4.0737276  5.939613   1.6720012 -2.094022  -2.8754365\n  1.168871  -2.749539   3.5641603  2.2350204]"",""33"":""[ 4.8015084 -4.0754232  5.851884   1.2221514 -2.2914457 -2.9277492\n  1.0939176 -3.068842   3.6681745  1.9692308]"",""34"":""[ 3.0957007 -3.5441322  6.391353   2.770601  -2.464857  -3.618198\n  3.5637033 -2.405823   4.1300898  2.6544175]"",""35"":""[ 3.9313319 -4.0074615  6.3636165  2.815764  -2.7735505 -3.1192489\n  2.758328  -2.0807872  3.6879022  3.2527244]"",""36"":""[ 4.618333  -4.0377     5.7059693  1.0682018 -2.4020693 -3.3737395\n  1.6175798 -3.0795383  3.664016   2.1061802]"",""37"":""[ 3.5395863 -3.7357576  6.432392   2.5889537 -2.7015944 -3.2920122\n  3.1926057 -1.9703435  3.903124   3.2105942]"",""38"":""[ 4.123043  -3.896277   6.286601   2.1900327 -2.6407266 -3.250804\n  1.8654448 -1.8220615  3.4949648  3.0087461]"",""39"":""[ 4.47224   -3.975422   5.6089854  0.7924574 -2.6122603 -3.5567389\n  1.6671621 -3.2120578  3.372884   2.4235284]"",""4"":""[ 3.9754455 -3.837945   6.7902317  2.5139015 -2.7782955 -3.2764297\n  2.8219264 -2.2730136  3.9823394  2.4753819]"",""40"":""[ 5.0574136 -4.0407367  5.799267   1.4798251 -1.9801853 -3.0082366\n  1.2081285 -2.9338098  3.5732152  2.2103589]"",""41"":""[ 4.9052935 -4.0749097  5.7600427  1.1926197 -2.185236  -3.0216465\n  1.0813274 -3.1240149  3.6128056  1.9938966]"",""42"":""[ 4.232946  -4.020502   6.041007   2.0350246 -2.5604248 -3.1861143\n  1.8360574 -2.1569598  3.404023   3.0801048]"",""43"":""[ 4.078189  -3.8118584  5.9246225  1.0139703 -2.7260234 -3.5358872\n  1.7403445 -2.852382   3.4076896  2.6806517]"",""44"":""[ 4.537426  -3.8557162  6.0520406  1.205447  -2.3001065 -3.0446422\n  1.2042191 -3.0920396  3.4733834  2.275941 ]"",""45"":""[ 3.6880713 -3.4534256  6.8588977  2.2251875 -2.387443  -2.8764534\n  2.1886077 -2.2205954  3.472784   3.038061 ]"",""46"":""[ 3.949709  -3.6521144  7.1187134  2.371136  -2.610696  -2.8837504\n  2.2279394 -2.2789147  3.395458   3.0776372]"",""47"":""[ 4.8314266 -4.10146    5.61262    1.4710222 -2.0559697 -3.3124487\n  1.8603607 -2.8831165  3.8388774  2.127481 ]"",""48"":""[ 3.2035859 -3.3563519  6.2449746  2.517697  -2.583045  -3.796805\n  3.5929449 -2.5484931  4.0514812  2.4236245]"",""49"":""[ 3.9553428 -3.8468983  6.617489   2.4636116 -2.8264384 -3.0946205\n  2.7641656 -2.3478277  3.3257751  3.490957 ]"",""5"":""[ 3.3777695 -3.440122   6.3363595  2.5090714 -2.704628  -3.7040617\n  3.5737813 -2.2978911  4.1122403  2.5946684]"",""50"":""[ 5.086495  -4.200605   5.789733   1.7067516 -2.0564737 -2.9587092\n  1.2882506 -2.6681392  3.5207777  2.2605908]"",""51"":""[ 3.4465866 -3.536513   6.842609   1.9426079 -3.0998054 -3.384894\n  2.7191966 -2.1028223  3.259434   3.4053626]"",""6"":""[ 3.6645942 -3.87561    6.4381704  2.7935739 -2.8827512 -3.113986\n  3.0360389 -2.0483928  3.6260774  3.4634788]"",""7"":""[ 4.7916217 -3.9767349  5.4050913  1.6335995 -2.0582032 -3.312114\n  2.083521  -3.0074852  3.745766   2.1719196]"",""8"":""[ 3.9486449 -3.7490268  6.005932   1.9627968 -3.1607347 -3.4391272\n  2.2097566 -2.3190575  3.298754   2.8394592]"",""9"":""[ 4.073408  -3.7898083  7.259825   2.386407  -3.1799955 -3.1309164\n  2.5790362 -2.5363457  3.328278   2.900718 ]""},""vocab_index"":{""0"":0,""1"":4,""10"":26,""11"":28,""12"":30,""13"":34,""14"":35,""15"":36,""16"":38,""17"":40,""18"":50,""19"":60,""2"":10,""20"":61,""21"":62,""22"":63,""23"":64,""24"":83,""25"":84,""26"":93,""27"":94,""28"":104,""29"":105,""3"":12,""30"":129,""31"":133,""32"":134,""33"":135,""34"":137,""35"":138,""36"":158,""37"":177,""38"":190,""39"":197,""4"":13,""40"":198,""41"":199,""42"":202,""43"":203,""44"":205,""45"":209,""46"":210,""47"":211,""48"":212,""49"":213,""5"":18,""50"":214,""51"":215,""6"":19,""7"":20,""8"":21,""9"":23},""word"":{""0"":""data"",""1"":""user"",""10"":""analysis"",""11"":""text"",""12"":""challenges"",""13"":""multiple"",""14"":""generated"",""15"":""dimensional"",""16"":""features"",""17"":""pipeline"",""18"":""weighting"",""19"":""metaphors"",""2"":""layout"",""20"":""domain"",""21"":""area"",""22"":""proc"",""23"":""endert"",""24"":""involves"",""25"":""north"",""26"":""manually"",""27"":""computationally"",""28"":""science"",""29"":""contact"",""3"":""documents"",""30"":""interpret"",""31"":""scales"",""32"":""real"",""33"":""explicit"",""34"":""conf"",""35"":""computing"",""36"":""understand"",""37"":""interac"",""38"":""metric"",""39"":""combine"",""4"":""spatialization"",""40"":""different"",""41"":""ambiguous"",""42"":""scale"",""43"":""display"",""44"":""implicit"",""45"":""bias"",""46"":""biases"",""47"":""fully"",""48"":""symp"",""49"":""technology"",""5"":""ieee"",""50"":""vast"",""51"":""content"",""6"":""computer"",""7"":""directly"",""8"":""figure"",""9"":""interactions""},""word*"":{""0"":""data"",""1"":""user"",""10"":""analysis"",""11"":""text"",""12"":""challenges"",""13"":""multiple*"",""14"":""generated*"",""15"":""dimensional"",""16"":""features"",""17"":""pipeline"",""18"":""weighting"",""19"":""metaphors"",""2"":""layout"",""20"":""domain"",""21"":""area"",""22"":""proc"",""23"":""endert"",""24"":""involves*"",""25"":""north"",""26"":""manually"",""27"":""computationally"",""28"":""science*"",""29"":""contact"",""3"":""documents"",""30"":""interpret*"",""31"":""scales"",""32"":""real*"",""33"":""explicit*"",""34"":""conf"",""35"":""computing*"",""36"":""understand"",""37"":""interac"",""38"":""metric"",""39"":""combine*"",""4"":""spatialization"",""40"":""different*"",""41"":""ambiguous*"",""42"":""scale"",""43"":""display"",""44"":""implicit"",""45"":""bias"",""46"":""biases"",""47"":""fully"",""48"":""symp"",""49"":""technology*"",""5"":""ieee"",""50"":""vast"",""51"":""content"",""6"":""computer*"",""7"":""directly"",""8"":""figure"",""9"":""interactions""},""x2D"":{""0"":-0.5252723098,""1"":-0.3072060049,""10"":-1.5258016586,""11"":-1.0368523598,""12"":-1.0052477121,""13"":-2.8135786057,""14"":-4.0209364891,""15"":-1.7873095274,""16"":-1.2944716215,""17"":-0.2953367233,""18"":-1.0580322742,""19"":-0.4012543559,""2"":-1.3331427574,""20"":-0.0243359152,""21"":-0.7301505208,""22"":1.2251688242,""23"":-0.6671244502,""24"":-3.8322162628,""25"":-0.9240301251,""26"":-2.3983302116,""27"":0.4830516577,""28"":-0.2638604343,""29"":-2.8438091278,""3"":-1.1407310963,""30"":-3.4852240086,""31"":-1.3205928802,""32"":-3.1101706028,""33"":-3.6111426353,""34"":1.0984307528,""35"":0.2651383281,""36"":-3.2193024158,""37"":0.686250031,""38"":-1.5285272598,""39"":-3.7529723644,""4"":0.0952617154,""40"":-3.1819243431,""41"":-3.2897486687,""42"":-1.4919915199,""43"":-4.0440092087,""44"":-3.6696021557,""45"":-1.0442535877,""46"":-0.9230442643,""47"":-2.7282624245,""48"":1.2717092037,""49"":-0.1994535327,""5"":1.0848616362,""50"":-3.187194109,""51"":-0.8028575182,""6"":0.3762154579,""7"":-2.5198378563,""8"":-1.6610363722,""9"":-0.7587667108},""y2D"":{""0"":-2.0944831371,""1"":-2.4870216846,""10"":-0.6750449538,""11"":-2.4908216,""12"":-1.392385006,""13"":5.6794228554,""14"":4.6870498657,""15"":0.8566009402,""16"":-1.4928085804,""17"":-1.6612448692,""18"":-0.2567332685,""19"":-0.8133084178,""2"":-2.327755928,""20"":-2.070981741,""21"":0.3211371899,""22"":-0.5523046255,""23"":1.3456532955,""24"":4.5979990959,""25"":0.8114022613,""26"":4.420645237,""27"":-0.9802536964,""28"":-1.2363698483,""29"":4.4327096939,""3"":-2.0370190144,""30"":4.7549266815,""31"":0.2520913184,""32"":6.1495079994,""33"":5.8549690247,""34"":-0.6858976483,""35"":-1.2755298615,""36"":5.0872335434,""37"":-1.3677922487,""38"":0.4038819075,""39"":5.0673236847,""4"":-0.552942276,""40"":5.8335399628,""41"":5.4239578247,""42"":0.6395658255,""43"":4.8093266487,""44"":5.4899587631,""45"":-0.513137579,""46"":-0.6061078906,""47"":5.0712757111,""48"":-0.5716515779,""49"":-1.5944602489,""5"":-0.4141603708,""50"":5.9732494354,""51"":-2.2872555256,""6"":-1.6509225368,""7"":4.6537394524,""8"":-0.0645438507,""9"":-1.0088634491}}",False,False,False,http://ieeexplore.ieee.org/document/6562729/,,Beyond Control Panels: Direct Manipulation for Visual Analytics,"[ 9.23567265e-02 -1.80099696e-01  1.31506756e-01  1.57658651e-01
  1.04620051e+00  1.03658244e-01 -5.41096926e-01  1.33815259e-01
 -6.28177643e-01 -3.14812422e-01  1.88802391e-01 -1.51309848e-01
 -1.23549970e-02  1.79988459e-01 -2.56545752e-01  8.25527787e-01
 -3.59993756e-01 -1.06891125e-01  1.21595629e-01  2.66081840e-01
 -2.52162535e-02 -7.26575032e-02  2.60316074e-01  4.29179341e-01
  1.42003953e-01 -1.56565517e-01 -2.14592680e-01 -1.77052289e-01
 -1.30750120e-01  5.75144112e-01  9.13297907e-02  2.55333006e-01
 -9.37477499e-02 -5.38685679e-01  3.50323260e-01 -2.82906860e-01
 -2.08497122e-01  3.35823417e-01  7.65306801e-02  7.49297380e-01
 -6.12096667e-01 -6.52315199e-01 -1.39078498e-01 -4.28507239e-01
  2.97843903e-01  2.22811848e-01 -1.79244533e-01 -3.66585910e-01
  2.47171596e-01 -1.09502107e-01 -1.17791367e+00 -4.33174938e-01
 -6.81421220e-01 -3.29076171e-01  1.96845755e-01  2.80782014e-01
  1.49948210e-01 -6.48431420e-01  2.78690279e-01  1.37175024e-01
 -4.69658136e-01 -1.99324429e-01 -5.23514986e-01  9.20971408e-02
  2.79129118e-01 -4.13740277e-01  3.08051795e-01 -3.75285000e-02
 -2.67715931e-01  4.08714980e-01  9.90410447e-02  9.74068567e-02
 -2.21202508e-01  3.69219959e-01 -5.85605130e-02 -9.29915532e-03
 -2.93793291e-01  3.76340568e-01  1.88602105e-01 -1.06861502e-01
 -4.97587025e-02  2.89762795e-01  3.84467989e-02  3.34021100e-03
  3.83981198e-01  7.57360280e-01 -2.90590450e-02  5.28633773e-01
 -2.31855065e-01  2.35345438e-01 -3.58564138e-01 -2.12148950e-01
 -1.14371479e-01  3.09990972e-01  7.24992514e-01 -6.67099178e-01
 -6.48732424e-01  6.65809885e-02 -2.69208997e-01  4.84862365e-03
  1.58124015e-01 -3.56569946e-01  4.31836322e-02  1.21077098e-01
  3.30990374e-01 -2.38309234e-01 -7.47214854e-02 -1.21814936e-01
 -4.92152989e-01  4.83730510e-02  4.69602505e-03  4.87308167e-02
  1.06001377e-01 -5.04279494e-01 -6.27648592e-01  3.84529680e-01
  3.42035025e-01 -7.82921985e-02  6.89707518e-01  2.40225255e-01
  5.91693595e-02  7.78158128e-01 -1.08055599e-01  4.23860461e-01
  1.77718624e-01  1.65997490e-01 -2.68850066e-02  1.60934091e-01
  5.03432751e-01  8.07255283e-02  4.23653156e-01 -2.42522866e-01
  1.73065420e-02  4.58630547e-03  2.58205861e-01  6.51800632e-01
 -4.28292267e-02  1.03505485e-01  2.56077703e-02 -1.24444932e-01
 -4.92829025e-01 -4.19992894e-01 -1.84015483e-02  1.97813530e-02
  1.21424876e-01 -2.97576636e-02 -5.58906615e-01  3.76983404e-01
 -4.43535894e-01  3.99281919e-01 -3.93811524e-01  2.01176286e-01
 -8.74364495e-01  4.17591967e-02 -9.98436809e-02 -1.75991803e-01
 -3.43466885e-02  1.57626823e-01  2.68979192e-01  4.02585082e-02
  1.14771031e-01 -7.32245445e-02 -1.64195940e-01  2.42658421e-01
  3.46011698e-01 -1.65639818e-01  1.87805608e-01  1.45244077e-01
 -3.40265721e-01 -1.32380277e-01  1.07710272e-01 -3.11620265e-01
  2.93277979e-01  4.84885067e-01  1.89022616e-01  4.11027903e-03
 -1.17530324e-01  1.76455930e-01  1.04413703e-01  9.85430300e-01
 -3.61454695e-01 -1.11225292e-01 -1.68351099e-01 -3.25464100e-01
  2.80837804e-01 -5.83666936e-02  1.48881629e-01 -5.17942905e-01
 -4.73977253e-03  3.27541530e-02 -2.57754266e-01 -3.71475518e-01
 -1.51472270e-01 -2.57032573e-01  1.41907617e-01 -3.67748141e-01
 -3.59074846e-02 -1.79219648e-01 -3.95577848e-01 -3.42972726e-01
 -2.72567034e-01 -6.76608607e-02  2.36770421e-01  8.56107324e-02
 -3.82033527e-01  1.97024629e-01 -8.38367939e-02 -6.57371521e-01
 -5.10001957e-01  8.10040981e-02 -1.72506765e-01  6.36722147e-01
 -2.82532901e-01  5.49300730e-01  1.44742921e-01  1.50572807e-01
 -2.07813606e-01  5.78717850e-02  2.19417721e-01  1.65513441e-01
 -1.40693888e-01 -2.70426393e-01 -2.40073770e-01  6.20344765e-02
 -7.29082748e-02  1.66498399e+00  2.17379719e-01 -6.64197206e-01
  6.34590387e-01  2.36333385e-01  5.05183451e-02  8.89997035e-02
 -4.42139655e-02 -7.46856093e-01  3.04744273e-01  6.29230309e-03
  9.62989032e-02 -3.15953702e-01  5.99924803e-01 -3.06042880e-02
 -2.71626860e-01  2.67737299e-01  1.38574511e-01  3.25140148e-01
  1.64918631e-01 -1.76284462e-01  1.03083039e-02 -2.23048016e-01
 -1.88610274e-02 -9.36107039e-02 -1.85883269e-01  2.91374505e-01
 -7.91391850e-01 -3.39780301e-01  1.09337471e-01  3.03965271e-01
 -1.49608567e-01 -2.66658157e-01 -3.15094084e-01  2.47980416e-01
  4.25191432e-01  1.37234941e-01  5.18865027e-02 -2.77314276e-01
 -1.05886506e-02 -7.91677833e-01  1.47956908e-01 -2.60446906e-01
  6.15065813e-01  3.63639563e-01  2.12499164e-02 -2.83421218e-01
  5.48949912e-02  3.41145515e-01 -4.44743812e-01 -2.78928936e-01
  2.15645224e-01  5.44537753e-02 -3.79097909e-02 -3.77038389e-01
  4.29587185e-01  4.96217072e-01 -7.85729736e-02  3.46435726e-01
 -6.07470572e-01 -1.68974698e-01  3.00161600e-01  8.41925517e-02
 -9.06103253e-02 -2.69787967e-01  2.28659250e-02  3.35704982e-01
 -7.78544843e-01  1.83882173e-02  5.78408599e-01  4.48742598e-01
  4.23093945e-01 -2.26568088e-01 -3.46008450e-01 -7.13047087e-01
 -5.64576626e-01  2.44990766e-01  1.38144404e-01 -2.03952849e-01
  2.37095430e-01 -2.58343220e-01 -2.20775828e-02 -8.98413539e-01
 -8.83058262e+00 -3.16247314e-01 -2.43712977e-01 -1.29965022e-01
 -1.69877820e-02 -9.68275666e-02  2.08183274e-01  2.20775455e-02
  1.74266949e-01  3.34417075e-02  1.78263277e-01  1.64166272e-01
 -2.78258145e-01  1.35274291e-01 -1.02485359e-01 -2.59698331e-01
  3.07785958e-01 -8.19103718e-02 -1.96429729e-01  3.96243244e-01
  2.15336997e-02 -6.23969555e-01  2.34085470e-01 -3.64360958e-01
  1.15731791e-01 -4.68904406e-01 -5.51697791e-01  3.42327625e-01
 -2.21644968e-01 -5.69223166e-01 -3.10551003e-02 -3.01829576e-01
 -4.62989211e-01  8.08056355e-01 -4.33991328e-02 -2.51615137e-01
 -3.56774360e-01 -5.72831631e-01  5.12281120e-01  2.68328011e-01
  7.22016841e-02 -5.02089977e-01 -2.20056951e-01  2.17044689e-02
  6.22231781e-01  8.69011208e-02  3.26761514e-01  4.18601841e-01
  1.41841080e-02 -1.62993222e-01 -5.77290282e-02  3.47196087e-02
  3.65584254e-01 -6.20332003e-01 -1.06748894e-01  1.18737839e-01
  4.20427561e-01  7.88505733e-01  3.61378677e-02 -1.79262817e-01
 -1.29395435e-02 -3.45832825e-01 -5.91888130e-01  1.25909433e-01
 -9.39071774e-02  1.51525632e-01 -5.08663952e-01 -7.78004706e-01
 -1.58103853e-01 -2.18693390e-02 -4.74983662e-01  3.91307831e-01
  1.31838605e-01 -1.69899869e+00 -6.70980752e-01 -2.94160128e-01
  2.96699226e-01 -2.70316809e-01 -4.34060484e-01 -4.91793394e-01
 -5.93066990e-01 -3.74908715e-01  3.84431571e-01 -1.59179345e-01
 -4.19065863e-01 -8.28326680e-03 -1.44291267e-01 -1.30872905e-01
 -7.91151635e-03  2.37458751e-01  4.16201539e-02 -3.80284749e-02
  4.47653770e-01 -1.19854711e-01  1.78060248e-01  8.74759536e-03
  3.35153759e-01 -1.63616270e-01  4.13527787e-01  1.92384243e-01
 -4.33213226e-02  6.81936741e-02  1.59253955e-01 -4.11263764e-01
 -6.69853985e-01  3.24235260e-02 -3.61085534e-01  4.83317189e-02
  1.76107079e-01  4.99142528e-01 -2.99836189e-01  8.75612274e-02
 -3.93527150e-01 -3.05739015e-01 -5.24352610e-01 -5.96313290e-02
 -2.70420015e-01  5.25171161e-01 -1.35979399e-01 -7.03173041e-01
 -3.63302529e-01  3.11175168e-01 -2.70164281e-01 -1.30069420e-01
  6.08623326e-01  7.14931190e-02 -1.52759060e-01  4.28779423e-01
 -6.64484352e-02 -6.02876917e-02 -1.28320709e-01 -5.56092560e-02
  9.03456211e-02  4.63981405e-02  5.04878089e-02 -1.21098101e-01
 -6.68338016e-02 -1.56057805e-01 -8.58537912e-01  4.30964589e-01
  2.25256056e-01  1.21063955e-01  4.99594837e-01  2.59019732e-01
 -5.08872233e-02 -3.30190957e-01 -3.11030746e-01  4.53070402e-01
 -8.04238543e-02  1.34608939e-01 -2.17131272e-01 -7.51655817e-01
 -1.34783834e-01 -2.18711719e-01  4.00664866e-01  3.91693383e-01
  2.27945462e-01 -5.00063419e-01  3.25344086e-01 -2.48114973e-01
  3.94593090e-01  3.26826096e-01 -1.28751099e-01  2.41987363e-01
 -2.00688154e-01  1.92307040e-01 -1.21793598e-01  1.87874109e-01
  3.78651321e-01 -6.13969266e-01 -2.98017144e-01 -2.89423019e-01
  5.49097024e-02 -2.38390014e-01 -9.87063199e-02  7.02730000e-01
  4.03639406e-01 -7.94037879e-02 -6.06773496e-01  4.46729302e-01
  5.27401209e-01  4.81156170e-01 -4.17795599e-01  4.38649327e-01
  3.73997092e-01  2.41566435e-01  3.11755687e-02  4.28184420e-02
  2.23521143e-01  2.42312551e-02 -3.46524209e-01  3.01687777e-01
 -3.37687761e-01  2.92290866e-01 -3.95448685e-01 -2.89321125e-01
  3.15567732e-01 -4.40133661e-01  5.29241338e-02 -6.11438416e-02
 -3.93902183e-01 -1.22677349e-01 -2.90821463e-01  7.16343999e-01
 -1.64539903e-01 -2.49535441e-01  3.27690631e-01  3.69654119e-01
 -2.26194590e-01 -4.01489846e-02 -1.28491759e-01 -1.98939249e-01
  3.26676190e-01 -4.91648942e-01 -1.19249403e-01  1.48725808e-01
 -1.34474754e-01 -4.99958456e-01 -7.55303204e-01  1.63342074e-01
 -2.11756855e-01  2.26196438e-01  2.00554043e-01  4.71733451e-01
  1.97147518e-01 -2.26626456e-01  1.63388267e-01 -1.69169065e-02
 -1.98444009e-01 -1.42721772e-01 -5.06362677e-01 -1.34773302e+00
 -1.14794806e-01  1.88563675e-01  6.68125972e-02 -2.46441036e-01
 -4.66285139e-01 -9.73263904e-02 -2.78082639e-01 -3.38805735e-01
  4.31843996e-01 -3.82196337e-01 -1.96792379e-01 -1.73219070e-01
 -6.15746453e-02 -4.48388070e-01 -8.16293135e-02 -2.50496477e-01
 -4.81574863e-01  4.10612449e-02  4.83009100e-01 -9.38422680e-02
  2.18037665e-01 -8.20261776e-01  5.18651903e-01 -4.47003245e-01
 -1.26980901e-01 -4.68913376e-01 -1.33048356e-01 -1.28198877e-01
 -4.77676004e-01 -1.63793698e-01 -5.74782729e-01  6.78185374e-02
 -7.79286563e-01  4.66395728e-02 -1.55715402e-02 -1.83260918e-01
 -9.85578373e-02 -3.61462444e-01  2.96515495e-01 -4.26405631e-02
  3.31695415e-02  5.91236174e-01 -7.82801807e-01 -9.20800418e-02
 -3.15493137e-01  2.48552859e-01  3.14120382e-01 -3.55486631e-01
  2.68537849e-01  4.58804704e-02  2.57357270e-01  1.66385308e-01
  4.25671399e-01 -3.23633432e-01  1.16537236e-01  3.67652960e-02
 -2.07797721e-01 -2.18267992e-01  6.11009538e-01  5.67200296e-02
 -5.47385156e-01 -3.22177500e-01 -3.53332639e-01  2.58865505e-01
  6.30803406e-01  4.61342037e-02  3.80776227e-01  3.90310138e-01
 -3.94076049e-01  2.23583162e-01  6.95261240e-01  2.47828737e-01
  1.40347227e-01 -3.11938107e-01 -1.01191171e-01 -5.59994817e-01
 -2.39156246e-01 -6.05826437e-01 -1.56620458e-01 -2.49070287e-01
  3.78186762e-01  4.82967466e-01  3.30228984e-01 -2.61802524e-01
  2.26149391e-02  2.60559589e-01  1.14750281e-01  2.77230218e-02
 -5.25950909e-01  7.14419186e-01  3.83171082e-01 -5.16804397e-01
 -2.35769659e-01  7.24142015e-01  2.18530536e-01 -3.64398032e-01
 -4.40805703e-01  1.49065098e-02 -4.81739827e-03 -1.42324867e-03
  1.18246458e-01  5.45091480e-02  4.47060734e-01 -1.73489396e-02
  2.73164034e-01 -2.37423167e-01 -1.44736007e-01  2.39241242e-01
 -2.17670739e-01  3.95292789e-01  5.57509698e-02  3.27515215e-01
 -1.42063042e-02 -1.03072971e-01 -2.11047977e-02  7.70047307e-01
  2.10332170e-01  2.49787509e-01  9.23213214e-02 -3.50973934e-01
  6.94058761e-02 -1.75374568e-01  5.00380881e-02 -2.86899477e-01
  3.32549185e-01  2.48180307e-03  2.01422438e-01  3.95584464e-01
  2.62033820e-01 -5.81180900e-02  2.25544170e-01 -7.40519702e-01
 -3.28359574e-01  1.38513654e-01  2.73709178e-01  1.37448944e-02
  1.23056486e-01 -2.88918883e-01  6.45985425e-01  2.31580779e-01
  2.55443484e-01 -1.65219486e-01  2.09979683e-01  4.69497234e-01
  2.07804337e-01 -3.70464504e-01  1.94181114e-01  1.10498190e-01
 -1.08362176e-01 -1.03397788e-02 -2.95554906e-01 -2.79333860e-01
 -5.84412932e-01  1.09570414e-01 -1.42811924e-01  1.89021602e-01
  1.75498605e-01 -3.26824874e-01 -4.77174670e-01  3.66230935e-01
  6.25182629e-01 -6.62410408e-02  8.44289288e-02 -2.37567171e-01
  1.76779956e-01 -7.90488943e-02  3.55823696e-01  1.07840516e-01
  2.45495990e-01 -2.13022918e-01 -2.77802229e-01 -3.09045147e-02
 -2.10637301e-01 -2.79253930e-01 -1.24890603e-01  3.79392028e-01
 -4.89261270e-01 -3.22388738e-01  3.00084770e-01  4.74984199e-01
 -4.75386083e-02  8.12970325e-02 -4.61206049e-01  1.54783100e-01
  4.75344568e-01  3.00205082e-01 -3.34183186e-01  1.69469923e-01
 -4.51722234e-01 -6.47327185e-01  5.14908671e-01 -1.31545559e-01
  2.90100962e-01  4.59017336e-01  8.35788324e-02 -2.65659153e-01
  2.38321498e-01  6.27289936e-02  1.31055400e-01  3.31795841e-01
 -6.49783731e-01  1.89827055e-01 -2.04578683e-01  3.47179651e-01
 -3.18952858e-01  5.33958018e-01  1.90308154e-01 -1.96001962e-01
 -4.62898761e-01  4.17441726e-01  9.28270742e-02 -3.82470042e-01
  5.50859749e-01 -9.16703865e-02  1.15187252e-02  1.67541727e-01
 -1.33720830e-01 -3.86440232e-02 -5.45944333e-01  5.11884987e-02
 -2.95046747e-01 -1.40625998e-01  1.69958889e-01  2.10923981e-02
 -1.25625536e-01 -2.65201628e-01 -3.17586884e-02 -5.30616380e-02]",5EPFBH2Y,False,False,"[10.981800079345703, -2.2430341243743896]"
8QJPPCPZ,6VMGJTXT,"Multi-Model Semantic Interaction for Text Analytics 

Lauren Bradel, Chris North, Leanna House, Scotland Leman 

semantic interaction. 
Fig. 1. StarSPIRE spatial workspace showing clusters of open documents and numerous iconified documents selected and arranged through 
Abstract—  Semantic  interaction  offers  an  intuitive  communication  mechanism  between  human  users  and  complex  statistical 
models. By shielding the users from manipulating model parameters, they focus instead on directly manipulating the spatialization, 
thus  remaining  in  their  cognitive  zone.  However,  this  technique  is  not  inherently  scalable  past  hundreds  of  text  documents.  To 
remedy this, we present the concept of multi-model semantic interaction, where semantic interactions can be used to steer multiple 
models at multiple levels of data scale, enabling users to tackle larger data problems. We also present an updated visualization 
pipeline model for generalized multi-model semantic interaction. To demonstrate multi-model semantic interaction, we introduce 
StarSPIRE, a visual text analytics prototype that transforms user interactions on documents into both small-scale display layout 
updates as well as large-scale relevancy-based document selection. 
Index Terms— Visual analytics, Semantic Interaction, Sensemaking, Text Analytics. 

 
INTRODUCTION 

to  manage  different  portions  of 

1 
The problem of “too much data” has become a significant challenge 
in unstructured text sensemaking. Analysts are expected to “connect 
the  dots”  across  many  documents  [19],  requiring  analysts  to  work 
across  multiple  models 
the 
sensemaking loop [28]. 
During  foraging,  analysts  work  at  the  large  scale  (beyond  data 
displayed  on  the  screen).  Because  the  number  of  documents 
available  far  outweighs  the  number  of  relevant  documents  (e.g. 
millions of documents with hundreds or fewer relevant documents), 
the  low  signal-to-noise  ratio  makes  this  a  “needle  in  a  haystack” 
problem. Thus, analysts need methods of honing in on and finding 
additional relevant documents. Additionally, analysts must find all of 
the relevant documents in order to avoid missing important pieces of 
information. Relevance models are helpful at this scale. 
 During  synthesis,  analysts  work  at  the  small  scale  (e.g.  the 

information  on 

foraging  and  synthesis,  using  multiple  models 

amount of data that comfortably fits onto a display) with hundreds or 
fewer  documents.  A  common  synthesis  strategy  is  to  spatially 
organize 
the  display  [1].  Spatialization  and 
dimensionality reduction models are helpful at this scale [10]. The 
analyst then performs synthesis on these documents to make sense of 
them, but may have need for additional information.   
Thus,  the  sensemaking  process  consists  of  continuous  iteration 
between 
to 
accomplish  different  sensemaking-related  tasks.  However,  current 
tools require the analyst to break from synthesis actions to forage for 
additional information, which interrupts their cognitive processes. 
We propose unifying the sensemaking loop by coupling synthesis 
with foraging, and therefore coupling the corresponding models and 
interactions,  resulting  in  a  multi-model  approach.  In  other  words, 
synthesis  activities  can  be  interpreted  to  forage  for  additional 
relevant information and filter out irrelevant data. Likewise, foraging 
activities can influence synthesized structure.  To accomplish this, a 
method of usable control over coupled models is needed. 
Models which support computing data relevance (foraging) and 
spatial layout (synthesis) typically require parametric interaction, but 
most analysts are not experts in these underlying models and are ill-
equipped to interact directly with the parameters. Instead, semantic 
interaction  (SI)  techniques  convert  user  interactions  within  a 
spatialization into parametric feedback, enabling a spatialization that 

•  Lauren Bradel, Chris North, Leanna House, and Scotland Leman are with 
Virginia Tech. E-mail: [lbradel1, north, lhouse, leman]@vt.edu 
Manuscript  received  31  March  2014;  accepted  1  August  2014;  posted 

online 13 October 2014; mailed on 4 October 2014. 

For information on obtaining reprints of this article, please send  
e-mail to: tvcg@computer.org. 

 
 

 

is jointly created by user and algorithm [12, 14]. These techniques 
shield  the  user  from  the  complexity  of  underlying  spatialization 
algorithms  and  allow  them  to  focus  on  data  analysis.  However, 
semantic interaction has been limited to steering a single underlying 
model with fewer than 1000 data points.  
Our goal is to generalize semantic interaction to simultaneously 
steer  multiple  models.  This  involves  new  challenges  in  mapping 
semantic interactions to multiple model parameters in a coordinated 
way  and  conveying  combined  model  output  via  visual  feedback. 
Specifically, we instantiate this for the purpose of leveraging models 
at  different  levels  of  data  scale  to  support  larger  datasets.  In  our 
method,  users  invoke  semantic  interaction  techniques  in  order  to 
incrementally adjust a spatial layout model as well as influence what 
information is presented to them via a relevancy model.  
We present three contributions: (1) The concept, named Multi-
Model  Semantic  Interaction  (MSI),  is  an  alternative  to  explicitly 
controlling  parameters  in  multiple  models.  (2)  We  formalize  this 
extension  in  the  form  of  an  updated  visualization  pipeline  that 
reflects  the  generalizability  of  semantic  interaction  to  multiple 
models.  (3)  To  demonstrate  multi-scale  semantic  interaction,  we 
present  StarSPIRE 
[Figure  1],  a  visual  analytics  prototype 
implementing MSI for unstructured text data, which has been tested 
on  datasets  up  to  10,000  text  documents.  We  conclude  with  a 
discussion of multi-scale semantic interaction and research directions 
moving forward. 
Table  1.  Multiple  levels  of  data  scale  and  their  associated  models, 
visualizations, and feedback mechanisms. 

Scale of 
Interaction 
Sensemaking 
Loop 
Model purpose 

Usage 
Description 

Model  

Model 
Parameters 
Model metrics 
Visualization 

Interactive 
Feedback 

Small  

Synthesis 

Large 

Foraging 

Spatially project small 
scale data points onto the 
display, e.g. based on 
similarity 
System lays out displayed 
data, according to user’s 
spatial organization 
feedback 
Dimensionality reduction 

Dimension weights 

Extract useful data 
from large scale, e.g. 
based on relevance or 
coverage 
System selects data 
to display based on 
relevance according 
to user’s interests 
Relevance-based data 
selection 
Dimensions weights 

Similarity metric 
Similarity mapped to 
visual proximity 

Relevance metric 
Relevance mapped to 
working set, glyph 
size, and saturation 
Semantic interactions (see Table 2) update the 

dimension weights 

2  RELATED WORK 
Spatializations are frequently employed to aid sensemaking (foraging 
and  synthesis)  of  unstructured  text  documents  [2,  21,  30,  33,  34]. 
Large,  high-resolution  displays  in  particular  have  been  found 
beneficial in affording a large, flexible workspace that allows users 
to externalize knowledge and create semantic schemas [1]. However, 
this  knowledge  externalization 
through 
parametric interactions (e.g. [22]), many of which require users to go 
outside  the  spatial  metaphor  by  manipulating  control  panels  [11]. 
Furthermore, parametric interaction does not easily scale to big data 
problems. In unstructured text data, dimensions map to the terms or 
entities contained in the documents. Thus, the dimensionality of the 
data grows extremely large as the number of documents increases. 
Aside  from  navigating  through  the  flood  of  dimensions,  altering 
multiple models becomes extremely tedious. If multiple models are 
used for layout and/or retrieval, the user must update the dimensional 

typically  achieved 

is 

landmarks 

to  adjust 

to  manipulate  spatial 

weights or parameters for each model. To remove this redundancy, 
we prefer to contain the interaction within the spatial metaphor and 
translate interactions into parametric feedback. 
For  tools  that  allow  users  to  stay  within  the  spatial  metaphor, 
parametric interaction is still common. For example, Dust & Magnet 
allows  users 
the 
spatialization of multi-variate data [35]. However, these landmarks 
are attributes of the data, not points themselves. The users only have 
control  over  the  parameters  in  the  space.  Similarly,  VIBE  allows 
users to designate keywords as spatial landmarks [27]. In MSI, users 
can  designate  specific  data  points  as  spatial  landmarks.  These 
landmarks  attract  other  data  points  (e.g.  documents)  based  on  the 
high-dimensional data instead of a single attribute or dimension. 
Systems  exist  which  allow  users  to  directly  manipulate  data 
points, interpret this feedback via a dimensionality reduction model 
to  generate  a  new  spatialization  that  better  reflect  the  user’s 
understanding  of  the  high-dimensional  data  [6,  14,  20].  These 
methods  inherently  suffer  from  scalability  issues.  Users  expect  a 
quick interaction-feedback loop in order to remain in their “cognitive 
zone” [16], but calculations on thousands, let alone millions, of data 
points take from minutes to hours to complete. It is more practical to 
perform dimensionality reduction on a subset of a much larger data 
set  and  use  information  retrieval  techniques  to  retrieve  additional 
information to add to the workspace. 
MSI  is  perhaps  most  similar  to  adaptive  query-by-example 
systems. These systems, such as Adaptive Information Retrieval [3], 
use relevance feedback to augment future retrieval requests to return 
results that are better tuned to the user(s). Attempts have been made 
to visualize information retrieval results (e.g. term distribution charts 
[18], self-organizing semantic maps [25]), but these techniques have 
not been widely adopted. Information retrieval results are typically 
visualized as a ranked list of results [26]. Presenting results in this 
format  is  suitable  for  targeted  queries  where  the  user  may  view  a 
handful of results at most (e.g. a web search for a specific culinary 
recipe). However, when the user is presented with hundreds of viable 
documents  worth  reading  (e.g.  an  intelligence  analysis  task)  that 
relate in complicated, intricate, and fuzzy ways, a linear list becomes 
less than ideal [5]. 
Card  presents  a  survey  of  visualization  techniques  for  huge 
amounts of unstructured text data [7]. These techniques include, but 
are  not  limited  to,  dimensionality  reduction  (e.g.  [33]),  semantic 
maps (e.g. [25]), hierarchies (e.g. [4]), and link-node diagrams (e.g. 
[24]).  We  have  chosen 
to  explore  dimensionality  reduction 
techniques and link-node diagrams for representing unstructured text 
data,  but  we  recognize  the  potential  to  explore  other  visual 
representations in the future.  
Choo  and  Park  provide  an  overview  on  scaling  computational 
methods  to  the  problem  of  big  data  [8].  In  our  research,  we  have 
chosen  the  data  scale  confinement  solution.  By  constraining  the 
visualized  data  to  a  subset  of  the  actual  dataset,  dimensionality 
reduction  calculations  grow  much  more  efficient  than  computing 
across the entire dataset. This motivates our multi-scale approach to 
sensemaking. After performing information retrieval requests on the 
entire data set to procure a subset, the subset can be run through a 
suitable spatial layout model. 
We have developed multi-model semantic interaction in order to 
accommodate the need to work with extremely large amounts of data 
interpreting 
while  staying  within 
interactions to manipulate multiple data models. 
3  SEMANTIC INTERACTION 
Semantic interaction serves as means for analysts to work with data 
within a spatialization instead of altering algorithms or the raw data 
[Figure 2]. This is particularly important when the analyst is a non-
expert in the layout model(s). 
To develop semantic interaction, we first observed analysts, both 
novice and expert, completing sensemaking tasks and recorded the 
actions  analysts  undertook  [1,  5,  13].  We  then  harnessed  these 

the  spatial  metaphor  and 

can interact. The interactions done within the spatialization are then 
interpreted to influence the layout and/or retrieval models. Thus, the 
user is able to work with multiple models working at multiple levels 
of scale through interactions done on the data in the spatialization. 
For example, if a user executes a search for a term, documents 
containing this term in the spatial workspace would be drawn closer 
to the search node and the system would query the larger  “behind 
the  scenes”  dataset  for  this  term  and  add  the  top  n  retrieved 
documents  that  surpass  a  relevance  threshold,  ranked  by  the 
importance  the  user  has  given  to  entities.  This  is  an  incremental 
formalism approach [29] wherein the system considers the history of 
interactions  to  gradually  construct  and  refine  the  user’s  interest 
model of the data. In addition to just retrieving documents, multi-
scale semantic interaction augments the relevance model to tune the 
results to the user’s interests. 
In terms of the sensemaking loop [28], synthesis actions  are used 
to drive foraging activities and many foraging activities are able to 
be  conducted  implicitly  instead  of  explicitly.  For  example,  as  the 
user constructs a cluster by dragging documents together, the system 
can  search  the  entire  dataset  for  documents  that are  similar  to  the 
shared  terms  in  the  clustered  documents  and  add  them  to  the 
workspace.  Foraging  actions  such  as  these  that  are  conducted 
through implicit means allow for a richer and more nuanced query 
than explicit actions. For example, an explicit search for additional 
documents  may  take  the  form  of  a  boolean  search.  An  implicitly 
constructed  query  could  go  beyond  boolean  values  to  indicate  the 
relative importance of terms as well as include a far greater number 
of  terms  than  the  user  is  likely  to  enter.  This  method  of  implicit 
query formation attempts to return semantically relevant information 
to the user and seeks to fill in gaps of knowledge that a strict boolean 
search might miss. 
In  addition  to  bringing  information  into  the  spatial  workspace, 
multi-model  semantic 
irrelevant 
information.  If  a  user  indicates  that  a  document  or  term  is 
uninteresting or not relevant to their current investigation, the system 
will  interpret  this  interaction  to  update  the  user’s  interest  model 
parameters  to  reflect  this.  Accordingly,  information  related  to  this 
document or term would be filtered or removed from the display and 
would  be  less  likely  to  be  returned  from  information  retrieval 
requests. 
Multi-model  semantic  interaction  conveys  the  output  of  the 
multiple  models  through  visual  encodings  to  convey  document 
relevance and relationships between documents. This serves to give 
the user immediate visual feedback regarding their interactions. 
4.1 
We present an updated visualization pipeline to reflect multi-scale 
semantic 
is 
constructed  by  taking  the  data,  or  a  working  set  of  the  data  as 
determined by a relevance model, and passing it through a display 
layout model. The user then perceives the spatialization and has the 
option of interacting with the data within the spatial metaphor. All 
interactions are interpreted and directed to the appropriate inverted 
model(s). The inverted models then are combined, if necessary, and 
the new parameters are stored in the user’s high dimensional model 

Updated Visualization Pipeline 

interaction  also 

filters  out 

interaction  [Figure  3].  The 

initial  spatialization 

levels  Bottom:  semantic 

Fig. 2. Top: original visualization pipeline showing user interaction at 
the  algorithmic  and  data 
interaction 
visualization pipeline showing user interaction within the spatialization, 
which is then interpreted by the model to extract parameters (stored in 
the system as “soft data”), which are used to update the spatialization. 
actions such that the system could learn from the user which terms 
were  important  to  them  in  their  analysis,  resulting  in  semantic 
interaction  [12].  Previously,  we  have  applied  this  technique  to 
unstructured text data in a modified force-directed layout, allowing 
the semantic interactions to update the spatial layout, which used a 
“near  =  similar”  metaphor.  Alternatively,  semantic  interaction  has 
been applied to additional dimensionality reduction models, namely 
Multi-Dimensional  Scaling  (MDS),  Principle  Component  Analysis 
(PCA), and Generative Topographic Mapping (GTM) [14]. Semantic 
interaction  has  been  practically  applied  to  Multi-Dimensional 
Scaling  using  multivariate  data,  although  the  interactions  were 
limited to moving and highlighting data points [20]. 
While current forms of semantic interactions have shown to be 
successful,  they  are  limited  in  the  number  of  data  items  they  can 
handle  simultaneously  (less  than  1000)  and  have  been  limited  to 
steering a single model (spatial layout). Thus, semantic interaction 
alone is not adequate for tackling the challenge of big data.  
4  MULTI-MODEL SEMANTIC INTERACTION 
We  addressed  the  scalability  concern  by  developing  a  generalized 
semantic 
interaction  pipeline  where  multiple  models  can  be 
leveraged,  providing  functionality  across  multiple  levels  of  data 
scale. The result of this pipeline is a spatialization with which the 
user can interact, externalizing their knowledge of the data. These 
interactions are then converted into parametric feedback in order to 
update  the  underlying  model(s),  and  ultimately,  update  the  spatial 
representation of the data to reflect these changes [Fig. 3]. 
Using  [Table  1]  as  a  guide  for  interaction  and  visualization  at 
multiple levels of data scale, we see that small amounts of data map 
to dimensionality reduction models, while large amounts of data map 
to retrieval models. Using semantic interaction techniques, we seek 
to communicate with and between these various models in order to 
update the spatialization, select potentially relevant new information, 
and filter out irrelevant data. 
At the large scale, semantic interactions are mapped to retrieval 
requests, which serve to constrain the amount of data piped into a 
display  layout  model  by  extracting  a  working  set  of  relevant 
documents, which then creates a spatialization with which the user 

Fig. 3. Generalized multi-scale semantic interaction visualization pipeline. Any number of models can be inserted for use in this pipeline. Once 
the user perceives the spatialization, they can choose to interact in it. This interaction feedback is interpreted as input to one or many inverted 
models. The updated model parameters are stored, which are then used, along with the original data, to create an updated spatialization. 

of the data. This high dimensional model is then coupled with the 
dataset  to  pass  through  the  retrieval  and  projection  portion  of  the 
loop, resulting in an updated spatialization. This pipeline currently 
assumes a single shared set of model parameters. Possible extensions 
of this pipeline include multiple user models for the data (e.g. the 
user believes the data should be arranged in a different manner than 
what the user believes should be displayed). 
Not  all  semantic  interactions  will  necessarily  influence  every 
model or have the same impact. We offer a few examples to illustrate 
this point. Highlighting a phrase in a document typically indicates its 
importance,  while  minimizing  a  document  when  space  is  not 
constricted  typically  indicates  the  unimportance  of  its  contents. 
Moving points around the display would naturally update the display 
layout,  but  would  not  necessarily  fetch  new  data  points  for  the 
workspace.  
Furthermore,  updates  to  the  underlying  models  should  be 
executed wisely. Updating a model that impacts the entirety of the 
data  set  will  likely  be  a  slow  operation,  whereas  a  display  layout 
model operating on a small subset of the data can be executed much 
quicker. Therefore, it is practical to update the display layout model 
with each semantic interaction, but it may not be practical to do so 
for the information retrieval model. Obviously, if a user explicitly 
queries for information, it should be returned promptly. Otherwise, it 
may  be  a  better  option  to  check  for  new  potentially  relevant 
information and/or update the underlying model every n interactions. 
5  STARSPIRE 
StarSPIRE (Semantic Translation of Actions for Retrieval – Spatial 
Paradigm  for  Information  Retrieval  and  Exploration)  is  a  visual 
analytics  tool  prototype  that  implements  multi-model  semantic 
interaction  techniques  using  two  models  (relevancy  and  display 
layout)  [Figure  4].  StarSPIRE  is  built  upon  the  foundation  of 
ForceSPIRE,  a  semantic  interaction  visual  analytics  tool  prototype 
for  exploring  unstructured  text  documents  [12].  StarSPIRE  and 
ForceSPIRE share a flexible spatial workspace (driven by a modified 
force-directed  layout  [12,  15])  and  several  semantic  interactions. 
This  system  extends  upon  previous  work  to  integrate  relevance-
based retrieval and layout models, provides richer visual encodings, 
leveraged.  StarSPIRE 
and  adds 
interactions 
dynamically  adjusts  how  many  data  points  are  displayed  by  using 
heuristic-based  relevance  metrics.  While 
its  predecessor  was 
designed specifically for use on large, high-resolution displays, the 
push-and-pull  nature  of  displayed  data  in  StarSPIRE  has  made  it 
usable regardless of display size. 
5.1 
Within the spatial workspace, document nodes are visually encoded 
to relate their relevance to the user’s high dimensional understanding 
of the data [Figure 5]. Node size and saturation are encoded to reflect 
how closely a document matches the entities the user has deemed 
important. Node size and saturation are calculated by summing all of 
the entity weights in a document, ranking these values, and sorting 
them  into  quartiles.  Quartiles  were  chosen  instead  of  absolute 

Visual Encodings 

the  semantic 

to 

Interactions 

ranking  to  optimize  the  node  drawing  process,  minimizing  the 
number  of  calculations  and  changes  required  with  each  user 
interaction. This was done to promote a quick interaction-feedback 
loop. 
These  encodings  give  the  illusion  of  a  third  dimension  in  the 
workspace where more important documents are in the foreground 
while less important documents fade into the background. However, 
unlike  a  true  three-dimensional  layout,  document  nodes  cannot 
overlap each other, preventing occlusion. 
Additionally, StarSPIRE provides visual cues for navigating the 
workspace.  Node  color  is  used  to  indicate  search  term  matches. 
Instead  of  showing  all  links  between  all  documents,  StarSPIRE 
restricts  the  edges  shown  to  those  connected  to  the  selected  node. 
Entities shared between documents are labelled on the edge, but are 
restricted  to  the  top  four  entities,  determined  by  their  importance 
weights. All nodes are labelled with their document’s titles in order 
to allow for easier navigation in the space and to allow users to track 
a  specific  node’s  movement  throughout  the  space.  Each  node’s 
outline color is used to denote its read or unread status in order to 
allow analysts to see which documents they have read and closed. 
Within each document, search terms are identified and the text color 
is changed to allow the terms to stand out for easier identification. 
These encodings were identified and/or adjusted through an informal 
usability requirements analysis of StarSPIRE. 
5.2 
StarSPIRE  begins  with  a  blank  spatial  workspace  with  documents 
loaded  into  memory.  The  user  then  executes  a  search  to  add 
documents  to  the  workspace.  This  grants  the  user  flexibility  for 
where  to  start  their  analysis  and  mimics  an  analyst  executing  a 
database  search  to  return  a  set  of  documents  with  which  to  begin 
their  analysis.  Granted,  this  supported  use  case  assumes  that  the 
analyst  is  conducting  a  directed  sensemaking  task.  This  does  not 
support the use case of being handed a stack of documents and told 
to  “see  if  there  is  anything  suspicious.”  In  this  scenario,  other 
methods, such as topic modelling, would be useful to aid the analyst 
in finding a starting point for their analysis. 
Documents  are  laid  out  using  a  modified  force-directed  layout 
where the spring attractive force between two nodes is determined by 
summing the weights of shared entities. Thus, the layout’s input is 
the displayed data for the current timestep and the weight vector for 
the  previous 
is  determined  by 
interpreting  user  interactions  [Table  2].  The  set  of  displayed 
documents is determined from a document relevance model. 
Users can then interact with the data to incrementally formalize 
their understanding of the data. These interactions include moving 
nodes,  pinning  nodes  to  create  spatial  landmarks,  resizing  nodes, 
collapsing open nodes, annotating documents, searching for terms, 
highlighting 
linking  document  nodes.  With  each 
interaction, the display layout updates to allow nodes to move about 
the space to reflect the new entity-weighting scheme. Additionally, 
the visual encodings are updated to reflect document relevance based 
on the entity weights. 

timestep.  The  weight  vector 

terms,  and 

Fig. 4. Implemented version of the multi-scale semantic interaction visualization pipeline. In StarSPIRE, a relevance model and a display layout 
model are used. With each user interaction, the perceived importance of terms updates, changing the spatial and the working set of data is 
modified. The dashed black arrow indicates typical force-directed layout interactions that do not influence the user’s interest model parameters. 

Fig. 5. StarSPIRE workspace, which is a node-link diagram connected by shared entities using a modified force-directed layout. Nodes represent 
closed documents, which are color-coded based on search terms. Node size and saturation encode document relevance, based on how well the 
document matches the user-driven entity-weighting scheme. Node outline color denotes read/unread status (white for unread, black for read). All 
nodes are labelled with their file names for easy tracking of documents as they move in the workspace. Edges radiate from the selected document 
node, labelled with shared entities. 

Moving nodes and pinning nodes have no impact on the entity 
weighting scheme, but serve to rearrange the spatial workspace to 
reflect the user’s organizational schema. These are traditional force-
directed layout actions. 
Resizing a document to make it larger or smaller increases or 
decreases the weight value of each entity contained in the document, 
respectively.  This  is  interpreted  as  relevance  feedback  and  the 
system updates the working set of documents appropriately.  
Minimizing  a  document  decreases  the  weight  values  of  all 
entities  contained  in  the  document.  Closing  a  document  also 
decreases the weight values of all entities contained in the document, 
but at a higher magnitude than minimization [Figure 6]. 
Resizing  a  node  to  make  it  larger  or  smaller  increases  or 
decreases the weight values of all entities contained in the document, 
respectively. Resizing a node is accomplished by selecting a node 
and using the mouse scroll button to alter the node’s size. If a node is 
made larger, the system queries for additional similar documents. If a 
node  is  made  smaller,  the  system  tracks  this  feedback  to  be  less 
likely to retrieve similar documents in the future. 
Annotating  a  document  adds  the  [new]  terms  to  the  typed-in 
document  and  increases  their  weight  values.  The  system  retrieves 
documents matching the entities contained in the annotation. 
Searching for a term increases that term’s associated weight and 
retrieves  documents  matching  the  search  term.  This  action  returns 
more matching documents than other semantic interactions because 
it is an explicit request for related information. 
Highlighting a term or phrase increases the weight values of all 
highlighted  entities  and 
the 
highlighted entities. 
Overlapping  documents  increases  the  weight  values  of  all 
common  entities  between  the  two  overlapping  documents  and 
retrieves  documents  matching  the  shared  entities  between  the 
documents. 
With each semantic interaction, the spatial layout updates and, if 
necessary, the system queries for new relevant documents and adds 

retrieves  documents  matching 

Relevance-Based Retrieval 

them, if any, to the workspace. Because StarSPIRE is designed to 
test the usability of semantic interactions operating across multiple 
models (and theoretically vastly different levels of data scale), we 
have thus far only tested the system on smaller datasets (e.g. on the 
order  of  10,000  documents).  As  a  result,  StarSPIRE  is  capable  of 
updating all models (display layout and information retrieval) with 
each user interaction as well as storing the entire dataset in memory. 
This  will  likely  not  be  the  case  with  much  larger  datasets.  Future 
implementations  will  likely  require  database  support  or  leverage 
cloud-based architectures. 
5.3 
We selected a simple modified linear search algorithm to serve as the 
relevance model. When StarSPIRE increases an entity’s importance, 
it searches the backend database for additional documents to add to 
the  workspace  and  adds  the  top  n  search  results  that  exceed  a 
relevance  metric  [Figure  7].  Currently,  a  maximum  of  twenty 
documents are added if the user executes a search and a maximum of 
eight documents are added from all other semantic interactions that 
result  in  a  request  for  more  information.  Additional  data  can  be 
obtained, if available, by repeating the interaction. This allows for 
progressive disclosure of information to keep too much information 
being added to the display at one time, which could overwhelm the 
analyst. The spatial layout then updates to accommodate these new 
data points. 
The  current  relevancy-based  threshold  allows  for  a  variable 
number of documents in the working set of data. By not restricting 
the number of documents that can be present on the screen, the user 
is  capable  of  maintaining  as  much  information  as  inferred  to  be 
relevant  to  their  sensemaking  task.  In  the  future,  this  could  be 
updated  to  allow  for  additional  heuristics,  such  as  the  number  of 
opened/closed document nodes, node proximity to the center of the 
workspace,  or  how  recently  a  document  has  been  added  to  the 
workspace. 

Table 2. StarSPIRE’s interpretation of semantic interactions in terms of 
the parametric updates to the model of the user’s interests. 
Interaction 
Resize document 
Minimize document 
Close document 

Model Parameter Effect 
Scale all weights of terms in the document 
Down-weight terms by 25% 
Down-weight terms by or 40%, remove from 
working set 
Scale all weights of terms in the document 
Up-weight terms by a constant, add terms to 
model 
Up-weight term by a constant, add terms to 
model, adjust relevance threshold as needed 
Up-weight terms by a constant 
Up-weight shared terms by a constant 

Resize node 
Annotation 

Search 

Highlight 
Overlap documents 

respectively 

 
New  information  can  be  added  to  the  display  implicitly  or 
explicitly.  The  user  can  explicitly  query  for  new  documents  by 
executing  a  search.  Implicit  queries  are  constructed  using  the 
interpreted  semantic  interactions  [Table  2].  These  implicit  queries 
are typically more complex than the explicit queries, which include 
single terms. The implicit queries often include multiple terms and 
their associated relative importance. 
Documents  that  fall  below  the  current  relevance  threshold  are 
removed  from  the  display,  leaving  the  user  with  a  working  set  of 
documents that match the user’s interests in the data. 
This retrieval process was chosen in order to support incremental 
changes  to  the  information  on  the  display  as  well  as  real-time 
interaction. If data were not merely added (or subtracted) from the 
displayed documents, the user could be presented with an entirely 
new  set  of  displayed  data,  which  could  be  disorienting.  Thus,  we 
prefer an incremental approach. 
The  psuedocode  for  StarSPIRE’s  retrieval  algorithm  is  as 
follows: 
 
retrieveDocuments(docsDisp, docsHid, Wt, Wt-1, limit): 
//docsDisp = list of documents displayed 
//docsHid = list of documents not displayed 
//  Wt,  Wt-1  =  array  of  entity  weights  at  timestep  t  and  t-1, 
//limit = maximum documents to add to the display 
1. 
2. 
3. 
4. 
5. 
6. 
7. 
8. 
9. 
10. 
11. 
12. 
13. 
14. 
15. 
16. 
17. 
18. 
19. 
20. 
21. 

docMatches = empty list of documents 
ΔW[] = Wt – Wt-1 
for i = 1 : docsHid.length 
     weight = 0 
     for j = 1 : ΔW.length 
          if(docsHid[i].hasEntity(Wt.entity) 
               weight += ΔW[j] 
     if(weight > 0) 
          docMatches.add(docsHid[i]) 
for i = 1 : docMatches.length 
     docMatches[i].relevance =  
for i = 1 : docDisp.length 
     docDisp[i].relevance =  
docsRanked[] = Sort(docMatches) based on relevance 
for i = 1 : min(limit, docsRanked.length) 
     docsDisp.add(docsRanked[i]) 
     docsHid.remove(docsRanked[i]) 
docsDisp[] = Sort(docsDisp) based on relevance 
for i = 1 : docsDisp.length 
     docsDisp[i].rank = i 
return docsDisp 

sum(e.weight for each Entity e in docMatches[i] 

sum(e.weight for each Entity e in docDisp[i]) 

 
In  the  algorithm,  the  positive  changes  in  entity  weights  are 
identified  to  determine  which  terms  have  increased  in  importance 
and  should  be  used  to  identify  new  documents  to  add  to  the 
workspace.  Step  two  computes  the  dot  product  between  the  entire 

backend  dataset  with  the  change  in  entity  weights  vector  (ΔW), 
which  results  in  a  single  number  for  each  document.  To  optimize 
performance, we discard all documents whose value is zero, because 
they do not contain any entities whose weights were increased within 
the past timestep. This results in the set of documents docMatches, 
which are candidates for addition to the workspace. The weights of 
entities contained in these candidate documents are summed using 
the current weighting scheme to obtain a score that reflects how well 
each document matches what the user has deemed important in the 
dataset  thus  far.  These  values  are  then  sorted  and  the  top  n 
documents are added to the list of documents included in the spatial 
workspace  at  timestep  t  and  removed  from  the  set  of  hidden 
documents (i.e. documents in the dataset not included in the spatial 
workspace). This results in the set of documents displayed at the next 
timestep, t+1. The algorithm returns this modified set of documents 
(which could be the same as the previous timestep if no documents 
are  chosen  to  be  added).  The  updated  rank  of  each  displayed 
document  is  stored  as  an  attribute  of  each  document.  This  rank 
information allows the system to apply appropriate visual encodings 
to  denote  how  closely  documents  match  the  user-imparted  entity 
importance values. 
 The documents returned from the information retrieval algorithm 
are then used as input, along with the current weighting scheme at 
timestep  t,  to  the  modified  force-directed  layout  to  determine  the 
two-dimensional layout of the data points for timestep t+1. 
We chose to select candidate documents first instead of applying 
the  weight  vector  across  all  documents  in  the  dataset  in  order  to 
provide  an  incremental  update  to  the  displayed  data.  If  we  had 
applied  W(t)  to  the  entire  dataset,  it  is  possible  that  the  displayed 
data would be much different in each iteration.  
Similarly,  selecting  candidate  documents  and  eliminating  all 
documents which do not contain any of the newly increased entities 
allows  us  to  optimize  the  retrieval  process.  This  is  crucial  for 
maintaining a quick interaction-feedback loop. 
The  linear  nature  of  this  algorithm  prevents  it  from  scaling  to 
much larger document collections. More advanced retrieval methods, 
either  running  in  real  time  or  as  a  background  process,  could  be 
substituted in order to handle larger amounts of data. 
6  USAGE SCENARIO 

(“Blue 

activities 

“unexpected 

Iguanodon”) 

concerning  wildlife 

To  demonstrate  StarSPIRE’s  functionality,  we  used  the  VAST 
2007  Challenge  Dataset 
[17].  Because 
StarSPIRE  is  currently  designed  to  operate  on  unstructured  text 
documents only, we omitted all images and spreadsheets from the 
dataset, resulting in approximately 1,500 text files. Blog entries that 
were included in the data were converted into text files, one for each 
blog entry. Preliminary entity extraction was done on the dataset.  
The  challenge  task  is  an  open-ended  sensemaking  task  to 
investigate 
law 
enforcement, endangered species issues, and ecoterrorism” [17]. We 
present the following usage scenario to demonstrate how StarSPIRE 
can leverage the MSI technique. 
The  user  began  with  a  search  for  “chinchilla.”  This  was 
unsurprising,  because  the  dataset  contained  a  directory  titled 
“Chinchillas.” She read through several documents, arranging them 
in  the  display  based  on  document  similarity.  The  user  then  began 
highlighting information regarding chinchillas, which branched into 
additional  endangered  species.  This  loosely  structured  analysis 
continued until the user read a document concerning a musical artist 
owning an extremely large number of exotic animals whose actions 
did not seem to match his words regarding animal conservation. The 
analyst denoted this as suspicious and began investigating it further. 
This investigation was driven through highlighting the artist’s name 
and  the  name  of  his  animal  sanctuary,  which  imported  many 
documents onto the display, some of which had a large node size. 
The analyst opened the largest new nodes first. 
[Figure 8] shows the evolution of the user’s spatial organization 
schemas through the sensemaking task. Clusters of documents were 

Fig.  6.  Multi-model  semantic  interaction  in  StarSPIRE:  Document  relevance  feedback.  Left:  The  user  explicitly  searches  for  documents 
containing the term “POK.” Documents matching this search term are added to the display and arranged using a “near = similar” metaphor. 
Middle:  The  user  selects  the  outlying  document,  opens  it,  then  closes  the  document  to  remove  it  from  the  workspace.  Right:  The  system 
decreases the entity weights of the terms contained in the deleted document. The system updates the visual encodings to reflect this relevancy 
feedback and updates the display layout. 

the  choice  of  documents 

moved  around  the  screen  and  a  mixture  of  visual  encodings  and 
document  proximity  motivated 
to 
investigate next. Furthermore, it can be seen that the user initially 
executed  two  searches  to  obtain  some  initial  documents,  but  then 
opted for other multi-scale semantic interaction techniques to obtain 
new documents (e.g. highlighting, linking documents – denoted by 
the purple bars, and annotating documents). Document annotations 
were used to record hypotheses and insights (e.g. “r’Bert is r’Bear?” 
and “r’Bear might have monkeypox”). In the later stages of analysis, 
searches were used primarily to label the space, serving as reminders 
of  which  documents  concerns  which  persons  or  topics.  However, 
they  were  also  used  to  ensure  that  important  information  or 
documents had not been overlooked. 
Once  the  user  identified  suspicious  activity  regarding  a  large 
exotic animal reservation, it became apparent that many documents 
were  interconnected  via  several  subplots.  As  her  understanding  of 
the dataset evolved, so did her spatial representation. For example, 
two documents that were initially considered “not quite relevant, but 
interesting  enough  to  not  minimize”  concerning  an  outbreak  of  a 
disease were initially placed in the upper right hand corner of the 
display.  After  realizing  that  the  owner  of  the  large  exotic  animal 
sanctuary  had  contracted  the  same  disease,  she  moved  the  two 
documents down next to the exotic animal sanctuary documents. 
Highlights,  document  annotations,  and  document  linking  were 
primarily used to obtain new documents in the workspace. Searches 
were  executed  to  check  for  additional  information  on  important 

persons,  but  also  used  to  label  the  spatial  workspace.  After 
approximately  ninety  minutes  of  analyzing  the  data,  the  user 
concluded  that  she  had  a  sufficient  understanding  of  the  plot  and 
subplots in the data. 
The user’s results were compared with the known ground truth 
solution. The user correctly identified four out of five subplots in the 
data. The use added 145 documents to the workspace, which is 10% 
of the actual dataset. 47 documents were opened and 33 remained 
open at the conclusion of the sensemaking session. The user made 
eight  searches,  four  document  annotations,  and  21  highlights.  45 
documents were added through searches, whereas the remaining 100 
documents  were  added 
through  other  multi-scale  semantic 
interactions (e.g. highlight, annotate, document proximity). 
Out of 26 documents relevant to the final solution, the user had 
added 18 of them to the workspace. Six of these 18 documents were 
added through an explicit search, while twelve were added through 
implicit multi-scale semantic interactions. 13% (6/45) of documents 
added  through  explicit  searches  were  relevant  to  the  solution,  and 
12%  (12/100)  of  documents  added  through  implicit  searches  were 
relevant  to  the  solution.  Therefore,  the  documents  that  originated 
from  multi-scale  semantic  interactions  were  similar  in  quality  to 
those that originated from explicit searches from the user. 
Out of approximately 1,500 documents, 47 were read. Thus, the 
analyst was able to construct 80% (four out of five subplots) of the 
solution while only reading 3.13% of the documents in the dataset. 
While  the  results  of  this  usage  scenario  appear  promising,  further 

Fig.  7.  Multi-model  semantic  interaction  in  StarSPIRE.  Left:  The  user  explicitly  searches  for  documents  containing  the  word  “chinchilla.” 
Documents  matching  this  search  term  are  added  to  the  display  and  arranged.  Middle:  The  user  selects  a  document  to  read.  To  prevent 
occlusion, nodes are pushed aside but still maintain their relationships to other documents as much as possible. Right: The user highlights the 
entity “PETA.” Eight new documents are retrieved and added to the display. Documents rearrange due to the shift in weighting scheme – 
documents that contain “chinchilla” and “PETA” (as well as other shared terms) are brought closer together in the middle, documents that 
contain only “chinchilla” are pushed to the top and left, and documents that only contain “PETA” are pushed to the bottom and right. 

work is required to evaluate the performance of MSI techniques as 
compared to existing SI techniques. 
7  DISCUSSION 
7.1 

Comparison to Existing Techniques 

Most similar to our system prototype is ForceSPIRE [10], which 
implements  semantic 
the 
exploration  of  small  text  datasets.  However,  ForceSPIRE  operates 
using a single model (display layout), which hinders data analysis 

techniques  and  allows 

interaction 

Fig. 8. Organizational schema evolution throughout the use case. Top: 
Early  analysis  into  chinchillas  and  endangered  species  that  are 
growing 
in  popularity  with  a  seemingly  unrelated  outbreak  of 
monkeypox. Middle: Intermediate analysis that has linked chinchillas, 
the  monkeypox  outbreak,  and  a  rapper  keeping  a  suspicious  exotic 
animal  sanctuary.  Bottom:  Final  spatial 
the 
relationships  between  multiple  subplots  in  the  dataset,  along  with 
searches  that  have  been  executed  to  label  the  space  as  well  as 
hypotheses entered as annotations to documents. 

layout  showing 

in  StarSPIRE 

(several  seconds) 

compared to StarSPIRE. 
Data loading and processing takes much longer in ForceSPIRE  
(several  minutes) 
than 
for 
moderately sized datasets on the order of 1,000 to 1,500 documents. 
Most  of  this  delay  is  computing  the  force-directed  layout  and  the 
relationship between all documents. Because StarSPIRE stores most 
of the data and only displays a smaller working set of documents, 
processing is much faster. For these same reasons, the interaction-
feedback loop is slower in ForceSPIRE. Thus, the large scale model 
relieves much of the computational overhead from the small scale 
model. 
Furthermore,  we  have  extended  the  visual  encodings  to  give  a 
richer  overview  of  the  displayed  documents  and  have  enabled  the 
users to provide positive and negative relevance feedback, which is 
reflected in a separate model. 
Instead  of  comparing  these  tools  directly,  we  will  design  a 
comparative  user  study  using  StarSPIRE  with  MSI  techniques 
enabled and with only SI techniques enabled. Users will be presented 
with  a  subset  of  the  data  on  the  screen,  alleviating  ForceSPIRE’s 
inability  to  display  more  than  a  few  hundred  documents  on  the 
screen. With the SI-only condition, they will be required to explicitly 
request additional information through either through written queries 
or query-by-example (e.g. “show me more like this document”). This 
will allow for a comparison between the two techniques in regard to 
how information is retrieved and interacted with in the workspace. 
Many  existing  systems  transform  user  interactions  into  model 
feedback to drive a spatial layout. Dis-function [6] enables users to 
inject feedback into a spatialization model by repositioning points, 
allowing  the  system  to  incrementally  update  the  distance  function 
driving  the  low-dimensional  projection  of  high-dimensional  data. 
Similarly,  Visual  to  Parametric  Interaction  [20]  infers  analytic 
reasoning  from  users  moving  and/or  highlighting  data  points  in  a 
spatial  projection  of  high-dimensional  data.  These  interactions  are 
converted into parametric updates to change the spatial layout. Work 
in  observation-level 
[14]  also  allows  document 
repositioning to drive an underlying spatialization model. However, 
all of these techniques are limited to using a single model, whereas 
our  technique  leverages  multiple  models  that  are  capable  of 
operating at different levels of data scale. 
Document Selection Models 
7.2 

interaction 

The  model  used  here  is  only  one  example  of  many  possible 
models for document selection. We chose this approach in order to 
focus on the interactions within StarSPIRE and their mappings to the 
parameters  driving  the  retrieval  results.  However,  this  approach  is 
not  practical  for  extremely  large  datasets  with  large  numbers  of 
entities. The relevancy-based retrieval algorithm used in StarSPIRE 
runs in O(nm) time where n is the number of documents and m is the 
number  of  entities,  due  to  the  initial  search  process.  We  have 
optimized the algorithm to perform the sorting operations on a subset 
of  the  possible  documents  to  improve  this  runtime.  However,  the 
worst-case scenario is that all, or nearly all, documents in the dataset 
match  an  entity  that  has  been  upweighted  (e.g.  “the”).  Even  in 
average and best case scenarios, this algorithm is not an ideal choice 
for scaling to extremely large datasets. Parallelization is one option 
for  speeding  up  the  algorithm,  but  we  also  wish  to  consider 
alternative models for retrieval. 
Future  implementations  of  multi-model  semantic  interaction 
should  consider  the  streaming  and  ever-growing  nature  of  data. 
Accordingly, streaming or a mixture of dynamic and static models 
could  be  employed.  Further  methods  of  handling  this  type  and 
amount of data could take a multi-threaded or parallel approach. 
In addition to optimizations for algorithm performance, different 
models  could  be  leveraged  at  the  display  layout  and  information 
retrieval  levels.  Different  models  naturally  lend  themselves  to 
different  interactions.  For  example,  moving  data  points  or  pinning 
them as spatial landmarks could be interpreted by algorithms such as 
Latent Semantic Indexing [9], Principal Component Analysis [23], or 
Multi-Dimensional Scaling [31], among others, to adjust the lower-

dimensional space of all of the documents to create a representation 
that better fits the user’s high-dimensional understanding of the data, 
thus producing subjectively better search results. 
7.3  Multi-Model Visualization Pipeline 

The  flexibility  of  generalized  multi-model  semantic  interaction 
enables researchers to explore many alternative models, methods of 
interpreting interactions, and mappings to analytical reasoning.  
There are multiple options for routing of interactions to models. 
For some interactions (e.g. changing data point distances), it may be 
appropriate to propagate the interaction to each underlying model up 
the  levels  of  scale.  However,  for  other  interactions  (e.g.  giving 
relevance feedback on a document), it may be more appropriate to 
send this feedback directly to a specific model. Further complicating 
matters, the same interaction may have a different intent based on 
context. For example, a user may construct a cluster of documents. 
The clustered documents could be important and relevant to the user, 
or  the  user  could  be  grouping  them  in  order  to  filter  out  other 
irrelevant documents from the main display area. In this example, it 
is possible that this distinction could be captured by the proximity of 
the cluster to the periphery or center of the display.  Investigating 
alternative  approaches  to  enabling  users  to  naturally  express  these 
intents  within  the  visual  interactions  remains  an  open  research 
question. 
It may be appropriate to maintain several models for each level of 
data  scale  and  dynamically  adapt  which  is  used  based  on  which 
model is able to best incorporate the user’s feedback. For example, 
having multiple display layout models allows the system to choose 
the one that converges the best or has the lowest deviation from the 
user’s  feedback.  We  plan  on  investigating  how  the  notion  of 
competing  models  changes  the  performance  of  the  system,  both 
qualitatively  and  quantitatively.  Maintaining  multiple  models  for 
accomplishing a single task could result in a better approximation of 
the  high-dimensional  data,  and  we  will  investigate  methods  for 
providing visual feedback to inform users of these switches.  
Due to the runtime of these algorithms and the time required to 
invert  the  models  to  compute  a  new  representation,  it  may  not  be 
practical  to  apply  interactive  feedback  to  every  model  at  each 
interaction. Slower models could be told to invert and execute after a 
certain  number  of  interactions  and  instructed  to  run  in  the 
background. However, display-level models should be updated with 
each  interaction  in  order  to  provide  the  user  with  immediate 
feedback.  Therefore,  whichever  models  are  chosen  to  drive  the 
spatial layout should execute quickly. 
7.4 

Limitations 

StarSPIRE  is  currently  designed  for  text  analysis.  Multimedia 
cannot currently be incorporated in the tool. Future implementations 
could  overcome  this  limitation  by  using  metadata  and  user-
designated  tags  for  multimedia  files.  Although  StarSPIRE  is  not 
equipped  to  handle  generic  high-dimensional  data,  multi-model 
semantic interaction techniques can be applied across data types. As 
multi-model semantic interaction is an extension of observation-level 
interaction for high-dimensional data [32], these systems (ex. [6, 20]) 
are suitable for extension to multi-model semantic interaction. 
We have applied multi-model semantic interaction techniques to 
sensemaking  tasks,  but  have  not  attempted  other  analytical  tasks, 
such  as  social  network  analysis.  Additionally,  we  have  not  yet 
empirically evaluated if users understand and accept the mappings of 
interactions  to  model  feedback.  This  will  be  conducted  in  future 
work. 
StarSPIRE  has  currently  been  tested  on  over  10,000  text 
documents that had an entity extractor run on them, resulting in over 
20,000 distinct entities. Total loading time was under one minute and 
interactions  could  be  completed  in  close  to  real  time  (queries  are 
typically executed in under three seconds). Due to the nature of the 
retrieval model, the execution time depends largely on the size of the 
set of candidate documents, which need to be sorted and ranked, then 

compared against a relevance threshold. This problem is exacerbated 
by  document  collections  with  extremely  large  numbers  of  entities. 
Therefore, broad searches tend to have slower response times. This 
limitation  could  be  overcome  by  implementing  more  sophisticated 
and  optimized  algorithms.  StarSPIRE  is  not  equipped  to  handle 
much larger datasets (e.g. on the order of 100,000 documents and 
higher).  Moving  to  a  database  or  cloud-based  architecture  and 
implementing different algorithms could overcome this limitation. 
8  CONCLUSION 

includes 

interaction 

Future  work 

In  this  paper,  we  have  introduced  the  concept  of  multi-model 
semantic interaction, which harnesses user interactions to manipulate 
underlying  models.  We  have  presented  an  instantiation  of  this 
technique that operates across multiple levels of data scale. Along 
with  this  technique,  we  introduced  a  generalized  visualization 
pipeline  for  semantic  interaction  using  multiple  models.  We  have 
shown  an  example 
implementation  of  multi-model  semantic 
interaction  techniques  through  the  visual  analytics  tool  prototype, 
StarSPIRE. Using this prototype, we demonstrated the functionality 
of  multi-model  semantic 
techniques.  Finally,  we 
concluded  with  a  discussion  of  multi-model  semantic  interaction 
techniques. 
We  plan  on  conducting  a  comparative  user  study  using 
StarSPIRE to observe the differences between explicitly constructed 
queries and the addition of implicitly constructed queries. This will 
serve  to  compare  multi-model  semantic  interaction  with  semantic 
interaction. The study will use one of the VAST Challenge datasets 
in order to quantitatively evaluate user performance. 
investigating  additional  multi-model 
semantic  interaction  techniques,  visual  encodings,  and  models. 
Additionally,  we  plan  on  creating  a  visual  representation  of  the 
dataset to grant users an overview of the document content. We wish 
to practically apply multi-model semantic interaction techniques to 
much  larger  datasets,  including  streaming  data.  This  will  likely 
require 
implementing  additional  algorithms  and  cloud-based 
architectures. 
We  hope  that  multi-model  semantic  interaction  will  serve  as  a 
usable means of interacting with multiple models for data analytics. 
ACKNOWLEDGMENTS 
This work was supported in part by NSF grant IIS-1218346. 
REFERENCES 
[1]  Andrews,  C.,  Endert,  A.  and  North,  C.  Space  to  think:  large  high-
resolution  displays  for  sensemaking  Proceedings  of  the  SIGCHI 
conference on human factors in computing systems, ACM, 2010, 55-64. 
[2]  Andrews,  C.  and  North,  C.  Analyst’s  Workspace:  An  Embodied 
Sensemaking Environment For Large, High-Resolution Displays IEEE 
visual analytics science and technology, IEEE, 2012, 123-131. 

[3]  Belew,  R.K.,  Adaptive  information  retrieval:  Using  a  connectionist 
representation  to  retrieve  and  learn  about  documents.  in  ACM  SIGIR 
Forum, (1989), ACM, 11-20. 

[4]  Benedikt, M., Cyberspace: some proposals. in Cyberspace, (1991), MIT 

Press, 119-224. 

[5]  Bradel,  L.,  Self,  J.Z.,  Endert,  A.,  Hossain,  M.S.,  North,  C.  and 
Ramakrishnan,  N.,  How  analysts  cognitively  ""connect  the  dots"".  in 
Intelligence  and  Security  Informatics  (ISI),  2013  IEEE  International 
Conference on, (2013), 24-26. 

[6]  Brown,  E.T.,  Liu,  J.,  Brodley,  C.E.  and  Chang,  R.,  Dis-function: 
Learning  distance  functions  interactively.  in  Visual  Analytics  Science 
and Technology (VAST), 2012 IEEE Conference on, (2012), IEEE, 83-
92. 

international ACM SIGIR conference on Research and development in 
information retrieval, (1991), ACM, 262-269. 

[26]  Maron, M.E. and Kuhns, J.L. On relevance, probabilistic indexing and 
information retrieval. Journal of the ACM (JACM), 1960, 7 (3). 216-
244. 

[27]  Olsen,  K.A.,  Korfhage,  R.R.,  Sochats,  K.M.,  Spring,  M.B.  and 
Williams,  J.G.  Visualization  of  a  document  collection:  The  VIBE 
system. Information Processing & Management, 1993, 29 (1). 69-81. 

[28]  Pirolli, P. and Card, S. The Sensemaking Process and Leverage Points 
for Analyst Technology as Identified Through Cognitive Task Analysis 
International conference on intelligence analysis, 2005. 

[29]  Shipman  III,  F.M.  and  Marshall,  C.C.  Formality  considered  harmful: 
Experiences,  emerging  themes,  and  directions  on  the  use  of  formal 
representations in interactive systems. Computer Supported Cooperative 
Work (CSCW), 1999, 8 (4). 333-352. 

[30]  Stasko,  J.,  Görg,  C.  and  Liu,  Z.  Jigsaw:  supporting  investigative 
analysis  through  interactive  visualization.  Information  visualization, 
2008, 7 (2). 118-132. 

[31]  Torgerson,  W.  Multidimensional  scaling:  I.  Theory  and  method. 

Psychometrika, 1952, 17 (4). 401-419. 

[32]  Vogt, K., Bradel, L., Andrews, C., North, C., Endert, A. and Hutchings, 
D. Co-located Collaborative Sensemaking on a Large High-Resolution 
Display with Multiple Input Devices Conference on Human-Computer 
Interaction, Springer, 2011, 589-604. 

[33]  Wise, J.A., Thomas, J.J., Pennock, K., Lantrip, D., Pottier, M., Schur, 
A.  and  Crow,  V.,  Visualizing  the  non-visual:  spatial  analysis  and 
interaction  with  information  from  text  documents.  in  Information 
Visualization, 1995. Proceedings., (1995), IEEE, 51-58. 

[34]  Wright, W., Schroh, D., Proulx, P., Skaburskis, A. and Cort, B., The 
Sandbox  for  analysis:  concepts  and  methods.  in  Proceedings  of  the 
SIGCHI conference on Human Factors in computing systems, (2006), 
ACM, 801-810. 

[35]  Yi,  J.S.,  Melton,  R.,  Stasko,  J.  and  Jacko,  J.A.  Dust  &  magnet: 
multivariate  information  visualization  using  a  magnet  metaphor. 
Information visualization, 2005, 4 (4). 239-256. 

[7]  Card,  S.K.  Visualizing  retrieved  information:  A  survey.  Computer 

Graphics and Applications, IEEE, 1996, 16 (2). 63-67. 

[8]  Choo, J. and Park, H. Customizing computational methods for visual 
analytics  with  big  data.  IEEE  Computer  Graphics  and  Applications, 
2013, 33 (4). 22-28. 

[9]  Deerwester,  S.,  Dumais,  S.T.,  Furnas,  G.W.,  Landauer,  T.K.  and 
Harshman,  R.  Indexing  by  latent  semantic  analysis.  Journal  of  the 
American society for information science, 1990, 41 (6). 391-407. 

[10]  Endert,  A.  Semantic  Interaction  for  Visual  Analytics:  Inferring 
Analytical Reasoning for Model Steering, Virginia Polytechnic Institute 
and State University, 2012. 

[11]  Endert,  A.,  Bradel,  L.  and  North,  C.  Beyond  control  panels:  Direct 
manipulation for visual analytics. Computer Graphics and Applications, 
IEEE, 2013, 33 (4). 6-13. 

[12]  Endert, A., Fiaux, P. and North, C. Semantic Interaction for Visual Text 
Anayltics Proceedings of the SIGCHI conference on Human factors in 
computing systems, ACM, 2012, 473-482. 

[13]  Endert, A., Fox, S., Maiti, D., Leman, S. and North, C. The semantics of 
clustering: analysis of user-generated spatializations of text documents 
Proceedings  of  the  International  Working  Conference  on  Advanced 
Visual Interfaces, ACM, Capri Island, Italy, 2012, 555-562. 

[14]  Endert,  A.,  Han,  C.,  Maiti,  D.,  House,  L.,  Leman,  S.  and  North,  C., 
Observation-level interaction with statistical models for visual analytics. 
in  Visual  Analytics  Science  and  Technology  (VAST),  2011  IEEE 
Conference on, (2011), IEEE, 121-130. 

[15]  Fruchterman,  T.M.  and  Reingold,  E.M.  Graph  drawing  by  force-
directed placement. Software: Practice and experience, 1991, 21 (11). 
1129-1164. 

[16]  Green,  T.M.,  Ribarsky,  W.  and  Fisher,  B.  Building  and  applying  a 
human cognition model for visual analytics. Information Visualization, 
2009, 8 (1). 1-13. 

[17]  Grinstein, G., Plaisant, C., Laskowski, S., O'Connell, T., Scholtz, J. and 
Whiting, M., VAST 2007 contest-blue iguanodon. in IEEE Symposium 
on Visual Analytics Science and Technology, (2007), IEEE, 231-232. 

[18]  Hearst, M.A., TileBars: visualization of term distribution information in 
full text information access. in Proceedings of the SIGCHI conference 
on Human factors in computing systems, (1995), ACM Press/Addison-
Wesley Publishing Co., 59-66. 

[19]  Hossain, M.S., Andrews, C., Ramakrishnan, N. and North, C., Helping 
Intelligence  Analysts  Make  Connections.  in  Scalable  Integration  of 
Analytics and Visualization, (2011). 

[20]  Hu,  X.,  Bradel,  L.,  Maiti,  D.,  House,  L.  and  North,  C.  Semantics  of 
Directly  Manipulating  Spatializations.  Visualization  and  Computer 
Graphics, IEEE Transactions on, 2013, 19 (12). 2052-2059. 

[21]  i2. Analyst Notebook, www.i2.co.uk, 2007. 
[22]  Jeong, D.H., Ziemkiewicz, C., Fisher, B., Ribarsky, W. and Chang, R., 
iPCA:  An  Interactive  System  for  PCA‚Äêbased  Visual  Analytics.  in 
Computer Graphics Forum, (2009), Wiley Online Library, 767-774. 

[23]  Jolliffe, I.T. Principal component analysis. Springer-Verlag New York, 

[24]  Lamping, J., Rao, R. and Pirolli, P., A focus+ context technique based 
on hyperbolic geometry for visualizing large hierarchies. in Proceedings 
of  the  SIGCHI  conference  on  Human  factors  in  computing  systems, 
(1995), ACM Press/Addison-Wesley Publishing Co., 401-408. 

[25]  Lin, X., Soergel, D. and Marchionini, G., A self-organizing semantic 
map  for  information  retrieval.  in  Proceedings  of  the  14th  annual 

1986. 

","{""0"":{""0"":""search*"",""1"":""searches*"",""2"":""matching*"",""3"":""docmatches*"",""4"":""retrieves*""},""1"":{""0"":""added*"",""1"":""modified*"",""2"":""read*"",""3"":""determined*"",""4"":""labelled*""},""2"":{""0"":""multi"",""1"":""human*"",""2"":""animal*"",""3"":""exotic*"",""4"":""chinchilla""},""3"":{""0"":""visualization*"",""1"":""spatialization*"",""2"":""analytics"",""3"":""dimensionality*"",""4"":""timestep*""},""4"":{""0"":""models*"",""1"":""information"",""2"":""terms"",""3"":""techniques*"",""4"":""analysts""},""pos"":{""0"":1,""1"":2,""2"":3,""3"":4,""4"":5}}",2014,{},False,False,conferencePaper,False,8QJPPCPZ,[],self.user,"{""C"":{""0"":9.3683420506,""1"":6.7714604384,""10"":6.5996080475,""11"":6.0524492255,""12"":6.6837989664,""13"":5.999839367,""14"":13.0948776567,""15"":9.9466910742,""16"":25.8034484167,""17"":10.2710679979,""18"":7.7413806884,""19"":20.6434058174,""2"":8.2739043137,""20"":12.4771746792,""21"":6.401740121,""22"":20.5825001448,""23"":11.055433094,""24"":5.2022314726,""25"":8.3064955628,""26"":16.839377112,""27"":11.7445695188,""28"":5.2311307638,""29"":9.9341492755,""3"":6.1699977263,""30"":8.2052800073,""31"":6.0514030324,""32"":7.165090443,""33"":9.6159423065,""34"":6.7592648265,""35"":6.6421386411,""36"":5.4028469428,""37"":4.8059657891,""38"":5.3090436983,""39"":13.5332029799,""4"":12.2194066119,""40"":11.7269360947,""41"":10.6587403469,""42"":6.0133214027,""43"":11.5238679106,""44"":10.0301087886,""45"":10.1429565523,""46"":7.7734537339,""47"":5.0484226527,""48"":7.0512339865,""49"":6.2214376599,""5"":14.9687258375,""50"":7.0061310867,""51"":6.2114353917,""52"":6.2114353917,""53"":6.7434412298,""54"":6.749824881,""55"":7.431461881,""56"":5.3798487603,""57"":5.7325721666,""58"":6.3979163053,""59"":6.6083884937,""6"":5.6998674018,""60"":6.6225592332,""61"":4.8201141065,""62"":4.9740510843,""63"":5.2065676675,""64"":5.1374560228,""65"":4.9011978809,""66"":5.5405730254,""7"":6.6715821979,""8"":6.7642167346,""9"":6.5677556754},""Unnamed: 0"":{""0"":0,""1"":1,""10"":10,""11"":11,""12"":12,""13"":13,""14"":14,""15"":15,""16"":16,""17"":17,""18"":18,""19"":19,""2"":2,""20"":20,""21"":21,""22"":22,""23"":23,""24"":24,""25"":25,""26"":26,""27"":27,""28"":28,""29"":29,""3"":3,""30"":30,""31"":31,""32"":33,""33"":34,""34"":35,""35"":36,""36"":37,""37"":38,""38"":39,""39"":40,""4"":4,""40"":41,""41"":42,""42"":43,""43"":44,""44"":45,""45"":46,""46"":47,""47"":48,""48"":49,""49"":50,""5"":5,""50"":51,""51"":52,""52"":53,""53"":54,""54"":55,""55"":56,""56"":57,""57"":58,""58"":59,""59"":60,""6"":6,""60"":62,""61"":63,""62"":64,""63"":65,""64"":66,""65"":67,""66"":68,""7"":7,""8"":8,""9"":9},""count"":{""0"":286,""1"":220,""10"":52,""11"":48,""12"":46,""13"":46,""14"":46,""15"":44,""16"":44,""17"":40,""18"":38,""19"":38,""2"":178,""20"":34,""21"":32,""22"":28,""23"":26,""24"":26,""25"":26,""26"":24,""27"":22,""28"":22,""29"":20,""3"":166,""30"":20,""31"":20,""32"":18,""33"":18,""34"":16,""35"":16,""36"":16,""37"":16,""38"":16,""39"":16,""4"":120,""40"":16,""41"":16,""42"":14,""43"":14,""44"":12,""45"":12,""46"":12,""47"":10,""48"":10,""49"":10,""5"":114,""50"":10,""51"":10,""52"":10,""53"":10,""54"":10,""55"":10,""56"":8,""57"":8,""58"":8,""59"":8,""6"":108,""60"":8,""61"":8,""62"":8,""63"":8,""64"":8,""65"":8,""66"":8,""7"":88,""8"":74,""9"":58},""exemplar"":{""0"":null,""1"":null,""10"":""*"",""11"":""*"",""12"":null,""13"":""*"",""14"":null,""15"":""*"",""16"":null,""17"":null,""18"":null,""19"":""*"",""2"":null,""20"":null,""21"":null,""22"":null,""23"":null,""24"":null,""25"":""*"",""26"":null,""27"":null,""28"":""*"",""29"":null,""3"":null,""30"":""*"",""31"":null,""32"":null,""33"":""*"",""34"":""*"",""35"":null,""36"":null,""37"":""*"",""38"":""*"",""39"":null,""4"":null,""40"":null,""41"":null,""42"":""*"",""43"":""*"",""44"":null,""45"":null,""46"":""*"",""47"":""*"",""48"":null,""49"":""*"",""5"":""*"",""50"":null,""51"":null,""52"":""*"",""53"":null,""54"":null,""55"":null,""56"":""*"",""57"":null,""58"":""*"",""59"":null,""6"":null,""60"":null,""61"":null,""62"":null,""63"":null,""64"":null,""65"":null,""66"":""*"",""7"":null,""8"":null,""9"":null},""pos"":{""0"":1,""1"":2,""10"":4,""11"":1,""12"":7,""13"":1,""14"":8,""15"":2,""16"":9,""17"":3,""18"":10,""19"":1,""2"":3,""20"":11,""21"":12,""22"":13,""23"":14,""24"":5,""25"":2,""26"":15,""27"":16,""28"":6,""29"":17,""3"":4,""30"":4,""31"":7,""32"":18,""33"":5,""34"":2,""35"":6,""36"":19,""37"":2,""38"":3,""39"":20,""4"":5,""40"":21,""41"":22,""42"":3,""43"":4,""44"":23,""45"":24,""46"":3,""47"":4,""48"":25,""49"":4,""5"":1,""50"":26,""51"":27,""52"":8,""53"":28,""54"":9,""55"":7,""56"":5,""57"":29,""58"":5,""59"":30,""6"":2,""60"":31,""61"":5,""62"":32,""63"":33,""64"":34,""65"":35,""66"":6,""7"":1,""8"":6,""9"":3},""sigma_nor"":{""0"":1.5373365941,""1"":1.4380188882,""10"":1.8099522346,""11"":1.764740769,""12"":1.86229126,""13"":1.7707862812,""14"":2.7200109559,""15"":2.3223919708,""16"":4.4836541445,""17"":2.4196807123,""18"":2.0823988288,""19"":3.9504594768,""2"":1.5927424441,""20"":2.846498317,""21"":1.9475052341,""22"":4.3107432676,""23"":2.8020270343,""24"":1.8185463027,""25"":2.3401384357,""26"":3.8550261766,""27"":3.0333347137,""28"":1.8694954952,""29"":2.7647239881,""3"":1.454320448,""30"":2.4451729482,""31"":2.0470667178,""32"":2.2943084313,""33"":2.7640368405,""34"":2.2588273112,""35"":2.2354850827,""36"":1.9885050417,""37"":1.8695518267,""38"":1.9698108721,""39"":3.6088141828,""4"":2.0555215294,""40"":3.2488409256,""41"":3.0359588172,""42"":2.1500999569,""43"":3.2956788293,""44"":3.0676526582,""45"":3.092213795,""46"":2.5764952638,""47"":2.0187414449,""48"":2.4769949841,""49"":2.2871333146,""5"":2.3265460078,""50"":2.4666752086,""51"":2.2848447442,""52"":2.2848447442,""53"":2.4065704176,""54"":2.4080310298,""55"":2.563993083,""56"":2.1330622689,""57"":2.2182774558,""58"":2.3790193405,""59"":2.4298677575,""6"":1.5091982769,""60"":2.4332912961,""61"":1.9978348009,""62"":2.035024758,""63"":2.0911989266,""64"":2.0745020995,""65"":2.0174239999,""66"":2.1718919809,""7"":1.6552022484,""8"":1.7164994834,""9"":1.7704897871},""topic"":{""0"":-1,""1"":-1,""10"":4,""11"":0,""12"":-1,""13"":3,""14"":-1,""15"":3,""16"":-1,""17"":3,""18"":-1,""19"":1,""2"":-1,""20"":-1,""21"":-1,""22"":-1,""23"":-1,""24"":4,""25"":0,""26"":-1,""27"":-1,""28"":4,""29"":-1,""3"":-1,""30"":3,""31"":4,""32"":-1,""33"":3,""34"":2,""35"":3,""36"":-1,""37"":1,""38"":1,""39"":-1,""4"":-1,""40"":-1,""41"":-1,""42"":0,""43"":0,""44"":-1,""45"":-1,""46"":2,""47"":1,""48"":-1,""49"":2,""5"":4,""50"":-1,""51"":-1,""52"":4,""53"":-1,""54"":4,""55"":3,""56"":1,""57"":-1,""58"":0,""59"":-1,""6"":4,""60"":-1,""61"":2,""62"":-1,""63"":-1,""64"":-1,""65"":-1,""66"":2,""7"":2,""8"":-1,""9"":4},""vector"":{""0"":""[ 0.15113592  4.6953588   0.12251031  1.4554398   5.5370936   4.748887\n  4.1412396   1.7304499   5.0204496  -3.0718813 ]"",""1"":""[ 0.02569576  4.21662     0.4095236   2.0800028   5.830197    4.9887733\n  4.3707614   1.5858485   4.5824103  -3.150852  ]"",""10"":""[ 0.46484104  4.385325    0.31006566  2.0971658   6.1468334   4.8615284\n  4.5007205   2.3695822   4.240952   -2.751667  ]"",""11"":""[ 0.3423105   3.4856281  -0.15035085  1.3149357   6.1174316   3.9123807\n  3.1144278   1.1566391   5.013179   -2.8385744 ]"",""12"":""[ 0.37883344  4.777444    0.48685083  2.1800632   6.030527    5.173093\n  4.797853    2.0544796   4.819939   -3.0059507 ]"",""13"":""[ 0.17189015  3.8565357   0.921335    2.064209    5.922251    4.8704224\n  4.2586565   2.0046341   4.303387   -3.641963  ]"",""14"":""[ 0.4945763   4.230011    0.83336896  1.8750985   5.9990435   4.950018\n  3.8499458   1.7340732   4.981369   -4.2454286 ]"",""15"":""[ 0.31953338  3.6881397   0.933025    1.9888468   6.0263186   4.8084\n  3.8520951   1.9699458   4.3077035  -3.9481862 ]"",""16"":""[ 1.098684    4.195002    0.07027434  2.1699524   6.782366    4.3731666\n  3.6514633   1.7446678   4.52739    -2.4884636 ]"",""17"":""[ 0.05961147  4.1354976   0.94412625  2.0669823   5.801993    4.921783\n  4.5320163   1.8804334   4.5218196  -3.3200543 ]"",""18"":""[ 0.39563408  4.6602726   0.16661833  1.7708358   5.9561086   4.7165008\n  4.6015515   1.813775    5.1241813  -2.9269052 ]"",""19"":""[ 1.0771292   3.3825862  -0.31041163  1.3263346   6.5199666   3.3666122\n  2.360686    1.2605758   4.767762   -2.4177604 ]"",""2"":""[ 0.72339803  4.443681    0.2136364   2.169771    6.451062    4.6461787\n  4.673595    1.8276315   5.0309176  -2.789852  ]"",""20"":""[ 0.5077342  4.370648   0.6332241  1.9378479  6.037829   5.0506\n  3.9294374  1.8335851  4.8803415 -4.014048 ]"",""21"":""[ 0.96059656  4.3410034   0.18242523  2.2073717   6.593105    4.6126304\n  3.8076372   1.9333488   4.41426    -2.624512  ]"",""22"":""[ 0.4328123  4.0778136  1.2026312  1.6441692  5.7676673  4.5953712\n  3.5778928  1.561442   4.960607  -4.1222568]"",""23"":""[ 0.8338508  3.8871217  0.5321059  1.8001661  6.668835   3.5990813\n  3.587685   0.8872581  4.8768024 -2.4185858]"",""24"":""[ 0.3028424  4.6627855  0.6982352  2.189014   5.910816   5.0948067\n  4.716474   2.1332498  4.6013913 -2.9511538]"",""25"":""[ 0.24812809  3.57072    -0.10931938  1.2105526   5.7909317   3.9854016\n  3.0575535   1.34529     4.949189   -2.8361337 ]"",""26"":""[ 0.42319238  4.60147     0.70745945  1.4791834   5.588432    4.322765\n  4.10909     1.8812548   4.966099   -3.016316  ]"",""27"":""[ 0.19330108  3.942139    0.58362514  2.0637228   5.9889174   4.8848577\n  4.3034587   2.1281388   4.148908   -3.3133216 ]"",""28"":""[ 0.48746443  4.5812626   0.40573192  2.1251373   6.1536303   4.8521285\n  4.843475    2.204526    4.650637   -2.760141  ]"",""29"":""[ 0.51776034  3.5855725   0.08378156  1.6293428   6.3715663   4.269178\n  3.6716707   1.4804418   5.0643005  -3.383124  ]"",""3"":""[ 0.3622013   4.1185584  -0.06892273  1.5094063   6.116016    4.5422573\n  3.7769263   1.5671486   4.923518   -3.342729  ]"",""30"":""[ 0.5022969   3.7595634   0.83413017  2.0477078   6.171244    4.8589067\n  3.6718252   1.9761947   4.343809   -4.008552  ]"",""31"":""[ 0.63496745  4.486691    0.16660734  2.3180168   6.3763976   4.8998365\n  4.2565293   1.9005319   4.401798   -2.5758367 ]"",""32"":""[ 0.9414819   3.8810136  -0.09905817  1.8248757   6.61666     4.2191353\n  3.1403463   1.6861819   4.4249516  -2.724442  ]"",""33"":""[ 0.5649166   3.944771    0.85880786  1.9514785   6.1260138   4.901606\n  3.5912507   1.8312279   4.6740875  -4.254888  ]"",""34"":""[ 0.79335135  4.204596    0.5251937   1.9566914   6.5507016   4.01708\n  4.428238    1.381692    5.0801377  -2.5953784 ]"",""35"":""[ 0.3795899   4.0972695   0.91444767  2.0662093   6.069579    4.494123\n  4.7753873   1.8313446   4.8423986  -3.108545  ]"",""36"":""[ 1.0270793   3.7651484  -0.21024093  1.6546466   6.5592346   3.954556\n  2.815918    1.5806743   4.5271783  -2.5568078 ]"",""37"":""[ 1.2708648   3.501744   -0.29649594  1.4128761   6.5761247   3.3830588\n  2.4077864   1.4804034   4.7288747  -2.3771014 ]"",""38"":""[ 1.1643366   3.5845969  -0.11177564  1.2044741   6.296558    3.2202375\n  2.5449114   1.210088    4.8966804  -2.6002202 ]"",""39"":""[ 0.28339654  4.4512563   0.88234246  1.4630424   5.5688643   4.641491\n  3.780244    1.4897002   5.1688137  -3.7199821 ]"",""4"":""[ 0.20869073  4.5461006   0.09031618  1.3519024   5.6118016   4.5515046\n  4.018292    1.5395846   5.200475   -3.1478195 ]"",""40"":""[ 0.5379156   3.5770075   0.75750685  1.6512202   6.111329    4.372472\n  3.2408288   1.5316539   4.7936187  -3.9558892 ]"",""41"":""[ 0.4903885  4.7531524  0.3842244  1.5071422  5.65371    4.463695\n  3.989368   2.074389   4.763457  -2.823465 ]"",""42"":""[ 0.53860235  3.449602    0.03818051  1.4690577   6.294626    3.78189\n  2.9739966   1.1288383   4.852033   -2.6641936 ]"",""43"":""[ 0.38481355  3.3799605   0.26440036  1.3802958   6.0162683   3.8867295\n  2.9106183   1.1621397   4.884008   -2.9944887 ]"",""44"":""[ 0.23815665  4.46872     0.9422473   1.5530506   5.4776406   4.733199\n  3.9366784   1.745312    4.9518704  -3.7273707 ]"",""45"":""[ 1.0548389   4.1213083   0.13403265  1.9990005   6.683971    4.1475105\n  3.4999495   1.6174557   4.5647225  -2.4554205 ]"",""46"":""[ 0.8077813  3.9820735  0.4026608  1.9590492  6.5703926  4.060352\n  4.504885   1.5783411  5.220582  -2.6522055]"",""47"":""[ 1.1456617   3.530033   -0.02986703  1.5119693   6.5901613   3.392824\n  2.6015446   1.252338    4.720369   -2.3986235 ]"",""48"":""[ 0.58787894  3.7846043   0.8626319   2.2079325   6.366101    4.300152\n  4.0708885   1.5232881   4.571944   -2.9717784 ]"",""49"":""[ 0.8744313   3.9039023   0.57676995  1.8321344   6.57803     3.8150816\n  4.3701262   1.3649095   5.392867   -2.6272604 ]"",""5"":""[ 0.6871559  4.483936   0.3284599  2.3591607  6.425596   4.929907\n  4.6576495  2.1374037  4.6091104 -2.7928586]"",""50"":""[ 0.6202643   4.7993793   0.25780353  1.9158083   5.981841    4.8410735\n  4.1380515   2.3219144   4.415789   -2.7280521 ]"",""51"":""[ 0.42059636  4.116791    1.1128011   1.5445695   5.6162925   4.429199\n  3.6118977   1.7792155   4.852886   -3.796363  ]"",""52"":""[ 0.62219644  4.6921883   0.23955274  2.1809406   6.201207    4.9784193\n  4.4170547   2.3373446   4.3418074  -2.6335778 ]"",""53"":""[ 0.37929967  4.0961776   0.9651765   1.8465081   5.998784    4.1973276\n  4.5592527   1.6490561   4.873565   -2.9287162 ]"",""54"":""[ 0.34155858  4.3143134   0.71538776  1.9403932   5.974764    4.535373\n  4.7312346   1.9570439   4.7302265  -2.8881536 ]"",""55"":""[ 0.3988899  3.9175165  0.9892608  2.1435797  6.080748   4.6348305\n  4.3032193  1.8635169  4.504953  -3.391547 ]"",""56"":""[ 1.090683    3.4919453  -0.02631555  1.3999895   6.4831953   3.3207283\n  2.5829926   1.1662459   4.8020654  -2.4706125 ]"",""57"":""[ 0.67069495  3.8549325   0.80566376  2.1743128   6.3283443   4.722298\n  3.849714    1.962867    4.4061813  -3.6394382 ]"",""58"":""[ 0.63367397  3.4550169  -0.1827467   1.2540952   6.135098    3.6813462\n  2.7082863   1.2482226   4.885027   -2.7040997 ]"",""59"":""[ 1.1927696   3.9415276  -0.04397246  1.7847334   6.678674    3.9005342\n  3.0911565   1.624275    4.5962687  -2.4476624 ]"",""6"":""[ 0.02844125  4.478002    0.30873567  1.881666    5.7014627   4.921471\n  4.604311    1.8864102   4.618983   -2.9173572 ]"",""60"":""[ 0.57004136  3.5214903   0.5434425   1.4248215   6.0062456   3.8884306\n  2.8361232   1.2389417   4.845186   -3.2021692 ]"",""61"":""[ 0.8126492  3.9185033  0.5056859  2.058706   6.6154966  4.3008127\n  4.394763   1.5518864  5.24324   -3.0527124]"",""62"":""[ 0.8407062   3.926217    0.74006975  1.9119406   6.5966225   3.769873\n  3.581935    0.9926444   4.814102   -2.5991392 ]"",""63"":""[ 0.95172495  3.7765367   0.45759168  1.8237638   6.6602545   3.5850518\n  3.3383121   1.0110722   4.783106   -2.4565065 ]"",""64"":""[ 0.23191053  4.4389734   0.00769191  1.4048889   5.745664    4.676906\n  3.857427    1.6297193   5.004955   -3.3574412 ]"",""65"":""[ 0.45960894  4.121177    1.1342976   1.6119691   5.877295    4.4289107\n  3.6801794   1.3543495   5.1031704  -3.8358996 ]"",""66"":""[ 0.79396474  4.1510944   0.70824546  1.7341378   6.3648267   3.799457\n  4.27534     1.3801804   5.209586   -2.5999622 ]"",""7"":""[ 0.82769156  4.088001    0.79266536  1.6813302   6.405024    3.7283475\n  4.012827    1.1714873   5.251615   -2.7090158 ]"",""8"":""[ 0.52233887  3.5775878   0.7740251   1.8328937   6.1762066   4.6430545\n  3.3634756   1.7009914   4.6363535  -4.158618  ]"",""9"":""[ 0.7385356   4.7510085  -0.04136451  2.0494175   6.3255024   4.844327\n  4.386889    2.2545643   4.611448   -2.5117784 ]""},""vocab_index"":{""0"":0,""1"":1,""10"":24,""11"":29,""12"":30,""13"":31,""14"":35,""15"":36,""16"":37,""17"":40,""18"":42,""19"":43,""2"":3,""20"":47,""21"":50,""22"":58,""23"":59,""24"":60,""25"":64,""26"":70,""27"":73,""28"":77,""29"":80,""3"":5,""30"":83,""31"":86,""32"":92,""33"":103,""34"":104,""35"":109,""36"":114,""37"":117,""38"":119,""39"":121,""4"":6,""40"":122,""41"":123,""42"":140,""43"":141,""44"":164,""45"":165,""46"":166,""47"":192,""48"":196,""49"":202,""5"":7,""50"":203,""51"":205,""52"":206,""53"":207,""54"":208,""55"":209,""56"":262,""57"":266,""58"":267,""59"":268,""6"":8,""60"":271,""61"":274,""62"":278,""63"":279,""64"":280,""65"":282,""66"":283,""7"":10,""8"":14,""9"":22},""word"":{""0"":""documents"",""1"":""data"",""10"":""techniques"",""11"":""search"",""12"":""users"",""13"":""visualization"",""14"":""node"",""15"":""spatialization"",""16"":""weight"",""17"":""analytics"",""18"":""entity"",""19"":""added"",""2"":""model"",""20"":""nodes"",""21"":""weights"",""22"":""ieee"",""23"":""north"",""24"":""analysts"",""25"":""searches"",""26"":""conference"",""27"":""synthesis"",""28"":""systems"",""29"":""foraging"",""3"":""semantic"",""30"":""dimensionality"",""31"":""values"",""32"":""reduction"",""33"":""timestep"",""34"":""human"",""35"":""computer"",""36"":""increases"",""37"":""modified"",""38"":""read"",""39"":""docsdisp"",""4"":""document"",""40"":""endert"",""41"":""proceedings"",""42"":""matching"",""43"":""docmatches"",""44"":""docshid"",""45"":""length"",""46"":""animal"",""47"":""determined"",""48"":""color"",""49"":""exotic"",""5"":""models"",""50"":""subplots"",""51"":""sigchi"",""52"":""factors"",""53"":""science"",""54"":""technology"",""55"":""graphics"",""56"":""labelled"",""57"":""resizing"",""58"":""retrieves"",""59"":""constant"",""6"":""information"",""60"":""docsranked"",""61"":""chinchilla"",""62"":""middle"",""63"":""right"",""64"":""annotations"",""65"":""andrews"",""66"":""international"",""7"":""multi"",""8"":""starspire"",""9"":""terms""},""word*"":{""0"":""documents"",""1"":""data"",""10"":""techniques*"",""11"":""search*"",""12"":""users"",""13"":""visualization*"",""14"":""node"",""15"":""spatialization*"",""16"":""weight"",""17"":""analytics"",""18"":""entity"",""19"":""added*"",""2"":""model"",""20"":""nodes"",""21"":""weights"",""22"":""ieee"",""23"":""north"",""24"":""analysts"",""25"":""searches*"",""26"":""conference"",""27"":""synthesis"",""28"":""systems*"",""29"":""foraging"",""3"":""semantic"",""30"":""dimensionality*"",""31"":""values"",""32"":""reduction"",""33"":""timestep*"",""34"":""human*"",""35"":""computer"",""36"":""increases"",""37"":""modified*"",""38"":""read*"",""39"":""docsdisp"",""4"":""document"",""40"":""endert"",""41"":""proceedings"",""42"":""matching*"",""43"":""docmatches*"",""44"":""docshid"",""45"":""length"",""46"":""animal*"",""47"":""determined*"",""48"":""color"",""49"":""exotic*"",""5"":""models*"",""50"":""subplots"",""51"":""sigchi"",""52"":""factors*"",""53"":""science"",""54"":""technology"",""55"":""graphics"",""56"":""labelled*"",""57"":""resizing"",""58"":""retrieves*"",""59"":""constant"",""6"":""information"",""60"":""docsranked"",""61"":""chinchilla"",""62"":""middle"",""63"":""right"",""64"":""annotations"",""65"":""andrews"",""66"":""international*"",""7"":""multi"",""8"":""starspire"",""9"":""terms""},""x2D"":{""0"":2.6995530128,""1"":2.7359893322,""10"":1.7718975544,""11"":-2.615336895,""12"":1.9565576315,""13"":3.7212221622,""14"":5.0503025055,""15"":4.5618920326,""16"":-0.4660099447,""17"":3.0579442978,""18"":2.3516325951,""19"":-2.5573747158,""2"":1.180508256,""20"":4.6591658592,""21"":0.2122345865,""22"":5.118768692,""23"":-0.7847003341,""24"":2.1329996586,""25"":-2.0871584415,""26"":3.3557178974,""27"":3.5276575089,""28"":1.834985137,""29"":1.0378667116,""3"":2.293566227,""30"":4.5969500542,""31"":0.9687206745,""32"":-1.2376213074,""33"":4.9103374481,""34"":0.4248318374,""35"":1.9068570137,""36"":-1.809060216,""37"":-2.6574430466,""38"":-2.5098695755,""39"":4.5578947067,""4"":2.9900491238,""40"":5.3156557083,""41"":2.8619241714,""42"":-2.3726112843,""43"":-2.4383170605,""44"":4.4178323746,""45"":-0.7881599665,""46"":0.3038636148,""47"":-2.4906218052,""48"":1.1340210438,""49"":0.2417192757,""5"":1.5066058636,""50"":1.5160442591,""51"":4.8693270683,""52"":1.3975180387,""53"":1.5017881393,""54"":1.9844150543,""55"":3.3978397846,""56"":-2.7311778069,""57"":4.2035727501,""58"":-2.6242337227,""59"":-1.4309448004,""6"":2.4470214844,""60"":-2.2127428055,""61"":0.614090085,""62"":-0.5740890503,""63"":-1.1106930971,""64"":2.801356554,""65"":4.9739317894,""66"":0.1648201048,""7"":-0.1536034346,""8"":5.1636939049,""9"":1.1802078485},""y2D"":{""0"":-0.5138382316,""1"":-1.9225678444,""10"":-3.0744791031,""11"":-0.3266071975,""12"":-2.4246325493,""13"":-1.825732708,""14"":-1.2266185284,""15"":-1.7714146376,""16"":-2.3579790592,""17"":-1.92892313,""18"":-1.3293319941,""19"":-1.3296644688,""2"":-2.362036705,""20"":-1.1099914312,""21"":-2.7019195557,""22"":-0.8763182759,""23"":-1.4079538584,""24"":-2.4310183525,""25"":-0.7839311957,""26"":-0.3150396347,""27"":-1.9515503645,""28"":-2.5510070324,""29"":-0.2066768408,""3"":-0.2145325989,""30"":-1.7681673765,""31"":-2.9004209042,""32"":-2.1250855923,""33"":-1.5353112221,""34"":-0.8952755332,""35"":-1.6465009451,""36"":-1.7168556452,""37"":-1.4929578304,""38"":-1.2224872112,""39"":-0.4330489933,""4"":-0.3651377857,""40"":-1.0991253853,""41"":-0.5806949735,""42"":-0.5445502996,""43"":-0.3286736012,""44"":-0.5027129054,""45"":-2.0514717102,""46"":-1.2415748835,""47"":-1.4762957096,""48"":-1.2359195948,""49"":-1.2040973902,""5"":-2.7148427963,""50"":-3.1611871719,""51"":-0.5918318033,""52"":-3.0158846378,""53"":-1.3612077236,""54"":-1.7836052179,""55"":-1.6709825993,""56"":-1.2419929504,""57"":-1.6316615343,""58"":-0.87124753,""59"":-1.8021541834,""6"":-1.8701031208,""60"":-0.2841771245,""61"":-1.1996048689,""62"":-1.3741607666,""63"":-1.3189535141,""64"":-0.1166084632,""65"":-0.7614407539,""66"":-1.1122992039,""7"":-1.3076257706,""8"":-1.3799086809,""9"":-3.0501365662}}",False,False,False,http://ieeexplore.ieee.org/document/7042492/,,Multi-model semantic interaction for text analytics,"[ 1.77498236e-02 -2.72784054e-01  9.12552178e-02 -2.63421655e-01
  8.01154375e-01  1.60295516e-04 -8.66523758e-02 -1.89399570e-01
 -5.62582970e-01 -1.16722479e-01 -1.66909784e-01 -3.47464412e-01
  2.51984119e-01  1.52365580e-01 -2.39200503e-01  8.84977043e-01
 -3.80918860e-01 -2.72101700e-01 -7.57297724e-02  7.77113140e-02
  1.58951670e-01 -2.56622016e-01  1.28405383e-02  5.32469988e-01
  1.07026428e-01 -3.85462269e-02 -9.44609344e-02 -2.75256801e-02
 -2.72658974e-01  1.92127153e-01  3.26947987e-01  6.50464952e-01
  3.39526497e-02 -4.83020782e-01  1.33529171e-01 -3.59715931e-02
 -3.06144923e-01 -9.04606730e-02 -1.66434541e-01  6.44230485e-01
 -2.55805433e-01 -2.82111883e-01  5.90182282e-03 -3.02149683e-01
  1.64989427e-01 -1.64339542e-02 -2.72958934e-01 -6.07265905e-02
 -4.74730283e-02 -3.09727848e-01 -1.44340014e+00 -1.85966209e-01
  5.14171831e-03 -6.74969435e-01  3.40737100e-03  6.59664989e-01
 -1.80381894e-01 -7.03753650e-01  3.23323429e-01  3.74607503e-01
 -1.81000516e-01 -4.06695753e-02 -9.33949724e-02  3.33051644e-02
  4.68856901e-01 -3.42032343e-01  1.58624887e-01  3.51867259e-01
 -5.33934712e-01  2.38109052e-01 -7.97014832e-02 -1.21905729e-01
 -6.81523085e-02  6.10922992e-01 -8.43241751e-01 -4.00845297e-02
  1.15304753e-01  1.20939113e-01  2.69688904e-01 -3.01521271e-01
 -1.16594732e-01  2.45050564e-01 -1.42449401e-02  3.36449258e-02
  5.92211664e-01  9.25270438e-01 -2.78731763e-01  6.47722840e-01
 -4.56508547e-01  3.20142061e-01 -8.88528600e-02  3.67686674e-02
 -2.89935797e-01  4.43369955e-01  8.99208844e-01 -3.21556002e-01
 -4.71678495e-01  9.60362852e-02  5.40896468e-02 -1.30152658e-01
  3.59719723e-01 -5.95119834e-01 -5.68105318e-02 -2.12593898e-01
 -1.86436296e-01 -1.91463038e-01 -3.41671944e-01 -6.23948693e-01
 -9.63342413e-02 -1.29805163e-01  2.09385723e-01  6.25096308e-03
  1.09860756e-01 -7.39118934e-01 -2.55949676e-01  2.84158319e-01
  4.44052964e-02  3.39978367e-01 -8.72165486e-02  2.89033085e-01
  5.63590303e-02  3.87729615e-01 -9.47309136e-02  6.66963875e-01
  2.08902568e-01  1.53133169e-01 -2.86001623e-01  1.97288394e-01
  3.18919897e-01  1.46216989e-01  3.37935001e-01  2.88130417e-02
  1.24715112e-01 -4.21321616e-02 -4.18459207e-01  8.51342976e-01
 -2.63802886e-01  2.88761526e-01  2.17774808e-01  6.87939525e-02
 -4.52579618e-01 -6.83886170e-01  2.16344953e-01 -4.44773920e-02
  5.55019140e-01  9.45151970e-03 -6.42399713e-02  2.16807827e-01
 -2.21158236e-01  2.37566084e-01 -2.63530284e-01  5.11656523e-01
 -7.67940462e-01  8.13322067e-02 -1.91191137e-01  8.32885280e-02
 -3.69452775e-01  2.44729668e-01  4.22519408e-02  1.23617984e-01
 -1.02215465e-02 -4.68836911e-02  6.94719329e-03  2.67670602e-01
 -5.83380014e-02 -2.91630864e-01 -1.75507084e-01  3.42739463e-01
 -4.39894013e-02 -2.62150466e-01  1.15971439e-01 -3.19660276e-01
  3.09875190e-01  1.28557731e-03  4.68915403e-01  1.09772198e-02
 -2.54955798e-01  1.69180959e-01  9.04954523e-02  7.48206317e-01
 -3.74187380e-01 -2.81548947e-02 -2.58901685e-01 -6.09296203e-01
  6.10340357e-01  1.21301748e-01  3.29433568e-02 -4.82117116e-01
  2.34764099e-01  3.07559460e-01 -3.47707510e-01 -4.50199932e-01
  2.90171858e-02 -3.35371375e-01  3.42360377e-01 -5.12635231e-01
  1.42774001e-01  2.95604412e-02 -7.17591718e-02  5.97098842e-02
 -3.46746534e-01  1.47597399e-02 -2.23059356e-01  1.79291114e-01
 -9.99225080e-02  2.67957240e-01 -2.99993247e-01 -6.29149497e-01
 -7.38680601e-01 -3.69796306e-02 -7.05732554e-02  2.29135036e-01
 -2.45641783e-01  5.69502652e-01  1.26863062e-01  1.93755195e-01
  2.27940708e-01 -2.10759431e-01  4.48752642e-01 -9.69342440e-02
  5.36355257e-01 -2.62359232e-01  8.55411142e-02  2.08091676e-01
 -1.22942455e-01  1.70734298e+00  5.02872169e-01 -2.22178921e-01
  8.08766127e-01 -1.02396935e-01  2.91069418e-01  2.28630677e-01
  6.76260233e-01 -7.54921496e-01  2.58462667e-01  2.08081603e-01
 -7.72499666e-02 -3.86138484e-02  1.18830442e-01  7.46000111e-02
 -1.21703155e-01  3.06998014e-01  2.90738463e-01  1.58147693e-01
  1.22982971e-02  1.00029610e-01  2.56678015e-01 -1.62128843e-02
 -3.64880040e-02  1.38322532e-01 -5.92173636e-03  2.45123997e-01
 -6.20976150e-01 -4.16146427e-01 -2.73309767e-01 -2.48839427e-02
 -1.17698848e-01 -1.42280683e-01 -2.04507157e-01  4.35335815e-01
  3.28644753e-01  3.73317629e-01  4.98707518e-02  2.02621054e-02
  6.41682222e-02 -2.57660419e-01 -1.04056880e-01 -5.87854862e-01
  5.98138332e-01  2.71262139e-01  2.10643500e-01 -6.16590261e-01
  2.34558299e-01  6.37426555e-01 -2.12041497e-01 -1.15839578e-01
  3.29910874e-01 -2.23191693e-01 -2.67720342e-01 -5.07807851e-01
  8.42571333e-02  4.39478755e-01 -4.65996228e-02  1.72369778e-02
 -5.41397095e-01 -4.29056250e-02  1.64646104e-01  8.83666724e-02
  2.48299956e-01 -2.37189636e-01  3.65979671e-02  3.44020665e-01
 -2.78079599e-01 -2.86721885e-01  6.07175112e-01  3.99350315e-01
 -2.98528317e-02 -1.04529545e-01 -7.82607198e-01 -4.55314785e-01
 -1.28907904e-01  5.30221574e-02 -6.37346655e-02 -1.06336009e-02
  5.16612768e-01  2.17052042e-01 -2.53153026e-01 -4.90219265e-01
 -9.08692837e+00 -3.80311191e-01 -2.49554083e-01  4.92157899e-02
  2.39636809e-01 -1.93634167e-01  2.34933168e-01 -2.27515787e-01
 -1.14727318e-01  6.38061687e-02 -2.72350311e-01 -1.79566473e-01
 -3.08561057e-01  9.10833851e-03  5.68409078e-02 -1.24024563e-01
  3.21670711e-01  1.99369043e-01 -1.71113431e-01  6.50124967e-01
 -2.38546625e-01 -3.52969885e-01 -5.43951150e-03 -2.64667004e-01
 -2.15113580e-01 -4.14739072e-01 -2.81485200e-01  8.86097923e-02
 -3.62240970e-01 -5.95823288e-01 -2.88161159e-01 -4.96313542e-01
 -6.96580112e-01  8.23848426e-01 -4.65874225e-01 -1.26533657e-01
 -2.15363771e-01 -2.80629873e-01  3.85837972e-01  2.68729687e-01
  1.42539993e-01 -1.72804907e-01  1.57931596e-02  1.91810220e-01
  6.79460704e-01 -1.63409755e-01  2.47108385e-01  3.37874144e-01
 -3.55007440e-01 -1.16453268e-01 -1.74610764e-01 -6.25410825e-02
  3.78435969e-01 -6.31511271e-01 -2.81895727e-01 -3.31507325e-01
  5.78544855e-01  3.98669422e-01 -5.14198877e-02 -2.92054325e-01
  3.86905223e-01 -3.51651847e-01 -2.80965924e-01  4.30457592e-02
 -5.50658256e-02  2.87872870e-02 -1.06432736e+00 -9.43897545e-01
  3.77165452e-02 -4.15983379e-01 -4.39433664e-01  2.80846417e-01
 -1.91937964e-02 -1.51981676e+00 -7.84745872e-01 -3.86444598e-01
  4.34339941e-01 -6.63017482e-02 -2.51562685e-01 -4.78015095e-01
 -3.90896350e-01 -5.81098497e-01  1.36534020e-01 -1.77048668e-02
 -4.47478741e-01  2.50993986e-02 -8.52323845e-02 -3.19065839e-01
 -6.15499675e-01  1.30561411e-01 -2.29216024e-01  2.68804848e-01
  3.17053974e-01  4.54999506e-01  4.10768483e-03 -6.89907447e-02
  5.35395086e-01 -1.10028848e-01  5.81654496e-02  8.04046243e-02
 -1.50469720e-01 -2.22656772e-01 -1.81128457e-01 -3.25809866e-01
 -2.88276412e-02  2.18520984e-01 -5.23869514e-01  1.82351202e-01
  2.06544831e-01  3.84960353e-01 -8.76345411e-02  3.04936737e-01
 -2.99401134e-01 -1.66127831e-01 -5.22270918e-01  1.38307691e-01
 -6.76714927e-02  3.71422678e-01 -2.63405088e-02 -3.03158104e-01
 -6.02238357e-01  1.20134227e-01 -2.32931525e-02  8.55203122e-02
  7.27530301e-01  1.29518211e-01  1.69249862e-01  1.58597469e-01
 -4.22491103e-01 -9.08263847e-02  5.48835881e-02 -4.76772964e-01
  2.96159205e-03 -9.72002447e-02  4.41172756e-02 -3.75348240e-01
 -7.78306201e-02 -2.90182203e-01 -6.72709048e-01  3.58512312e-01
  4.91643310e-01  4.13178205e-02  5.32285571e-01  1.68861613e-01
 -5.65184131e-02 -3.23746145e-01 -1.05365165e-01  3.32332224e-01
 -2.31939867e-01  1.70167565e-01 -4.55027819e-01 -7.89251328e-01
  1.41298488e-01 -3.30809087e-01  5.74333608e-01 -1.87079772e-01
  2.06961244e-01 -3.57967645e-01 -4.65877056e-02 -4.44428682e-01
  1.21164411e-01  3.57865877e-02  2.81578135e-02 -6.38682917e-02
  1.39869779e-01  2.85750683e-02 -1.50898129e-01  4.69345510e-01
  8.43647197e-02 -4.39647585e-01 -3.82348061e-01 -1.38173088e-01
  1.14171684e-01 -3.05109084e-01 -1.53074130e-01  6.40897274e-01
  3.31069678e-01  5.42135388e-02 -3.55330855e-01  6.73182547e-01
  1.56737611e-01  5.33781230e-01  2.55250856e-02  7.58329391e-01
  7.02243209e-01  5.16567588e-01  1.91883042e-01  1.87405288e-01
  1.24568097e-01  2.51248986e-01 -2.41656765e-01  4.49145406e-01
 -1.63687859e-02 -5.79081709e-03 -2.34134868e-01 -7.18357861e-01
  5.94504595e-01 -6.75917506e-01 -9.58924089e-03  2.46213317e-01
 -8.26825425e-02 -1.81789976e-02 -2.08594278e-01  3.57503980e-01
 -1.57241970e-01 -4.31706399e-01  2.10828707e-01  1.74051017e-01
 -4.32468027e-01  3.43259163e-02 -5.52216589e-01 -1.66314378e-01
  2.08961815e-01 -4.00570154e-01  1.07858956e-01 -1.35570571e-01
 -3.31273913e-01 -4.58186924e-01 -8.40679765e-01  6.70175195e-01
 -5.69054782e-01 -1.90258428e-01  2.16448456e-01  4.14772809e-01
  2.58793980e-01 -6.50956407e-02  2.18625695e-01  6.61284998e-02
 -5.47293007e-01 -2.29281522e-02  6.78228885e-02 -1.59408581e+00
  7.02663884e-02  3.04431487e-02  1.06845960e-01 -4.44851905e-01
 -6.69147670e-01 -7.58219510e-02 -3.51718217e-01 -3.42143714e-01
  1.73556268e-01 -5.40336549e-01  2.77060479e-01 -4.29016709e-01
 -4.39207673e-01 -2.06919655e-01 -4.40532386e-01  1.09032065e-01
 -2.85281152e-01  7.54629821e-02  1.63960502e-01 -1.36238337e-01
  1.23232305e-01 -7.75539756e-01  5.25559425e-01 -5.09203114e-02
 -4.31135744e-02 -7.91020811e-01 -2.11319447e-01 -1.26986280e-01
 -2.72700876e-01 -2.62273014e-01 -2.49583587e-01  1.57294482e-01
 -4.92537647e-01 -6.15908578e-02  1.12347603e-01 -3.83773416e-01
 -1.42522613e-02 -2.97499187e-02 -2.16910169e-01 -2.95497090e-01
 -1.81304649e-01  4.44098294e-01 -5.98926485e-01 -2.17524126e-01
 -3.35136503e-01 -8.52623433e-02  3.38979632e-01 -1.88261703e-01
  3.91075671e-01 -3.50619018e-01  2.59407640e-01  6.52875900e-01
  3.13416004e-01 -3.99441004e-01 -2.70418096e-02  2.26968769e-02
 -1.52430862e-01 -1.83762759e-01  3.19607019e-01  4.50701825e-03
 -4.35825706e-01  1.21872082e-01 -3.86556089e-01  5.33424854e-01
  5.73647082e-01  8.16841498e-02 -2.61624884e-02  1.36760518e-01
 -2.03344878e-02  2.36902490e-01  3.72108549e-01  5.65926135e-01
  8.65502059e-02  2.70610023e-02 -2.37120271e-01 -5.50569832e-01
 -5.80346249e-02 -5.90709805e-01 -1.32462993e-01 -1.05441496e-01
  7.43655980e-01  3.51044014e-02  1.94546068e-03 -4.47682828e-01
 -1.67435601e-01 -3.13956022e-01  1.98164523e-01 -9.03534219e-02
 -7.34856725e-01  3.69014174e-01  7.85387516e-01 -1.18813060e-01
  3.24813187e-01  6.00459576e-01 -4.77266669e-01 -1.98189259e-01
 -3.74725848e-01  5.71177423e-01  1.45973817e-01  2.97721028e-01
 -2.62996554e-01  9.92608741e-02  4.81842846e-01  1.17045984e-01
  4.73184615e-01 -3.01431399e-02  5.40678613e-02  3.33434284e-01
 -1.45665199e-01  3.03011954e-01 -2.24735159e-02  4.62227553e-01
 -9.10354108e-02 -3.40657569e-02 -4.36237864e-02  5.96058667e-01
  1.07819580e-01  2.75891513e-01  4.21106339e-01  9.81307924e-02
  4.50199395e-01 -7.84004629e-02 -5.21267429e-02 -3.05957437e-01
  2.73678929e-01 -2.01502144e-01  1.29587367e-01  7.28072941e-01
  2.13971049e-01  1.16934665e-01  1.15695976e-01 -6.99003577e-01
 -3.85199100e-01 -1.76901832e-01  7.62725115e-01  7.91561324e-03
  2.85588831e-01 -1.16748467e-01  3.45085531e-01  4.19316173e-01
 -1.41770514e-02  7.66267926e-02  3.66409749e-01  2.27790400e-01
  1.09952822e-01 -4.37407404e-01 -6.28279224e-02  7.04936385e-02
 -6.10585362e-02 -3.31410646e-01 -3.59333694e-01  5.21813408e-02
 -5.30299723e-01 -4.34557229e-01 -2.90021092e-01  2.62789816e-01
  1.04320489e-01 -1.08635314e-01 -3.98816228e-01  3.93685639e-01
  4.94788766e-01 -6.95299357e-02 -1.40887812e-01 -1.17762260e-01
  1.97193190e-01 -1.65978458e-03  2.42536500e-01  5.15976995e-02
  1.83134526e-02  2.35677175e-02 -3.31720918e-01  3.13362092e-01
  7.12914541e-02 -3.48521695e-02 -1.05123818e-01  7.44007647e-01
 -4.41127360e-01 -4.41339403e-01  3.88392210e-01  2.95657724e-01
 -1.04061097e-01  4.86772299e-01 -1.64727541e-03  3.01960230e-01
  2.48914286e-01  1.88126341e-02 -2.92304069e-01  1.02958106e-01
 -2.15419471e-01 -8.35823298e-01  5.75394154e-01 -3.36718172e-01
  1.55999698e-02  1.77669182e-01 -2.65092909e-01 -2.21469745e-01
 -9.66186747e-02 -2.53894404e-02  3.59016716e-01  4.28049117e-01
 -1.09495968e-01 -1.10853026e-02 -8.85893852e-02  2.40152285e-01
 -3.82305533e-01  3.34127307e-01 -1.31602585e-02 -5.36745787e-02
 -5.48425853e-01  3.53538334e-01 -2.73668408e-01 -2.87351832e-02
 -2.29643472e-02  2.84331352e-01  1.87097281e-01 -8.49028230e-02
 -2.11679205e-01 -6.78431153e-01 -3.88992310e-01 -4.30818275e-02
 -3.39840353e-01 -5.48770189e-01  1.57332510e-01 -4.57367264e-02
 -3.11022311e-01 -4.43479657e-01 -3.25434446e-01  4.57314923e-02]",8QJPPCPZ,False,False,"[9.303430557250977, -0.8699579834938049]"
4J6N3XSN,F759W6EK,"J Intell Inf Syst
DOI 10.1007/s10844-014-0304-9

The human is the loop: new directions for visual analytics
Alex Endert · M. Shahriar Hossain ·
Naren Ramakrishnan · Chris North ·
Patrick Fiaux · Christopher Andrews

Received: 10 October 2012 / Accepted: 2 January 2014
© Springer Science+Business Media New York 2014

Abstract Visual analytics is the science of marrying interactive visualizations and analytic
algorithms to support exploratory knowledge discovery in large datasets. We argue for a
shift from a ‘human in the loop’ philosophy for visual analytics to a ‘human is the loop’
viewpoint, where the focus is on recognizing analysts’ work processes, and seamlessly
fitting analytics into that existing interactive process. We survey a range of projects that
provide visual analytic support contextually in the sensemaking loop, and outline a research
agenda along with future challenges.
Keywords Visual analytics · Clustering · Spatialization · Semantic interaction ·
Storytelling

A. Endert
Pacific Northwest National Laboratory, Richland, WA 99352, USA
e-mail: alex.endert@pnnl.gov

M. S. Hossain
Department of Computer Science, University of Texas at El Paso,
El Paso, TX 79968, USA
e-mail: mhossain@utep.edu
N. Ramakrishnan ((cid:2)) · C. North · P. Fiaux
Department of Computer Science, Virginia Tech, Blacksburg, VA 24060, USA
e-mail: naren@cs.vt.edu

C. North
e-mail: north@cs.vt.edu

P. Fiaux
e-mail: pfiaux@vt.edu

C. Andrews
Department of Computer Science, Mount Holyoke College,
South Hadley, MA 01075, USA
e-mail: andrews@mtholyoke.edu

J Intell Inf Syst

1 Introduction

The emerging field of visual analytics seeks to address the needs of exploratory discov-
ery in big data (Kielman et al. 2009; Thomas and Cook 2005). The approach is to marry
the big data processing capabilities of analytics with the human intuitive capabilities of
interactive visualization. The rationale is that data is too large for purely visual methods,
requiring the use of data processing and mining; yet, the desired tasks are too exploratory
for purely analytical methods, requiring the involvement of human analysts, using visualiza-
tion as a medium for human interaction with the data. This approach must be situated within
an understanding of human cognitive reasoning processes. Thus, visual analytics research
necessitates an interdisciplinary approach.

Targeted tasks in visual analytics are those that are exploratory in nature, where the
questions are ill-defined or unknown a priori and training data is not available. Tasks are
strategic in nature, and must be translated into operational questions during the course of
the analysis. For example, in intelligence or business analysis, analysts may be confronted
with large amounts of textual information that they must make sense of. Stasko points out
that while text analytics and visualizations are helpful in structuring the information, even-
tually the analyst must “read and understand the actual text documents” to gain semantic
insight and report a finding (Stasko et al. 2008). Cybersecurity analysts must defend net-
works against attack or misuse. While known attack methods may be easily detectable by
pattern analysis, creative new attacks are continually being developed by innovative adver-
saries. The analysts goal here is to seek, identify, track, understand, prevent, and document,
such attacks (Fink et al. 2009).

To date, exemplar research in visual analytics has varied in its emphasis on the visual
or the analytics, and the degree of interaction. Simoff et al. (2008) discuss the challenge
of transitioning from interaction between computational analytic runs, to interaction dur-
ing analytic runs. Keim et al. (2010) describe visual analytics as a problem solving process
following the mantra: ‘analyze first; show the important; zoom, filter, and analyze further;
details on demand.’ For example, Jigsaw (2008) supports visual analytics of text collections
by first conducting entity extraction and link analysis, and then enabling users to explore
the results in a variety of visual representations. Van Wijk et al. (1999) demonstrate the
use of iterative model testing and refinement by experts to develop a final visual repre-
sentation that communicates a valuable insight. InSpire (2012) and StreamIt (2011) exploit
complex topic modeling to visualize document collections, and users can make parameter
adjustments (e.g., by changing keyword weights) to compute entirely new views of the col-
lection. iPCA (2009) users can navigate a principal component analysis model with sliders
for adjusting model parameters, thus manipulating the role of eigenvalues and eigenvectors
in data reduction.

Interaction is thus the critical glue that integrates analytics, visualization, and human
analyst. But how should this interaction be designed? A common phrase used to describe
interactive analytics is ‘human in the loop,’ representing the need for analytic algorithms
to occasionally consult human experts for feedback and course correction. However, we
believe human-in-the-loop thinking leads to inevitable usability problems, as analysts are
presented with results out of context, without understanding their meaning or relevance, and
interactive controls are algorithm specific and difficult to understand. In place of the flood
of data, analysts are confronted with navigating a flood of disconnected algorithms and their
parameters/settings.

J Intell Inf Syst

Our hypothesis is that we must move beyond human-in-the-loop to ‘human is the loop’
analytics. The focus here is on recognizing analysts’ work processes, and seamlessly fit-
ting analytics into that existing interactive process. For example, Pirolli and Card’s model
of the sensemaking loop for analysts (Pirolli and Card 2005) (see Fig. 1) describes the com-
plex interactive process that analysts conduct. The two major sub-loops involve foraging
for relevant information and synthesis of hypotheses. The dual search loop involves the
cognitively challenging process of generating hypotheses from found evidence, and simul-
taneously searching for evidence that supports potential hypotheses, while managing the
potential effects of cognitive bias (Heuer 1999). This philosophy means that algorithms
must be redesigned from the ground up to fit into this model, learning from the interactions
that analysts are already performing in their sensemaking process and displaying results
naturally within the context of that process. In this article, we present several examples of
this approach to visual analytics and a research agenda to realize it.

2 Interaction in visual analytics

To emphasize the relevance of interaction, and to illustrate through examples the ‘human is
the loop’ philosophy, we survey four projects from our group. The projects can be variously
classified (see Table 1) in terms of the problem domain they study and in terms of the
granularity of interaction.

The two broad analysis tasks we consider are related to clustering and storytelling.
Clustering (Jain et al. 1999) needs almost no introduction to this audience. As a classical
technique for data analysis it has become increasingly repurposed for new uses, with the
advent of novel applications in bioinformatics (Sese et al. 2004; Ernst et al. 2005; Xu et al.
2002; Monti et al. 2003), intelligence analysis (Petrushin 2005; Liang et al. 2003; Baron
and Freedman 2008), and web modeling (Miao et al. 2009; Aghabozorgi and Wah 2009;
Cadez et al. 2003). Clustering is closely related to spatialization and dimension reduction,
where the goal is to ensure that a dataset is laid out spatially in a way that reflects the user’s
notions of dissimilarity or distance.

Fig. 1 The sensemaking process and leverage points for analyst technology as identified through cognitive
task analysis. From Pirolli and Card (2005)

Table 1 Four projects that straddle multiple granularities of ‘human is the loop’ interaction

Project

Type of user interaction

Analysis task User input

Visual feedback

J Intell Inf Syst

ForceSPIRE

Instance-level interaction Spatializing
(instances = data points)
Scatter-Gather Bundle-level interaction

Clustering

Analyst’s
Workspace
Bixplorer

(bundles = clusters)
Instance-level interaction Storytelling
(instances = documents)
Bundle-level interaction
(bundles = biclusters)

Storytelling

Implicit
(semantic interactions)
Explicit
(scatter gather constraints)
Explicit
(path constraints)
Explicit
(entity constraints)

Updated
spatialization
Updated clustering

Updated stories

Compositional
patterns

Of recent interest has been the ability to impart prior domain knowledge to data min-
ing algorithms in the form of constraints (Wang and Davidson 2010; Davidson et al.
2007; Wagstaff et al. 2001; Davidson and Ravi 2005), clustering nonhomogeneous datasets
(Hossain et al. 2010; Momtazpour et al. 2012), or providing expressive forms of user input
(Alonso and Talbot 2008; Hwang et al. 2011; Huang and Mitchell 2006). In the below sec-
tions we are motivated by how users can steer the iterative process by which users can
inspect clustering or spatialization outcomes, and how the system can provide feedback
using visual analytic means. In particular, our desire was to provide natural interfaces for
users by which they can critique results and, at the same time, operationalize their input into
an effective mechanism to recluster the results. Our thesis is that ‘a little domain knowledge
goes a long way’, and enabling the user in the loop to supply input can be significantly more
effective than trying to design a clever clustering algorithm.

The second analysis task we study involves storytelling (Kumar et al. 2006; 2008), the
investigative process of ‘connecting the dots’ between seemingly disconnected information
(Hossain et al. 2011, 2012a, b, c; Wu et al. 2012). Storytelling is an accepted metaphor
in analytical reasoning and in visual analytics (Thomas and Cook 2005). (By storytelling,
we do not mean creative writing activities, e.g., composing a novel, or designing an ani-
mated movie (Kelleher and Pausch 2007), but rather the task of connection building between
desired end-points.) Different researchers have employed this metaphor in different con-
texts. For instance, it has been used to denote generating event timelines (Guha et al. 2005),
filling in the gaps in chains of evidence, threading information across dialogs, tracking col-
lective reasoning patterns across a corpus (Rzhetsky et al. 2006), information organization
based on narrative structures (Kuchinsky et al. 2002), topic tracking, and, in general, deci-
phering genealogy from a collage of information (Shaparenko and Joachims 2007). The
common theme to all of them is their ability to present spatial/temporal/spatio-temporal
progressions of multifaceted information. Many software tools exist to support story build-
ing activities (Eccles et al. 2008; Hsieh and Shipman 2002; Wright et al. 2006; i2group ).
Analysts are able to lay out evidence according to spatial cues and incrementally build
connections between them. Such connections can then be chained together to create sto-
ries which either serve as end hypotheses or as templates of reasoning that can then be
prototyped. However, sophisticated analytic support for storytelling remains a significant
research frontier. We describe how we have demonstrated visual analytic approaches for
exploring connections in document collections and for building stories between possibly
disparate end points.

J Intell Inf Syst

The other distinction being made in Table 1 refers to whether user input and control of the
knowledge discovery process occurs at the level of instances (i.e., the original data points)
or at the level of a higher-level abstraction as a result of some grouping/bundling process.
Two examples of such grouping could be clusters or biclusters (Madeira and Oliveira 2004),
described in greater detail below. Both forms of interaction are relevant for different appli-
cations. Finally, as Table 1 shows, it is helpful to view all projects through a common lens,
viz. the type of user input they accommodate and how the visual feedback is presented back
to the user in the context of their analytic process.

2.1 ForceSPIRE

ForceSPIRE (Endert et al. 2012a) is a visual analytics system (Fig. 2) to generate mean-
ingful spatializations from text data, i.e., laying out documents visually such that the layout
reflects user notions of similarity and distance. ForceSPIRE supports visual data exploration
through interpreting the user interaction and performing implicit model steering operations
(Endert et al. 2012b). Such user interactions are tailored towards the domain expertise and

Fig. 2 ForceSPIRE can automatically generate spatializations from text that respect user’s interactions

J Intell Inf Syst

tasks of users, while providing implicit computational support are called semantic interac-
tions. As a result, these semantic interactions such as repositioning documents, highlighting
phrases as they read a document, annotations, and search results train the underlying dimen-
sion reduction model towards understanding the features important to the user. For example,
by the user moving two documents closer together in the spatialization, ForceSPIRE can
determine the characteristics responsible for the similarity through metric learning tech-
niques. The resulting computation incrementally adjusts the spatialization in accordance
with this user input.

It is instructive to contrast ForceSPIRE with approaches that require explicit user input
for model steering. For example, tools such as IN-SPIRE (PNNL 2012) enable model steer-
ing through users explicitly selecting features (keywords) through a menu. While more
expressive, such explicit user input does not provide the flexibility that may be desired for
visual data exploration.

Implicit user feedback entails providing the feedback of the model through the visualiza-
tion, rather than explicitly via the weighted dimensions. For example, ForceSPIRE provides
an updated spatialization as a result of a semantic interaction (an entity viewer window also
exists, where dimension weighting can be individually viewed and adjusted). Similarly, pre-
vious work on observation-level interaction also uses the updated spatialization as a medium
for communicating the learned domain knowledge (Endert et al. 2011).

Liu et al. (2011) describe how after performing similar observation-level interaction, the
system can provide explicit feedback to the user regarding the model learning. Through
performing this type of observation-level interaction, the users are given a set of weights that
correspond to their newly generated spatialization. As such, this work focuses on explicitly
showing the user the dimensions that were adjusted based on their interaction (i.e., the
feedback from the system to the users).

However, how can a system support a mixture between these two forms of feedback?
One can see that as the number of dimensions increase (and become more abstract), explicit
feedback may not be effective or meaningful to the users. Further, the results of a user study
of ForceSPIRE (where explicit feedback can be obtained by the entity viewer window)
shows that users may not prefer, or need, this form of feedback (Endert et al. 2012a). Sim-
ilarly, users may require some feedback to gauge what information the system is learning
based on their interaction, and given the ability to provide more fine-grained model steering
(e.g., steering at the entity-level, rather than at the document level).

One possibility is to maintain this feedback within the spatialization. That is, instead
of providing a separate view for the explicit feedback, augmenting the spatialization to
include this sort of information may be beneficial. For example, ForceSPIRE includes entity
underlining within the text of a document to inform users of which keywords are entities
in the model. However, this depth of information could be increased, to highlighting words
on a color ramp based on their weight. Then, if users find inconsistencies in the entity
weighting scheme, adjustments can be made, and the bi-directional learning can continue.
To enable the implicit model learning of ForceSPIRE and semantic interaction, an inver-
sion of the mathematical projection model is used. The decision of inverting a mathematical
projection model may be a good fit for systems where the semantic interactions are pri-
marily observation-level interactions. However, other forms of semantic interactions may
not lend themselves to directly inverting a projection model (e.g., highlighting text, per-
forming a search, etc.). One possibility for these forms of interaction is to create a forward
model for each of these, by which the inversion can take place. For example highlight-
ing can be automated given the weights of entities. Then, as users manually highlight (or
change the highlighting that the system recommended), the system can invert the model

J Intell Inf Syst

used for highlighting to maintain mathematically valid visualizations. The fundamental
principles of semantic interaction still apply to these interactions, as they generalize beyond
spatializations and observation-level interactions.

The updating of the spatial layout in ForceSPIRE is very important, as it provides the
opportunity to show the user what has changed from one layout to the other. That is, it
provides the user feedback on what the system has learned from their previous semantic
interaction. Models that are incremental in nature (where the calculation of the lowest-
stress configuration is incrementally obtained) more easily support this concept, as the
user can observe the model achieving the state. For example, users can gain insight into
both the characteristics of the model, as well as the weighting vector, through observing
a force-directed model settling out. Figure 3 illustrates a series of spatializations showing
the progression of the spatialization when using ForceSPIRE. The co-creation of the spa-
tial layout of the dataset through semantic interaction fosters visual data exploration and

Fig. 3 Sample interactions in ForceSPIRE

J Intell Inf Syst

sensemaking. An important design principle here is that the incremental learning of the
model closely mirrors the incremental formalism (Hsieh and Shipman 2002) exhibited by
the analyst’s sensemaking process, both conceptually and spatially.

2.2 Scatter-gather

We now turn to our second example of a visual analytic framework for clustering. This
framework aims to incorporate user input at the level of clusters, rather than instances.

In our experiences working with diverse application scientists, we have identified an
interaction style (Pirolli et al. 1996)—scatter/gather clustering—that helps users iteratively
restructure clustering results to meet their expectations. As the names indicate, scatter and
gather are dual primitives that describe whether clusters in a current segmentation should
be broken up further or, alternatively, brought back together. By combining scatter and
gather operations in a single step (referred to as scatter-gather clustering), we support very
expressive dynamic restructurings of data.

To illustrate the idea of scatter/gather clustering, we use a synthetic dataset composed of
1000 two-dimensional points (see Fig. 4(a)). The dataset is composed of four petals and a
stalk each containing 200 points. When the user applies simple k-means clustering, with a
setting of four clusters (i.e., k = 4), the flower is divided into four parts as shown in Fig.
4(b) where the petals are indeed in different clusters, but each of the petals also takes up
one-fourth of the points from the stalk of the flower. When a setting of five clusters is used,
the user obtains the clustering shown in Fig. 4(c). It is evident that the five clusters generated
by k-means are not able to cleanly differentiate the stalk from the petals.

A conventional clustering algorithms like k-means does not take user expectation as an
input to produce better clustering results. Even constrained clustering algorithms would
require an inordinate number of user interactions to clearly separate the stalk from the petals.
In the scatter-gather clustering framework, the user can provide an input to the algorithm
regarding the expected outcome as shown in Fig. 5. The constraints shown in the middle of
the figure should be read both from left to right and from right to left. Reading from left to
right, we see that the user expects the four clusters to be broken down (scattered) into five
clusters. Reading from right to left, we see that the stalk is expected to gather points from
all current clusters, but there is a one-to-one correspondence between the desired petals to
the original petals. Figure 5 shows that the results of such a scatter/gather clustering provide

Given data: 1000 points

3.5

3.0

2.5

Y

2.0

1.5

1.0

0.5

k-means (k=4)

3.5

3.0

2.5

Y

2.0

1.5

1.0

0.5

k-means (k=5)

3.5

3.0

2.5

Y

2.0

1.5

1.0

0.5

1.5 2.0 2.5 3.0 3.5 4.0 4.5

1.5 2.0 2.5 3.0 3.5 4.0 4.5

1.5 2.0 2.5 3.0 3.5 4.0 4.5

X

(a) Original data

X

(b) k-means (k=4)

X

(c) k-means (k=5)

Fig. 4 Clustering the flower dataset. (a) The dataset has 1000 2D points arranged in the form of a flower.
(b) Result of k-means clustering with k = 4. (c) k-means clustering with k = 5. Points from the stalk spill
over into the petals

J Intell Inf Syst

k
-means (

k=4)

Y

3.5

3.0

2.5

2.0

1.5

1.0

0.5

1.5 2.0 2.5 3.0 3.5 4.0 4.5

X

Scatter/gather clustering

+

Petal 1

Petal 2

Petal 3

Petal 4

Petal 1

Petal 2

Stalk

Petal 3

Petal 4

=

Y

3.5

3.0

2.5

2.0

1.5

1.0

0.5

1.5 2.0 2.5 3.0 3.5 4.0 4.5

X

Fig. 5 Clustering the flower dataset with user provided input: Scatter/gather constraints when imposed over
a clustering with four clusters yields five clusters with well-separated petals and center with the stalk, unlike
Fig. 4(c)

well-separated petals and stalk, unlike the result provided by simple k-means with k=5 (as
shown in Fig. 4(c)). Thus, instead of being frustrated by choosing a seemingly arbitrary
parameter value for k, the analyst directly manipulates the cluster reorganization scheme.
The interaction fits the analyst’s cognitive process of incrementally redistributing specific
clusters to test hypotheses.

The way in which constraints from Fig. 5 are incorporated to revise a clustering is cov-
ered in detail in (Hossain et al. 2012c). Essentially, we prepare a contingency table relating
the current clustering to the target clustering, and use a non-linear optimization framework
to propagate the given mean prototypes through the contingency table, to identify prototypes
for the target clustering.

Figure 6 illustrates the use of scatter-gather clustering by an analyst studying the bat
biosonar system. The expert is trying to find partitions of a woolly horseshoe bat ear. The
expert at first partitions the object into two clusters using k-means clustering (Fig. 6(a)).
The expert finds the partitions interesting. He observes that the boundary and the vertical
ridges are in the same cluster (green), and the rest of the ear is in another cluster. This
fosters a thought in the expert’s mind that the vertical ridges could be separated to form a
new cluster. The expert also believes that there could be less prominent layers in the borders
of the ear. Being unsure about the constraints, the expert provides a uniform scatter/gather
constraint table of size 2× 3 indicating that he desires three clusters out of the two clusters.

e
u
B

l

 
t
h
g
L

i

w
o

l
l
e
Y

d
e
R

Green

Red

e
u
B

l

 
t
h
g
L

i

w
o

l
l
e
Y

d
e
R

Light Blue

Red

Yellow

e
u
B

l

 
t
h
g
L

i

n
e
e
r
G

d
e
R

w
o

l
l
e
Y

Yellow

Red

Light Blue

(a)

(b)

(c)

(d)

Fig. 6 An example of interactive scatter/gather clustering of a woolly horseshoe bat ear. The expert partitions
the ear into four clusters beginning from a setting of two clusters. (a) to (b)—The expert supplies a 2 × 3
constraint table to generate three clusters from two, and the vertical ridge is lost in the result; (b) to (c)—
the expert supplies constraints in a 3 × 3 table to retrieve the vertical ridge; (c) to (d)—the expert provides
constraints in a 3 × 4 matrix to scatter the border into two layers but to keep the rest of the clusters the same

J Intell Inf Syst

Our scatter/gather clustering provides the result shown in Fig. 6(b). The partitioning of
Fig. 6(b) was able to pick up two border layers, but the vertical ridges now diminish inside
the surrounding cluster. At this point, the expert believes that it is more important to reveal
the shape of the vertical ridges rather than discovering the layers in the boundary. The expert
now provides an S/G constraint table to merge two boundaries (light blue and red), and split
the mid region of the ear (yellow) into two clusters. The resulting clusters are shown in Fig.
6(c) where the vertical ridges are well separated in one cluster. The expert now desires to
split the border into two layers that he previously merged. Setting up an S/G constraint table
of size 3 × 4 as shown in the middle of (c) and (d) objects of Fig. 6, the user obtains four
clusters. These four clusters contain two layers of border (green and red), vertical ridges
(light blue), and the flat region of the ear (yellow).

Unlike the way user interaction is used in ForceSPIRE the reader should note that user
input is given here not at the instance level (i.e., specific data points) but at the cluster
level, viz. which clusters should be broken up or brought back together. Thus, scatter-gather
provides a fundamentally different type of interaction paradigm for visual analytics that fits
into the analyst’s process of redistributing clusters.

2.3 Analyst’s workspace

We now shift our attention to navigating and mining large document collections. Analyst’s
Workspace (AW) is a visual analytics environment that i) closely mimics information orga-
nization layouts employed by analysts, ii) relates multiple representations to accommodate
different strategies of exploration, and iii) provide automated algorithmic assistance for for-
aging connections and hypothesis generation. It is primarily targeted at datasets such as the
VAST (Symposium on Visual Analytics Science and Technology) 2011 Challenge dataset
(Mini Challenge 3: Investigation into Terrorist Activity). This dataset contains 4,474 doc-
uments, which are primarily synthetic news stories from a fictitious city newspaper, and
the goal is to uncover the nature of a threat embedded in the document collection. Most of
this collection is actually noise, with only about thirteen of the documents being relevant to
uncovering the plot. Another feature of this dataset is that even if the analyst uncovers all
thirteen documents, some analysis is still required to actually determine the actual form of
the underlying threat.

AW provides the user with a plethora of interaction tools for use with large screen dis-
plays (e.g., familiar click-and-drag selection rectangles, multi-click selections) as well as
information organization facilities (e.g., graph layout, temporal ordering). Because these
operations are local, they only affect the local area or the currently selected documents and
hence enable the analyst to freely mix spatial metaphors (see Fig. 7).

While the primary visual elements in AW are full text documents, we also provide sup-
port at the entity level. Documents are marked up based on extracted entities, and the analyst
can use context menus to quickly identify new entities and create aliases between entities
(Fig. 8). Double clicking an entity of interest in a document opens an entity object, which
is initially displayed as a list of documents in which that entity appears. Entities can also
be collapsed down to a representational icon (Fig. 9), and AW automatically draws links
between entities when they co-occur in a document. These two features allow the ana-
lyst to rapidly construct and explore social networks, which are commonly used tools in
intelligence analysis.

AW also provides basic facilities for text-based search. Search results are displayed as
lists of matching documents in the space, like the entities. The documents are color coded
to tell the analyst the state of a document: open, previously viewed, or never viewed.

J Intell Inf Syst

Fig. 7 An active session in Analyst’s Workspace. Full text documents and entities share the space, with a
mixture of spatial metaphors, such as clusters, graphs and timelines all in evidence. The yellow lines are the
links of the derived social network

Visual links play a strong role in AW. These allow a number of relationships to be
expressed, freeing spatial proximity to be used to express more complex relationships more
directly related to making sense of the dataset.

While Analyst’s Workspace is designed to be support a flexible approach to sensemaking,
it does encourage a particular analytic approach that we observed being used by the analysts.
This is a strategy that Kang et al. referred to as “Find a Clue, Follow the Trail” (Kang et al.
2009). In this strategy, the analyst identifies some starting place and then branches out the
investigation from that point, following keywords and entities.

In AW, a starting point can be provided by the entity browser Fig. 10, which allows the
analyst to order entities by the number of occurrences in the dataset. The analyst opens this
entity and gets a list of documents in which this entity appears. The analyst then works
through these documents, opening new entities or performing searches as new clues are
found. Since all of the search results are independent objects in the space and there is a visual
record of which documents have been visited, AW can support both a breadth-first and a
depth-first search through the information. As the investigation progresses, the analyst uses

Fig. 8 An ’Al-Qaeda’ entity viewed in AW displaying a list of the files in which this entity appears. The
green files are currently open in the workspace, the red have been viewed and rejected by the analyst, and
the white files have not yet been viewed

J Intell Inf Syst

Fig. 9 A section of the generated social network from an AW session. Here, the entities have all been
collapsed down to iconified form

the space to arrange the information as it is uncovered, building and rebuilding structures to
reflect his or her current understanding of the underlying narrative.

While this approach has been shown to be fairly effective (Kang et al. 2009), it does not
permit greater characterization of the dataset and does not support more complex questions
that the analyst might ask. For example, this approach relies entirely on the analyst to pick
the right keywords and entities to “chase,” and can miss less direct lines of investigation.
It is common for terrorists to use multiple aliases or code words that can easily thwart
this approach. However, it is possible that common patterns of behavior or other document
similarities might help the analyst to uncover some of these connections.

AW’s story generation framework is exploratory in nature so that, given starting and end-
ing documents of interest, it explores candidate documents for path following, and heuristics
to admissibly estimate the potential for paths to lead to a desired destination. The generated
paths are then presented to the AW analyst who can choose to revise them or adapt them for
his/her purposes.

J Intell Inf Syst

Fig. 10 AW’s entity browser,
here showing the people
identified in the dataset, sorted
by the number of documents in
which each appears

A story between documents d1 and dn is a sequence of intermediate documents d2,
d3, . . . , dn−1 such that every neighboring pair of documents satisfies some user defined cri-
teria. Given a story connecting a start and an end document, analysts perform one of two
tasks: they either aim to strengthen the individual connections, possibly leading to a longer
chain, or alternatively they seek to organize evidence around the given connection. The
notions of distance threshold and clique size are used to mimic these behaviors.

The distance threshold refers to the maximum acceptable distance between two neighbor-
ing documents in a story. Lower distance thresholds impose stricter requirements and lead
to longer paths. The clique size threshold refers to the minimum size of the clique that every
pair of neighboring documents must participate in. Thus, greater clique sizes impose greater
neighborhood constraints and lead to longer paths. These two parameters hence essentially
map the story finding problem to one of uncovering clique paths in the underlying induced
similarity network between documents.

Figure 11 describes the steps involved in generating stories for interaction by the AW
analyst. For document modeling, a bag-of-words (vector) representation is used where the
terms are weighted by tf-idf with cosine normalization. The search framework has three key
computational stages:

construction of a concept lattice,

1.
2. generating promising candidates for path following, and
3.
evaluating candidates for potential to lead to destination.

Of these, the first stage can be viewed as a startup cost that can be amortized over multi-
ple path finding tasks. The second and third stages are organized as part of an A* search
algorithm that begins with the starting document, uses the concept lattice to identify candi-
dates satisfying the distance and clique size requirements, and evaluates them heuristically

Stop-word 
removal and 

stemming

Document 
modeling

Concept
lattice  
generation

Input 

documents

Fig. 11 Pipeline of the storytelling framework in AW

Analyst’s 

input

Heuristic 
search

J Intell Inf Syst

for their promise in leading to the end document. Hossain et al. (2011; 2012a) describe the
storytelling algorithms in great details.

The analyst may also need the discovery of paths through the dataset to be more efficient.
For example, the analyst may have uncovered that a revolutionary in South America shares
the same last name as a farmer in the Pacific Northwest who has been implicated in some
nefarious affairs and wishes to ask if there is any link between them other or if their last
name is a coincidence. An exhaustive background check of the two men is possible through
AW if the dataset is relatively small, but it is an indirect and time consuming process.

Figure 12 shows an example of the usage of AW and our algorithms. In this scenario, the
analyst requests a story connecting a pair of interesting documents. The algorithm returns a
story but the analyst is not satisfied with parts of the story. The analyst then requests infor-
mation about documents in the surrounding neighborhood of an intermediate document.
Having explored the local neighborhood, the analyst identified two additional documents
that form a more meaningful connection and extends the original story. An important design
principle here is that the invocation and output of the storytelling algorithms occurs within
the analyst’s spatial layout, thus fitting naturally into their cognitive sensemaking process.
The end points of the story provide spatial anchors for the new information.

2.4 Bixplorer

Bixplorer is a visual analytics prototype (Fiaux 2012) that supports interactive exploration
of textual datasets in a spatial workspace using biclusters. A bicluster, or biclique, is a
complete bipartite subgraph in a relation, i.e., where every entity in one set is connected to
all entities of another set. Biclusters across entity types serve as an important abstraction by
‘bundling’ relationships into cohesive units that are key navigation aids as well as units of
knowledge discovery in themselves.
Consider Fig. 13 involving a relation capturing attendance of students in specific classes,
we might infer a bicluster involving a set of students {S1,S2,S3} all of whom attend the same
set of classes {C1,C2,C3,C4}. Biclusters are typically maximal, i.e., additional students and
additional classes cannot be added into the bicluster because they will not have a relation to
each other (in the original matrix).

Since biclusters are discovered in a single relation, we can ‘compose’ biclusters discov-
ered separately across two relations by (approximately) matching the biclusters across the
common domains. Jin et al. (2008) present this approach to identify compositional patterns
in multi-relational datasets. As shown in Fig. 14, biclusters from three different relations can
be chained using the common interfaces of people (between the first and second relation)
and places (between the second and third relation). The results of such compositions can be
read sequentially from one end to the other, not unlike a story. For instance in the scenario
from Fig. 14, we might learn about ‘a group of faculty from CS and other departments’,
many of whom ‘are planning a trip to Austin, Texas and nearby places’, the dates of which
are approximately aligned with ‘the second week of May 2012’; this might lead us to infer
that they are likely HCI researchers planning to attend the CHI’12 conference. Documents
supporting these relationships can then be inspected to gather evidence for this hypothesis.
Thus, by relating biclusters across multiple relations we can ‘bundle’ relationships from a
diversity of domains in a coherent manner. Such bundling and composition constitute one
of the key features of Bixplorer.

Bixplorer is closest in spirit to hybrid matrices and node-link diagrams. NodeTrix, the
work of Henry et al., allows exploration of social networks through a hybrid visualization of
adjacency matrices (for dense subgraphs) and node-link diagrams (for sparse connections

J Intell Inf Syst

The generated story between the two endpoints. The system has identified 
two linking documents, and connected them together into a linked story.

The analyst requests a story connecting a pair of interesting 
documents. 

A list of the neighbors of the third document. The lines 
provide visual links to open documents.

Unsatisfied with the strength of the connection, the analyst requests 
information about documents in the surrounding neighborhood (i.e., 
within the local clique).

New connections have been manually added to extend the story

Having explored the local neighborhood, the analyst has identified 
two additional documents that form a more meaningful connection 
and extends the original story.

Fig. 12 Illustration of interactively finding a story in AW

between the subgraphs) (Henry et al. 2007). Through clustering and linking clusters, users
can explore relationships of a single type, such as co-authorship between authors. NodeTrix
generates initial clusters, and then allows users to group or ungroup nodes to explore how
they interact with the layout. OntoTrix by Bach et al. extends this technique to work with
ontologies with multiple types of relationships (Bach et al. 2011). Thus allowing clustering
and linking nodes of different types within the same graph. Bixplorer is different in that we
use biclusters as the key unit of information organization rather than clusters and individual
relationships.

J Intell Inf Syst

Fig. 13 Example bicluster extracted from a student to classes relationship. Dark cells represent relationships,
orange cells represent relationships part of this specific bicluster

Bixplorer uses closed itemset mining algorithms such as CHARM (Zaki and Hsiao 2002)
and LCM (Uno et al. 2003); the results of such algorithms are then chained and made avail-
able for sensemaking (Fig. 15). Initially, the workspace is empty. Throughout the course
of their analysis, users add documents and biclusters into the workspace. The workspace
enables users to organize and visualize biclusters and documents together, and the links
between them, in a single space. Figure 16 shows Bixplorer on a large, high-resolution dis-
play. Previous studies and tools have shown that a spatial workspace such as this enables
users to create spatial representations (e.g., clusters, timelines, etc.) to capture their insights
about the dataset (Andrews et al. 2010; Shipman and Marshall 1999; Endert et al. 2012). As
such, biclusters and documents can be repositioned within the space by the user. A ‘Link
to...’ function from the context menu allows users to create custom links between elements.
User-defined links are shown in blue, whereas white links are computationally determined
by the data mining.

We conducted a user study of Bixplorer with the Atlantic Storm dataset. Initial text
extraction and mining was done offline, resulting in 437 unique entities, 4257 relation-
ships, and 1001 biclusters. We learnt that each of the users was successful in integrating

Fig. 14 Chaining biclusters
through multiple relations by
approximately matching sets of
entities across common domains

Organizations

Places

e
e
l
p
o
e
P

e
e
l
l
p
p
o
o
e
e
P
P

s
s
e
e
t
t
a
a
D
D

Places

J Intell Inf Syst

Fig. 15 Sample area of graph workspace with biclusters and documents connected

biclusters into the spatial analysis of the dataset, leveraging the visual representation of
relationships in a variety of ways. Although none of the users in this study had previous
experience or knowledge of biclusters, each of them was able to quickly integrate biclusters
into their process.Biclusters were used to quickly scan relationships, to provide an overview
of relationships involving a specific document, and to transition between the overview to
the documents that are contained in the bicluster. Thus, user explored bicluster chains by
intermittently injecting documents into the chain. This enabled a rapid exploration of the
dataset, and users were able to quickly follow leads of suspicious entities and identify the
latent plot. Biclusters also played a significant role in the final analytic product of the users.
The spatial workspace was used to visually maintain the biclusters and documents that the
users deemed relevant. Therefore, their findings were based on not only the documents,
but also the biclusters. Users referred to the biclusters as a collection of evidence through
which two or more documents were connected. Also, users found biclusters to be a useful
label for a particular region of the workspace, capturing and representing the relationships

Fig. 16 Bixplorer on a large, high-resolution display

J Intell Inf Syst

there at a high level. Thus, biclusters are a powerful visual representation of entity relation-
ships within a data set. The encouraging results of this study show potential for future work
exploring the benefits of biclusters not only as a visual representation of relationships, but
also as a complex glyph with which users can interact.

3 Future opportunities

We have given an overview of four varied visual analytics projects, each of which pro-
vides rich capabilities for human interaction. We now present some possible themes that can
serve to make interaction even more central, thus helping further the ‘human is the loop’
philosophy.

3.1 Mixing interaction modes

Users refer to information in different regions of spatializations with different contexts and
metaphors (Andrews et al. 2010; Robinson 2008). Common metaphors include topical clus-
ters, timelines, geospatial layouts, and social networks. Users frequently mix metaphors
within the same workspace as either separate or nested schemas (Andrews et al. 2010;
Robinson 2008). These metaphors may be well defined or ambiguous, and may evolve over
time. This mixed-metaphor use of a spatialization poses challenges to layout and clustering
models that are generally designed to compute a single model layout across the entire visu-
alization. For example, iCluster (Drucker et al. 2011) which enables direct manipulation of
a cluster model, could be combined with ForceSpire (Endert et al. 2012b) to enable dynamic
layout of clusters, in much the same way as analysts currently do manually.

Challenge 1: How do we detect, interpret, compute, and visualize mixed models that
represent mixed metaphors?

Challenge 2: How can we learn which model best captures the user’s domain
knowledge based on the layout?

Existing work has manually identified users’ spatial metaphors (Andrews et al. 2010;
Robinson 2008). Work in spatial parsers has developed heuristics for recognizing certain
patterns (Marshall et al. 1994). Currently, tools make assumptions regarding user intentions
(Endert et al. 2012b) or require explicit interaction by the user, such as switching views.

One way to organize mixed models is to operate at multiple levels of scale (Table 2).
When all data points can feasibly be displayed on the screen, dimensionality reduction (DR)
models can be used to lay out space, but this is less appropriate for larger datasets where the
data points overfill the screen. At larger scales, cluster models can be aggregate data into
visual groups. At even larger scales, information retrieval (IR) algorithms become essen-
tial to streaming or sampling data to dynamically display relevant data. A consistent direct
manipulation approach to interaction can be applied across each level of scale. For exam-
ple, IR algorithms can query for data relevance based on dimension weights learned by DR
models, and learn from user actions such as placing uninteresting data in the ‘trash pile.’

Challenge 3: How should direct manipulation be used to steer models across multiple
scales?

J Intell Inf Syst

Table 2 Multi-scale models

Levels of scale

Display scale

Database scale

Cloud scale

Usage Description

System lays out data
according to users
spatial organization
feedback
Data scale of manipulation <1 Million
Algorithms

System groups clusters
of data in the layout
according to users
grouping feedback
<1 Billion

Dimensionality reduction Clustering, Classification,

Visualization

Spatial layout; Visual
proximity = similarity

Interactive feedback
for machine learning

Similarities, dimension
weights, object weights

Topic modeling
Groups, hierarchy,
containment; Visual
group = similarity
Group counts and
contents, centroid
landmarks, labels

System uses layout to
query very large data
and retrieve additional
relevant data
>1 Trillion
Information retrieval,
sampling, streaming
Salience, 3rd
dimension; Visual
salience = similarity
Object relevance,
keyword dimensions
and weights

ForceSpire can be viewed as initial steps in this direction; it combines several of these
techniques (e.g. document repositioning, highlighting, annotations, searching) in one sys-
tem that tightly couple with the underlying dimension reduction model (Endert et al. 2012b).
In addition to providing spatial constraints, the fundamental enhancement of this form of
interactions is the ability to provide these constraints directly on the information (e.g.,
pinning a document to a specific location), and performing interactions that change the
dimension-weighting scheme applied to the underlying dimension reduction models. For
example, highlighting a phrase that contains a set of keywords implies increasing the weight
of the corresponding dimensions (Endert et al. 2012b). The spatialization updates to reflect
the incremental insights generated, creating a symbiotic relationship between the user’s
sensemaking and the system’s machine learning.

3.2 Expressive forms of feedback for data mining algorithms

We have re-iterated the importance of user-provided feedback but thus far the forms of
feedback considered are typically critiques of current results or preferences or constraints
of desired outputs. It is not difficult to contemplate more structured and more expressive
forms of feedback that will require significant re-tooling of algorithms.

Challenge 4: Can we design expressive forms of feedback more naturally adapted to
the visual forms of interaction that users desire?

For instance, in the storytelling algorithm described above, users typically are able to pro-
vide feedback in the form of ‘I would prefer this story NOT use this document’ or ‘I would
prefer that the story provide a justification for why this entity participates in it.’ Such a feed-
back is quite non-trivial to translate back into the algorithmic machinery. This is because the
algorithm is geared toward finding paths through document similarity networks, and thus the
constraint must be translated into inequalities involving paths, and solved simultaneously to
ensure that previously discarded paths become superior.

J Intell Inf Syst

Going forward, it is conceivable that as visual analytics applications proliferate we will
need to be more organized in terms of how we design user feedback/interaction mechanisms
and the way in which such feedback is incorporated into constraints:

Challenge 5: Can we develop a taxonomy of user feedback and algorithmic constraints
that can be used to standardize application development?

3.3 Space as a medium between human intuition and machine learning

Visualizations are intended to provide a visual representation of structure within informa-
tion, with the purpose of illuminating patterns, relationships, trends, and other observable
features within a dataset. Through continuous visual exploration, the features within the
visual representation establish meaning to the user. For example, a two-dimensional spatial-
ization of text reports may initially reveal themes or groups of related information. However,
through exploration, more meaning and insight is generated, and the spatial layout begins to
help the user construct a mental model of the data (Andrews et al. 2010; Endert et al. 2012).
An emerging opportunity for visual analytics is combining the computational advan-
tages of data mining with the cognitive abilities of users by considering the visualization
as a medium for interaction and analysis, and therefore an artifact to help facilitate com-
mon ground between user and system (Clark and Brennan 1991). Common ground (an
understood shared knowledge between two or more parties) is created by the computational
generation of the visualization, and the user-driven exploration and interaction with it.

Challenge 6: How can visualizations serve as artifacts for common ground between
algorithms and users?

For instance, consider a two-dimensional spatialization created algorithmically (see
Fig. 17). Similarity between data points is typically shown as relative Euclidean distance

HOW TO NEGOTIATE COMMON GROUND

Similarity

COMPUTATION:
(cid:129) Distance function
(cid:129) Stress reduction/ 
minimization

COGNITION:
(cid:129) Related terms
(cid:129) Past connection known
(cid:129) Domain expertise

Fig. 17 Negotiating common ground between computation and cognition

J Intell Inf Syst

between any two points. Computationally, this distance was determined by a distance func-
tion that calculated, based on several features of the data, and how far those two points
should be apart. Such an output is easily interpretable by the user. However, users often
have domain knowledge that contradicts the features used in distance function calculations.
To share this knowledge with the system, they can interact with parameters of the distance
reduction algorithm to reflect this knowledge. As a result, the system and user engage in a
discourse to facilitate the process of common ground.

To strengthen this process, user interactions can be designed to occur directly within
the visual representation of the data, instead of directly on model parameters. User inter-
action approaches such as semantic interaction (Endert et al. 2012), relevance feedback
(MacArthur et al. 2002), and distance function learning (Brown et al. 2012) help facilitate
this capability. These approaches present opportunities to engage users with metric learning,
semi-supervised machine learning, and other computationally valuable methods of model
steering without requiring expertise in data mining. Further, the ability for these approaches
to enable the interactions purely within the visual space strengthens the process of common
ground.

Challenge 7: How can domain knowledge be captured and communicated spatially?

In instantiating these features, the important distinction is in how the user communi-
cates knowledge back to the system. Instead of directly manipulating model parameters, the
insights that are gained spatially can be communicated spatially. If the user identifies two
documents that are computationally placed far apart (implying dissimilarity), the distance
function can be trained by relocating those two points closer together in the spatialization.
As a result, the domain knowledge of the user is captured, interpreted, and extrapolated
across the entire dataset (Endert et al. 2012), resulting in other data points correcting their
relative distances from each other. The success of these approaches for user interaction
in visual analytics has the potential to transform the analytic workflow of visual analytics
users. Instead of structuring sensemaking around the computational models, the focus shifts
back to thinking visually while maintaining the computational advantages of data mining.

3.4 Towards design principles

Our examples suggest design principles for ‘human is the loop’. User input and visual feed-
back are conducted and presented within the context of the analyst’s process. User input
includes both the algorithm invocation command as well as the parameters and settings for
the algorithm execution. Implicit steering is perhaps the ultimate form of in-context input
as it passively takes advantage of interactions the analysts are already performing anyway
(Endert et al. 2011), and the already existing objects/parameters of those interactions.

Yet, explicit steering can be carefully inserted within context as well. In the AW example,
the user may explicitly invoke the algorithm to find connections, but the parameters evolve
directly out of the user’s spatial layout and analytic process. Analysts frequently pose hypo-
thetical connections by drawing a dotted line between entities, and thus also can trigger a
connection finding algorithm. This perhaps suggests a potential implicit approach in which
the invocation is automatic for proximal objects and numerous connections are visualized
as a background distribution. Thus, space becomes the medium for computation.

At the opposite end of the spectrum would be completely out-of-context approaches. For
example, the user might be required to export the data and load it into a separate algorithm
while specifying numerous complex parameters, and then compare results back to their
manual layout. The design tension is to strive for as much in-context as possible, while

J Intell Inf Syst

preserving user control and expressiveness. It should be noted that the implicit approach,
while appearing indirect to algorithm designers since interpretation is required, appears
direct to the users because the operations are on objects of their concern, and in the domain
of their expertise. Such implicit approaches map more closely to the user’s flow of analysis
(Elmqvist et al. 2011). When users stay in this ‘cognitive zone’ (Green et al. 2009), they can
more effectively engage in sensemaking. Empirical evidence suggests that users prefer the
implicit approach (Endert et al. 2012a) when carefully designed.

Interactions must also be cumulative. In many cases, the analyst must come to a con-
clusion incrementally (Shipman and Marshall 1999). If the conclusion were given to the
analyst at the very beginning, it is likely that the analyst would not understand nor recog-
nize it as a meaningful conclusion because it would be out of context. The analyst needed
to experience the process. Sensemaking is inherently situated. Furthermore, there typically
is not a single conclusion, but rather the analyst explores multiple alternative hypotheses so
as to avoid confirmation bias (Heuer 1999). Thus, algorithms must incrementally adapt and
compute over potentially large interaction data throughout this process.

This approach also suggests a highly integrated design in which many algorithms are
simultaneously responding to user input. We are not suggesting a single panacea tool, but
rather a compositional approach. In sensemaking for example, there are numerous oppor-
tunities for better integrating the foraging and synthesis halves of the sensemaking process
(Andrews and North 2012).

4 Conclusion

We have provided a tour of visual analytics projects with a peek into the type of capabilities
that might be enabled in the future. Beyond the interactive visualization and computational
construction of semantically associated information objects, our goal is to ultimately under-
stand how human analysts makes sense of data. The traditional viewpoint is that users can
specify reasoning structures or frameworks and algorithms can help fill in the blanks. But it
is not clear that such a viewpoint advances the user’s conceptualization. We have argued that
if space, visual entities, and algorithms become material objects that support joint reasoning
between human and the machine, then users can perform actions that establish understand-
ing to the algorithms, and be rewarded with results that fit naturally in the context of their
analytic process. This can significantly further the cause and objectives of visual analytics
research.

Acknowledgments This work is supported in part by the Institute for Critical Technology and Applied
Science, Virginia Tech, and the US National Science Foundation through grant CCF-0937133.

References

Aghabozorgi, S.R., & Wah, T.Y. (2009). Recommender systems: incremental clustering on web log data. In

ICIS ’09 (pp. 812–818).

Alonso, O., & Talbot, J. (2008). Structuring collections with scatter/gather extensions. In SIGIR ’08

(pp. 697–698).

Alsakran, J., Chen, Y., Zhao, Y., Yang, J., Luo, D. (2011). STREAMIT: dynamic visualization and interactive

exploration of text streams. In PACIFICVIS ’11 (pp. 131–138).

Andrews, C., Endert, A., North, C. (2010). Space to think: large high-resolution displays for sensemaking.

In CHI ’10 (pp. 55–64).

J Intell Inf Syst

Andrews, C., & North, C. (2012). Analyst’s workspace: an embodied sensemaking environment for large,

high resolution displays. In VAST ’12.

Bach, B., Pietriga, E., Liccardi, I., Legostaev, G. (2011). OntoTrix: a hybrid visualization for populated

ontologies. In WWW ’11 (pp. 177–180).

Baron, A., & Freedman, M. (2008). Who is who and what is what: experiments in cross-document co-

reference. In EMNLP ’08 (pp. 274–283).

Brown, E.T., Liu, J., Brodley, C.E., Chang, R. (2012). Dis-function: learning distance functions interactively.

In VAST ’12.

Cadez, I., Heckerman, D., Meek, C., Smyth, P., White, S. (2003). Model-based clustering and visualization

of navigation patterns on a web site. Data Mining and Knowledge Discovery, 7(4), 399–424.

Clark, H.H., & Brennan, S.A. (1991). Grounding in communication. In Perspectives on socially shared

cognition. Washington, DC: APA Books.

Davidson, I., Ravi, S., Ester, M. (2007). Efficient incremental constrained clustering. In KDD ’07 (pp. 240–

249).

Davidson, I., & Ravi, S.S. (2005). Clustering with constraints: feasibility issues and the k-means algorithm.

In SDM ’05 (pp. 201–211).

Drucker, S.M., Fisher, D., Basu, S. (2011). Helping users sort faster with adaptive machine learning

recommendations. In INTERACT ’11 (pp. 187–203).

Eccles, R., Kapler, T., Harper, R., Wright, W. (2008). Stories in GeoTime. Information Visualization, 7(1),

3–17.

Elmqvist, N., Moere, A.V., Jetter, H.-C., Cernea, D., Reiterer, H., Jankun-Kelly, T.J. (2011). Fluid interaction

for information visualization. Information Visualization, 10(4), 327–340.

Endert, A., Fiaux, P., Chung, H., Stewart, M., Andrews, C., North, C. (2011). ChairMouse: leveraging natural

chair rotation for cursor navigation on large, high-resolution displays. In CHI EA ’11 (pp. 571–580).

Endert, A., Fiaux, P., North, C. (2012a). Semantic interaction for sensemaking: inferring analytical reasoning

for model steering. In VAST ’12.

Endert, A., Fiaux, P., North, C. (2012b). Semantic interaction for visual text analytics. In CHI ’12 (pp.

473–482).

Endert, A., Fox, S., Maiti, D., Leman, S., North, C. (2012). The semantics of clustering: analysis of user-

generated spatializations of text documents. In AVI ’12 (pp. 555–562).

Endert, A., Han, C., Maiti, D., House, L., Leman, S., North, C. (2011). Observation-level interaction with

statistical models for visual analytics. In VAST ’11 (pp. 121–130).

Ernst, J., Nau, G., Joseph, Z. (2005). Clustering short time series gene expression data. Bioinformatics, 21,

i159–i168.

Fiaux, P. (2012). Solving intelligence analysis problems using biclusters. Blacksburg, VA: Master’s thesis,

Virginia Tech. http://scholar.lib.vt.edu/theses/available/etd-02202012-084450/.

Fink, G.A., North, C.L., Endert, A., Rose, S. (2009). Visualizing cyber security: usable workspaces. In VizSec

’09 (pp. 45–56).

Green, T.M., Ribarsky, W., Fisher, B. (2009). Building and applying a human cognition model for visual

analytics. Information Visualization, 8(1), 1–13.

Guha, R., Kumar, R., Sivakumar, D., Sundaram, R. (2005). Unweaving a web of documents. In KDD ’05

(pp. 574–579).

Henry, N., Fekete, J.-D., McGuffin, M.J. (2007). NodeTrix: a hybrid visualization of social networks. TVCG,

13(6), 1302–1309.

Heuer, R. (1999). Psychology of intelligence analysis. CIA: Center for the study of intelligence.
Hossain, M.S., Akbar, M., Polys, N.F. (2012). Narratives in the network: interactive methods for mining cell

signaling networks. Journal of Computational Biology, 19(9), 1043–1059.

Hossain, M.S., Andrews, C., Ramakrishnan, N., North, C. (2011). Helping intelligence analysts make con-
nections. In AAAI ’11 workshop on scalable integration of analytics and visualization (WS-11-17) (pp.
22–31).

Hossain, M.S., Butler, P., Boedihardjo, A.P., Ramakrishnan, N. (2012a). Storytelling in entity networks to

support intelligence analysts. In KDD ’12 (pp. 1375–1383).

Hossain, M.S., Gresock, J., Edmonds, Y., Helm, R., Potts, M., Ramakrishnan, N. (2012b). Connecting the

dots between PubMed abstracts. PLoS ONE, 7(1), e29509.

Hossain, M.S., Ojili, P.K.R., Grimm, C., Mueller, R., Watson, L.T., Ramakrishnan, N. (2012c). Scatter/gather

clustering: flexibly incorporating user feedback to steer clustering results. In VAST ’12.

Hossain, M.S., Tadepalli, S., Watson, L., Davidson, I., Helm, R., Ramakrishnan, N. (2010). Unifying

dependent clustering and disparate clustering for non-homogeneous data. In KDD ’10 (pp. 593–602).

Hsieh, H., & Shipman, F.M. (2002). Manipulating structured information in a visual workspace. In UIST’02

(pp. 217–226).

J Intell Inf Syst

Huang, Y., & Mitchell, T.M. (2006). Text clustering with extended user feedback. In SIGIR ’06 (pp. 413–

420).

Hwang, I., Kahng, M., Lee, S. (2011). Exploiting user feedback to improve quality of search results

clustering. In ICUIMC ’11 (Vol. 5, pp. 68:1–68:5).

i2group. The analyst’s notebook. http://www.i2group.com/us. Accessed 08 Oct 2012.
Jain, A.K., Murty, M.N., Flynn, P.J. (1999). Data clustering: a review. ACM Computing Surveys, 31(3), 264–

323.

Jeong, D.H., Ziemkiewicz, C., Fisher, B., Ribarsky, W., Chang, R. (2009). iPCA: an interactive system for

pca-based visual analytics. Computers and Graphics Forum, 28(3), 767–774.

Jin, Y., Murali, T.M., Ramakrishnan, N. (2008). Compositional mining of multirelational biological datasets.

ACM Transactions Knowledge in Discovery Data, 2(1), 1–35.

Kang, Y., Grg, C., Stasko, J. (2009). The evaluation of visual analytics systems for investigative analysis:

deriving design principles from a case study. In VAST (pp. 139–146).

Keim, D.A., Mansmann, F., Thomas, J. (2010). Visual Analytics: how much visualization and how much

analytics?. SIGKDD Exploration Newsletter, 11(2), 5–8.

Kelleher, C., & Pausch, R. (2007). Using storytelling to motivate programming. Communications of the ACM,

50(7), 58–64.

Kielman, J., Thomas, J., May, R. (2009). Foundations and frontiers in visual analytics. Information

Visualization, 8(4), 239–246.

Kuchinsky, A., Graham, K., Moh, D., Adler, A., Babaria, K., Creech, M.L. (2002). Biological storytelling: a
software tool for biological information organization based upon narrative structure. ACM SIGGROUP
Bulletin, 23(2), 4–5.

Kumar, D., Ramakrishnan, N., Helm, R., Potts, M. (2006). Algorithms for storytelling. In KDD ’06.
Kumar, D., Ramakrishnan, N., Helm, R., Potts, M. (2008). Algorithms for storytelling. IEEE Transactions

on Knowledge and Data Engineering, 20(6), 736–751.

Liang, J., Abidi, B., Abidi, M. (2003). Automatic x-ray image segmentation for threat detection. In ICCIMA

’03 (pp. 396–401).

Liu, J., Brown, E.T., Chang, R. (2011). Find distance function, hide model inference. In VAST ’11 (pp.

289–290).

MacArthur, S.D., Brodley, C.E., Kak, A.C., Broderick, L.S. (2002). Interactive content-based image retrieval

using relevance feedback. Computer Vision and Image Understanding, 88(2), 55–75.

Madeira, S.C., & Oliveira, A.L. (2004). Biclustering algorithms for biological data analysis: a survey.

IEEE/ACM Transactions Computer Biology Bioinformatics, 1(1), 24–45.

Marshall, C.C., Shipman, III F.M., Coombs, J.H. (1994). VIKI: spatial hypertext supporting emergent

structure. In ECHT ’94 (pp. 13–23).

Miao, G., Tatemura, J., Hsiung, W., Sawires, A., Moser, L. (2009). Extracting data records from the web

using tag path clustering. In WWW ’09 (pp. 981–990).

Momtazpour, M., Butler, P., Hossain, M.S., Bozchalui, M.C., Ramakrishnan, N., Sharma, R. (2012). Coor-
dinated clustering algorithms to support charging infrastructure design for electric vehicles. In The ACM
SIGKDD international workshop on urban computing, UrbComp ’12 (pp. 26–133).

Monti, S., Tamayo, P., Mesirov, J., Golub, T. (2003). Consensus clustering: a resampling-based method for

class discovery and visualization of gene expression microarray data. Machine Learning, 52, 91–118.

Petrushin, V. (2005). Mining rare and frequent events in multi-camera surveillance video using self-

organizing maps. In KDD ’05 (pp. 794–800).

Pirolli, P., & Card, S. (2005). The sensemaking process and leverage points for analyst technology as

identified through cognitive task analysis. In ICIA ’05.

Pirolli, P., Schank, P., Hearst, M., Diehl, C. (1996). Scatter/gather browsing communicates the topic structure

of a very large text collection. In CHI ’96 (pp. 213–220).

PNNL (2012). Pacific Northwest National Laboratory, IN-SPIRE Visual Document Analysis. http://in-spire.

pnnl.gov/. Accessed 08 Oct 2012.

Robinson, A.C. (2008). Design for synthesis in geovisualization. University Park, PA: PhD thesis, Pennsyl-

vania State University.

Rzhetsky, A., Iossifov, I., Loh, J.M., White, K.P. (2006). Microparadigms: chains of collective reasoning
in publications about molecular interactions. Proceedings of the national academy of sciences, USA,
103(13), 4940–4945.

Sese, J., Kurokawa, Y., Monden, M., Kato, K., Morishita, S. (2004). Constrained clusters of gene expression

profiles with pathological features. Bioinformatics, 20(17), 3137–3145.

Shaparenko, B., & Joachims, T. (2007). Information genealogy: uncovering the flow of ideas in non-

hyperlinked document databases. In KDD ’07 (pp. 619–628).

J Intell Inf Syst

Shipman, F.M., & Marshall, C.C. (1999). Formality considered harmful: experiences, emerging themes, and

directions on the use of formal representations in interactive systems. CSCW, 8, 333–352.

Simoff, S., Bhlen, M., Mazeika, A. (2008). Visual data mining: an introduction and overview. In S. Simoff,

M. Bhlen, A. Mazeika (Eds.), Visual Data Mining (Vol. 4404, pp. 1–12). Berlin/Heidelberg: Springer.

Stasko, J., G¨org, C., Liu, Z. (2008). Jigsaw: supporting investigative analysis through interactive visualiza-

tion. Information Visualization, 7(2), 118–132.

Thomas, J.J. & Cook, K.A. (Eds.), (2005). Illuminating the path: the research and development agenda for

visual analytics. IEEE Computer Society Press.

Uno, T., Asai, T., Uchida, Y., Arimura, H. (2003). LCM: an efficient algorithm for enumerating frequent

closed item sets. In FIMI03.

Van Wijk, J.J., & Van Selow, E.R. (1999). Cluster and calendar based visualization of time series data. In

INFOVIS ’99 (pp. 4–9).

Wagstaff, K., Cardie, C., Rogers, S., Schr¨odl, S. (2001). Constrained k-means clustering with background

knowledge. In ICML ’01 (pp. 577–584).

Wang, X., & Davidson, I. (2010). Flexible constrained spectral clustering. In KDD ’10 (pp. 563–572).
Wright, W., Schroh, D., Proulx, P., Skaburskis, A., Cort, B. (2006). The sandbox for analysis: concepts and

methods. In CHI ’06 (pp. 801–810).

Wu, H., Mampaey, M., Tatti, N., Vreeken, J., Hossain, M.S., Ramakrishnan, N. (2012). Where do i start?
algorithmic strategies to guide intelligence analysts. In ACM SIGKDD workshop on intelligence and
security informatics ISI-KDD ’12 (pp. 3:1–3:8).

Xu, Y., Olman, V., Xu, D. (2002). Clustering gene expression data using a graph-theoretic approach: an

application of minimum spanning trees. Bioinformatics, 18(4), 536–545.

Zaki, M., & Hsiao, C. (2002). Charm: an efficient algorithm for closed itemset mining. In SIAM international

conference on data mining (pp. 457–473).

","{""0"":{""0"":""level*"",""1"":""table*"",""2"":""ground*"",""3"":""scale*"",""4"":""size"",""5"":""setting*""},""1"":{""0"":""gather"",""1"":""scatter"",""2"":""north"",""3"":""shown"",""4"":""stalk"",""5"":""vertical""},""2"":{""0"":""clustering*"",""1"":""clusters*"",""2"":""biclusters*"",""3"":""endert"",""4"":""petal"",""5"":""bicluster*""},""3"":{""0"":""model*"",""1"":""visualization*"",""2"":""input*"",""3"":""representation*"",""4"":""manipulation*"",""5"":""projection*""},""4"":{""0"":""user*"",""1"":""documents"",""2"":""analytics*"",""3"":""andrews*"",""4"":""bixplorer*"",""5"":""mail*""},""5"":{""0"":""entities*"",""1"":""forcespire*"",""2"":""forms*"",""3"":""links"",""4"":""classes*"",""5"":""places*""},""6"":{""0"":""interaction*"",""1"":""interactions*"",""2"":""relationships*"",""3"":""metaphors*"",""4"":""pair*"",""5"":""relations*""},""pos"":{""0"":1,""1"":2,""2"":3,""3"":4,""4"":5,""5"":6}}",2014,{},False,False,journalArticle,False,4J6N3XSN,[],self.user,"{""C"":{""0"":12.9464462143,""1"":8.8970905964,""10"":13.7502802062,""11"":13.872766824,""12"":6.7155594134,""13"":10.3123236737,""14"":5.0897999834,""15"":5.7221021153,""16"":7.921787295,""17"":5.1230571049,""18"":9.4882689684,""19"":6.0312649229,""2"":14.3738153986,""20"":5.9118348787,""21"":10.7111321972,""22"":7.1034508034,""23"":7.2236647575,""24"":4.4638477791,""25"":7.4377896346,""26"":13.3755641147,""27"":6.8440668621,""28"":5.7370350416,""29"":12.0039113241,""3"":5.847054771,""30"":5.6363961526,""31"":5.2293778809,""32"":6.112820256,""33"":21.9859905238,""34"":10.6104233462,""35"":4.6842626259,""36"":5.3671485762,""37"":5.6970536853,""38"":5.2839633515,""39"":5.2246441558,""4"":15.3721606122,""40"":10.2758109345,""41"":16.4857470558,""42"":14.7404682702,""43"":8.1620562099,""44"":5.3110540547,""45"":14.1561394082,""46"":13.1383993896,""47"":7.2182795683,""48"":8.477577988,""49"":10.6974900748,""5"":10.130855394,""50"":13.5275258308,""51"":6.2719819323,""52"":9.5719891749,""53"":5.0166900651,""54"":9.5368596695,""55"":10.1752600206,""56"":4.8103442401,""57"":9.6202736899,""58"":9.7321460798,""59"":6.6273747123,""6"":11.7652948764,""60"":6.4601423594,""61"":7.9032164313,""62"":5.3959564946,""63"":6.7762038842,""64"":4.9534907601,""65"":6.5810301739,""66"":6.5556129427,""67"":4.799711511,""68"":5.1542839809,""69"":6.6305181756,""7"":6.3835362637,""70"":5.7815052065,""71"":6.4285519267,""72"":6.1938414634,""73"":6.391326649,""74"":5.2832403171,""75"":5.3928014492,""76"":4.8222298488,""77"":5.5812217402,""78"":4.7067531533,""79"":5.645957156,""8"":11.7680039795,""80"":5.313125478,""81"":5.376971144,""82"":6.3304516619,""83"":6.0033624198,""84"":5.2139400243,""85"":6.3997021771,""86"":5.8541823719,""87"":6.1217301828,""88"":4.6103771603,""89"":4.6685623388,""9"":11.4412860101,""90"":4.7029239656,""91"":4.5661357694,""92"":4.6582754413,""93"":4.5797361671,""94"":4.6685555879,""95"":4.6960361552,""96"":4.5629356015,""97"":4.6411721878},""Unnamed: 0"":{""0"":0,""1"":1,""10"":10,""11"":11,""12"":12,""13"":13,""14"":14,""15"":15,""16"":16,""17"":17,""18"":18,""19"":19,""2"":2,""20"":20,""21"":21,""22"":22,""23"":23,""24"":24,""25"":25,""26"":26,""27"":27,""28"":28,""29"":29,""3"":3,""30"":30,""31"":31,""32"":32,""33"":33,""34"":34,""35"":35,""36"":36,""37"":37,""38"":38,""39"":39,""4"":4,""40"":40,""41"":41,""42"":42,""43"":43,""44"":44,""45"":45,""46"":46,""47"":47,""48"":48,""49"":49,""5"":5,""50"":50,""51"":51,""52"":52,""53"":53,""54"":54,""55"":55,""56"":56,""57"":58,""58"":59,""59"":60,""6"":6,""60"":61,""61"":62,""62"":63,""63"":64,""64"":65,""65"":66,""66"":67,""67"":68,""68"":71,""69"":72,""7"":7,""70"":73,""71"":74,""72"":75,""73"":76,""74"":77,""75"":78,""76"":79,""77"":80,""78"":81,""79"":82,""8"":8,""80"":83,""81"":84,""82"":85,""83"":86,""84"":87,""85"":88,""86"":90,""87"":91,""88"":92,""89"":93,""9"":9,""90"":94,""91"":95,""92"":96,""93"":97,""94"":98,""95"":99,""96"":100,""97"":101},""count"":{""0"":148,""1"":122,""10"":66,""11"":58,""12"":48,""13"":44,""14"":44,""15"":44,""16"":42,""17"":42,""18"":42,""19"":40,""2"":116,""20"":40,""21"":40,""22"":40,""23"":34,""24"":32,""25"":32,""26"":32,""27"":30,""28"":30,""29"":28,""3"":102,""30"":26,""31"":26,""32"":26,""33"":26,""34"":24,""35"":24,""36"":24,""37"":20,""38"":20,""39"":20,""4"":100,""40"":20,""41"":20,""42"":18,""43"":18,""44"":16,""45"":16,""46"":16,""47"":16,""48"":16,""49"":16,""5"":96,""50"":16,""51"":14,""52"":14,""53"":14,""54"":14,""55"":12,""56"":12,""57"":12,""58"":12,""59"":12,""6"":96,""60"":10,""61"":10,""62"":10,""63"":10,""64"":10,""65"":10,""66"":10,""67"":10,""68"":8,""69"":8,""7"":86,""70"":8,""71"":8,""72"":8,""73"":8,""74"":8,""75"":8,""76"":8,""77"":8,""78"":8,""79"":8,""8"":70,""80"":8,""81"":8,""82"":8,""83"":8,""84"":8,""85"":8,""86"":8,""87"":8,""88"":6,""89"":6,""9"":70,""90"":6,""91"":6,""92"":6,""93"":6,""94"":6,""95"":6,""96"":6,""97"":6},""exemplar"":{""0"":""*"",""1"":null,""10"":null,""11"":""*"",""12"":null,""13"":null,""14"":null,""15"":null,""16"":""*"",""17"":""*"",""18"":null,""19"":""*"",""2"":""*"",""20"":""*"",""21"":null,""22"":""*"",""23"":""*"",""24"":null,""25"":null,""26"":""*"",""27"":null,""28"":null,""29"":null,""3"":""*"",""30"":""*"",""31"":""*"",""32"":null,""33"":null,""34"":null,""35"":null,""36"":null,""37"":""*"",""38"":null,""39"":""*"",""4"":null,""40"":null,""41"":null,""42"":null,""43"":null,""44"":""*"",""45"":null,""46"":null,""47"":""*"",""48"":null,""49"":null,""5"":null,""50"":""*"",""51"":null,""52"":null,""53"":""*"",""54"":""*"",""55"":""*"",""56"":null,""57"":null,""58"":null,""59"":null,""6"":null,""60"":""*"",""61"":null,""62"":null,""63"":null,""64"":null,""65"":""*"",""66"":null,""67"":null,""68"":""*"",""69"":""*"",""7"":""*"",""70"":""*"",""71"":""*"",""72"":null,""73"":null,""74"":null,""75"":""*"",""76"":""*"",""77"":null,""78"":""*"",""79"":""*"",""8"":""*"",""80"":""*"",""81"":""*"",""82"":null,""83"":""*"",""84"":""*"",""85"":null,""86"":null,""87"":null,""88"":null,""89"":""*"",""9"":""*"",""90"":""*"",""91"":null,""92"":""*"",""93"":""*"",""94"":null,""95"":null,""96"":null,""97"":null},""pos"":{""0"":1,""1"":1,""10"":4,""11"":3,""12"":4,""13"":5,""14"":6,""15"":1,""16"":2,""17"":1,""18"":2,""19"":2,""2"":1,""20"":3,""21"":7,""22"":1,""23"":2,""24"":8,""25"":9,""26"":3,""27"":10,""28"":11,""29"":3,""3"":1,""30"":4,""31"":2,""32"":4,""33"":12,""34"":13,""35"":14,""36"":15,""37"":5,""38"":16,""39"":3,""4"":2,""40"":17,""41"":18,""42"":5,""43"":19,""44"":3,""45"":5,""46"":6,""47"":4,""48"":4,""49"":20,""5"":3,""50"":4,""51"":21,""52"":22,""53"":4,""54"":6,""55"":6,""56"":23,""57"":24,""58"":25,""59"":5,""6"":2,""60"":7,""61"":26,""62"":8,""63"":9,""64"":27,""65"":10,""66"":28,""67"":11,""68"":6,""69"":12,""7"":3,""70"":13,""71"":7,""72"":29,""73"":30,""74"":31,""75"":14,""76"":5,""77"":7,""78"":15,""79"":5,""8"":1,""80"":6,""81"":6,""82"":16,""83"":5,""84"":7,""85"":32,""86"":17,""87"":33,""88"":34,""89"":6,""9"":2,""90"":8,""91"":18,""92"":7,""93"":8,""94"":8,""95"":19,""96"":35,""97"":36},""sigma_nor"":{""0"":2.0160121379,""1"":1.7594356268,""10"":2.5525267363,""11"":2.6557476126,""12"":1.8518801512,""13"":2.3722273748,""14"":1.6604019581,""15"":1.7465841863,""16"":2.0659235543,""17"":1.6770135218,""18"":2.2836009999,""19"":1.8185473737,""2"":2.26323899,""20"":1.8016141861,""21"":2.4820744737,""22"":1.9705654431,""23"":2.0509858785,""24"":1.6469230305,""25"":2.1082045873,""26"":3.0291996803,""27"":2.0403337227,""28"":1.864232493,""29"":2.9092990751,""3"":1.5361556241,""30"":1.8914965656,""31"":1.8231075619,""32"":1.9715474431,""33"":4.6386274647,""34"":2.7767461928,""35"":1.7508820227,""36"":1.8690948525,""37"":1.9815714808,""38"":1.9052190069,""39"":1.8942548981,""4"":2.4461882441,""40"":2.8278741293,""41"":3.9756714684,""42"":3.7461995998,""43"":2.485386134,""44"":1.9702115186,""45"":3.7329599871,""46"":3.5301332661,""47"":2.3503049512,""48"":2.6012721575,""49"":3.0436813005,""5"":1.9655265398,""50"":3.6076827765,""51"":2.2038724888,""52"":2.8899058197,""53"":1.9429118309,""54"":2.8826028019,""55"":3.0992445937,""56"":1.9315791809,""57"":2.9784526988,""58"":3.0028015471,""59"":2.327052982,""6"":2.1237924979,""60"":2.3417501782,""61"":2.6719329517,""62"":2.0982589762,""63"":2.4140666815,""64"":1.9970205393,""65"":2.3694099322,""66"":2.3635943389,""67"":1.9618350558,""68"":2.0785676012,""69"":2.4352141137,""7"":1.6325148168,""70"":2.2300992914,""71"":2.3864206644,""72"":2.3297164718,""73"":2.3774273316,""74"":2.1097224327,""75"":2.1361915361,""76"":1.9983459476,""77"":2.1817123891,""78"":1.9704476907,""79"":2.1973519538,""8"":2.2921964365,""80"":2.1169424513,""81"":2.1323670595,""82"":2.3627204159,""83"":2.2836982405,""84"":2.0929800297,""85"":2.379450793,""86"":2.2476575201,""87"":2.3122949564,""88"":1.966229523,""89"":1.9811281934,""9"":2.2557343237,""90"":1.9899266979,""91"":1.9549012446,""92"":1.9784941705,""93"":1.9583837095,""94"":1.9811264648,""95"":1.988163032,""96"":1.9540818221,""97"":1.9741147779},""topic"":{""0"":4,""1"":-1,""10"":-1,""11"":2,""12"":2,""13"":-1,""14"":-1,""15"":1,""16"":3,""17"":0,""18"":1,""19"":6,""2"":2,""20"":3,""21"":-1,""22"":5,""23"":5,""24"":-1,""25"":-1,""26"":6,""27"":-1,""28"":-1,""29"":1,""3"":6,""30"":4,""31"":0,""32"":1,""33"":-1,""34"":-1,""35"":-1,""36"":-1,""37"":4,""38"":-1,""39"":5,""4"":-1,""40"":-1,""41"":-1,""42"":1,""43"":-1,""44"":0,""45"":2,""46"":1,""47"":6,""48"":5,""49"":-1,""5"":-1,""50"":0,""51"":-1,""52"":-1,""53"":3,""54"":2,""55"":4,""56"":-1,""57"":-1,""58"":-1,""59"":0,""6"":4,""60"":1,""61"":-1,""62"":1,""63"":1,""64"":-1,""65"":1,""66"":-1,""67"":1,""68"":0,""69"":1,""7"":4,""70"":1,""71"":2,""72"":-1,""73"":-1,""74"":-1,""75"":1,""76"":6,""77"":4,""78"":1,""79"":5,""8"":3,""80"":6,""81"":5,""82"":1,""83"":3,""84"":5,""85"":-1,""86"":1,""87"":-1,""88"":-1,""89"":3,""9"":2,""90"":4,""91"":1,""92"":0,""93"":2,""94"":5,""95"":1,""96"":-1,""97"":-1},""vector"":{""0"":""[ 0.16748363 -5.282526    0.50430834  2.1307316   3.6184888   0.88454914\n  5.0342045  -9.716625   -2.937044   -3.9348369 ]"",""1"":""[ 0.12697388 -4.6235495   0.19459389  2.0013795   3.7065938   1.108237\n  4.5538197  -9.392206   -3.3787255  -3.863376  ]"",""10"":""[-0.51696736 -5.31824     0.04435379  1.7894598   4.1941404   1.3945503\n  4.662843   -9.392672   -3.0512424  -3.3914416 ]"",""11"":""[ 0.8493577  -4.886363    1.0289029   2.1151235   4.0465617   0.12768355\n  4.8032174  -9.178718   -3.643824   -3.8856425 ]"",""12"":""[ 0.9858202  -4.7520804   0.9194803   1.8633592   3.6861196   0.05813499\n  4.915895   -9.29381    -3.5122418  -4.0044017 ]"",""13"":""[-0.01779291 -4.9967284   0.69979763  1.3280721   3.605385    1.2538657\n  4.3113365  -9.603466   -4.0379753  -3.739912  ]"",""14"":""[ 0.3419607  -4.757088    0.27009544  2.2554348   3.8655477   0.8237013\n  4.539366   -9.2263565  -3.2970397  -3.8029654 ]"",""15"":""[ 0.95726085 -3.2480311   0.8300409   0.74093837  3.8293934   0.20367609\n  4.8052335  -9.094563   -4.2862244  -3.4700618 ]"",""16"":""[-0.11790755 -5.400337    0.34493053  2.0375204   3.9085042   0.9602031\n  4.14571    -9.164105   -3.4360628  -4.018304  ]"",""17"":""[ 0.6419399  -4.25948     0.20916085  1.4830596   3.42808     1.1938603\n  4.405578   -9.459959   -3.6893394  -3.0213878 ]"",""18"":""[ 0.9383262  -3.3767817   0.8308937   0.7780568   3.7899742   0.21970162\n  4.688423   -9.071852   -4.3952603  -3.5668914 ]"",""19"":""[-0.24429563 -5.4470687   0.59788877  1.4607644   4.3212295   1.2619678\n  4.4663444  -9.556473   -2.8398945  -2.8916612 ]"",""2"":""[ 0.6987009  -5.027449    1.0685552   2.152696    4.1221466   0.23840162\n  4.642092   -9.140325   -3.7710001  -3.907014  ]"",""20"":""[-0.44749525 -5.2105427  -0.07210529  1.7390709   4.0615487   1.3675708\n  4.5224895  -9.305081   -3.1870396  -3.4669018 ]"",""21"":""[-0.0182098  -4.567263    0.29202482  0.9219555   3.766359    1.3947262\n  4.3658037  -9.2899685  -3.017314   -3.447691  ]"",""22"":""[ 0.18336031 -4.999306    0.8289722   1.4092803   4.22955     0.8705098\n  5.201178   -9.795094   -2.6606205  -2.8448775 ]"",""23"":""[ 0.46480268 -4.683301    0.8292952   1.2235165   4.1762257   0.61536425\n  5.2694044  -9.663122   -2.815748   -2.804706  ]"",""24"":""[-0.15009877 -5.3636894   0.42413872  1.9325148   3.9883428   0.9718516\n  4.0414557  -9.124926   -3.7028687  -3.9391234 ]"",""25"":""[ 0.45148534 -4.0729184   0.8013145   0.9939406   4.104228    0.7033369\n  5.2431984  -9.656433   -3.1640754  -2.9037611 ]"",""26"":""[-0.13034672 -5.0805693   0.79493576  1.1417603   4.394529    1.206543\n  4.523096   -9.561744   -2.9593997  -2.8250802 ]"",""27"":""[-0.47304043 -5.293761    0.15340419  1.6244318   4.331277    1.3430283\n  4.5706725  -9.311966   -3.2438424  -3.2548747 ]"",""28"":""[-0.13660802 -5.010624    0.85766464  1.3012204   4.2181506   1.1367754\n  3.9128466  -9.265195   -4.0677614  -3.4071977 ]"",""29"":""[ 0.95706666 -3.6760437   0.54457396  0.625945    3.8960047   0.6192342\n  4.582545   -9.099895   -4.0226865  -2.8068442 ]"",""3"":""[-0.4333991  -5.4793005   0.46812978  1.381367    4.2187333   1.3686676\n  4.1340723  -9.380981   -3.1794732  -3.221753  ]"",""30"":""[ 0.0423901 -5.0993795  0.7214146  2.1343143  3.799235   1.073749\n  4.9382286 -9.804649  -2.9307075 -3.9436364]"",""31"":""[ 0.4654142  -3.981528    0.03968501  1.187935    3.4863544   1.0952551\n  4.3990746  -9.211574   -3.7344298  -3.4709706 ]"",""32"":""[ 0.8429613  -2.927498    0.6633952   0.2575874   3.855179    0.40344253\n  4.770449   -9.179276   -4.394523   -3.1642635 ]"",""33"":""[-0.1389655  -5.034701   -0.09194786  1.7585675   3.5791643   1.4543104\n  4.4984818  -9.41463    -3.1317894  -3.6459043 ]"",""34"":""[ 0.40204495 -5.2452574   0.6684808   2.0446947   3.4872177   0.7142375\n  4.9472537  -9.658851   -3.104974   -4.0598035 ]"",""35"":""[ 0.13304251 -4.9942746   0.43255907  1.8040304   4.2613873   1.0482968\n  4.518902   -9.404509   -2.8801894  -2.8998897 ]"",""36"":""[ 0.19023164 -4.971065    0.62397665  1.6422178   3.5184348   1.0655727\n  4.635774   -9.614175   -3.874752   -3.8575683 ]"",""37"":""[ 0.32352686 -5.2712073   0.46257785  2.254898    3.655897    0.7132129\n  4.7852645  -9.476776   -3.0228882  -3.988257  ]"",""38"":""[-0.14018995 -4.860715    0.6961025   1.078616    4.1855617   1.1702064\n  3.8354843  -9.17762    -4.061046   -3.2734168 ]"",""39"":""[ 0.28159592 -4.5823164   0.82101864  1.4450684   4.1328254   0.82430005\n  5.320775   -9.781745   -2.970826   -3.0772028 ]"",""4"":""[ 0.12615646 -5.3124785   0.68635887  1.8333224   3.856451    0.9594627\n  5.19924    -9.896166   -2.6740406  -3.3809643 ]"",""40"":""[ 0.5404774  -3.6782098   0.76267636  0.8498396   4.03825     0.6307146\n  5.1751623  -9.543832   -3.4506984  -2.9813616 ]"",""41"":""[ 1.0818596  -4.2596574   0.8574049   1.583891    3.9484844  -0.05134261\n  4.835488   -9.068452   -3.7905586  -3.6722658 ]"",""42"":""[ 1.0634422  -3.75872     0.89056313  1.1544346   3.858918    0.01549679\n  4.817545   -9.051511   -4.1224494  -3.6567216 ]"",""43"":""[-0.07002343 -4.711934    1.0085034   1.5600232   4.523193    1.1060499\n  4.925646   -9.777447   -2.9498482  -3.0627208 ]"",""44"":""[ 0.6374971  -4.230158    0.32543638  1.28714     3.3523061   1.081113\n  4.461574   -9.440195   -3.8802683  -3.3561707 ]"",""45"":""[ 1.135161   -4.2652917   0.7886491   1.5830605   3.8456104  -0.12784731\n  4.8152156  -9.058884   -3.7938628  -3.795868  ]"",""46"":""[ 0.8540417  -3.7687807   0.69362444  1.1453822   3.8760912   0.7033731\n  4.2877555  -9.101756   -4.5239778  -3.0803308 ]"",""47"":""[-0.13775958 -5.0139933   0.80168504  1.524248    4.511936    1.1582811\n  4.449789   -9.503911   -3.0322444  -2.9647532 ]"",""48"":""[-0.11005302 -5.0184016   0.8999862   1.5074484   4.3212423   1.1584984\n  4.9333878  -9.822963   -2.7897549  -3.0850053 ]"",""49"":""[-0.16621073 -4.95949     0.43182027  1.0610036   4.161048    1.2732188\n  3.993018   -9.231672   -3.4105322  -3.0385847 ]"",""5"":""[ 0.01759833 -5.088423    0.05713338  1.9794168   3.514513    1.3478224\n  4.5177646  -9.494376   -3.0330157  -3.7423935 ]"",""50"":""[ 0.7114054  -4.1639366   0.05705622  1.6591997   3.763287    0.9782511\n  4.1568046  -9.049874   -3.8411424  -2.91724   ]"",""51"":""[ 0.21404363 -4.6981993   0.41591415  1.6275375   4.2079067   1.1163595\n  4.361894   -9.28681    -3.1641536  -2.8837016 ]"",""52"":""[ 0.3278769  -5.427992    1.0913006   1.2611225   4.112315    0.83886397\n  4.8612957  -9.756351   -2.9860966  -2.842816  ]"",""53"":""[-0.24115628 -5.181185    0.04952614  1.6234041   4.1498117   1.1008602\n  4.0521092  -9.0176525  -3.4514284  -3.395455  ]"",""54"":""[ 0.8455358 -4.980192   0.9354549  2.1048732  3.8327806  0.1680957\n  4.838943  -9.266268  -3.483747  -3.9992938]"",""55"":""[-0.06295369 -4.86944     0.49893105  1.9185456   3.7417438   1.1486752\n  5.124265   -9.788462   -3.2928398  -3.923687  ]"",""56"":""[ 0.01390765 -5.122839    0.4838058   1.7704633   3.4897888   1.2096107\n  4.673327   -9.706029   -3.4882534  -3.9198906 ]"",""57"":""[ 0.8464401  -4.3643775   0.9617406   1.633388    4.1698146   0.40369433\n  4.841616   -9.302645   -3.64773    -3.1745975 ]"",""58"":""[ 0.5526248  -4.566445    0.8328241   1.7312717   4.218662    0.69024795\n  4.8465853  -9.451017   -3.3164947  -3.0753672 ]"",""59"":""[ 0.65828896 -4.1434565   0.06177786  1.5231819   3.739723    0.9521214\n  4.0774474  -8.991226   -4.026657   -2.9967926 ]"",""6"":""[ 0.04525383 -4.6844444   0.5592286   1.6974761   4.059618    1.0429771\n  5.2958307  -9.759951   -2.8221474  -3.3766677 ]"",""60"":""[ 0.7324111  -2.8155832   0.59474057  0.28167683  3.797216    0.49673477\n  4.624115   -9.115117   -4.5282393  -3.2521276 ]"",""61"":""[ 1.0405012  -4.116327    0.845417    1.3802688   3.840269    0.01614596\n  4.79104    -9.05027    -3.9355097  -3.7199173 ]"",""62"":""[ 0.8817055  -3.3663082   0.56851035  0.5264503   3.8879695   0.5526122\n  4.8116937  -9.151619   -3.9880202  -2.995364  ]"",""63"":""[ 0.82813656 -3.7792284   0.52240926  0.67193854  3.723752    0.6147585\n  4.518152   -9.091808   -4.0623736  -3.2533705 ]"",""64"":""[ 0.6406429  -3.887375    0.5959614   0.77133757  3.6652322   0.91654694\n  4.0461807  -9.184646   -4.58126    -2.9855835 ]"",""65"":""[ 0.9789851  -2.856299    0.6390975   0.5100393   3.754547    0.57202643\n  4.5088067  -8.979608   -4.4374766  -3.0102491 ]"",""66"":""[ 0.49004695 -5.28989     1.0818723   1.0995357   3.9896166   0.793681\n  4.709707   -9.663961   -3.2318904  -2.8146408 ]"",""67"":""[ 0.6547801  -3.6668797   0.54875475  0.81813365  3.7737558   0.850643\n  4.0319467  -9.041109   -4.6591926  -3.06691   ]"",""68"":""[ 0.5456105  -3.9500062   0.25476587  1.1595201   3.704159    1.1316842\n  4.4420114  -9.327824   -3.5475218  -2.852134  ]"",""69"":""[ 1.0141412  -2.9717624   0.71487045  0.44848865  3.7961714   0.43653336\n  4.6955714  -9.071041   -4.3655405  -3.042214  ]"",""7"":""[ 0.0387101  -5.1669235   0.35212743  2.259157    3.7044218   1.0589857\n  4.540984   -9.468156   -3.0776582  -4.0572796 ]"",""70"":""[ 0.8819688  -3.112996    0.71235216  0.33909267  3.788482    0.43246576\n  4.469872   -9.0932665  -4.692352   -3.1934156 ]"",""71"":""[ 0.37622017 -4.9768157   1.0087891   2.0697846   4.071486    0.6531651\n  4.76682    -9.402459   -3.8260274  -3.865576  ]"",""72"":""[ 0.5206038  -4.0115523   0.42239508  0.7468685   3.6195445   0.8667889\n  4.326042   -9.124297   -4.0069394  -3.48171   ]"",""73"":""[ 0.85965645 -4.053241    0.4936594   0.76287514  3.929127    0.6716944\n  4.600613   -9.139245   -3.6870463  -2.8022368 ]"",""74"":""[-0.1557895  -4.7633452   0.30923626  0.98444307  3.748319    1.4713552\n  4.270459   -9.357445   -3.09846    -3.4891245 ]"",""75"":""[ 0.8084492  -2.9926138   0.57183975  0.44866988  3.7885356   0.62040395\n  4.5704446  -9.151092   -4.3606877  -3.0262008 ]"",""76"":""[-0.2753955 -5.1332827  0.6189078  1.0096425  4.352339   1.299492\n  4.2645307 -9.397063  -3.1868422 -2.9087582]"",""77"":""[-0.18455969 -4.840907    0.33778903  1.9507158   3.9903822   1.1482866\n  5.2634554  -9.7041645  -2.9599493  -3.732992  ]"",""78"":""[ 0.9671152  -3.0059786   0.6278786   0.38180402  3.8158102   0.48223853\n  4.408671   -9.0078745  -4.6648993  -3.034766  ]"",""79"":""[ 0.3340404  -5.3866215   0.9780035   1.4467386   3.8123457   0.96753603\n  4.9635434  -9.942342   -2.8259592  -3.0533345 ]"",""8"":""[ 0.08024798 -4.9372344   0.10008744  1.8174099   4.1731977   1.1161561\n  4.2142053  -9.121152   -3.114666   -3.0330667 ]"",""80"":""[-0.10408702 -5.34773     0.73215944  1.2858367   4.1809025   1.219459\n  4.3794684  -9.577772   -2.9941099  -2.9505289 ]"",""81"":""[ 0.30800658 -4.803837    1.0458344   1.3286871   3.9852      0.9425501\n  5.1744995  -9.962428   -3.040532   -3.031009  ]"",""82"":""[ 0.77966154 -3.5026867   0.742901    0.46641603  3.720237    0.52796173\n  4.321437   -9.1345825  -4.708482   -3.311002  ]"",""83"":""[-0.3387908  -5.391951    0.40210718  1.6068275   4.007188    1.2250931\n  4.008349   -9.222815   -3.5455842  -3.7312145 ]"",""84"":""[ 0.35404664 -5.1960597   1.0225451   1.383441    4.045307    0.801693\n  5.11774    -9.843908   -2.884489   -2.9610732 ]"",""85"":""[ 0.08072647 -4.426238    0.18614535  0.9474382   3.6874893   1.3618429\n  4.2242265  -9.23124    -3.3037705  -3.3770084 ]"",""86"":""[ 1.0702924 -3.058907   0.5935835  0.5624459  3.7993631  0.5731134\n  4.630816  -8.982921  -4.132732  -2.8693352]"",""87"":""[-0.11545291 -5.00156     0.82110626  1.2434291   3.9398446   1.2124112\n  4.075784   -9.4472065  -4.0918674  -3.55456   ]"",""88"":""[ 0.21031822 -5.214673    0.6886428   1.4734634   3.4247732   1.2291071\n  4.777897   -9.904998   -3.133181   -3.502705  ]"",""89"":""[-0.1925695  -5.240503    0.10191946  1.7433908   4.012796    1.0304856\n  4.0031915  -8.9973755  -3.5754828  -3.693468  ]"",""9"":""[ 0.84070534 -4.821386    1.0885224   2.0266218   4.123261    0.16745694\n  4.7829885  -9.177914   -3.722136   -3.7454455 ]"",""90"":""[-4.0260297e-03 -4.8035746e+00  5.4671323e-01  2.0369675e+00\n  3.9648511e+00  1.0360769e+00  5.1161947e+00 -9.6854820e+00\n -3.1204650e+00 -3.8226082e+00]"",""91"":""[ 0.9098723  -3.2281709   0.52016073  0.6220247   3.7727396   0.64866626\n  4.2700725  -8.977202   -4.597203   -2.9903119 ]"",""92"":""[ 0.5453185  -4.1252203   0.04705036  1.2902453   3.5426462   1.2013675\n  4.3597794  -9.287474   -3.5493462  -3.0561993 ]"",""93"":""[ 0.4453469  -4.929231    1.0400037   2.0090425   4.2154117   0.58736616\n  4.657065   -9.28986    -3.8369153  -3.6697297 ]"",""94"":""[ 0.30138266 -5.3573456   0.9190372   1.585586    3.6991975   0.98406976\n  5.069843   -9.996764   -2.8057864  -3.2636073 ]"",""95"":""[ 0.81940675 -3.675641    0.3983321   0.9902275   3.7383368   0.82009375\n  4.0215335  -8.986369   -4.6130757  -2.930478  ]"",""96"":""[ 0.78096414 -4.243351    0.25738183  1.7688344   3.911291    0.7922827\n  4.263965   -9.046317   -3.8156054  -2.9506185 ]"",""97"":""[ 9.7006828e-02 -4.8516712e+00 -7.3554424e-05  1.7115023e+00\n  4.0858293e+00  8.4114116e-01  4.1422634e+00 -8.8867998e+00\n -3.4972899e+00 -3.4444947e+00]""},""vocab_index"":{""0"":0,""1"":2,""10"":12,""11"":14,""12"":20,""13"":22,""14"":25,""15"":26,""16"":28,""17"":30,""18"":31,""19"":33,""2"":3,""20"":34,""21"":36,""22"":37,""23"":48,""24"":53,""25"":54,""26"":57,""27"":58,""28"":60,""29"":63,""3"":4,""30"":65,""31"":67,""32"":68,""33"":69,""34"":70,""35"":74,""36"":75,""37"":88,""38"":89,""39"":90,""4"":5,""40"":92,""41"":93,""42"":101,""43"":102,""44"":108,""45"":118,""46"":119,""47"":121,""48"":122,""49"":123,""5"":6,""50"":124,""51"":144,""52"":148,""53"":149,""54"":150,""55"":154,""56"":155,""57"":179,""58"":181,""59"":182,""6"":7,""60"":206,""61"":222,""62"":224,""63"":228,""64"":230,""65"":234,""66"":235,""67"":236,""68"":293,""69"":294,""7"":8,""70"":295,""71"":297,""72"":299,""73"":300,""74"":303,""75"":311,""76"":315,""77"":317,""78"":318,""79"":320,""8"":9,""80"":321,""81"":322,""82"":328,""83"":329,""84"":330,""85"":333,""86"":337,""87"":338,""88"":347,""89"":405,""9"":10,""90"":428,""91"":430,""92"":432,""93"":433,""94"":440,""95"":457,""96"":458,""97"":475},""word"":{""0"":""user"",""1"":""data"",""10"":""feedback"",""11"":""biclusters"",""12"":""endert"",""13"":""human"",""14"":""dataset"",""15"":""gather"",""16"":""visualization"",""17"":""level"",""18"":""scatter"",""19"":""interactions"",""2"":""clustering"",""20"":""input"",""21"":""story"",""22"":""entities"",""23"":""forcespire"",""24"":""spatialization"",""25"":""means"",""26"":""relationships"",""27"":""loop"",""28"":""semantic"",""29"":""north"",""3"":""interaction"",""30"":""andrews"",""31"":""table"",""32"":""shown"",""33"":""expert"",""34"":""ramakrishnan"",""35"":""models"",""36"":""space"",""37"":""bixplorer"",""38"":""implicit"",""39"":""forms"",""4"":""users"",""40"":""provides"",""41"":""petals"",""42"":""stalk"",""43"":""paths"",""44"":""ground"",""45"":""petal"",""46"":""vertical"",""47"":""metaphors"",""48"":""links"",""49"":""relation"",""5"":""analyst"",""50"":""scale"",""51"":""framework"",""52"":""clique"",""53"":""representation"",""54"":""bicluster"",""55"":""mail"",""56"":""computer"",""57"":""ridges"",""58"":""layers"",""59"":""size"",""6"":""documents"",""60"":""updated"",""61"":""flower"",""62"":""right"",""63"":""yellow"",""64"":""local"",""65"":""lead"",""66"":""neighborhood"",""67"":""additional"",""68"":""setting"",""69"":""left"",""7"":""analytics"",""70"":""separated"",""71"":""partitions"",""72"":""light"",""73"":""border"",""74"":""investigation"",""75"":""starting"",""76"":""pair"",""77"":""requests"",""78"":""connected"",""79"":""classes"",""8"":""model"",""80"":""relations"",""81"":""places"",""82"":""mixed"",""83"":""manipulation"",""84"":""groups"",""85"":""conclusion"",""86"":""helm"",""87"":""biological"",""88"":""department"",""89"":""projection"",""9"":""clusters"",""90"":""files"",""91"":""longer"",""92"":""threshold"",""93"":""lattice"",""94"":""students"",""95"":""larger"",""96"":""scales"",""97"":""image""},""word*"":{""0"":""user*"",""1"":""data"",""10"":""feedback"",""11"":""biclusters*"",""12"":""endert"",""13"":""human"",""14"":""dataset"",""15"":""gather"",""16"":""visualization*"",""17"":""level*"",""18"":""scatter"",""19"":""interactions*"",""2"":""clustering*"",""20"":""input*"",""21"":""story"",""22"":""entities*"",""23"":""forcespire*"",""24"":""spatialization"",""25"":""means"",""26"":""relationships*"",""27"":""loop"",""28"":""semantic"",""29"":""north"",""3"":""interaction*"",""30"":""andrews*"",""31"":""table*"",""32"":""shown"",""33"":""expert"",""34"":""ramakrishnan"",""35"":""models"",""36"":""space"",""37"":""bixplorer*"",""38"":""implicit"",""39"":""forms*"",""4"":""users"",""40"":""provides"",""41"":""petals"",""42"":""stalk"",""43"":""paths"",""44"":""ground*"",""45"":""petal"",""46"":""vertical"",""47"":""metaphors*"",""48"":""links"",""49"":""relation"",""5"":""analyst"",""50"":""scale*"",""51"":""framework"",""52"":""clique"",""53"":""representation*"",""54"":""bicluster*"",""55"":""mail*"",""56"":""computer"",""57"":""ridges"",""58"":""layers"",""59"":""size"",""6"":""documents"",""60"":""updated*"",""61"":""flower"",""62"":""right"",""63"":""yellow"",""64"":""local"",""65"":""lead*"",""66"":""neighborhood"",""67"":""additional"",""68"":""setting*"",""69"":""left*"",""7"":""analytics*"",""70"":""separated*"",""71"":""partitions*"",""72"":""light"",""73"":""border"",""74"":""investigation"",""75"":""starting*"",""76"":""pair*"",""77"":""requests"",""78"":""connected*"",""79"":""classes*"",""8"":""model*"",""80"":""relations*"",""81"":""places*"",""82"":""mixed"",""83"":""manipulation*"",""84"":""groups*"",""85"":""conclusion"",""86"":""helm"",""87"":""biological"",""88"":""department"",""89"":""projection*"",""9"":""clusters*"",""90"":""files*"",""91"":""longer"",""92"":""threshold*"",""93"":""lattice*"",""94"":""students"",""95"":""larger"",""96"":""scales"",""97"":""image""},""x2D"":{""0"":7.1073083878,""1"":6.0597085953,""10"":5.9434156418,""11"":9.5950374603,""12"":9.8076562881,""13"":4.7669911385,""14"":6.4256210327,""15"":11.1996412277,""16"":5.4792985916,""17"":8.262377739,""18"":10.9797477722,""19"":6.4877400398,""2"":9.6829862595,""20"":5.7265725136,""21"":5.1796331406,""22"":7.7850012779,""23"":8.0570964813,""24"":5.1156921387,""25"":8.2557907104,""26"":6.7349085808,""27"":5.7675580978,""28"":4.4969124794,""29"":10.2896127701,""3"":5.9936065674,""30"":7.3034877777,""31"":8.3265266418,""32"":11.7390632629,""33"":5.8909082413,""34"":6.9188923836,""35"":6.2775640488,""36"":5.746817112,""37"":6.8600144386,""38"":4.6451883316,""39"":8.0200214386,""4"":7.7523589134,""40"":9.8495521545,""41"":9.8585643768,""42"":10.1240282059,""43"":7.4190330505,""44"":8.6015701294,""45"":9.8957767487,""46"":10.4080228806,""47"":6.4556875229,""48"":7.3328595161,""49"":5.1836700439,""5"":6.2210798264,""50"":8.5175704956,""51"":5.951488018,""52"":8.267375946,""53"":5.1278429031,""54"":9.6095933914,""55"":6.8416872025,""56"":6.3091926575,""57"":9.3892507553,""58"":8.553812027,""59"":8.7560224533,""6"":7.5832824707,""60"":11.769818306,""61"":9.9968700409,""62"":10.746544838,""63"":10.1732053757,""64"":10.2506837845,""65"":11.5787906647,""66"":8.1808919907,""67"":10.4798231125,""68"":8.426525116,""69"":11.7897462845,""7"":6.5575003624,""70"":11.4990215302,""71"":9.3488206863,""72"":9.5368556976,""73"":9.7676486969,""74"":5.1680688858,""75"":11.6135263443,""76"":6.0745782852,""77"":7.334458828,""78"":11.5225057602,""79"":7.9953951836,""8"":5.5040564537,""80"":6.386619091,""81"":8.087808609,""82"":11.0902223587,""83"":5.1495580673,""84"":8.1057796478,""85"":4.9600944519,""86"":11.1605138779,""87"":4.572830677,""88"":7.3960738182,""89"":5.2063159943,""9"":9.8025245667,""90"":7.1930470467,""91"":11.2582483292,""92"":8.2871179581,""93"":9.4772443771,""94"":7.999920845,""95"":10.6756019592,""96"":8.6762399673,""97"":5.1795434952},""y2D"":{""0"":3.4873769283,""1"":3.5003716946,""10"":2.214435339,""11"":-0.173898533,""12"":-0.4460936487,""13"":2.7535145283,""14"":3.6219928265,""15"":-2.9469325542,""16"":2.8635063171,""17"":-3.5484130383,""18"":-2.7850935459,""19"":1.4384871721,""2"":0.0450032949,""20"":2.2773935795,""21"":1.2017519474,""22"":1.4869480133,""23"":1.2350714207,""24"":2.5915162563,""25"":0.806157887,""26"":1.2293412685,""27"":1.9959485531,""28"":2.3899059296,""29"":-3.3227312565,""3"":1.7357103825,""30"":3.6815257072,""31"":-3.908929348,""32"":-3.3204138279,""33"":2.5775980949,""34"":3.3386566639,""35"":1.0652444363,""36"":3.3046078682,""37"":3.550440073,""38"":2.1653883457,""39"":1.1786122322,""4"":2.5849049091,""40"":-2.7552998066,""41"":-0.7941486239,""42"":-1.2557809353,""43"":1.1804013252,""44"":-3.6716635227,""45"":-0.835478127,""46"":-3.8871366978,""47"":1.1276478767,""48"":1.4783893824,""49"":1.3485298157,""5"":2.9648926258,""50"":-3.5822761059,""51"":1.0195559263,""52"":1.8939570189,""53"":2.1141524315,""54"":-0.1418417841,""55"":3.7160673141,""56"":3.2900524139,""57"":-0.5797809362,""58"":0.5117664337,""59"":-3.6628668308,""6"":2.2021970749,""60"":-3.2145211697,""61"":-0.9446519017,""62"":-3.2346642017,""63"":-3.4604387283,""64"":-3.9832940102,""65"":-3.6880662441,""66"":1.7801367044,""67"":-3.900239706,""68"":-3.9514865875,""69"":-3.521727562,""7"":3.2997736931,""70"":-3.3231608868,""71"":0.0615681782,""72"":-3.638620615,""73"":-3.3088424206,""74"":1.2769588232,""75"":-3.7201926708,""76"":1.440494895,""77"":3.2517874241,""78"":-3.4395022392,""79"":2.0316267014,""8"":1.6098026037,""80"":1.1951041222,""81"":1.2953549623,""82"":-3.7563951015,""83"":2.4836304188,""84"":1.6734060049,""85"":0.9991701841,""86"":-3.4886479378,""87"":2.5449340343,""88"":2.7862510681,""89"":2.2915842533,""9"":-0.2055851966,""90"":3.6102118492,""91"":-3.5197682381,""92"":-3.6440289021,""93"":-0.0808023512,""94"":2.2684078217,""95"":-4.0157032013,""96"":-3.6594214439,""97"":1.9759755135}}",False,False,False,http://link.springer.com/10.1007/s10844-014-0304-9,,The human is the loop: new directions for visual analytics,"[-4.10166293e-01  3.34802009e-02  8.74480233e-02 -8.68603528e-01
  8.13692570e-01 -4.30131048e-01  1.22317284e-01  3.57150257e-01
  7.92681500e-02 -4.55565572e-01 -4.36485469e-01 -3.17278624e-01
  1.52607247e-01  3.43857229e-01 -7.59261549e-01  9.96653676e-01
  2.33979613e-01 -4.59221452e-01  4.01555985e-01  3.53866726e-01
  1.95278943e-01  2.33168676e-01  7.34246150e-02  5.14426827e-01
  1.45407632e-01 -5.84618628e-01  4.39738005e-01  1.29117906e-01
 -4.81441319e-01  1.05971470e-01  2.57223934e-01  3.88037443e-01
 -2.97466516e-01 -4.14120138e-01 -4.56244618e-01  1.52135476e-01
 -2.55075276e-01 -1.54404029e-01  8.89735669e-02  7.20495284e-01
  2.13451404e-02 -8.48621666e-01 -4.61743951e-01  5.50339639e-01
  2.64158010e-01 -1.19854115e-01 -4.70009372e-02 -1.18089274e-01
  9.31789260e-03  7.13202953e-01 -1.57208189e-01 -5.50812662e-01
 -2.05336377e-01 -4.09802288e-01  6.25740290e-01  1.08979595e+00
 -1.10714920e-01 -4.79908943e-01 -2.71111935e-01 -3.42842400e-01
  1.31884694e-01  1.06233843e-01  2.39223137e-01 -8.26821506e-01
  3.67422670e-01 -1.39674917e-01  5.42134531e-02  3.59407663e-01
 -4.80046362e-01 -4.27701235e-01 -1.23248386e+00  2.17117667e-01
 -1.20133206e-01  6.49028301e-01  2.90675133e-01 -2.11975217e-01
  5.20259500e-01  2.71987200e-01 -2.46891975e-01  4.48857062e-03
 -2.84379780e-01 -1.47566840e-01 -4.26428504e-02  1.80561885e-01
  1.04049064e-01  9.94664878e-02 -2.94437706e-01 -6.35640323e-02
 -7.93251634e-01  3.60410690e-01 -3.32415197e-03  2.27853149e-01
 -2.48177812e-01 -1.85413092e-01  3.76415014e-01  3.22328061e-01
 -2.23088875e-01 -4.43321317e-01  7.70685682e-03 -3.32853436e-01
 -8.84504020e-02  1.83282495e-01  2.18790010e-01  5.36767393e-02
 -6.00911200e-01 -1.09343298e-01 -9.24535468e-02 -5.94262838e-01
 -7.22236112e-02  3.15218300e-01 -9.95641202e-02  2.02967495e-01
 -3.50553125e-01 -6.44457996e-01  4.70151126e-01 -4.27316159e-01
 -5.50365634e-02  5.26048653e-02  3.81052434e-01  3.00334413e-02
 -2.39123851e-02  1.62661877e-02  2.15334639e-01  3.39305848e-01
 -1.11254923e-01  2.52080142e-01 -2.18317851e-01 -3.73055860e-02
  5.41324556e-01  2.26828486e-01  2.88796484e-01  3.82532120e-01
 -3.62470970e-02 -8.39269459e-02 -2.53161103e-01  4.67053145e-01
 -1.58657700e-01  6.25840500e-02  6.32044226e-02  3.15304667e-01
 -3.10317308e-01 -8.72373223e-01 -2.82202121e-02 -4.62740928e-01
 -2.45344430e-01  1.63285598e-01  1.29456505e-01  3.64285350e-01
  1.65191397e-01  6.25564456e-01 -2.93068856e-01 -4.65729445e-01
 -3.85635883e-01  1.85178239e-02  2.50179619e-02  5.96793056e-01
 -5.88002577e-02  5.81857264e-02  4.02570844e-01 -2.25285664e-01
 -1.02427229e-02 -3.42769921e-01  3.81577648e-02  1.25953600e-01
  1.23010270e-01  1.62951186e-01  6.25193775e-01  1.17190674e-01
 -3.05966586e-01 -1.80931836e-01 -3.52520794e-01 -1.02001190e+00
 -1.95408687e-02  2.75755525e-01  1.33993357e-01  5.69352880e-03
  4.08239454e-01 -8.79645050e-02  3.52453202e-01  1.88333705e-01
 -5.63583434e-01  2.64990002e-01 -2.24643514e-01 -4.28213507e-01
  1.72511429e-01  5.47332764e-01  7.81873643e-01 -4.47848827e-01
 -1.07342847e-01  1.48277283e-01 -2.50860840e-01  3.96860927e-01
  3.95900756e-02 -4.60005641e-01 -1.76884998e-02 -2.83176377e-02
 -5.76646514e-02 -1.27032399e-01 -5.19090593e-01 -1.53390586e-01
  1.90806966e-02  5.33854999e-02  3.64624381e-01 -6.32618591e-02
 -8.17319974e-02 -6.02625385e-02 -5.62597394e-01 -7.49346972e-01
 -5.00734687e-01 -2.97858357e-01 -7.66924441e-01 -1.48217246e-01
 -2.39846453e-01  6.92260504e-01 -1.25907511e-01  1.53107032e-01
  1.82802737e-01  4.11761031e-02  1.00088708e-01 -3.46305400e-01
  1.24811143e-01 -2.37036636e-03  2.91791439e-01  1.10133672e+00
 -8.67655501e-02  1.39211726e+00 -2.46229172e-02 -3.62471901e-02
  5.54594934e-01  6.60790622e-01 -3.71118665e-01 -5.49317360e-01
  9.43415463e-01 -6.86297059e-01  4.22983356e-02  2.75452077e-01
 -2.53538519e-01  1.54726073e-01 -2.64250189e-01 -9.58992094e-02
 -3.31024617e-01  3.71257514e-01  6.66726232e-01  4.21514958e-02
  3.99869531e-01 -2.87200987e-01 -1.33557945e-01  7.74611384e-02
 -2.50951856e-01 -4.86867249e-01 -5.98592907e-02  9.54492807e-01
 -3.65720749e-01 -7.09225416e-01 -5.32213986e-01  3.19804907e-01
 -1.07529379e-01  2.64073938e-01 -3.65313917e-01  6.20372295e-01
 -1.54650211e-01 -1.17267609e+00  3.78392667e-01 -3.61960113e-01
 -2.12561116e-01 -4.39371943e-01  3.38239111e-02 -1.88401476e-01
  6.40668392e-01  2.40236409e-02  5.18531799e-02  1.96803525e-01
  3.46800834e-02 -1.40133038e-01 -1.32227376e-01  2.22258978e-02
 -5.22498548e-01 -4.73746181e-01  9.36773792e-02  8.44504535e-01
  5.59317708e-01  3.73240054e-01 -2.90833920e-01  1.83198169e-01
 -3.32108617e-01  3.15012008e-01 -3.79905045e-01 -7.92025924e-02
  5.21302402e-01 -1.71687037e-01 -4.29086834e-01 -1.00355474e-02
 -7.55037904e-01 -3.10329407e-01  2.47647241e-01 -4.09292758e-01
 -1.47801414e-01 -1.76615894e-01  9.11121294e-02 -1.76434517e-01
 -6.06092736e-02 -2.57874876e-01 -4.43250358e-01 -3.71096492e-01
 -9.07580793e-01  3.12270194e-01 -5.08060634e-01 -4.98338751e-02
 -4.20825052e+00  3.56731303e-02 -5.10558724e-01 -4.13780093e-01
 -6.56964853e-02  1.60138253e-02  2.66855359e-01 -6.40657172e-03
  2.41135061e-01  6.27724707e-01 -8.20565283e-01  7.98915550e-02
  1.05354674e-01 -4.45941240e-01  1.37410581e-01 -3.09063613e-01
 -5.31411290e-01 -6.59218654e-02  8.48451629e-02  2.57173896e-01
 -3.05471532e-02 -1.43109128e-01  8.59466270e-02  1.71318680e-01
  8.68382275e-01 -1.68599397e-01 -4.72454935e-01 -2.63591390e-02
 -1.18031777e-01  1.01885043e-01  6.96629286e-01 -9.65053737e-01
 -1.28967762e-01  8.20717394e-01  3.64227563e-01 -4.55809124e-02
 -5.31692445e-01 -1.81985304e-01 -3.47343534e-01  4.15623009e-01
  1.61611006e-01 -2.61706740e-01 -3.92938316e-01  3.12030256e-01
  9.11547482e-01  7.81992748e-02  5.27856469e-01 -9.29605290e-02
 -1.99676186e-01  1.82774849e-02 -6.41324744e-02 -3.80629033e-01
  3.02659661e-01 -3.71463209e-01  8.12792182e-02 -2.04579338e-01
  5.06467581e-01  5.88377535e-01 -7.84366667e-01 -7.38203824e-02
  9.90245879e-01 -4.69911218e-01 -5.24441376e-02 -3.51434708e-01
 -1.39635205e-01  3.64251167e-01 -1.15451038e+00 -4.16570783e-01
 -1.89903721e-01 -5.89589715e-01 -2.49013811e-01  1.01739299e+00
 -1.33728251e-01 -3.83827984e-02 -4.90671620e-02 -7.40233660e-01
 -5.05033910e-01  1.30241871e-01 -3.07841361e-01 -2.10337177e-01
 -2.64874756e-01  5.49319461e-02 -1.08955622e+00 -2.13598996e-01
 -1.02436446e-01 -5.52028045e-02 -3.66245538e-01 -4.82303739e-01
 -4.90143090e-01 -8.67997631e-02 -2.76235968e-01  1.50895834e-01
  5.19517720e-01  7.81992435e-01 -1.84122145e-01 -2.39714965e-01
  7.31410801e-01  4.98197138e-01 -2.17253938e-01 -5.10340273e-01
  2.72877842e-01 -5.11070788e-01  1.46460682e-01 -1.66182220e-01
 -4.73995656e-01 -2.46964127e-01 -9.62030947e-01 -4.71790135e-01
  4.09445494e-01 -2.57464081e-01  8.47272500e-02  7.15501234e-02
  4.43899035e-01  4.18133251e-02  1.27809376e-01  1.70593068e-01
 -2.10065559e-01  3.21581155e-01  1.19385354e-01 -8.28956068e-01
 -7.43744910e-01  6.21791065e-01 -5.24760067e-01  1.12076245e-01
  6.29815638e-01  4.72401649e-01 -2.71037936e-01  2.77329028e-01
 -5.05873799e-01 -3.78491431e-01 -3.25526416e-01 -2.73876697e-01
 -3.51136029e-02  3.07545871e-01  6.01297140e-01  7.72736222e-02
  9.30275321e-02  2.87742436e-01 -6.68178260e-01  1.34901311e-02
  6.82096183e-01 -1.30681703e-02  4.93099123e-01 -3.71046454e-01
  2.51450568e-01  1.12960465e-01  3.98165822e-01  5.58794618e-01
  3.71574968e-01  1.74989074e-01  3.48129719e-02 -3.80604178e-01
  8.71432051e-02  1.38850942e-01  4.48727071e-01  3.82530361e-01
  1.49166167e-01 -6.52048066e-02 -2.48386905e-01 -9.58354890e-01
  1.07820839e-01  5.32660484e-01 -2.63912588e-01 -2.57706285e-01
  4.80467789e-02 -1.05806902e-01  4.24074568e-02  3.78216028e-01
 -9.19579118e-02 -7.34438717e-01 -8.60354662e-01 -2.07043111e-01
 -5.03250003e-01 -6.15287006e-01 -9.44118425e-02  3.20730299e-01
  1.25043720e-01 -1.94143549e-01 -2.01988503e-01  1.28894806e-01
  4.97047693e-01  1.03477418e-01 -1.88006073e-01 -1.90061405e-02
  5.50175905e-01 -1.72835425e-01  3.20196003e-01 -1.20859385e-01
 -3.43138799e-02  4.19216812e-01 -7.94161320e-01  2.03462765e-02
  6.12955272e-01 -5.75406015e-01  4.36969846e-02 -6.33635163e-01
 -1.24034442e-01 -2.33788088e-01  9.89031419e-02  4.13871892e-02
 -4.10203904e-01  1.65623814e-01 -5.39125204e-02  1.67215783e-02
 -2.72748709e-01 -3.28239799e-01 -4.55738217e-01  6.07959628e-01
  1.02113955e-01 -2.28686959e-01  1.10014655e-01 -3.74383241e-01
 -2.23886184e-02  4.48238909e-01  2.45937601e-01  7.20952749e-01
 -1.43785909e-01  1.90725982e-01 -2.58678555e-01 -4.29339856e-02
 -3.77594233e-01  1.52148604e-01  6.29210591e-01 -4.04761434e-01
 -1.62669331e-01 -4.60432440e-01 -3.47501375e-02  1.82227075e-01
  2.62827903e-01 -5.83473928e-02  2.11014122e-01 -1.90144789e+00
 -5.97084522e-01  5.19373894e-01  3.84292722e-01 -6.02978230e-01
 -7.64319062e-01  6.13130890e-02  1.56851918e-01  5.39053023e-01
 -8.75477731e-01 -5.32197654e-01 -8.28281760e-01 -1.50137395e-01
 -1.81668058e-01  1.06538154e-01  1.29126877e-01  5.15893519e-01
  9.62257311e-02 -1.88063160e-01 -4.04352069e-01 -7.49030888e-01
  2.37441316e-01 -5.86002588e-01  4.06680882e-01 -1.77508950e-01
 -1.65446967e-01 -8.41840982e-01 -4.36468661e-01 -3.69722217e-01
 -3.06954712e-01  2.70961583e-01  2.68343866e-01 -2.91308239e-02
 -4.43333089e-02 -3.57164919e-01  3.88783514e-02  1.12962000e-01
  1.05040491e+00 -4.67287749e-01 -4.29270655e-01 -4.50699210e-01
 -5.80681920e-01  1.08123131e-01  6.05903327e-01  1.65686160e-02
 -2.61953324e-01 -5.62100559e-02 -2.00126320e-01 -6.75356984e-01
 -8.41957688e-01 -4.51792896e-01  2.02705398e-01  2.83576041e-01
 -1.38094395e-01 -5.33603072e-01  8.76323208e-02  4.94251102e-01
 -2.52503961e-01  1.13746278e-01 -2.03584656e-02  3.04185182e-01
 -1.06746696e-01  8.49342793e-02 -5.89339674e-01  4.73729998e-01
  8.05628717e-01  2.71965880e-02  3.64181638e-01  5.45690179e-01
 -4.14106190e-01  3.05417210e-01  3.83551717e-02 -1.54550821e-01
  5.52027464e-01  1.30714653e-02  1.21293090e-01  6.07725620e-01
 -3.57116729e-01 -3.45925599e-01  2.19849944e-02 -4.21809286e-01
  3.15289795e-01  6.91049278e-01 -1.69819146e-01 -5.62964380e-01
 -9.60489750e-01  1.94059566e-01 -1.15053423e-01 -3.95942420e-01
  6.95670843e-02  5.24928927e-01 -1.82516858e-01 -6.40673161e-01
  3.71465921e-01 -2.12416902e-01 -3.00757825e-01  3.69615071e-02
 -3.35016370e-01  4.64883298e-01  6.14022929e-03  3.55429262e-01
  1.09047800e-01  1.93891883e-01  8.45514238e-02  4.43633348e-01
 -1.08058795e-01 -3.27902526e-01 -1.53324818e-02  3.14709127e-01
  1.23539716e-01  1.25397608e-01  2.23939821e-01  3.53856266e-01
  1.71456829e-01  6.56825542e-01 -4.38301355e-01 -1.44036591e-01
  2.35789105e-01 -5.75450100e-02  3.27325970e-01  1.58221483e-01
  5.70936836e-02  1.23003758e-01 -1.29683688e-01  2.29820266e-01
  4.87601310e-01 -7.14131415e-01 -2.47431900e-02  1.03793144e+00
 -2.22778708e-01  2.47072712e-01  1.72151297e-01 -1.68974727e-01
  4.33062091e-02  3.09642881e-01  8.13951731e-01 -1.15831718e-01
  3.49134415e-01  4.24039476e-02  2.47127399e-01  1.33024454e-01
  4.22696561e-01 -1.01789616e-01  1.75403267e-01 -2.05711633e-01
 -1.96130887e-01 -2.23552182e-01 -1.01227380e-01  6.86340094e-01
 -8.04842055e-01  7.41755888e-02 -5.85995972e-01 -4.96622473e-01
  1.28963709e-01  2.52384041e-02  1.78480268e-01  6.95885867e-02
  2.58104652e-01 -3.32550198e-01 -4.83053923e-01  1.50515318e-01
  5.57519555e-01 -6.91647083e-02 -6.92747712e-01  1.09956570e-01
  1.65186107e-01 -2.77133077e-01  4.81329530e-01 -4.32892412e-01
  3.83756869e-03 -2.65887022e-01 -5.21007717e-01  3.72733355e-01
 -4.08729792e-01 -2.18507409e-01  1.82310775e-01 -3.85155454e-02
 -4.16916549e-01 -7.05457618e-03 -2.97198206e-01  8.04505229e-01
  1.43392801e-01 -4.97734547e-03 -2.55377054e-01 -1.50346443e-01
 -6.32254854e-02  8.22133124e-02 -4.67112988e-01  1.03709489e-01
  8.74808282e-02 -3.36653262e-01  1.24337308e-01 -3.66065204e-01
 -4.85663861e-01 -1.12369037e+00  2.89946735e-01  1.44063547e-01
  3.74367207e-01  2.64433205e-01  1.33437589e-01  5.88412344e-01
 -5.04446745e-01  4.38481867e-01 -2.52555427e-03  2.84269422e-01
  4.89463061e-02  4.01675195e-01 -3.19045186e-01  6.97410762e-01
 -3.02709788e-01  8.23522359e-02 -2.80377775e-01  1.18203638e-02
  1.39769122e-01 -1.85566813e-01 -6.08722448e-01 -9.19073105e-01
 -5.27099967e-01 -8.23427141e-02  1.86758284e-02  5.95058687e-02
 -3.32026869e-01 -7.49079525e-01  3.66906255e-01  3.01606238e-01
 -9.27446932e-02  1.22355483e-01 -3.47711831e-01  4.33875531e-01]",4J6N3XSN,False,False,"[7.283907413482666, -0.8643151521682739]"
R7WYTFYJ,586YZDHK," Semantic Interaction for Sensemaking:  Inferring Analytical Reasoning for Model Steering Alex Endert, Patrick Fiaux, and Chris North, Member, IEEE Abstract—Visual analytic tools aim to support the cognitively demanding task of sensemaking. Their success often depends on the ability to leverage capabilities of mathematical models, visualization, and human intuition through flexible, usable, and expressive interactions. Spatially clustering data is one effective metaphor for users to explore similarity and relationships between information, adjusting the weighting of dimensions or characteristics of the dataset to observe the change in the spatial layout. Semantic interaction is an approach to user interaction in such spatializations that couples these parametric modifications of the clustering model with usersʼ analytic operations on the data (e.g., direct document movement in the spatialization, highlighting text, search, etc.). In this paper, we present results of a user study exploring the ability of semantic interaction in a visual analytic prototype, ForceSPIRE, to support sensemaking. We found that semantic interaction captures the analytical reasoning of the user through keyword weighting, and aids the user in co-creating a spatialization based on the userʼs reasoning and intuition. Index Terms—User Interaction, visualization, sensemaking, analytic reasoning, visual analytics.  1 INTRODUCTION Visual analytics is a science based on supporting sensemaking of large, complex datasets through interactive visual data exploration [2]. The success of such systems hinges on their ability to combine capabilities of statistical models, visualization, and human intuition – with the goal of supporting the user’s analytic process. Through interacting with the system, users are able to explore possible connections, investigate hypotheses, and ultimately gain insight. This complex and personal process is referred to as sensemaking [3].  Sensemaking is composed of two primary parts – foraging and synthesis. Foraging refers to the stages of the process where users filter and gather collections of interesting or relevant information, while synthesis describes stages of the process where users create and test hypotheses about how foraged information may relate. In general, foraging lends itself to more computational support, while synthesis leverages human intuition for establishing relationships between information. Thus, a goal of visual analytics is to develop visualizations that are tightly coupled with mathematical models to provide computational support for the user – integrating foraging and synthesis.  Semantic interaction [1, 4] is an approach that enables such coupling, where analytic interactions designed for synthesis in visualizations are also designed to steer the underlying computation responsible for foraging of relevant information. Semantic interaction focuses on enabling direct manipulation of spatializations, which are two-dimensional views of high-dimensional data such that similarity between information is represented by relative distances between data points (e.g., a cluster represents a collection of similar information) [5].  ForceSPIRE (shown in Fig. 1) is a visual analytic prototype incorporating semantic interaction for analysis of text document collections represented in a spatialization [1]. Semantic interactions in ForceSPIRE include repositioning documents, highlighting text, searching, and annotating documents. When users perform semantic interactions in the course of their reasoning process, the system incrementally updates a keyword weighting scheme in accordance with the user’s analytical reasoning (Table 1). The learned weighting scheme emphasizes relevant keyword entities within the dataset and adjusts the layout of the spatialization accordingly. Thus, the goal of ForceSPIRE is to automatically steer the spatialization based on the user’s interaction with a subset of the information. Essentially, human and computer co-create the spatial layout.  The challenge, then, is deriving a weighting scheme representative of the user’s analytical reasoning, and ensuring that the co-creation of the spatialization is in accordance with the user’s reasoning process and intended meaning of the layout. Further, the semantic interactions should enable users to cognitively focus on their analysis rather than on directly steering a complex mathematical spatialization model.  In this paper we present the results of a user study exploring ForceSPIRE’s ability to address these challenges. How can ForceSPIRE systematically quantify the reasoning process of users by building and modifying an entity weighting scheme? Additionally, we explore if the weighting scheme aided the system in adjusting the spatialization in accordance with the user’s analytical reasoning. Finally, how did users interact with the system during their analytic process (i.e., were they focused on adjusting the weighting scheme, or focused on synthesizing information)?  Our results show that each user’s weighting scheme was updated in accordance with that user’s reasoning at specific times during the investigation, and that it provided the flexibility for this scheme to adapt to the dynamic process of each user. The updates to the spatialization based on semantic interaction provided support for each user’s process, such as suggesting which documents to read next, incrementally determining the meaning of a cluster, and promoting the re-visiting of information. Users conducted their investigation by utilizing the semantic interactions to synthesize information, without focusing directly on the weighting scheme. The final spatializations generated in ForceSPIRE were co-created by the user and the system, as evidenced by a mixture of user-defined document locations, and model-defined locations, and were representative of the findings of the user as evidenced by their debriefing. These positive results suggest that semantic interaction in ForceSPIRE provides meaningful computational support for sensemaking. As a result, users are able to focus on the synthesis of information in the spatialization, while the system provides computational foraging support suited to the user’s analytic process.   •Alex Endert is with Virginia Tech, e-mail: aendert@vt.edu. •Patrick Fiaux is with Virginia Tech, e-mail: pfiaux@vt.edu. •Chris North is with Virginia Tech, e-mail: north@vt.edu Manuscript received 31 March 2012; accepted 1 August 2012; posted online  14 October 2012; mailed on 5 October 2012. For information on obtaining reprints of this article, please send  e-mail to: tvcg@computer.org. 2879        1077-2626/12/$31.00 © 2012 IEEE       Published by the IEEE Computer SocietyIEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. 18, NO. 12, DECEMBER 20122 RELATED WORK Sensemaking is an inherently cognitive-demanding task. It involves establishing implicit connections between information based on the domain expertise and intuition of the user. Pirolli and Card [3] model this process as a sequence of cognitive stages pertaining to foraging (i.e., collecting and filtering information) and synthesis (i.e., generating and testing hypotheses and relationships) [6]. It is important to note that while this sensemaking loop contains specific stages, sensemaking as a process is very complex, and at times these stages are cognitively performed in parallel [7]. Therefore, we believe it is an important goal of visual analytic tools to support this dynamic process by coupling foraging and synthesis.  Spatializations have been used to support foraging by representing high-dimensional information, such as text, in an easily comprehendible two-dimensional view. In such views, the primary representation is one where information that is relatively closer to other information is more similar [5], enabling users to find relevant information and gain new insights. For example, the “Galaxy View” within IN-SPIRE [8, 9] presents users with a spatial clustering of documents based on a dimension-reduction algorithm. Users can interact and modify this view via direct manipulation of the keyword weighting (i.e., if a user finds a term more important, she can increase the weight on that term). Similarly, STREAMIT enables direct control over keyword weighting in a force-directed model [10]. Visualizations such as “Dust & Magnet” [11] and VIBE [12] allow users to place specific points of interest in the space, acting as anchors from which the remaining points attract and repel form. Spatializations have also been used to support synthesis by enabling users to externalize their insights during an investigation. In a spatial workspace where users can manually manipulate the location of information, users build spatial structures to capture their synthesis of the information over time – a process referred to as “incremental formalism” [13-15]. Andrews et al. found that intelligence analysts can make use of such spatial structures as a means to externalize insights during sensemaking, manually placing relevant documents in clusters on a large, high-resolution display [16, 17]. Additionally, they found that the large display workspace promoted a more spatially-oriented analysis. Tools, such as Analyst’s Notebook [18], Jigsaw’s “Tablet” [19], nSpace2 [20], Analyst’s Workspace [21], and others have also found it helpful to provide users with a workspace where spatial representations of information can be manually organized. Semantic interaction strives to enable a similar ability, without requiring the user to manually place all the information. Instead, the goal is for the system to learn from the interactions and co-create the layout, essentially merging the foraging and synthesis uses of spatializations. Developing user interactions for visualizations that integrate into the sensemaking process and support analysis is an open challenge for visual analytics [22]. For example, Green et al. mentioned that during an analysis, users become focused on their task, a state they call being in the “cognitive zone” [23]. They propose that it is the responsibility of designers to offer interactions that thus focus on the task (and the data), rather than on the tool, as a means for keeping users in their cognitive zone. Similarly, Elmqvist et al. presented the concept of “fluid interaction” as a way to maintain the “flow” of the analytic process [24]. They claim that interactions should be designed so as to adhere to the inherent flow of each individual’s analysis. Dou et al. have demonstrated the capability for interaction to portray a user’s reasoning process [25]. They showed that humans could interpret a log of another user’s interactions during an analysis and effectively infer that user’s reasoning. With semantic interaction, we aim to infer the user’s reasoning systematically, supporting the “flow” of the investigation through updating the mathematical model while the user focuses on synthesizing. 3 SEMANTIC INTERACTION IN FORCESPIRE ForceSPIRE (Fig. 1) is a visual analytic prototype for spatial text analysis using semantic interaction [1]. ForceSPIRE presents users with a spatialization of the dataset, representing documents as minimized boxes, which can be expanded to full-detail documents via double-clicking. The underlying force-directed model (modified from [26]) treats documents as nodes, and edges between nodes are created if one or more keyword entity co-occurs in both documents. Entities are algorithmically extracted using LingPipe [27]. The model learns through various semantic interactions that affect the weighting, creation, and removal of entities, and the “mass” of documents. An overview of the supported semantic interactions, their corresponding analytical reasoning, and coupling to the underlying force-directed model is shown in Table 1. ForceSPIRE also includes an “Entity Viewer”, from which entities can be directly created, removed, as well as have their weights directly modified. ForceSPIRE supports the following semantic interactions (described in more detail in [1]): Document movement allows users to manipulate the spatial layout directly in the spatialization by placing documents in locations based on the user’s domain knowledge. These movements can be both exploratory and expressive [28]/{v2pi/}, differentiated by how they adjust the underlying model. Exploratory movements do not change the weighting of keywords (or entities), but use the current weights to determine the position of the remaining documents given the user-defined location of the document being moved. These can be seen as a “model constraint”, as the user decides the placement of one or more documents, and the model produces the remaining layout based on these static locations. With expressive movements, users are able to inform the system that the weighting scheme should be updated to reflect the increased similarity between two (or more) documents. For example, when placing two documents closer together, the system determines the similarity between those two documents, and increases the weight on the corresponding entities. As a result, a new layout is incrementally generated reflecting the new similarity weighting, where those two documents (as well as others sharing similar entities) are closer together. Users also have  Fig. 1. A scaled-down screenshot of ForceSPIRE taken on the large, high-resolution display used in this study (two zoomed in views shown). Users can search, highlight, annotate, and reposition documents spatially. Documents can be shown as minimized rectangles, as well as full detail windows.   2880IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. 18, NO. 12, DECEMBER 2012the ability to pin documents to specific locations. These documents serve as spatial landmarks, in that they persist at that location, and the force-directed model treats them as layout constraints, organizing the remaining documents around them. Additionally, pinning allows ForceSPIRE to distinguish between exploratory and expressive movements. Dragging a document near a pinned document will briefly color both documents pink to alert the user of the expressive movement (if the user releases the document at this location). Thus, all other movements in the space are exploratory movements. Text highlighting allows users to highlight text segments directly in the full-detail document views. As a result, the system increases the importance of the terms highlighted, updating the underlying mathematical model, and ultimately the layout. The phrases highlighted are also parsed for entities using a more aggressive entity extraction algorithm, so as to add entities to the model that may have been initially missed. (Users also have the ability to select an exact entity to add to the system.) Search allows users to perform a standard text search within the dataset. As a result, documents containing the search term will be highlighted, and an edge between the search box and those documents will be created (multiple search boxes can exist). The model is updated by increasing the weight of the entity searched for (and creating a new entity for the search term if it does not already exist).  Annotation is available for each document in the dataset. Through annotating a document, users can add “meta-information” to the document based on their domain expertise. For example, adding a note “relates to the events in Chicago” results in parsing the note for entities (i.e., “Chicago”), and adding them to the document, which creates edges to other documents containing “Chicago”.  Each of these semantic interactions creates soft data, a quantitative representation of captured user interaction within the context of the dataset. Fig. 2 models how soft data is collected (i.e., captured and interpreted interactions within the context of the dataset), as well as how it is combined with the hard data to produce the spatial layout. As a result, the soft data steers the underlying force-directed model. Also, soft data serves as a log of the entity weighting throughout the user’s analytic process, and can be examined at any time to gain insight about their process. 4 METHOD This user study investigates the following research questions about the capabilities and benefits of semantic interaction: 1. How well can semantic interaction systematically quantify analytical reasoning based on user interaction as a dynamic entity-weighting scheme? 2. How does the real-time modification of the weighting scheme and adjustment of the spatialization aid users’ sensemaking? 3. What was the focus of users while exploring the dataset through semantic interaction? That is, were they focused on adjusting the weighting scheme, or synthesizing information? 4. How does the co-created spatialization map to the users’ findings? We hypothesize that the coupling between the semantic interactions and model updates will create a dynamic weighting scheme that appropriately captures a signature of the analytical reasoning of each user throughout his or her investigation in the form of entity weights. As a result, this weighting scheme will adjust the spatialization, aiding in the co-creation of the layout, where users need not develop the entire layout manually, but also not rely on solely algorithmic generation. During this process, this will help users by adjusting the layout while users read documents and synthesize the information, bringing related documents nearby. Also, we hypothesize that the soft data captured during the analysis will be representative of the analytic product of each user, and therefore the co-created spatialization will be meaningful to the user. Throughout this process, we hypothesize that the users will remain focused on the synthesizing of information, rather than interacting to directly modify the weights of entities.  4.1 Equipment For this study, we used a large, high-resolution display (shown in Fig. 3). Such workstations allow users of ForceSPIRE to leverage the additional resolution to show many text documents at full detail, and the additional physical size to provide users with a more embodied analytic experience [17, 21, 29, 30][31, 32]. This particular Table 1. Forms of semantic interaction supported in ForceSPIRE. Each interaction corresponds to reasoning of users within the analytic process. Corresponding model updates are performed to steer the model based on the userʼs reasoning. Semantic Interaction Associated Analytic Reasoning Model Updates Document Movement •Similarity/Dissimilarity •Create spatial construct (e.g. cluster, timeline, list, etc.) •Test hypothesis, see how document “fits” in region •Similarity/Dissimilarity b/w documents •Up-weight shared entities, down-weight others Text Highlighting •Mark importance of phrase (collection of entities) •Augment visual appearance of document for reference •Up-weight highlighted entities Pinning Document to Location •Give semantic meaning to space/layout •Layout constraint of specific document Annotation, “Sticky Note” •Put semantic information in workspace, within document context •Up-weight entities in note  •Append entities to document and model Level of Visual Detail (Document vs Icon) •Change ease of visually referencing information (e.g. full detail = more important = easy to reference) •(Full Document): “heavier node”, increase node’s friction •(Icon): “lighter node”, less friction Search Terms •Expressive search for entity •Up-weight entities contained in search •Add entities to model   Fig. 2. The spatialization in ForceSPIRE is treated as a “medium for interaction”, where interpreted analytical reasoning from each interaction is stored as “soft data” [1].  2881ENDERT ET AL: SEMANTIC INTERACTION FOR SENSEMAKING: INFERRING ANALYTICAL REASONING FOR MODEL STEERINGworkstation is constructed using 8 30-inch displays, driven by a single node, providing a total workspace resolution of 10,240 x 3,200 pixels. The curvature allows easy access to all areas via physical navigation, such as chair rotation [32, 33].  The dataset used for this study is an analysis exercise called Atlantic Storm developed for the purpose of training and evaluating intelligence analysts, as well as analytic tools. The dataset consists of 111 text intelligence reports containing a fictitious terrorist plot. Using LingPipe [27] to extract keywords (i.e., entities) from these documents, 294 unique entities occurring more than once in the dataset were extracted (singletons were removed). The choice to use this dataset is based on the ability to have a realistic dataset, containing a known ground truth against which to compare the findings of the users, while requiring no detailed domain knowledge beyond English reading comprehension and creativity.  4.2 Data Collection and Analysis ForceSPIRE has the ability to log the soft data used for semantic interaction. For the purpose of this study, this gives us a record of every interaction performed by the user, as well as how the system interpreted the interaction in context of the dataset. For example, when a user highlights a phrase, the soft data shows us when the highlight occurred, what the text is, in which document, as well as what entities’ weights changed, and what the new weights are.  The users were asked to provide us with verbal feedback throughout their process. In a post-study interview, subjects explained their findings, the resulting spatialization, and insights about their process that may have been missed during the think-aloud protocol. Video recordings and screenshots were also taken during each task for post-study analysis. 4.3 Procedure This study consisted of observing 6 computer science graduate students. The age of the participants ranged from 27 to 38, with an average age of 30. Each participant was given a brief overview of ForceSPIRE, using a practice dataset, for the purpose of making each user familiar with how ForceSPIRE and the supported semantic interactions function. Upon informing us that they were comfortable, each user was given verbal instructions on their task. Each user was given the same initial view of the Atlantic Storm dataset in ForceSPIRE as a starting point. We informed the participants that they had a maximum of 90 minutes to analyze the dataset, after which they will be debriefed regarding their investigation. They were allowed to finish early if they felt they were finished before time expired.  5 RESULTS The success of a visual analytic tool hinges on the ability to provide support during the analytic process, as well as a meaningful representation of the user’s findings. Thus, the results of this study are presented in terms of the analytic process and product. The analytic process describes how the semantic interactions within ForceSPIRE were used during the analysis, how the corresponding model and spatialization updates benefitted the users, and how the soft data mapped to each user’s process. The analytic product details how the findings of each user are represented in the final spatialization, as well as the final weighting of keywords. 5.1 Analysis of Process Each user’s process was different, and thus utilized semantic interaction differently (Table 2). However, the analysis of each user’s process reveals general usages of each semantic interaction. To address the research questions, we present the analysis of the processes of the users in terms of usage (how and when they used each semantic interaction), reasoning (what was their purpose for interacting, sensemaking or model steering), impact on weighting scheme (how the updated weighting scheme coincided with their reasoning process), and impact on spatialization (how did the updating spatialization benefit their analysis). 5.1.1 Semantic Interaction Usage Performing a spatial analysis of data focuses around rearranging documents and creating spatial constructs or clusters [17, 34]. As such, pinning and document movement (both exploratory and expressive), were the fundamental methods of exploring the dataset. Pinning documents to absolute positions in the spatialization was used to create “spatial landmarks”. That is, users pinned a document to a specific location in the layout to create (and maintain) meaning of a specific region of the spatialization. Based on these landmarks, document movement was used to organize the spatialization based on the user’s intuition. For example, User3 pinned a document mentioning “Nassau” in a specific location. From there, he placed other documents related to “Nassau” nearby, and also quickly re-acquired these documents when needed. Highlighting was used mostly while reading a document to indicate terms or phrases that “stood out”. These highlights were beneficial to users to produce visual and cognitive aids. The highlighted phrases (mostly single words and fragments of sentences) helped remind users of what information was important in a document when re-acquiring the document later. User6 was the only user who did not perform any highlighting during his investigation, simply stating that he “did not feel a need to.” Search was used to find other documents containing a term of Table 2. Semantic interaction counts during each userʼs analysis.  User  Interaction: 1 2 3 4 5 6 Total Search 13 32 37 14 38 21 155 Highlight 47 58 12 10 5 0 132 Expressive Movement 45 76 47 62 26 27 283 Exploratory Movement 41 102 64 26 98 43 374 Annotation 3 40 3 0 0 0 46 Total 149 308 163 112 167 91   Table 3. Number of entities added via semantic interaction during each userʼs investigation. The majority of these new entities (92%) maintained a weight above 0 throughout their process.  User   1 2 3 4 5 6 Entites Added 43 62 35 13 15 10 Weight > 0 38 54 35 13 14 10   Fig. 3. The 32 megapixel large, high-resolution display used in this study.  2882IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. 18, NO. 12, DECEMBER 2012interest to the user. Generally, users performed a search on keywords for two reasons. First, the unique color assigned to each search provided a quick overview of where in the dataset the term occurred given the current spatial layout. Second, users treated the search window (of which more than one could be opened) as a means to “tag” the space. For example, all of the users commented that leaving multiple search windows open and pinned to specific locations was an effective way to recall the meaning of that specific position in the spatialization.  With the exception of User2, annotation was rarely used. User2 said that he enjoyed the ability to “add personalized notes to important documents.” In his case, ForceSPIRE detected 23 entities in his annotations (that were not in the dataset), including entities such as “irrelevant”, “suspicious”, and “revisit” (extracted from a note stating “should revisit this later”). During his investigation, he also found it useful to track what documents he found important by scanning the workspace and seeing which documents had the yellow notes window visible. Thus, annotations can be helpful to some users, while others prefer to utilize other interactions to support their analysis.  5.1.2 Aiding the Sensemaking Process The primary benefit for sensemaking provided by ForceSPIRE was aiding the user in adjusting the layout by bringing related information nearby.  Each semantic interaction in ForceSPIRE is tightly coupled with the dynamic weighting scheme used by the force-directed model responsible for generating the spatial layout. As such, ForceSPIRE responds to each interaction via updating the spatialization as a result of the updated weighting scheme.  Each user’s process involved multiple stages of the investigation, including exploring specific leads (e.g., a person, place, etc.) and hypotheses regarding the dataset. As such, it is important for semantic interaction to allow a flexible entity weighting scheme to support exploring each of these aspects during different times of the investigation.  For example, while a user investigates information regarding the entity “Atlanta”, the weight of entities similar to (and including) “Atlanta” should increase. If the user chooses to investigate “weapons” at a later time, the weighting scheme should reflect this change. The challenge then, comes in supporting the rapid and fluid change of what is currently being investigated by a user through rapidly changing keyword weights, while maintaining a history of the previously emphasized keywords.  For example, Fig. 4 shows the temporal history of User4’s keyword weighting during his analysis. The patterns and trends observed in User4’s analysis of the soft data is also representative of the other users’ history. One can see that approximately two minutes into the investigation, the entity “package” was created. The creation occurred while User4 read a document and found the phrase “carefully wrapped package” important, and thus highlighted it. The effect on the layout was that documents containing the entity “package” were brought closer. He did not immediately switch to reading those documents, instead continued to read the document while other related documents came nearby. This strategy was found in other users’ processes also. “It was nice to see what documents would come near while I was reading and highlighting”, User1 told us after his investigation. He continued to tell us that he would notice other documents coming closer, but would “continue reading and highlighting until I finished that document, then decide where to go next depending on what’s close by.” Upon finishing reading the document, User4 pinned it, and chose the closest document to continue his investigation. This document was one related to “package”, and important to the plot. He continued reading three  Fig. 4. User4ʼs entity weighting over the duration of his analytic process. Semantic interactions in ForceSPIRE adjusted the weights of entities to coincide with his investigation of multiple hypotheses. As a result, the layout adjusted incrementally with each interaction. Table 4. Each userʼs top 5 entities, collected both from the userʼs debriefing (user), and based on the final entity weighting (model). Underlined entities indicate a match between the user and model. Bold entities were entities added to the model as a result of semantic interaction during the analytic process (i.e., missed by the initial entity extraction). 1 (user) 1 (model) 2 (user) 2 (model) 3 (user) 3 (model) 4 (user) 4 (model) 5 (user) 5 (model) 6 (user) 6 (model) diamonds diamonds package Nassau explosives Nassau diamonds package Al Queda Nassau diamonds weapons scholarship weapons Hanif Hanif weapons students Nassau Chicago Caribbean Miami antibiotics diamonds jihad graduate antibiotics Freeport Nassau weapons Burgarov Russia Russia Freeport Ortiz Nassau weapons Jamal diamonds Miami students scholarship antibiotics Nassau Hanif Apple St. Bahamas graduate freeport Nassau Nassau package scholarship Jamal package Burgarov Odeh weapons Hijazi Hijazi  2883ENDERT ET AL: SEMANTIC INTERACTION FOR SENSEMAKING: INFERRING ANALYTICAL REASONING FOR MODEL STEERINGmore documents containing “package”, highlighting other phrases that contained the term. As such, the term continued to increase in weight, and related documents continued to form more tightly around the one that was pinned.  Fig. 4 also shows instances when User4 explored other potentially relevant information. For example, at 36 minutes into his analysis, he informed us that he wanted find out more information regarding events in “Chicago”. This stemmed from reading a document that mentioned “Chicago”. He highlighted the single word, and immediately pinned the document in a specific location, away from other documents. Then, he searched for the term “Chicago”, and placed the search window next to the pinned document. Then, he opened and read some of the documents containing Chicago (they were highlighted teal from the search) that came closer. The first 2 documents he read, he placed near the first pinned document. As a result, the weighting of “Chicago” increased, but so did the weights of other related entities, such as “Russia”, “weapons”, and “Panama City”. This occurred because the documents he dragged near the pinned document containing “Chicago” were not similar based on only “Chicago”, but those other entities as well. As a result, more documents came closer that did not contain strictly “Chicago”, but were related. In this case, he read some of the documents containing “Russia” and “weapons” and moved them into another, separate location. Again, ForceSPIRE responded by moving the documents more similar to “Russia” and “weapons” into that location, rather than near the location regarding “Chicago”.  This benefitted the user as he noticed how some documents remained in the middle of the two areas, showing relevance to both topics. These were documents connecting these two, and important to the plot.  Towards the end of his investigation (approximately one hour into it), he focused on tying all the pieces of evidence he had collected together. He did so through exploring the relevance of “Bahamas” and “Nassau”. He did so primarily through small, local movements within an area specific to each. He arranged the documents within the region to reflect a sequence of events related to transportation of a package. In addition to the weight increase of those entities, he discovered the relevance of some of the key persons involved in the suspicious activity (i.e., “Odeh”, “Hanif”, and others). He found an important document detailing how some of the weapons (which he investigated earlier) were possibly being transported by students funded through a suspicious scholarship fund. The history of his weighting scheme reflects each of these hypotheses and branches during his investigation, as indicated in Fig. 4.  In addition to increasing the weighting of entities that were relevant to the investigation, semantic interaction also reduced the weight of entities that were not. ForceSPIRE does so through “decaying” the weights of previously emphasized keywords over time. That is, as other keywords are emphasized via various semantic interactions, weights of previously emphasized keywords will begin to decay. Therefore, if they are never investigated again, they will eventually return to their lower weight, but if they are revisited again later, they will increase in weight again. At times, this resulted in the weights of those entities going to zero (thus having no impact on the spatial layout). Across all users’ processes, the average number of entities where this occurred at least once is 245 (out of the 294 unique entities initially extracted by ForceSPIRE). While these entities did not have an impact on the spatial layout when their weight was set to 0, subsequent semantic interactions continued to use these entities to measure similarity. As a result, entities that may not have been relevant during the early stages of an investigation and were relevant to a later hypothesis being explored, saw their weight increased. An example from User4 is the term “Nassau”, which was not relevant to his investigation until approximately 54 minutes into the study, where the weight increased from zero (as shown in Fig. 4). This happened as a result of him dragging one document close to another on the basis of both being about an event in the “Bahamas”. ForceSPIRE interpreted this similarity, but also found these documents similar because of “Nassau”, increasing the weight of the term and bringing those related documents nearby. Semantic interaction aided two users from this study in creating a “junk pile” (i.e., a collection of documents that are not relevant to the main plot, and are thus placed in a location away from the relevant information). As these two users placed more information into the same cluster that they referred to as “junk”, ForceSPIRE calculated the similarity between the documents being placed into this cluster and increased the weight of those entities. “Look! It’s moving other junk into my junk pile for me” User1 remarked. However, he was sceptical of the system’s ability to detect irrelevant documents, so he opened and read a few of them as they moved closer. Some, he agreed with being junk and left them in the junk cluster, while others he moved near other pinned documents in the spatialization. By doing so, he continued to improve ForceSPIRE’s ability to detect irrelevant documents. When asked about this experience after the study, he told us that the more he interacted with the layout (including his “junk pile”), the more pleased he became with the metrics for determining junk, and the “more [he] trusted it”.  An important capability in ForceSPIRE is the steering of the entity extraction algorithm for generating additional entities during an investigation.  Entities can be added to the system through semantic interaction, which was critical to the ability to capture and infer the users’ reasoning processes. While the entity extraction algorithm in ForceSPIRE managed to extract 294 unique entities, each user found additional entities that were relevant to their analysis. Table 3 shows the number of entities created as a direct outcome of semantic interaction. Of these, most (92%) maintained a weight greater than zero throughout the investigation. This shows that not only was it important for users to steer the weighting of existing, extracted entities, but also to steer the entity extraction algorithms to generate additional entities. For example, User3 highlighted the phrase “he has students now in the USA”, which was passed through a more aggressive entity extraction algorithm, and detected “students” as an entity. This entity was important to the user’s findings, as well as highly weighted in the model (Table 4).  Pinning and un-pinning documents was used not only to place meaningful documents in absolute positions in the workspace, but also to check if the current weighting model would place the document in another region (or into another cluster). For example, three of the users commented that they un-pinned a document to see where it went after it had been pinned for a long time. They were interested in other possible topics it might relate to. If nothing particularly interesting was found, they returned the document to the previous location and pinned it again. However, often users found relationships between these documents and other clusters, and typically either left the document un-pinned, or pinned it in a different location from where it was pinned previously. For instance,  Fig. 5. The “Entity Viewer” in ForceSPIRE allows users direct control over entity weights, adding entities, and removing them. With semantic interaction, this view was not needed.  2884IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. 18, NO. 12, DECEMBER 2012User1 found that he had a document pinned from very early in his investigation that referred to the Freeport Star Hotel. When he un-pinned it, he saw it go near other documents about the Bahamas and Nassau, which helped him make the connection about the events happening in that area. In general, users emphasized the importance of observing the spatialization adjust incrementally. That is, to notice the change in relative distances between documents as a result of the highlighting they did while reading, searching, etc. Such exploration can be found in other tools, such as VIBE [12] or Dust&Magnet [11], where users can place “points of interest” corresponding to keywords in specific locations, and observe how the spatial layout adjusts given those keywords and locations.  Users did not treat the semantic interactions as a means to directly manipulate entities. That is, they interacted as a means to synthesize the information. For instance, based on their comments, highlighting was performed not to pass a phrase through a more aggressive entity extraction algorithms, but to emphasize a part of the text as being important, so as to be able to find it again more easily later. “Oh, that’s important … [I] might need to come back to [it]”, one user stated while highlighting a phrase. None of the users found the need to directly manipulate entities (e.g., adjust the weights, add, remove) via the “Entity Viewer” (shown in Fig. 5). All users were shown this feature in the training, but none found it necessary to use during their actual investigations. These results evidence that semantic interaction properly coupled the semantic interactions with model updates, to the extent that users never felt the need to do so directly. This contrasts with the intended usage of other tools, such as IN-SPIRE [35], where model steering occurs via direct parameter manipulation on the part of the user. With ForceSPIRE, users were successfully able to focus on the synthesis necessary for sensemaking, while the parameter adjustments occurred systematically in accordance with their analytic reasoning. 5.2 Analysis of Product At the conclusion of each trial, we asked the user to describe his findings (both in terms of what information is relevant to the suspicious plot, which all users found, and information that was not). ForceSPIRE remained visible during this debriefing, but we asked users to not interact with the tool, but simply use the final layout as a means to help describe their findings. The analytic product with regards to this study refers to the final spatial layout in ForceSPIRE, as well as the user’s debriefing after the study. We analyze this information in addition to the final weighting scheme (i.e., soft data) at the conclusion of the analysis. Compared to the known ground truth of the dataset, each user found the suspicious activities, with varying amounts of detail to support the findings. Thus, the analysis of the product here is with regards to ForceSPIRE’s ability to create synergy between what the system and the user knows (rather than compared to the ground truth).  The final weighting schemes at the conclusion of each user’s investigation served as a good approximation of the keywords relevant to their findings (see Table 4). This table shows the top 5 keywords from each user’s debriefing and the top 5 entities based on entity weight, labelled “user” and “model” respectively. The entities from the debriefing were given to us by the user as part of their debriefing to represent their findings. The entity weights were obtained by taking the top 5 highest weighted entities in the final soft data state. The entities highlighted in bold are entities that were not initially extracted, but added to the model through the user’s semantic interaction during the study.  These results reveal that 47% of the entities match directly from the user’s findings to the highly weighted entities. In addition, 11 of the highly weighted entities were added to the model as a result of semantic interaction. Of these 11, 7 were important based on the debriefing of the user (i.e., they matched with the top 5 entities given to us by the user). Therefore, not only were these entities added as a result of semantic interaction, but they were also relevant to the user’s findings.  In some cases, there is not a direct match between the entities obtained during the debriefing and the entity weighting. For example, User5’s entities show no direct matches. However, a more sophisticated entity correlation algorithm may find connections between entities such as “Caribbean” and “Nassau”, “Freeport”, “Miami”, and “Apple St.” (an address in Nassau in this dataset). Thus, even when there are not direct matches, we find that the higher weighted entities provide a good estimate of characteristics of the dataset users found important and relevant to their investigation. In fact, this indicates that the system was successfully able to interpret the user’s reasoning within the context of the actual data.  That is, the system identified keywords relevant to the user’s process that the user did not think of or at least had used other words in place of. This suggests that the system fulfills the needs of incremental formalism and ill-defined user-generated clustering [34]. 5.2.1 Spatialization Co-Creation One of the goals of semantic interaction is to properly steer the underlying model to allow for co-creation of the spatialization Table 5. Pinned and unpinned documents and search windows in each userʼs final spatialization.   User   1 2 3 4 5 6 Docs. Pinned 34 41 44 28 32 34 Un-Pinned 77 70 67 83 79 77 Detail 85 88 89 36 40 49 Minimized 26 23 22 75 71 62 Search Windows Pinned 9 19 31 2 16 5 Un-Pinned 0 0 0 1 1 0    Fig. 6. The progression of the spatialization over time for User04. The annotations (labels and red region boundaries) were added after the study. They represent the meaning of the regions of the space, indicated by the user during his process.  2885ENDERT ET AL: SEMANTIC INTERACTION FOR SENSEMAKING: INFERRING ANALYTICAL REASONING FOR MODEL STEERINGbetween the user and the model. As such, we hypothesized that some documents (and search windows) would be pinned by the user to maintain their absolute position in the workspace, and others would be un-pinned so that the model could determine their position based on the current entity weighting. Table 5 shows the number of pinned and un-pinned documents and search windows in the final layout produced by each user.  In the final layouts, 32% of the documents were pinned. Based on the debriefing, the users informed us that some documents were pinned to maintain their absolute position in the workspace for the purpose placing meaning into the workspace. However, others were at times pinned for more detailed adjustments to cluster layout. For example, User2 commented that he would pin documents in a cluster so that he could create detailed spatial structures within a cluster (e.g., a timeline). ForceSPIRE currently does not well support such multi-scale spatial layouts, but feedback from users suggests doing so in the future. The majority of search windows were pinned (98%). Users treated them as “tags” for their spatialization, as searches were performed on entities. The only two users who had one search window un-pinned (User4 and User5), explained that they preferred to have it “float” to get an idea of where the documents are that related to that term.  For example, User4’s progression of the co-created spatialization can be seen in Fig. 6. After 16 minutes, his layout was made up of two main clusters: one about “package” and one about the “Central Russian Airline”. Then, as his investigation continued, he learned more about the dataset (e.g., a suspicious “fund”, documents about “weapons”, etc.). At the completion of his trial (83 minutes), he was aware of much more detail regarding the dataset, such as events happening in “Nassau” regarding the “package”, a suspicious person named “Ortiz”, and a unrelated plot in “Russia”. Additionally, the layout placed a collection of documents along the far left, which the user told us were “junk”. These results indicate that the spatialization was successfully co-created (based on the coinciding weights, shown in Fig. 4), and maintained meaning for the user. As such, not only did the weights reflect the analytic reasoning of the user, but the spatialization seemed to successfully reflect the shared knowledge between the user and the system at each stage. 6 DISCUSSION Through this user study, we explored and validated the principles grounding semantic interaction. These principles include (fully described in [1]: • capturing semantics from user interaction; • shielding the users from direct parameter manipulation; • incrementally co-creating of the spatialization through incremental model learning, to coincide with the incremental formalism [13] of the user. 6.1 Capturing Semantics from User Interaction ForceSPIRE captured the semantics from users in terms of the entities contained in the dataset. The method for capturing these semantics is supported via changing the weighting of entities, as well as the creation of entities. In turn, the semantics are reflected in the steering of the weighting scheme of the model.  The ability to steer this model at multiple levels of detail was important because it coincided with the user’s reasoning about different levels of detail. For example, document movement allowed users to provide more broad and informal feedback regarding important relationships between documents. Generally, this feedback was at the document level, where users would create clusters of documents without a formalized schema as to precisely why they are all similar. For example, User 2 told us he enjoyed the flexibility of moving documents because “[the system] will eventually figure out what [he] mean[s]”. Similarly, User4 used expressive movements more heavily than exploratory movements. When asked about his preference, he informed us that “[expressive movements] tell the system something”, and that the more he told the system, the “better chance the system will figure it out”.  Other semantic interactions, such as search and highlighting, were used to provide more detailed insight into what characteristics of a dataset were relevant to the user. Similar to the results found by Endert et al. [34], highlights were typically short phrases containing relevant entities, while searches were performed only on keywords. To the users, the highlighting was preformed to provide visual importance to portions of documents. However, the system interpreted these as indicators as to what information should be examined more closely, resulting in entity creation and up-weighting. As a result, ForceSPIRE did not only change the distribution of the weights, given the initially extracted entities, to attempt to produce the best fit given the user feedback, but also added entities when given feedback regarding relevant text within the dataset. As shown in Table 4, the entities added through semantic interaction were not only highly weighted in the soft data, but many also correlate to entities important to the users. 6.2 Shielding from Direct Model Steering The users in this study treated their investigation not as steering a model, but rather synthesizing information. This is an important distinction, as it shows semantic interaction as providing a fundamentally different and richer method of interacting with visual analytic systems. As a result, semantic interaction enabled a analytic process similar to the effective spatial processes described in [13, 16, 34], where the informality of the spatial synthesis interactions were beneficial in supporting incremental formalism. However, unlike these examples where a majority of the spatialization is created manually, semantic interaction provides computational support. Therefore, while users realized an implicit ability for ForceSPIRE to learn about the characteristics important to them, the explicit use of the system was to synthesize information.  6.3 Incremental Model Learning and Formalism Users develop insights into a dataset through interacting and exploring it. As such, users learn additional information as they proceed through their analysis. For example, when constructing spatial groups manually, the meaning of these clusters gradually changes as more information is learned [34]. A cluster that was created based on a single term of interest, may evolve to represent a more broad meaning, represented via a collection of terms.  ForceSPIRE was able to incrementally learn these insights, and translate them into representative entity weightings and ultimately helpful spatializations. For example, User4’s cluster regarding “Nassau” transformed into a cluster also containing documents that did not include the term directly, but instead contained terms such as “Bahamas” and “Freeport Star Hotel”. These were conceptually related events, and thus the user decided to group them. The structural relationship between these documents can be described as a “transitive relationship” [34] (i.e., there is a connecting document that contains both terms). One challenge in this form of relationship is determining which terms to use for the transitivity. ForceSPIRE incrementally learned these terms, through semantic interactions such as moving a document near a cluster (confirming membership) and moving a document towards a different cluster (disagreeing with transitive relationship).  7 FUTURE WORK The concept of “undoing” a semantic interaction is not trivial, as not only was the spatial location of a document adjusted, but the coupled model updates changed the entity weighting scheme used to probabilistically determine the position of the other documents. The version of ForceSPIRE used in this study did not include an undo 2886IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. 18, NO. 12, DECEMBER 2012functionality. However, none of the users requested it. User3 made an erroneous move, where he accidentally dragged a document near the wrong cluster. “Ooops, oh well, [ForceSPIRE] will fix that later”, he said (instead of asking how to undo), implying that the small number of erroneous interactions will be outweighed by the sum of the meaningful interactions over time. One approach in another version of ForceSPIRE is to store previous weighting schemes, so that when an undo occurs, the previous weights are restored, and the model updates the spatialization accordingly [1]. However, a “true undo” of a semantic interaction would be one from which the model learns about the user’s analytical reasoning. As such, instead of restoring the weights of upweighted entities from the interaction, the system could lower the weights below the previous weights to reflect the user’s decision to discontinue the investigation of those topics. This is an open research area we plan to investigate. The soft data captured during each user’s process is used directly to steer the force-directed model calculating the spatialization (Fig. 2). We believe soft data has potential for additional benefits. Various types of biases are common pitfalls for analyses [36]. For example, confirmation bias can result in users accepting evidence to confirm a given hypothesis, and ignoring evidence that may refute it. Showing the history of weighting to users during their investigation might help illuminate some of these biases, making users more aware of the potential to explore other hypotheses. We are planning to incorporate a soft data graph view into the workspace in the future. Soft data has the potential to aid a group of analysts with asynchronous collaboration. Each collaborator’s soft data provides an approximation of both the process and the findings. For example, continuing an investigation started by another can be made easier by illuminating the process through observing the weighting changes. This gives the collaborator a better understanding of the hypotheses already explored. Additionally, when multiple analysts are asked to investigate the same dataset, the history of entity weighting for each user enables an overview of the group’s collective investigation. One open challenge is how to effectively merge soft data from multiple users. 8 CONCLUSION In this paper, we present results of a user study investigating the principles of semantic interaction for supporting sensemaking. Semantic interaction is an approach to user interaction with visualization that couples analytic interactions within a spatialization (e.g., document repositioning, text highlighting, search, annotations) with updates to the underling model responsible for generating the spatial layout. As such, semantic interaction tactfully combines interactions enabling users to synthesize information with model updates to support computational foraging support for sensemaking.  The results indicate that the semantic interactions in ForceSPIRE provided the flexibility for users to investigate and explore data spatially. Semantic interaction provided the expressiveness required to update the model to coincide with the user’s analytic reasoning. The captured soft data during the investigation supports the analytic product of each user, and was also able to adapt to the different points of emphasis and hypotheses during each investigation. Users regarded semantic interactions not as direct model steering, but as interactions for synthesis. Finally, ForceSPIRE updated the spatialization based on the semantic interactions of the user, and the final layouts were representative of each user’s findings. The spatialization was incrementally co-created between the user and the system.  Given the positive results of this study we encourage further research in this area to advance the field of visual analytics through exploring the science of interaction. ACKNOWLEDGMENTS This research was supported by NSF FODAVA grant CCF-0937071 and the DHS VACCINE Center of Excellence.  REFERENCES [1] Endert, A., Fiaux, P. and North, C. Semantic Interaction for Visual Text Analytics. In ACM CHI, 2012. [2] Thomas, J. J. and Cook, K. A. Illuminating the path. IEEE Computer Society, 2005. [3] Pirolli, P. and Card, S. Sensemaking Processes of Intelligence Analysts and Possible Leverage Points as Identified Though Cognitive Task Analysis Proceedings of the 2005 International Conference on Intelligence Analysis, McLean, Virginia2005), 6. [4] Endert, A., Fiaux, P. and North, C. Unifying the Sensemaking Loop with Semantic Interaction. In IEEE Workshop on Interactive Visual Text Analytics for Decision Making at VisWeek 2011, Providence, RI, 2011. [5] Skupin, A. A Cartographic Approach to Visualizing Conference Abstracts. IEEE Computer Graphics and Applications, 222002), 50-58. [6] Pirolli, P. and Card, S. Information foraging in information access environments. In Proceedings of the SIGCHI conference on Human factors in computing systems, Denver, Colorado, United States, 1995. [7] Kang, Y.-a. and Stasko, J. Characterizing the intelligence analysis process: Informing visual analytics design through a longitudinal field study. City, 2011. [8] Wise, J. A., Thomas, J. J., Pennock, K., Lantrip, D., Pottier, M., Schur, A. and Crow, V. Visualizing the non-visual: spatial analysis and interaction with information for text documents. In Readings in information visualization: using vision to think, 1999. [9] Bohn, S. J., Calapristi, A. J., Brown, S. D. and Nakamura, G. C. Analytic Steering: Inserting Context into the Informaion Dialog. In IEEE Workshop on Interactive Visual Text Analytics for Decision Making at VisWeek 2011, Providence, RI, 2011. [10] Alsakran, J., Chen, Y., Zhao, Y., Yang, J. and Luo, D. STREAMIT: Dynamic visualization and interactive exploration of text streams. In IEEE Pacific Visualization Symposium, 2011. [11] Yi, J. S., Melton, R., Stasko, J. and Jacko, J. A. Dust & magnet: multivariate information visualization using a magnet metaphor. Information Visualization, 4, 4 2005), 239-256. [12] Olsen, K. A., Korfhage, R. R., Sochats, K. M., Spring, M. B. and Williams, J. G. Visualization of a document collection: the vibe system. Inf. Process. Manage., 29, 1 1993), 69-81. [13] Shipman, F. and Marshall, C. Formality Considered Harmful: Experiences, Emerging Themes, and Directions on the Use of Formal Representations in Interactive Systems. Comput. Supported Coop. Work, 8, 4 1999), 333-352. [14] Shipman, F., Hsieh, H., Airhart, R., Maloor, P., Moore, J. M. and Shah, D. Emergent Structure in Analytic Workspaces: Design and Use of the Visual Knowledge Builder. City, 2001. [15] Marshall, C. C., Frank M. Shipman, I. and Coombs, J. H. VIKI: spatial hypertext supporting emergent structure. In Proceedings of the 1994 ACM European conference on Hypermedia technology, Edinburgh, Scotland, 1994. [16] Andrews, C. Space to Think: Sensemaking and Large, High-Resolution Displays. Virginia Tech, Blacksburg, 2011. 2887ENDERT ET AL: SEMANTIC INTERACTION FOR SENSEMAKING: INFERRING ANALYTICAL REASONING FOR MODEL STEERING[17] Andrews, C., Endert, A. and North, C. Space to Think: Large, High-Resolution Displays for Sensemaking. In CHI, 2010. [18] i2 Analyst's Notebook. [19] Stasko, J., Goerg, C. and Liu, Z. Jigsaw: supporting investigative analysis through interactive visualization. Information Visualization, 7, 2 2008), 118-132. [20] Wright, W., Schroh, D., Proulx, P., Skaburskis, A. and Cort, B. The Sandbox for analysis: concepts and methods. In CHI '06, New York, NY, 2006. [21] Andrews, C. and North, C. Analyst’s Workspace: An Embodied Sensemaking Environment For Large, High-Resolution Displays. In IEEE VAST, Seattle, WA, 2012. [22] Pike, W. A., Stasko, J., Chang, R. and O'Connell, T. A. The science of interaction. Inf Visualization, 8, 4, 263-274. [23] Green, T. M., Ribarsky, W. and Fisher, B. Building and applying a human cognition model for visual analytics. Information Visualization, 8, 1 2009), 1-13. [24] Elmqvist, N., Moere, A. V., Jetter, H.-C., Cernea, D., Reiterer, H. and Jankun-Kelly, T. Fluid interaction for information visualization. Information Visualization, 10, 4 (October 1, 2011 2011), 327-340. [25] Dou, W., Jeong, D. H., Stukes, F., Ribarsky, W., Lipford, H. R. and Chang, R. Recovering Reasoning Processes from User Interactions. IEEE Computer Graphics and Applications, 292009), 52-61. [26] Fruchterman, T. M. J. and Reingold, E. M. Graph drawing by force-directed placement. Software: Practice and Experience, 21, 11 1991), 1129-1164. [27] Alias-i. 2008. LingPipe 4.0.1. City, 2008. [28] Endert, A., Han, C., Maiti, D., House, L., Leman, S. C. and North, C. Observation-level Interaction with Statistical Models for Visual Analytics. In IEEE VAST, 2011. [29] Andrews, C., Endert, A., Yost, B. and North, C. Information visualization on large, high-resolution displays: Issues, challenges, and opportunities. Information Visualization, 10, 4 (October 1 2011), 341-355. [30] Endert, A., Andrews, C., Bradel, L., Zeitz, J. and North, C. Designing Large High-Resolution Display Workspaces. City, 2012. [31] Ball, R., North, C. and A. Bowman, D. Move to improve: promoting physical navigation to increase user performance with large displays. In CHI 2007, San Jose, California, USA, 2007. [32] Shupp, L., Andrews, C., Dickey-Kurdziolek, M., Yost, B. and North, C. Shaping the Display of the Future: The Effects of Display Size and Curvature on User Performance and Insights. Human–Computer Interaction, 24, 1 2009), 230 - 272. [33] Endert, A., Fiaux, P., Chung, H., Stewart, M., Andrews, C. and North, C. ChairMouse: leveraging natural chair rotation for cursor navigation on large, high-resolution displays. In Proceedings of the 2011 annual conference extended abstracts on Human factors in computing systems, Vancouver, BC, Canada, 2011. [34] Endert, A., Fox, S., Maiti, D., Leman, S. C. and North, C. The Semantics of Clustering: Analysis of User-Generated Spatializations of Text Documents. In AVI, 2012. [35] Pak Chung, W., Hetzler, B., Posse, C., Whiting, M., Havre, S., Cramer, N., Anuj, S., Singhal, M., Turner, A. and Thomas, J. IN-SPIRE InfoVis 2004 Contest Entry, 2004. [36] Heuer, R. Psychology of Intelligence Analysis, 1999.   2888IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. 18, NO. 12, DECEMBER 2012","{""0"":{""0"":""nassau*"",""1"":""chicago*"",""2"":""endert"",""3"":""ieee*"",""4"":""user4""},""1"":{""0"":""visual*"",""1"":""visualization*"",""2"":""synthesis*"",""3"":""human"",""4"":""dimensional*""},""2"":{""0"":""document"",""1"":""resolution*"",""2"":""detail*"",""3"":""goal*"",""4"":""relationship*""},""3"":{""0"":""pinned"",""1"":""found*"",""2"":""added*"",""3"":""continued"",""4"":""emphasized*""},""4"":{""0"":""important*"",""1"":""soft*"",""2"":""large*"",""3"":""remaining*"",""4"":""successfully""},""pos"":{""0"":1,""1"":2,""2"":3,""3"":4,""4"":5}}",2012,{},False,False,journalArticle,False,R7WYTFYJ,[],self.user,"{""C"":{""0"":8.1053825407,""1"":5.4230586157,""10"":7.2110691375,""11"":4.7659471828,""12"":4.7140239512,""13"":8.3221062309,""14"":4.8823079781,""15"":7.0766667463,""16"":5.3776624337,""17"":10.6356932927,""18"":11.2874764869,""19"":5.5381527096,""2"":7.9039044794,""20"":5.0056358373,""21"":11.9444614624,""22"":8.6176795829,""23"":5.0114667594,""24"":4.6285661021,""25"":10.1873930742,""26"":10.4428651369,""27"":6.1649971561,""28"":8.3810263904,""29"":7.4481796579,""3"":14.7958328644,""30"":5.1410347043,""31"":5.8950567464,""32"":6.5274911278,""33"":10.057638484,""34"":6.1016516788,""35"":6.3715978059,""36"":6.1239448077,""37"":4.7162962471,""38"":10.2318458802,""39"":4.825844831,""4"":5.7452143576,""40"":5.6063158343,""41"":5.0284165478,""42"":5.3559303787,""43"":4.7671518485,""44"":6.4778708542,""45"":4.5894256947,""46"":4.9933098213,""47"":6.5287715281,""48"":4.8785489134,""49"":6.4685373985,""5"":7.2025477351,""50"":5.5881826375,""51"":5.6530896651,""52"":4.585039711,""53"":6.5288154081,""54"":6.4541404026,""55"":4.8879455076,""56"":5.7472352173,""57"":4.6085547739,""58"":4.4897708703,""59"":4.6666207626,""6"":7.3461648128,""60"":4.5969161246,""61"":4.474244163,""62"":4.6200847014,""63"":4.5700081177,""64"":4.6123467556,""7"":5.2693818133,""8"":17.082589142,""9"":5.3239684068},""Unnamed: 0"":{""0"":0,""1"":1,""10"":10,""11"":11,""12"":12,""13"":13,""14"":14,""15"":15,""16"":16,""17"":17,""18"":18,""19"":19,""2"":2,""20"":20,""21"":21,""22"":22,""23"":23,""24"":24,""25"":25,""26"":26,""27"":27,""28"":28,""29"":29,""3"":3,""30"":30,""31"":31,""32"":32,""33"":33,""34"":34,""35"":35,""36"":36,""37"":37,""38"":38,""39"":39,""4"":4,""40"":40,""41"":41,""42"":42,""43"":43,""44"":44,""45"":45,""46"":46,""47"":47,""48"":48,""49"":49,""5"":5,""50"":50,""51"":51,""52"":52,""53"":53,""54"":54,""55"":55,""56"":56,""57"":59,""58"":60,""59"":61,""6"":6,""60"":62,""61"":63,""62"":64,""63"":65,""64"":66,""7"":7,""8"":8,""9"":9},""count"":{""0"":250,""1"":184,""10"":50,""11"":48,""12"":48,""13"":46,""14"":42,""15"":42,""16"":40,""17"":38,""18"":28,""19"":28,""2"":172,""20"":26,""21"":26,""22"":24,""23"":24,""24"":24,""25"":24,""26"":24,""27"":22,""28"":22,""29"":22,""3"":154,""30"":20,""31"":20,""32"":18,""33"":18,""34"":16,""35"":16,""36"":16,""37"":12,""38"":12,""39"":12,""4"":116,""40"":12,""41"":12,""42"":10,""43"":10,""44"":10,""45"":8,""46"":8,""47"":8,""48"":8,""49"":8,""5"":114,""50"":8,""51"":8,""52"":8,""53"":8,""54"":8,""55"":8,""56"":8,""57"":6,""58"":6,""59"":6,""6"":92,""60"":6,""61"":6,""62"":6,""63"":6,""64"":6,""7"":74,""8"":66,""9"":54},""exemplar"":{""0"":null,""1"":null,""10"":""*"",""11"":""*"",""12"":""*"",""13"":null,""14"":""*"",""15"":null,""16"":""*"",""17"":""*"",""18"":null,""19"":""*"",""2"":null,""20"":""*"",""21"":""*"",""22"":null,""23"":""*"",""24"":""*"",""25"":null,""26"":null,""27"":null,""28"":""*"",""29"":null,""3"":null,""30"":""*"",""31"":null,""32"":null,""33"":null,""34"":null,""35"":""*"",""36"":null,""37"":null,""38"":null,""39"":null,""4"":null,""40"":null,""41"":null,""42"":""*"",""43"":""*"",""44"":null,""45"":null,""46"":""*"",""47"":null,""48"":""*"",""49"":null,""5"":null,""50"":null,""51"":null,""52"":null,""53"":""*"",""54"":null,""55"":null,""56"":null,""57"":null,""58"":""*"",""59"":null,""6"":null,""60"":null,""61"":null,""62"":null,""63"":null,""64"":""*"",""7"":null,""8"":null,""9"":null},""pos"":{""0"":1,""1"":2,""10"":1,""11"":2,""12"":1,""13"":9,""14"":2,""15"":10,""16"":2,""17"":1,""18"":11,""19"":3,""2"":3,""20"":3,""21"":2,""22"":12,""23"":2,""24"":3,""25"":13,""26"":14,""27"":3,""28"":4,""29"":15,""3"":4,""30"":3,""31"":5,""32"":16,""33"":17,""34"":4,""35"":6,""36"":4,""37"":18,""38"":19,""39"":7,""4"":5,""40"":20,""41"":21,""42"":4,""43"":5,""44"":22,""45"":23,""46"":5,""47"":24,""48"":4,""49"":25,""5"":1,""50"":26,""51"":8,""52"":5,""53"":5,""54"":6,""55"":6,""56"":9,""57"":27,""58"":7,""59"":28,""6"":6,""60"":29,""61"":30,""62"":8,""63"":31,""64"":10,""7"":7,""8"":1,""9"":8},""sigma_nor"":{""0"":1.4948334421,""1"":1.3797516461,""10"":1.9019441687,""11"":1.595681395,""12"":1.5888581575,""13"":2.0814756557,""14"":1.6435591534,""15"":1.9484860603,""16"":1.7258774456,""17"":2.5014610632,""18"":2.7922584449,""19"":1.8530181354,""2"":1.574961029,""20"":1.7855134377,""21"":2.9514054987,""22"":2.4317868636,""23"":1.8075235841,""24"":1.7412405244,""25"":2.7035163869,""26"":2.7477405732,""27"":2.0363613203,""28"":2.4323275418,""29"":2.2656439123,""3"":2.1412982369,""30"":1.8788011633,""31"":2.01816886,""32"":2.1721066301,""33"":2.8486919949,""34"":2.1277707388,""35"":2.1815686507,""36"":2.1322135652,""37"":1.9111097844,""38"":3.1115604163,""39"":1.93495286,""4"":1.4972205009,""40"":2.1048211363,""41"":1.9790422729,""42"":2.0891007949,""43"":1.9543852375,""44"":2.345806549,""45"":1.9421023041,""46"":2.0396775166,""47"":2.4106329279,""48"":2.0119521884,""49"":2.3960808384,""5"":1.6315309046,""50"":2.1833940869,""51"":2.1990751117,""52"":1.9410426851,""53"":2.410643529,""54"":2.3926026379,""55"":2.0142223313,""56"":2.2218199329,""57"":1.9657628899,""58"":1.9353475457,""59"":1.980631041,""6"":1.709120178,""60"":1.9627827426,""61"":1.9313718374,""62"":1.9687151982,""63"":1.955892783,""64"":1.9667338499,""7"":1.5537393014,""8"":2.9341991509,""9"":1.6381109862},""topic"":{""0"":-1,""1"":-1,""10"":1,""11"":1,""12"":4,""13"":-1,""14"":3,""15"":-1,""16"":4,""17"":0,""18"":-1,""19"":1,""2"":-1,""20"":4,""21"":0,""22"":-1,""23"":2,""24"":2,""25"":-1,""26"":-1,""27"":0,""28"":0,""29"":-1,""3"":-1,""30"":3,""31"":0,""32"":-1,""33"":-1,""34"":1,""35"":0,""36"":3,""37"":-1,""38"":-1,""39"":0,""4"":-1,""40"":-1,""41"":-1,""42"":2,""43"":3,""44"":-1,""45"":-1,""46"":1,""47"":-1,""48"":4,""49"":-1,""5"":2,""50"":-1,""51"":0,""52"":4,""53"":2,""54"":3,""55"":2,""56"":0,""57"":-1,""58"":3,""59"":-1,""6"":-1,""60"":-1,""61"":-1,""62"":3,""63"":-1,""64"":0,""7"":-1,""8"":3,""9"":-1},""vector"":{""0"":""[ 2.611502    5.1937394  -0.5435293  -0.8096719  -0.21347745 -0.28460723\n  3.2530892   0.28927872 -2.0021384  -3.5809774 ]"",""1"":""[ 2.6966317   5.0768466  -0.55591375 -0.64926904 -0.27011046 -0.41260654\n  3.2351098   0.34955993 -1.9668405  -3.3038912 ]"",""10"":""[ 1.2964451   5.558256   -0.7842095  -0.7525582  -1.2081876  -0.47921115\n  3.3893313  -0.11318551 -1.403276   -3.444143  ]"",""11"":""[ 1.7238922   5.4173384  -0.85440665 -0.4742012  -0.8796058  -0.38988483\n  3.5300212  -0.07248425 -1.6418992  -3.4395084 ]"",""12"":""[ 1.1895244   5.538293   -0.26206464 -0.94928116 -1.9502364  -0.9329315\n  2.6266289  -0.17361712 -1.1600225  -2.7161763 ]"",""13"":""[ 1.3898745   4.875007   -0.69895804 -0.7305262  -1.3561007  -1.1891444\n  3.1929598   0.10038217 -0.75709707 -2.6650934 ]"",""14"":""[ 0.47900814  5.8704524  -0.9246381  -0.38126874 -1.5582054  -0.27258962\n  2.7272124   0.16990352 -1.3125855  -2.5774095 ]"",""15"":""[ 1.5340188   5.4845104  -0.35773778 -0.7183181  -1.7953681  -0.95915973\n  2.6638     -0.07254532 -1.2632729  -2.5788784 ]"",""16"":""[ 1.0099802   5.2236905  -0.17429233 -1.1031922  -1.6470425  -0.77131236\n  2.9020336  -0.20518936 -0.79841477 -2.8706563 ]"",""17"":""[ 2.0858288   5.3274474  -0.73572886 -1.0001054   0.6884789   0.27632624\n  3.0580504   0.2440737  -2.5282323  -4.3804517 ]"",""18"":""[ 0.9088677   5.103294   -0.04046945 -1.1662606  -1.4599454  -0.25789583\n  2.6314428  -0.03566125 -1.1861838  -2.8633833 ]"",""19"":""[ 1.941355    5.2257676  -0.8421609  -0.05805663 -0.9167717  -0.50885874\n  3.5581446  -0.11068901 -1.5135112  -3.0073836 ]"",""2"":""[ 2.516192    4.884927   -0.80533254 -0.21479967 -0.84355587 -0.8335292\n  3.0571454   0.45979646 -1.6657047  -2.443132  ]"",""20"":""[ 1.0133544   5.21908    -0.06917197 -1.2080411  -1.7305765  -0.6111419\n  2.6602292  -0.13679698 -1.1460315  -2.8716238 ]"",""21"":""[ 2.2499206   5.3349433  -0.7066121  -0.88793397  0.5924479   0.21666326\n  3.0884821   0.18650489 -2.5462275  -4.2066455 ]"",""22"":""[ 0.97023183  5.6645417  -1.0656223  -0.51494104 -0.96131444 -0.31087697\n  3.167825    0.25787604 -1.460102   -3.1283386 ]"",""23"":""[ 2.1033282   4.797923   -0.5107632  -0.0887175  -1.2596881  -0.30884147\n  2.9294424   0.23864366 -1.7000033  -2.1029975 ]"",""24"":""[ 2.3169382   5.1781273  -0.68651354 -0.277396   -1.3249918  -0.83539194\n  2.8858635   0.26517826 -1.6831963  -2.411036  ]"",""25"":""[ 2.28964     4.547695   -0.804606   -0.57007366 -0.70741373 -1.0206417\n  3.3488655   0.39506784 -1.1804242  -2.73553   ]"",""26"":""[ 1.6625123   4.555807   -1.0093076  -0.35947973 -0.85840577 -0.7653872\n  3.303861    0.5046151  -1.2242492  -2.467678  ]"",""27"":""[ 1.6634369   5.497878   -0.6568576  -1.0663209   0.28358188  0.23843835\n  3.2384748   0.38953575 -2.2068872  -4.0941243 ]"",""28"":""[ 2.0587397   5.554323   -0.67956275 -0.94857687  0.43453655  0.22759937\n  3.21136     0.24012522 -2.5971763  -4.2070656 ]"",""29"":""[ 2.017255    5.3694606  -0.84505373 -0.46347883 -0.60409904 -0.4072326\n  3.4501584   0.05373997 -1.7588739  -3.4490523 ]"",""3"":""[ 2.7804499   4.923831   -0.3163523  -0.5983131  -0.62926745 -0.4275239\n  3.0850985   0.29221988 -1.8478445  -2.893042  ]"",""30"":""[ 0.5068236   5.9013495  -0.868508   -0.33253288 -1.7037381  -0.44467214\n  2.5889192   0.16678701 -1.1616001  -2.3732982 ]"",""31"":""[ 2.4776642   5.3236012  -0.5154863  -0.7206871  -0.03093854 -0.04134142\n  3.2611644   0.33801472 -2.2612097  -3.5931003 ]"",""32"":""[ 0.7775268   5.4667125  -1.0704237  -0.633092   -1.2979157  -0.4125251\n  3.0799642   0.27076164 -1.5551895  -3.0328774 ]"",""33"":""[ 1.2563918   4.6372046  -0.9612645  -0.628824   -1.0221678  -1.0439738\n  3.3398104   0.34094185 -0.8027875  -2.654146  ]"",""34"":""[ 1.6039726   5.2359524  -0.33170375 -0.9916047  -1.1997389  -0.6364462\n  3.2415688  -0.18512529 -1.1663843  -3.2691934 ]"",""35"":""[ 2.0993216   5.47212    -0.6612834  -1.0557778   0.5804087   0.24905665\n  3.2268505   0.40949264 -2.4202745  -4.431034  ]"",""36"":""[ 0.63482994  5.65507    -0.40065238 -0.71452075 -1.8745023  -0.49234128\n  2.4988182  -0.03543504 -1.0938696  -2.4694593 ]"",""37"":""[ 1.3477583e+00  5.5386224e+00 -6.6130590e-01 -9.2197239e-01\n -1.0563408e+00 -4.8929965e-01  3.1657314e+00 -3.1993785e-03\n -1.6311606e+00 -3.4864793e+00]"",""38"":""[ 2.3436868   4.490951   -0.76013637 -0.44057727 -0.54561347 -0.7214916\n  3.3959212   0.34998015 -1.3289013  -2.7828817 ]"",""39"":""[ 2.3292303   5.243677   -0.6833872  -0.85760367  0.48232293  0.14635618\n  3.0728784   0.19517583 -2.4375598  -4.1152973 ]"",""4"":""[ 2.3734162   5.089402   -0.86607087 -0.33672974 -1.0977694  -0.9919033\n  3.082596    0.32465369 -1.6627198  -2.650492  ]"",""40"":""[ 1.0475174   5.219462   -0.54396707 -0.83923596 -1.700807   -1.0766939\n  2.9011176  -0.01490084 -0.8272464  -2.6377335 ]"",""41"":""[ 2.6392236   5.0528793  -0.46349278 -0.3877686  -0.8728361  -0.43365544\n  3.0947468   0.1349695  -1.7728817  -2.8219006 ]"",""42"":""[ 1.9084104   4.7969494  -0.31947267 -0.20328964 -1.0559838  -0.1097038\n  2.9530044   0.15273282 -1.5485384  -2.2573946 ]"",""43"":""[ 0.5657301   5.835033   -0.6815426  -0.5087203  -1.8460301  -0.535629\n  2.5441942   0.05133189 -1.1473174  -2.4303977 ]"",""44"":""[ 2.3036091   4.8831735  -0.5769823   0.231557   -0.77166337 -0.34579855\n  3.134637    0.13587777 -1.6415757  -2.3053777 ]"",""45"":""[ 1.2872716   5.303731   -0.22555608 -1.157594   -1.591313   -0.6473268\n  2.8925982  -0.15959355 -1.3438212  -3.12911   ]"",""46"":""[ 1.5628201   5.3223844  -0.58222455 -0.9055238  -1.1420498  -0.60116124\n  3.4341028  -0.18063883 -1.3388218  -3.4836893 ]"",""47"":""[ 1.4628471   4.5420666  -1.036231   -0.48303622 -0.88471895 -0.91623896\n  3.355205    0.46741343 -1.0007472  -2.5633752 ]"",""48"":""[ 0.8939254   5.2665796  -0.14243585 -0.9496358  -1.583015   -0.45988908\n  2.7327127  -0.11096705 -0.9293998  -2.6882365 ]"",""49"":""[ 2.5454836   5.1895337  -0.4045627  -0.69238776 -0.3514347  -0.06482948\n  3.091537    0.18423498 -2.0936828  -3.3537083 ]"",""5"":""[ 2.082323    5.1792564  -0.8252798  -0.17756419 -1.0517173  -0.48089838\n  2.8428507   0.5198054  -1.8405461  -2.279484  ]"",""50"":""[ 2.1896884   5.122964   -0.6648186   0.20408753 -0.7831129  -0.5564237\n  3.3035822  -0.03383338 -1.4695231  -2.585568  ]"",""51"":""[ 2.0686314   5.59986    -0.642758   -0.99283123  0.4279104   0.22962163\n  3.318792    0.39060512 -2.4947133  -4.2851396 ]"",""52"":""[ 0.97648036  5.161784   -0.22539057 -0.80288506 -1.5577457  -0.21743019\n  2.6817253   0.02377874 -1.2607938  -2.549068  ]"",""53"":""[ 2.154891    5.132285   -0.28968433 -0.2824589  -1.1937718  -0.33824575\n  2.9253516   0.03952648 -1.5819546  -2.4356804 ]"",""54"":""[ 0.79550064  5.914394   -0.9896321  -0.13493308 -1.3467547  -0.18101743\n  2.7872486   0.22571494 -1.429447   -2.5050578 ]"",""55"":""[ 2.2847378   4.7334604  -0.6166312   0.11709322 -1.0599376  -0.3848517\n  3.0467088   0.24652238 -1.6904855  -2.1324968 ]"",""56"":""[ 1.728643    5.5697203  -0.71074265 -0.96989393  0.09403516  0.1095989\n  3.34752     0.35413387 -2.1398733  -4.122176  ]"",""57"":""[ 1.917142    4.8407073  -0.6932229  -0.39652258 -1.1200252  -0.28891852\n  3.3380783   0.13034673 -1.5830384  -2.7786965 ]"",""58"":""[ 0.8313321   5.871275   -0.9006283  -0.34008622 -1.4351385  -0.40215588\n  2.8396528   0.09748306 -1.3639541  -2.6767318 ]"",""59"":""[ 2.161512    4.6930213  -0.8462909  -0.44460532 -0.65515184 -0.9602369\n  3.4878638   0.24291322 -1.1446934  -2.8894095 ]"",""6"":""[ 1.6755259   4.745654   -0.7466247  -0.15255183 -1.1265415  -0.11388794\n  3.20523     0.28273675 -1.6351814  -2.3706293 ]"",""60"":""[ 1.9076563   5.2938256  -0.36418313 -0.4162012  -1.4918369  -0.7800598\n  2.8391569  -0.04413002 -1.2822189  -2.4495668 ]"",""61"":""[ 1.0341923   4.839455   -0.8947366  -0.6423226  -1.2242264  -0.93190384\n  3.2015407   0.26734814 -0.82693344 -2.614987  ]"",""62"":""[ 0.5887311   5.463966   -0.8210708  -0.6913286  -1.3826656  -0.29813844\n  2.9216342   0.19687533 -1.2978388  -2.8484428 ]"",""63"":""[ 1.4997467   5.2123227  -0.10643597 -0.7397395  -1.4366308  -0.50837165\n  2.9074714  -0.1935016  -1.0471584  -2.6871703 ]"",""64"":""[ 2.0090137   5.3719206  -0.6840725  -0.9869648   0.41904274  0.1996432\n  3.2385929   0.41539183 -2.3022172  -4.2906866 ]"",""7"":""[ 2.496613    5.138979   -0.23287891 -0.49714968 -0.68621147 -0.10797933\n  2.928004    0.19110109 -2.0106797  -2.8131855 ]"",""8"":""[ 0.33762044  5.5893493  -0.8463907  -0.5713872  -1.6253428  -0.46255648\n  2.7509022   0.17537224 -1.0292401  -2.5276828 ]"",""9"":""[ 1.10535     5.8506117  -1.0390836  -0.18902415 -1.0781091  -0.25001743\n  2.9933865   0.23531264 -1.5058511  -2.7699697 ]""},""vocab_index"":{""0"":0,""1"":1,""10"":27,""11"":30,""12"":32,""13"":33,""14"":38,""15"":39,""16"":40,""17"":43,""18"":51,""19"":53,""2"":2,""20"":61,""21"":69,""22"":70,""23"":72,""24"":73,""25"":75,""26"":76,""27"":77,""28"":78,""29"":79,""3"":5,""30"":90,""31"":91,""32"":100,""33"":101,""34"":102,""35"":115,""36"":118,""37"":148,""38"":182,""39"":184,""4"":7,""40"":185,""41"":186,""42"":197,""43"":222,""44"":227,""45"":232,""46"":239,""47"":250,""48"":257,""49"":276,""5"":8,""50"":291,""51"":292,""52"":299,""53"":302,""54"":303,""55"":304,""56"":305,""57"":346,""58"":361,""59"":393,""6"":11,""60"":394,""61"":396,""62"":402,""63"":405,""64"":407,""7"":14,""8"":20,""9"":26},""word"":{""0"":""user"",""1"":""users"",""10"":""visual"",""11"":""visualization"",""12"":""important"",""13"":""weight"",""14"":""found"",""15"":""relevant"",""16"":""soft"",""17"":""nassau"",""18"":""north"",""19"":""synthesis"",""2"":""documents"",""20"":""large"",""21"":""chicago"",""22"":""foraging"",""23"":""resolution"",""24"":""detail"",""25"":""weapons"",""26"":""package"",""27"":""endert"",""28"":""ieee"",""29"":""analytics"",""3"":""entities"",""30"":""added"",""31"":""user4"",""32"":""reading"",""33"":""junk"",""34"":""human"",""35"":""andrews"",""36"":""continued"",""37"":""interactive"",""38"":""diamonds"",""39"":""russia"",""4"":""information"",""40"":""weighted"",""41"":""semantics"",""42"":""goal"",""43"":""emphasized"",""44"":""conference"",""45"":""complex"",""46"":""dimensional"",""47"":""mail"",""48"":""remaining"",""49"":""node"",""5"":""document"",""50"":""scholarship"",""51"":""hanif"",""52"":""successfully"",""53"":""relationship"",""54"":""undo"",""55"":""proceedings"",""56"":""stasko"",""57"":""flow"",""58"":""hypothesize"",""59"":""antibiotics"",""6"":""process"",""60"":""relevance"",""61"":""pile"",""62"":""capturing"",""63"":""potential"",""64"":""shipman"",""7"":""entity"",""8"":""pinned"",""9"":""search""},""word*"":{""0"":""user"",""1"":""users"",""10"":""visual*"",""11"":""visualization*"",""12"":""important*"",""13"":""weight"",""14"":""found*"",""15"":""relevant"",""16"":""soft*"",""17"":""nassau*"",""18"":""north"",""19"":""synthesis*"",""2"":""documents"",""20"":""large*"",""21"":""chicago*"",""22"":""foraging"",""23"":""resolution*"",""24"":""detail*"",""25"":""weapons"",""26"":""package"",""27"":""endert"",""28"":""ieee*"",""29"":""analytics"",""3"":""entities"",""30"":""added*"",""31"":""user4"",""32"":""reading"",""33"":""junk"",""34"":""human"",""35"":""andrews*"",""36"":""continued"",""37"":""interactive"",""38"":""diamonds"",""39"":""russia"",""4"":""information"",""40"":""weighted"",""41"":""semantics"",""42"":""goal*"",""43"":""emphasized*"",""44"":""conference"",""45"":""complex"",""46"":""dimensional*"",""47"":""mail"",""48"":""remaining*"",""49"":""node"",""5"":""document"",""50"":""scholarship"",""51"":""hanif"",""52"":""successfully"",""53"":""relationship*"",""54"":""undo"",""55"":""proceedings"",""56"":""stasko"",""57"":""flow"",""58"":""hypothesize*"",""59"":""antibiotics"",""6"":""process"",""60"":""relevance"",""61"":""pile"",""62"":""capturing"",""63"":""potential"",""64"":""shipman*"",""7"":""entity"",""8"":""pinned"",""9"":""search""},""x2D"":{""0"":-6.8074846268,""1"":-6.5695881844,""10"":-2.7355585098,""11"":-3.3151931763,""12"":-0.5539784431,""13"":-2.3688743114,""14"":-1.4220371246,""15"":-1.1516817808,""16"":-0.8898800015,""17"":-9.2730503082,""18"":-0.6495994329,""19"":-4.1632089615,""2"":-5.1775507927,""20"":-0.6773399711,""21"":-8.7782335281,""22"":-2.2397527695,""23"":-4.9804477692,""24"":-5.3857159615,""25"":-4.203476429,""26"":-3.6750321388,""27"":-8.4484786987,""28"":-8.8047380447,""29"":-3.9586398602,""3"":-6.1159610748,""30"":-1.2633625269,""31"":-7.1986522675,""32"":-1.9826514721,""33"":-2.9140925407,""34"":-2.2279682159,""35"":-8.9966630936,""36"":-0.8339632154,""37"":-2.7176094055,""38"":-4.2552261353,""39"":-8.6036748886,""4"":-5.0621109009,""40"":-0.7660641074,""41"":-5.6459245682,""42"":-4.8249230385,""43"":-1.0040552616,""44"":-5.1396708488,""45"":-1.2080322504,""46"":-2.675565958,""47"":-3.3151278496,""48"":-0.919862926,""49"":-6.6681785583,""5"":-5.4156150818,""50"":-4.6494050026,""51"":-8.6237163544,""52"":-0.7064415812,""53"":-5.0754265785,""54"":-1.7984437943,""55"":-4.93232584,""56"":-8.239979744,""57"":-4.3764128685,""58"":-1.6666402817,""59"":-3.9626727104,""6"":-4.5197291374,""60"":-1.5542616844,""61"":-2.7055892944,""62"":-1.4519121647,""63"":-1.3625999689,""64"":-8.786239624,""7"":-6.0710391998,""8"":-1.1051362753,""9"":-2.0780773163},""y2D"":{""0"":1.735419631,""1"":2.0546059608,""10"":1.5178469419,""11"":1.8686164618,""12"":2.5816137791,""13"":3.3629126549,""14"":0.4856803715,""15"":2.8037590981,""16"":2.512493372,""17"":1.1102153063,""18"":1.8866935968,""19"":2.6841888428,""2"":3.3621840477,""20"":2.2370700836,""21"":1.2338806391,""22"":0.9582708478,""23"":4.0841803551,""24"":3.6082584858,""25"":3.5571801662,""26"":3.719325304,""27"":1.7163470984,""28"":1.0456413031,""29"":2.1268012524,""3"":2.5632457733,""30"":0.2015504241,""31"":1.752250433,""32"":1.0167653561,""33"":3.6752171516,""34"":2.1067433357,""35"":1.4630565643,""36"":1.0040867329,""37"":1.5705631971,""38"":3.3939609528,""39"":1.2733776569,""4"":3.4944672585,""40"":2.8984427452,""41"":2.968537569,""42"":4.350581646,""43"":0.6064438224,""44"":4.1178269386,""45"":2.2001657486,""46"":1.8324794769,""47"":3.6135063171,""48"":2.0269124508,""49"":1.9889134169,""5"":4.0314002037,""50"":3.2036600113,""51"":1.4111449718,""52"":1.7423871756,""53"":4.3430905342,""54"":0.4531179667,""55"":4.0130000114,""56"":1.3964802027,""57"":4.0042829514,""58"":0.5691952109,""59"":3.2494902611,""6"":4.4169545174,""60"":3.034709692,""61"":3.4655580521,""62"":0.8998485208,""63"":2.4971673489,""64"":1.6593462229,""7"":2.4802019596,""8"":0.4012015462,""9"":0.5973983407}}",False,False,False,http://ieeexplore.ieee.org/document/6327294/,,Semantic Interaction for Sensemaking: Inferring Analytical Reasoning for Model Steering,"[-4.87544835e-01 -7.99826831e-02 -3.17214042e-01 -4.01762575e-02
  4.14838612e-01 -2.42438796e-03 -8.31315964e-02 -3.55648309e-01
  1.41896382e-01 -3.08914363e-01  7.21525922e-02 -2.39908487e-01
  5.89595884e-02 -4.72208709e-02 -2.08923638e-01  7.70704746e-01
 -6.49967045e-02 -9.70836356e-02 -2.08258539e-01 -2.68303216e-01
 -4.98274006e-02 -2.97971219e-02 -7.88964853e-02  5.74422300e-01
  3.26296985e-01  2.02504486e-01  2.03816146e-01  1.69560209e-01
 -4.70598459e-01  2.38370553e-01  1.02496147e-01  6.43342197e-01
 -5.74367344e-02 -4.91475075e-01 -4.09239084e-01  2.22277433e-01
 -4.64924037e-01 -1.83697447e-01  3.50137092e-02  6.91815019e-01
 -4.01351750e-01 -4.38658036e-02 -3.18928123e-01 -2.62060374e-01
  2.10964397e-01 -1.78635195e-01 -2.62373418e-01 -2.45955318e-01
  5.92247099e-02 -4.91982341e-01 -1.32169342e+00 -5.14249094e-02
 -1.55147851e-01 -4.12622809e-01 -1.15701027e-01  5.26126385e-01
 -1.09520525e-01 -8.57015967e-01  5.91439307e-01  2.51115441e-01
 -2.50964820e-01 -1.34633154e-01  1.49858057e-01 -7.14323446e-02
  3.41778725e-01 -1.93915799e-01  1.70592859e-01 -3.31368297e-01
 -5.10092795e-01  4.33803648e-01 -1.58542186e-01  3.14418525e-01
 -3.44279140e-01  2.79309869e-01 -7.20196664e-01 -5.80447167e-02
 -1.44880980e-01  3.30201119e-01 -1.31193176e-01 -3.75152342e-02
 -5.04553556e-01  6.00904748e-02  3.34542990e-02 -2.42717385e-01
  5.96461058e-01  8.85850668e-01  1.08046949e-01  5.18612385e-01
 -1.94627509e-01  1.19483501e-01 -5.34612179e-01 -1.38872504e-01
 -3.93652827e-01  3.54370415e-01  8.72789919e-01 -1.54510066e-01
  3.75527777e-02  1.66944414e-01 -2.05701262e-01  1.93057925e-01
  7.74490416e-01 -7.45838642e-01  1.57442912e-01 -4.45294753e-02
 -8.82431865e-02 -2.11982101e-01 -3.98736238e-01 -5.79182804e-01
 -3.65416229e-01 -3.23385670e-04  8.84278864e-02  6.01474419e-02
  2.07165316e-01 -3.88526052e-01 -1.05730236e-01 -5.92105687e-02
  2.53398772e-02  4.96266216e-01  6.21031336e-02  1.90192044e-01
 -3.93065095e-01  1.71647772e-01  7.92590529e-03  4.18127745e-01
  3.95143498e-03  2.25357726e-01 -9.40805897e-02  2.11118951e-01
  4.67312843e-01  1.54193223e-01  5.27089953e-01  1.66980490e-01
  2.13249266e-01  4.83140387e-02 -4.76687014e-01  3.94890189e-01
 -2.84828525e-02  1.42826304e-01 -2.16122195e-02  2.14751855e-01
 -5.29641509e-01 -5.06774187e-01  5.88255227e-01 -1.31683514e-01
  3.27029139e-01 -1.59023851e-01 -1.48071438e-01  3.15174043e-01
  2.79514696e-02  2.61055410e-01 -2.73934543e-01  4.40639943e-01
 -7.58463442e-01 -3.88412178e-02  6.78820089e-02  5.78609705e-01
 -5.00411928e-01  2.64143080e-01  1.30032944e-02  8.46655741e-02
 -1.10282078e-01 -7.78184384e-02 -4.30489451e-01  8.10189843e-02
  1.01795822e-01 -2.31013760e-01  1.19368136e-01  4.82188582e-01
  1.38659805e-01 -1.53266460e-01  2.42183089e-01 -3.58320683e-01
  1.75944045e-01 -8.68949592e-02  4.81104016e-01  3.25988419e-02
 -4.50065508e-02  1.04620196e-02  2.45157301e-01  1.00051296e+00
 -5.68430603e-01  8.07637572e-02  2.69537698e-03 -3.66822094e-01
  5.77312946e-01 -6.35321960e-02  2.69336939e-01 -5.65017521e-01
  1.75295353e-01  1.63893282e-01 -2.48655602e-01 -3.00596863e-01
 -1.81128178e-03 -3.90291214e-01  2.59504288e-01 -4.06283826e-01
  7.09071830e-02  2.01131567e-01 -4.31464389e-02 -3.08660328e-01
 -2.61213511e-01 -2.09392413e-01  1.12309262e-01  3.21496874e-01
  1.33210853e-01 -1.41181216e-01 -2.56622434e-01 -6.27066910e-01
 -8.59917521e-01 -1.02635480e-01 -3.29317391e-01  4.26016897e-01
 -1.35205895e-01  1.43993706e-01  3.68570060e-01 -1.25695527e-01
  1.53192490e-01  4.30925131e-01 -1.57434613e-01  5.72811216e-02
  3.84271026e-01 -4.15652692e-01 -8.14535916e-02  4.19944912e-01
 -3.86461407e-01  1.39270544e+00  3.20227653e-01  1.36889398e-01
  6.58046901e-01  6.89344527e-03 -7.18858168e-02  1.14450846e-02
  5.79119682e-01 -5.31779945e-01  1.00639276e-01  2.88774401e-01
 -1.59395784e-01 -1.94327831e-01  2.29087174e-01 -3.33042517e-02
 -3.09318691e-01  1.07380927e-01  2.01114982e-01  3.90976548e-01
 -1.92052543e-01 -1.02797180e-01  3.28699648e-01  4.48785335e-01
 -2.80192882e-01  1.62962317e-01 -3.27136755e-01  1.22007124e-01
 -5.05797446e-01 -3.44482034e-01 -2.22127512e-01 -6.21346682e-02
 -2.32131779e-01 -2.59430408e-01 -2.44491905e-01  1.34842753e-01
  8.02903116e-01  2.21402705e-01  5.82245700e-02  1.85846135e-01
  2.50058949e-01 -6.25610828e-01  9.27397050e-03 -1.78470403e-01
  1.00570631e+00  5.32446504e-01  1.08118668e-01 -6.04415238e-01
  1.65397629e-01  5.74534595e-01 -2.81143636e-01 -2.07197100e-01
  1.21958898e-02 -3.66432458e-01 -3.33332568e-01 -2.20585272e-01
 -2.08777502e-01  1.69417709e-02 -2.06327394e-01  2.51053959e-01
 -3.59156162e-01 -1.86647791e-02  8.47691447e-02  1.97012514e-01
  1.92158014e-01 -3.36342663e-01 -2.42530257e-01  1.55969799e-01
 -3.37223053e-01 -3.08146149e-01  2.20359609e-01  3.91628027e-01
  7.23654218e-03 -4.92031276e-02 -4.29670483e-01 -1.31581530e-01
 -1.95750639e-01 -3.72218825e-02  4.23564196e-01  5.69093861e-02
  1.24739140e-01  1.84660479e-01 -1.55754834e-01 -3.79951209e-01
 -8.91462612e+00 -7.59489611e-02 -1.74173653e-01  1.67104796e-01
  1.11171648e-01  2.00853139e-01  1.61322311e-01 -1.30565673e-01
 -1.75705850e-01  9.21979174e-02 -2.25127220e-01 -1.30144954e-01
 -5.69463193e-01  3.68662775e-02  1.55984297e-01 -3.52756053e-01
 -1.62966654e-01  1.78219005e-02  1.19698912e-01  4.34468716e-01
 -1.63185194e-01 -4.52207685e-01 -3.08302373e-01 -1.05688021e-01
 -1.90443650e-01 -4.07271922e-01 -3.26459080e-01  5.61675727e-01
 -3.51209223e-01 -3.80762190e-01 -1.73015743e-01 -4.91880387e-01
 -2.41936386e-01  8.40288937e-01  7.92145506e-02 -2.01824248e-01
 -8.44471827e-02  2.04699978e-01  6.69184208e-01  3.17996331e-02
 -5.25374115e-02  3.53203192e-02 -2.59288996e-02 -5.06999791e-02
  7.59884477e-01 -3.04787904e-01  2.31425479e-01  2.01064453e-01
 -3.28659505e-01 -7.30572194e-02 -2.93668080e-02 -9.25285071e-02
  3.05019468e-01 -1.41805232e-01  1.25672117e-01 -7.89612114e-01
  6.07549906e-01  9.90563482e-02 -2.18382403e-01 -2.60644853e-01
  5.75121701e-01 -2.65297234e-01 -1.22518510e-01 -1.23025239e-01
  9.80928615e-02  2.02440947e-01 -1.01205981e+00 -9.22919035e-01
 -1.75587252e-01 -1.87343746e-01 -1.98807836e-01  5.71920574e-01
 -1.31036878e-01 -1.36805248e+00 -4.64249015e-01 -1.77436143e-01
  2.17646480e-01 -2.69544482e-01 -2.84710556e-01 -1.88589767e-01
 -5.79746485e-01 -3.69368017e-01  1.02135547e-01 -3.27223063e-01
 -2.68613815e-01  2.44517878e-01 -3.19314927e-01 -9.41081420e-02
 -7.61972189e-01  3.76721114e-01 -2.15971544e-01  7.10013449e-01
  3.37200522e-01  5.15853822e-01  3.87477912e-02  7.97769576e-02
  7.39947915e-01 -7.14701340e-02  2.18624771e-01  2.98321724e-01
 -1.44879490e-01 -2.97797859e-01  1.03657745e-01  1.24158310e-02
 -1.03489831e-01  3.38431269e-01 -5.43944597e-01 -1.71358451e-01
  4.81575876e-01  1.73978880e-01 -2.05913454e-01  5.53941548e-01
 -2.46448419e-03 -2.98092123e-02 -2.26643488e-01  2.69169807e-01
 -2.54023045e-01  1.57741055e-01  5.48855700e-02 -1.02302037e-01
 -3.27285737e-01  1.19019516e-01 -2.33167037e-01  4.71766628e-02
  9.13008034e-01  6.43974245e-02  1.20455943e-01  3.53826642e-01
 -2.81769067e-01 -1.77859038e-01  2.20165953e-01 -3.69338334e-01
  2.41233677e-01  2.66564935e-01  4.27580059e-01 -3.95510674e-01
 -1.83655858e-01 -3.16708922e-01 -7.59565949e-01  8.79790559e-02
  7.90004373e-01  2.12967947e-01  4.45243001e-01 -3.68148118e-01
 -2.62944579e-01 -1.64384156e-01 -1.71901986e-01  7.53992051e-02
 -3.56763452e-01  4.95970637e-01 -2.29252160e-01 -8.55254292e-01
 -1.54488519e-01  1.03290148e-01  4.85007524e-01  3.08012456e-01
  2.06909835e-01 -5.08378923e-01  5.73685467e-02 -5.45526266e-01
  6.97399452e-02  3.07133764e-01  8.43374729e-02 -6.14976510e-02
 -2.80063540e-01  3.70798670e-02 -1.12239227e-01 -5.11010550e-02
  1.18039943e-01 -4.33714151e-01 -2.48741627e-01 -1.88634440e-01
  5.56758821e-01 -3.56550902e-01  7.97348022e-02 -1.20138340e-01
  3.05127054e-01  2.35355392e-01 -5.01955628e-01  4.30328727e-01
  1.01130508e-01  3.33674438e-02 -2.25204483e-01  3.08374643e-01
  3.68936688e-01  1.66331246e-01  6.03178501e-01 -9.98695940e-02
  9.70188677e-02  1.23891585e-01 -5.05594850e-01  2.36681864e-01
 -7.26593658e-02 -4.00794685e-01 -3.33852679e-01 -3.11505169e-01
  2.19578892e-01 -4.30432200e-01 -1.61602478e-02  2.35413536e-01
 -2.59029210e-01 -2.00249732e-01 -1.98503062e-01  2.62115210e-01
 -2.50211924e-01 -1.57585666e-01  2.51078662e-02  2.31917515e-01
 -5.33546388e-01 -2.36053243e-01 -2.35519454e-01 -1.82146117e-01
  1.14738852e-01 -4.15978521e-01  1.34749606e-01 -2.42818490e-01
 -8.81502703e-02 -2.94788659e-01 -8.90771329e-01  4.98766065e-01
 -1.89996913e-01 -2.39754263e-02  1.85658395e-01  1.45449430e-01
  5.72711788e-02 -1.12429582e-01  2.26984933e-01  3.76025587e-02
 -6.08155727e-01  4.62231904e-01 -2.20811278e-01 -1.66360307e+00
 -1.85314994e-02 -1.52804434e-01 -8.71063620e-02 -5.07640660e-01
 -6.79164827e-01  2.18817726e-01  1.27787873e-01 -5.67205787e-01
  2.67409831e-01 -2.15156630e-01 -1.17366187e-01 -3.74429747e-02
 -1.84640601e-01 -3.36201698e-01 -1.24924831e-01 -1.95180088e-01
 -9.02632028e-02 -1.48316562e-01  3.94452643e-03 -1.64620783e-02
 -6.61326349e-02 -4.30201560e-01  3.73800844e-01 -4.27291021e-02
 -3.61528307e-01 -5.53185701e-01 -2.07224786e-01  3.37882489e-01
 -4.70186114e-01 -3.56686562e-01  5.38261086e-02  4.93399262e-01
 -3.49902689e-01 -3.40953857e-01  2.15072349e-01 -2.68179387e-01
  1.85207114e-01 -6.26360625e-02  5.01557961e-02 -3.71783286e-01
 -1.77107662e-01  3.40138614e-01 -4.74961996e-01 -2.36975819e-01
  1.18257001e-01  1.62333250e-02  6.25216141e-02 -3.10229182e-01
  5.88861369e-02 -2.37675756e-01  4.31460410e-01  4.17030156e-01
  3.64437401e-01 -8.95603560e-03  7.95146450e-04  1.60588145e-01
  4.35948186e-02  1.35383666e-01 -4.67821071e-03 -5.68231493e-02
 -3.35826427e-01  2.48959929e-01 -1.04191802e-01  6.63976431e-01
  7.65436888e-01  3.77728075e-01 -1.09895296e-01  5.45268953e-01
  4.63193320e-02  6.22232378e-01  3.15642029e-01  8.81223679e-02
  4.60230233e-03 -1.29653309e-02 -1.94160998e-01 -4.82533097e-01
  1.20723031e-01 -5.39635062e-01 -9.21083838e-02 -1.04886949e-01
  5.27757883e-01 -2.25072335e-02 -1.55742422e-01 -1.77896351e-01
 -3.82439971e-01 -1.33033559e-01  3.02146047e-01  2.72485763e-01
 -3.63949269e-01  3.69078130e-01  8.14926624e-01 -4.42321777e-01
 -1.17533714e-01  3.44985723e-01 -4.78228508e-03 -3.25308770e-01
 -4.13391382e-01  6.75103009e-01  3.13462876e-02  4.58080828e-01
 -1.66277587e-01  4.31079902e-02  3.32842559e-01  2.43205547e-01
  3.80058676e-01 -3.00427433e-02 -8.39461479e-03  3.29376936e-01
  3.06108981e-01  3.54431301e-01  3.03025357e-02  1.89773098e-01
 -1.80388361e-01 -3.49488974e-01  2.18676478e-01  6.78278804e-01
 -5.56164095e-03  5.05264550e-02  1.33451685e-01  7.28638917e-02
  3.24704319e-01 -1.28837347e-01  3.48950401e-02 -1.03182971e-01
  1.83677867e-01 -1.76162243e-01 -2.85481572e-01  7.77369976e-01
 -2.35373564e-02  1.01238921e-01  5.51272072e-02 -8.15050721e-01
 -2.36330777e-02 -4.68490683e-02  5.68381011e-01  1.07329540e-01
  7.46327877e-01 -9.55192372e-02  3.68278138e-02  4.88973469e-01
 -1.38450548e-01 -2.80855060e-01  3.23171645e-01  1.22202985e-01
  1.45468146e-01 -4.15446311e-01 -2.73733377e-01 -8.76414105e-02
 -1.23165749e-01 -4.78689313e-01 -3.29315484e-01 -2.35893533e-01
 -6.34240091e-01 -2.20416844e-01 -3.66923213e-01  2.87461758e-01
  3.57645899e-01 -1.45542532e-01 -4.72796023e-01  2.42480934e-01
  4.91182446e-01 -4.57687736e-01 -3.68701786e-01  4.07036781e-01
  2.27166384e-01  1.03615284e-01  2.49707699e-01 -2.18463555e-01
 -6.58954084e-02 -9.89791006e-02  4.18518633e-02  2.53257453e-01
 -2.53103107e-01 -1.52185299e-02 -8.59350711e-02  2.43517891e-01
 -6.98302746e-01 -4.00819063e-01  3.89401853e-01  2.87683994e-01
 -1.45773351e-01  3.57371986e-01  1.66876048e-01  1.92135215e-01
  1.04701087e-01 -1.38001859e-01  8.57732520e-02  2.48537473e-02
 -4.49858010e-02 -2.99965382e-01  6.92952275e-01 -2.81848282e-01
 -5.31501472e-02  5.11205316e-01 -1.78187549e-01 -5.71935534e-01
 -3.33500542e-02 -1.69503689e-01  4.57295805e-01  2.23109528e-01
 -4.54703510e-01  1.76884100e-01  3.21769454e-02  1.15665235e-02
 -3.99723768e-01  7.14153796e-02 -2.29028508e-01 -1.81143567e-01
 -4.82259661e-01  2.82848150e-01 -1.98295370e-01 -1.68706477e-01
 -6.72153756e-02  5.31466603e-01 -1.26254484e-01 -3.69851470e-01
  1.72242876e-02 -6.09251082e-01 -3.63646924e-01 -4.32791263e-01
 -5.89551270e-01 -2.62857825e-01 -2.79795360e-02  3.81494522e-01
 -4.43190187e-02 -2.66254902e-01 -1.39193714e-01  1.39048293e-01]",R7WYTFYJ,False,False,"[8.087623596191406, 0.19884444773197174]"
VUUD5TST,ZIKGJ2ND,"See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/220506453

IPCA: An interactive system for PCA-based visual analytics

Article  in  Computer Graphics Forum · June 2009

DOI: 10.1111/j.1467-8659.2009.01475.x · Source: DBLP

CITATIONS
105

5 authors, including:

Dong Hyun Jeong
University of the District of Columbia

48 PUBLICATIONS   530 CITATIONS   

SEE PROFILE

Some of the authors of this publication are also working on these related projects:

Data Analysis View project

HOT Admin Security Project View project

READS
657

Brian David Fisher
Simon Fraser University

116 PUBLICATIONS   1,326 CITATIONS   

SEE PROFILE

All content following this page was uploaded by Brian David Fisher on 15 October 2017.

The user has requested enhancement of the downloaded file.

Eurographics/ IEEE-VGTC Symposium on Visualization 2009
H.-C. Hege, I. Hotz, and T. Munzner
(Guest Editors)

Volume 28 (2009), Number 3

iPCA: An Interactive System for PCA-based Visual Analytics

Dong Hyun Jeong1, Caroline Ziemkiewicz1, Brian Fisher2, William Ribarsky1, and Remco Chang1

1Charlotte Visualization Center & UNC Charlotte, USA

2School of Interactive Arts+Technology& Simon Fraser University, USA

Abstract

Principle Component Analysis (PCA) is a widely used mathematical technique in many ﬁelds for factor and trend
analysis, dimension reduction, etc. However, it is often considered to be a “black box” operation whose results are
difﬁcult to interpret and sometimes counter-intuitive to the user. In order to assist the user in better understanding
and utilizing PCA, we have developed a system that visualizes the results of principal component analysis using
multiple coordinated views and a rich set of user interactions. Our design philosophy is to support analysis of
multivariate datasets through extensive interaction with the PCA output. To demonstrate the usefulness of our
system, we performed a comparative user study with a known commercial system, SAS/INSIGHT’s Interactive
Data Exploration. Participants in our study solved a number of high-level analysis tasks with each interface and
rated the systems on ease of learning and usefulness. Based on the participants’ accuracy, speed, and qualitative
feedback, we observe that our system helps users to better understand relationships between the data and the
calculated eigenspace, which allows the participants to more accurately analyze the data. User feedback suggests
that the interactivity and transparency of our system are the key strengths of our approach.

Categories and Subject Descriptors (according to ACM CCS): User Interfaces [H.5.2]: Interaction styles (e.g., com-
mands, menus, forms, direct manipulation)—Methodology and Techniques [I.3.6]: Interaction techniques—

1. Introduction
Principle Component Analysis (PCA) is a widely used math-
ematical technique for high dimension data analysis. Just
within the ﬁelds of computer graphics and visualization
alone, PCA has been used in many different research ar-
eas [Jol02]. At its core, PCA is a method that projects a
dataset to a new coordinate system by determining the eigen-
vectors and eigenvalues of a matrix (Figure 1). This method
ﬁnds the factors which explain the most variation among
data points.

Although PCA is a powerful technique capable of re-
ducing dimensions and revealing relationships among data
items, it has traditionally been viewed as a “black box” ap-
proach that is difﬁcult to grasp for many of its users [Jol02,
Shl05]. The process and result of the coordinate transform
from original data space into eigenspace in PCA makes it
challenging for the end user to identify the relationships be-
tween the input data and the data after the projection into
eigenspace. This is especially problematic for novice users

c(cid:13) 2009 The Author(s)
Journal compilation c(cid:13) 2009 The Eurographics Association and Blackwell Publishing Ltd.
Published by Blackwell Publishing, 9600 Garsington Road, Oxford OX4 2DQ, UK and
350 Main Street, Malden, MA 02148, USA.

and students who need to use PCA but do not yet grasp how
it works. Without a certain amount of background knowl-
edge in the math behind PCA, it is often difﬁcult for the user
to perform effective analysis both in understanding how the
original data items transform between coordinate systems
and how the data dimensions relate to the principle compo-
nents.

In order to assist the user in better understanding and uti-
lizing PCA for analysis, we have developed a system called
iPCA (interactive PCA) that visualizes the results of prin-
ciple component analysis using multiple coordinated views
and a rich set of user interactions. The four coordinated
views in our system visualize the data items in original data
space (Data View), the data items in eigenspace (Eigenvec-
tor View), the data items projected onto two principle com-
ponents (Projection View), and the correlations between all
data dimensions (Correlation View). User interactions in one
view are immediately reﬂected in the others so that the user

D.H. Jeong et. al / iPCA: An Interactive System for PCA-based Visual Analytics

can easily identify a data item or a data dimension in the
original data space and its counterpart in eigenspace.

To demonstrate the effectiveness of iPCA, we performed a
comparative user study with a well-known commercial sys-
tem called Interactive Data Exploration, which is part of
SAS/INSIGHT. The two systems are similar in that both
systems use the same mathematical functions for perform-
ing PCA calculations, but they differ in their approaches
to interface and interaction design. While the visualizations
and interactions in our system are ﬂuid, dynamic, and coor-
dinated, in SAS/INSIGHT, a more traditional menu-driven
and command-line approach forms the basis of interaction.
Using SAS/INSIGHT, the user iteratively inputs parameters
into the system before clicking on a button (or typing in a
command) to initiate the PCA process and generate the re-
sults as static images and charts.

Our user study involved 12 participants performing com-
plex analysis tasks on high dimensional data using both
iPCA and SAS/INSIGHT. We quantitatively measured the
accuracy and speed of the users’ analyses, and asked the par-
ticipants for qualitative feedback on ease of use, preference,
and effectiveness. Based on the quantitative results of the
user study, we ﬁnd that users were faster and more accurate
in analysis tasks using our system. Participants’ feedback in-
dicates that our system better facilitates the understanding of
PCA, is more intuitive to use, and is unanimously preferred
over SAS/INSIGHT. Many participants attributed the suc-
cess of our system to its high interactivity and transparency,
which suggests that our system is successful in opening up
the “black box” of principle component analysis.

The rest of the paper consists of six sections. First we dis-
cuss other research in visualizing PCA and the beneﬁts of
interaction. Then, we provide our system’s interface design
and the available sets of interactions. In section 5, we in-
troduce the evaluation procedures and results, and conclude
with discussions, conclusion, and future work.

(a)

(b)

(c)

Figure 1: Illustration of principal component analysis.
High-dimensional data (a) are plotted with respect to their
ﬁrst three Principal Components (PCs) (b) and ﬁrst two PCs
(c).

2. Previous Work
PCA has been applied in many disciplines for various pur-
poses. In visualization, PCA is used mostly for dimension

reduction. For example, Hibbs et al. [HDLT05] apply PCA
to visually analyze microarray data. Wall et al. [WRR03]
demonstrate how to visualize gene expression data using
PCA and how to interpret the results. However, while PCA
is popular and effective as a tool, there have been few avail-
able products or research projects on assisting the under-
standing of PCA results. Mathematical applications such as
MATLAB [Theb] and SAS/INSIGHT [SAS] can perform
PCA and visualize its results accurately. An open-source vi-
sualization tool, GGobi [Thea], supports interactive analysis
of data through PCA and can be linked to R (Statistical Com-
puting Software) for additional statistical methods. Müller
and Alexa [MA04] developed a system which allows the
user to visually detect and create clusters of data elements in
the PCA space. Müller et al. [MNS06] further enhanced con-
ventional information visualizations with PCA and demon-
strated that this combination improved data analysis. All
these PCA-based tools are powerful and employ various vi-
sualization techniques. However, they also share the same
goal of utilizing PCA with the assumption that users are ex-
perts at mentally transforming data elements from their orig-
inal space into the projected PCA space. Our work differs in
that we intend to use interaction to make the transformation
of coordinate spaces intuitive to both novices and experts,
and to show that by opening this “black box,” users can gain
a deeper understanding of data analysis using PCA.

Interaction plays an important role in visualization for as-
sisting users in understanding their data. Several user evalua-
tions have found a beneﬁt for interactive visual systems over
traditional iterative input systems in understanding and using
data. Ahlberg et al. [AWS92] study the difference between
using dynamic sliders and traditional text entry to visually
explore periodic table data. They ﬁnd that participants are
faster with the dynamic slider interface on some but not all
of their tasks. However, they do not ﬁnd a clear difference in
the participants’ subjective evaluation of the interfaces.

More recently, Callahan and Koenemann [CK00] com-
pare an interactive visual tool, InfoZoom, against two tra-
ditional interfaces for online catalog browsing. With In-
foZoom, users are more likely to complete tasks faster.
The users also report higher ease of use and efﬁciency
than traditional interfaces. In contrast, Combs and Beder-
son [CB] compare a zoomable image browser to a static
image browser and ﬁnd no difference in performance, al-
though users tend to (non-signiﬁcantly) prefer the zoomable
browser. Unfortunately, while these studies inform us of the
value of interaction, the tasks are simpler than asking users
to perform complex analysis using PCA. Although some re-
search studies [SNLD06, SS06] have been performed to un-
derstand the effects of interactions in a more complex anal-
ysis task, these studies are narrowed to ﬁnding the effective-
ness and the limitations of their applications.

c(cid:13) 2009 The Author(s)
Journal compilation c(cid:13) 2009 The Eurographics Association and Blackwell Publishing Ltd.

D.H. Jeong et. al / iPCA: An Interactive System for PCA-based Visual Analytics

Figure 2: The system overview (left) showing the four views and the two control panels with the E. Coli dataset, and three
examples with the Iris dataset (right). (A) Projection view. Data items are projected onto the two user-selected eigenvectors (in
this case, the primary and secondary principle components). (B) Eigenvector view. Each eigenvector is treated as a dimension in
this parallel coordinates view, and every data item is drawn as a line. (C) Data view. Another parallel coordinates view, but this
time each dimension represents the dimensions in the original data, and each line represents each data item. (D) Correlation
view. Pearson-correlation coefﬁcient and the relationships (scatter plot) between each pair of variables are represented. (E)
Dimension sliders. Each slider controls the amount of contribution of a dimension in the PCA calculation. (F) Control options.
(G) shows the result of diminishing the ﬁrst dimension (Sepal length) of the Iris dataset from 100% to 0%. The trails show how
the data points move in PCA space in response to the change. The images (H) and (I) show 10% uncertainty in the data (in all
dimensions). The possible locations for each data point are drawn in a hypercube (H) and in outlines (I) corresponding to the
number of data item(s) selected.

3. Interface Design
The overall interface design of our system, iPCA, is based
on multiple coordinated views. Each of the four views in the
system represents a speciﬁc aspect of the input data either in
data space or eigenspace, and are coordinated in such a way
that any interaction with one view is immediately reﬂected
in all the other views (brushing & linking). The coordination
between the views depicts the same data item or data dimen-
sion in both data space and eigenspace simultaneously, thus
allowing the user to infer the relationships between the two
coordinate spaces.

Along with two control panels, iPCA contains four dis-
tinct views: the Projection View (Figure 2A), the Eigenvec-
tor View (Figure 2B), the Data View (Figure 2C), and the
Correlation View (Figure 2D).

Projection View: Two principal components (by default,
the ﬁrst and second most dominant eigenvectors) are used to
project data points onto a two-dimensional coordinate sys-
tem.

Data view: The Data View is located below the Projection
View, and shows a parallel coordinates visualization of all

c(cid:13) 2009 The Author(s)
Journal compilation c(cid:13) 2009 The Eurographics Association and Blackwell Publishing Ltd.

data points in the original data dimensions. In this view, an
auto-scaling function is applied to increase the readibility of
data.

Eigenvector View: In the Eigenvector View, data points
are shown in the eigenspace. The calculated eigenvectors
and their eigenvalues are displayed in a vertically projected
parallel coordinates visualization, with eigenvectors ranked
from top to bottom by dominance. The distances between
eigenvectors in the parallel coordinate view vary based on
their eigenvalues, separating the eigenvectors based on their
mathematical weights.

Correlation View: Pearson-correlation coefﬁcients and
relationships between variables are represented in the Cor-
relation View as a matrix of scatter plots and values. Since
correlations between dimensions are symmetric, repetition
is avoided by separating the matrix into three components:
the diagonal, the bottom triangle, and the top triangle. The
diagonal displays the name of the dimension as a text string.
The bottom triangle shows the coefﬁcient value between two
dimensions with a color indicating positive (red), neutral
(white), and negative (blue) correlations. The top triangle

D.H. Jeong et. al / iPCA: An Interactive System for PCA-based Visual Analytics

contains cells of scatter plots in which all data items are pro-
jected onto the two intersecting dimensions. The colors of
the data items are the same as the colors used in the other
three views so that clusters are easily identiﬁed.

It is relevant to note that the selection operation in all
views and the zooming-in mechanism in the Projection and
Correlation views help users to focus their interest on a data
item or items. Also, the Projection View and the Correlation
View can be switched such that the Projection View takes
up the lower right hand position and the Correlation View
ﬁlls the main display. This simple switch operation allows
the user to utilize the visual real estate for focusing either on
a single projection of data or to examine in detail all (or one)
scatter plot(s) in the Correlation View.

The two control panels include a set of dimension slid-
ers (Figure 2E) that can be used to decrease or increase the
contributions of each of the original data dimensions, whose
purpose will be discussed further in the following section
(Section 4). Several additional modes can also be speciﬁed
in the other control panel to enhance understanding of the vi-
sual changes during data analysis (Figure 2F). The user can
enable trails so that the path of each data point’s recent mo-
tion is painted to the screen, making the movement of each
point during interaction operations more apparent. The user
can also choose to show uncertainty (Figure 2H and I) by
setting a percentage of possible error in the dataset, which is
reﬂected as bounding boxes around data items in the Projec-
tion View.

4. Interaction
Since iPCA is designed with high interactivity in mind, the
types of available interactions are carefully considered. We
categorize all the interactions in iPCA into two groups: in-
teractions with the views, and interactions with PCA. Inter-
actions with the views are operations that do not result in
PCA calculations, and include brushing, ﬁltering, zooming
and panning, etc; whereas interactions with PCA will result
in new PCA calculations, including operations that change
the weights of dimensions, move data points in either data
space and eigenspace, and removal of data points. Both types
of interactions are embedded in the coordinated views such
that all views react to all interactions.

4.1. Interacting with the Views
Interactions in this category are operations that do not cause
the system to recompute PCA. As mentioned above, these
operations include brushing, ﬁltering of data items or dimen-
sions, zooming and panning, etc. Although these interactions
are standard in most Infovis or visual analytics tools, they
are nonetheless very important, and are essential in multi-
ple coordinated views. The ability to allow the user to select
a cluster of data items in one coordinate space and imme-
diately see the corresponding items highlighted in the other

coordinate space helps the user understand the relationship
between the two.

The most notable interactions in this category are the dif-
ferent types of selections implemented in iPCA. iPCA al-
lows the user to select data items in all four views. In Data
View and Eigenvector View, where the visualizations are
parallel coordinates, selection means clicking on a single
line or brushing a range of items. In Projection View and
Correlation View, the user can either click on a single dot or
draw an enclosed space upon which all data items within the
space will be selected.

4.2. Interacting with PCA
As mentioned previously, one of the biggest hurdles in ef-
fectively analyzing PCA results is in understanding the re-
lationships between data space and eigenspace. While the
interactions provided in the previous section allow the user
to see a data item appear in different coordinate systems, the
interactions do not immediately lead the user to see the rela-
tionship between the coordinate spaces. Speciﬁcally, eigen-
vectors are linear combinations of data dimensions, there-
fore, understanding which data dimension contributes to an
eigenvector is a key point in comprehending how the coor-
dinate spaces relate to each other.

In order to visually assist the user in recognizing how data
space relates to eigenspace, we create a set of interactions
that allow the user to alter the values of the data items. For
example, if the user drags a data item in the Projection View
towards the positive direction along the x-axis (increasing
the data points value in the ﬁrst principle component), the
user should be able to immediately observe in the Data View
how that change affects the values of that data item in the
original data space, thus shedding light on the relationship
between the ﬁrst principle component and all dimensions in
the original data space.

Similarly, if there is an obvious cluster in the Projection
View, the user can interactively change the weights of a di-
mension to see its affect on the formation of the cluster. For
example, if diminishing the contribution of a data dimension
in PCA calculation down to 0% does not affect the cluster-
ing, then it should be clear that the cluster does not depend
on that particular dimension.

While the concept of encouraging interactions that di-
rectly alter the values of data items seem counter-intuitive,
the idea is not novel. Spotﬁre includes a “jitter” opera-
tion [Ahl96], and Dust and Magnet has a “dust shake” op-
eration [YMSJ05], both of which are designed to reveal oc-
cluded data items. In medical visualization, deformation or
“cut-aways” modify the data to expose hidden structures un-
derneath skin and ﬂesh [MTB03]. The interactions in iPCA
share a similar goal, but instead of revealing hidden or oc-
cluded information, our interactions assist the user in reveal-
ing relationships between coordinate spaces.

c(cid:13) 2009 The Author(s)
Journal compilation c(cid:13) 2009 The Eurographics Association and Blackwell Publishing Ltd.

D.H. Jeong et. al / iPCA: An Interactive System for PCA-based Visual Analytics

Three speciﬁc interactions are implemented based on the
concept of data alteration: modifying dimension contribu-
tion, adjusting data items, and removal of data items.

Modifying Dimension Contribution: Each slider in Fig-
ure 2E corresponds to a data dimension. By modifying the
slider, the user can change the contribution of the data di-
mensions in the ﬁnal PCA calculation. For instance, chang-
ing the dimension contribution to 50% indicates the weight
change of the selected dimension to 0.5. This interaction al-
lows the user to observe which data dimensions contribute
to the projections of the data in eigenspace. By adjusting
these sliders, a user can quickly test hypotheses about how
the analysis would be affected if a dimension or set of di-
mensions were removed or considered less important. This
makes it possible for a user to observe the formation and
dispersion of clusters and to identify the cause of outliers.

Adjust Data Items: Values of data items can be modi-
ﬁed in either the Projection View, Data View, or Eigenvector
View. This interaction not only allows the user to see the re-
lationship between a principle component and the contribut-
ing data dimensions as mentioned above, but also allows the
user to test what-if scenarios. If the user suspects that a data
item should appear in a certain cluster, the user can manually
move the data item and see how the values of that data item
would have to be modiﬁed.

Removing Data Items: In analysis using PCA, a common
task is for the user to remove outliers. iPCA supports direct
removal of data items from the system so that the user can
observe how the projection from data space to eigenspace
changes with the removal.

One caveat of these interactions is that they are compu-
tationally expensive. Modifying any data requires the re-
computation of PCA, and in the cases of interactively ad-
justing sliders and moving data items on screen, PCA has
to be re-calculated quickly to avoid lag or ﬂickering. For
very large datasets, this type of interactions has the poten-
tial of becoming a bottleneck in usability. In iPCA, the scal-
ability issue is addressed by incorporating a faster version
of singular value decomposition called online-SVD [Bra06]
which trades precision for speed. Brand demonstrates how
online-SVD is faster than traditional SVD (see [Bra06] for
detail). The user has the option to use either traditional SVD
or online-SVD depending on the speed and accuracy require-
ments as well as the scale of the data.

5. Evaluation
We conducted a comparative evaluation to assess the effec-
tiveness of our system in relation to a well-known commer-
cial tool, SAS/INSIGHT’s Interactive Data Exploration. A
total of 12 students (nine males) participated in the evalu-
ation. Three of the 12 participants were undergraduate stu-
dents and nine were graduate students, and 11 of the partic-
ipants majored in computer science and one in management

c(cid:13) 2009 The Author(s)
Journal compilation c(cid:13) 2009 The Eurographics Association and Blackwell Publishing Ltd.

of information science. Based on self reported familiarity,
we found that nine participants were aware of PCA prior to
the evaluation, and of the nine, three had used PCA in the
past.

At the start of the evaluation, all participants receive a de-
tailed explanation about PCA followed by a pre-evaluation
background questionnaire. Each participant was provided
a total of ten minutes to train with the two systems prior
to the evaluation. The evaluation consisted of performing
four analysis tasks using each system. The participants were
given ﬁve minutes to perform each task and were requested
to answer questions immediately after each task. The eval-
uation was conducted using an online website, where time
spent and answers were saved into a database.

We performed the evaluation using three different
datasets: the Iris dataset (150 data items × 4 dimensions),
the E.coli dataset (336 data items × 7 dimensions) and the
Wine dataset (179 data items × 13 dimensions). The Iris
dataset was used in the training session whereas the E.coli
and the Wine datasets were used in the actual evaluation. All
three datasets are scientiﬁc results that are publicly available
at the UCI Machine Learning Repository [AN07].

5.1. Procedure

Each participant was requested to use the two systems on
different datasets. Therefore, six participants used iPCA ﬁrst
and the rest of the participants began with SAS/INSIGHT.
The order in which datasets were given to each participant
was counterbalanced with system order, so that six partici-
pants used the E.Coli dataset ﬁrst and the rest used the Wine
dataset ﬁrst.

Four tasks were given to each participant during the eval-

uation of both systems:
• What is the most striking outlier you can ﬁnd? An out-
lier is a point that does not ﬁt the overall patterns of the
dataset.
• Find a dimension that least affects the PCA outputs in the
Projection View using ﬁrst and second principle compo-
nents.
• Find two dimensions with a highly positive correlation.
Also ﬁnd the class name and label of an outlier that does
not follow that correlation.
• How does removing the ﬁrst dimension affect the PCA
results using the ﬁrst and second principle components?
List as many observations as possible.

The ﬁrst three tasks are related to ﬁnding exact answers
and the last one is a descriptive task asking the participant to
describe the difference between including and excluding a
speciﬁc dimension. Five minutes were given to solve each
task. If time expired, partial answers were saved into the
database. As soon as each task was completed, a post-task
questionnaire was given to participants to track how they

D.H. Jeong et. al / iPCA: An Interactive System for PCA-based Visual Analytics

Figure 3: Results broken down by tasks for each of the two systems. (a) Number of participants who answered the task question
correctly. (b) Task difﬁculty and (c) helpfulness of the system in solving the task, as reported by participants.

felt about the task. These questions included “How difﬁcult
was this task?” and “How helpful was the interface in solv-
ing the task?” A post-application questionnaire was given
after a participant completed all four tasks. This question-
naire asked the participant to give feedback on their over-
all subjective opinion about each system. After a participant
completed the evaluation using both systems, the participant
completed an additional set of questions (post-study ques-
tionnaire) that described the preference, the ease of use, and
the effectiveness of the system in analyzing data. Finally, the
participant graded each system on a scale of ‘A’ to ‘F’.

5.2. Results
We present the results of our evaluation based on accuracy,
speed, difﬁculty and usefulness, effectiveness, and prefer-
ence. Both accuracy and speed are measured quantitatively;
whereas the other three categories are analyzed based on the
participants’ qualitative feedback.

Accuracy: Figure 3(a) shows the results of the partici-
pants’ accuracy in solving each task using both iPCA and
SAS/INSIGHT. As shown, approximately 85% of the par-
ticipants answered correctly using iPCA. On the other hand,
when using SAS/INSIGHT, they were only able to an-
swer correctly 62% of the time. Furthermore, when using
SAS/INSIGHT, there were three instances in which a par-
ticipant could not complete the task. One of the instances
was due to the fact that the participant ran out of time. In the
other two cases, the participants simply gave up and claimed
that they were unable to ﬁnd the solutions (see Figure 3(a)).
Note that the accuracy difference is statistically signiﬁcant
across the two systems (p < 0.01).

Speed: Table 1 shows the overall average time spent solv-
ing each task. Participants spent less time in solving each
task using iPCA except for task 4 (a descriptive question).
This seems to be because participants tried to ﬁnd as many
differences as possible through interaction with dimensions.
On average, participants spent about 150 seconds using
iPCA, and 170 seconds using SAS/INSIGHT. Although the

difference is not statistically signiﬁcant (p = 0.17), there is
a trending effect towards a faster solution when using iPCA.
Difﬁculty & usefulness (post-task questionnaire): Fig-
ure 3(b) and (c) show how participants rated the difﬁculty
of each task when using iPCA or SAS/INSIGHT, as well as
how they rated the usefulness of each system in solving the
task. Figure 3(b) indicates that about 81% of the participants
found the tasks to be easy when using iPCA. On the other
hand, only about 48% of the participants identiﬁed the tasks
as being easy when using SAS/INSIGHT. Interestingly, al-
though more than half of the participants mentioned that task
1 is easy to solve, Figure 3(a) indicates that the accuracy in
solving task 1 is low (58% iPCA and 41% SAS/INSIGHT).
This might be because most participants have little previous
experience with ﬁnding outliers.

Figure 3(c) shows that about 90% of the participants iden-
tiﬁed iPCA to be helpful in solving the tasks; whereas only
about 40% of the participants found SAS/INSIGHT to be
helpful. Furthermore, only two participants (participant D
and I) rated iPCA to be not helpful in solving a task (tasks
4 and 1, respectively); whereas ten participants indicated
that SAS/INSIGHT was unhelpful in solving some tasks
(one participant indicated SAS/INSIGHT was completely
not helpful in solving all tasks).

Overall, we ﬁnd that the more difﬁcult a task was rated
(very easy = 5, fairly easy = 4, etc), the more time the par-
ticipants spent on solving it (p < 0.0001). However, solv-
ing a task with a “helpful” system (very helpful = 5, fairly
helpful = 4, etc) did not decrease the time spent on the task

Table 1: Average time spent in solving each task.

Application

iPCA

SAS/INSIGHT

Task
Task 1
Task 2
Task 3
Task 4
Task 1
Task 2
Task 3
Task 4

Time Spent (seconds)

136.58
128.33
125.50
211.33
177.67
165.58
142.92
197.08

c(cid:13) 2009 The Author(s)
Journal compilation c(cid:13) 2009 The Eurographics Association and Blackwell Publishing Ltd.

D.H. Jeong et. al / iPCA: An Interactive System for PCA-based Visual Analytics

Figure 4: Participants’ responses to a post-application questionnaire, ﬁlled out after solving all four tasks using one of the
systems. (a) How well do you understand the application now? (b) How well do you understand PCA now? (c) How well do you
understand the data you worked with now? (d) How useful was the system? (e) How difﬁcult or easy was the system to learn?

(p = 0.2586). With a helpful system, the participants did
solve the tasks more accurately (p = 0.0027), but partici-
pants did not rate the tasks to be less difﬁcult (p = 0.0966).
Effectiveness (post-application questionnaire): Fig-
ure 4 shows the results of the ﬁve questions in the post-
application questionnaire conducted right after the evalua-
tion of each system. Of particular signiﬁcance are the ques-
tions asking the participants how well they understood the
application (Figure 4(a)), how well they understood the data
(Figure 4(c)), how useful was the system (Figure 4(d)), and
how difﬁcult or easy was the system to learn (Figure 4(e)).

In answering how well the participants understood PCA,
most participants did not indicate that they understood PCA
“very well.” However, the majority of the iPCA users indi-
cated that they understood PCA “fairly well”; whereas the
majority of the SAS/INSIGHT users only claimed “a little
bit” of understanding.

In answering how well the participants understood the
data, the majority of the iPCA users indicated that they un-
derstood the data either “fairly well” or “a little bit”; whereas
the SAS/INSIGHT users either understood the data “a little
bit” or “not at all.”

Lastly, in answering about the usefulness of the system,
the majority of the iPCA users found the system to be “very
useful”; whereas SAS/INSIGHT users consistently ranked
the system to be “fairly useful” and below, with four partic-
ipants claiming the system to be “not very useful” or “not
useful at all.”

Preference (post-study questionnaire): After the evalu-
ation, each participant ranked the two systems and described
their pros and cons. Figure 5 clearly shows that most par-
ticipants preferred iPCA over SAS/INSIGHT, giving iPCA
eight A’s and four B’s. On the other hand, the majority of the
participants gave SAS/INSIGHT a C or D grade, with one
participant failing it by giving it an F.

When describing the pros and cons of iPCA, eight par-
ticipants speciﬁcally pointed out the strength of iPCA as

c(cid:13) 2009 The Author(s)
Journal compilation c(cid:13) 2009 The Eurographics Association and Blackwell Publishing Ltd.

Figure 5: At the end of the evaluation, each participant
grades the systems on a scale of ‘A’ to ‘F’.

being “interactive,” and eight participants described iPCA
as “transparent.” While a few participants gave constructive
feedback on how to further enhance the iPCA tool (e.g., add
the ability to rearrange the dimensions in the Correlation
View), the only negative criticism for iPCA was that it did
not generate printable reports similar to the static charts and
numbers that SAS/INSIGHT generates.

For SAS/INSIGHT, two participants who were previously
familiar with the SAS system pointed out that while they
preferred iPCA over SAS/INSIGHT for analyzing PCA re-
sults, SAS is still a far more comprehensive and complete
numerical and statistical analysis tool. One participant fur-
ther noted that if he was allowed to use additional features
in SAS outside of the tools speciﬁc to PCA, deeper analysis
on the dataset could have been performed.

6. Discussion
Since our evaluation compared two systems (iPCA and
SAS/INSIGHT) that use the same mathematical methods for
computing PCA, we can safely assume that the increase in
our participants’ performance in using iPCA is attributed
solely to the interface design and the set of interactions. Un-
fortunately, we are not able to further isolate the speciﬁc fac-
tor(s). Based on our evaluation alone, we cannot determine

D.H. Jeong et. al / iPCA: An Interactive System for PCA-based Visual Analytics

if the increase is due to the multiple coordinated views, the
interactions, or the combination of the two. However, we do
hypothesize that the “interactions with PCA” play a signif-
icant role in that the user’s direct and continuous manipu-
lation with PCA is rewarded with immediate visual feed-
back. This allows the user to “play” with the data and intuit
the subtleties behind the coordinate transform between data
space and eigenspace in a way that less interactive visualiza-
tions such as SAS/INSIGHT cannot achieve.

The “interactions with PCA” are also the most unique set
of the interactions in iPCA. Unlike our other interactions that
merely highlight or explore the data, the design decision be-
hind the “interactions with PCA” is to focus on reasoning. In
fact, we design the “interactions with PCA” to be less faithful
to the data, but more revealing in discovering relationships
between coordinate spaces and data dimensions. For exam-
ple, most of our participants credited the rich interactions in
iPCA to be the primary strength of the system, but two of our
participants pointed out the fact that in modifying dimension
contribution, moving a slider from 100% to 72% and taking
a snapshot of the Projection View was not meaningful as the
projection was not of the original data. Similarly, moving a
data point across the screen seemed counter-intuitive as it di-
rectly modiﬁed the values of the data. While these concerns
are valid, we contend that they miss the spirit of the inter-
actions. It is true that the resulting images from these inter-
actions cannot be considered by themselves, but it is during
the direct manipulation of the data and coordinate spaces that
the user gains insight about their relations and how changes
in one affects the other, which is otherwise hidden. One very
interesting future direction for our research will be to further
understand why these types of interactions are successful,
and examine the extent to which they can be applied.

7. Conclusion and Future Work

We present a visual analytical system for analyzing PCA re-
sults called iPCA. We design the interface using multiple
coordinated views, and add a rich set of interactions for both
interacting with the views and interacting with the PCA cal-
culations. To validate the effectiveness of our system, we
performed a comparative user study with a well-known com-
mercial system called SAS/INSIGHT. The participants of
the evaluation used both iPCA and SAS/INSIGHT to per-
form complex analysis with high dimensional datasets. The
results of the evaluation indicate that iPCA is somewhat
faster, more accurate, easier to use, more effective in learn-
ing about PCA and the dataset, and is overwhelmingly pre-
ferred over SAS/INSIGHT.

Since iPCA and SAS/INSIGHT use the same mathemati-
cal functions in performing PCA, the difference in the eval-
uation between the two systems can only be attributed to
either the interface design or the interactions. While our cur-
rent evaluation cannot isolate the speciﬁc factor(s), we can

View publication stats
View publication stats

gather some important insights and have a signiﬁcant basis
for further studies.

References
[Ahl96] AHLBERG C.: Spotﬁre: An information exploration en-

vironment. SIGMOD Record 25, 4 (1996), 25–29.

[AN07] ASUNCION A., NEWMAN D.: UCI machine learning

repository, 2007.

[AWS92] AHLBERG C., WILLIAMSON C., SHNEIDERMAN B.:
Dynamic queries for information exploration: an implementation
and evaluation. In SIGCHI (1992), ACM.

[Bra06] BRAND M.: Fast low-rank modiﬁcations of the thin sin-
gular value decomposition. Linear Algebra and its Applications
415, 1 (2006), 20–30.

[CB] COMBS T. T. A., BEDERSON B. B.: Does zooming im-
prove image browsing? In ACM Conference on Digital Libraries,
pp. 130–137.

[CK00] CALLAHAN E., KOENEMANN J.: A comparative usabil-
ity evaluation of user interfaces for online product catalog. In EC
’00 (2000), ACM Press, pp. 197–206.

[HDLT05] HIBBS M. A., DIRKSEN1 N. C., LI K., TROYAN-
SKAYA O. G.: Visualization methods for statistical analysis of
microarray clusters. BMC Bioinformatics 6, 115 (2005).

[Jol02]

JOLLIFFE I. T.: Principal Component Analysis, sec-

ond ed. Springer, 2002.

[MA04] MÜLLER W., ALEXA M.: Visual component analysis.
In VisSym 2004 (2004), Eurographics Association, pp. 129–136.
[MNS06] MÜLLER W., NOCKE T., SCHUMANN H.: Enhancing
the visualization process with principal component analysis to
support the exploration of trends. In APVis ’06 (2006), Australian
Computer Society, Inc., pp. 121–130.

[MTB03] MCGUFFIN M. J., TANCAU L., BALAKRISHNAN R.:
Using deformations for browsing volumetric data. In IEEE Visu-
alization (2003), IEEE Computer Society, pp. 401–408.

[SAS] SAS INSTITUTE, INC:

SAS/INSIGHT.

http://

sas.com/technologies/analytics/statistics/
insight.

[Shl05] SHLENS J.: A tutorial on principal component anal-
http://www.snl.salk.edu/~shlens/notes.

ysis.
html, 2005.

[SNLD06] SARAIYA P., NORTH C., LAM V., DUCA K. A.: An
insight-based longitudinal study of visual analytics. IEEE TVCG
12, 6 (2006), 1511–1522.

[SS06] SEO J., SHNEIDERMAN B.: Knowledge discovery in
high-dimensional data: Case studies and a user survey for the
rank-by-feature framework. IEEE TVCG 12, 3 (2006), 311–322.
[Thea] THE GGOBI FOUNDATION, INC: Ggobi. http://www.

ggobi.org.

[Theb] THE MATHWORKS, INC: Matlab.
mathworks.com/products/matlab.

http://www.

[WRR03] WALL M. E., RECHTSTEINER A., ROCHA L. M.: Sin-
gular value decomposition and principal component analysis. In
A Practical Approach to Microarray Data Analysis (D.P. Berrar,
W. Dubitzky, M. Granzow, eds.) Kluwer: Norwell, MA, pp. 91-
109., 2003.

[YMSJ05] YI J. S., MELTON R., STASKO J., JACKO J. A.: Dust
& magnet: multivariate information visualization using a magnet
metaphor. Information Visualization 4, 4 (2005), 239–256.

c(cid:13) 2009 The Author(s)
Journal compilation c(cid:13) 2009 The Eurographics Association and Blackwell Publishing Ltd.

","{""0"":{""0"":""easy"",""1"":""understood"",""2"":""parallel"",""3"":""useful*"",""4"":""fairly*""},""1"":{""0"":""spent*"",""1"":""change*"",""2"":""completed*"",""3"":""represents*"",""4"":""allow*""},""2"":{""0"":""analysis*"",""1"":""evaluation*"",""2"":""tasks"",""3"":""application*"",""4"":""operations*""},""3"":{""0"":""participants*"",""1"":""items*"",""2"":""users*"",""3"":""participant"",""4"":""citations*""},""pos"":{""0"":1,""1"":2,""2"":3,""3"":4,""4"":5}}",2009,{},False,False,journalArticle,False,VUUD5TST,[],self.user,"{""C"":{""0"":12.8873000198,""1"":11.8624660873,""10"":8.2262294725,""11"":6.805117327,""12"":7.0491491804,""13"":4.73357254,""14"":8.0444854162,""15"":16.8208180538,""16"":4.1603664765,""17"":5.8636658796,""18"":5.7306273737,""19"":16.6731450256,""2"":10.6158515209,""20"":5.8675631428,""21"":12.1560830248,""22"":7.6041375271,""23"":9.3464750303,""24"":9.2079040672,""25"":4.9838489023,""26"":8.9123429293,""27"":10.3489378795,""28"":11.8431968431,""29"":8.3896831826,""3"":16.5873046847,""30"":6.1038454622,""31"":4.6226087046,""32"":7.1705514285,""33"":8.5724144724,""34"":9.4381894267,""35"":3.9660036921,""36"":5.6408530988,""37"":4.7791382305,""38"":7.9290518374,""39"":7.1658712887,""4"":13.8963688095,""40"":7.9694506904,""41"":4.0333161221,""42"":4.6354690894,""43"":3.9507381545,""44"":6.552906427,""45"":6.2455502694,""46"":5.5059998017,""47"":5.3013205999,""48"":6.2105990784,""49"":4.546209139,""5"":25.7573287007,""50"":4.2714466345,""51"":4.4825449477,""52"":4.6807764523,""53"":4.3238260251,""54"":4.0431228064,""55"":4.0151909055,""56"":4.4481731288,""57"":4.1569278635,""58"":3.952111847,""59"":4.5286955854,""6"":9.458036129,""7"":5.0251287813,""8"":12.5921883987,""9"":5.5198096336},""Unnamed: 0"":{""0"":0,""1"":1,""10"":10,""11"":11,""12"":12,""13"":13,""14"":14,""15"":15,""16"":16,""17"":17,""18"":18,""19"":19,""2"":2,""20"":20,""21"":21,""22"":22,""23"":23,""24"":24,""25"":25,""26"":26,""27"":27,""28"":28,""29"":29,""3"":3,""30"":30,""31"":31,""32"":32,""33"":33,""34"":34,""35"":35,""36"":36,""37"":37,""38"":38,""39"":39,""4"":4,""40"":40,""41"":41,""42"":42,""43"":43,""44"":44,""45"":45,""46"":46,""47"":47,""48"":48,""49"":49,""5"":5,""50"":50,""51"":51,""52"":52,""53"":53,""54"":54,""55"":55,""56"":56,""57"":57,""58"":58,""59"":59,""6"":6,""7"":7,""8"":8,""9"":9},""count"":{""0"":260,""1"":106,""10"":44,""11"":42,""12"":40,""13"":40,""14"":38,""15"":34,""16"":28,""17"":26,""18"":24,""19"":24,""2"":98,""20"":22,""21"":18,""22"":16,""23"":16,""24"":16,""25"":14,""26"":14,""27"":14,""28"":14,""29"":12,""3"":90,""30"":12,""31"":12,""32"":12,""33"":12,""34"":12,""35"":10,""36"":10,""37"":10,""38"":10,""39"":10,""4"":76,""40"":10,""41"":8,""42"":8,""43"":8,""44"":8,""45"":8,""46"":8,""47"":8,""48"":8,""49"":6,""5"":76,""50"":6,""51"":6,""52"":6,""53"":6,""54"":6,""55"":6,""56"":6,""57"":6,""58"":6,""59"":6,""6"":72,""7"":64,""8"":58,""9"":46},""exemplar"":{""0"":null,""1"":null,""10"":null,""11"":""*"",""12"":null,""13"":null,""14"":""*"",""15"":null,""16"":null,""17"":null,""18"":null,""19"":null,""2"":null,""20"":null,""21"":null,""22"":null,""23"":""*"",""24"":null,""25"":null,""26"":""*"",""27"":null,""28"":null,""29"":null,""3"":""*"",""30"":null,""31"":""*"",""32"":null,""33"":null,""34"":""*"",""35"":null,""36"":null,""37"":null,""38"":""*"",""39"":""*"",""4"":null,""40"":null,""41"":""*"",""42"":null,""43"":null,""44"":null,""45"":""*"",""46"":null,""47"":""*"",""48"":null,""49"":""*"",""5"":null,""50"":null,""51"":null,""52"":null,""53"":""*"",""54"":null,""55"":""*"",""56"":null,""57"":null,""58"":null,""59"":null,""6"":null,""7"":""*"",""8"":""*"",""9"":null},""pos"":{""0"":1,""1"":2,""10"":8,""11"":2,""12"":3,""13"":9,""14"":3,""15"":4,""16"":10,""17"":11,""18"":12,""19"":13,""2"":3,""20"":14,""21"":15,""22"":16,""23"":1,""24"":17,""25"":18,""26"":4,""27"":1,""28"":2,""29"":19,""3"":1,""30"":3,""31"":2,""32"":20,""33"":21,""34"":4,""35"":22,""36"":23,""37"":24,""38"":5,""39"":5,""4"":4,""40"":25,""41"":6,""42"":26,""43"":27,""44"":28,""45"":3,""46"":29,""47"":7,""48"":30,""49"":5,""5"":5,""50"":31,""51"":32,""52"":33,""53"":4,""54"":34,""55"":5,""56"":35,""57"":8,""58"":36,""59"":37,""6"":6,""7"":1,""8"":2,""9"":7},""sigma_nor"":{""0"":1.775662033,""1"":2.0837435852,""10"":2.0878945575,""11"":1.9107516999,""12"":1.9628663789,""13"":1.6345562447,""14"":2.1262848086,""15"":3.5042342657,""16"":1.6279356009,""17"":1.9296834268,""18"":1.9320158383,""19"":3.8262501192,""2"":2.0031811556,""20"":1.9832149897,""21"":3.2508782839,""22"":2.4272030815,""23"":2.7744357697,""24"":2.7468197838,""25"":1.9360845331,""26"":2.7527729961,""27"":3.0514244676,""28"":3.3620636204,""29"":2.7106166262,""3"":2.6375068514,""30"":2.2131076709,""31"":1.8907188393,""32"":2.445274533,""33"":2.7503878017,""34"":2.9388223476,""35"":1.7710784167,""36"":2.1542925795,""37"":1.9571277834,""38"":2.6778442255,""39"":2.5032245888,""4"":2.475698924,""40"":2.687087691,""41"":1.8077506271,""42"":1.9532260243,""43"":1.7878004429,""44"":2.4164637287,""45"":2.3422089106,""46"":2.1635393633,""47"":2.1140904861,""48"":2.3337649791,""49"":1.9497989092,""5"":3.7518785974,""50"":1.8794442913,""51"":1.9334973041,""52"":1.9842556918,""53"":1.8928563543,""54"":1.8209805803,""55"":1.8138284464,""56"":1.9246961898,""57"":1.8501210604,""58"":1.7976766681,""59"":1.9453144568,""6"":2.0218799569,""7"":1.5603161735,""8"":2.5005607075,""9"":1.7065644901},""topic"":{""0"":-1,""1"":-1,""10"":-1,""11"":2,""12"":2,""13"":-1,""14"":3,""15"":3,""16"":-1,""17"":-1,""18"":-1,""19"":-1,""2"":-1,""20"":-1,""21"":-1,""22"":-1,""23"":1,""24"":-1,""25"":-1,""26"":2,""27"":0,""28"":0,""29"":-1,""3"":3,""30"":0,""31"":1,""32"":-1,""33"":-1,""34"":0,""35"":-1,""36"":-1,""37"":-1,""38"":2,""39"":0,""4"":-1,""40"":-1,""41"":0,""42"":-1,""43"":-1,""44"":-1,""45"":1,""46"":-1,""47"":0,""48"":-1,""49"":3,""5"":-1,""50"":-1,""51"":-1,""52"":-1,""53"":1,""54"":-1,""55"":1,""56"":-1,""57"":0,""58"":-1,""59"":-1,""6"":-1,""7"":2,""8"":3,""9"":-1},""vector"":{""0"":""[ 2.365918  -2.1458666  3.3052337  2.92312    6.2759256  1.570666\n -1.5184945  2.6690867 -0.8237069  2.7094579]"",""1"":""[ 2.619289   -2.4493902   3.4557016   2.7310445   6.130289    2.1869214\n -2.0975702   2.897233   -0.68794036  2.4537957 ]"",""10"":""[ 2.4226177 -1.8131133  3.7136798  2.6534824  5.6724415  1.914728\n -1.3769691  2.619668  -1.2131653  2.7712758]"",""11"":""[ 1.9442677 -1.8043206  3.610208   3.0737813  6.4203477  1.8024222\n -1.3402991  2.1361406 -0.777569   2.1972742]"",""12"":""[ 2.576888  -2.0055578  3.5640872  2.9604745  6.2218704  2.3844643\n -1.6146885  1.9860101 -0.950634   2.27878  ]"",""13"":""[ 2.7745476  -2.0498729   3.4701405   2.3116763   6.118836    2.14001\n -1.6075748   2.6569638  -0.40653723  2.6232023 ]"",""14"":""[ 2.859362   -2.4271786   3.5026455   2.896275    5.8985896   2.0436428\n -1.9968252   2.8858125  -0.81614166  2.7155325 ]"",""15"":""[ 2.650957   -2.2310824   3.6803906   3.2376165   6.254267    2.013654\n -1.9552515   2.3712864  -0.97703665  2.3583202 ]"",""16"":""[ 2.1485798  -1.9103109   3.660466    3.1409512   6.190646    1.5566087\n -1.2729565   2.22634    -0.36218086  2.304899  ]"",""17"":""[ 1.9912043  -1.9482627   3.5257006   2.0440662   4.760765    2.6075785\n -0.7728268   2.5869126   0.41495925  2.7206604 ]"",""18"":""[ 2.7738543  -2.0649896   3.7731543   3.0903068   6.2594004   1.7601073\n -1.7001699   2.25668    -0.43259767  2.314975  ]"",""19"":""[ 2.3417046 -1.5132033  3.7793043  2.451121   6.216981   2.553403\n -1.232304   1.7476236 -0.8156799  2.1549501]"",""2"":""[ 2.3298562 -1.4284229  3.9226375  2.219708   5.580221   1.941687\n -1.0563308  2.5397766 -0.9463937  2.720536 ]"",""20"":""[ 2.8224516 -1.7508227  3.7939107  1.9081299  5.72954    2.6114748\n -1.4407142  2.4725637 -0.3763206  2.563833 ]"",""21"":""[ 2.0657723  -1.8939463   3.31682     1.2932476   4.6864653   3.1060138\n -0.64860725  2.7607036   0.81373096  2.750817  ]"",""22"":""[ 2.3626187 -1.8618095  3.735849   3.0891485  6.5613313  1.904011\n -1.6249928  2.0876315 -0.8051638  2.15937  ]"",""23"":""[ 2.208195   -1.2251751   3.825686    1.0297856   5.167554    3.3078847\n -0.53285766  2.0734751   0.11569867  2.461978  ]"",""24"":""[ 2.541107  -1.3246315  3.9405856  1.7822508  5.60924    2.4095662\n -1.0054023  2.3528876 -0.5990498  2.61001  ]"",""25"":""[ 2.2226362  -2.4738927   3.0460434   2.6707451   5.968198    2.1123638\n -1.4529595   2.6400716   0.02416641  2.6596315 ]"",""26"":""[ 1.9249977  -1.9189572   3.4652977   2.871078    6.2999444   1.882095\n -1.4130443   2.4571052  -0.76746356  2.2982857 ]"",""27"":""[ 2.028229   -1.5645897   3.644738    1.3208634   4.429932    3.0245008\n -0.36829212  2.5349984   0.5276382   2.9016824 ]"",""28"":""[ 2.1014497  -1.4195348   3.846974    1.2703437   4.8322687   3.2380738\n -0.64016896  2.282041    0.1673121   2.6196964 ]"",""29"":""[ 2.352158   -2.5801606   3.0089056   2.606939    5.9743032   2.2307353\n -1.6015046   2.764802   -0.12617324  2.740138  ]"",""3"":""[ 2.8951688 -2.3411686  3.6061077  3.1434786  6.1122184  2.0883217\n -2.0477576  2.5306625 -1.09487    2.5727983]"",""30"":""[ 1.8463317  -1.567575    3.5798101   1.7019649   4.6404963   2.5598323\n -0.327718    2.541181    0.30585548  2.8841355 ]"",""31"":""[ 2.1226242  -1.1279014   3.90394     1.7835534   5.325634    2.3549447\n -0.48591864  2.1755707  -0.58774006  2.6518567 ]"",""32"":""[ 2.004627   -1.9814217   3.5063908   2.8327048   5.7169414   1.7887841\n -1.028421    2.3590622   0.06690992  2.4450848 ]"",""33"":""[ 2.1414385 -1.3481162  3.781006   1.4641402  5.3329115  3.0796251\n -0.7689533  2.1110125 -0.2581258  2.4543753]"",""34"":""[ 2.01884    -1.7055285   3.4478834   1.2507123   4.602435    2.9710243\n -0.42243066  2.689893    0.6934417   2.8542154 ]"",""35"":""[ 2.5693672  -2.461385    3.2350645   1.9384874   5.4288945   2.6896093\n -1.4745909   2.9626498   0.46381187  2.7754478 ]"",""36"":""[ 2.012022   -1.2267513   3.8262227   2.0100787   5.4378366   2.276161\n -0.58992743  2.2016523  -0.80133665  2.633384  ]"",""37"":""[ 2.3689873 -2.2403185  3.1526716  2.99732    6.2596383  1.8141735\n -1.4084401  2.3853307 -0.7225782  2.7139153]"",""38"":""[ 2.289552  -1.9684539  3.3801775  3.0236518  6.108583   2.1232626\n -1.2518454  1.9717922 -0.8789275  2.4282477]"",""39"":""[ 2.0287762  -1.6142162   3.841084    1.7000159   4.5291576   2.82227\n -0.66741997  2.5992196   0.13663532  2.8493989 ]"",""4"":""[ 1.837938  -1.616721   3.5397327  2.5677116  5.82571    1.9060696\n -1.0290356  2.4320257 -1.1002659  2.573974 ]"",""40"":""[ 2.2721422 -1.5114723  3.896112   2.1434813  5.2320666  2.143631\n -0.9808681  2.625965  -0.8741738  2.8468912]"",""41"":""[ 1.9384278 -1.7346888  3.5450563  1.5298009  4.582622   2.916372\n -0.502921   2.6013446  0.5242117  2.8075316]"",""42"":""[ 1.8734488  -1.3806361   3.6281374   1.8580136   5.2163014   2.3624785\n -0.46623486  2.2803185  -0.28828216  2.6636343 ]"",""43"":""[ 2.1046445 -1.5041991  3.6341727  2.2998824  5.9850674  2.8060853\n -1.0857943  1.8430982 -0.8289279  2.230032 ]"",""44"":""[ 2.1457918  -1.8544142   3.62624     3.02858     5.943852    1.6850723\n -1.0317401   2.0637307  -0.21596679  2.378296  ]"",""45"":""[ 2.1032627  -1.1972126   3.876065    1.1289726   5.0498085   3.159524\n -0.5118817   2.1447687  -0.06341229  2.5547354 ]"",""46"":""[ 2.2544222  -2.1959176   3.4269664   2.3192575   5.092075    2.388587\n -1.1320156   2.706536    0.33991826  2.6961994 ]"",""47"":""[ 1.8843739  -1.8038507   3.4499998   1.7386745   4.7229      2.7179694\n -0.5490314   2.5969417   0.39876527  2.7571914 ]"",""48"":""[ 2.52999   -2.2938986  3.3344908  1.6729532  5.1908436  2.8704553\n -1.2755108  2.9228315  0.5707703  2.7866142]"",""49"":""[ 2.8164618  -2.3120582   3.449894    2.9600136   6.114274    1.6516415\n -1.7997301   2.770777   -0.73973227  2.7736313 ]"",""5"":""[ 2.5724711  -1.7199273   3.8288033   2.9467437   6.132633    2.1643739\n -1.3209175   1.738712   -0.71669406  2.2335925 ]"",""50"":""[ 2.7275388  -2.180676    3.5922322   2.4606004   5.568227    2.1231327\n -1.544511    2.7626421   0.00832962  2.6155605 ]"",""51"":""[ 2.6344874  -2.288598    3.4274464   1.7766174   5.2652383   2.8200734\n -1.3923631   2.8910472   0.44205096  2.7236066 ]"",""52"":""[ 2.4324732 -2.383977   3.3526032  2.725186   6.154262   1.9712309\n -1.8938409  3.014203  -0.5811071  2.5271792]"",""53"":""[ 2.1956854  -1.15117     3.8675408   1.210479    5.285129    3.0538197\n -0.56050825  2.0776832  -0.20425515  2.4892302 ]"",""54"":""[ 2.1649127  -1.00241     3.904651    1.3109994   5.1781178   2.609406\n -0.35312328  2.2723653  -0.42625898  2.7177525 ]"",""55"":""[ 2.0040953  -1.1914806   3.7266946   1.4199301   5.2200956   2.5671582\n -0.47690606  2.352508   -0.4320414   2.7052932 ]"",""56"":""[ 2.8672664  -2.1841662   3.6910293   2.799328    5.798043    1.933573\n -1.640126    2.5019178  -0.02663009  2.4547315 ]"",""57"":""[ 2.1903517  -1.5849793   3.8886845   1.5911268   4.7079196   3.0291598\n -0.75654864  2.4277976   0.21663858  2.767272  ]"",""58"":""[ 3.061582   -2.273716    3.6701825   2.5689325   6.011856    2.3417373\n -2.0300145   2.6750429  -0.63129514  2.5656269 ]"",""59"":""[ 2.3506653 -1.4693266  3.8262658  2.187091   6.0712485  2.766343\n -1.2069005  1.8270729 -0.6543883  2.1829865]"",""6"":""[ 2.2888448 -2.026072   3.5669167  2.9887586  5.8491826  2.172949\n -1.5663403  2.4277308 -1.2996979  2.5087159]"",""7"":""[ 1.9781874 -1.6488148  3.5571322  2.780446   6.1467566  1.8623838\n -1.1248164  2.1856525 -0.9512818  2.3953223]"",""8"":""[ 3.0589845 -2.2792466  3.58017    3.0618467  6.188048   1.8705567\n -1.8506547  2.3769782 -0.555598   2.5272605]"",""9"":""[ 2.3564632 -1.5532556  3.932082   2.8334796  5.8620963  1.670777\n -0.9548353  1.9790564 -0.4436724  2.4218879]""},""vocab_index"":{""0"":0,""1"":2,""10"":13,""11"":16,""12"":17,""13"":18,""14"":20,""15"":25,""16"":31,""17"":35,""18"":39,""19"":40,""2"":4,""20"":43,""21"":55,""22"":67,""23"":68,""24"":69,""25"":76,""26"":78,""27"":79,""28"":80,""29"":92,""3"":5,""30"":93,""31"":95,""32"":98,""33"":99,""34"":100,""35"":103,""36"":122,""37"":123,""38"":126,""39"":128,""4"":6,""40"":129,""41"":136,""42"":162,""43"":164,""44"":166,""45"":175,""46"":176,""47"":177,""48"":178,""49"":180,""5"":7,""50"":182,""51"":184,""52"":237,""53"":243,""54"":250,""55"":256,""56"":274,""57"":279,""58"":286,""59"":289,""6"":8,""7"":9,""8"":10,""9"":12},""word"":{""0"":""data"",""1"":""user"",""10"":""views"",""11"":""evaluation"",""12"":""tasks"",""13"":""space"",""14"":""users"",""15"":""participant"",""16"":""component"",""17"":""\ufb01rst"",""18"":""item"",""19"":""solving"",""2"":""view"",""20"":""time"",""21"":""helpful"",""22"":""questionnaire"",""23"":""spent"",""24"":""post"",""25"":""eigenvector"",""26"":""application"",""27"":""easy"",""28"":""understood"",""29"":""eigenvectors"",""3"":""participants"",""30"":""parallel"",""31"":""change"",""32"":""cluster"",""33"":""given"",""34"":""useful"",""35"":""ieee"",""36"":""control"",""37"":""coordinates"",""38"":""operations"",""39"":""fairly"",""4"":""insight"",""40"":""majority"",""41"":""better"",""42"":""scatter"",""43"":""brushing"",""44"":""triangle"",""45"":""completed"",""46"":""dif\ufb01culty"",""47"":""little"",""48"":""http"",""49"":""citations"",""5"":""task"",""50"":""university"",""51"":""brian"",""52"":""browser"",""53"":""represents"",""54"":""include"",""55"":""allow"",""56"":""wine"",""57"":""correctly"",""58"":""seconds"",""59"":""answering"",""6"":""interactions"",""7"":""analysis"",""8"":""items"",""9"":""figure""},""word*"":{""0"":""data"",""1"":""user"",""10"":""views"",""11"":""evaluation*"",""12"":""tasks"",""13"":""space"",""14"":""users*"",""15"":""participant"",""16"":""component"",""17"":""\ufb01rst"",""18"":""item"",""19"":""solving"",""2"":""view"",""20"":""time"",""21"":""helpful"",""22"":""questionnaire"",""23"":""spent*"",""24"":""post"",""25"":""eigenvector"",""26"":""application*"",""27"":""easy"",""28"":""understood"",""29"":""eigenvectors"",""3"":""participants*"",""30"":""parallel"",""31"":""change*"",""32"":""cluster"",""33"":""given"",""34"":""useful*"",""35"":""ieee"",""36"":""control"",""37"":""coordinates"",""38"":""operations*"",""39"":""fairly*"",""4"":""insight"",""40"":""majority"",""41"":""better*"",""42"":""scatter"",""43"":""brushing"",""44"":""triangle"",""45"":""completed*"",""46"":""dif\ufb01culty"",""47"":""little*"",""48"":""http"",""49"":""citations*"",""5"":""task"",""50"":""university"",""51"":""brian"",""52"":""browser"",""53"":""represents*"",""54"":""include"",""55"":""allow*"",""56"":""wine"",""57"":""correctly"",""58"":""seconds"",""59"":""answering"",""6"":""interactions"",""7"":""analysis*"",""8"":""items*"",""9"":""figure""},""x2D"":{""0"":-5.5664610863,""1"":-6.84745121,""10"":-4.5558600426,""11"":-4.1432805061,""12"":-4.076022625,""13"":-6.697165966,""14"":-6.5452275276,""15"":-5.8135170937,""16"":-4.5215129852,""17"":-6.3225226402,""18"":-5.4164538383,""19"":-3.4832856655,""2"":-4.2850680351,""20"":-5.0055074692,""21"":-6.2629404068,""22"":-4.3942909241,""23"":-4.7878489494,""24"":-4.2637696266,""25"":-6.0161142349,""26"":-4.4223504066,""27"":-5.8241114616,""28"":-4.9444065094,""29"":-6.3072857857,""3"":-6.0108819008,""30"":-5.9076867104,""31"":-4.2564997673,""32"":-4.7215647697,""33"":-4.5574574471,""34"":-5.9360728264,""35"":-6.877779007,""36"":-4.0348191261,""37"":-5.154238224,""38"":-3.9973676205,""39"":-5.6914601326,""4"":-4.1595163345,""40"":-4.3340339661,""41"":-6.1026272774,""42"":-4.1316719055,""43"":-3.5144717693,""44"":-4.2869253159,""45"":-4.511595726,""46"":-6.8036527634,""47"":-6.2762880325,""48"":-6.8034315109,""49"":-6.313501358,""5"":-3.5877919197,""50"":-6.4265561104,""51"":-6.6711964607,""52"":-6.6425566673,""53"":-4.3943424225,""54"":-4.4589982033,""55"":-4.313598156,""56"":-6.1295847893,""57"":-5.4519495964,""58"":-6.5521745682,""59"":-3.725985527,""6"":-4.7941131592,""7"":-3.8859615326,""8"":-6.3327302933,""9"":-3.9486920834},""y2D"":{""0"":7.0320353508,""1"":7.0979590416,""10"":5.4745640755,""11"":7.0523376465,""12"":7.5945305824,""13"":6.1066436768,""14"":7.1113696098,""15"":7.6119804382,""16"":6.6091985703,""17"":2.6091604233,""18"":7.4651918411,""19"":5.5458693504,""2"":4.8063354492,""20"":4.6453719139,""21"":1.7922948599,""22"":7.3548903465,""23"":2.2071285248,""24"":4.2157888412,""25"":6.0803232193,""26"":6.827726841,""27"":1.7582786083,""28"":2.1171693802,""29"":6.0402817726,""3"":7.4347052574,""30"":2.2760639191,""31"":3.6752359867,""32"":6.1307859421,""33"":2.7115635872,""34"":1.6509168148,""35"":4.3063583374,""36"":3.8425283432,""37"":6.9446897507,""38"":7.1629490852,""39"":2.361856699,""4"":5.6734209061,""40"":4.3436288834,""41"":1.9618206024,""42"":3.3310644627,""43"":5.1301569939,""44"":6.4222559929,""45"":2.2143886089,""46"":4.1043152809,""47"":2.2149372101,""48"":3.6349396706,""49"":7.1149659157,""5"":7.1100993156,""50"":5.6158967018,""51"":3.922535181,""52"":6.8822550774,""53"":2.4749391079,""54"":3.0212993622,""55"":3.2287113667,""56"":6.4533114433,""57"":2.1387541294,""58"":6.7659759521,""59"":5.0013241768,""6"":7.3237333298,""7"":6.692196846,""8"":7.532204628,""9"":6.1242432594}}",False,False,False,http://doi.wiley.com/10.1111/j.1467-8659.2009.01475.x,,iPCA: An Interactive System for PCA-based Visual Analytics,"[-4.82807867e-03 -8.61385241e-02  7.45861456e-02 -2.65238464e-01
  5.09493798e-02 -8.32806945e-01  5.65917678e-02  7.38730669e-01
 -4.03962433e-01  2.27047061e-03 -6.87278509e-01 -2.03711689e-01
  4.34088707e-02  2.62720823e-01  3.10841743e-02  5.53030908e-01
 -6.81991100e-01  6.62546828e-02 -1.24628708e-01  4.29542631e-01
  6.85534656e-01  2.68023293e-02 -2.99007744e-02  2.16250673e-01
  6.99101686e-01  5.55054061e-02 -7.93231372e-03 -4.49131280e-01
 -8.84690881e-01 -2.70795703e-01  2.11816236e-01 -7.45382085e-02
  6.27837181e-02  2.95537487e-02 -5.84202290e-01 -7.08953917e-01
 -1.33176371e-01  1.37654133e-02  6.00967586e-01  4.81520504e-01
 -3.93820763e-01 -2.00682312e-01 -3.62562761e-02  7.62162209e-02
  1.93626553e-01  4.48046714e-01  1.50852904e-01 -1.67134017e-01
 -5.53881586e-01  1.33112267e-01 -4.61062044e-01 -4.09539878e-01
  7.34333754e-01  9.57196429e-02  6.51588440e-01  6.50047287e-02
  2.52850026e-01 -3.58068764e-01 -9.16881025e-01 -1.73193306e-01
 -3.48197073e-01  5.68658948e-01  3.53714347e-01 -2.39828661e-01
  8.18756163e-01 -3.70570943e-02  1.42186284e-01  4.84603852e-01
 -1.05902147e+00  1.27359614e-01 -6.69729039e-02  2.36808181e-01
 -1.50250062e-01  7.98813999e-01  2.80180097e-01  5.56048751e-01
  3.16660367e-02  6.77237630e-01  1.68513849e-01 -5.30812740e-01
 -1.88420251e-01  8.62459838e-02 -2.59140104e-01  9.88765880e-02
 -5.15950546e-02  2.34337747e-01 -3.52569483e-02 -1.67967588e-01
 -8.08617115e-01  7.56982446e-01 -4.33424294e-01  1.71447933e-01
  2.55431116e-01 -5.72116934e-02  9.47715998e-01 -5.70481956e-01
  3.12168151e-01  3.75944525e-02 -4.01636392e-01 -2.21256182e-01
  5.67790031e-01  1.06850885e-01  1.62628777e-02 -3.23463947e-01
 -5.30878425e-01  4.57554787e-01 -1.32949710e-01  3.47549357e-02
 -1.34877980e-01  3.04873973e-01 -2.38451734e-01  5.33794045e-01
 -1.90702081e-01 -9.39414620e-01 -3.44434023e-01  5.60093939e-01
  2.51744896e-01  1.23366356e-01 -1.25949532e-01  3.59850913e-01
  1.30076051e-01  2.00729564e-01  2.44145826e-01  1.28124803e-01
  3.91087770e-01 -1.45245463e-01  2.18142167e-01 -2.95833379e-01
  3.14511180e-01  2.01647133e-02  9.32160556e-01  2.89166927e-01
  1.37130037e-01 -3.79231066e-01  7.93809518e-02  1.20686568e-01
  1.55730948e-01 -4.03111815e-01 -2.81531036e-01  6.06083497e-02
  1.84306696e-01 -7.49115288e-01  1.59558117e-01 -5.97206473e-01
 -5.96615821e-02 -5.55747896e-02 -2.59019136e-01 -4.13725704e-01
 -3.04965824e-01  3.92155945e-02 -2.24585528e-04 -4.38505888e-01
 -1.81366503e-01  7.63192922e-02  8.07304308e-02  3.04611009e-02
  2.94934303e-01 -4.32409197e-02  3.54310632e-01 -5.44746339e-01
  3.73319745e-01  1.66738123e-01 -2.59485006e-01  4.67811078e-02
 -1.36798799e-01  2.39210889e-01 -3.41806293e-01 -1.63442567e-01
  6.75382689e-02 -4.18910421e-02 -4.42282520e-02 -3.12043071e-01
  6.71017528e-01 -1.60371706e-01  5.06690919e-01  6.69150233e-01
  4.11654674e-02  3.03277850e-01  3.23941469e-01  5.21854043e-01
 -7.10457623e-01 -1.37059122e-01 -1.35176465e-01 -8.07719827e-01
  7.77075887e-02  1.79079607e-01  6.61128461e-01 -1.11347161e-01
  3.85275871e-01  7.18700647e-01 -4.02320057e-01 -1.33341357e-01
  9.34245661e-02 -2.71581799e-01  5.44126093e-01 -2.12910607e-01
 -2.42982581e-01 -3.96178544e-01 -8.54851678e-03 -2.47237682e-01
  1.03165321e-01 -7.32845813e-02  2.96090722e-01  3.12328428e-01
 -4.71617520e-01 -1.92742780e-01 -2.10448191e-01 -5.55899322e-01
 -9.86969247e-02 -3.01046193e-01 -3.33043009e-01  4.47655797e-01
 -1.28824428e-01  2.44749054e-01 -2.60630816e-01  4.13286984e-01
 -9.72004980e-02 -1.78218573e-01 -6.45122603e-02  2.05185980e-01
  5.77756226e-01  3.34731251e-01  6.15696847e-01  1.55496776e-01
  2.50425160e-01  9.56627429e-01 -1.03581570e-01  3.04973200e-02
  8.21519136e-01  4.80271071e-01 -3.65763158e-01  9.42427069e-02
  3.95261765e-01  5.12290478e-01  4.45241809e-01  3.47159892e-01
 -4.30451989e-01 -2.72296458e-01  8.20266753e-02 -2.09089682e-01
 -1.02849118e-01  3.61723304e-01  3.05654883e-01  4.12190408e-01
  2.45785639e-01  2.93794245e-01 -3.24611694e-01 -1.26468748e-01
 -1.92341134e-01 -3.92457604e-01  1.98644787e-01  5.74928164e-01
 -5.81306934e-01 -5.29802918e-01 -3.69289011e-01  2.27942914e-02
 -5.69314659e-01 -2.43816972e-01 -1.88504174e-01  4.49024737e-01
  1.38334380e-02  2.87222862e-01 -2.05350995e-01 -2.76310205e-01
 -2.36702323e-01 -3.83555055e-01  4.31412935e-01 -2.85395831e-01
  3.59491736e-01 -8.74684080e-02 -4.33078110e-01 -3.95195812e-01
 -4.00222927e-01  7.70101070e-01  2.18475796e-02 -1.22317724e-01
  4.36140075e-02 -4.13016587e-01 -3.47970650e-02  4.88131911e-01
  1.54716402e-01 -1.35208175e-01 -1.41170353e-01 -9.79205128e-03
 -4.75846469e-01 -1.58137128e-01  3.01600546e-01  1.04096167e-01
 -2.13482782e-01  6.53660074e-02 -1.27654994e+00  1.92117542e-01
 -2.03269750e-01 -1.95738733e-01  9.67177749e-01  1.81522101e-01
  8.02537650e-02  1.29760697e-01 -6.29125774e-01 -3.08342963e-01
 -7.94899762e-02 -5.87742805e-01  1.62367299e-01  2.46902049e-01
 -5.43659888e-02  8.96648169e-01 -3.68689626e-01 -6.51547790e-01
 -3.51038551e+00 -5.20264730e-02 -6.88104987e-01 -1.14516936e-01
 -1.46631315e-01 -1.23049662e-01  1.92568570e-01 -4.54901785e-01
  6.91919997e-02 -6.55476153e-01 -1.26773104e-01 -1.96890756e-01
  1.53041035e-01  3.56500447e-01 -1.85702201e-02  6.07871413e-01
  3.43621761e-01  2.27791533e-01 -2.01869965e-01  2.32938766e-01
 -2.07579434e-01  9.66314226e-02 -1.21236257e-01 -5.13033569e-01
  2.31709704e-01  6.26890421e-01 -5.51503241e-01  2.99089521e-01
 -2.41478398e-01 -2.21074641e-01 -1.67594373e-01 -3.15406829e-01
 -4.22653854e-01  5.68803012e-01 -2.31200069e-01 -3.65235895e-01
 -2.34750286e-01 -7.89545476e-02 -3.73926125e-02 -2.36015305e-01
 -6.45323098e-02 -1.73201993e-01 -4.44249302e-01 -4.34449911e-01
  1.25168598e+00 -7.56209016e-01  3.12885307e-02  3.93695652e-01
 -1.60308369e-02  3.64222914e-01 -2.11582780e-01 -6.32641554e-01
  3.23893040e-01 -2.48482361e-01 -1.29847705e-01 -7.43490607e-02
  3.59180421e-01  7.05038071e-01 -3.21396679e-01 -4.88293350e-01
  8.30779433e-01 -3.17487836e-01  1.05182000e-01 -1.95747122e-01
 -4.15350765e-01 -3.81769866e-01 -6.26719534e-01 -8.76351953e-01
 -4.56025094e-01 -5.82419991e-01 -5.08567452e-01  1.21622038e+00
 -2.38706395e-01 -5.98835886e-01  4.16594595e-02 -7.13716507e-01
  3.08173716e-01  2.36231610e-01 -5.28701007e-01 -4.29196626e-01
 -1.84212089e-01  1.11816369e-01 -4.79254544e-01  1.70972526e-01
 -4.97557878e-01 -5.75097688e-02 -3.02165151e-01 -8.48741233e-01
 -1.03363979e+00 -4.44157958e-01 -1.65484026e-01  5.84891178e-02
  4.15627122e-01  3.69208343e-02 -1.28395945e-01 -5.76029718e-02
  1.00828135e+00  2.72620171e-01  2.40222469e-01 -1.37491703e-01
  5.30184805e-01  1.35106266e-01  7.63978660e-01 -2.83510029e-01
 -4.40495729e-01 -1.96559697e-01 -6.50500715e-01 -1.74017608e-01
 -7.23059699e-02 -4.40704495e-01 -1.57457560e-01 -5.87495416e-02
 -5.22917271e-01 -1.16691597e-01 -1.59817547e-01 -1.42052412e-01
  1.77694559e-02 -3.90788540e-02  5.05877733e-01 -2.37578824e-01
 -5.59696257e-01 -1.91217195e-02 -2.52243221e-01  1.93222746e-01
  6.74839735e-01 -3.05233657e-01  1.02689780e-01 -3.94957781e-01
 -1.42690778e-01  2.00537685e-03 -1.12522028e-01  9.32516307e-02
  2.28031799e-02  1.70652598e-01 -2.07178414e-01 -5.84790707e-01
  3.84107120e-02 -2.07459703e-01  2.12980464e-01  3.06420997e-02
  1.62108496e-01  7.93842852e-01 -4.35457468e-01 -2.59753078e-01
  3.57069932e-02  3.93642843e-01  1.18204176e-01  9.35276568e-01
 -3.53150100e-01 -8.64429548e-02 -4.41864580e-01 -5.18742085e-01
 -5.31650305e-01 -2.66440630e-01  2.90345430e-01 -1.60092413e-01
  5.84866405e-01  4.65802848e-01 -6.25697374e-01 -2.43277192e-01
 -1.80139631e-01 -2.64153093e-01 -1.02706939e-01  3.54371369e-01
 -1.69062078e-01 -1.90961361e-02  2.10934281e-01 -1.41037712e-02
  4.16007265e-02 -1.14192605e+00 -2.11822450e-01  7.40851045e-01
  5.40056944e-01 -2.24831924e-01  3.49095881e-01  2.23466262e-01
  1.57448456e-01 -2.66902298e-02  4.44087267e-01  1.93580896e-01
 -3.40307593e-01 -1.20996371e-01  2.20721468e-01 -8.53211209e-02
 -1.69268191e-01 -3.29327234e-03  7.07320422e-02  2.13284567e-01
  5.41981637e-01  6.76783502e-01 -3.74605834e-01  2.00123385e-01
 -1.18747197e-01 -4.73554254e-01 -5.28466888e-02 -8.91941249e-01
  2.75150061e-01 -8.05855393e-01 -1.62228629e-01  4.70194727e-01
 -1.14695504e-01  1.11612387e-01 -8.64349306e-01  3.20655048e-01
 -4.65650320e-01  2.81104833e-01 -2.63059974e-01 -6.00612834e-02
  2.36985281e-01  1.66942880e-01 -4.13758546e-01 -2.77607292e-01
  2.59074401e-02 -2.89062321e-01  4.36419517e-01  3.29669088e-01
 -4.22616154e-01  2.48785079e-01 -7.25029588e-01  1.77991852e-01
  2.09387049e-01  4.64813143e-01  8.35554361e-01 -2.89300948e-01
 -4.45003882e-02  4.12018687e-01  3.18360358e-01 -6.97605982e-02
 -4.85319704e-01 -1.43660933e-01 -7.35659525e-02 -5.13824940e-01
  1.45433191e-03 -6.57025218e-01 -5.14681816e-01 -4.87930387e-01
 -6.69326544e-01 -2.62477696e-01  3.66165817e-01 -7.83980131e-01
  8.47016424e-02 -3.18582773e-01 -4.31411892e-01 -3.28305334e-01
 -6.09805584e-01 -2.84042601e-02 -2.69754857e-01  2.08758876e-01
 -1.85582921e-01 -1.75886780e-01  5.77380136e-03 -4.72066224e-01
 -4.65889931e-01 -5.05387425e-01  6.73122048e-01 -4.52558547e-01
 -5.04614592e-01  5.74821932e-03  2.34881192e-01  1.36158122e-02
  1.42987296e-01  4.69902996e-03  1.15476854e-01  6.77212119e-01
 -2.80155003e-01 -2.62316108e-01 -1.28075272e-01 -1.68122929e-02
  1.85876787e-01 -7.57744551e-01 -4.31041181e-01  3.18389386e-01
 -1.88718855e-01  5.33591986e-01  5.26905417e-01  4.15468991e-01
 -1.29709855e-01 -4.10306156e-01 -2.38463953e-01 -4.84066427e-01
 -6.47237420e-01 -2.18262784e-02 -5.43672554e-02  2.58908421e-01
  3.32650065e-01 -5.43739140e-01 -4.44766395e-02  5.25625050e-01
  2.33677775e-01 -3.06648850e-01  2.31813043e-01  4.39937860e-01
 -3.59059200e-02  3.11726391e-01 -2.55930781e-01  4.96395648e-01
  8.85717154e-01  9.45108905e-02  1.60876483e-01  1.01465341e-02
 -2.88264006e-01  3.30905467e-01  5.28103232e-01  1.86871856e-01
  2.99794763e-01  8.77985954e-02 -9.80384126e-02 -1.72047123e-01
  1.78372920e-01 -1.42332658e-01 -1.71126015e-02  1.93106949e-01
  5.33847868e-01  1.03510702e+00  2.63376124e-02 -4.59289581e-01
 -1.12467301e+00 -2.10089982e-01 -3.45117658e-01 -4.33658183e-01
 -8.81664976e-02 -7.09965602e-02  4.65613544e-01  1.14505947e-01
 -3.98872972e-01 -2.13503897e-01 -2.91967094e-01  6.79572448e-02
  6.63679242e-02 -4.70747024e-01 -5.44190764e-01  3.71879429e-01
 -1.22445785e-01  3.42282444e-01 -8.03049877e-02 -9.11287367e-02
 -2.29008108e-01 -2.09376216e-01  3.76272082e-01  1.97706625e-01
 -3.87226254e-01  6.76212132e-01  4.99023318e-01  4.45841670e-01
 -1.85618475e-01  4.66886386e-02 -5.06873488e-01  8.65030065e-02
  8.38492140e-02 -1.74820691e-01 -1.64691031e-01  6.35989070e-01
 -2.88221408e-02  3.17995906e-01  2.79761493e-01 -7.62233436e-02
  8.97876024e-01  4.11468521e-02 -3.23707312e-02  2.76803613e-01
  1.83904156e-01  3.05075794e-01 -2.88079709e-01 -4.13086772e-01
 -1.06813088e-01  7.04837143e-02  5.87996244e-01 -4.30054277e-01
 -3.02108694e-02  5.59984386e-01  1.61514193e-01  2.87404895e-01
 -2.41535529e-01 -6.32007182e-01 -5.82342334e-02  1.92730308e-01
  1.85309872e-01 -2.36894548e-01 -6.11658454e-01 -1.29557192e-01
 -3.39324683e-01 -3.19251716e-01 -9.40820336e-01  2.06853058e-02
  5.34431219e-01 -4.40866083e-01  2.36593932e-01 -3.23668510e-01
 -1.54754043e-01 -9.54980552e-01 -5.85127294e-01  3.99205714e-01
  5.61174333e-01  2.54278421e-01 -1.35206223e-01  1.63861707e-01
  4.17191207e-01  3.13709617e-01  4.76647943e-01 -4.60819334e-01
 -3.97277981e-01 -2.60399789e-01 -3.15943897e-01  5.15812337e-01
  1.36000276e-01 -3.71035695e-01 -4.74426448e-02 -1.46497712e-01
 -2.92191833e-01 -2.52003908e-01 -4.10531741e-03  3.09309512e-01
 -1.07853577e-01  4.74447250e-01  2.45103657e-01  1.58585951e-01
  7.00568035e-02  2.33066559e-01 -7.38953426e-02  3.40585746e-02
  4.60049450e-01 -2.64215022e-01  1.80847403e-02  5.68304956e-01
  2.59241134e-01 -6.38725877e-01 -2.49869257e-01  6.55560791e-02
 -8.63580704e-02  1.75882608e-01 -5.15113592e-01 -1.59811944e-01
  1.75248474e-01  2.81650394e-01 -4.03691381e-02 -4.91932839e-01
  1.08118087e-01  2.78272510e-01  1.62656635e-01  1.93557143e-03
 -8.83211315e-01  1.01934411e-01  2.52588727e-02  4.82923836e-02
 -3.83217663e-01  3.85759652e-01  3.46991450e-01 -9.78647396e-02
 -7.75766596e-02 -2.19388872e-01 -1.76240936e-01  9.06260237e-02
 -7.66742229e-01 -7.32441545e-01 -1.41977668e-01  3.84469293e-02
 -1.35227963e-01 -4.88842130e-01 -2.55635440e-01  3.02160650e-01]",VUUD5TST,False,False,"[6.330516815185547, 0.22321876883506775]"
LPYLPDEE,6YINZH2N,"Semantic Interaction for Visual Text Analytics 
Chris North 
Alex Endert 
Virginia Tech 
Virginia Tech 

Patrick Fiaux 
Virginia Tech 

Blacksburg, VA USA 

aendert@vt.edu 

Blacksburg, VA USA 

pfiaux@vt.edu 

 

Blacksburg, VA USA 

north@vt.edu 

by 

For 

through 

ABSTRACT 
Visual analytics emphasizes sensemaking of large, complex 
datasets 
interactively  exploring  visualizations 
generated 
example, 
statistical  models. 
dimensionality  reduction  methods  use  various  similarity 
metrics to visualize textual document collections in a spatial 
metaphor,  where  similarities  between  documents  are 
approximately  represented  through  their  relative  spatial 
distances  to  each  other  in  a  2D  layout.  This  metaphor  is 
designed to mimic analysts’ mental models of the document 
collection  and  support  their  analytic  processes,  such  as 
clustering similar documents together. However, in current 
methods, users must interact with such visualizations using 
controls  external  to  the  visual  metaphor,  such  as  sliders, 
menus, or text fields, to directly control underlying model 
parameters  that  they  do  not  understand  and  that  do  not 
relate  to  their  analytic  process  occurring  within  the  visual 
metaphor.  In  this  paper,  we  present  the  opportunity  for  a 
new  design  space  for  visual  analytic  interaction,  called 
semantic  interaction,  which  seeks  to  enable  analysts  to 
spatially interact with such models directly within the visual 
metaphor using interactions that derive from their analytic 
process,  such  as  searching,  highlighting,  annotating,  and 
repositioning  documents.  Further,  we  demonstrate  how 
semantic  interactions  can  be  implemented  using  machine 
learning 
tool,  called 
ForceSPIRE, for interactive analysis of textual data within 
a  spatial  visualization.    Analysts  can  express  their  expert 
domain knowledge about the documents by simply moving 
them,  which  guides  the  underlying  model  to  improve  the 
overall layout, taking the user’s feedback into account. 
Author Keywords 
Visualization; visual analytics; interaction 
ACM Classification Keywords 
H5.m.  Information  interfaces  and  presentation  (e.g.,  HCI): 
Miscellaneous.  
General Terms 
Design; Human Factors; Theory 

in  a  visual  analytic 

techniques 

 
Permission to  make digital or hard copies of all or part of this work for 
personal or classroom use is granted without fee provided that copies are 
not made or distributed for profit or commercial advantage and that copies 
bear this notice and the full citation on the first page. To copy otherwise, 
or  republish,  to  post  on  servers  or  to  redistribute  to  lists,  requires  prior 
specific permission and/or a fee. 
CHI’12, May 5–10, 2012, Austin, Texas, USA. 
Copyright 2012 ACM 978-1-4503-1015-4/12/05...$10.00. 
 

 

INTRODUCTION 
Visual analytics bases its success on combining the abilities 
of statistical models, visualization, and human intuition for 
users to gain insight into large, complex datasets [23]. This 
success often hinges on the ability for users to interact with 
the  information,  manipulating  the  visualization  based  on 
their  domain  expertise,  interactively  exploring  possible 
connections, and investigating hypotheses. It is through this 
interactive exploration that users are able to make sense of 
complex  datasets,  a  process  referred  to  as  sensemaking 
[19].  
The  two  primary  parts  of  sensemaking  are  foraging  and 
synthesis. Foraging refers to the stages of the process where 
users filter and gather collections of interesting or relevant 
information.  Then,  using  that  information,  users  advance 
through  the  synthesis  stages  of  the  process,  where  they 
construct  and  test  hypotheses  about  how  the  foraged 
information  may  relate  to  the  larger  plot.  Tools  exist  that 
support users for either foraging or synthesis – but not both. 
In  this  paper  we  present  semantic  interaction,  combining 
the  foraging  abilities  of  statistical  models  with  the  spatial 
synthesis abilities of analysts. Semantic interaction is based 
on the following principles: 
1. Visual  “near=similar”  metaphor  supports  analysts’ 
spatial  cognition,  and  is  generated  by  statistical  models 
and similarity metrics. [22] 

2. Use  semantic  interactions  within  the  visual  metaphor, 
based  on  common  interactions  occurring  in  spatial 
analytic  processes  [4]  such  as  searching,  highlighting, 
annotating, and repositioning documents.  

3. Interpret  and  map  the  semantic  interactions  to  the 
underlying parameters of the model, by updating weights 
and adding information. 

4. Shield  the  users  from  the  complexity  of  the  underlying 

mathematical models and parameters. 

5. Models  learn  incrementally  by  taking  into  account 
interaction during the entire analytic process, supporting 
analysts’ process of incremental formalism [10]. 

6. Provide  visual  feedback  of  the  updated  model  and 

learned parameters within the visual metaphor. 

7. Reuse  learned  model  parameters  in  future  or  streaming 

data within the visual metaphor. 

To  demonstrate  the  concept  of  semantic  interaction,  we 
present  a  prototype  visual  analytics  tool,  ForceSPIRE,  for 
spatial analysis of textual information. In ForceSPIRE, the 
user  interaction  takes on  a deeper,  more  integrated role in 

the  exploratory  spatial  analytic  process.  This  is  done 
through capturing the semantic interaction, interpreting the 
analytical  reasoning  associated  with  the  interaction,  and 
updating the statistical model, and ultimately updating the 
spatialization.  Hence,  users  are  able  to  leverage  semantic 
interaction  to  explore  and  analyze  the  data  interactively, 
while  the  system  is  responsible  for  properly  updating  the 
underlying statistical model.  
RELATED WORK 
Foraging Tools 

 

Figure  1.  A  model  of  interaction  with  foraging  tools.  Users 
interact  directly  with  the  statistical  model  (red),  then  gain 
insight  through  observing  the  change  in  the  visualization 
(blue). 
We  categorize  foraging  tools  by  their  ability  to  pass  data 
through  complex  statistical  models  and  visualize  the 
computed structure of the dataset for the user to gain insight 
(Figure  1).  Thus,  users  interact  with  these  tools  primarily 
through directly manipulating the parameters of the model 
used  for  computing  the  structure.  As  such,  users  are 
required  to  translate  their  domain  expertise  and  semantics 
about  the  information  to  determine  which  (and  by  how 
much) to adjust these parameters. The following examples 
further describe this category of tools. 
Visualizations such as IN-SPIRE’s “Galaxy View” (shown 
in  Figure  3)  present  users  with  a  spatial  layout  of  textual 
information where similar documents are proximally close 
to  one  another  [25].  An  algorithm  creates  the  layout  by 
mapping the high-dimensional collection of text documents 
down  to  a  two-dimensional  view.  In  these  spatializations, 
the  spatial  metaphor  is  one  from  which  users  can  infer 
meaning  of  the  documents  based  on  their  location.  The 
notion  of  distance  between  documents  represents  how 
similar the two documents are (i.e., more similar documents 
are  placed  closer  together).  For  instance,  a  cluster  of 
documents  represents  a  group  of  similar  documents,  and 
documents  placed  between  two  clusters  implies  those 
documents are connected to both clusters. These views are 
beneficial  as  they  allow  users  to  visually  gain  a  quick 
overview  of  the  information,  such  as  what  key  themes  or 
groups  exist  within  the  dataset.  The  complex  statistical 
models  that  compute  similarity  between  documents  are 
based on the structure within the data, such as term or entity 
frequency. In order to interactively change the view, users 
are  required  to  directly  adjust  keyword  weights,  add  or 
remove documents/keywords, or provide more information 
on how to parse the documents for keywords/entities upon 
import. 

 

to  a 

to  understand 

the 

[15].  Through  adjusting 

Similarly, an interactive visualization tool called iPCA uses 
Principal  Component  Analysis  (PCA)  to  reduce  high-
dimensional  data  down 
two-dimensional  plot, 
providing  users  with  sliders  and  other  visual  controls  for 
directly  adjusting  numerous  parameters  of  the  algorithm, 
such  as  individual  eigenvalues,  eigenvectors,  and  other 
components  of  PCA 
the 
parameters,  the  user  can  observe  how  the  visualization 
changes.  This  allows  users  to  gain  insight  into  a  dataset, 
given  they  have  a  thorough  understanding  of  PCA, 
necessary 
the 
changes they are making to the model parameters. 
Alsakran  et  al.  presented  a  visualization 
system, 
STREAMIT,  capable  of  spatially  arranging  text  streams 
based  on  keyword  similarity  [3].  Again,  users  can 
interactively  explore  and  adjust  the  spatial  layout  through 
directly  changing  the  weight  of  keywords  that  they  find 
important.  In  addition,  STREAMIT  allows  for  users  to 
conduct  a  temporal  investigation  of  how  clusters  change 
over time. 
Synthesis Tools 

implications  behind 

 

Figure  2.  A  model  of  interaction  with  synthesis  tools.  Users 
manually  create  a  spatial  layout  of  the  information  to 
maintain and organize their insights about the data. 
Synthesis  tools  focus  on  allowing  users  to  organize  and 
maintain their hypotheses and insight regarding the data in 
a  spatial  medium.  In  large  part,  this  is  done  through 
presenting users with a flexible spatial workspace in which 
they  can  organize  information  through  creating  spatial 
structures,  such  as  clusters,  timelines,  stories,  etc.  (Figure 
2). In doing so, users externalize their thought processes (as 
well  as  their  insights)  into  a  spatial  layout  of  the 
information. 
For example, Analyst’s Notebook [2] provides users with a 
spatial workspace where information can be organized, and 
connections  between  specific  pieces  of  information  (e.g., 
entities, documents, events, etc.) can be created. Similarly, 
The Sandbox [26] enables users to create a series of cases 
(collections  of 
information)  which  can  be  organized 
spatially within the workspace.  
From  previous  studies,  we  found  cognitive  advantages 
associated  with  the  manual  creation  of  a  spatial  layout  of 
the  information  [4].  By  providing  users  a  workspace  in 
which  to  manually  create  spatial  representations  of  the 
information, users were able to externalize their semantics 
of the information into the workspace. That is, they created 
spatial  structures  (e.g.,  clusters,  timelines,  etc.),  and  both 
the structures as well as the locations relative to remaining 
layout  carried  meaning  to  the  users  with  regards  to  their 
sensemaking process. Marshall et al. have pointed out that 

this 

interaction  (and 

From  the  sensemaking  loop  presented  by  Pirolli  and  Card 
[19],  we  learn  that  in  intelligence  analysis,  that  analytic 
process  consists  not  only  of  the  information  that  is 
explicitly  within  the  dataset  being  analyzed,  but  also  the 
domain knowledge of the analyst performing the analysis. It 
is through this domain knowledge that analysts interact and 
explore  the  dataset  to  “make  sense”  of  the  information. 
Thus,  we  believe 
the  domain 
knowledge  associated  with  it)  is  equally  important  as  the 
raw data, and must be incorporated into the visualization by 
tightly coupling the model with the interaction. 
From this body of work, we most notably come away with 
an understanding that 1) analysts fundamentally understand 
the spatial metaphor used in many spatial visualizations, 2) 
many  of  these  systems  are  constructed  using  complex 
mathematical  algorithms  to  transform  high-dimensional 
data  to  two  dimensions,  and  3)  in  most  cases  these 
algorithms  can  be  controlled  by  analysts  largely  through 
visual  controls  (e.g.,  sliders,  knobs,  etc.)  to  directly  adjust 
parameters of the algorithms, updating the spatial layout. 
SEMANTIC INTERACTION 

 

Figure 4. A model of semantic interaction. Users are able to 
interact directly in the spatial metaphor. The system updates 
the corresponding parameters of the statistical model based on 
the analytic reasoning of the users. Finally, the model updates 

the visualization based on the changes, thus unifying the 
synthesis and foraging stages of the sensemaking loop. 

In the purest sense, semantic interaction refers to interaction 
occurring  within  a  spatial  visualization,  with  the  added 
benefit that it is tightly coupled to the model calculating the 
spatial layout (Figure 4). Given the previous work of what 
interaction  in  visual  analytic  tools  is,  semantic  interaction 
occupies a new design space for interaction. It merges the 
ability to change the statistical model while maintaining the 
flexibility  and  familiar  methods  for  interacting  within  the 
metaphor  of  spatial  visualizations.  Users  can  benefit  from 
semantic  interactions  in  that  they  can  interact  within  a 
metaphor  which 
they  are  familiar  with,  performing 
interactions  which  are  part  of  the  spatial  analytic  process 
[4], without having to focus on formal updates to the model.  
Semantic  interaction  leverages  the  cognitive  connection 
formed  between  the  user  and  the  spatial  layout.  The 
following intelligence analysis scenario is representative of 
the strategies and interactions of analysts when performing 
an  intelligence  analysis  task  of  textual  documents  in  a 
spatial visualization, as previously found by Andrews et al. 
[4],  and  further  motivates  and  explains  the  concept  of 
semantic interaction: 

 
Figure  3.  The  IN-SPIRE  Galaxy  View  showing  a 
spatializtiation  of  documents  represented  as  dots.  Each 
cluster of dots represents a group of similar documents.  
 
allowing users to create such informal relationships within 
information  is  beneficial,  as  it  does  not  require  users  to 
formalize these relationships [17].  
From this related work, we believe a trend is emerging in 
how interaction is currently handled in many visual analytic 
systems where complex statistical models are used – users 
are  required  to  go  outside  of  the  metaphor.  That  is,  while 
the  visual  representation  given  to  users  is  spatial,  the 
methods of interaction require users to step outside of that 
metaphor  and  interact  directly  with  the  parameters  of  the 
statistical model using visual controls, toolbars, etc.  
There  has  been  some  work  in  providing  more  easy  to  use 
interactions  for  updating  statistical  models.  For  example, 
relevance feedback has been used for content-based image 
retrieval, where users are able to move images towards or 
away  from  a  single  image  in  order  to  portray  pair-wise 
similarity  or  dissimilarity  [24].  From  there,  an  image 
retrieval algorithm determines the features and dimensions 
shared between the images that the user has determined as 
being  similar.  We  view  this  as  one  example  where  the 
interaction stays in the spatial metaphor of the visualization.  
Also, spatializations of document sets exist that allow users 
to place “points of interest” into the spatial layout. In VIBE, 
users are allowed to define multiple points of interest in the 
spatial  layout  that  correspond  to  a  series  of  keywords 
describing  a  subject  matter  of  interest  to  the  user  [18]. 
Similarly,  Dust  &  Magnet  [27]  allows  users  to  place  a 
series  of  “magnets”  representing  keywords  into  the  space 
and observe how documents are attracted or repelled from 
the  locations  of  these  magnets.  Through  both  of  these 
systems, users can interact in the spatial metaphor through 
these  placements  of  “nodes”  representing  keywords. 
However, the focus of semantic interaction is on interacting 
with  data  (i.e.,  documents),  an 
important  distinction 
discussed in the following section. 

 

 

 
Figure  5.  (top)  The  basic  version  of  the  “visualization 
pipeline”.  Interaction  can  be  performed  on  directly  the 
Algorithm  (blue  arrow)  or  the  data  (red  arrow).  (bottom) 
Our  modified  version  of 
for  semantic 
interaction,  where  the  user  interacts  within  the  spatial 
metaphor (purple arrow). 

the  pipeline 

During her analysis, an intelligence analyst finds a 
suspicious  and 
interesting  phrase  within  a 
document. While reading through the document, she 
highlights  the  phrase  “suspicious  individuals  were 
spotted  at  the  airport”,  in  order  to  more  easily 
recall  this  information  later.  After  she  finishes 
reading the document, she moves the document into 
the  bottom  right  corner  of  her  workspace,  in  the 
proximity of other documents related to an event at 
an airport. To remind herself of her hypothesis, she 
annotates  the  document  with  “might  be  related  to 
Revolution  Now  terrorist  group”.  Now,  with  the 
goal  of 
the 
“airport”, she searches for the term, continuing her 
investigation. 

further  examining 

the  events  at 

investigating 

that  each  of 

instead  point  out 

the  analytic  process  of 

In addition to the three forms of semantic interaction in the 
scenario,  Table  1  provides  a  list  of  various  forms  of 
semantic  interaction,  including  how  each  can  be  used 
within 
textual 
information  spatially.  We  do  not  claim  that  this  list  is 
complete,  but 
these 
interactions  can  relate  to  a  user’s  reasoning  within  the 
analytic process.  
Designing for Semantic Interaction 
In order for analysts to interact with information in a spatial 
metaphor, it must first be created. Following the model of 
the visualization pipeline [13], this creation calls for a series 
of  mathematical  transformations,  turning  raw  data  into  a 
spatial  layout  –  much  the  way  many  of  the  visualizations 
mentioned  previously  are  constructed.  However,  these 
visualizations  fit  this  model,  as  their  user  interactions  are 
primarily  focused  on  directly  modifying  the  statistical 
model  (as  well  as  other  attributes  of  the  visualization  or 
data  transformation).  Designing  for  semantic  interaction 
requires  a  fundamentally  different  model  for  how  tools 
integrate  user  interaction  –  one  that  can  capture  the 
interaction,  interpret  the  associated  analytical  reasoning, 
and update the appropriate mathematical parameters.  
Figure  5  illustrates  this  model,  where  the  spatialization  is 
treated  a  medium  through  which  the  user  can  perceive 

 

Figure 6. Overview of how nodes and edges in ForceSPIRE’s 
force-directed layout are created from documents (Doc) and 
entities (Ent), respectively.  

 

 

it 

interaction, 

information  and  gain  insight,  as  well  as  interact  and 
perform  his  analysis.  Through  expanding  the  pipeline  to 
accommodate  for  semantic 
is  a  more 
appropriate match to the user’s sensemaking process. 
Capturing the Semantic Interaction 
A  non-trivial  first  step  in  the  model  is  capturing  the  user 
interaction.  Much  research  has  been  done  in  this  area, 
primarily  for  the  purpose  of  maintaining  process  history 
(e.g., [5], [21], [12], etc.). When considering how to capture 
interaction,  one  decision  to  be  made  is  at  what  “level”  to 
capture  it.  For  example,  GlassBox  [6]  captures  interaction 
at a rudimentary level (i.e. mouse clicks and key strokes), 
while  Graphical  History  [14]  keeps  track  of  a  series  of 
previous  visualizations  as  a  user  changes  the  visualization 
during the exploration of the data.  
Semantic  interaction  is  captured  at  a  data  level,  as  the 
interactions  occur  on  the  data,  and  within  the  spatial 
metaphor.  Using 
the 
interaction being captured would be: 

the  earlier  analytic  scenario, 

•  The highlighted phrase 
•  When the highlighting occurs (timestamp) 
•  The color chosen for the highlight 
•  The document in which the highlight occurs 
•  The new document location 
•  The text of the annotation 

By  capturing  (and  storing)  the  interaction  history,  we  can 
interpret the analytical reasoning of the user. Thus, we not 
only capture the interaction, but also use it. 
Interpreting the Associated Analytical Reasoning 
In interpreting the interaction, the goal is for the system to 
determine  the  analytical  reasoning  associated  with  the 
interactions  and  update  the  model  accordingly.  From 
previous findings [4], we can associate analytical reasoning 
with  forms  of  semantic  interaction  (see  Table  1).  It  is 
essentially the model’s task to determine  why, in terms of 
the data, the interaction occurred. To answer this question, 
we do not propose that this model can accurately gauge user 
intent.  Instead,  the  goal  is  to  calculate,  based  on  the  data, 

Figure 7. Using ForceSPIRE on a 32 megapixel large, 
high-resolution display. 

 

 
what information is consistent with the captured interaction. 
For  instance,  we  associate  text  highlighting  with  adding 
importance to the text being highlighted. We do not claim 
that we can associate the interaction of highlighting to the 
intuition that spurred the analyst to highlight the text, which 
is far more challenging, and arguably impossible. 
We refer to the captured and interpreted interactions as soft 
data, in comparison to the hard data that is extracted from 
the raw textual information (e.g., term or entity frequency, 
titles,  document  length,  etc.).  We  define  soft  data  as  the 
stored result of user interaction as interpreted by the system. 
In  representing  interaction  as  soft  data,  the  algorithm  can 
calculate  and  reconfigure  the  spatial  layout  accordingly. 
Figure  5  illustrates  how  our  approach  differs  from  the 
traditional visualization pipeline. 
There has been previous work in capturing and interpreting 
reasoning from user interaction. For instance, Dou et al. [7] 
performed  a  study  where  financial  analysts  were  asked 
analyze  a  dataset  using  WireVis,  an  interactive  financial 
transaction visualization. The tool developers then analyzed 
the captured interaction, and assumptions were made about 
the  reasoning  of  the  analysts  at  specific  points  in  the 
investigation. These results were compared to the analysts’ 
self-recorded  reasoning,  and  found  to  be  accurate  up  to 
82%. While our work has similar goals (i.e., interpreting the 
analytical reasoning associated with the analysts through an 
evaluation  of  the  interaction)  our  model  does  so  through 
tightly  integrating  the  interaction  with  the  underlying 
mathematical model. In doing so, the interpretation can be 
done algorithmically. 
Updating the Underlying Model 
Through  metric  learning  of  distance  weights,  the  layout 
uses  the  soft  data  to  update  the  underlying  model. 
Depending  on  the  algorithm  used  to  compute  the  spatial 
layout,  the  precise  parameters  being  updated  will  vary.  In 
general,  this  will  refer  to  weighting  of  a  combination  of 
dimensions  that  will  help  guide  the  model  as  to  which 
dimensions the user finds important.  
FORCESPIRE: SYSTEM OVERVIEW 
ForceSPIRE  is  a  visual  analytics  prototype  designed  for 
specific 
(document 
movement,  text  highlighting,  search,  and  annotation)  for 

forms  of 

interaction 

semantic 

 

Figure  8.  Moving  the  document  shown  by  the  arrow, 
ForceSPIRE  adapts  the  layout  accordingly.  Documents 
sharing entities with the document being moved follow. 

 

interactively exploring textual data. The system has a single 
spatial  view  (shown  in  Figure  12),  where  a  collection  of 
documents is represented spatially based on similarity (i.e., 
documents closer together are more similar).  
ForceSPIRE is designed for large, high-resolution displays 
(such  as  the  one  shown  in  Figure  7).  As  semantic 
interaction emphasizes the importance of context in which 
the  interaction  takes  place  (e.g.,  highlighting  text  in  the 
context  of  the  document),  having  the  full  detail  text 
available  in  the  context  of  the  spatial  layout  is  beneficial 
over having a single document viewer. Further, the physical 

Table  1.  Forms  of  semantic  interaction.  Each  interaction 
corresponds  to  reasoning  of  users  within  the  analytic 
process. 

Form of Semantic 

Interaction 

Document Movement 

Text Highlighting 

Pinning  Document 
Location 
Annotation, “Sticky Note” 

to 

Document Coloring 

Level of Visual Detail 

Query Terms 
 

Associated Analytic Reasoning 

• Similarity/Dissimilarity 
• Create 

spatial  construct 

timeline, list, story, etc) 

• Test 

hypothesis, 

see 
document “fits” in region 

(.e.g 

how 

• Mark 

importance  of  phrase 

(collection of entities) 

• Augment  visual  appearance  of 

document for reference 

to 

in 

• Give 

semantic  meaning 

space/layout 

• Put 

semantic 

information 

workspace, within context 
• Create visual group/cluster 
• Mark group membership 
• Change 

ease 

of 

visually 
referencing  information  (e.g.  full 
detail = more important = easy to 
reference) 

• Expressive search for entity 

(and 

to  match 

is  positioning 

Semantic Interaction in ForceSPIRE 
The  semantic  interactions  in  ForceSPIRE  are:  placing 
information  at  specific  locations,  highlighting,  searching, 
and annotating in order to incrementally change the spatial 
layout 
their  mental  model.  The  primary 
parameters  of  the  force-directed  model  that  are  being 
updated  through  this  learning  model  are  the  importance 
values of the entities.  
Document  Movement.  The  predominant  interaction  in  a 
spatial  workspace 
repositioning) 
documents.  In  previous  work,  we  have  demonstrated  how 
users can perform both exploratory and expressive forms of 
this type of interaction [9]. In ForceSPIRE, we allow for the 
following  exploratory  interaction  (i.e.,  interaction  that 
allows users to explore the structure of the current model, 
but  does  not  change  it).  Users  are  able  to  interactively 
explore the information by dragging a document within the 
workspace, pinning a document to a particular location (see 
Figure  8),  as  well  as  linking  two  documents.  When 
dragging a document, the force-directed system responds by 
finding the lowest energy state of the remaining documents 
given  the  current  location  of  the  dragged  document. 
Mathematically, this adds a constraint to the stress function 
being  optimized  (in  this  case  the  force-directed  model). 
This  allows  users  to  explore  the  relationship  of  that 
document in comparison to the remaining documents.  
In addition to the exploratory dragging of a document, users 
have the ability to pin a document. By pinning a document, 
users  are  able  to  incrementally  add  semantic  meaning  to 
locations in their workspace. By specifying key documents 
to  user-defined  locations,  the  layout  of  the  remaining 
documents will adapt to these constraints. Thus, users can 
explore  how  documents  are  positioned  based  on  their 
similarity  (or  dissimilarity)  to  the  pinned  documents.  For 
instance,  if  the  layout  places  a  document  between  two 
pinned  documents, 
the  particular 
document holds a link between the two pinned documents, 
sharing entities that occur in both. 
Finally,  users  can  perform  an  expressive  form  of  this 
interaction  by  linking  two  documents,  performed  by 
dragging  one  document  onto  another  pinned  document.  In 
doing so, ForceSPIRE calculates the similarity between the 
documents,  and  increases  the  importance  value  of  the 
entities  shared  between  both  documents.  As  a  result,  the 
layout will place more emphasis on the characteristics that 
make those two documents similar. 
Highlighting.  When  highlighting  a  term,  ForceSPIRE 
creates an entity from the term (if not already one), and the 
importance  value  of  that  term  is  increased.  Similarly, 
highlighting  a  phrase  results  in  the  phrase  being  first 
parsed for entities, then increasing the importance value of 
each  of  those  entities.  For  example,  Figure  11  shows  the 
effect of highlighting the terms “Colorado” and “missiles” 
in the document pointed to with the arrow. As a result, the 

it  may 

imply 

that 

 
Figure  9.  The  Effect  of  adding  an  annotation  (“these 
individuals  may  be  related  to  Revolution  Now”)  to  the 
document shown with an arrow. As  a result,  the document 
becomes 
linked  with  other  documents  mentioning  the 
terrorist organization “Revolution Now”.  

presence of these displays creates an environment in which 
the  virtual  information  (in  this  case  the  documents)  can 
occupy  persistent  physical  space.  As  a  result,  users  are 
further  immersed  into  the  spatial  metaphor,  as  they  can 
point and quickly refer to information based on the physical 
locations.  
Constructing the Spatial Metaphor 
The spatial layout of the text documents is determined by a 
modified  version  a  force-directed  graph  model  [11].  This 
model  functions  on  the  principle  of  nodes  with  a  mass 
connected  by  springs  with  varying  strengths.  Thus,  each 
node has attributes of attraction and repulsion: nodes repel 
other  nodes,  and  two  nodes  attract  each  other  only  when 
connected  by  a  spring  (edge).  The  optimal  layout  is  then 
computed  by  iteratively  calculating  these  forces  until  the 
lowest energy state of all the nodes is reached. A complete 
description of this algorithm can be found in [11].  
We  apply  this  model  to  textual  information  by  treating 
documents  as  nodes  (an  overview  is  shown  in  Figure  6). 
The entire textual content of each document is parsed into a 
collection  of  entities  (i.e.,  keywords).  The  number  of 
entities corresponds to the mass of each document (heavier 
nodes  do  not  move  as  fast  as  lighter  nodes).  A spring  (or 
edge) represents one or more matching entities between two 
nodes.  Therefore,  the  initial  distance  metric  is  a  based  on 
co-occurrence  of  terms  between  documents.  For  example, 
two  documents  containing  the  term  “airport”  will  be 
connected  by  a  spring.  The  strength  of  a  spring  (i.e.  how 
close together it tries to place two nodes) is based on two 
factors:  the  number  of  entities  two  documents  have  in 
common,  and  the  importance  value  associated  with  each 
shared entity (initially, importance values are created using 
a  standard  tfidf  method  [16]).  The  sum  of  all  importance 
values add up to 1. 
The resulting spatial layout is one where similarity between 
documents  is  represented  by  distance  relative  to  other 
documents.  Similarity  in  this  system  is  defined  by  the 
strength of the spring between two documents. A stronger 
spring  (and  therefore  a  larger  amount  of  shared  entities) 
will pull two documents closer together, and thus represent 
two similar documents. 

 

 
Figure  10.  Searching  for  the  term  ”Atlanta”,  documents 
containing the term highlight green within the context of the 
spatial  layout.  Additionally,  the  importance  value  of  entity 
“Atlanta” is increased. 

other  documents  containing  that  term  are  clustered  more 
tightly. 
Searching.  When  coming  across  a  term  of  particular 
interest, analysts usually search on that term in order to find 
other  occurrences.  In  a  spatial  workspace,  this  is  of 
particular  importance,  because  the  answer  to  “where  the 
term  is  also  found”  is  not  only  given  in  terms  of  what 
documents,  but  also  where  in  the  layout  those  documents 
occur. The positions of documents containing the term are 
shown in context of the entire dataset, from which users can 
infer the importance of that term (as shown in Figure 10).  
ForceSPIRE  first  creates  an  entity  from  the  search  term 
(unless  it  is  already  one),  then  increases  the  importance 
value  of  the  search  term.  Figure  10  gives  an  example  of 
how a search result appears in ForceSPIRE. Searching for 
the  term  “Atlanta”,  documents  that  contain  the  term  are 
highlighted  green,  and  links  are  drawn  to  show  where  the 
resulting documents are in relation to the current document.  
Annotation.  Annotations  (i.e.,  “sticky  notes”)  are  also 
viewed as a form of semantic interaction, occurring within 
the analytic process, from which analytic reasoning can be 
inferred. When a user creates a note regarding a document, 
that semantic information should be added to the document. 
For example, if Document A refers to “Revolution Now” (a 
suspicious  terrorist  group),  and  Document  B  refers  to  “a 
group of suspicious individuals”, and the user has reason to 
believe  these  individuals  are  related  to  Revolution  Now, 
adding a note to Document B stating “these individuals may 
be  related  to  Revolution  Now”  is  one  way  for  the  user  to 
add semantic meaning to the document.  
ForceSPIRE  handles  the  addition  of  the  note  (shown  in 
Figure 9) by 1) parsing the note for any currently existing 
entities,  then  2)  increasing  the  importance  value  of  each, 
and 3) creating any new springs between other documents 
sharing these entities. In the example in Figure 9, edges are 
created between Document B and Document A (as well as 
any  other  documents  that  mention  “Revolution  Now”). 
Additionally,  if  the  note  contains  any  new  entities  not 
currently in the model, they are created, with the intent that 

 

 
Figure 11. The effect of highlighting a phrase containing the 
entites  “Colorado”  and  “missiles”.  Documents  containing 
these  entities  move  closer,  as  the  increase  in  importance 
value increases the edge strength.  

the 

importance  values  of 

any future entities that may match to that note can be linked 
at that time. ForceSPIRE also handles cases where notes are 
edited,  with  text  added  or  removed  from  the  note,  by 
updating  the  entities  associated  with  the  document,  and 
adjusting 
these  entities 
accordingly. 
Model Updates 
Each  of  the  semantic  interactions  in  ForceSPIRE  impacts 
the  model  by  updating  the  importance  values  of  entities, 
and  the  mass  of  each  document.  The  calculation  for 
updating the importance value of an entity is the same for 
each interaction. If an entity was “hit” (i.e., it was included 
in  a  highlight,  it  was  searched,  it  was  in  a  note,  etc.), 
ForceSPIRE increases its importance value by 10%. As the 
sum  of  all  importance  values  of  entities  adds  up  to  1, 
ForceSPIRE  subtracts  an  equal  amount  from  all  other 
entities’ importance values. As a result, importance values 
decay over time, and entities that are rarely used during the 
analysis  have  less  impact  on  the  layout.  The  mass  of  a 
document  uses  a  similar  calculation,  in  that  each  time  a 
document  is  “hit”  (i.e.,  text  was  highlighted,  it  was  the 
result of a search hit, etc.), it increases by 10%.  
When  undoing  an 
standard 
the 
“Control+Z”  keyboard  shortcut,  a  linear  history  of  the 
interactions will be reversed, and the importance values of 
affected  entities  will  be  returned  to  their  prior  values  (as 
well  as  document  masses).  As  for  the  locations  of  the 
documents,  the  reverted  importance  values  and  document 
masses  will  be  responsible  for  updating 
layout. 
However, this does not guarantee that the layout will return 
to  the  exact  previous  view,  and  the  user  may  find  it 
necessary to perform small adjustments. 
The model updates used in ForceSPIRE serve as an initial 
approach at how to couple semantic interactions with model 
updates. Other, more complex methods may exist, and we 
encourage  further  research  in  this  area.  Sensemaking  is  a 
complex exploratory process. As such, semantic interaction 

interaction  using 

the 

through 

more  central  documents.  While  reading 
the 
documents, he highlighted phrases of interest. For example, 
he highlighted the phrase “Nizar A. is now known to have 
spent six months in Afghanistan”. In doing so, ForceSPIRE 
increased  the  importance  value  of  the  entities  within  the 
phrase,  particularly  “Afghanistan”  and  “Nizar  A”.  As  a 
result, the layout forms more tightly around those entities. 
Each change incrementally changes the layout. 
Continuing  with  his  investigation,  he  began  searching  for 
words  of  interest  (e.g.,  “weapons”,  “Colorado”,  “Atlanta”, 
etc.). ForceSPIRE provided him with quick visual feedback 
on where in the dataset each terms showed up (the search 
result  for  “Atlanta”  is  shown  in Figure  10).  In  addition  to 
gaining an overview of the distribution of the term within 
the  dataset  (by  highlighting  each  document  containing  the 
term  green),  ForceSPIRE  treats  performing  a  search  as 
either  creating  a  new  entity  from  the  search  term,  or 
increasing the importance value if an entity corresponding 
to the search term already exists. As a result of the multiple 
search terms and highlights corresponding to locations (e.g., 
“Atlanta”,  “Los  Angeles”,  “Missouri”,  etc.),  ForceSPIRE 
adapts  the  spatialization  by  creating  a  more  geographic-
oriented layout (shown in the “Mid Stage” layout in Figure 
12).  
During  further  investigation,  he  began  opening  more 
documents and adding annotations to documents where he 
found  information  missing  that  he  knew.  For  example, 
Figure  9  shows  how  he  opened  one  document  where 
“suspicious individuals” were mentioned. Earlier, he read a 
document  containing 
terrorist 
organization  named  “Revolution  Now”.  While  reading 
about  the  suspicious  individuals,  the  other  information  in 
the document triggered him to make a connection between 
these  individuals  and  Revolution  Now.  He  made  added  a 
note  to  the  document  about  the  suspicious  individuals 
stating  “these  individuals  may  be  related  to  Revolution 
Now”. As a result, ForceSPIRE parsed the note for entities, 
added  them  to  the  document,  and  pulled  the  document 
closer to other documents containing the entity “Revolution 
Now”.  
After  continuing  his  investigation  in  this  manner,  he 
ultimately  made  the  connections  within  the  dataset  to 
uncover  the  terrorist  plot.  The  progression  of  the  spatial 
layout,  shown  in Figure 12, shows the final layout, where 
he  was  able  to  pinpoint  regions  of  the  layout  as  being 
important  in  his  finding.  Some  of  the  spatial  locations  of 
clusters  are  a  result  of  him  pinning  documents  to  that 
region (e.g., “Atlanta”, “Los Angeles”, etc.). These pinned 
documents are shown in red. Perhaps more interestingly is 
not the regions that were created as a result of him pinning 
documents  to  that  location,  but  rather  how  the  remaining 
documents respond in the layout. For example, in the final 
state  shown  in  Figure  12,  a  group  of  documents  began  to 
emerge  in  the  middle  of  all  the  pinned  locations.  Upon 
examining  these  documents,  he  discovered  that  these 

information  about  a 

the 

layout 

 

interaction, 

instances  during 

 
Figure 12. The incremental change of the spatial layout (main 
view  of  ForceSPIRE)  from  the  initial  to  the  final  state. 
Through  semantic 
incrementally 
changed  based  on the  semantic  input of the user. We labeled 
the regions based on what the user told us the regions meant to 
him at each stage. 
can  enable  analysts  to  explore  their  hypothesis  in-situ, 
while  the  provenance  of  their  insights  is  captured  and 
stored. An open area of research is what analyzing the soft 
data might reveal about the analytic process. For instance, if 
the  importance  values  of  entities  converge  on  a  small 
number  of  entities,  specific  biases  might  be  revealed. 
Similarly, 
the  analysis  when  new 
hypotheses  are  being  explored  may  be  indicated  by 
diverging importance values. 
Use Case 
We  demonstrate  the  functionality  of  ForceSPIRE  through 
the  following  use  case.  In  this  scenario,  we  simulate  an 
intelligence  analysis  scenario  where  the  task  is  to  find  a 
hidden terrorist plot in a pre-constructed, ficticious textual 
dataset.  The  dataset  consists  of  50 
text  documents, 
containing  a  complex  terrorist  plot  (explosives  are  being 
transported to various cities in the U.S. using trucks). The 
combination of the task of finding the hidden terrorist plot 
and  the  textual  dataset  is  representative  of  daily  work 
performed  by  professional  intelligence  analysts  [8].  The 
analysis  described  below  lasted  70  minutes,  and  was 
performed  by  an  individual  computer  science  graduate 
student.  
The user began the investigation by loading the collection 
of  documents  into  ForceSPIRE.  The  documents  were 
automatically  parsed  for  entities  using 
the  LingPipe 
keyword  extraction  library  [1].  From  these  entities,  an 
initial layout was generated, shown in Figure 12(top). From 
this  layout,  he  began  investigation  by  reading  through  the 

 

interpreting 

leverage 

interactions 

DISCUSSION 
Unifying the Sensemaking Loop 
With the fundamentally different role occupied by semantic 
interaction, we explore a new design space for interaction in 
visual analytic tools. With the addition of soft data, and a 
model  capable  of 
the  user’s  analytical 
reasoning,  we 
that  are  already 
occurring in the spatial analytic process to further aid users 
in their sensemaking process.  
With  semantic  interaction,  the  amount  of  formalization 
between foraging and sensemaking (Figure 13) on the part 
of the user is reduced. For instance, in moving a document, 
users  can  formulate  a  hypothesis  based  on  that  document, 
expecting  similar  documents 
to  follow.  ForceSPIRE 
attempts to update the layout based on the interaction, and 
gives the user feedback. Thus, the foraging stage occurs as 
a  result  of  the  hypothesis  being  formed  through  semantic 
interaction.  By  not  forcing  users  to  over-formalize  their 
analytic  reasoning  too  early  in  order  to  forage  for  the 
relevant  information,  semantic  interaction  creates  a  more 
seamless 
transition  between 
foraging  and  synthesis, 
unifying the sensemaking loop.  
Future Work 
Semantic 
interaction,  as  a  concept,  opens  up  many 
possibilities for further research, such as: what interactions 
to  capture  and  store,  which  parameters  of  the  model  to 
update,  how  to  store  the  soft  data,  and  which  models 
present a metaphor that can be extended upon.  
In  order  to  make  more  concrete  claims  regarding  the 
usability  and  effectiveness  of  ForceSPIRE  (and  thus,  of 
semantic  interaction),  a  formal  user  study  is  needed.  Our 
plan is to introduce ForceSPIRE to professional intelligence 
analysts  and  have  them  solve  scenarios  that  model  their 
daily  task,  such  as  one  of  the  VAST  datasets  [2020].  The 
observations  and  feedback  from  these  users  will  provide 
ecological validity for semantic interaction. 
CONCLUSION 
In  this  paper  we  have  discussed  how  the  concept  of 
semantic  interaction  leads  to  a  new  design  space  for 
interaction 
information. 
Semantic  interactions  occur  directly  within  the  spatial 
metaphor,  support  spatial  cognition,  and  exploit  spatial 
analytic  interactions.  We  describe  semantic  interaction, 
discussing  the  three  components  required  –  capturing  the 
interaction, 
the  analytical  reasoning,  and 
updating  the  mathematical  model.  Further,  we  present 
ForceSPIRE, designed for semantic interaction with textual 
information, discussing its functionality and demonstrating 
how it can be used through a use case. Lastly, we discuss 
how  semantic  interaction  has  the  opportunity  to  unify  the 
sensemaking  loop,  creating  a  more  seamless  analytic 
process.  In  allowing  users  to  interact  within  the  spatial 
metaphor, they can remain more focused on their analysis 
of  the  data,  without  having  to  become  experts  in  the 
underlying mathematical models of the system.  

in  spatializations  of 

interpreting 

textual 

 

Figure  13.  The  sensemaking  loop,  illustrating  the  complex 
sequence  of  steps  used  by  intelligence  analysts  in  order  to 
gain insight into data.  
 
documents  are  about  the  terrorist  organization  using  “U-
Haul”  or  “Ryder”  trucks  for  transportation  between  these 
locations. ForceSPIRE placing these documents in between 
these  cities  in  the  layout  was  helpful,  as  these  documents 
contain  information  “connecting”  the  events  in  these 
locations.  Immediately  after  noticing  this  event,  he  also 
made use of the expressive form of interaction, performed 
by dragging two of these documents together to determine 
what  made  them  similar.  After  seeing  that  it  was  indeed 
terms  such  as  “Ryder”  and  “U-Haul”,  the  layout  formed 
more tightly around these terms. 
ForceSPIRE interpreted the analytical reasoning of the user 
through the creation of new entities that were not found by 
the  initial  keyword  extraction,  as  well  as  the  increase  of 
importance values of existing entities. This is evidenced by 
the  creation  of  39  new  entities  during  the  course  of  the 
analysis.  LingPipe  extracted  89  initial  entities  from  this 
dataset,  and  at  the  time  of  completing  our  investigation 
ForceSPIRE  included  128.  Examples  of  newly  created 
entities  are  “big  event”,  “grenades”,  “Fisher  Island”, 
“weapons”,  and  others.  The  ability  for  new  entities  to  be 
created  via  semantic  interaction  did  not  interfere  with  the 
fluid sensemaking process of the user. Instead, it aided the 
process  by  creating  new  entities,  which  in  turn  created 
semantically relevant connections within the dataset. 
In  addition  to  creating  new  entities,  existing  entities 
dynamically  changed  their  importance  value  based  on  the 
semantic 
interpreted 
reasoning 
interactions.  Examples  of  entities 
their 
importance  values  are  “Atlanta”,  “Revolution  Now”, 
“Colorado”,  “L.A.”,  and  others.  As  a 
the 
ForceSPIRE incrementally adapted the layout based on the 
user  input.  This  shows  that  adjusting  importance  values, 
creating entities, and changing locations of key documents 
helped  the  user  discover  the  structure  of  the  dataset,  and 
ultimately make out the hidden terrorist plot.  

of 
that  changed 

analytical 

result, 

the 

 

ACKNOWLEDGEMENTS 
This research was funded by the NSF grant CCF-0937071 
and the DHS center of excellence. 
REFERENCES 
1.  Alias-i. 2008. LingPipe 4.0.1. City, 2008. 
2.  i2 Analyst's Notebook. City. 
3.  Alsakran, J., Chen, Y., Zhao, Y., Yang, J. and Luo, D. 

STREAMIT: Dynamic visualization and interactive 
exploration of text streams. In Proceedings of the IEEE 
Pacific Visualization Symposium, 2011.  

4.  Andrews, C., Endert, A. and North, C. Space to Think: 
Large, High-Resolution Displays for Sensemaking. In 
Proceedings of the CHI '10, 2010.  

5.  Callahan, S. P., Freire, J., Santos, E., Scheidegger, C. E., 

C, Silva, u. T. and Vo, H. T. VisTrails: visualization 
meets data management. In Proceedings of the 
SIGMOD international conference on Management of 
data (Chicago, IL, USA, 2006). ACM.  

6.  Cowley, P., Haack, J., Littlefield, R. and Hampson, E. 

Glass box: capturing, archiving, and retrieving 
workstation activities. In Proceedings of the workshop 
on Continuous archival and retrival of personal 
experences (Santa Barbara, California, USA, 2006). 
ACM.  

7.  Dou, W., Jeong, D. H., Stukes, F., Ribarsky, W., 

Lipford, H. R. and Chang, R. Recovering Reasoning 
Processes from User Interactions. IEEE Computer 
Graphics and Applications, 2009. 

8.  Endert, A., Andrews, C., Fink, G. A. and North, C. 

Professional Analysts using a Large, High-Resolution 
Display. In Proceedings of the IEEE VAST Extended 
Abstract (2009).  

9.  Endert, A., Han, C., Maiti, D., House, L., Leman, S. C. 

and North, C. Observation-level Interaction with 
Statistical Models for Visual Analytics. IEEE VAST, 
2011. 

10. Frank M. Shipman, I. and Marshall, C. C. Formality 

Considered Harmful: Experiences, Emerging Themes, 
and Directions on the Use of Formal Representations 
inInteractive Systems. ACM CSCW, 8, 4, 1999, 333-352. 

11. Fruchterman, T. M. J. and Reingold, E. M. Graph 

drawing by force-directed placement. Software: Practice 
and Experience, 21, 11 1991, 1129-1164. 

12. Gotz, D. Interactive Visual Synthesis of Analytic 

Knowledge. IEEE VAST, 2006. 
13. Heer, J. prefuse manual, 2006. 
14. Heer, J., Mackinlay, J., Stolte, C. and Agrawala, M. 

Graphical Histories for Visualization: Supporting 
Analysis, Communication, and Evaluation. IEEE 
Transactions on Visualization and Computer Graphics, 
14, 6 , 2008, 1189-1196. 

 

15. Jeong, D. H., Ziemkiewicz, C., Fisher, B., Ribarsky, W. 

and Chang, R. iPCA: An Interactive System for PCA-
based Visual Analytics. Computer Graphics Forum, 28, 
2009, 767-774. 

16. Karen A Statistical Interpretation of Term Specificity 

and its Application in Retrieval. Journal of 
Documentation, 28, 1972, 11-21. 

17. Marshall, C. C., Frank M. Shipman, I. and Coombs, J. 

H. VIKI: spatial hypertext supporting emergent 
structure. In Proceedings of the European conference on 
Hypermedia technology (Edinburgh, Scotland, 1994). 
ACM.  

18. Olsen, K. A., Korfhage, R. R., Sochats, K. M., Spring, 
M. B. and Williams, J. G. Visualization of a document 
collection: the vibe system. Information Process 
Management, 29, 1 1993, 69-81. 

19. Pirolli, P. and Card, S. Sensemaking Processes of 

Intelligence Analysts and Possible Leverage Points as 
Identified Though Cognitive Task Analysis Proceedings 
of the International Conference on Intelligence 
Analysis,2005, 6. 

20. Plaisant, C., Grinstein, G., Scholtz, J., Whiting, M., 

O'Connell, T., Laskowski, S., Chien, L., Tat, A., Wright, 
W., Gorg, C., Zhicheng, L., Parekh, N., Singhal, K. and 
Stasko, J. Evaluating Visual Analytics at the 2007 
VAST Symposium Contest. Computer Graphics and 
Applications, IEEE, 28, 2 2008, 12-21. 

21. Shrinivasan, Y. B. and Wijk, J. J. v. Supporting the 

analytical reasoning process in information 
visualization. In Proceedings of the CHI '08 (Florence, 
Italy, 2008). ACM.  

22. Skupin, A. A Cartographic Approach to Visualizing 
Conference Abstracts. IEEE Computer Graphics and 
Applications, pp. 50-58, January/February, 2002. 

23. Thomas, J. J., Cook, K. A., National, V. and Analytics, 
C. Illuminating the path. IEEE Computer Society, 2005. 
24. Torres, R. S., Silva, C. G., Medeiros, C. B. and Rocha, 

H. V. Visual structures for image browsing. In 
Proceedings of the conference on Information and 
knowledge management (New Orleans, LA, USA, 
2003). ACM.  

25. Wise, J. A., Thomas, J. J., Pennock, K., Lantrip, D., 

Pottier, M., Schur, A. and Crow, V. Visualizing the non-
visual: spatial analysis and interaction with information 
for text documents. Morgan Kaufmann Publishers, 1999. 

26. Wright, W., Schroh, D., Proulx, P., Skaburskis, A. and 

Cort, B. The Sandbox for analysis: concepts and 
methods. In Proceedings of the CHI '06 (New York, 
NY, 2006). ACM.  

27. Yi, J. S., Melton, R., Stasko, J. and Jacko, J. A. Dust & 
magnet: multivariate information visualization using a 
magnet metaphor. Information Visualization, 4, 4, 2005, 
239-256. 

","{""0"":{""0"":""importance"",""1"":""result"",""2"":""interact*"",""3"":""directly"",""4"":""note"",""5"":""containing*""},""1"":{""0"":""users"",""1"":""entities*"",""2"":""forcespire"",""3"":""models*"",""4"":""tools"",""5"":""individuals*""},""2"":{""0"":""ieee*"",""1"":""atlanta*"",""2"":""computer"",""3"":""virginia*"",""4"":""tech*"",""5"":""blacksburg""},""3"":{""0"":""spatial*"",""1"":""semantic*"",""2"":""visual*"",""3"":""visualization*"",""4"":""statistical"",""5"":""workspace""},""pos"":{""0"":1,""1"":2,""2"":3,""3"":4,""4"":5,""5"":6}}",2012,{},False,False,conferencePaper,False,LPYLPDEE,[],self.user,"{""C"":{""0"":7.2848872773,""1"":8.7500788697,""10"":16.3118178679,""11"":7.8016054686,""12"":11.9889398587,""13"":5.3710290453,""14"":5.9795156066,""15"":8.722432648,""16"":6.4049889016,""17"":9.4925714079,""18"":6.6073391207,""19"":4.6489736931,""2"":19.9176817341,""20"":4.8593026338,""21"":8.7669936395,""22"":4.4977930176,""23"":10.4155810887,""24"":10.0894101761,""25"":5.9501903633,""26"":5.1097411038,""27"":9.5530385662,""28"":5.2354497707,""29"":10.2311602559,""3"":5.0091155864,""30"":14.231974754,""31"":13.1393054417,""32"":5.6759369401,""33"":6.8774539129,""34"":5.4671744282,""35"":4.5996316311,""36"":6.3680531712,""37"":5.2142210552,""38"":6.2300983189,""39"":4.4803287121,""4"":6.10784078,""40"":5.9426864206,""41"":5.2416101829,""42"":6.3157706186,""43"":5.3690801073,""44"":6.852109183,""45"":7.2214548521,""46"":4.5504038732,""47"":6.2639356526,""48"":5.1767086885,""49"":4.7147070268,""5"":13.6390249506,""50"":4.7147070268,""51"":4.7045181642,""52"":4.689257153,""53"":4.6385661802,""54"":4.6436278912,""55"":4.5033242745,""6"":5.4376104745,""7"":10.58337383,""8"":7.633272827,""9"":5.9298993686},""Unnamed: 0"":{""0"":0,""1"":1,""10"":10,""11"":11,""12"":12,""13"":13,""14"":14,""15"":15,""16"":16,""17"":17,""18"":18,""19"":19,""2"":2,""20"":20,""21"":21,""22"":22,""23"":23,""24"":24,""25"":25,""26"":26,""27"":27,""28"":28,""29"":29,""3"":3,""30"":30,""31"":31,""32"":32,""33"":33,""34"":34,""35"":35,""36"":36,""37"":37,""38"":38,""39"":39,""4"":4,""40"":40,""41"":41,""42"":42,""43"":43,""44"":44,""45"":45,""46"":46,""47"":47,""48"":48,""49"":49,""5"":5,""50"":50,""51"":51,""52"":54,""53"":55,""54"":56,""55"":57,""6"":6,""7"":7,""8"":8,""9"":9},""count"":{""0"":186,""1"":174,""10"":66,""11"":64,""12"":56,""13"":54,""14"":48,""15"":34,""16"":32,""17"":32,""18"":30,""19"":26,""2"":128,""20"":26,""21"":26,""22"":24,""23"":24,""24"":24,""25"":22,""26"":22,""27"":22,""28"":20,""29"":20,""3"":124,""30"":20,""31"":18,""32"":16,""33"":14,""34"":12,""35"":12,""36"":12,""37"":12,""38"":10,""39"":10,""4"":116,""40"":10,""41"":10,""42"":10,""43"":10,""44"":10,""45"":10,""46"":8,""47"":8,""48"":8,""49"":6,""5"":116,""50"":6,""51"":6,""52"":6,""53"":6,""54"":6,""55"":6,""6"":102,""7"":90,""8"":76,""9"":66},""exemplar"":{""0"":null,""1"":null,""10"":null,""11"":null,""12"":""*"",""13"":null,""14"":null,""15"":null,""16"":null,""17"":null,""18"":""*"",""19"":""*"",""2"":null,""20"":null,""21"":null,""22"":null,""23"":null,""24"":null,""25"":null,""26"":null,""27"":null,""28"":""*"",""29"":""*"",""3"":""*"",""30"":null,""31"":""*"",""32"":""*"",""33"":null,""34"":null,""35"":null,""36"":null,""37"":""*"",""38"":""*"",""39"":null,""4"":""*"",""40"":null,""41"":null,""42"":null,""43"":null,""44"":null,""45"":null,""46"":null,""47"":""*"",""48"":null,""49"":""*"",""5"":null,""50"":""*"",""51"":null,""52"":null,""53"":""*"",""54"":null,""55"":""*"",""6"":null,""7"":""*"",""8"":null,""9"":""*""},""pos"":{""0"":1,""1"":2,""10"":1,""11"":5,""12"":4,""13"":6,""14"":7,""15"":5,""16"":2,""17"":8,""18"":4,""19"":3,""2"":3,""20"":4,""21"":9,""22"":5,""23"":10,""24"":11,""25"":12,""26"":6,""27"":5,""28"":6,""29"":6,""3"":1,""30"":7,""31"":1,""32"":2,""33"":3,""34"":13,""35"":14,""36"":7,""37"":8,""38"":7,""39"":15,""4"":2,""40"":16,""41"":9,""42"":10,""43"":11,""44"":17,""45"":8,""46"":12,""47"":8,""48"":18,""49"":4,""5"":1,""50"":5,""51"":6,""52"":9,""53"":13,""54"":19,""55"":14,""6"":4,""7"":2,""8"":3,""9"":3},""sigma_nor"":{""0"":1.5103325111,""1"":1.6340203392,""10"":2.8459173803,""11"":1.8826516604,""12"":2.4487763722,""13"":1.643992573,""14"":1.7551565542,""15"":2.2779367204,""16"":1.9480091453,""17"":2.4269172526,""18"":2.0026762267,""19"":1.7255854924,""2"":2.6777187581,""20"":1.760925888,""21"":2.417513352,""22"":1.7186026939,""23"":2.7430174938,""24"":2.6865547909,""25"":1.9979790496,""26"":1.8478052557,""27"":2.6417459129,""28"":1.8962521258,""29"":2.8196212377,""3"":1.4191682738,""30"":3.5591013459,""31"":3.4393219466,""32"":2.0429294995,""33"":2.3297431094,""34"":2.0745372299,""35"":1.8857179157,""36"":2.2706120598,""37"":2.0194823293,""38"":2.289114918,""39"":1.8887586279,""4"":1.5294132681,""40"":2.2233535967,""41"":2.0629437459,""42"":2.308717181,""43"":2.0921095205,""44"":2.4314342044,""45"":2.5159423941,""46"":1.9326749405,""47"":2.3466506738,""48"":2.0839852332,""49"":1.9929438227,""5"":2.198006739,""50"":1.9929438227,""51"":1.9903349022,""52"":1.986427227,""53"":1.9734474938,""54"":1.9747435758,""55"":1.9388179776,""6"":1.4975911413,""7"":2.0388294899,""8"":1.8018212734,""9"":1.6568043723},""topic"":{""0"":-1,""1"":-1,""10"":0,""11"":-1,""12"":3,""13"":-1,""14"":-1,""15"":3,""16"":0,""17"":-1,""18"":1,""19"":0,""2"":-1,""20"":0,""21"":-1,""22"":1,""23"":-1,""24"":-1,""25"":-1,""26"":3,""27"":0,""28"":1,""29"":0,""3"":3,""30"":1,""31"":2,""32"":2,""33"":2,""34"":-1,""35"":-1,""36"":0,""37"":0,""38"":3,""39"":-1,""4"":3,""40"":-1,""41"":0,""42"":0,""43"":0,""44"":-1,""45"":3,""46"":0,""47"":1,""48"":-1,""49"":2,""5"":1,""50"":2,""51"":2,""52"":1,""53"":0,""54"":-1,""55"":0,""6"":-1,""7"":1,""8"":1,""9"":3},""vector"":{""0"":""[ 1.3162606   5.0050855  -0.21318144  2.3465474  -1.6024877  -0.45927387\n  1.1317587   0.11744681 -2.4485073   0.10803837]"",""1"":""[ 0.21490052  4.906967   -1.0969152   2.3609536  -0.94365823 -0.9121546\n  1.6262487   0.0621701  -3.1291256   0.29652694]"",""10"":""[ 1.1410977   4.7728834  -0.9374341   2.2274957  -1.1936173  -0.6488974\n  1.0270493   0.30747616 -2.212185    0.87679064]"",""11"":""[ 0.26679116  5.278541   -0.01543311  2.6511967  -0.9308144  -0.45310372\n  1.7822847  -0.25899577 -2.8861723   0.34034   ]"",""12"":""[ 9.2173803e-01  5.3115492e+00 -3.9308746e-03  2.8785219e+00\n -1.5073262e+00 -1.6212521e-01  1.7666513e+00 -5.2872425e-01\n -2.3506653e+00 -1.5799293e-01]"",""13"":""[ 1.243532    5.064958   -0.7345739   2.5328147  -1.5903593  -0.45905122\n  1.4544641  -0.18253686 -2.1436272  -0.03066739]"",""14"":""[ 1.1504109   4.7098703  -1.0329187   2.1683493  -1.5528138  -0.9222704\n  1.0744274   0.05163501 -2.5544739   0.06259288]"",""15"":""[ 0.638772    5.165945    0.28410518  2.576431   -1.3107065  -0.38262686\n  1.4325429  -0.53275    -2.5669062   0.06796689]"",""16"":""[ 1.0165241   4.3158402  -1.4962685   2.2371285  -1.6043243  -0.89835495\n  0.9293174   0.2756144  -2.6360161   0.82190657]"",""17"":""[ 0.6861776   4.8737135  -1.0565379   2.6817656  -1.1953151  -0.49377793\n  1.5475328   0.26444244 -2.5636237   1.02023   ]"",""18"":""[ 0.65662616  5.3001485  -0.9430574   2.9342098  -1.1669558  -0.32633215\n  2.0435023   0.04505815 -2.5931365   0.42879474]"",""19"":""[ 1.1567547   4.374835   -0.67213726  1.5312376  -1.548111   -0.89283806\n  0.54119146  0.96543914 -2.8372207   0.6411905 ]"",""2"":""[ 0.659332    4.6396346  -1.130051    2.0720327  -1.2117864  -1.1111394\n  1.0954281   0.16341831 -3.010829    0.28396967]"",""20"":""[ 1.1296353   4.4329095  -0.99012583  1.5593646  -1.3544239  -0.9328083\n  0.6325666   0.76840556 -2.5411537   0.68393964]"",""21"":""[ 1.0145879   4.7225614  -1.033502    2.5509114  -1.3793937  -0.59432095\n  1.2065364   0.25026542 -2.473097    0.98164785]"",""22"":""[ 0.8310737   5.5446873  -0.5393468   2.7491024  -1.1188436  -0.26171765\n  2.038984   -0.03372773 -2.5580623  -0.02251037]"",""23"":""[ 0.14702158  5.1212735  -0.37912712  2.7708237  -1.128222   -0.14634158\n  2.3560603   0.05855524 -2.7697775   0.29914144]"",""24"":""[ 0.9380679   4.5267673  -0.7031581   1.9918483  -1.6536765  -1.0364026\n  0.9105746   0.08838733 -2.9795935  -0.03246421]"",""25"":""[ 1.1130725   4.846126    0.18446617  2.2350311  -1.7714602  -0.5869695\n  1.0418946  -0.25167224 -2.7003818  -0.3024863 ]"",""26"":""[ 0.7578536   5.4718432  -0.21208927  2.8892825  -1.1652279  -0.19631359\n  2.0800142  -0.4097308  -2.6200128  -0.22402051]"",""27"":""[ 1.1279511   4.4770737  -1.4023845   2.0312128  -1.3842924  -0.9664958\n  0.83603543  0.31572965 -2.4331574   0.7034667 ]"",""28"":""[ 0.17150386  4.953336   -1.095518    2.6464171  -1.0201955  -0.24737167\n  2.1315093   0.40294763 -2.8093722   0.70924175]"",""29"":""[ 0.87565273  4.1712356  -1.4224503   1.8588591  -1.4981017  -1.0100975\n  0.780477    0.5473915  -2.7829037   0.84016556]"",""3"":""[ 1.0831969   5.083006    0.5065097   2.5029778  -1.7295933  -0.3368017\n  1.1477745  -0.5675963  -2.4856763  -0.21456452]"",""30"":""[ 0.6475594   4.8254113  -1.1782899   2.6721902  -1.0255644  -0.9154649\n  1.5432956  -0.30820012 -3.007452    0.1157783 ]"",""31"":""[ 0.1954238   4.8998833   0.3313593   2.6039002  -1.0660381  -0.44992822\n  2.1006868  -0.43479678 -3.5192533  -0.5679184 ]"",""32"":""[ 0.48961583  4.796985    0.43371758  2.4504378  -1.1824281  -0.6172898\n  1.8338379  -0.57686156 -3.4721904  -0.85601044]"",""33"":""[ 0.47588667  5.0802445   0.05200307  2.845525   -1.1663641  -0.32497796\n  2.0019212  -0.64049846 -2.9882615  -0.34195894]"",""34"":""[ 1.0445546   5.224257   -0.573816    2.170763   -1.0420493  -0.60588413\n  1.498904    0.22463678 -2.3840702   0.10075638]"",""35"":""[ 1.0620879   5.032212   -0.6866882   2.7682195  -1.6543036  -0.23906025\n  1.7052748  -0.27457255 -2.1307845   0.12124838]"",""36"":""[ 1.1789758   4.925786   -0.9402      2.0725636  -1.2280105  -0.7086176\n  1.1574279   0.27339807 -2.1951492   0.36660406]"",""37"":""[ 1.0094149   4.100751   -1.2504733   1.7382631  -1.6125802  -1.0763961\n  0.5883362   0.66058356 -2.913355    0.7779094 ]"",""38"":""[ 0.97735757  5.0691166   0.40602663  2.6926417  -1.68086    -0.24066967\n  1.4074689  -0.64930624 -2.515222   -0.2916298 ]"",""39"":""[ 0.862602    4.925824   -1.2356975   2.9244514  -1.3112154  -0.62003297\n  1.6723751  -0.14696866 -2.7000306   0.39687932]"",""4"":""[ 1.0539151   4.9139957   0.21623735  2.3233087  -1.702712   -0.4183228\n  1.1421078  -0.4256671  -2.383227   -0.20181388]"",""40"":""[ 0.4673698   5.298409   -0.25812256  2.965732   -1.0005121  -0.43106487\n  1.8788215  -0.44691497 -2.722999    0.34325284]"",""41"":""[ 0.79942244  4.1702204  -1.3183178   2.020924   -1.5447751  -0.7597761\n  0.9407928   0.60182863 -2.7183008   1.079823  ]"",""42"":""[ 0.8993384   4.070942   -0.9842759   1.7159499  -1.6798792  -0.9202691\n  0.6606074   0.97483397 -3.0962534   0.8277877 ]"",""43"":""[ 0.7234082   4.300244   -1.1979697   1.7403712  -1.3112779  -0.720886\n  1.0288169   0.4754937  -2.3077378   0.84822226]"",""44"":""[ 0.6920418   4.8464217  -0.8493754   2.5628848  -1.0039561  -0.89601016\n  1.5447487  -0.34256172 -3.1179078  -0.13674468]"",""45"":""[ 0.6007708   5.0375934  -0.05823188  2.9243124  -1.4138515  -0.2201978\n  1.9184262  -0.6669816  -2.741953   -0.279028  ]"",""46"":""[ 0.9768561   4.51605    -1.2550555   1.7381439  -1.2356248  -0.85307705\n  0.93557316  0.49494123 -2.279542    0.6519702 ]"",""47"":""[ 0.378907    5.065933   -0.7391716   2.4541101  -1.099723   -0.31080058\n  2.0205534   0.4026281  -2.499268    0.6312865 ]"",""48"":""[ 0.9392588   5.3498535  -0.397504    2.4665241  -1.022142   -0.63004094\n  1.625309   -0.07049026 -2.7962852  -0.14837155]"",""49"":""[ 0.30747285  4.8016176   0.44055545  2.41057    -1.0763044  -0.6158364\n  2.004415   -0.44314137 -3.6043394  -0.8207492 ]"",""5"":""[ 0.01738642  5.101418   -0.80140007  2.811135   -0.9880253  -0.16892105\n  2.346427    0.19066155 -2.904929    0.516091  ]"",""50"":""[ 0.42505544  4.9955554   0.16395324  2.6589289  -1.0147566  -0.54142547\n  1.9843619  -0.5886641  -3.313092   -0.57017815]"",""51"":""[ 0.21347268  4.663547    0.21306331  2.49147    -1.2542347  -0.43319294\n  2.0333738  -0.35704574 -3.6062448  -0.7098471 ]"",""52"":""[ 0.16307767  4.8852777  -1.1928535   2.5799978  -0.9896254  -0.69041985\n  1.8462666   0.09542003 -3.0096507   0.48893425]"",""53"":""[ 0.9450972  4.235819  -0.7686871  1.608504  -1.621948  -1.0625876\n  0.5915332  0.8703029 -3.1864326  0.5063559]"",""54"":""[ 0.22260174  5.2087917  -0.17489809  2.7788937  -1.080786   -0.21922064\n  2.2507272  -0.12915827 -2.89141     0.09807622]"",""55"":""[ 1.1326516   4.340689   -0.8617362   1.5964595  -1.5923283  -1.0806816\n  0.5811112   0.698404   -2.9303615   0.41367736]"",""6"":""[ 1.03034     5.221684   -1.0379866   2.9237232  -1.3626026  -0.44278902\n  1.7416707   0.02238204 -2.426657    0.46057054]"",""7"":""[ 0.1023729   5.098926   -0.85134697  2.4344094  -1.0585765  -0.31418365\n  2.1653607   0.5541903  -2.700617    0.6453517 ]"",""8"":""[ 0.17022625  5.058491   -0.6539097   2.2744439  -1.174396   -0.46479997\n  1.9589131   0.4878635  -2.7956324   0.47158277]"",""9"":""[ 0.9118785   4.8512197   0.11452872  2.613089   -1.7049446  -0.24061467\n  1.4345211  -0.63919306 -2.4846926  -0.32785386]""},""vocab_index"":{""0"":0,""1"":1,""10"":14,""11"":15,""12"":16,""13"":17,""14"":21,""15"":29,""16"":32,""17"":33,""18"":34,""19"":40,""2"":2,""20"":41,""21"":43,""22"":45,""23"":50,""24"":52,""25"":56,""26"":58,""27"":60,""28"":66,""29"":68,""3"":3,""30"":69,""31"":77,""32"":85,""33"":107,""34"":110,""35"":128,""36"":133,""37"":134,""38"":144,""39"":154,""4"":4,""40"":159,""41"":171,""42"":172,""43"":173,""44"":174,""45"":175,""46"":216,""47"":222,""48"":223,""49"":224,""5"":5,""50"":225,""51"":226,""52"":244,""53"":269,""54"":280,""55"":302,""6"":6,""7"":9,""8"":10,""9"":13},""word"":{""0"":""interaction"",""1"":""documents"",""10"":""importance"",""11"":""data"",""12"":""visualization"",""13"":""metaphor"",""14"":""term"",""15"":""statistical"",""16"":""result"",""17"":""values"",""18"":""models"",""19"":""interact"",""2"":""document"",""20"":""directly"",""21"":""value"",""22"":""tools"",""23"":""nodes"",""24"":""search"",""25"":""foraging"",""26"":""workspace"",""27"":""note"",""28"":""individuals"",""29"":""containing"",""3"":""spatial"",""30"":""proceedings"",""31"":""ieee"",""32"":""atlanta"",""33"":""computer"",""34"":""domain"",""35"":""arrow"",""36"":""context"",""37"":""pinned"",""38"":""dimensional"",""39"":""series"",""4"":""semantic"",""40"":""pipeline"",""41"":""increases"",""42"":""began"",""43"":""vast"",""44"":""conference"",""45"":""graphics"",""46"":""particular"",""47"":""regions"",""48"":""management"",""49"":""virginia"",""5"":""users"",""50"":""tech"",""51"":""blacksburg"",""52"":""copies"",""53"":""organize"",""54"":""algorithms"",""55"":""associate"",""6"":""model"",""7"":""entities"",""8"":""forcespire"",""9"":""visual""},""word*"":{""0"":""interaction"",""1"":""documents"",""10"":""importance"",""11"":""data"",""12"":""visualization*"",""13"":""metaphor"",""14"":""term"",""15"":""statistical"",""16"":""result"",""17"":""values"",""18"":""models*"",""19"":""interact*"",""2"":""document"",""20"":""directly"",""21"":""value"",""22"":""tools"",""23"":""nodes"",""24"":""search"",""25"":""foraging"",""26"":""workspace"",""27"":""note"",""28"":""individuals*"",""29"":""containing*"",""3"":""spatial*"",""30"":""proceedings"",""31"":""ieee*"",""32"":""atlanta*"",""33"":""computer"",""34"":""domain"",""35"":""arrow"",""36"":""context"",""37"":""pinned*"",""38"":""dimensional*"",""39"":""series"",""4"":""semantic*"",""40"":""pipeline"",""41"":""increases"",""42"":""began"",""43"":""vast"",""44"":""conference"",""45"":""graphics"",""46"":""particular"",""47"":""regions*"",""48"":""management"",""49"":""virginia*"",""5"":""users"",""50"":""tech*"",""51"":""blacksburg"",""52"":""copies"",""53"":""organize*"",""54"":""algorithms"",""55"":""associate*"",""6"":""model"",""7"":""entities*"",""8"":""forcespire"",""9"":""visual*""},""x2D"":{""0"":-3.0130655766,""1"":-5.6590614319,""10"":-3.4654493332,""11"":-4.9243535995,""12"":-3.8451178074,""13"":-3.4076960087,""14"":-3.3898341656,""15"":-3.5163750648,""16"":-2.9382448196,""17"":-4.680539608,""18"":-4.9102044106,""19"":-1.6470563412,""2"":-3.1983983517,""20"":-1.956330061,""21"":-3.8832998276,""22"":-4.4393591881,""23"":-5.6040306091,""24"":-2.8143787384,""25"":-2.9244270325,""26"":-4.2939810753,""27"":-2.9085655212,""28"":-5.8914213181,""29"":-2.2874557972,""3"":-2.929107666,""30"":-5.3915858269,""31"":-4.6902098656,""32"":-5.1114258766,""33"":-4.5118384361,""34"":-3.7506420612,""35"":-3.6811594963,""36"":-3.6041681767,""37"":-1.812482357,""38"":-3.1868915558,""39"":-4.772105217,""4"":-2.8864862919,""40"":-4.6994361877,""41"":-2.4484758377,""42"":-1.4506188631,""43"":-2.5288338661,""44"":-5.174135685,""45"":-4.2625861168,""46"":-2.7111675739,""47"":-5.5705313683,""48"":-4.2112226486,""49"":-4.7582507133,""5"":-6.0599107742,""50"":-4.8205137253,""51"":-4.8952684402,""52"":-5.5843429565,""53"":-1.4355084896,""54"":-5.2105541229,""55"":-1.6587857008,""6"":-4.4399089813,""7"":-5.7084913254,""8"":-5.9865312576,""9"":-3.2908182144},""y2D"":{""0"":0.0792598799,""1"":-0.9317694902,""10"":-2.5489301682,""11"":1.0917783976,""12"":1.2452733517,""13"":-0.1451755911,""14"":-1.7549887896,""15"":1.7002849579,""16"":-3.1324076653,""17"":-1.4157580137,""18"":-0.2411413491,""19"":-2.5409853458,""2"":-2.0424053669,""20"":-2.7223126888,""21"":-2.5032820702,""22"":0.4226954579,""23"":0.6073452234,""24"":-1.7230752707,""25"":0.7446238399,""26"":1.1282889843,""27"":-2.7038948536,""28"":-0.229725495,""29"":-3.117978096,""3"":1.49563241,""30"":-1.4106578827,""31"":2.4891898632,""32"":2.4718234539,""33"":1.7159042358,""34"":-0.4732470512,""35"":0.0332050659,""36"":-2.082709074,""37"":-3.1682975292,""38"":1.5556272268,""39"":-0.89973104,""4"":1.1624327898,""40"":0.6553325057,""41"":-3.3112618923,""42"":-2.9629395008,""43"":-3.0564780235,""44"":-1.1989816427,""45"":1.5261098146,""46"":-2.699678421,""47"":-0.0512988381,""48"":0.2294874042,""49"":2.6457045078,""5"":0.1541163772,""50"":2.1629948616,""51"":2.3191092014,""52"":-0.7204707861,""53"":-2.722417593,""54"":0.9553381205,""55"":-2.8447480202,""6"":-0.6057106853,""7"":-0.0728163421,""8"":-0.1658378094,""9"":1.1817923784}}",False,False,False,http://dl.acm.org/citation.cfm?doid=2207676.2207741,,Semantic interaction for visual text analytics,"[-1.37927175e-01 -1.54253602e-01  2.68985510e-01  1.24898856e-04
  8.66144657e-01  1.56499028e-01 -2.28903443e-01  3.07761431e-01
 -4.87633854e-01 -3.90738845e-01  1.56396031e-02 -1.45184383e-01
 -3.77245218e-01  2.90179670e-01 -1.46641359e-02  1.08802748e+00
 -1.30494937e-01  9.82559845e-02  5.67772202e-02 -7.52299726e-02
 -1.08519748e-01  1.43800601e-01  1.40982971e-01  4.65801656e-01
  2.71615326e-01 -2.00568393e-01 -2.24875450e-01  8.35525319e-02
 -3.19302976e-02  2.50238061e-01  1.11258067e-01  3.35151672e-01
 -1.49319127e-01 -3.14927816e-01  3.00257802e-01 -4.06159788e-01
 -3.30037266e-01  4.20856237e-01  7.23880380e-02  6.04586661e-01
 -6.82869852e-01 -6.61216497e-01 -1.32945716e-01 -3.54861021e-01
  2.83059478e-01  1.18503846e-01 -7.28244008e-03 -6.09189928e-01
 -8.73753130e-02 -3.31280112e-01 -1.28108418e+00 -1.50009617e-01
 -4.64782000e-01 -2.09070757e-01  6.51753396e-02  3.36882293e-01
  6.17145523e-02 -1.01296484e+00  4.44402546e-01  1.59418816e-03
 -2.27247447e-01  8.02094266e-02 -6.21818483e-01  2.58319974e-01
  6.89413995e-02 -5.10566890e-01 -3.32088098e-02  6.07566684e-02
 -5.44700146e-01  4.29404825e-01  1.08024031e-01  7.58334398e-02
 -3.49161059e-01  1.20327175e-01 -1.98952138e-01  1.11926652e-01
 -5.70405602e-01  3.92173588e-01 -5.82415611e-02 -3.47645998e-01
 -1.72340274e-01  4.98981386e-01  4.04958874e-01 -2.87089404e-03
  3.63792062e-01  7.64743328e-01 -1.28653139e-01  5.08287072e-01
 -8.31861123e-02  4.33255643e-01 -4.66423482e-01  1.80964738e-01
 -3.89906496e-01  2.35436320e-01  3.66917759e-01 -6.34261549e-01
 -4.53991532e-01  5.60296476e-02 -2.20567226e-01  5.72905317e-02
  1.09295338e-01 -4.44537878e-01  8.23210776e-02 -1.00630827e-01
  5.40689677e-02 -1.86522186e-01 -1.15236595e-01 -4.55335006e-02
 -3.87942463e-01  4.41625118e-02 -3.05387974e-01  8.07034746e-02
  1.15006335e-01 -5.55917919e-01 -2.76854247e-01  3.04133594e-01
 -8.33104772e-04 -8.65281746e-02  2.97690481e-01 -2.09779561e-01
 -2.23564401e-01  5.10757923e-01 -5.39237494e-03  4.22875762e-01
  2.13363096e-01 -4.68789879e-03 -9.76739917e-03  2.47390680e-02
  4.35128480e-01  3.00615221e-01  5.96868157e-01 -2.05707729e-01
  1.90662816e-02  2.18344569e-01 -1.39497861e-01  8.18736553e-01
  4.10801321e-02  2.35852897e-01  1.91632822e-01 -2.36213267e-01
 -1.00013518e+00 -2.58162796e-01  2.32262127e-02 -4.49414924e-02
 -8.20248425e-02 -1.82294901e-02 -2.19805300e-01  5.35663605e-01
  4.12399769e-02  4.67552751e-01 -5.64847231e-01  2.93780923e-01
 -7.84390509e-01  1.78393543e-01  1.13807917e-01 -1.51925787e-01
  1.65388566e-02 -2.84309871e-02  2.89208084e-01  4.18571323e-01
 -7.92370215e-02  2.52613544e-01 -4.19866703e-02  2.03923076e-01
  3.05144131e-01 -4.52983379e-02  3.65036912e-02 -1.50650991e-02
 -5.48198782e-02 -2.09441006e-01  2.83070877e-02 -2.07727045e-01
  3.45881283e-01  3.49877954e-01  2.44487494e-01  1.70102119e-01
  6.08477034e-02  8.56863186e-02  1.43410876e-01  8.32649767e-01
 -3.35920930e-01 -1.89787865e-01  1.79058284e-01 -3.08778346e-01
  7.23376200e-02 -2.99262721e-02  3.34989458e-01 -6.74248636e-01
  1.44107059e-01 -1.13046333e-01 -3.31558526e-01 -3.35380942e-01
 -3.44043046e-01 -2.55251765e-01  1.68093130e-01 -2.01766491e-01
 -1.55929789e-01 -9.02446285e-02 -3.05719554e-01 -2.87733108e-01
  4.99934424e-03 -1.83201432e-01  2.34241903e-01  1.64016206e-02
 -5.86093724e-01  2.50991315e-01 -1.42245188e-01 -3.08633685e-01
 -6.25765026e-01  2.41546229e-01 -1.01416200e-01  4.71172363e-01
 -4.40965563e-01  6.31353140e-01  5.32394536e-02  2.08072603e-01
 -1.33962750e-01 -1.47726342e-01  2.91972548e-01  1.08000562e-01
  3.74349624e-01 -7.11395204e-01  1.56166583e-01  2.21617758e-01
 -9.81037244e-02  1.58472133e+00 -8.49329531e-02 -6.19210422e-01
  3.11877966e-01  3.09059001e-03  4.30057719e-02  1.19559281e-01
 -6.01109639e-02 -7.70268857e-01  2.54336387e-01  3.33151605e-04
 -1.59930438e-02 -2.09955424e-01  1.33210167e-01 -2.91122720e-02
 -5.04182056e-02  5.20513691e-02  1.77748382e-01  3.45961928e-01
 -6.83216751e-02 -1.02948077e-01  6.33891597e-02 -3.21470022e-01
  7.24922121e-02 -1.79023482e-02 -3.69253069e-01  5.10332167e-01
 -5.72154880e-01 -1.30122110e-01  1.87046140e-01  2.62169689e-01
 -2.21172050e-01  7.98594952e-02 -4.43110764e-01  1.58603191e-01
  2.46390477e-01  1.24822743e-01  7.23790526e-02  2.52218600e-02
  1.49466664e-01 -4.50151742e-01  2.02749550e-01 -1.24554798e-01
  3.74894589e-01  3.39991540e-01 -1.45281598e-01 -1.49278253e-01
  8.03373475e-03  1.77711964e-01 -3.98897737e-01 -1.72331855e-01
  4.23049420e-01 -3.32226932e-01 -2.82062609e-02 -5.62702775e-01
 -1.82448402e-02  2.48900548e-01 -1.63811222e-01  6.31705299e-02
 -2.96380937e-01 -1.18744515e-01  1.30783960e-01  1.02227837e-01
  9.56856757e-02  7.28185177e-02 -1.50556803e-01  5.14996573e-02
 -5.52918732e-01  1.28406674e-01  6.85195029e-01  5.21673203e-01
  5.61749160e-01  2.29417253e-02 -2.58474737e-01 -4.47560668e-01
 -7.11483598e-01  4.90328342e-01  1.94647774e-01 -1.97549000e-01
  7.76859879e-01 -6.00545108e-01 -2.45168898e-02 -4.19126630e-01
 -7.40989637e+00 -4.66518588e-02 -8.89817253e-02  3.85782570e-02
 -2.12314546e-01 -2.41223335e-01  1.35083169e-01 -6.67572469e-02
 -1.73027426e-01  6.89294785e-02  1.99461896e-02  1.22905143e-01
 -1.16519213e-01  1.72094777e-01 -1.68556511e-01 -6.65160343e-02
  4.90193903e-01 -2.00230807e-01 -1.48091674e-01  3.34163308e-01
 -8.83370712e-02 -4.68981862e-01  5.03096543e-02 -3.11142117e-01
  1.49092562e-02 -1.92525715e-01 -1.71645641e-01  7.10670352e-02
  9.32516456e-02 -7.46107876e-01 -9.37723815e-02 -1.69896737e-01
 -8.98792818e-02  9.79642570e-01 -2.41295531e-01 -3.47303212e-01
 -4.61413801e-01 -5.45472741e-01 -1.05337948e-01  1.74715325e-01
  7.54778099e-04 -4.43902403e-01 -4.65964139e-01 -3.33518207e-01
  5.74891508e-01  1.06219180e-01  6.11865222e-01  5.92728019e-01
  9.79221836e-02  8.31397846e-02 -8.26299787e-02 -2.65446067e-01
  2.84411520e-01 -2.57333964e-01  2.34317500e-02  3.30944955e-02
  3.60092729e-01  6.76840305e-01 -1.01168662e-01 -1.77686691e-01
  2.59903193e-01 -5.26205420e-01 -4.23793435e-01  3.04744571e-01
 -4.32858467e-02 -6.01516813e-02 -7.43031383e-01 -3.34113300e-01
 -1.36255249e-01  4.10031527e-02 -1.60673231e-01  4.15377975e-01
  1.15622245e-01 -1.48232722e+00 -4.45648491e-01 -1.71798110e-01
  3.01329881e-01 -1.06551617e-01 -5.16518414e-01 -5.25935292e-01
 -5.45986950e-01 -3.46349627e-01  4.09732133e-01 -3.11769754e-01
 -1.13957256e-01  3.94565687e-02 -9.09658223e-02 -1.74477756e-01
 -3.86646956e-01  1.86558850e-02 -4.43453807e-03  1.01912849e-01
  4.64766055e-01 -2.85611957e-01  3.26376855e-02  3.21172252e-02
  5.65800905e-01 -2.33327672e-01 -2.46223714e-03  3.30044240e-01
  1.12133376e-01  4.19600904e-02  2.49498218e-01 -2.72109151e-01
 -4.75753009e-01  3.28687638e-01 -3.62554401e-01  1.48064941e-01
  1.64325312e-01  3.19481105e-01 -2.48557165e-01  2.54999399e-01
 -6.37672365e-01 -2.66312629e-01 -2.23049462e-01 -1.85049444e-01
 -7.78014734e-02  1.51796997e-01 -1.56251490e-01 -6.42692506e-01
 -2.15744227e-01  4.05564845e-01 -1.61606058e-01 -4.24233019e-01
  4.59051907e-01  1.18685635e-02  2.68300585e-02  6.48286760e-01
 -2.32298791e-01 -2.48317033e-01  7.09874406e-02 -5.37853539e-01
  1.29020378e-01 -2.90150285e-01  6.26523271e-02 -3.00270349e-01
  8.20047557e-02 -3.80070776e-01 -8.29212248e-01  2.70930141e-01
 -3.78553569e-02 -2.08546706e-02  2.44516805e-01  5.81777215e-01
  1.80475041e-01 -4.54177290e-01 -4.12985273e-02  3.55649382e-01
 -2.06575736e-01  2.31413588e-01 -3.57180506e-01 -8.72860789e-01
  8.38060081e-02 -3.88930827e-01  6.45290732e-01  3.07523906e-01
  1.93796858e-01 -3.63554090e-01  8.53530690e-02 -3.52991700e-01
  4.52660471e-01 -5.30064255e-02  1.08398227e-02  7.49832913e-02
 -2.68635929e-01  5.61462305e-02 -2.75800020e-01  3.29138488e-01
  1.44982442e-01 -7.06171572e-01 -1.85188696e-01 -1.63460106e-01
  2.54662216e-01 -3.22213858e-01 -2.23208919e-01  4.44363832e-01
  1.85632855e-01  3.63854855e-01 -4.70521539e-01  3.57061625e-01
  3.94579709e-01  7.57446110e-01 -5.74503057e-02  2.86839932e-01
  3.52465093e-01  5.37248373e-01  4.00597930e-01  2.97960371e-01
  3.01047236e-01  1.49130061e-01 -8.88925731e-01  3.44896287e-01
 -2.27046430e-01  2.21414685e-01 -4.93006885e-01 -5.99750102e-01
  4.88281071e-01 -6.14731133e-01  1.67653427e-01  9.27401632e-02
 -1.49627924e-01  8.18319991e-02 -2.54592448e-01  5.96714437e-01
 -1.56461462e-01 -6.16112091e-02  2.88490683e-01  1.23010375e-01
 -3.81892353e-01  2.96745785e-02 -2.20547408e-01 -3.75927925e-01
  4.68254358e-01 -5.09929299e-01  6.59480542e-02 -7.22429305e-02
 -4.43602830e-01 -4.80806261e-01 -8.79034519e-01  9.42303520e-03
 -2.53938079e-01  1.80823788e-01  3.11737120e-01  1.80436045e-01
  3.36142451e-01 -1.11934185e-01  3.36191952e-01  5.38866743e-02
 -5.58816195e-02 -4.21587259e-01 -2.31767565e-01 -1.67634678e+00
 -2.47686908e-01  6.42762482e-02  9.66830701e-02  2.67487555e-03
 -2.27760196e-01 -4.97372478e-01  1.20019257e-01 -5.56075633e-01
  6.15914285e-01 -3.88526112e-01 -1.99407533e-01 -4.21260655e-01
 -8.44080746e-02 -4.38462943e-01 -2.55520374e-01 -3.20917368e-02
 -7.67825782e-01  1.25752330e-01  4.77022678e-01  1.22330211e-01
 -7.33852684e-02 -6.60754919e-01  1.42930388e-01 -3.52084935e-01
 -2.44949490e-01 -2.20010698e-01  1.79796340e-03 -5.91422282e-02
 -1.17113240e-01 -2.90754467e-01 -5.59557498e-01  9.93357822e-02
 -7.71653533e-01 -1.33192658e-01  9.85682458e-02  5.77531084e-02
 -1.73547536e-01 -4.68712687e-01  4.08645123e-02 -2.51067191e-01
 -2.63114810e-01  6.31908596e-01 -6.31801784e-01 -5.87497614e-02
 -1.65379912e-01  1.14237420e-01  4.47411299e-01 -2.63333172e-02
  1.74159914e-01 -2.51027524e-01  1.31258830e-01  2.72532642e-01
  4.63337719e-01 -6.66104257e-01  5.05391918e-02  2.61927009e-01
  2.02279761e-02 -2.13240713e-01  4.21829641e-01  3.85721505e-01
 -3.07308793e-01 -6.37073278e-01 -5.89863181e-01  2.66139120e-01
  5.96289694e-01 -2.52255231e-01  3.50170434e-01  3.55909616e-01
 -2.46136323e-01  2.31025547e-01  7.33443677e-01 -2.13966891e-02
  2.39995614e-01 -5.86404741e-01 -3.75946403e-01 -5.45308173e-01
 -1.00742504e-01 -5.59010565e-01  7.15191513e-02 -4.29376602e-01
  5.40907383e-01  6.48371458e-01  3.31927598e-01 -5.21083117e-01
 -3.16696674e-01  1.81616858e-01  8.14689249e-02 -2.70378232e-01
 -4.94960189e-01  7.59839833e-01  4.73872691e-01 -1.30470827e-01
  4.47030365e-02  8.91491175e-01 -1.14962729e-02 -1.12355277e-01
 -1.10003814e-01  5.02213240e-02 -2.33038604e-01 -3.21440399e-02
 -7.76751265e-02  1.14419200e-01  5.49578130e-01 -2.62756824e-01
  3.51223722e-02 -2.35713273e-01 -4.82085675e-01  4.00476068e-01
  4.97627296e-02  2.67520010e-01  2.14953139e-01  3.81854892e-01
  5.44272102e-02 -1.33719698e-01 -8.23756382e-02  7.85679042e-01
  2.31846929e-01 -2.90153593e-01 -5.15514985e-03  7.54315988e-04
  1.09219201e-01 -2.00417861e-01 -5.11499755e-02 -8.37881565e-02
  3.55392575e-01 -1.10336930e-01 -1.52423650e-01  4.83478576e-01
  3.12284350e-01 -1.62697047e-01  8.10239092e-02 -9.55345094e-01
 -2.23442301e-01  1.20980255e-01  3.80974591e-01  4.38399583e-01
  3.97677124e-02 -2.68047959e-01  6.59532785e-01  4.01038438e-01
  4.20111924e-01 -1.00171909e-01  3.85998458e-01  5.62170625e-01
  5.56708947e-02 -4.51358259e-02  1.91811144e-01 -1.25254512e-01
 -1.86918661e-01 -2.24939913e-01 -3.14856559e-01  7.82756358e-02
 -5.51683366e-01 -1.96385160e-01 -3.92149627e-01  1.27070442e-01
  2.60112472e-02 -4.91044402e-01 -6.25641048e-01  1.96360469e-01
  4.92692828e-01 -9.24165547e-02  1.05049111e-01 -1.59420550e-01
  1.79819927e-01  4.37498391e-01  5.71978569e-01  1.22914918e-01
  1.75389826e-01 -2.27498174e-01 -3.99462670e-01 -6.99924305e-02
  3.58318239e-02 -3.44304889e-01 -2.92238355e-01  4.66336221e-01
 -7.83419728e-01 -9.69677418e-02  4.63757604e-01  6.91011250e-01
 -4.17065583e-02  1.98998392e-01  1.67695671e-01  3.40079039e-01
  5.06149113e-01  3.16312127e-02 -4.38809812e-01 -9.33860689e-02
 -3.48733813e-01 -1.59923211e-01  5.23047805e-01 -7.72966743e-02
  1.25309855e-01  2.84262925e-01 -1.09113343e-01 -3.25740308e-01
 -1.23992093e-01  3.10584515e-01  1.16442531e-01  1.68742791e-01
 -2.85188228e-01  3.76078039e-01 -1.15353607e-01  3.13802361e-01
 -4.24751848e-01  6.25073373e-01 -1.35887951e-01 -1.24757804e-01
 -4.91088420e-01  1.64059699e-01 -4.06992584e-02 -1.10026553e-01
  2.20920011e-01  1.46509022e-01 -1.57020509e-01  2.21208245e-01
 -1.15764722e-01 -3.37220997e-01 -4.70445752e-01 -9.07611288e-03
 -2.38111079e-01 -5.03406208e-03  3.84201229e-01  2.47256085e-02
 -5.61484516e-01 -4.56381701e-02 -2.01041222e-01 -9.88464653e-02]",LPYLPDEE,False,False,"[10.690591812133789, -1.9692655801773071]"
7HWEXAYH,JL8VM2MZ,"A Bidirectional Pipeline for Semantic Interaction

Michelle Dowling*, John Wenskovitch†, Peter Hauck‡, Adam Binford§, Nicholas Polys¶, Chris North||

Virginia Tech

ABSTRACT
Semantic interaction techniques in visual analytics tools allow ana-
lysts to indirectly adjust model parameters by directly manipulating
the visual output of the models. Many existing tools that support
semantic interaction do so with a number of similar features, includ-
ing using a set of mathematical models that are composed within a
pipeline, having a semantic interaction be interpreted by an inverse
computation of one or more mathematical models, and using an
underlying bidirectional structure within the pipeline. We propose a
new visual analytics pipeline that captures these necessary features
of semantic interactions. To demonstrate how this pipeline can be
used, we represent existing visual analytics tools and their semantic
interactions within this pipeline. We also explore a series of new
visual analytics tools with semantic interaction to highlight how the
new pipeline can represent new research as well.
Index Terms:
Human-centered computing—Visualization—
Visualization systems and tools; Human-centered computing—
Interaction design—Interaction design process and methods

1 INTRODUCTION
Semantic interaction is a powerful interaction methodology, allowing
analysts to explore and discover relationships in data [10]. Semantic
interaction exploits intuitive interactions to manipulate underlying
model-level parameters. Through semantic interactions such as the
direct manipulation of visualizations, visual analytics tools are able
to learn about the analyst’s reasoning process. This learning is ex-
pressed as alterations to the parameters of underlying mathematical
models, ultimately resulting in an updated visualization to reﬂect this
newly-learned information [13]. This coupling of machine learning
algorithms with the analyst’s knowledge and interactions allows for
the creation of robust analytics tools that collaboratively exploit the
skills of both human and computer.

For example, a number of semantic interaction tools and tech-
niques have been developed that make use of a visual “proxim-
ity ≈ similarity” metaphor to map observations1 into a visualiza-
tion [4, 12–14, 19, 25]. As analysts manipulate the observations in
these visualizations, they communicate a desired similarity between
a subset of observations, which in turn updates the underlying model
parameters that deﬁne the visualization. These interactions allow
an analyst to continue exploring and understanding relationships in
the data without pausing to manipulate model parameters manually.
This frees the analyst’s cognition to focus on high-level analysis
concepts rather than low-level parameter details [11]. As the analyst
continues to perform such semantic interactions, the tool learns more

*e-mail: dowlingm@vt.edu
†e-mail: jw87@vt.edu
‡e-mail: phauck@vt.edu
§e-mail: adamq@vt.edu
¶e-mail: npolys@vt.edu
||e-mail: north@cs.vt.edu

1In this work, we employ the convention of referring to individual data
items as observations and the properties of those observations as attributes.

about the analyst’s reasoning, and the visualization incrementally
adjusts to reﬂect the current data exploration [12].

Though a number of tools that use semantic interactions have
been developed, each is described in a distinct manner to highlight
the purpose for which the tool was built. Although there are more
generalized pipelines to describe the concepts behind such visual
analytics tools, such as the those proposed by Card et al. for informa-
tion visualization [6] and Keim et al. [16] for visual analytics tasks,
they do not incorporate sufﬁcient focus on the interactions to fully
capture the power and complexity of semantic interaction. Thus,
it can be difﬁcult to understand how semantic interactions affect
the underlying mathematical models and how these mathematical
models work together in a single tool.

To address this need for capturing the complexity involved in
semantic interactions for visual analytics tools, we begin by explor-
ing the characteristics of semantic interactions in such tools. With
these characteristics to guide us, we deﬁne a new pipeline that can
properly communicate how the visualization is created and how
semantic interactions are interpreted. We then demonstrate this new
pipeline’s capabilities by discussing the pipeline representations for
a set of existing tools as well as a selection of new visual analyt-
ics tools. Finally, we discuss other implications of using this new
pipeline, such as the ability to more thoroughly explore the design
space of semantic interaction or enable rapid prototyping, as well as
the limitations.

Speciﬁcally, we note the following contributions:
1. A review of the necessary components to accomplish semantic
interactions in visual analytics tools (i.e., model composability,
inverse computations, pipeline bidirectionality);

2. A new conceptual pipeline that incorporates the necessary

components of semantic interaction;

3. A set of examples demonstrating how this pipeline is capable
of capturing semantic interaction designs in both existing and
new visual analytics tools.

2 RELATED WORK
To fully capture the complexity of semantic interactions, our goal
in this work is to deﬁne a new conceptual pipeline that depicts the
structure of the feedback loop between the various data processing
components of the semantic interaction-enabled visual analytics
pipeline. We justify the need for such a pipeline by surveying the
current state of commonly-referenced pipeline models in information
visualization and visual analytics as well as exploring the breadth of
pipelines used to model existing visual analytics tools.

2.1 Existing Pipelines for Visual Analytics Processes
The ﬁelds of information visualization and visual analytics rely
on computational and visual pipelines to convert data into visual
displays. For example, Figure 12 (top) shows the Sensemaking Loop
deﬁned by Pirolli et al. [23], which identiﬁes the different mental
processes involved in transforming raw data into a presentation of
a formalized hypothesis. Located below the Sensemaking Loop in
this ﬁgure are both the information visualization pipeline of Card et
al. [6] and the visual analytics task process of Keim et al. [16].

These pipelines model a high-level representation of how raw
data is transformed to a ﬁnal visualization or presentation and are

2Larger versions of all ﬁgures are provided in the supplementary material.

Figure 2: V2PI [19] is a mathematical representation of semantic
interaction. This framework supports the creation of a visualization
V . When the analyst U manipulates V to form V(cid:48) via a semantic
interaction, this triggers a manipulation of the parameters θ that
inﬂuence model M. The parameterized feedback (Fp) represents an
inverse process similar to what is described by the Sensemaking
Loop, in which the interaction is interpreted as a set of updates to
model parameters.

support semantic interaction in visual analytics tools.

In contrast to these pipelines, V2PI [19] provides a statistical
semi-supervised machine-learning methodology for realizing seman-
tic interaction. The V2PI pipeline (Figure 2) supports interactivity
for visualizations and relies on both proven statistical methods and
the analyst’s judgment. In this pipeline, a visualization is created
by processing data and parameters through a mathematical model.
This visualization is presented to the analyst to evaluate. The analyst
can directly manipulate the visualization, referred to as cognitive
feedback. This cognitive feedback is translated into parameterized
feedback, typically via machine learning, which updates the model
through newly learned parameter values. As a result, a new visu-
alization is created based on the analyst’s interaction. Given this
deﬁnition of V2PI, we assert that V2PI appropriately captures the
basics of semantic interaction. However, V2PI only permits the
exploration of a single mathematical model to accomplish such in-
teractions. Thus, while V2PI may be able to capture simple visual
analytics tools which contain a single mathematical model, it is
not capable of representing tools with multiple models, such as
StarSPIRE [4].

2.2 Tool-Speciﬁc Pipelines
Semantic interaction tools have become increasingly varied in inter-
action methods and purpose. Here, we consider tools as implement-
ing semantic interaction if they meet three characteristics: (1) an-
alysts can directly manipulate visualization, (2) the tool interprets
the analyst’s intent from these interactions to update some learned
model (typically a semi-supervised machine learning algorithm),
and (3) the goal of these models and interactions is to enhance the
cognitive Sensemaking Loop [23].

To incorporate semantic interaction, some tools leverage the V2PI
framework previously discussed, including ForceSPIRE [12], Star-
SPIRE [4], and Andromeda [25]. In each of these tools, the analyst
directly interacts with observations in a dimension-reduced projec-
tion of data. These interactions drive a model that learns the relative
importance of the attributes in the high-dimensional data space.

Additional tools also support interacting with a projection, but
were not explicitly created with the V2PI framework in mind. Ex-
amples include the LAMP framework described by Joia et al. [15]
and the extention to iLAMP [7], the technique described by Mamani
et al. [20], Dis-Function [5], the technique deﬁned by Paulovich et
al. [22], and the tool developed by Molchanov et al. [21]. However,
semantic interaction can extend beyond interactions with projected
observations to learn attribute weights. For example, both Inter-
Axis [17] and AxiSketcher [18] use interactions on observations in
the projection to update the axes of the projection. Intent Radar [24]

Figure 1: (top) In the Sensemaking Loop [23], sensemaking contains
a backward (or inverse) process for each forward step. Chaining
these combined forward/inverse processes as composable processes
yields a full bidirectional cognitive pipeline. (middle) The information
visualization pipeline presented by Card et al. [6] does not speciﬁcally
model semantic interactions. (bottom) The visual analytics model
provided by Keim et al. [16] provides a high-level overview of the
structure of visual analytics knowledge discovery, but lacks detail in
deﬁning how mathematical models are used to interpret semantic
interactions.
In order to support semantic interaction, a different
pipeline structure is necessary.

quite generalizable, but the resulting trade-off is that these pipelines
abstract any details of the mathematical model(s) and visualization(s)
into single nodes in the graph. For example, the emphasis on a high-
level abstraction on visual analytics task processes means that the
pipeline deﬁned by Keim et al. does not explicitly discuss interaction.
Similarly, the focus on the mental processes in the Sensemaking
Loop means that mathematical models are not considered in this
pipeline. In contrast, the interactions described in the pipeline from
Card et al. represent methods to directly manipulate parameters
of mathematical models, such as slider interactions. While this is
interaction, we do not deﬁne this to be semantic interaction as no
interpretation is necessary by any model for this interaction; the
value provided by the analyst is simply stored and used. Thus, the
precise mechanisms used to process and visualize the data or to
interpret semantic interactions are not adequately captured in either
of these pipelines. Looking at other pipeline representations, such
as those presented in a survey of analytical pipelines by Wang et
al. [29], we ﬁnd the same limitations for semantic interaction tool
design. Thus, these pipelines are insufﬁcient for capturing how to

3.1 Model Composability
The ﬁrst characteristic we identiﬁed is that each mathematical model
used to process the data as it works its way to the ﬁnal visualization
has speciﬁc input and output requirements. This hints to how these
mathematical models must be composed to work together within the
pipeline in order to produce the desired visualization. For example,
PCA requires numerical high-dimensional data as input to produce
low-dimensional coordinates as output. Therefore, any models pre-
ceding PCA must produce these high-dimensional data, and any
models after PCA must be able to work with the low-dimensional co-
ordinates as input. As another example, Weighted Multidimensional
Scaling (WMDS) accepts numerical high-dimensional data as well
as a set of attribute weights as input to produce low-dimensional
coordinates as output. Thus, while the output is the same as with
PCA, the input requirements have changed. This change must be
accounted for in either data preprocessing steps or in a mathematical
model that precedes the WMDS model. Therefore, model compos-
ability is a fundamental characteristic of semantic interaction and is
represented by the top row of Figure 3.

3.2 Forward and Inverse Computations
While the model composability characteristic may seem simple or
intuitive, it has important implications for the structure of a pipeline
that captures semantic interaction. For example, Andromeda [26]
uses WMDS (Weighted Multi-Dimensional Scaling) to produce low-
dimensional coordinates given a set of attribute weights. However,
observation-level interaction, or OLI (which is a type of semantic
interaction), expands the WMDS model by providing new low-
dimensional coordinates from which to learn a new set of attribute
weights. Given that the dataset is treated as a constant, this effec-
tively inverts the WMDS computation.

We ﬁnd this type of computation inversion common in tools with
semantic interaction [4, 5, 8, 20, 22, 26, 31]; it is this inversion which
deﬁnes the learning or interpretation necessary to realize semantic
interaction. Therefore, we propose that computation inversion is a re-
quired characteristic for visual analytics tools that support semantic
interaction. Thus, our new pipeline must capture both forward and
inverse computations for a given model. This concept is represented
by the bottom right of Figure 3. Combined with the aforementioned
model composability, this means that each mathematical model must
fulﬁll composability requirements for its inverse computation as
well as its forward computation.

3.3 Looping Sensemaking via Bidirectionality
Taking the model composability and forward and inverse require-
ments a step further begins to imply a required bidirectionality in
how the models are used together.
In other words, each model
must fulﬁll composability requirements for both its forward and
inverse computations. Combine this with the fact that the forward
computations help produce the given visualization and the inverse
computations help interpret an interaction, then the pipeline must be
bidirectional to support a looping structure. This bidirectional struc-
ture can be seen in both StarSPIRE [4] and Andromeda [26], which
each use inverse computations of their models to interpret seman-
tic interactions, followed by the forward computations to generate
updated visualizations.

Referring back to the Sensemaking Loop [23], we see a similar
structure between pairs of processes that allow for information to
be progressively transformed. These pairs of processes allow the
transformation to occur in both forward and inverse directions, im-
plying that there is a concept of looping between these collections of
information. Thus, bidirectionality in a pipeline to represent seman-
tic interaction mimics this natural process of incrementally building
information to generate an output and then reassessing and reﬁning
information to produce a better output. This approach captures the

Figure 3: A representation of our three characteristics for a new
semantic interaction pipeline: Model Composability, Bidirectionality,
and Model Inversion. Model Composability refers to how different
mathematical models must work together to produce the desired
visualization. Bidirectionality allows interactions to drive updates to
the underlying models. Model Inversion refers to the pairs of a forward
computation with an inverse computation. The inverse computation
supports the translation of semantic interactions into manipulations of
model parameters.

introduces interactive intent modeling, allowing an analyst to pro-
vide feedback by dragging or clicking keywords, increasing the
relevance by moving the keyword closer to the center or decreasing
it by moving it outward in the radar interface. Moving away from
projection-based tools entirely, Podium [28] is a tabular ranking
tool in which an analyst reorders rows (still observations) in the
table while the tool learns the attributes important to the current
ranking scheme. iCluster [9] provides analysts with the ability to
interactively move documents into clusters, learning the attributes
important to the current clustering scheme. Similarly, ReGroup [1]
interactively learns a model of group membership as an analyst adds
members to groups.

Although each of these tools employ semantic interaction, few
of the papers offer associated pipelines to properly capture the com-
plexity involved with the interaction. Moreover, the pipeline rep-
resentations are diverse, ranging from high-level abstractions to
more detail-oriented representations. In Figure 5, we show a subset
of these pipeline representations, including Andromeda [26], Star-
SPIRE [4], Dis-Function [5], Piecewise Laplacian Projection [22],
and the pipeline provided by Mamani et al. [20] to describe their
technique. Although the pipelines for Andromeda and StarSPIRE
arguably achieve the highest level of detail to capture the semantic
interaction therein, we feel that these pipelines can be improved
to focus even more on the mathematical models used to create the
visualization and interpret the semantic interactions therein (which
is further explained in Section 5). In contrast, the pipelines for
Dis-Function, Piecewise Laplacian Projection, and the technique by
Mamani et al. are high-level pipelines which focus on the general
concepts behind how the associated tools and techniques work. The
trade-off in these, just as with the pipelines by Card et al. and Keim
et al., is that the mathematical models used are abstracted away, mak-
ing it difﬁcult to determine how the semantic interactions therein are
accomplished.

3 CHARACTERISTICS OF SEMANTIC INTERACTION IN VI-

SUAL ANALYTICS TOOLS

When comparing the characteristics of the visual analytics tools
discussed in the previous section, we note that there are several
commonalities. Combined with the ideas from the Sensemaking
Loop [23], we deﬁne three properties as necessary for supporting
semantic interaction in visual analytics tools. Each of these proper-
ties map directly to structures required to represent the complexity
involved in modeling semantic interactions in a generalized pipeline
for visual analytics tools.

concept of incremental formalism [2, 3, 27] in the cognitive sense-
making processes, in which analysts incrementally improve their
mental models of the data through interaction, and represents that
cognitive process formally as a machine learning process.

However, the Sensemaking Loop as well as existing semantic
interaction tools [8, 20, 22, 26, 31] also indicate that it is not always
necessary to iterate through the entire pipeline and all models to
generate the desired results. As an example, Andromeda [26] uses
the aformentioned semantic interaction of OLI. When this occurs,
an inverse computation is triggered that determines new attribute
weights given a set of low-dimensional coordinates. However, since
all the observations are already visualized, there is no need to pull
any additional data into the pipeline. Thus, there is no need for any
new data processing, meaning processing can skip to immediately
recalculating new low-dimensional coordinates for all observations
using the learned attribute weights. In the Sensemaking Loop, a
similar concept is represented by the fact that the analyst does not
have to go all the way back to the external data sources every time
he/she wishes to reﬁne information. For instance, an analyst reﬁning
an evidence ﬁle may only need to reread or perhaps read more
of a ﬁle that has already been accessed rather than foraging for a
completely new ﬁle.

These examples reveal an important feature with respect to this
bidirectionality characteristic: the ability to short circuit the rest
of the pipeline when appropriate. This is a key new feature of a
multi-model pipeline not found in earlier deﬁnitions [4]. Short cir-
cuiting happens when the inverse computation of a model does not
need to send the interaction any further down the pipeline. Thus,
instead of running the entire pipeline, we can short circuit to skip
over unnecessary components of the pipeline, executing the forward
computations beginning with the last model used to perform an in-
verse computation. From there, other models that were also updated
should also have their forward computations rerun to produce an
updated visualization. While the bidirectionality chatacteristic is
represented in the lower-left of Figure 3, this short circuiting concept
is depicted by the upward arrow between the inverse computation
and the forward computation in the lower-right of Figure 3.

4 COMPONENTS OF A SEMANTIC INTERACTION PIPELINE

FOR VISUAL ANALYTICS TOOLS

4.1 A New Semantic Interaction Pipeline
When evaluating traditional visual analytics models (e.g., Keim et
al. [16]), we note that there is rarely a distinction between different
models that may be used in the pipeline. Thus, model composability
is not well-represented in these existing models. Furthermore, while
bidirectionality may be represented on some level, the manner in
which the visual analytics pipeline handles this bidirectionality is
not discussed or represented in detail. Additionally, there is no
representation of inverse computations within the models. Therefore,
there is a need for a new pipeline for visual analytics tools that better
captures these characteristics of semantic interaction.

For our proposed new pipeline, we require properties of the
pipeline to map back to the model composability, model inversion,
and bidirectionality characteristics discussed previously. To capture
these characteristics, we deﬁne this new pipeline to consist of three
components, which are further described in the following subsec-
tions: a Data Controller, a set of Models, and the Visualization3.
This new pipeline is shown in Figure 4. The forward and inverse
computation characteristic is addressed by having each Model repre-
sent a set of such computations. Arrows between Models and other
pipeline components indicate how the input and outputs require-
ments for each component line up4, thereby addressing the model

3To differentiate common terms (e.g., a mathematical model) from

pipeline components, we capitalize pipeline components (e.g., Model).

4As shown in the SIRIUS pipeline in Section 6.2, it is certainly possible

composability characteristic. The bidirectionality of the overall
pipeline is handled through transitions between these computations,
using the forward computations in the projection direction and the
inverse computations in the interaction direction to loop through
the pipeline in response to a semantic interaction. Upward arrows
between inverse computations and forward computations of a given
Model show when the pipeline short-circuits rather than iterating
through the entire pipeline to interpret a semantic interaction. Thus,
this proposed structure accurately captures the power and complexity
of semantic interactions.

4.2 Models
As evident by our discussion thus far, the primary focal point of
our proposed pipeline is the Models. This is because the Models
alone must encompass two of the three identiﬁed characteristics of
semantic interaction: model composability and model inversion. To
capture the inversion characteristic, each Model consists of a set of
computations: a forward computation that is used to help produce
the desired Visualization and at least one inverse computation that
is used to help interpret an interaction by updating the inputs to
the forward computation. These inverse computations can come in
many forms, including precise mathematical inverses [25], heuristic
inverses [31], and probabilistic inverses [14].

The forward and inverse computations of the Model naturally
have input and output requirements, hinting at the given Model’s
composability with other pipeline components, whether they be
other Models in the pipeline, the Data Controller, or the Visual-
ization itself. These input and output requirements and how they
are addressed is implied by how the Model connects to these other
components in the pipeline. In Figure 4, this connectivity between a
given Model and other pipeline components is represented by the
arrows between these pipeline components. These arrows therefore
represent the process used to both create the desired Visualization
and interpret interactions within the Visualization. However, it is
important to note that while these arrows provide an overview of
how each Model is composed within the pipeline, the speciﬁc details
of how composability requirements are met are left to the corre-
sponding text accompanying the pipeline. To help provide more
details for these composability requirements through the pipeline
itself, the pipeline can be further annotated. For example, the ar-
rows throughout the pipeline can be annotated with mathematical
variables used to represent the inputs and outputs of each pipeline
component. The trade-off in doing so is that such annotations may
lead to visual clutter or initial confusion as to what these annotations
mean.

Since these arrows represent the processes of Visualization pro-
duction and interaction interpretation, we begin to note how the bidi-
rectionality requirement is also addressed through this new pipeline.
That is, there are a set of arrows that ﬂow through each Model in
the pipeline in a forward direction to produce the given Visualiza-
tion as well as a set of arrows that ﬂow in a backwards direction to
interpret interactions within the Visualization. Thus, the manner in
which the Models are represented in the pipeline alongside the other
pipeline components denotes the pipeline’s bidirectionality, thereby
capturing this ﬁnal characteristic of semantic interaction.

However, there is an additional nuance of bidirectionality that
is also captured within each Model: being able to short-circuit the
pipeline when no further computation is needed to interpret the given
interaction. This is represented by an arrow between the inverse
computation of a Model and its forward computation. Referring
to our previous example with Andromeda, OLI does not need to
communicate with any other pipeline component. Therefore, there is
no need to send this interaction further down the pipeline, allowing
the Model to short-ciruit. This immediately triggers a recalculation

to create non-linear pipelines that model how subsets of models collaborate
to handle different groups of semantic interactions.

Figure 4: Our new pipeline for semantic interaction in visual analytics tools, created from the combination of the three characteristics shown in
Figure 3. Model composability is shown through the chaining of a series of models horizontally in the pipeline. Bidirectionality results from the
separated forward (top) and inverse (bottom) paths through the models. Model inversion is shown through the pairing of a forward computation
and an inverse computation in each of the models. This representation also shows short circuiting arrows that connect the inverse and forward
computations in the Models. The resulting structure captures how data is transformed into a Visualization and how semantic interactions are
interpreted to update the parameters of the forward computations of the different Models.

of the low-dimensional coordinates of the data using the newly
calculated attribute weights, enabling the Visualization to update as
soon as possible.

4.3 Data Controller
Which Models are supported in a pipeline is highly dependent on
the data being used. Therefore, to better contextualize the Models in
the pipeline, our pipeline necessitates a Data Controller to serve as
the main access point to the underlying data that is being visualized.
Its key purpose is to retrieve the raw data and any possible metadata
as well as to transform this data into a form usable to the Models
through data preprocessing. Thus, the Data Controller can enable
analysts to view the raw data directly or allow the pipeline to pull
additional data to process and visualize. This means that a Data
Controller is speciﬁc to a particular type of data or dataset.

4.4 Visualization
Finally, it is difﬁcult to understand or appreciate a Model without un-
derstanding the Visualization being used and the interactions enabled
therein. Therefore, our new pipeline also requires a Visualization
component. Firstly, the Visualization must deﬁne how the output
from the Models are mapped to different visual elements in the Vi-
sualization. Additionally, this pipeline component determines how
the visual elements are interacted with and which Model(s) should
be used to interpret this interaciton. Thus, an interaction within the
Visualization initiates inverse computations in the Models of the
pipeline to interpret the given interaction and produce an updated
Visualization.

5 USING THE PIPELINE FOR EXISTING VA TOOLS
With this pipeline structure, we have the ability to well describe
the complexity of semantic interaction in existing visual analytics
tools. To exemplify this, we focus on the ﬁve of the visual analytics
tools and techniques we described in Section 2.2. Figure 5 shows a
side-by-side comparison of the pipelines provided in the perspective
papers for each tool or technique and how to represent each using
our newly proposed pipeline. From A to E in Figure 5:

Andromeda [26] provides a scatterplot projection of numerical
high-dimensional data using Weighted Multidimensional Scaling
(WMDS). In this projection, the analyst can perform a semantic
interaction called Observation-Level Interaction (or OLI) in which
he/she provides new low-dimensional coordinates for a subset of
the observations. From these observations, new attribute weights
are learned, which are then used to update the low-dimensional
coordinates of all the observations. Both these interactions manipu-
late the parameters for the WMDS mathematical model. Therefore,
three pipeline components are needed to represent Andromeda using
our new pipeline: a CSV Data Controller, a WMDS Model, and

the Visualization. The CSV Data Controller reads in a speciﬁed
CSV ﬁle of numerical high-dimensional data and normalizes each
attribute using z-scores. It also initializes each attribute weight to
be 1/p, where p is the number of attributes in the dataset. Using
this normalized data and attribute weights, the forward computation
of the WMDS Model determines the low-dimensional coordinates
for each observation. The Visualization component displays the
low-dimensional coordinates and the attribute weight values. The
inverse computation then determines new attribute weights based on
the analyst-deﬁned low-dimensional coordinates. At this point, the
pipeline always short-circuits to run the forward computation and de-
termine (and then display in the Visualization) new low-dimensional
coordinates for all observations; the CSV Data Controller is never
needed beyond the data preprocessing steps since all observations
are always displayed, meaning no further computation from the Data
Controller is needed.

StarSPIRE [4] provides a scatterplot-like projection for queried
text data. Thus, the analyst must perform a query and perform sub-
sequent queries or interactions in order to pull documents into the
visualization. To represent this process in our new pipeline, four
pipeline components are needed: a Text Data Controller, a Rele-
vance Model, a Force-Directed Model, and a Visualization. The
Text Data Controller initializes a set of extracted entities from the
document set and ensures each document has an associated TF-IDF
value for every entity. After providing references to the locations of
the documents themselves and an initialized set of entity weights,
1/p, the forward computation of the Relevance Model computes the
relevance of all documents according to the current entity weights.
Only the top n documents above a given threshold will be added to
the visualization. Thus, the Relevance Model acts as a query ﬁlter
for which documents are passed to the Force-Directed Model. The
forward computation of the Force-Directed Model determines the
low-dimensional coordinates of each document passed to it, using
the same entity weights to place similar documents near each other.
The Visualization then uses both the low-dimensional coordinates
and the relevance (mapped to node sizes) to display the documents.
Semantic interactions in StarSPIRE can cause the Force-Directed
Model and the Relevance Model to learn new entity weights in
their inverse computations. Thus, when the analyst manipulates
the document positions or relevances, new entity weights represent-
ing the analyst’s interest are learned and then used in the forward
computation to update the visualization accordingly.

Dis-Function [5] displays, among other views, a scatterplot of
projected pairwise distances using Principal Component Analysis
(PCA). An analyst is able to perform semantic interactions by pro-
viding new low-dimensional coordinates for observations, causing
the tool to learn new attribute weights for PCA and reprojecting the
observations using these new weights. This behavior is quite similar

Figure 5: Using the proposed semantic interaction pipeline shown in Figure 4, we can now model the behavior of existing semantic interaction
tools like (A) Andromeda [26], (B) StarSPIRE [4], and (C) Dis-Function [5], (D) Piecewise Laplacian Projection [22], and (E) Mamani et al. [20]).

to Andromeda, thereby using a PCA Model in place of Andromeda’s
WMDS Model in its pipeline.

Paulovich et al. [22] present a Piecewise Laplacian projection
tool in which samples are drawn from a full dataset, control points
are created for each sample, and a neighborhood graph is constructed
for the full dataset. As an analyst manipulates the projection through
semantic interactions, these control points and neighborhood graphs
dynamically update. Using our new pipeline, we can model this
process using a Sampling Model to perform the sampling step and a
Neighborhood Graph Model to perform the projection. In the Sam-
pling Model, the forward computation performs the initial sampling
step, which then feeds into the forward computation of the Neighbor-
hood Graph Model to specify the control points and project the data.
Semantic interactions can be performed by directly manipulating
the projection, causing the Neighborhood Graph Model to learn a
new projection through its inverse computation and short-circuiting
to rerun its forward computation. Since there is no semantic interac-
tion deﬁned that alters the Sampling Model, this model effectively
has no inverse computation deﬁned, highlighting the possibility for
additional semantic interactions to be included in this type of tool.
Mamani et al. [20] propose a tool similar to that of Paulovich et
al., though the projection is based on local afﬁne mappings rather
than Laplacian. Still, the basic process of sample ﬁrst and project
second remains the same in the forward computations. This means
that the pipeline representation of this tool uses a Local Afﬁne Force
Scheme Model in place of the Neighborhood Graph Model described
above. However, the process of responding to semantic interaction
also incorporates the inclusion of a new set of samples, thereby
incorporating an inverse computation in both the Local Afﬁne Force
Scheme Model and the Random Sampling Model.

6 USING THE PIPELINE FOR NEW VISUAL ANALYTICS

TOOLS

In this section, we illustrate three visual analytics prototypes that
have been developed using our new visual analytics pipeline to
further explore the design space for semantic interaction. These
prototypes handle different types of data (numerical and text) and
alter similar Models to create distinct Visualizations and semantic
interactions therein. Each of the prototypes are discussed in the

following format:

• Motivation: We begin by motivating the creation of the proto-
type, describing why such a tool is useful and what we could
learn from it.

• Visualization and Semantic Interactions: We describe the
Visualization developed and the semantic interactions enabled
therein to provide context for the various pipeline components.
• Pipeline: We discuss how the given Visualization and seman-
tic interactions are accomplished mathematically through our
new visual analytics pipeline. Since we deﬁne the Visualiza-
tion previously, we effectively separate the discussion of this
pipeline component from the others to improve clarity.

6.1 Cosmos
6.1.1 Motivation
The Cosmos pipeline was created to explore how to incorporate
the Relevance Model from StarSPIRE [4] with a stricter notion of
similarity than a force-directed layout, such as is accomplished in
Andromeda’s WMDS Model [26]. With these two models, analysts
can query for speciﬁc terms or documents in the dataset, view the
raw text from a document, manipulate a document’s relevance, and
directly manipulate the projection of the documents.

6.1.2 Visualization and Semantic Interactions
As shown at the bottom of Figure 6, the Cosmos Visualization
consists of two panels. While the left panel is an interactive WMDS
projection of the documents, the right panel displays the details
for a single selected document. Unlike in Andromeda, the WMDS
projection is initially empty, requiring the analyst to perform a
search to bring documents into the Visualization. After documents
are placed on the screen, their relevance calculations are mapped to
the sizes of the projected observations. The analyst can then use an
array of interactions to manipulate the Visualization. For example,
double-clicking an observation populates the panel to the right of this
projection with information speciﬁc to the corresponding document.
This includes an interactive relevance slider, the label of the projected
observation, and the raw text of a document and associated notes.
The analyst also has the ability to remove a document from the
Visualization by clicking a button on this panel.

the CSV ﬁle and preprocesses the data in the same manner as An-
dromeda’s Data Controller to ensure each entity is treated equally
by the Models. This is accomplished by normalizing each entity’s
TF-IDF values to be within a standard deviation of 1. Additionally,
this Text Data Controller adds references to the ﬂat ﬁles for each
document, which are assumed to be in a single directory.

The ﬁnal role of the Text Data Controller is to initialize a set of
entity weights for the Relevance Model and Similarity Model to
use, thus fulﬁlling the composability requirements for the forward
computations in these Models. We initialize these weights to be 1/p,
where p is the number of extracted entities in the uploaded CSV ﬁle.
These weights, along with the other document-related data, are sent
along the pipeline to the Models.

Relevance Model: We drew inspiration from StarSPIRE [4] to
create our Relevance Model. The Relevance Model uses the same set
of attribute weights that the WMDS Model does (which is described
next), but in a different manner. In the forward computation, this
model computes the relevance of a document given a set of attribute
weights as a linear combination of those weights and the document’s
TF-IDF values. This simple relevance calculation combined with a
threshold determines which documents are passed on to the WMDS
Model. That is, the Relevance Model acts as a ﬁlter that determines
which documents are visualized. The forward computation has a
matching inverse computation to calculate the entity weights that
produce a relevance value for a given document.

Additionally, the Relevance Model is responsible for querying
for new documents to display, whether the query was initiated by
the analyst by searching for a term or automatically by the Cosmos
itself (e.g., on OLI or increasing a document’s relevance). Using the
entity weights, the Relevance Model ﬁnds the top n most relevant
documents that are above the relevance threshold. This ensures that
only highly relevant documents are displayed while also guarantee-
ing that the analyst will not be overwhelmed by too many documents
appearing in the Visualization at once. If querying is not necessary
to interpret the given interaction (e.g., when the relevance value for
a document is decreased), then the Relevance Model simply short
circuits, allowing for immediate recalculation of the relevances of
all documents currently being displayed.

WMDS Model: The role of the WMDS Model is to spatial-
ize documents according to their similarity based on a given set
of attribute weights, just as is accomplished in Andromeda [26].
However, Cosmos relies on data passed from the Relevance Model
to deﬁne which documents should be used as well as the entity
weights. The forward computation uses these weights to project the
high-dimensional data in the Visualization.

The WMDS Model also uses the same inverse computation de-
ﬁned by Andromeda, enabling OLI interactions. This calculates the
entity weights based on low-dimensional coordinates of documents
in the Visualization. However, Cosmos also performs an automatic
query based on these new entity weights. Since this automatic query
always occurs after OLI and because the Relevance Model is re-
sponsible for such querying, the WMDS Model never short-circuits.
After the Relevance Model also recalculates document relevances,
the WMDS forward computation is then run to determine new low-
dimensional coordinates for all documents to be displayed in the
Visualization.

6.2 SIRIUS
6.2.1 Motivation
In the primary SIRIUS paper [8], we noted that analysts often think
about the observations and attributes in similar manners. In other
words, there is a symmetry between how analysts analyze attributes
and observations of a dataset. Therefore, there is a need to develop
visual analytics tools that afford this symmetric thought process,
leading us to develop SIRIUS (Symmetric Interactive Representa-
tions In a Uniﬁed System). While further details of SIRIUS are

Figure 6: (top) Our pipeline representation of Cosmos consists of
a Text Data Controller, Relevance Model, WMDS Model, and a Vi-
sualization. The Relevance and Similarity models each handle a
different component of manipulating the data to create the Visualiza-
tion. (bottom) The Cosmos interface allows analysts to interact with
documents, manipulating their similarity and relevance throughout the
exploration of the dataset.

As in Andromeda, the analyst can perform the semantic inter-
action of OLI in Cosmos by clicking and dragging documents
of interest in speciﬁc locations (to denote their desired similar-
ity/dissimilarity) and clicking an “Update Layout” button. This
triggers a recalcualtion of attribute weights using only the low-
dimensional observations the analyst interacted with. However,
Andromeda stops there and reprojects the entire dataset to create a
new Visualization; Cosmos continues its interpretation of this inter-
action by automatically performing a query for more documents on
behalf of the analyst, guided by these new attribute weights. After
combining the new documents with the old documents, the rele-
vance of each document is recalculated, and the data is reprojected
to genereate a new Visualization.

In addition to OLI, Cosmos affords an additional semantic in-
teractions through its “Relevance” slider. This slider is available
for a selected document, as seen in the details panel at the bottom
of Figure 6. When this slider is manipulated by the analyst, the
new attribute weights are calculated which best estimate the analyst-
deﬁned relevance for the given document. If the relevance for the
document is increased, then this interaction is interpreted as reﬂect-
ing a document that the analysts likes and would want to see more
of. Therefore, this interaction also triggers an automatic query for
more documents, which uses these new attribute weights. Otherwise,
the pipeline simply continues its process by recalculating all doc-
ument relevancies and reprojecting all documents to create a new
Visualization.

6.1.3 Pipeline
The Cosmos pipeline is shown at the top of Figure 6. Note that
this pipeline is similar to the StarSPIRE pipeline. In addition to the
replacing the Display Similarity Model with the WMDS Model, we
have modiﬁed the Data Controller and Visualization as well. Each
component of this pipeline is described below:

Text Data Controller: For this pipeline, we modiﬁed the Data
Controller from Andromeda to work with text documents. To do
so, we ﬁrst assume that the uploaded CSV ﬁle contains the TF-IDF
values for entities extracted from the document set. This assumption
allows us to skip additional preprocessing steps to focus instead on
the Models themselves and their inﬂuence on the Visualization.

Once uploaded, this Text Data Controller reads the data from

for any one observation or attribute using a linear combination of
attribute or observation weights and the associated data for the given
observation or attribute (respectively). However, these calculations
also make it easy to translate the importance of attributes to the
importance of observations and vice versa by expanding the impor-
tance calculation for a single observation or attribute to calculate
the importance of all observations or all attributes at once. Thus,
these importance calculations enable a recalculation of observation
weights based on entity weights and vice versa. Since the WMDS
Models (discussed next) use the same set of weights, this means
that both projections update based on a single interaction in either
projection.

To enable semantic interactions, the Importance Model’s inverse
computations begin when the analyst manipulates the “Importance”
slider. This triggers an inverse calculation of the weights that pro-
duce the analyst-deﬁned “importance” value using equations similar
to those used in the Relevance Model’s inverse computation from
Cosmos. For example, if the analyst manipulates the “importance”
value for an attribute, then the observation weights to produce that
“importance” value are calculated using one of these inverse com-
putations. However, these new weights are then used to determine
new attribute weights. To enable more insights for attribute similar-
ities/correlations, these attribute weights from the inverse compu-
tation are then used to recalculate new observation weights in the
forward computation. These ﬁnal sets of weights are then used in
the WMDS Models to reproject the data in the Visualization.

The Importance Model performs a similar set of calculations on
OLI. For example, if OLI is performed in the observation panel,
then a new set of attribute weights are determined in the WMDS
Model. However, to translate this change to changes in the attribute
projection as well, new observation weights must be determined. As
a result, both new sets of weights are passed to the WMDS Models
to determine the new positions of the nodes in both panels.

It is important to note that just as with Andromeda, SIRIUS
assumes that all observations and attributes are used from the begin-
ning. Since no querying for new data is performed, SIRIUS never
needs to communicate with the CSV Data Controller again, causing
the Importance Model to always short-circuit.

WMDS Models: As seen in Figure 7, SIRIUS consists of two
WMDS Models: one for the projection of observations and one
for the projection of attributes. The Observation WMDS Model
uses the normalized form of the original dataset and the same at-
tribute weights used by the Relevance Model to determine the low-
dimensional coordinates for each observation using the same WMDS
equation from Andromeda and Cosmos. Similarly, the Attribute
WMDS Model uses the normalized form of the transposed dataset
and the same observation weights used by the Relevance Model to
determine the low-dimensional coordinates for each attribute.

Each of these WMDS Models enable OLI separately. That is,
OLI can only be performed on one panel at a time. Then, an inverse
WMDS computation similar to the computation described in [26]
is used to calculate a new set of weights. These weights are then
passed to the Relevance Model to enable updates in both panels.

6.3 A Cluster-Based Visualization
6.3.1 Motivation
We have also begun investigating how the introduction of explicit
clustering assignments affect the ways in which analysts perceive
and interact with projections [31]. The technique itself can make use
of a variety of layout and clustering techniques, but the following im-
plementation describes an instantiation using a force-directed layout
for similarity projection and k-means clustering on the projection to
automatically group similar observations. Analysts directly interact
with the projection using semantic interactions to alter clustering as-
signments of the observations in order to manipulate the underlying
mathematical models.

Figure 7: (top) Our pipeline representation of how SIRIUS produces
the observation and attribute WMDS projections and how this tool in-
terprets semantic interactions therein using our new proposed pipeline.
This is accomplished using a CSV Data Controller, Importance Model,
two WMDS Models, and a Visualization. (bottom) This Visualization
consists of two interconnected, interactive WMDS projections: one
for the observations and one for the attributes of a high-dimensional
dataset.

described in [8], we focus on its pipeline representation here.

6.2.2 Visualization and Semantic Interactions
The SIRIUS Visualization in Figure 7 consists of two main panels:
a left panel for a projection of the observations and a right panel
for the projection of the attributes. Both projections are WMDS
projections, with node sizes and opacities reﬂecting the importance
of the given observation or attribute. Both of these panels enable the
same semantic interaction of OLI previously described. However,
instead of only updating one projection, this semantic interaction
updates both projections in SIRIUS.

Below these two main panels is a third panel that provides an
interactive “Importance” slider that allows the analyst to deﬁne the
importance of a selected observation or attribute. The associated raw
data is also provided in the text ﬁeld in this panel for the analyst’s
convenience. Manipulation of this “Importance” slider is a semantic
interaction that triggers a recalculation of attribute weights and
observation weights, thereby resulting in updates to both projections
in SIRIUS.

6.2.3 Pipeline
CSV Data Controller: The Data Controller used in SIRIUS is virtu-
ally the same as the one used in Andromeda. The main difference is
that the Data Controller in SIRIUS must normalize both the original
data as well as its transpose separately. This enables the projections
to represent all observations and attributes without an artiﬁcial em-
phasis placed on any one attribute or observation due to naturally
higher values (e.g., height vs weight of a person).

Importance Model: We again drew inspiration from Star-
SPIRE’s Relevance Model as it provides a simple method for the
forward computation to calculate the importance (i.e., relevance)

and the weights that have been learned for those attributes. This
dissimilarity matrix is then passed to the Layout Model to be ren-
dered. The inverse computation aims to understand why the analyst
decided that this observation does not belong to its original assigned
cluster and/or better belongs to its analyst-assigned cluster. This is
accomplished by computing a distance between the observation and
the involved cluster(s) centroid(s), ranking the attributes based on
dissimilarity, and then updating the attribute weights accordingly.
Force-Directed Model: After a distance has been computed
for every observation pair, these distances are loaded into a force-
directed node-link visualization. The force-directed graph then
stabilizes to a low-energy layout. There is no inverse computation
for this model.

k-Means Model: Clusters are computed continuously using a
modiﬁed k-means algorithm in the forward computation of the k-
Means Model. This computation has been altered from traditional
k-means to include a maximum cluster radius that allows some
nodes to exist external to all clusters. As the force-directed graph
reaches a stable layout, individual observations may transition into
and out of clusters as they move closer to and further from each
cluster centroid. The inverse computation of this model detects
analyst-initiated changes in observation clustering assignments, and
it passes the old and new cluster information to the next inverse
computation.

7 DISCUSSION
In this section, we discuss the implications of our new pipeline that
is capable of capturing the complexity of semantic interactions in
visual analytics tools. This discussion includes how this pipeline
highlights the various semantic interaction possibilities in any given
visual analytics tool, the ability to leverage this pipeline for rapid
prototyping, and the limitations of this pipeline.

7.1 Exploring the Design Space of Semantic Interaction
With the greater emphasis placed on the mathematical models in
our proposed new pipeline for visual analytics tools, opportunities
for semantic interaction are highlighted. This is due to the fact
that every Model should have both a forward computation and an
inverse computation. If a given pipeline does not have an inverse
computation for a Model, such as in the Sampling Model in the
Piecewise Laplacian projection tool [22], then perhaps there is a
missed opportunity for implementing a semantic interaction. Even
for those that already have inverse computations, there may still
be the potential to implement an additional or alternative inverse
computation for the same Model.

For example, the forward computation in Andromeda’s WMDS
Model uses two parameters (the high-dimensional data and a set
of attribute weights) to produce a single output (low-dimensional
coordinates). However, the “inverse WMDS” computation described
only computes new attribute weights given new low-dimensional
coordinates, thereby assuming the high-dimensional data is static.
However, what if instead the assumption was that the attribute
weights were static and new high-dimensional data for an undeﬁned
observation was desired? Such an interaction may be triggered by
the analyst clicking in an empty space of the projection not already
occupied by an observation, effectively interpolating what attributes
a high-dimensional observation would have if it were projected in
that location.

Additionally, our previous research has identiﬁed a variety of
ways to combine a similarity-based Model with a clustering Model
to create different types of projections [30]. With this multitude of
pipelines possible, there are naturally many methods of enabling
semantic interactions with just two Models. Thus, in cases such
as these, our newly-proposed pipeline can help further explore the
design space of semantic interaction by highlighting the numerous
possibilities, even when there are few Models involved.

Figure 8: (top) Our pipeline representation for how the cluster-based
visualization by Wenskovitch and North is created and semantic in-
teractions therein are interpreted. This is accomplished using a CSV
Data Controller, Dissimilarity Model, Force-Directed Model, k-Means
Model, and Visualization. (bottom) The clustering interface allows
analysts to explore related groups of observations depending on the
learned attribute weights.

6.3.2 Visualization and Semantic Interactions
The Visualization for this tool (bottom of Figure 8) simply consists
of a large projection space accompanied by a column of attribute
weights. Individual observations are still rendered as labeled nodes
in the display, but are grouped by saturated convex hulls. The dis-
tance between pairs of observations is a weighted dissimilarity com-
putation, in which the resting length of each link corresponds to the
difference between the observation endpoints across all attributes.

Once again, analysts can perform OLI interactions on the ob-
servations. However, these semantic interactions only affect the
mathematical models when an observation has been reclassiﬁed into
a new cluster (i.e., manipulating the distance between observations
within a cluster has no effect on the learned weights). When an
analyst adds an observation to a cluster or removes an observation
from a cluster (or both), the attribute weights are recalculated based
on a dissimilarity measurement between the relocated observation
and the centroid(s) of the involved cluster(s). After this computa-
tion, the resting length of each link is recalculated based on the new
attribute weights. As a result, additional observations may reclassify
themselves as the force-directed layout repositions the observations
in the projection.

6.3.3 Pipeline
CSV Data Controller: The Data Controller used in this tool is
identical to that used in Andromeda: numerical high-dimensional
data is simply read in from a CSV ﬁle and normalized, and attributes
weights are initialized to equal values.

Dissimilarity Model: The forward computation of the Dissimi-
larity Model computes a distance between each pair of observations,
taking into account both the differences between the attributes values

7.2 Rapid Prototyping to Explore Design Trade-Offs
To quickly and efﬁciently explore the design space of semantic in-
teraction, the ability to rapidly prototype several techniques from
the visual analytics literature, and augment them with semantic
interaction, would be immensely helpful. Trade-offs in different
implementations may imply different Models being used or perhaps
the same ones being altered to produce different results. For ex-
ample, Cosmos is very similar in appearance to Andromeda, yet
functions more like StarSPIRE (as evidenced by the similarities
in their pipeline representations). SIRIUS and the visualization by
Wenskovitch and North are both similar to Cosmos in their own man-
ners as well, yet these tools operate in distinctly different manners
by adding additional Models to the pipeline.

However, the current issue in experimenting with these kinds of
trade-offs is that many visual analytics tools are created such that
changing one Model for another is difﬁcult; too often, the program
structure for the given tool is heavily reliant on the speciﬁc Models
being used. By deﬁning the pipeline components and creating a
pipeline such as the ones that we present here, we assert that our
new visual analytics pipeline can help promote more modularized
code. This is because every pipeline component has composabil-
ity requirements, which are described by the arrows between the
pipeline components. By structuring the program for the tool in
this manner, the composability requirements help enforce modular
code design. This modularity then makes interchanging different
Models– and even different Visualizations and Data Controllers–
trivial, thereby making exploring different areas of the design space
of semantic interaction even easier.

For example, it may be apparent from Figure 6 and Figure 7
that Cosmos and SIRIUS have very similar-looking Visualizations.
This is because the Cosmos pipeline– including its Models and
Visualization– were all leveraged and adapted to enable SIRIUS. In
fact, we have been able to separate each pipeline component to the
point that we are able to interchange Cosmos and SIRIUS at will.

7.3 Limitations
Despite the power and ﬂexibility of our proposed new visual ana-
lytics pipeline for semantic interaction, it is not without limitations.
We brieﬂy address several of these limitations here.

7.3.1 Requirements Limitations
The primary limitation of our semantic interaction pipeline lies
in the requirement of providing an inverse computation for each
forward computation. We assert this requirement as essential for
enabling semantic interaction, yet we provide no guidance for how
to determine what such an inverse computation should be. That is,
the inverse computation can be mathematically rigorous, heuristic,
or probabilistic, but the creation of the inverse computation lies with
the Model creator.

Similarly, the pipeline requires Models to be composable with
other pipeline components, but we provide limited instructions for
deﬁning this composability. For example, if the Text Data Controller
for Cosmos were altered to use dynamic document sets, then at some
point before any of the data preprocessing steps could be performed,
the TF-IDF values would need to be computed on the ﬂy. This would
allow the other pipeline components to remain unchanged. If instead
the TF-IDF values were not computed and no data preprocessing
steps occurred in the Data Controller, the responsibility for doing
so (to maintain data composability with the WMDS Model) would
either fall to the Relevance Model or to a new Model that would rest
between the Data Controller and Relevance Model.

7.3.2 Limitations of Pipeline Components
Another potential limitation is that we deﬁne a Model to be com-
prised of any forward computation and at least one accompanying
inverse computation. It may very well be that there are only a few

different categories or types of such Models (e.g., data manipulation
Models that work the raw data into a form usable to the Visualiza-
tion, projection Models that determine the overall type of projection
used in the Visualization, and other Models that seek to augment
the Visualization with additional information). Such a categoriza-
tion may be useful to deﬁne the nuanced differences between how
Models may be used and which ones deﬁnitely should have inverse
computations to interpret semantic interactions. However, we do not
attempt to make any such categorization; instead, we focus on the
overall pipeline structure to generate discussion and critical thinking
regarding which Models should be included, how the Models ﬁt to-
gether to realize an interactive visual analytics tool, and the various
manners in which semantic interaction can be realized.

7.3.3 Limitations of the New Visual Analytics Tools
Rather than creating fully-featured tools, we use this pipeline to
quickly and efﬁciently prototype visual analytics tools to explore the
semantic interaction design space. As a result of this design decision,
the prototypes that we implemented in Section 6 only support a
limited number of semantic interactions. However, we argue that
each of our prototypes can support additional semantic interactions
with the addition of more Models or alterations of existing Models
in each pipeline.

8 CONCLUSION
In this work, inﬂuenced by the Sensemaking Loop described by
Pirolli and Card [23] as well as the growing body of visual analyt-
ics tools that implement semantic interaction, we proposed three
characteristics shared by semantic interaction applications: model
composability, model inversion, and pipeline bidirectionality. From
these characteristics, we proposed a new visual analytics pipeline
that enables proper representation of the complexity involved in
semantic interactions. This new pipeline is comprised of three main
types of components: Data Controllers, Models (containing forward
and inverse computations), and Visualizations.

We demonstrated the ability of our new pipeline to capture se-
mantic interactions by providing pipeline representations of existing
visual analytics tools. Then, we discussed pipeline representations
for new visual analytics tools, highlighting the extensibility of this
new pipeline new research in this area.

We also brieﬂy discussed how this new pipeline may help further
the exploration of the design space of semantic interaction and
enable rapid prototyping of new visual analytics tools with semantic
interaction. By rapidly prototyping such tools, researchers will
be able to quickly create and study many alternative methods of
semantic interaction. We intend to continue expanding on our own
prototypes and conduct user studies to study how analysts perceive
and use different visualization and interactions. Such research may
uncover which methods best support the analyst’s sensemaking
process and how to develop better visual analytics tools in the future.

ACKNOWLEDGMENTS
This research was partially supported by NSF grant IIS-1447416.
The authors also wish to thank the BaVA @ VT research group
for their contributions in this research, General Dynamics for their
support, and the reviewers for helping improve this paper.

REFERENCES
[1] S. Amershi, J. Fogarty, and D. Weld. Regroup: Interactive machine
learning for on-demand group creation in social networks. In Pro-
ceedings of the SIGCHI Conference on Human Factors in Computing
Systems, CHI ’12, pp. 21–30. ACM, New York, NY, USA, 2012. doi:
10.1145/2207676.2207680

[2] C. Andrews, A. Endert, and C. North. Space to think: Large high-
resolution displays for sensemaking. In Proceedings of the SIGCHI
Conference on Human Factors in Computing Systems, CHI ’10, pp.

[20] G. M. H. Mamani, F. M. Fatore, L. G. Nonato, and F. V. Paulovich.
User-driven feature space transformation. Computer Graphics Forum,
32(3pt3):291–299, 2013. doi: 10.1111/cgf.12116

[21] V. Molchanov and L. Linsen.

Interactive Design of Multidimen-
sional Data Projection Layout. In N. Elmqvist, M. Hlawitschka, and
J. Kennedy, eds., EuroVis - Short Papers. The Eurographics Associa-
tion, 2014. doi: 10.2312/eurovisshort.20141152

[22] F. Paulovich, D. Eler, J. Poco, C. Botha, R. Minghim, and L. Nonato.
Piecewise laplacian-based projection for interactive data exploration
and organization. Computer Graphics Forum, 30(3):1091–1100, 2011.
doi: 10.1111/j.1467-8659.2011.01958.x

[23] P. Pirolli and S. Card. The sensemaking process and leverage points
for analyst technology as identiﬁed through cognitive task analysis.
Proceedings of International Conference on Intelligence Analysis, 5,
2005.

[24] T. Ruotsalo, J. Peltonen, M. Eugster, D. Glowacka, K. Konyushkova,
K. Athukorala, I. Kosunen, A. Reijonen, P. Myllym¨aki, G. Jacucci,
and S. Kaski. Directing exploratory search with interactive intent
modeling. In Proceedings of the 22nd ACM international conference
on Conference on information and knowledge management, CIKM
’13, pp. 1759–1764. ACM, New York, NY, USA, 2013. doi: 10.1145/
2505515.2505644

[25] J. Z. Self, X. Hu, L. House, S. Leman, and C. North. Designing usable
In CHI
interactive visual analytics tools for dimension reduction.
2016 Workshop on Human-Centered Machine Learning (HCML), p. 7,
05/2016 2016.

[26] J. Z. Self, R. K. Vinayagam, J. T. Fry, and C. North. Bridging the gap
between user intention and model parameters for human-in-the-loop
data analytics. In Proceedings of the Workshop on Human-In-the-Loop
Data Analytics, HILDA ’16, pp. 3:1–3:6. ACM, New York, NY, USA,
2016. doi: 10.1145/2939502.2939505

[27] F. M. Shipman and C. C. Marshall. Formality considered harmful:
Experiences, emerging themes, and directions on the use of formal rep-
resentations in interactive systems. Computer Supported Cooperative
Work (CSCW), 8(4):333–352, 1999. doi: 10.1023/A:1008716330212
[28] E. Wall, S. Das, R. Chawla, B. Kalidindi, E. T. Brown, and A. Endert.
Podium: Ranking data using mixed-initiative visual analytics. IEEE
Transactions on Visualization and Computer Graphics, 24(1):288–297,
Jan 2018. doi: 10.1109/TVCG.2017.2745078

[29] X.-M. Wang, T.-Y. Zhang, Y.-X. Ma, J. Xia, and W. Chen. A survey of
visual analytic pipelines. Journal of Computer Science and Technology,
31(4):787–804, 2016. doi: 10.1007/s11390-016-1663-1

[30] J. Wenskovitch, I. Crandell, N. Ramakrishnan, L. House, S. Leman, and
C. North. Towards a systematic combination of dimension reduction
and clustering in visual analytics. IEEE Transactions on Visualization
and Computer Graphics Proceedings of the Visual Analytics Science
and Technology 2017, 24(01), January 2018.

[31] J. Wenskovitch and C. North. Observation-level interaction with clus-
In Proceedings of the
tering and dimension reduction algorithms.
2nd Workshop on Human-In-the-Loop Data Analytics, HILDA’17, pp.
14:1–14:6. ACM, New York, NY, USA, 2017. doi: 10.1145/3077257.
3077259

55–64. ACM, New York, NY, USA, 2010. doi: 10.1145/1753326.
1753336

[3] C. Andrews and C. North. Analyst’s workspace: An embodied sense-
making environment for large, high-resolution displays. In 2012 IEEE
Conference on Visual Analytics Science and Technology (VAST), pp.
123–131, Oct 2012. doi: 10.1109/VAST.2012.6400559

[4] L. Bradel, C. North, L. House, and S. Leman. Multi-model semantic
In 2014 IEEE Conference on Visual
interaction for text analytics.
Analytics Science and Technology (VAST), pp. 163–172, Oct 2014. doi:
10.1109/VAST.2014.7042492

[5] E. T. Brown, J. Liu, C. E. Brodley, and R. Chang. Dis-function:
Learning distance functions interactively. In 2012 IEEE Conference on
Visual Analytics Science and Technology (VAST), pp. 83–92, Oct 2012.
doi: 10.1109/VAST.2012.6400486

[6] S. K. Card, J. D. Mackinlay, and B. Shneiderman. Readings in in-
formation visualization: using vision to think. Morgan Kaufmann,
1999.

[7] E. P. dos Santos Amorim, E. V. Brazil, J. Daniels, P. Joia, L. G. Nonato,
and M. C. Sousa. ilamp: Exploring high-dimensional spacing through
backward multidimensional projection. In 2012 IEEE Conference on
Visual Analytics Science and Technology (VAST), pp. 53–62, Oct 2012.
doi: 10.1109/VAST.2012.6400489

[8] M. Dowling, J. Wenskovitch, J. Fry, S. Leman, L. House, and C. North.
SIRIUS: Dual, symmetric, interactive dimension reductions. In 2018
IEEE Conference on Visual Analytics Science and Technology (VAST),
Oct 2018.

[9] S. M. Drucker, D. Fisher, and S. Basu. Helping users sort faster with
adaptive machine learning recommendations. In P. Campos, N. Gra-
ham, J. Jorge, N. Nunes, P. Palanque, and M. Winckler, eds., Human-
Computer Interaction – INTERACT 2011, pp. 187–203. Springer Berlin
Heidelberg, Berlin, Heidelberg, 2011.

[10] A. Endert. Semantic interaction for visual analytics: Toward coupling
cognition and computation. Computer Graphics and Applications,
IEEE, 34(4):8–15, July 2014. doi: 10.1109/MCG.2014.73

[11] A. Endert, P. Fiaux, and C. North. Semantic interaction for sensemak-
ing: Inferring analytical reasoning for model steering. IEEE Trans-
actions on Visualization and Computer Graphics, 18(12):2879–2888,
Dec 2012. doi: 10.1109/TVCG.2012.260

[12] A. Endert, P. Fiaux, and C. North. Semantic interaction for visual text
analytics. In Proceedings of the SIGCHI Conference on Human Factors
in Computing Systems, CHI ’12, pp. 473–482. ACM, New York, NY,
USA, 2012. doi: 10.1145/2207676.2207741

[13] A. Endert, C. Han, D. Maiti, L. House, S. Leman, and C. North.
Observation-level interaction with statistical models for visual ana-
In 2011 IEEE Conference on Visual Analytics Science and
lytics.
Technology (VAST), pp. 121–130, Oct 2011. doi: 10.1109/VAST.2011.
6102449

[14] L. House, S. Leman, and C. Han. Bayesian visual analytics: BaVA.
Statistical Analysis and Data Mining, 8(1):1–13, 2015. doi: 10.1002/
sam.11253

[15] P. Joia, D. Coimbra, J. A. Cuminato, F. V. Paulovich, and L. G. Nonato.
Local afﬁne multidimensional projection. IEEE Transactions on Visu-
alization and Computer Graphics, 17(12):2563–2571, Dec 2011. doi:
10.1109/TVCG.2011.220

[16] D. Keim, G. Andrienko, J.-D. Fekete, C. G¨org, J. Kohlhammer, and
G. Melanc¸on. Visual Analytics: Deﬁnition, Process, and Challenges,
pp. 154–175. Springer Berlin Heidelberg, Berlin, Heidelberg, 2008.
doi: 10.1007/978-3-540-70956-5 7

[17] H. Kim, J. Choo, H. Park, and A. Endert. Interaxis: Steering scat-
terplot axes via observation-level interaction. IEEE Transactions on
Visualization and Computer Graphics, 22(1):131–140, Jan 2016. doi:
10.1109/TVCG.2015.2467615

[18] B. C. Kwon, H. Kim, E. Wall, J. Choo, H. Park, and A. Endert.
Axisketcher: Interactive nonlinear axis mapping of visualizations
through user drawings. IEEE Transactions on Visualization and Com-
puter Graphics, 23(1):221–230, Jan 2017. doi: 10.1109/TVCG.2016.
2598446

[19] S. C. Leman, L. House, D. Maiti, A. Endert, and C. North. Visual to
parametric interaction (v2pi). PLoS ONE, 8(3):1–12, 03 2013. doi: 10.
1371/journal.pone.0050474

","{""0"":{""0"":""wmds"",""1"":""sirius"",""2"":""ieee*"",""3"":""v2pi"",""4"":""endert""},""1"":{""0"":""computation"",""1"":""computer*"",""2"":""human*"",""3"":""graphics*"",""4"":""technology*""},""2"":{""0"":""data"",""1"":""models"",""2"":""weights"",""3"":""tools"",""4"":""documents*""},""3"":{""0"":""semantic*"",""1"":""relevance*"",""2"":""importance*"",""3"":""characteristic"",""4"":""dissimilarity*""},""4"":{""0"":""observation"",""1"":""loop*"",""2"":""input*"",""3"":""feedback*"",""4"":""direction*""},""pos"":{""0"":1,""1"":2,""2"":3,""3"":4,""4"":5}}",2018,{},False,False,journalArticle,False,7HWEXAYH,[],self.user,"{""C"":{""0"":7.4233940671,""1"":17.7970989022,""10"":8.850603457,""11"":14.3794272917,""12"":18.4832570352,""13"":14.6258890775,""14"":7.4272239173,""15"":6.8767523363,""16"":9.9984391457,""17"":25.0680978736,""18"":13.2422616151,""19"":18.3472983228,""2"":7.1942408099,""20"":7.062410517,""21"":7.4637742741,""22"":5.9001558718,""23"":16.0132925861,""24"":14.1192479137,""25"":6.4520424066,""26"":10.8915946176,""27"":7.4439180218,""28"":7.4924660484,""29"":9.198473127,""3"":6.0445992494,""30"":16.7972342417,""31"":9.8124782909,""32"":17.5279705086,""33"":19.3049544458,""34"":10.7075003269,""35"":8.0404300124,""36"":16.7940543668,""37"":9.5496845724,""38"":12.1839548678,""39"":17.8109031169,""4"":7.1378460479,""40"":7.9041756327,""41"":9.1785022108,""42"":10.7320658428,""43"":6.2903884356,""44"":12.7179685509,""45"":9.1034597394,""46"":11.5034842963,""47"":11.7178393725,""48"":12.8790832832,""49"":8.7100219737,""5"":10.188552188,""50"":8.3938754718,""51"":12.2173908624,""52"":6.7110904334,""53"":9.4417321822,""54"":9.3050282822,""55"":9.3155875655,""56"":10.3614415194,""57"":6.404197935,""58"":6.0153008501,""59"":7.8074678837,""6"":9.3323515176,""60"":6.2047810027,""61"":6.7822853748,""62"":8.0282551183,""63"":6.6658192345,""64"":6.6536366103,""65"":5.8783386865,""66"":6.072522372,""67"":6.072522372,""7"":12.6006091934,""8"":22.3053785131,""9"":7.445349566},""Unnamed: 0"":{""0"":0,""1"":1,""10"":10,""11"":11,""12"":12,""13"":13,""14"":14,""15"":15,""16"":16,""17"":17,""18"":18,""19"":19,""2"":2,""20"":20,""21"":21,""22"":22,""23"":23,""24"":24,""25"":25,""26"":27,""27"":28,""28"":29,""29"":30,""3"":3,""30"":31,""31"":32,""32"":33,""33"":34,""34"":35,""35"":36,""36"":37,""37"":38,""38"":39,""39"":41,""4"":4,""40"":42,""41"":43,""42"":44,""43"":45,""44"":46,""45"":47,""46"":48,""47"":49,""48"":50,""49"":51,""5"":5,""50"":52,""51"":54,""52"":55,""53"":56,""54"":57,""55"":58,""56"":59,""57"":62,""58"":63,""59"":64,""6"":6,""60"":65,""61"":66,""62"":67,""63"":68,""64"":69,""65"":70,""66"":72,""67"":73,""7"":7,""8"":8,""9"":9},""count"":{""0"":318,""1"":316,""10"":98,""11"":92,""12"":82,""13"":80,""14"":78,""15"":76,""16"":74,""17"":64,""18"":62,""19"":50,""2"":244,""20"":46,""21"":44,""22"":42,""23"":40,""24"":38,""25"":38,""26"":32,""27"":32,""28"":32,""29"":32,""3"":198,""30"":30,""31"":28,""32"":26,""33"":26,""34"":24,""35"":24,""36"":24,""37"":22,""38"":22,""39"":22,""4"":164,""40"":20,""41"":20,""42"":20,""43"":20,""44"":20,""45"":18,""46"":18,""47"":18,""48"":18,""49"":16,""5"":158,""50"":16,""51"":16,""52"":14,""53"":14,""54"":14,""55"":14,""56"":12,""57"":12,""58"":12,""59"":12,""6"":142,""60"":10,""61"":10,""62"":10,""63"":10,""64"":10,""65"":8,""66"":8,""67"":8,""7"":136,""8"":130,""9"":116},""exemplar"":{""0"":null,""1"":null,""10"":null,""11"":null,""12"":""*"",""13"":null,""14"":null,""15"":null,""16"":null,""17"":""*"",""18"":null,""19"":null,""2"":""*"",""20"":""*"",""21"":null,""22"":null,""23"":null,""24"":""*"",""25"":null,""26"":null,""27"":null,""28"":""*"",""29"":null,""3"":null,""30"":null,""31"":null,""32"":null,""33"":""*"",""34"":""*"",""35"":null,""36"":null,""37"":""*"",""38"":null,""39"":null,""4"":null,""40"":""*"",""41"":null,""42"":null,""43"":null,""44"":null,""45"":null,""46"":null,""47"":""*"",""48"":""*"",""49"":""*"",""5"":null,""50"":null,""51"":""*"",""52"":""*"",""53"":""*"",""54"":null,""55"":""*"",""56"":null,""57"":""*"",""58"":null,""59"":""*"",""6"":null,""60"":null,""61"":null,""62"":null,""63"":null,""64"":""*"",""65"":""*"",""66"":null,""67"":null,""7"":null,""8"":null,""9"":null},""pos"":{""0"":1,""1"":2,""10"":5,""11"":6,""12"":2,""13"":1,""14"":7,""15"":8,""16"":1,""17"":5,""18"":9,""19"":10,""2"":1,""20"":6,""21"":11,""22"":12,""23"":13,""24"":3,""25"":2,""26"":14,""27"":15,""28"":2,""29"":16,""3"":1,""30"":17,""31"":18,""32"":19,""33"":3,""34"":2,""35"":20,""36"":7,""37"":3,""38"":21,""39"":22,""4"":2,""40"":8,""41"":4,""42"":23,""43"":24,""44"":25,""45"":4,""46"":5,""47"":4,""48"":5,""49"":3,""5"":3,""50"":26,""51"":6,""52"":5,""53"":9,""54"":27,""55"":6,""56"":28,""57"":4,""58"":29,""59"":7,""6"":4,""60"":30,""61"":31,""62"":32,""63"":10,""64"":8,""65"":5,""66"":9,""67"":10,""7"":1,""8"":3,""9"":4},""sigma_nor"":{""0"":1.4037521495,""1"":1.9775034486,""10"":1.8338485522,""11"":2.4034781442,""12"":2.9040759736,""13"":2.5194461968,""14"":1.7709210894,""15"":1.7204234707,""16"":2.0686471494,""17"":3.8872077445,""18"":2.5350601879,""19"":3.3402597541,""2"":1.4436020464,""20"":1.9129446056,""21"":1.98397258,""22"":1.7849987459,""23"":3.2338323548,""24"":3.0058385728,""25"":1.8957178945,""26"":2.6439166546,""27"":2.1091551479,""28"":2.1166853251,""29"":2.3813003174,""3"":1.409976966,""30"":3.6236351083,""31"":2.5512948436,""32"":3.8895712952,""33"":4.1881479675,""34"":2.7935509676,""35"":2.3318605066,""36"":3.8471804596,""37"":2.641146612,""38"":3.1118453009,""39"":4.1172839485,""4"":1.5299602706,""40"":2.3895191068,""41"":2.6250559347,""42"":2.9122048148,""43"":2.0912389612,""44"":3.2792639599,""45"":2.6658148204,""46"":3.1258017066,""47"":3.1668848379,""48"":3.3894479651,""49"":2.6475962192,""5"":1.7736371396,""50"":2.584590975,""51"":3.3465842888,""52"":2.2951580665,""53"":2.8628268977,""54"":2.8344077383,""55"":2.8366028912,""56"":3.1397667017,""57"":2.2784789103,""58"":2.1938360765,""59"":2.5838983896,""6"":1.743632482,""60"":2.2833221858,""61"":2.4154581578,""62"":2.7005424467,""63"":2.3888101056,""64"":2.3860226585,""65"":2.2534934947,""66"":2.3004067382,""67"":2.3004067382,""7"":2.0280249774,""8"":2.8668141634,""9"":1.6481528476},""topic"":{""0"":-1,""1"":-1,""10"":-1,""11"":-1,""12"":3,""13"":0,""14"":-1,""15"":-1,""16"":4,""17"":2,""18"":-1,""19"":-1,""2"":3,""20"":2,""21"":-1,""22"":-1,""23"":-1,""24"":3,""25"":0,""26"":-1,""27"":-1,""28"":4,""29"":-1,""3"":2,""30"":-1,""31"":-1,""32"":-1,""33"":0,""34"":1,""35"":-1,""36"":2,""37"":1,""38"":-1,""39"":-1,""4"":2,""40"":2,""41"":0,""42"":-1,""43"":-1,""44"":-1,""45"":3,""46"":0,""47"":1,""48"":1,""49"":4,""5"":-1,""50"":-1,""51"":1,""52"":3,""53"":2,""54"":-1,""55"":0,""56"":-1,""57"":4,""58"":-1,""59"":0,""6"":-1,""60"":-1,""61"":-1,""62"":-1,""63"":2,""64"":0,""65"":4,""66"":0,""67"":0,""7"":1,""8"":2,""9"":2},""vector"":{""0"":""[ 7.5411615  -3.7532854   2.602945   -1.6093284  -4.7108994  -1.5601671\n -5.553567   -5.093503    0.36272988 -0.45614466]"",""1"":""[ 7.7867393  -3.8188348   2.3294787  -1.8150367  -4.4715996  -2.2799065\n -5.555617   -4.9524465  -0.10574926  0.1296432 ]"",""10"":""[ 7.183777   -3.3682115   2.3106947  -2.1587799  -4.6360216  -1.5299801\n -4.9984     -5.1752725   1.0446296  -0.09077921]"",""11"":""[ 7.61494    -3.6859992   2.5146768  -1.6702565  -4.6957417  -1.3048908\n -5.058543   -5.553413    1.3599348  -0.26520815]"",""12"":""[ 7.9732156 -4.1229978  2.455867  -1.4423676 -4.721368  -1.80953\n -4.926604  -5.960236   1.1388808 -0.5119958]"",""13"":""[ 8.106494  -3.216814   2.798275  -1.1101536 -4.760285  -3.1965795\n -5.7065697 -5.4873238  1.4064759  2.3790815]"",""14"":""[ 7.9651566  -3.631656    2.4721053  -1.503264   -4.511793   -2.6416717\n -4.70725    -5.925654    0.32261395 -0.47641623]"",""15"":""[ 7.6019626  -4.168458    2.1812146  -1.8662951  -4.482268   -1.5123849\n -5.413188   -5.601601    0.24483867 -0.5880565 ]"",""16"":""[ 7.3273654 -3.9234207  2.3182929 -1.6508985 -4.5151567 -1.5726005\n -5.4970694 -5.7005672  0.7727272 -0.4478716]"",""17"":""[ 8.343717   -4.322496    2.3169217  -1.9622936  -4.738031   -1.591476\n -5.080109   -5.0409384   0.40806183 -0.02221778]"",""18"":""[ 6.9960814 -4.0070467  2.0364347 -2.1556394 -4.5281787 -1.9444629\n -5.1289363 -5.3911867  0.7547448 -0.6666476]"",""19"":""[ 8.137876   -4.179753    2.4302666  -1.820395   -4.907031   -1.5124294\n -5.040696   -5.201068    0.90095454 -0.14382981]"",""2"":""[ 7.947371   -4.0847225   2.3511515  -1.4561212  -4.465958   -2.404918\n -4.705607   -6.253008    0.9775459  -0.47638017]"",""20"":""[ 8.087867   -3.7168555   2.5084357  -1.7498971  -4.3406734  -1.5710512\n -5.301493   -5.0455575  -0.15315364 -0.20268477]"",""21"":""[ 7.414338   -3.9147491   1.9498662  -2.3270464  -4.3736935  -1.3937213\n -4.9650526  -5.5948205   0.5208562  -0.59789765]"",""22"":""[ 7.9815865  -3.8850398   2.278336   -1.8815411  -4.309689   -2.196175\n -5.493823   -5.0057983  -0.26114082  0.22533299]"",""23"":""[ 8.001275   -3.5490522   2.7966633  -1.359671   -4.975469   -2.5558496\n -5.133938   -5.0843244   0.45186785  0.14392225]"",""24"":""[ 7.9564505 -3.8262348  2.5642054 -1.4319654 -4.783021  -1.6401182\n -4.9531164 -5.7829175  1.218051  -0.3606063]"",""25"":""[ 7.8416643 -3.0083578  2.8155997 -1.2285815 -4.6930847 -3.4053202\n -5.5635395 -5.6366577  1.5146261  2.4016643]"",""26"":""[ 7.140978   -3.2105753   2.3390188  -1.9993654  -4.5927763  -1.902069\n -5.262958   -5.248152    0.9324583   0.29577404]"",""27"":""[ 7.7284904  -4.1313844   2.2771938  -1.5098283  -4.337854   -2.4144661\n -4.866277   -6.25651     1.1321508  -0.33170396]"",""28"":""[ 6.908076   -3.8462045   2.156042   -2.0106497  -4.524795   -1.8763968\n -5.4261103  -5.2713985   0.86667156 -0.38197228]"",""29"":""[ 8.075248   -4.351532    2.2594697  -1.5290959  -4.289435   -2.3888881\n -4.838483   -6.098707    0.72460246 -0.34477937]"",""3"":""[ 7.925484   -4.3257384   2.0385954  -2.083598   -4.41503    -1.7156119\n -4.901677   -5.637071    0.19925438 -0.58338094]"",""30"":""[ 7.9092994  -3.80477     2.7598195  -1.5275557  -4.9889207  -1.8231673\n -5.201126   -4.8460155   0.59684384 -0.2856324 ]"",""31"":""[ 7.5209603  -3.520174    2.7312982  -1.6545295  -4.968204   -1.7050205\n -5.190465   -4.8596053   0.74379766 -0.38715798]"",""32"":""[ 7.461852   -3.538523    2.5860171  -1.4789766  -4.618794   -1.8085957\n -5.53122    -5.4638596   1.0770291   0.27182797]"",""33"":""[ 7.821989  -3.0168898  2.8093393 -1.316491  -4.7113066 -3.3634489\n -5.4607563 -5.5481277  1.4505132  2.2897537]"",""34"":""[ 7.888723   -3.6744123   2.3335135  -1.9215854  -4.7091227  -2.8684843\n -4.7203565  -5.2806387   0.11796205  0.04383267]"",""35"":""[ 7.160402   -3.0073197   2.0965226  -2.35478    -4.2575254  -1.4917086\n -4.6516604  -5.5959077   0.8878282  -0.28715134]"",""36"":""[ 8.487119   -3.9412487   2.2483497  -2.0847313  -5.2402415  -1.9847424\n -5.114774   -5.080295    0.20588832  0.17398563]"",""37"":""[ 8.014944   -3.416822    2.6191797  -1.5222348  -4.7903686  -2.7463722\n -4.6411934  -5.4700737   0.44205377 -0.10125675]"",""38"":""[ 8.254059   -3.5848315   2.1295433  -2.3024623  -5.2454457  -2.0273607\n -5.1329527  -5.252427   -0.16798551 -0.05386196]"",""39"":""[ 7.79229    -3.2459588   2.568794   -1.5871711  -4.6488724  -2.333544\n -4.6244516  -5.652243    0.91575146 -0.04864063]"",""4"":""[ 7.831974  -3.7451422  2.4264612 -1.819095  -4.4866695 -1.6799643\n -5.350285  -5.202932  -0.2855573 -0.5211232]"",""40"":""[ 8.283906   -4.0880985   2.354768   -1.8530347  -4.434293   -1.704096\n -5.1637473  -4.976481   -0.09483859 -0.23850533]"",""41"":""[ 7.7117696 -3.0826774  2.8263798 -1.4822112 -4.5389867 -3.173026\n -5.592342  -5.334477   1.1324201  2.0270288]"",""42"":""[ 7.320715   -2.990274    2.2122736  -2.212381   -4.313244   -1.4307494\n -4.5694804  -5.6379914   1.0698912  -0.22666076]"",""43"":""[ 7.2541604  -3.343057    2.14265    -2.2490325  -4.279917   -1.5839882\n -5.0855694  -5.3343697   0.2368051  -0.36511454]"",""44"":""[ 7.7740617  -3.9536579   2.1973286  -2.0163665  -4.581755   -1.7140547\n -5.243845   -5.486906   -0.22524998 -0.666293  ]"",""45"":""[ 7.551807   -3.6771412   2.560379   -1.4216436  -4.5839763  -1.6070639\n -5.238364   -5.80746     1.2936417  -0.20754562]"",""46"":""[ 7.796916  -3.1259089  2.8323298 -1.4935325 -4.7363014 -3.0058374\n -5.4439516 -5.249773   1.280712   1.9054077]"",""47"":""[ 7.839035   -3.712939    2.2838676  -1.8444083  -4.555553   -2.6349711\n -4.897083   -5.572381   -0.10103451 -0.3513332 ]"",""48"":""[ 8.124606   -3.6666868   2.5697825  -1.7006756  -4.9111085  -2.40045\n -4.8461967  -5.076698    0.0403579  -0.27568522]"",""49"":""[ 7.3002143  -3.967142    2.0326345  -2.1869278  -4.5269427  -1.4879649\n -4.976703   -5.609888    0.88867414 -0.6802438 ]"",""5"":""[ 7.6572423  -3.663806    2.326845   -1.5717489  -4.583826   -2.699722\n -4.8013406  -6.148369    0.6404109  -0.48090807]"",""50"":""[ 7.8309207 -4.262233   2.1688313 -1.8671377 -4.5593805 -1.6622056\n -4.8059096 -5.884922   0.9467424 -0.6023459]"",""51"":""[ 8.152372   -3.635951    2.5454154  -1.6164439  -4.9254327  -2.732536\n -4.9184847  -5.259137    0.13315512  0.04694295]"",""52"":""[ 7.8727736  -3.9824555   2.4662814  -1.3232985  -4.487421   -2.1351762\n -4.8963904  -6.241933    1.2041196  -0.38062584]"",""53"":""[ 8.508613   -4.0716577   2.1638017  -2.1573944  -5.0452437  -1.8266578\n -5.1671596  -5.071008    0.06430235  0.1309412 ]"",""54"":""[ 7.8176    -3.4644532  2.4899282 -1.8127968 -4.8456044 -2.1371253\n -5.433597  -5.0764112  0.6957421  0.83722  ]"",""55"":""[ 7.94463   -3.0945807  2.8836608 -1.3160244 -4.765573  -3.2562609\n -5.4944086 -5.332582   1.4157861  2.2480094]"",""56"":""[ 7.756843   -3.8245902   2.1723163  -2.2368     -4.5962844  -2.2022195\n -4.6409507  -5.1421633   0.5621939   0.06603692]"",""57"":""[ 7.078229   -3.978728    2.0758295  -2.058611   -4.49047    -1.6994884\n -5.168143   -5.5762715   0.88712317 -0.68298805]"",""58"":""[ 8.3231277e+00 -3.6244588e+00  2.1810656e+00 -2.2170360e+00\n -5.0239234e+00 -1.9074466e+00 -5.1763864e+00 -5.1991305e+00\n -2.4711721e-01  6.6085043e-03]"",""59"":""[ 7.9400644 -3.1490595  2.6899302 -1.1714644 -4.7965074 -3.0629735\n -5.636818  -5.5964265  1.3698062  2.2106621]"",""6"":""[ 8.244761   -4.2683454   2.198347   -1.8300186  -4.3897705  -2.2079506\n -4.7282004  -5.6251135   0.06675281 -0.42785883]"",""60"":""[ 7.764029   -3.7092621   2.764713   -1.4082158  -4.9494667  -1.9311075\n -5.3088455  -5.091956    0.6594059  -0.29986808]"",""61"":""[ 7.393808   -2.9842916   2.1406105  -2.2847347  -4.204175   -1.5654261\n -4.481953   -5.6299515   0.87011784 -0.25603396]"",""62"":""[ 7.5318213  -3.4754825   2.5390363  -1.6757822  -4.7249656  -1.9617846\n -5.552267   -5.160196    0.7852501   0.48328412]"",""63"":""[ 8.307443   -4.4210753   2.2045028  -1.9464927  -4.512982   -1.8817016\n -5.0815754  -5.14067     0.05897965 -0.17815056]"",""64"":""[ 7.8295364 -3.0963304  2.7969306 -1.3277284 -4.520032  -3.339998\n -5.6105895 -5.462001   1.2063053  2.206951 ]"",""65"":""[ 7.086484   -3.4385476   2.147452   -2.2332437  -4.4825735  -1.4824171\n -5.0970373  -5.381435    0.75298077 -0.34677947]"",""66"":""[ 7.882803  -3.1588476  2.6649816 -1.2965807 -4.778779  -2.9904597\n -5.5838046 -5.518972   1.2527093  2.0267773]"",""67"":""[ 7.8049474 -3.2258923  2.6346202 -1.4991802 -4.7830515 -2.762233\n -5.459979  -5.3538575  1.0801744  1.5961522]"",""7"":""[ 8.112803   -4.055498    2.259881   -1.819149   -4.4972367  -2.7955983\n -4.7721877  -5.525115    0.16508244  0.06327679]"",""8"":""[ 8.199121   -3.6668694   2.3285692  -1.9049588  -4.12238    -1.6709459\n -4.830009   -5.361508   -0.16002204 -0.30573383]"",""9"":""[ 8.070548   -3.5694826   2.2916362  -2.0234222  -4.1721234  -1.7250735\n -4.7994647  -5.169214   -0.11370145 -0.2232204 ]""},""vocab_index"":{""0"":0,""1"":1,""10"":15,""11"":16,""12"":18,""13"":19,""14"":20,""15"":21,""16"":22,""17"":23,""18"":24,""19"":30,""2"":2,""20"":32,""21"":35,""22"":37,""23"":40,""24"":42,""25"":43,""26"":46,""27"":49,""28"":50,""29"":51,""3"":4,""30"":58,""31"":63,""32"":68,""33"":69,""34"":72,""35"":81,""36"":82,""37"":84,""38"":90,""39"":92,""4"":6,""40"":100,""41"":101,""42"":104,""43"":107,""44"":108,""45"":119,""46"":123,""47"":124,""48"":125,""49"":139,""5"":7,""50"":144,""51"":146,""52"":165,""53"":166,""54"":167,""55"":168,""56"":174,""57"":179,""58"":198,""59"":199,""6"":8,""60"":223,""61"":232,""62"":235,""63"":238,""64"":239,""65"":283,""66"":306,""67"":307,""7"":9,""8"":11,""9"":13},""word"":{""0"":""model"",""1"":""pipeline"",""10"":""forward"",""11"":""attribute"",""12"":""relevance"",""13"":""wmds"",""14"":""dimensional"",""15"":""observations"",""16"":""observation"",""17"":""documents"",""18"":""controller"",""19"":""document"",""2"":""semantic"",""20"":""components"",""21"":""coordinates"",""22"":""pipelines"",""23"":""cosmos"",""24"":""importance"",""25"":""sirius"",""26"":""north"",""27"":""bidirectionality"",""28"":""loop"",""29"":""sensemaking"",""3"":""data"",""30"":""entity"",""31"":""force"",""32"":""cluster"",""33"":""ieee"",""34"":""computer"",""35"":""directed"",""36"":""conference"",""37"":""human"",""38"":""panel"",""39"":""vast"",""4"":""models"",""40"":""processes"",""41"":""v2pi"",""42"":""represented"",""43"":""arrows"",""44"":""projections"",""45"":""characteristic"",""46"":""endert"",""47"":""graphics"",""48"":""technology"",""49"":""input"",""5"":""visual"",""50"":""query"",""51"":""science"",""52"":""dissimilarity"",""53"":""proceedings"",""54"":""house"",""55"":""leman"",""56"":""mail"",""57"":""feedback"",""58"":""panels"",""59"":""york"",""6"":""analytics"",""60"":""concept"",""61"":""needed"",""62"":""neighborhood"",""63"":""transactions"",""64"":""tvcg"",""65"":""direction"",""66"":""berlin"",""67"":""heidelberg"",""7"":""computation"",""8"":""weights"",""9"":""tools""},""word*"":{""0"":""model"",""1"":""pipeline"",""10"":""forward"",""11"":""attribute"",""12"":""relevance*"",""13"":""wmds"",""14"":""dimensional"",""15"":""observations"",""16"":""observation"",""17"":""documents*"",""18"":""controller"",""19"":""document"",""2"":""semantic*"",""20"":""components*"",""21"":""coordinates"",""22"":""pipelines"",""23"":""cosmos"",""24"":""importance*"",""25"":""sirius"",""26"":""north"",""27"":""bidirectionality"",""28"":""loop*"",""29"":""sensemaking"",""3"":""data"",""30"":""entity"",""31"":""force"",""32"":""cluster"",""33"":""ieee*"",""34"":""computer*"",""35"":""directed"",""36"":""conference"",""37"":""human*"",""38"":""panel"",""39"":""vast"",""4"":""models"",""40"":""processes*"",""41"":""v2pi"",""42"":""represented"",""43"":""arrows"",""44"":""projections"",""45"":""characteristic"",""46"":""endert"",""47"":""graphics*"",""48"":""technology*"",""49"":""input*"",""5"":""visual"",""50"":""query"",""51"":""science*"",""52"":""dissimilarity*"",""53"":""proceedings*"",""54"":""house"",""55"":""leman*"",""56"":""mail"",""57"":""feedback*"",""58"":""panels"",""59"":""york*"",""6"":""analytics"",""60"":""concept"",""61"":""needed"",""62"":""neighborhood"",""63"":""transactions"",""64"":""tvcg*"",""65"":""direction*"",""66"":""berlin"",""67"":""heidelberg"",""7"":""computation"",""8"":""weights"",""9"":""tools""},""x2D"":{""0"":-2.8723239899,""1"":-3.954236269,""10"":-2.0760953426,""11"":-2.9606580734,""12"":-3.8430860043,""13"":-31.7241287231,""14"":-4.9315991402,""15"":-2.0796034336,""16"":-2.0135402679,""17"":-3.8479425907,""18"":-1.4602999687,""19"":-3.4995398521,""2"":-4.5840454102,""20"":-3.2396154404,""21"":-1.3437361717,""22"":-3.6770620346,""23"":-4.2993216515,""24"":-3.5140089989,""25"":-31.5916996002,""26"":-2.4665706158,""27"":-4.3681025505,""28"":-1.824647069,""29"":-4.5204691887,""3"":-2.3240790367,""30"":-3.4508898258,""31"":-3.0455675125,""32"":-2.9181883335,""33"":-31.7316455841,""34"":-4.9721860886,""35"":-1.4931782484,""36"":-4.3777198792,""37"":-4.7886648178,""38"":-4.2575736046,""39"":-4.4444570541,""4"":-2.9541189671,""40"":-3.5113039017,""41"":-32.1156959534,""42"":-1.5918489695,""43"":-1.3847358227,""44"":-2.6902554035,""45"":-3.2517011166,""46"":-32.0019798279,""47"":-5.1672039032,""48"":-4.4326734543,""49"":-1.1316173077,""5"":-4.7429881096,""50"":-3.6251506805,""51"":-4.6692047119,""52"":-4.1256766319,""53"":-4.2155075073,""54"":-3.3005216122,""55"":-31.8886318207,""56"":-4.7161693573,""57"":-1.3547650576,""58"":-4.1308846474,""59"":-31.7724971771,""6"":-4.9174556732,""60"":-3.3789906502,""61"":-1.750921607,""62"":-3.0604231358,""63"":-3.7870051861,""64"":-32.084903717,""65"":-1.599301815,""66"":-31.9734153748,""67"":-32.0798187256,""7"":-5.045147419,""8"":-3.103587389,""9"":-3.3020009995},""y2D"":{""0"":3.4724030495,""1"":2.5457613468,""10"":4.705104351,""11"":5.1640090942,""12"":5.5953912735,""13"":19.9200801849,""14"":4.4282913208,""15"":2.9859888554,""16"":3.8876810074,""17"":1.4721794128,""18"":3.9853622913,""19"":3.2044520378,""2"":5.4540390968,""20"":1.8236577511,""21"":3.8741350174,""22"":2.1983969212,""23"":3.7870221138,""24"":5.3347835541,""25"":19.5561256409,""26"":4.5801243782,""27"":5.6991343498,""28"":4.1461482048,""29"":5.4612812996,""3"":2.5623753071,""30"":3.6029155254,""31"":3.7155311108,""32"":4.6373896599,""33"":19.8673191071,""34"":3.4445152283,""35"":4.9992909431,""36"":1.8503656387,""37"":4.0285768509,""38"":2.096555233,""39"":4.494550705,""4"":2.1233227253,""40"":1.6444351673,""41"":19.4371833801,""42"":4.89960289,""43"":4.641784668,""44"":2.2819244862,""45"":5.1824851036,""46"":19.4024753571,""47"":3.3869907856,""48"":3.2343974113,""49"":4.1880960464,""5"":4.9504070282,""50"":5.6601729393,""51"":3.5262663364,""52"":5.5228362083,""53"":1.6963230371,""54"":4.2300081253,""55"":20.0540866852,""56"":3.130407095,""57"":4.1583175659,""58"":1.8018833399,""59"":19.7084693909,""6"":2.7047514915,""60"":3.8534648418,""61"":5.1141691208,""62"":4.3367314339,""63"":1.749516964,""64"":19.813627243,""65"":4.5041532516,""66"":19.2966766357,""67"":19.248249054,""7"":3.5200805664,""8"":1.7445803881,""9"":2.1411480904}}",False,False,False,,,A Bidirectional Pipeline for Semantic Interaction,"[-1.85309529e-01 -6.84398487e-02 -1.96554307e-02 -3.72262716e-01
  3.46639991e-01 -9.05914083e-02 -1.41618758e-01 -1.15210488e-01
 -2.84200996e-01  1.11307114e-01 -7.85548910e-02 -1.98188111e-01
 -1.43089965e-01  1.14259884e-01 -2.23410241e-02  7.94463813e-01
 -3.37092698e-01 -7.02396557e-02 -1.50627226e-01 -4.61121239e-02
  2.60278791e-01  1.43946588e-01 -3.48733783e-01  4.76587653e-01
  4.53490376e-01  2.84012884e-01 -8.79465193e-02  2.70011514e-01
 -7.20774531e-01  1.78613096e-01  2.64284164e-01  6.31530285e-01
  2.06701130e-01 -4.28056061e-01  9.76928025e-02  3.38475406e-02
 -1.40626982e-01 -1.52353004e-01  3.33966851e-01  3.79495591e-01
 -3.39787066e-01 -4.08052877e-02  1.81941986e-01 -9.47161764e-02
  2.20746696e-01  3.29767019e-02  3.66039835e-02 -2.34944567e-01
 -6.08182438e-02 -6.22856200e-01 -1.39192736e+00 -2.92422444e-01
  1.09347127e-01 -4.55131978e-01  1.41616806e-01  4.72172022e-01
 -8.38283002e-02 -1.00315785e+00  4.30242240e-01  1.52721584e-01
 -6.52128235e-02 -2.07213257e-02  7.73864985e-02  1.25462383e-01
  2.35834211e-01 -2.10431457e-01  3.18679698e-02  1.79175332e-01
 -8.70026469e-01  2.96071559e-01  1.11763895e-01 -8.74966457e-02
 -2.60199636e-01  4.61042494e-01 -4.68112350e-01  1.27555639e-01
 -1.27293974e-01  2.68232405e-01  1.70056149e-01 -6.32605851e-02
 -4.53297257e-01  4.17992294e-01  2.50529736e-01  1.15386277e-01
  7.64378369e-01  5.80473125e-01  5.39681092e-02  6.32379293e-01
 -6.29166543e-01  3.17090511e-01 -4.63474631e-01 -1.97892591e-01
 -3.34096074e-01  2.77964741e-01  7.95812130e-01 -2.01767698e-01
 -4.56045508e-01  1.16419509e-01  2.70125926e-01 -3.48329663e-01
  9.78948101e-02 -5.50124764e-01 -3.39538679e-02 -3.18436682e-01
 -3.60952467e-01 -2.05550492e-01 -3.26724857e-01 -4.16167915e-01
 -8.02047923e-02 -1.71597712e-02  1.48216248e-01  2.54606813e-01
  9.92078483e-02 -6.99502349e-01  3.01321130e-02 -2.45517120e-02
 -3.28429222e-01  2.78860480e-01  1.76900670e-01 -5.70590794e-02
 -3.87787470e-03  3.62351686e-01 -6.67757494e-03  4.98979717e-01
  2.48342052e-01  2.32813098e-02 -1.24758855e-01  2.81816155e-01
  3.98029745e-01  5.70193306e-02  5.06420374e-01  5.56186795e-01
  2.28131950e-01  4.46297266e-02 -5.01632869e-01  5.55322707e-01
 -2.25496843e-01  1.26547590e-01 -2.98960716e-01 -9.29521620e-02
 -5.14640033e-01 -2.78880239e-01  2.13516563e-01  1.25446528e-01
  3.14719170e-01 -3.71830687e-02 -3.86164784e-01  3.23305368e-01
  1.14686284e-02  4.99732614e-01 -4.14781451e-01  4.98320550e-01
 -5.39679170e-01 -1.46376684e-01 -1.49731979e-01  2.43890554e-01
 -1.19678125e-01  5.34363985e-01  1.05483830e-01  9.32827443e-02
  3.87099952e-01  1.33966401e-01 -5.86797893e-02  1.00694112e-01
  1.35141715e-01 -2.50353515e-01 -2.47165829e-01  3.63238901e-01
 -1.39697924e-01 -3.93082529e-01  1.19812891e-01 -4.67428714e-01
  1.94138233e-02  1.34553999e-01  2.53472686e-01  2.60864288e-01
  1.92122310e-01 -1.62581012e-01  3.01690131e-01  8.64506304e-01
 -4.45134431e-01 -1.52955145e-01 -3.33103955e-01 -3.76959205e-01
  4.97418106e-01  2.99575388e-01 -1.21465646e-01 -2.84218490e-01
  5.80752134e-01  2.59025097e-01 -5.05661070e-01 -4.09002006e-01
 -2.38359094e-01 -3.67740393e-01  6.35628253e-02 -2.67737836e-01
 -1.07302114e-01 -2.19978735e-01  1.80151179e-01  3.51835452e-02
 -4.21205759e-01 -2.19512373e-01 -3.25685620e-01  1.23109452e-01
  1.72130719e-01  3.18784952e-01 -1.25772625e-01 -5.17762005e-01
 -8.65332782e-01  1.04749553e-01 -1.19108178e-01  3.59726936e-01
 -1.37583211e-01  2.89037466e-01  1.93636641e-01  3.15056890e-02
  1.97046563e-01 -4.54553604e-01  3.38859677e-01  8.69858861e-02
  3.72646153e-01 -2.34414175e-01  3.99958603e-02  3.02205831e-01
 -1.40395537e-02  1.78246427e+00  3.59105200e-01 -1.89429611e-01
  7.06232905e-01  9.34342444e-02  5.65557778e-02 -1.60631225e-01
  6.19493246e-01 -6.01187885e-01  2.46966690e-01  1.88377336e-01
 -2.67471075e-01 -2.98603714e-01  2.38254800e-01  1.68084607e-01
  1.79453008e-02  5.09636700e-01  1.14169434e-01 -1.32524781e-02
 -1.89079687e-01 -6.02986058e-03  1.22477032e-01  7.56078362e-02
 -6.81114644e-02 -6.02563396e-02 -2.10297152e-01  5.68667054e-01
 -7.08511710e-01 -2.33477667e-01 -7.79928938e-02 -1.59563065e-01
 -1.89195089e-02 -4.52104658e-01 -5.50003015e-02  2.68782526e-01
  5.51185668e-01  8.59567150e-02  1.07771985e-01 -9.24574956e-02
  5.09691350e-02 -3.07791680e-01  5.59102148e-02 -3.85148168e-01
  7.81692028e-01  6.97598577e-01 -3.38506609e-01 -3.99537176e-01
 -1.86364725e-01  5.81400633e-01 -4.46099639e-01 -4.89118159e-01
  2.94310991e-02 -3.53071362e-01 -3.64025503e-01 -4.45387989e-01
  5.25478125e-02  4.45664935e-02 -2.73838937e-01  6.86252341e-02
 -9.00881708e-01 -2.42025048e-01  1.80627912e-01 -5.75936213e-02
 -1.77079022e-01 -4.57120776e-01 -1.91393793e-01  1.12884551e-01
 -5.77514052e-01 -2.40090802e-01  5.45435071e-01  5.58133125e-01
 -8.05198476e-02 -4.46074009e-02 -5.93579531e-01 -5.08613825e-01
 -4.13127303e-01  1.17214182e-02 -1.39250158e-04  6.89165369e-02
  2.36701429e-01  2.02716947e-01 -4.30236131e-01 -3.75802904e-01
 -8.13688087e+00 -1.51930511e-01 -5.10482311e-01  6.23493567e-02
  2.50312895e-01  2.15956390e-01  1.02586359e-01  1.07237073e-02
  2.99071185e-02 -4.03304631e-03 -4.57226336e-02 -1.67632177e-01
 -4.80106801e-01  1.79320678e-01 -3.27261463e-02 -2.85079747e-01
  3.98363471e-01 -1.35848582e-01 -1.93633214e-01  2.86744922e-01
 -3.59046221e-01 -5.49245894e-01 -1.88909397e-01  4.16992512e-03
 -2.29014503e-03 -1.71945930e-01 -4.50974911e-01  1.92872137e-01
 -3.39138478e-01 -6.82418227e-01 -4.35810626e-01 -5.88311315e-01
 -8.16862211e-02  8.65332782e-01 -5.02638280e-01 -2.24918708e-01
 -2.18754545e-01 -2.16074273e-01  4.03939277e-01  5.92689700e-02
 -3.39469090e-02 -3.41532469e-01 -5.27627468e-02 -4.27696496e-01
  8.40021312e-01 -2.00184807e-01  8.74959454e-02  1.05591133e-01
 -6.21036291e-01 -1.27558723e-01 -3.08570206e-01 -4.42127623e-02
  3.26260269e-01 -2.93991327e-01  4.73142974e-02 -2.69316345e-01
  7.78865755e-01  5.75822771e-01 -1.98579580e-01 -2.39476219e-01
  5.39384365e-01 -1.99952185e-01 -1.93855241e-01  2.21660752e-02
 -3.13867182e-01  3.30160022e-01 -9.02240157e-01 -7.04508901e-01
 -3.36041674e-02 -2.97293901e-01 -5.42056918e-01  7.54003048e-01
 -1.90039780e-02 -1.28270054e+00 -3.49665403e-01 -5.68026125e-01
  2.22852096e-01 -2.14049861e-01 -2.23112315e-01 -4.15751904e-01
 -4.17326570e-01 -6.73846722e-01 -1.16123579e-01  7.70120770e-02
 -3.47970009e-01  1.66005045e-02 -2.30883509e-01 -4.61840212e-01
 -4.12094682e-01  1.50921047e-01 -1.63360983e-01  4.73933637e-01
  2.72840053e-01  4.66339678e-01 -3.84551287e-02  1.24266092e-02
  4.29229230e-01 -1.57564580e-02  1.60132155e-01 -1.26970693e-01
 -3.79111804e-02 -4.48263586e-01 -6.36506900e-02 -1.06919356e-01
 -9.14994180e-02  5.60943663e-01 -8.18338573e-01 -3.16807777e-01
  3.64108354e-01  3.54723006e-01 -8.57255757e-02  2.29318902e-01
 -2.28623480e-01  8.98372568e-03 -3.42913359e-01  2.46226907e-01
  1.42578453e-01  3.20158124e-01  6.53538331e-02 -4.45305824e-01
 -7.06030726e-01  3.34102660e-01  2.15533320e-02 -9.90253389e-02
  7.17954040e-01  2.35370442e-01 -1.12419939e-02  1.65957883e-01
 -2.67362773e-01 -2.77943969e-01 -1.82157233e-01 -4.05623853e-01
  6.31763861e-02 -2.74899825e-02  2.84424096e-01 -2.37301782e-01
 -1.72196522e-01 -2.95368046e-01 -7.16865718e-01  2.73024857e-01
  4.49534118e-01  3.68264802e-02  2.87028611e-01 -1.60599142e-01
 -7.76514262e-02 -2.56896168e-02  1.07782476e-01  1.61359102e-01
  7.45147513e-03  3.53386700e-01 -3.46751928e-01 -5.63982368e-01
  2.62299091e-01 -2.22936437e-01  3.16312402e-01  5.25799952e-02
  2.52781302e-01 -4.60798502e-01 -8.12805742e-02 -4.58096385e-01
  2.64384866e-01 -3.68169066e-03  2.06755310e-01 -2.14055359e-01
  1.35332927e-01  1.76084772e-01 -2.46407732e-01  3.03176522e-01
  2.70676404e-01 -5.02988219e-01 -3.89534920e-01  1.15146391e-01
  3.37090373e-01  1.16675273e-01 -8.81066024e-02  1.07337441e-02
  4.14625883e-01  1.24579966e-01 -1.68430343e-01  5.12402594e-01
  3.52370501e-01  3.45004648e-01  1.03698581e-01  4.40256655e-01
  4.94267583e-01  1.19192362e-01  1.95106208e-01  2.36723080e-01
  2.89544821e-01  8.06752145e-02 -3.62910122e-01  1.95140958e-01
  3.04387122e-01 -2.58133024e-01 -1.48404777e-01 -6.66015804e-01
  4.45521086e-01 -5.73933840e-01 -5.34438081e-02 -8.53198320e-02
 -6.26727790e-02 -3.30723912e-01 -2.84270376e-01  3.99967700e-01
 -2.74053663e-01 -1.98115170e-01  1.21149304e-03  1.70705151e-02
 -2.99944729e-01 -1.70915704e-02 -4.66525912e-01 -1.59557939e-01
 -4.34427261e-02 -6.70295358e-01  1.90485403e-01  4.01022770e-02
 -1.87175661e-01 -1.24615356e-01 -9.11902189e-01  1.01886041e-01
 -3.40256572e-01 -1.31367221e-01  5.19723296e-01  8.66373926e-02
 -3.22017908e-01  1.24943703e-01 -1.68150365e-01  9.30127129e-03
 -6.04880333e-01 -2.15403028e-02 -6.80254400e-02 -2.10276318e+00
  1.00419350e-01 -7.18236193e-02 -1.60425872e-01 -3.92187268e-01
 -5.24867654e-01 -1.36201736e-02 -1.50737882e-01 -3.34560990e-01
  3.34179223e-01 -1.30912766e-01 -1.59291208e-01 -6.78468108e-01
 -2.21436977e-01 -5.64480245e-01 -2.30586812e-01  3.54391225e-02
 -3.49171668e-01  1.19723991e-01 -5.32039553e-02 -2.33464167e-01
  3.12994309e-02 -7.37860560e-01  5.27343810e-01 -1.16404593e-01
 -7.03667030e-02 -7.25747764e-01 -2.38709733e-01  1.43162645e-02
 -2.64916569e-01 -2.76826501e-01 -2.70878196e-01  1.55194461e-01
 -5.15241861e-01  1.88753847e-02  1.80648386e-01  2.44958997e-02
 -2.19807014e-01 -4.06338662e-01 -1.07291393e-01 -4.39153910e-01
 -3.83356661e-02  5.76601803e-01 -4.06602889e-01 -2.86452055e-01
 -6.31482378e-02 -5.61043471e-02  3.47476691e-01 -4.92148399e-01
  1.55282348e-01 -2.64786869e-01  2.23939374e-01  5.20633996e-01
  1.67246670e-01 -1.90123264e-02 -1.00487709e-01 -9.69576240e-02
  7.35143870e-02 -1.28488213e-01  1.73498452e-01  1.97838515e-01
 -2.01165006e-01  1.01637743e-01 -2.58440375e-01  2.81076640e-01
  9.71765995e-01  3.10868233e-01 -3.63076061e-01  1.96802393e-01
  3.04996558e-02  3.91488224e-01  2.23348945e-01  3.72350544e-01
  2.90920854e-01 -1.97593309e-03 -3.51033121e-01 -3.80900890e-01
  1.78088933e-01 -4.34849620e-01  1.25478356e-04 -6.92533329e-02
  6.37906671e-01  2.69290775e-01  2.03064159e-01 -3.41465592e-01
 -3.83124501e-01 -1.08630486e-01  2.18989313e-01 -1.80317000e-01
 -5.05095720e-01  9.57565084e-02  7.54661322e-01 -1.18424390e-02
 -2.84419805e-01  4.45516884e-01 -8.98426846e-02 -2.94775724e-01
 -5.60480833e-01  4.81091887e-01  6.40161037e-02  1.13065198e-01
  1.12679355e-01 -1.11578226e-01  4.96219456e-01  3.36958393e-02
  1.70364559e-01 -5.19690402e-02  3.52731824e-01  3.53644967e-01
  1.39631420e-01  4.58762437e-01 -2.79217750e-01  5.56722403e-01
  6.49963319e-02 -1.50686890e-01  4.72177900e-02  5.25849164e-01
  9.85222608e-02  1.90003991e-01  3.81608397e-01  1.26354173e-01
  3.85951281e-01 -6.34083822e-02  1.98945090e-01 -2.27678210e-01
  1.45681083e-01 -1.89018980e-01  2.97782540e-01  8.64652812e-01
  3.74733895e-01  4.62078713e-02  3.15111466e-02 -7.38802969e-01
 -2.47246966e-01 -6.64537027e-02  4.47224230e-01  1.03779338e-01
  5.32440662e-01 -1.63929537e-01  3.32719147e-01  4.14162725e-01
 -1.21901251e-01  6.18085898e-02  2.50717252e-01  3.04401666e-01
  6.29359409e-02 -8.11276808e-02 -6.28997758e-02  1.85555797e-02
 -3.07436913e-01  2.49794908e-02 -3.49431068e-01  1.00013368e-01
 -3.87484580e-01 -4.85946655e-01 -4.59513962e-02  1.53045312e-01
  9.37381461e-02  1.26116313e-02 -2.40587845e-01  2.68661708e-01
  4.39870477e-01 -1.54568866e-01 -1.66592509e-01  5.55428714e-02
 -1.74337756e-02  1.67413101e-01  5.58753014e-01  3.15512642e-02
  2.53466219e-01 -2.06697751e-02 -2.40712419e-01 -1.77125745e-02
 -1.85415655e-01  1.23665921e-01  3.26462835e-02  6.46153390e-01
 -5.96283913e-01 -2.82245010e-01  2.25288987e-01  4.18140054e-01
  3.92627483e-03  4.23332572e-01  1.78837493e-01  2.68020391e-01
  9.70235318e-02 -6.69858754e-02 -1.29745856e-01  1.17157020e-01
 -3.17761987e-01 -3.87067258e-01  2.60502636e-01 -3.97348523e-01
 -8.88828635e-02  1.79305270e-01  5.57873137e-02 -2.20331252e-01
 -3.03386077e-02 -1.74665332e-01  3.12055945e-01  5.02697170e-01
 -1.90920219e-01  1.68365270e-01 -3.77828360e-01 -1.22723961e-02
 -1.41115978e-01  3.02866191e-01  7.87389055e-02  9.29675698e-02
 -3.55704397e-01  5.10434687e-01 -2.57978112e-01 -4.88380156e-02
 -1.42311409e-01  1.18838355e-01  1.38011903e-01 -1.04460694e-01
 -3.36668789e-01 -3.60115707e-01 -4.33797836e-01 -7.78645575e-02
 -3.76107782e-01 -2.15840608e-01  1.75723210e-01  8.68926048e-02
 -2.48954207e-01 -1.27390429e-01  2.09323820e-02  1.62517369e-01]",7HWEXAYH,False,False,"[8.42437744140625, -0.8445422053337097]"
SP8F58ZB,MANNT9GF,"Unifying the Sensemaking Loop with Semantic Interaction 

  

Alex Endert 

Patrick Fiaux 

Chris North 

Abstract—  Visual  analytics  emphasizes  sensemaking  of  large,  complex  datasets  through  interactively  exploring  visualizations 
generated by statistical models. For example, dimensionality reduction methods use various similarity metrics to visualize textual 
document  collections  in  a  spatial  metaphor,  where  similarities  between  documents  are  approximately  represented  through  their 
relative spatial distances to each other in a 2D layout. This metaphor is designed to mimic analystsʼ mental models of the document 
collection and support their analytic processes, such as clustering similar documents together. However, in current methods, users 
must  interact  with  such  visualizations  using  controls  external  to  the  visual  metaphor,  such  as  sliders,  menus,  or  text  fields,  to 
directly control underlying model parameters that they do not understand and that do not relate to their analytic process occurring 
within the visual metaphor. In this paper, we present the opportunity for a new design space for visual analytic interaction, called 
semantic interaction, which seeks to enable analysts to spatially interact with such models directly within the visual metaphor using 
interactions  that  derive  from  their  analytic  process,  such  as  searching,  highlighting,  annotating,  and  repositioning  documents. 
Further, we demonstrate how semantic interactions can be implemented using machine learning techniques in a visual analytic tool, 
called ForceSPIRE, for interactive analysis of textual data within a spatial visualization.  Analysts can express their expert domain 
knowledge about the documents by simply moving them, which guides the underlying model to improve the overall layout, taking 
the userʼs feedback into account. 
Index Terms— interaction, spatialization, sensemaking, analytics, textual datasets.

 
1 

 

INTRODUCTION 
Visual analytics bases its success on combining the abilities of 
statistical  models,  visualization,  and  human  intuition  for  users  to 
gain  insight  into  large,  complex  datasets  [1].  This  success  often 
hinges  on  the  ability  for  users  to  interact  with  the  information, 
manipulating  the  visualization  based  on  their  domain  expertise, 
interactively  exploring  possible  connections,  and 
investigating 
hypotheses. It is through this interactive exploration that users are 
able  to  make  sense  of  complex  datasets,  a  process  referred  to  as 
sensemaking  [2].  The  sensemaking  loop  models  the  series  of 
cognitive  stages  users  traverse  when  analyzing  and  progressively 
making sense of a dataset. The two primary parts of this model are 
foraging and synthesis. Foraging refers to the stages of the process 
where users are filtering and gathering collections of interesting or 
relevant  information.  Then,  using  that  information,  users  advance 
through the synthesis stages of the process, where they construct and 
test hypotheses about how the foraged information may relate to a 
larger  plot.  Tools  exist  that  support  users  for  either  foraging  or 
synthesis – but not both.  
In  this  paper,  we  present  semantic  interaction,  combing  the 
foraging abilities of statistical models with the spatial sensemaking 
abilities of analysts. Semantic interaction is based on the following 
principles: 
1.  Visual “near=similar” metaphor supports analysts’ spatial 
cognition,  and  is  generated  by  statistical  models  and 
similarity metrics. [3] 
2.  Use  semantic  interactions  within  the  visual  metaphor, 
based on common interactions occurring in spatial analytic 
processes [4] such as searching, highlighting, annotating, 
and repositioning documents.  
Interpret  and  map  the  semantic  interactions  to  the 
underlying parameters of the model, by updating weights 

3. 

 
 
• Alex Endert is with Virginia Tech, E-Mail: aendert@vt.edu 
• Patrick Fiaux is with Virginia Tech, E-Mail: pfiaux@vt.edu 
• Chris North is with Virginia Tech, E-Mail: north@cs.vt.edu 
Manuscript  received  31  March  2011;  accepted  1  August  2011;  posted 
online  23 October 2011; mailed on 14 October 2011. 
For information on obtaining reprints of this article, please send  
email to: tvcg@computer.org. 

 

learn 

taking 

incrementally  by 

and adding information. 
4.  Shield  the  users  from  the  complexity  of  the  underlying 
mathematical models and parameters. 
into  account 
5.  Models 
interaction  during  the  entire  analytic  process,  supporting 
analysts’ process of incremental formalism [shipman]. 
6.  Provide visual feedback of the updated model and learned 
parameters within the visual metaphor. 
7.  Reuse  learned  model  parameters  in  future  or  streaming 
data within the visual metaphor. 
To demonstrate semantic interaction, we present ForceSPIRE, a 
prototype  for  spatial  analysis  of  text  documents.  ForceSPIRE  is  a 
flexible workspace merging the ability to forage and synthesize. 
1.1 

Foraging Tools 

translate 

We categorize foraging tools by their ability to pass data through 
complex statistical models and visualize the computed structure of 
the dataset for the user to gain insight. Thus, users interact with these 
tools primarily through directly manipulating the parameters of the 
model used for computing the structure. As such, users are required 
to 
their  domain  expertise  and  semantics  about  the 
information to determine which (and by how much) to adjust these 
parameters. The following examples further describe this category of 
tools. 
Visualizations  such  as  IN-SPIRE’s  “Galaxy  View”  (shown  in 
Fig.  1)  present  users  with  a  spatial  layout  of  textual  information 
where similar documents are proximally close to one another [5]. An 
algorithm  creates  the  layout  by  mapping  the  high-dimensional 
collection  of  text  documents  down  to  a  two-dimensional  view.  In 
these spatializations, the spatial metaphor is one in which users can 
infer meaning of the documents based on their location. The notion 
of  distance  between  documents  represents  how  similar  the  two 
documents  are  (i.e.,  more  similar  documents  are  placed  closer 
together). For instance, a cluster of documents represents a group of 
similar  documents,  and  documents  placed  between  two  clusters 
implies those documents are connected to both clusters. These views 
are beneficial as they allow users to visually gain an overview of the 
information,  such  as  what  key  themes  or  groups  exist  within  the 
dataset.  The  complex  statistical  models  that  compute  similarity 
between documents are based on the structure within the data, such 
as term or entity frequency. In order to interactively change the view, 
users are required to directly adjust keyword weights, add or remove 

 

 

Fig. 1. The IN-SPIRE Galaxy View showing a spatializtiation of 
documents represented as dots. Each cluster of dots represents a 
group of similar documents.  
documents/keywords, or provide more information on how to parse 
the documents for keywords/entities upon import.  
Similarly,  an  interactive  visualization  tool  called  iPCA  uses 
Principal  Component  Analysis  (PCA)  to  reduce  high-dimensional 
data  down  to  a  two-dimensional  plot,  providing  users  with  sliders 
and other visual controls for directly adjusting numerous parameters 
of the algorithm, such as individual eigenvalues, eigenvectors, and 
other components of PCA [6]. Through adjusting the parameters, the 
user can observe how the visualization changes. This allows users to 
gain insight into a dataset, given they have a thorough understanding 
of PCA, necessary to understand the implications behind the changes 
they are making to the model parameters. 
Alsakran  et  al.  presented  a  visualization  system,  STREAMIT, 
capable  of  spatially  arranging  text  streams  based  on  keyword 
similarity [7]. Again, users can interactively explore and adjust the 
spatial layout through directly changing the weight of keywords that 
they  find  important.  In  addition,  STREAMIT  allows  for  users  to 
conduct a temporal investigation of how clusters change over time. 
1.2 

Synthesis Tools 

Synthesis tools focus on allowing users to organize and maintain 
their hypotheses and insight regarding the data in a visual medium. 
In large part, this is done through presenting users with a flexible 
spatial workspace in which they can organize information through 
creating spatial structures. In doing so, users externalize their thought 
processes  (as  well  as  their  insights)  into  a  spatial  layout  of  the 
information. 
For  example,  Analyst’s  Notebook  [8]  provides  users  with  a 
spatial  workspace  where 
information  can  be  organized,  and 
connections  between  specific  pieces  of  information  (e.g.,  entities, 
documents, events, etc.) can be created. Similarly, The Sandbox [9] 
enables users to create a series of cases (collections of information) 
which can be organized spatially within the workspace.  
From previous studies, we found cognitive advantages associated 
with the manual creation of a spatial layout of the information [4]. 
By providing users a workspace in which to manually create spatial 
representations  of  the  information,  users  were  able  to  externalize 
their semantics of the information into the workspace. That is, they 
created spatial structures (e.g., clusters, timelines, etc.), and both the 
structures as well as the locations relative to remaining layout carried 
meaning to the users with regards to their sensemaking process.  
1.3 

Semantic Interaction 

With  semantic  interaction,  the  challenge  is  to  combine  the 
strengths of the foraging tools with those of the synthesis tools. That 
is,  the  goal  is  to  leverage  the  flexibility  and  ease  in  which  the 
synthesis tools allow users to inject their semantics about a dataset 

 

 

this  similarity 

Fig. 2 (top) The basic version of the “visualization pipeline”. 
Interaction can be performed on directly the Algorithm (blue arrow) 
or the data (red arrow). (bottom) Our modified version of the pipeline 
for semantic interaction, where the user interacts within the spatial 
metaphor (pink arrow). 
into  the  layout,  with  the  computational  power  of  the  statistical 
algorithms  used  in  foraging  tools.  As  such,  semantic  interaction 
occurs within a spatial workspace, with the added benefit that it is 
tightly coupled to the statistical model. Through this coupling, the 
system  interprets  the  analytical  reasoning  associated  with  the 
interaction within the spatial layout, and updates the corresponding 
statistical parameters of the model.  
In ForceSPIRE, the statistical model generating the spatialization 
is  tightly  coupled  with  the  interaction.  That  is,  the  algorithm 
generates  a  layout  of  documents  based  on  similarity,  and  the 
parameters  and  characteristics  upon  which 
is 
calculated  can  be  adjusted  through  user  interaction  with  the 
documents in the spatial metaphor. ForceSPIRE utilizes a modified 
force-directed  system  (modified  from 
the  original  algorithm 
presented in [10]), to create a visualization where a spatial layout is 
algorithmically  generated.  The  modifications  of  the  layout  (and  in 
turn  the  algorithm)  are  performed  through  forms  of  semantic 
interaction  such  as  document  movement,  text  highlighting,  text 
querying, and annotations. In previous work, we have shown how 
movement in itself can be used to guide other statistical models (e.g., 
Multidimensional  Scaling,  Probabilistic  Principal  Component 
Analysis,  and  Generative  Topographic  Map)  [11].  The  statistical 
parameters  modified  in  ForceSPIRE  are  relative  importance  of 
keywords (entities), addition or removal of entities, and anchoring 
specific documents to locations in the layout. Thus, interaction takes 
on a deeper, more integrated role in the exploratory spatial analytic 
process. Essentially, users are able to input their domain knowledge 
by  modifying  the  spatial  layout,  which  in  turn  informs  the  layout 
models to respond and produce a better overall layout. 
Semantic interaction is grounded in the principles of how users 
are  familiar  with analysing  and  exploring  information  spatially [4, 
12]. We leverage these interactions and tightly integrate them into 
the modified force-directed model of the system, creating methods 
for  users  to  input  or  change  algorithm  parameters,  while  being 
abstracted from the complexities of doing so directly. Thus, semantic 
interaction is different from interactions designed to directly change 
statistical parameters (e.g. those incorporated in many foraging tools, 
modelled  by  the  traditional  visualization  pipeline),  and  are  more 
computationally  powerful  than  manual  layout  interactions  used  by 
many synthesis tools. In contrast, semantic interaction transforms the 
role  of  the  spatialization  into  a  medium  through  which  users  can 
perceive insight, as well as interact (Fig. 2). Semantic interaction is 
made  possible  through  capturing  the  interaction,  interpreting  the 
analytical reasoning associated with the interaction, and updating the 
corresponding statistical parameters.  
2  TEXT ANALYTICS USING FORCESPIRE 

ForceSPIRE  is  a  visual  analytic  system  designed  for  semantic 
interaction.  It  features  select  instances  of  semantic  interaction 
(document movement, text highlighting, search, and annotation) for 
interactively exploring textual data. The system has a single view, 
where  a  collection  of  documents  is  represented  spatially  based  on 

 
Fig. 3. Moving the document shown by the arrow, ForceSPIRE 
adapts the layout accordingly. Documents sharing entities with the 
document being moved follow. 
similarity  (i.e.,  documents  closer  together  are  more  similar). 
Documents  are  represented  as  nodes,  and  when  clicked  on,  show 
edges to other documents with shared entities. The shared entities are 
displayed on the edge. 
ForceSPIRE  is  designed  for  large,  high-resolution  displays.  As 
such,  users  have  the  ability  to  display  documents  at  two  different 
levels of detail: either small nodes or full detail text. As semantic 
interaction  emphasizes  the  importance  of  context  in  which  the 
interaction takes place (e.g., highlighting text in the context of the 
document), having the full detail text available in the context of the 
spatial layout is beneficial over having a single document viewer.  
2.1 

Constructing the Spatialization 

to 

textual 

We  apply 

this  model 

information  by 

The  spatial  layout  of  the  text  documents  is  determined  by  a 
modified  version  a  force-directed  graph  layout  model  [10].  This 
model functions on the principle of nodes with a mass connected by 
springs  with  varying  strengths.  Thus,  each  node  has  attributes  of 
attraction  and  repulsion:  nodes  repel  other  nodes,  and  two  nodes 
attract  each  other  only  when  connected  by  a  spring  (edge).  The 
optimal  layout  is  then  computed  by  iteratively  calculating  these 
forces until the lowest energy state of all the nodes is reached.  
treating 
documents as nodes. The entire textual content of each document is 
parsed into a collection of entities (i.e., keywords). The number of 
entities  corresponds  to  the  mass  of  each  document.  A  spring  (or 
edge) represents one or more matching entities between two nodes. 
For example, two documents containing the term “airport” will be 
connected  by  a  spring.  The  strength  of  a  spring  (i.e.  how  close 
together  it  tries  to  place  two  nodes)  is  based  on  two  factors:  the 
number  of  entities  two  documents  have  in  common,  and  the 
importance value associated with each shared entity. The importance 
value of an entity, and thus the strength of a spring, can be adjusted 
through the various instances of semantic interaction, explained in 
the following sections. The higher the sum of the importance values 
of all entities within a spring, the tighter the spring will pull the two 
documents that it connects. While we only create edges between two 
documents  that  share  at  least  one  entity,  the  model  can  also  be 
thought of as all pair of documents have edges, and if there are not 
shared entities between the two documents, the strength of that edge 
is set to zero. 
The  resulting  spatial  layout  is  therefore  one  where  similarity 
between  documents  is  represented  by  distance  relative  to  other 
documents. Similarity in this system is defined by the strength of the 
spring between two documents.  

Fig. 4. The effect of highlighting a phrase containing the entites 
“Colorado” and “missiles”. Documents containing these entities 
move closer by increasing their importance values. 

 

2.2 

Semantic Interaction in ForceSPIRE 

ForceSPIRE  allows  users  to  analyse  a  textual  dataset  by 
positioning  documents  at  specific  locations,  highlighting  phrases 
within the documents, performing searches, and adding annotations 
to documents. ForceSPIRE couples these interactions to updates of 
the  corresponding  parameters  of  the  force-directed  model.  The 
primary  parameters  of  the  force-directed  model  that  are  being 
updated by these interactions are the strengths of the edges through 
updating the importance values of entities.  
2.2.1 

Document Movement 

Users  are  able  to  interactively  explore  the  information  by 
dragging a document within the workspace, pinning a document to a 
particular location (see Fig. 3), as well as linking two documents. In 
previous  work,  we  have  shown  how  document  movement  in 
spatializations can be described as either exploratory or expressive 
[11]. An exploratory document movement enables users to explore 
the  relationships  between  the  information  given  the  current  model 
parameters.  In  contrast,  through  performing  an  expressive  form  of 
document  movement,  users  can  add  semantic  information  into  the 
system. For example, when dragging a document, the force-directed 
system responds by finding the lowest energy state of the remaining 
documents given the current location of the dragged document. As a 
result, documents rearrange based on similarity. Documents similar 
to the one being dragged will follow, while documents not similar 
will remain stationary. This allows users to explore the relationship 
of that document in comparison to the remaining documents. 
In addition to the exploratory dragging of a document, users have 
the ability to pin a document (an expressive interaction). By pinning 
a document, users are able to incrementally add semantic meaning to 
locations in their workspace (i.e., to express their domain knowledge 
into  the  system).  By  specifying  key  documents  to  user-defined 
locations, the layout of the remaining documents will adapt to the 
locations  of  the  pinned  documents.  Thus,  users  can  explore  how 
documents are positioned based on their similarity (or dissimilarity) 
to  the  pinned  documents.  For  instance,  if  the  layout  places  a 
document  between  two  pinned  documents,  it  may  imply  that  the 
particular document holds a link between the two pinned documents, 
sharing entities that occur in both. 
Finally, users can link two documents by dragging one document 
with another. In performing this expressive interaction, ForceSPIRE 
calculates the similarity between the documents in terms of shared 
entities, and increases their importance values. As a result, the layout 
will place more emphasis on the characteristics that make those two 
documents similar.  

 

Fig. 5. Searching for the term ”Atlanta”, documents containing the 
term highlight green within the context of the spatial layout. 
Additionally, the importance value of entity “Atlanta” is increased. 

 

2.2.2 

Highlighting 

While reading a document, users commonly utilize highlighting a 
term or phrase as a way to emphasize parts of the text. In a previous 
study,  we  found  analysts  highlighting  text  within  a  document  in 
order to mark important terms or phrases and personalize the visual 
representation of the document based on the highlights [4].  
In  ForceSPIRE,  we  present  users  with  the  similar  ability  to 
highlight  text  within  documents,  with  the  added  benefit  that  the 
system makes use of this information. When highlighting a term, the 
term is turned into an entity (if not already one), and the importance 
value of that term is increased. This term importance value increase 
is  global,  meaning  all  edges  between  documents  that  include  this 
entity  will  increase  in  strength.  Similarly,  highlighting  a  phrase 
results in the phrase being first parsed for entities that it contains, 
then increasing the importance value of each of those entities. Thus, 
users  are  able  to  focus  on  reading  and  understanding  a  particular 
document while ForceSPIRE performs the corresponding parameter 
updates (see Fig. 4). 
2.2.3 
Searching 

When coming across a term of particular interest, analysts usually 
search on that term in order to find other instances of where the term 
is  found.  In  a  spatial  workspace,  this  is  of  particular  importance, 
because  the  answer  to  “where  the  term  is  also  found”  is  not  only 
given in terms of what documents, but also where in the layout those 
documents  occur.  The  positions  of  documents  containing  the  term 
are shown in context of the entire dataset, from which users can infer 
the importance of that term.  
ForceSPIRE takes advantage of users searching by adjusting the 
importance value of the terms that are searched. ForceSPIRE ensures 
that the search term is an entity, and increases the importance value 
of the term accordingly. Fig. 5 gives an example of how a search 
result  appears  in  ForceSPIRE.  Searching  for  the  term  “Atlanta”, 
documents that contain the term are highlighted green, and links are 
drawn to show where the resulting documents are in relation to the 
current document.  
2.2.4 

Annotation 

Annotations  (i.e.  “sticky  notes”)  are  also  viewed  as  a  form  of 
semantic  interaction  occurring  within  the  analytic  process,  from 
which analytic reasoning can be inferred. When a user creates a note 
regarding a document, that semantic information should be added to 
the  document.  For  example,  if  Document  A  refers  to  “Revolution 
Now”  (a  suspicious  terrorist  group),  and  Document  B  refers  to  “a 
group of suspicious individuals”, and the user has reason to believe 
these  individuals  are  related  to  Revolution  Now,  adding  a  note  to 
Document B stating “these individuals may be related to Revolution 
Now”  is  one  way  for  the  user  to  add  semantic  meaning  to  the 
document.  
ForceSPIRE handles the addition of the note as follows (shown in 
Fig. 6). First, the note is parsed for any currently existing entities in 

 
Fig. 6. The effect of adding an annotation (“these individuals may be 
related to Revolution Now”) to the document shown with an arrow. 
As a result, the document becomes associated with other 
documents mentioning the terrorist organization “Revolution Now”.  
the  dataset  (in  this  case  “Revolution  Now”).  If  entities  are  found, 
they are added to the document, and any new corresponding edges to 
other  documents  are  added.  In  the  example  in  Fig.  6,  edges  are 
created between Document B and Document A (as well as any other 
documents  that  mention  “Revolution  Now”).  Second,  if  the  note 
contains any new entities, they are created, with the intent that any 
future entities that may match to that note can be linked at that time. 
Finally,  any  of  the  entities  in  a  note  receive  an  increase  in  their 
importance values. ForceSPIRE also handles cases where notes are 
edited, with text added or removed from the note, by updating the 
entities associated with the document, and adjusting the importance 
values of these entities accordingly. 
3  CONCLUSION 

in  ForceSPIRE 

(document  movement, 

In  this  paper  we  briefly  discussed  how  semantic  interaction  in 
ForceSPIRE can help combine the strengths foraging and synthesis 
tools  for  text  analytics.  We  present  how  each  of  the  four  primary 
interactions 
search, 
highlighting, and annotation) are tightly coupled with the underlying 
statistical  model.  Thus,  users  are  able  to  focus  on  their  task  of 
analysis,  without  the  added  complexity  of  directly  modifying 
statistical parameters.  
REFERENCES 
[1] Thomas, J. J., Cook, K. A., National, V. and Analytics, C. Illuminating 
the path. IEEE Computer Society, City, 2005. 
[2] Pirolli, P. and Card, S. Sensemaking Processes of Intelligence Analysts 
and Possible Leverage Points as Identified Though Cognitive Task Analysis 
Proceedings of the 2005 International Conference on Intelligence Analysis, 
McLean, Virginia, 2005, 6. 
[3]  Skupin,  A.  A  Cartographic  Approach  to  Visualizing  Conference 
Abstracts. City, 2002. 
[4]  Andrews,  C.,  Endert,  A.  and  North,  C.  Space  to  Think:  Large,  High-
Resolution Displays for Sensemaking. In Proceedings of the CHI (2010).  
[5] Wise, J. A., Thomas, J. J., Pennock, K., Lantrip, D., Pottier, M., Schur, A. 
and  Crow,  V.  Visualizing  the  non-visual:  spatial  analysis  and  interaction 
with information for text documents. Morgan Kaufmann Publishers Inc, 1999. 
[6] Jeong, D. H., Ziemkiewicz, C., Fisher, B., Ribarsky, W. and Chang, R. 
iPCA:  An  Interactive  System  for  PCA-based  Visual  Analytics.  Computer 
Graphics Forum, 28, 2009, 767-774. 
[7]  Alsakran,  J.,  Chen,  Y.,  Zhao,  Y.,  Yang,  J.  and  Luo,  D.  STREAMIT: 
Dynamic  visualization  and  interactive  exploration  of  text  streams.  In 
Proceedings of the IEEE Pacific Visualization Symposium (2011).  
[8] i2 Analyst's Notebook. 
[9]  Wright,  W.,  Schroh,  D.,  Proulx,  P.,  Skaburskis,  A.  and  Cort,  B.  The 
Sandbox for analysis: concepts and methods. In Proceedings of the CHI '06 
(New York, NY, 2006). ACM.  
[10]  Fruchterman,  T.  M.  J.  and  Reingold,  E.  M.  Graph  drawing  by  force-
directed placement. Software: Practice and Experience, 21, 11, 1991. 
[11] Endert, A., Han, C., Maiti, D., House, L., Leman, S. C. and North, C. 
Observation-level Interaction with Statistical Models for Visual Analytics, In 
Proceedings of the VAST, 2011. 
[12] Robinson, A. C. Design for Synthesis in Geovisualization. PhD thesis, 
Pennsylvannia State University, University Park, PA, 2008. 
 

","{""0"":{""0"":""document"",""1"":""importance"",""2"":""metaphor"",""3"":""note*"",""4"":""modified"",""5"":""shared*"",""6"":""strength"",""7"":""particular"",""8"":""edge""},""1"":{""0"":""entities*"",""1"":""models"",""2"":""tools"",""3"":""algorithm"",""4"":""datasets"",""5"":""dimensional"",""6"":""clusters*"",""7"":""stages*"",""8"":""structures*""},""pos"":{""0"":1,""1"":2,""2"":3,""3"":4,""4"":5,""5"":6,""6"":7,""7"":8,""8"":9}}",2011,{},False,False,conferencePaper,False,SP8F58ZB,[],self.user,"{""C"":{""0"":6.0400029277,""1"":18.6808480742,""10"":12.1169053223,""11"":7.3071622262,""12"":12.1892025498,""13"":5.1930540869,""14"":11.1255231326,""15"":5.799512616,""16"":3.9704360372,""17"":4.4354880101,""18"":5.2570875367,""19"":7.19781322,""2"":6.4379223444,""20"":4.7990161165,""21"":5.4726596917,""22"":4.1992213791,""23"":4.7758274492,""24"":5.1327700894,""25"":5.278651692,""26"":6.4458555138,""27"":6.3327589076,""28"":4.4823036574,""29"":4.5952974249,""3"":10.1015827593,""30"":4.5952974249,""31"":4.0836460489,""32"":4.5577176364,""33"":4.4825326909,""4"":8.3927555778,""5"":4.3461807133,""6"":5.4932362641,""7"":4.4344193027,""8"":6.0978078306,""9"":14.8443310723},""Unnamed: 0"":{""0"":0,""1"":1,""10"":10,""11"":11,""12"":12,""13"":13,""14"":14,""15"":15,""16"":16,""17"":17,""18"":18,""19"":19,""2"":2,""20"":20,""21"":21,""22"":22,""23"":23,""24"":24,""25"":25,""26"":26,""27"":27,""28"":28,""29"":29,""3"":3,""30"":30,""31"":33,""32"":34,""33"":35,""4"":4,""5"":5,""6"":6,""7"":7,""8"":8,""9"":9},""count"":{""0"":148,""1"":86,""10"":16,""11"":16,""12"":16,""13"":14,""14"":14,""15"":12,""16"":10,""17"":10,""18"":10,""19"":10,""2"":52,""20"":8,""21"":8,""22"":8,""23"":8,""24"":8,""25"":8,""26"":8,""27"":8,""28"":6,""29"":6,""3"":38,""30"":6,""31"":6,""32"":6,""33"":6,""4"":36,""5"":34,""6"":28,""7"":28,""8"":24,""9"":20},""exemplar"":{""0"":null,""1"":null,""10"":null,""11"":null,""12"":""*"",""13"":null,""14"":null,""15"":null,""16"":""*"",""17"":null,""18"":null,""19"":null,""2"":""*"",""20"":null,""21"":null,""22"":""*"",""23"":null,""24"":null,""25"":null,""26"":""*"",""27"":null,""28"":""*"",""29"":null,""3"":null,""30"":null,""31"":""*"",""32"":""*"",""33"":""*"",""4"":null,""5"":null,""6"":null,""7"":null,""8"":null,""9"":null},""pos"":{""0"":1,""1"":1,""10"":5,""11"":6,""12"":4,""13"":4,""14"":7,""15"":5,""16"":6,""17"":7,""18"":8,""19"":8,""2"":1,""20"":5,""21"":6,""22"":7,""23"":9,""24"":9,""25"":10,""26"":11,""27"":10,""28"":8,""29"":11,""3"":2,""30"":12,""31"":9,""32"":13,""33"":14,""4"":2,""5"":3,""6"":2,""7"":3,""8"":3,""9"":4},""sigma_nor"":{""0"":1.4686373569,""1"":2.8842120288,""10"":3.3265583959,""11"":2.3680184907,""12"":3.3409666036,""13"":1.9795758709,""14"":3.2128675581,""15"":2.1468701095,""16"":1.7720925601,""17"":1.8784988446,""18"":2.0664850441,""19"":2.510533067,""2"":1.7894156048,""20"":1.9927376933,""21"":2.1554846563,""22"":1.8478320258,""23"":1.9871354946,""24"":2.073370015,""25"":2.1086138571,""26"":2.3906010743,""27"":2.3632778282,""28"":1.9334355202,""29"":1.9623682647,""3"":2.4241281749,""30"":1.9623682647,""31"":1.8313568041,""32"":1.9527457302,""33"":1.9334941656,""4"":2.2015388086,""5"":1.6152630223,""6"":1.8456803445,""7"":1.6727063376,""8"":1.99557761,""9"":3.6722846281},""topic"":{""0"":-1,""1"":0,""10"":-1,""11"":-1,""12"":0,""13"":1,""14"":-1,""15"":0,""16"":0,""17"":0,""18"":0,""19"":-1,""2"":1,""20"":1,""21"":1,""22"":1,""23"":0,""24"":-1,""25"":0,""26"":0,""27"":-1,""28"":1,""29"":-1,""3"":-1,""30"":0,""31"":1,""32"":0,""33"":0,""4"":0,""5"":-1,""6"":1,""7"":1,""8"":0,""9"":-1},""vector"":{""0"":""[ 0.07335245 -4.318293   -0.5736595  -1.6396177   0.40584004  0.51721656\n  2.1387546   1.8950881  -1.3854108   5.0395446 ]"",""1"":""[ 0.09525894 -4.02816    -0.5359891  -2.161028    0.7466888   0.41518015\n  2.1111808   1.9121553  -1.4303566   4.634463  ]"",""10"":""[ 0.21906443 -3.6531856  -1.2930716  -1.8870277   1.4517664   1.2938432\n  1.9755082   1.7715257  -1.4738818   4.8174906 ]"",""11"":""[ 0.6606386  -3.6286144  -1.2588174  -2.4059482   0.9989313   0.81344366\n  2.5327911   1.2787567  -0.96617466  4.5411615 ]"",""12"":""[ 0.04060223 -3.5706854  -0.87113816 -2.6880367   1.0332475   0.5227957\n  1.9404749   1.6418078  -1.3240906   4.3455505 ]"",""13"":""[ 1.0404611  -4.6316023  -0.7225149  -1.9164656   0.6839626   0.77128524\n  2.4516954   1.8589691  -0.7185417   5.57038   ]"",""14"":""[ 0.77045107 -4.2138987  -1.1964929  -1.4581772   1.2935535   1.1706904\n  2.5755434   1.7522483  -1.5194069   4.9547157 ]"",""15"":""[-0.24101785 -4.027269   -1.0953944  -2.9780607   0.97894204  1.1222203\n  1.4716407   1.0739963  -1.5977986   4.522899  ]"",""16"":""[-0.25712314 -3.8972492  -1.1672028  -2.865405    1.201686    1.1104927\n  1.5336413   1.1931828  -1.874842    4.2894096 ]"",""17"":""[ 0.47626847 -3.4269512  -1.4966305  -2.1408064   1.1913847   1.2563477\n  2.2926593   1.4435967  -0.96870655  4.8539968 ]"",""18"":""[ 0.07076864 -3.5615375  -0.98228544 -2.5647047   1.3142762   0.8550356\n  1.7947861   1.7703032  -1.3620505   4.6071787 ]"",""19"":""[ 0.10979844 -4.0563655  -0.7614925  -1.350682    0.7788037   0.8131105\n  2.2186098   2.0159788  -1.5556849   4.9043107 ]"",""2"":""[ 0.33738518 -4.9471235  -0.41035917 -1.4967853   0.62175924  1.2008692\n  2.1233394   1.9129546  -1.4744313   5.7144194 ]"",""20"":""[ 0.6722619  -4.6166034  -0.5404979  -1.7272124   0.46029294  0.7946102\n  2.3466697   1.8881795  -0.86861575  5.779775  ]"",""21"":""[ 0.6372885  -4.000805   -1.0551043  -1.9450388   0.91944784  1.5524741\n  2.3039324   1.5672969  -0.7831312   5.6227374 ]"",""22"":""[ 0.9510414  -4.9034557  -0.45214674 -1.7170478   0.75778204  0.87036675\n  2.3675728   1.8844349  -1.1137136   5.6991982 ]"",""23"":""[ 0.70518625 -3.8146434  -1.6264993  -2.0439427   1.0676416   1.0410023\n  2.5455782   1.1804692  -1.1058452   4.7371206 ]"",""24"":""[ 0.0544745 -3.7989647 -1.3905715 -2.5442045  1.30533    1.3502505\n  1.8869606  0.9949137 -1.6995456  4.3349557]"",""25"":""[ 0.63683385 -3.8045745  -1.2656883  -2.2002566   1.1930916   1.6123158\n  2.3384848   1.382811   -0.97718066  5.1883407 ]"",""26"":""[-0.13867949 -3.8429158  -1.362791   -2.8191066   1.2264352   1.2308944\n  1.6546807   1.001455   -1.7337753   4.251681  ]"",""27"":""[ 0.16907658 -4.8030405  -0.4628594  -1.7447802   0.7155796   1.0064251\n  1.905448    1.8598219  -1.6309382   5.5333557 ]"",""28"":""[ 0.3195927  -4.4890113  -0.8009248  -1.2508833   0.85977596  1.3719302\n  2.1933126   1.892641   -1.5023482   5.5496078 ]"",""29"":""[ 1.0361232  -4.2272196  -1.2387156  -1.6934665   1.0788643   0.88771266\n  2.7380593   1.576442   -1.1437075   4.998674  ]"",""3"":""[ 0.60620147 -4.196995   -0.9206209  -1.8896128   1.5775006   1.328476\n  2.3418748   1.8111535  -1.6750386   4.8082376 ]"",""30"":""[ 0.11222667 -4.0511737  -0.90002394 -1.8549064   0.40515226  0.49990678\n  2.1600592   1.606159   -1.2173151   4.7980013 ]"",""31"":""[ 0.5626454 -4.781177  -0.5964197 -1.4838415  0.7191847  1.4229223\n  2.4201252  1.6983728 -1.3665032  5.679807 ]"",""32"":""[ 0.20721868 -3.5458488  -0.7623556  -2.261626    0.91724956  0.49736145\n  2.191874    1.9449121  -1.1293503   4.602406  ]"",""33"":""[-0.20831285 -3.8898723  -0.95423776 -2.782169    1.0859749   0.89645964\n  1.5421308   1.4276185  -1.6293906   4.5328007 ]"",""4"":""[ 0.3743487  -3.3131878  -1.1334882  -2.3522742   0.98300254  0.60308903\n  2.3440244   1.652029   -0.9476085   4.5017405 ]"",""5"":""[ 0.52850693 -3.995302   -0.8377239  -2.0722659   0.58931226  0.80714536\n  2.2502427   1.7432306  -0.67781764  5.450445  ]"",""6"":""[ 0.5223548  -4.568201   -0.8832873  -1.5357842   0.83643806  1.5762889\n  2.206088    1.7406532  -1.1556203   5.898263  ]"",""7"":""[ 0.5301625 -4.526297  -1.2819514 -1.6221479  0.7552952  1.2636417\n  2.419575   1.409882  -1.2928665  5.473288 ]"",""8"":""[ 0.6847015 -4.3406157 -1.1297119 -1.7653096  1.4124281  1.6669025\n  2.3789396  1.6194668 -1.542646   5.2031326]"",""9"":""[ 1.2103289  -4.9596386  -0.66689706 -1.6581765   0.72774655  0.9217233\n  2.4815698   1.8494976  -0.86459124  5.737667  ]""},""vocab_index"":{""0"":0,""1"":2,""10"":45,""11"":46,""12"":47,""13"":51,""14"":56,""15"":64,""16"":86,""17"":89,""18"":90,""19"":91,""2"":8,""20"":93,""21"":107,""22"":110,""23"":125,""24"":127,""25"":128,""26"":130,""27"":131,""28"":143,""29"":147,""3"":14,""30"":148,""31"":162,""32"":174,""33"":181,""4"":15,""5"":16,""6"":17,""7"":18,""8"":22,""9"":34},""word"":{""0"":""documents"",""1"":""document"",""10"":""spring"",""11"":""value"",""12"":""note"",""13"":""algorithm"",""14"":""revolution"",""15"":""modified"",""16"":""shared"",""17"":""strength"",""18"":""particular"",""19"":""proceedings"",""2"":""entities"",""20"":""datasets"",""21"":""dimensional"",""22"":""clusters"",""23"":""edge"",""24"":""dragging"",""25"":""expressive"",""26"":""pinned"",""27"":""individuals"",""28"":""stages"",""29"":""tech"",""3"":""term"",""30"":""mail"",""31"":""structures"",""32"":""detail"",""33"":""related"",""4"":""importance"",""5"":""statistical"",""6"":""models"",""7"":""tools"",""8"":""metaphor"",""9"":""nodes""},""word*"":{""0"":""documents"",""1"":""document"",""10"":""spring"",""11"":""value"",""12"":""note*"",""13"":""algorithm"",""14"":""revolution"",""15"":""modified"",""16"":""shared*"",""17"":""strength"",""18"":""particular"",""19"":""proceedings"",""2"":""entities*"",""20"":""datasets"",""21"":""dimensional"",""22"":""clusters*"",""23"":""edge"",""24"":""dragging"",""25"":""expressive"",""26"":""pinned*"",""27"":""individuals"",""28"":""stages*"",""29"":""tech"",""3"":""term"",""30"":""mail"",""31"":""structures*"",""32"":""detail*"",""33"":""related*"",""4"":""importance"",""5"":""statistical"",""6"":""models"",""7"":""tools"",""8"":""metaphor"",""9"":""nodes""},""x2D"":{""0"":7.0221757889,""1"":6.2402677536,""10"":6.7151217461,""11"":6.3521447182,""12"":5.5308613777,""13"":9.9704294205,""14"":7.913807869,""15"":4.4479231834,""16"":4.763484478,""17"":6.8411483765,""18"":5.4937496185,""19"":7.1922974586,""2"":8.9526472092,""20"":9.7833957672,""21"":8.6401033401,""22"":9.6414699554,""23"":7.0325431824,""24"":4.2920694351,""25"":7.4707798958,""26"":4.6130690575,""27"":8.4960126877,""28"":8.4986200333,""29"":8.1113653183,""3"":7.3590598106,""30"":6.5934581757,""31"":8.9943819046,""32"":6.034058094,""33"":5.0175004005,""4"":6.0092506409,""5"":9.3033533096,""6"":8.8876447678,""7"":8.2960996628,""8"":7.7491145134,""9"":10.0907258987},""y2D"":{""0"":7.3905982971,""1"":6.8696041107,""10"":5.6107621193,""11"":4.9341273308,""12"":6.3065886497,""13"":6.4049625397,""14"":5.7444491386,""15"":6.3142194748,""16"":6.0832920074,""17"":5.2668390274,""18"":5.9201979637,""19"":6.9968342781,""2"":7.5748057365,""20"":6.6048483849,""21"":6.0070734024,""22"":7.0295481682,""23"":4.8798074722,""24"":5.813832283,""25"":5.2001605034,""26"":5.864739418,""27"":7.665585041,""28"":7.1772623062,""29"":5.3908996582,""3"":5.7607536316,""30"":7.0059943199,""31"":7.1665663719,""32"":6.3085784912,""33"":6.366625309,""4"":5.6421275139,""5"":6.1259660721,""6"":6.7538528442,""7"":6.596637249,""8"":6.0389809608,""9"":7.0917396545}}",False,False,False,,"<p>In current methods, users must interact with the visualizations using cotrols extrnal to the visual metaphor, such as sliders, menus, or text input flied, to directly control underlying model parameters that they do not understand and that do not relate to their analytic process ocurring within the visualization.</p>
<p><strong>Foraging</strong> refers to the stages of the process where users are filtering and gathering collections of interesting or relevant information. Then, usign that information, users advance through the synthesis stages of the process, where they construct and test hypotheses about how the foraged information might relate to the larger plot. <strong>Their main claim is that tools exists that support either of them but not both.</strong></p>
<p>In previous paper space to think they found advantages associated with the manual creation of spatial layout of the information.</p>
<p>The algorithm generates a layout for the documents based on similarity, and the parameters of characteristics upon which the similarity is calculated can be adjusted through user interaction with the documents in the spatial metaphor.</p>
<p>Leverage this interactions allow methods for the users to input or change the algorithm parameter, while being abstract from the complexities of doing so directly.</p>
<p><strong>The interactions they define:</strong></p>
<p><strong>    1. Drag:        M</strong>ove a document others similar will follow</p>
<p>                    Move a document closer other gives a sense of higher similarity</p>
<p><strong>    2. Pin: </strong>Pin some documents at specific locations the rest will follow that</p>
<p><strong>    3. Link: </strong>One document to another to express direct relationship</p>
<p>    4. <strong>Highlighting: </strong>Increases the value of an entity in the model</p>
<p>    5. <strong>Searching: </strong>Searching for a term updates the importance of that term.</p>
<p><strong>    6. Annotation: </strong>Annotations add more semantic meaning to the regions of the documents adding new terms to them or raising the importance of the already existing terms.</p>",Unifying the sensemaking loop with semantic interaction,"[-2.23671257e-01  5.05415559e-01  6.74329996e-02 -1.76710755e-01
  1.74605981e-01 -8.72699358e-03  7.91767910e-02  1.13512956e-01
 -4.09647763e-01 -5.80804527e-01  9.84104276e-02  2.20842928e-01
  6.51027039e-02 -1.33168548e-01  4.07363661e-02  6.80476069e-01
 -1.43833518e-01 -5.93256280e-02  1.33993030e-01 -1.10961817e-01
  2.08921179e-01  1.67934433e-01 -1.38758674e-01  4.09719467e-01
  3.87931019e-01  1.32787883e-01 -1.40003264e-01  1.33305430e-01
 -2.91778326e-01  1.63160041e-01  1.89831987e-01  4.24058408e-01
 -1.78957656e-02 -1.70821190e-01  1.61820166e-02 -4.71293032e-02
 -4.72064435e-01 -4.46379464e-03 -4.76916693e-02  3.90343308e-01
 -5.09953856e-01 -1.67354673e-01 -2.83667203e-02 -5.16926311e-03
  1.90227628e-01  1.00322120e-01 -5.11794269e-01 -1.19446479e-01
 -2.31666699e-01 -2.02964306e-01 -1.19554639e+00 -3.55938733e-01
 -1.56285867e-01 -2.14014187e-01 -3.43653917e-01  3.42944026e-01
 -2.28333682e-01 -4.30139124e-01  2.05094874e-01  4.26178798e-02
 -2.54748970e-01 -2.40571156e-01 -2.80032545e-01  1.59424618e-01
  1.59946188e-01 -1.87984258e-01  9.36901644e-02  2.10969403e-01
 -5.00680208e-01  2.97666669e-01 -5.34399040e-02  2.04925954e-01
 -3.02747667e-01  4.88675646e-02 -4.31518734e-01  1.43694021e-02
 -3.78987283e-01  2.51532793e-01  4.71655838e-03 -1.83913797e-01
 -4.50813442e-01  1.31211877e-01  6.34897053e-02 -2.77834833e-01
  5.79781950e-01  3.11959416e-01  1.61195904e-01  6.07249856e-01
 -3.26907724e-01  3.72037858e-01 -4.97398265e-02  4.86479476e-02
 -1.19724661e-01  1.02117158e-01  5.42109072e-01  2.18993425e-03
 -3.34266514e-01  3.60414863e-01 -2.12778002e-01 -1.10476524e-01
  2.41930604e-01  4.34709266e-02  1.94057792e-01 -1.47156864e-01
  2.33277172e-01 -3.67789692e-03 -2.86177754e-01 -4.12316859e-01
  1.17768094e-01  3.65959071e-02  8.94427225e-02  1.29463866e-01
  1.17197879e-01 -1.11327827e-01 -3.93011346e-02  1.49675384e-01
  1.12245902e-02  2.97244728e-01  1.10198528e-01  3.28570120e-02
 -9.20069963e-02  6.79605082e-02 -1.81144536e-01  2.94032276e-01
  8.11436549e-02 -1.95334166e-01 -5.64261794e-01 -8.28148723e-02
 -4.54128645e-02  1.40253663e-01  3.61120880e-01 -3.84813435e-02
 -8.54495317e-02 -4.79697324e-02 -3.38499308e-01  5.68702102e-01
  1.54592246e-01  3.59426349e-01 -1.83712184e-01 -5.73661625e-02
 -4.38345820e-01 -3.90176289e-02 -1.23450562e-01 -1.49864271e-01
  3.08970422e-01  7.81552345e-02  9.48908702e-02 -1.06534828e-02
  1.06429346e-01  1.35642782e-01 -5.82469463e-01  4.21283334e-01
 -7.23358870e-01 -1.43845141e-01 -6.54711276e-02  2.65352368e-01
 -1.84530079e-01  3.51101756e-01 -2.04357475e-01 -8.26346949e-02
  1.02513753e-01  1.72939505e-02 -4.62720953e-02 -1.02416754e-01
  2.10479915e-01 -4.31477964e-01 -8.01467523e-02  3.50210279e-01
 -2.66901165e-01 -4.64547068e-01  2.34576762e-01 -5.58796287e-01
  4.97848988e-02 -8.05037916e-02  4.78912406e-02 -1.02877654e-01
 -2.01430041e-02 -1.24578141e-02  1.48145175e-02  9.70035374e-01
 -4.01693732e-01  3.06707352e-01 -2.54810691e-01 -3.55370432e-01
  2.82270879e-01 -8.03728104e-02 -1.02786042e-01 -4.20336008e-01
  1.99742317e-01 -5.63769490e-02 -4.82111961e-01 -6.46474138e-02
 -7.17500895e-02 -4.08633351e-01  3.78664404e-01 -4.89453971e-01
 -1.57859996e-01  2.43802622e-01  2.35012129e-01 -2.10710645e-01
  1.80136204e-01  4.41161878e-02 -1.30910829e-01 -4.03113812e-02
 -8.49184766e-02  2.60342173e-02  1.78799853e-01 -4.31414843e-01
 -7.36431181e-01  2.19677880e-01 -2.10864127e-01  2.78099567e-01
  2.27370169e-02  4.18733507e-01  1.98899090e-01 -2.16727391e-01
  1.99015528e-01  4.89130765e-02  1.41100973e-01  4.16624993e-01
  1.14121273e-01 -5.37717879e-01 -1.13786705e-01  4.19346839e-01
 -3.95860374e-01  1.08534610e+00  5.44998527e-01 -1.97539762e-01
  6.29194915e-01 -1.63607709e-02  6.91486821e-02 -9.44734067e-02
  3.53080869e-01 -5.07148683e-01 -9.88115519e-02  2.88452744e-01
  4.42848951e-02 -3.93025011e-01  2.69944251e-01 -2.83620179e-01
 -2.50152964e-02 -3.30454409e-02 -1.97372988e-01  6.47269469e-03
 -1.15178050e-02 -2.10456312e-01 -5.54196388e-02 -1.40706554e-01
 -3.13590527e-01  2.31442496e-01 -5.38443327e-01  6.83970144e-03
 -5.83441734e-01 -1.89404160e-01 -2.31456161e-02 -2.88904458e-01
  1.24457769e-01 -1.58060521e-01 -3.47275287e-01  2.21883789e-01
  7.08460569e-01  2.40736395e-01  1.85470916e-02  1.11968406e-01
 -1.80491582e-02 -3.07451963e-01  7.47480094e-02 -1.68076381e-01
  4.42918807e-01  1.68657497e-01  1.22890569e-01 -4.20726627e-01
  1.44267976e-01  6.89109564e-01 -2.16574371e-01 -1.96635917e-01
  3.54010135e-01 -5.03138788e-02 -2.29021817e-01 -2.17309892e-01
  8.45783018e-03  1.13513283e-02  2.68829137e-01 -2.53172759e-02
 -1.55498624e-01 -6.11336946e-01  1.03474833e-01  4.90919352e-02
  2.92778164e-01  2.11509485e-02  1.80257037e-01  6.20252669e-01
 -3.42750281e-01 -3.64572078e-01  8.45078051e-01  3.43826801e-01
  3.60396743e-01 -1.20887846e-01 -3.88740003e-01 -5.09416342e-01
 -4.23445016e-01  4.05923724e-01  2.31277004e-01 -2.92984955e-03
  3.11377615e-01  2.95884103e-01 -3.36568922e-01 -4.26907957e-01
 -1.36156740e+01 -4.77089994e-02 -8.10027421e-02 -1.60395671e-02
  2.92801932e-02 -1.87894121e-01 -8.03057477e-02 -3.71451955e-03
 -6.93563819e-02 -2.65870810e-01 -3.40536714e-01  2.55223334e-01
 -1.38654009e-01  3.17733884e-01  2.66581159e-02 -2.18637273e-01
 -4.11633253e-02  4.41253334e-02 -5.92110991e-01  6.13222718e-01
 -4.00488436e-01 -1.68196470e-01  2.71073997e-01 -5.32435142e-02
 -2.54434109e-01 -8.27518463e-01 -6.27924204e-01  5.93062103e-01
 -1.85576990e-01 -5.34071445e-01 -1.70372471e-01 -2.19496310e-01
 -5.83655119e-01  6.04933023e-01 -1.95176110e-01 -3.50741267e-01
 -2.39701360e-01 -4.44913208e-01  4.53534931e-01 -8.83040354e-02
  9.94307324e-02 -2.63849944e-01  2.55047530e-01  1.12439252e-01
  5.67160726e-01 -2.28656009e-02  3.05858612e-01  3.24157119e-01
 -1.57354504e-01  2.24697471e-01 -8.15174505e-02 -2.42789879e-01
  8.94818008e-02 -3.99358302e-01  2.48637244e-01 -1.46621168e-01
  7.80657351e-01  2.21185610e-01 -1.02486096e-01 -3.00914854e-01
 -2.16339916e-01 -5.68499327e-01 -1.08083248e-01  7.08366036e-02
  1.61707476e-01  4.11055610e-02 -9.00036216e-01 -3.56708825e-01
 -2.76331782e-01 -8.53492618e-02 -1.71246856e-01  6.26735628e-01
  1.53426215e-01 -1.18081760e+00 -5.83887279e-01 -2.99109340e-01
  1.71333715e-01 -1.40086964e-01  3.81683469e-01 -3.96016419e-01
 -2.11469114e-01 -1.19442433e-01  1.95353374e-01 -1.16505452e-01
 -6.55310690e-01  1.82231471e-01  3.43803428e-02 -2.70492613e-01
 -8.43988597e-01  3.69755208e-01  2.57293761e-01  1.23590171e-01
  7.33499527e-02  3.90672296e-01  6.79234192e-02  1.34138821e-03
  3.32087606e-01 -6.55701607e-02 -5.76547161e-03  9.23165232e-02
  2.32375637e-01 -2.16498449e-01  2.29437605e-01 -3.28991711e-01
 -1.47815660e-01  4.69133884e-01 -5.44845641e-01  5.30465782e-01
  6.23590529e-01  3.50014269e-01 -2.28811547e-01  3.39209110e-01
  2.62138814e-01 -8.43982771e-02 -1.96042329e-01  5.65627068e-02
 -3.05362374e-01  1.72112241e-01  1.99131425e-02 -4.17740822e-01
 -2.74378687e-01 -2.22912461e-01  1.97807312e-01 -5.27418740e-02
  2.74303377e-01 -1.32993236e-01 -2.34165788e-01  2.67492291e-02
  1.16846889e-01 -2.67903864e-01  2.02487886e-01 -3.21982563e-01
  4.28619504e-01  1.25654206e-01  3.86554033e-01  1.99793037e-02
 -1.15320534e-01 -4.18602139e-01 -5.74222505e-01  1.50383681e-01
  5.86038172e-01  1.06325023e-01  2.09236279e-01 -3.11689168e-01
 -2.15817600e-01 -1.07072204e-01 -2.04985470e-01  1.23260424e-01
 -3.20171326e-01  2.74476886e-01 -2.74752617e-01 -7.11085975e-01
  1.71745628e-01 -2.73559570e-01  3.21438760e-01  3.63824338e-01
  9.85371992e-02 -3.52709681e-01  1.00583315e-01 -5.94265163e-01
 -2.61751586e-03  1.56522423e-01  1.11030526e-02 -3.32872309e-02
 -2.97193229e-01  1.26831099e-01 -2.94363618e-01 -8.47424567e-02
  2.77361095e-01 -6.79169834e-01 -3.38828892e-01 -2.16683090e-01
  1.94583107e-02 -2.70840734e-01 -7.35936463e-02  4.41929430e-01
  8.01115483e-02 -6.81823771e-03 -5.23133099e-01  6.13909304e-01
  2.66999155e-01  2.76557744e-01 -2.73117334e-01  1.59084842e-01
  2.84729570e-01  2.08828866e-01  5.61119676e-01  1.37664122e-03
  6.16872534e-02 -7.52148032e-02 -4.95108783e-01  4.93793190e-01
 -1.14440843e-01 -9.92375314e-02 -1.15349859e-01 -3.82360458e-01
  3.36060882e-01 -2.80005872e-01 -5.85650168e-02 -6.25712378e-03
 -7.53355250e-02 -1.28135145e-01 -1.44488871e-01  8.41462985e-02
  7.81265646e-02 -1.21011712e-01 -1.46860927e-01  1.48641109e-03
 -2.39880234e-01 -1.62517399e-01 -1.68073192e-01 -3.07894677e-01
  2.17214569e-01 -4.23444897e-01  3.76918823e-01 -1.14729546e-01
 -1.20545350e-01 -1.45860910e-01 -6.30341530e-01  1.70058846e-01
 -9.62613802e-03  4.10984121e-02  8.29307437e-02  1.40848011e-01
  3.23744625e-01  5.30829877e-02  3.41435969e-01  9.24510658e-02
 -2.21433088e-01  9.15754810e-02 -3.68628532e-01 -1.15208554e+00
  1.06590576e-01  8.41260925e-02 -5.57995848e-02 -2.27588803e-01
 -4.12939608e-01  1.05213612e-01  2.73458213e-01 -2.76383042e-01
  3.86658132e-01 -9.47125331e-02 -1.49559513e-01 -3.28864664e-01
  1.77114472e-01 -1.93058535e-01 -3.01697642e-01 -2.87271678e-01
 -4.35189903e-01  1.83605939e-01  2.14723408e-01  6.73984513e-02
  1.61531031e-01 -3.22144955e-01  4.94188398e-01 -4.08203721e-01
 -1.91103175e-01 -4.01136577e-01 -1.68683872e-01 -1.94633365e-01
 -1.59240261e-01 -1.29037201e-01 -4.36653823e-01  2.70335555e-01
 -3.55957121e-01  8.27603266e-02 -1.89005546e-02 -2.02293053e-01
 -1.31499037e-01 -4.55067992e-01  3.48846942e-01 -2.01460838e-01
 -2.52237380e-01  4.18627232e-01 -2.75440931e-01 -2.18613490e-01
 -9.02594551e-02  2.02902228e-01 -1.01052644e-02 -1.02494058e-04
  1.28159404e-01 -3.86876673e-01  1.61160171e-01  1.63562790e-01
  4.59475905e-01 -4.59368736e-01 -2.95679539e-01 -3.59102249e-01
  9.22458172e-02 -2.47997910e-01  1.25702843e-01  1.49013072e-01
 -2.24984840e-01 -1.15102738e-01 -1.05437286e-01  5.33474505e-01
  3.41468096e-01  2.69477367e-01  2.49154180e-01  1.15280673e-01
 -6.75680414e-02  2.91382194e-01  5.52803874e-01 -3.07463527e-01
 -2.37166360e-01 -2.43370794e-02 -3.10984105e-01 -4.97278869e-01
 -8.25597942e-02 -4.67034250e-01 -2.01340288e-01 -1.72519851e-02
  4.15810347e-01  3.74413669e-01 -1.86859518e-02 -2.25235745e-01
  4.56346618e-03 -3.16649437e-01  4.16182011e-01  1.97793052e-01
 -6.01825953e-01  2.40344614e-01  6.15760446e-01 -4.30747449e-01
  1.86239198e-01  4.36346710e-01 -1.99613020e-01 -1.85861737e-01
  5.90442531e-02  5.05659640e-01  1.37327865e-01  5.00570871e-02
  1.13771204e-02  2.05522329e-01  3.44508410e-01  1.93495765e-01
  1.94540426e-01 -2.51970947e-01  1.21894926e-01  3.73683274e-01
  1.50177538e-01  2.92826205e-01 -3.74036014e-01  1.33562312e-01
 -7.19618350e-02 -4.18097764e-01  2.13543341e-01  4.19013113e-01
  1.54245319e-03  4.79298562e-01  4.77445006e-01 -2.07392827e-01
  1.65987015e-01 -3.32664102e-01  8.10106099e-02 -3.44514132e-01
  2.37583011e-01  4.42769498e-01  1.93315893e-01  6.62164509e-01
  1.99417159e-01  8.31224322e-02  6.80584982e-02 -3.92133296e-01
 -1.49247423e-01 -1.37535393e-01  5.27259886e-01  2.09141105e-01
  7.72783458e-02  5.74841946e-02 -1.67751163e-01  1.01936512e-01
 -5.88511527e-01  1.55922920e-01  3.37188721e-01  2.69648135e-01
  1.16093785e-01 -2.04683870e-01  4.10675518e-02 -2.02575460e-01
  1.35394961e-01 -3.85753065e-01 -1.02063999e-01 -2.09153350e-02
 -2.92321205e-01 -2.19719455e-01 -1.52037665e-01  4.12303001e-01
 -7.50223696e-02 -3.96274477e-01 -5.18438637e-01  3.42884243e-01
  4.80846941e-01 -4.44028974e-01 -9.23875123e-02  2.75998533e-01
 -2.94207633e-01  3.35146077e-02  2.90038794e-01  1.25295535e-01
 -1.05646998e-01  2.15129316e-01  4.62103337e-02  1.18323624e-01
  2.70192504e-01 -3.21837604e-01 -2.67866045e-01  1.61355540e-01
 -6.11167431e-01 -3.59757282e-02  5.44396192e-02  9.75240692e-02
  4.16306742e-02  2.18744692e-03 -3.81010294e-01  1.47666469e-01
  3.76308590e-01 -8.58278722e-02  1.05395354e-02 -2.12382093e-01
 -3.06839287e-01  7.88987204e-02  4.08663511e-01 -2.43067592e-01
 -9.80044156e-02  1.02388933e-01 -2.84200788e-01 -1.76606461e-01
 -7.62340426e-02  2.06916660e-01 -5.68726473e-03  3.61587942e-01
 -4.10524398e-01  6.22572362e-01  1.00162700e-01 -3.44722867e-01
 -4.24236834e-01  3.36572468e-01  4.17286634e-01 -2.28780687e-01
 -1.76544532e-01  5.69587231e-01 -1.05816014e-01  2.70939708e-01
  2.58012950e-01  4.73143011e-01 -1.35449499e-01  4.10340399e-01
 -1.64804250e-01 -2.56570905e-01 -1.80071741e-01  3.20275524e-03
 -2.68504590e-01 -2.20226839e-01  1.20729886e-01  9.80674773e-02
 -1.03129484e-01 -4.30162042e-01 -3.04259539e-01  6.64605126e-02]",SP8F58ZB,False,False,"[9.284546852111816, 0.22142596542835236]"
UQ2U6GFE,D9MCDRG2,"Observation-Level Interaction with Statistical Models for Visual Analytics 

Alex Endert+      Chao Han*      Dipayan Maiti *     Leanna House*      Scotland Leman*      Chris North+ 

+ Department of Computer Science  

* Department of Statistics 

Virginia Tech 

 

 

ABSTRACT 

specifically  designed  for  visualizations  of  this  purpose.  Thus, 
many  visual  analytic  systems  are  fundamentally  based  on 
interaction  with  statistical  models  and  algorithms,  using 
visualization as the medium for the communication (i.e. where the 
interaction occurs). This communication is performed via direct 
interaction  with  the  parameters  of  the  model.  For  example, 
Interactive  Principal  Component  Analysis,  iPCA [3],  allows  the 
user to change the weight for each dimension in calculating the 
direction  of  projection  using  multiple  sliders  (one  slider  per 
dimension). Also, in an interactive visualization using MDS [4], 
the  user  can  weight  the  dissimilarities  in  the  calculation  of  the 
stress function through similar visual controls.  
In both instances, the model is made aware of the user input 
through  a  formal  and  direct  modification  of  a  parameter  (i.e. 
parameter  level  interaction).  The  drawback  of  this  type  of 
interaction  is  that  users  are  expected  to  be  experts  in  the 
underlying  model  that  generates  the  visualization.  Moreover,  as 
datasets continue to increase in size and dimensionality, directly 
adjusting dimensions or parameters creates an issue of scalability. 
Both interactive MDS [4] and object-centered MDS [5] also allow 
interactions such as “anchoring” points to provide the algorithm 
with user specified starting positions, either to test the sensitivity 
of the current visualization or to obtain an alternate spatial layout 
based  on  the  anchored  observations.  In  both  cases,  the  visual 
analytic system does not leverage the observation level interaction 
to obtain information about the parameters of the model. 
In  this  paper,  we  reevaluate  interaction  with  such  models, 
moving  away  from  parameter  level  interactions,  and  propose  to 
focus on interacting with data (i.e. observation level interaction). 
In contrast to parameter level interactions, users are familiar and 
comfortable  interacting  directly  with  the  data  in  a  spatial 
visualization, freely organizing and relocating observations as an 
integral  part  of  their  sensemaking  process  [6].  Thus,  it  is 
necessary for us to design models that are more tightly integrated 
with interaction at the observation level, rather than through visual 
controls of parameters. 
Our  framework  shields  users  from  the  technicalities  of  the 
model  and  allows  them  to  interact  freely  with  the  data  in  the 
visual  space. The  typical  steps  in  a  discovery  process  based  on 
such a framework will be as follows: 1) the visual analytic system 
provides  a  visualization  based  on  initial  values  of  model 
parameters,  2)  users 
inject 
understanding  and  semantic  reasoning  of  the  data,  3)  under  a 
certain  predefined  mapping  of 
the  user's  observation-level 
interaction to analytic reasoning, the parameters of the model are 
tuned  or  re-weighted  to  reflect  the  user's  understanding  of  the 
data,  and  finally  4) 
the  system  regenerates  an  updated 
visualization  based  on  the  new  parameter  values  of  the  model. 
The  process  continues  iteratively,  as  does  sensemaking,  for  the 
duration of the analytic process.  
We  show  examples  that  such  a  framework  can  be  applied  to 
dimension  reduction  algorithms  for  visual  analysis  of  high-
dimensional data. Our framework of incorporating user interaction 
can be applied to either deterministic or probabilistic methods. We 
demonstrate  this  on:  PPCA  (a  probabilistic  projection-based 

interact  with  observations 

to 

is 

facilitated 

In  visual  analytics,  sensemaking 

through 
interactive  visual  exploration  of  data.  Throughout  this  dynamic 
process, users combine their domain knowledge with the dataset 
to  create  insight.  Therefore,  visual  analytic  tools  exist  that  aid 
sensemaking  by  providing  various  interaction  techniques  that 
focus  on  allowing  users  to  change  the  visual  representation 
through adjusting parameters of the underlying statistical model. 
However,  we  postulate  that  the  process  of  sensemaking  is  not 
focused on a series of parameter adjustments, but instead, a series 
of perceived connections and patterns within the data.  Thus, how 
can models for visual analytic tools be designed, so that users can 
express  their  reasoning  on  observations  (the  data),  instead  of 
directly  on  the  model  or  tunable  parameters?  Observation  level 
(and  thus  “observation”)  in  this  paper  refers  to  the  data  points 
within  a  visualization.  In  this  paper,  we  explore  two  possible 
observation-level interactions, namely exploratory and expressive, 
within  the  context  of  three  statistical  methods,  Probabilistic 
Principal Component Analysis (PPCA), Multidimensional Scaling 
(MDS),  and  Generative  Topographic  Mapping  (GTM).  We 
discuss  the  importance  of  these  two  types  of  observation  level 
interactions, in terms of how they occur within the sensemaking 
process.  Further,  we  present  use  cases  for  GTM,  MDS,  and 
PPCA,  illustrating  how  observation  level  interaction  can  be 
incorporated into visual analytic tools. 
 
KEYWORDS:  observation-level 
statistical models. 
 
INDEX TERMS: H.5.0 [Human-Computer Interaction] 
1 

interaction,  visual  analytics, 

INTRODUCTION 
Visual  analytics 

is  “the  science  of  analytical  reasoning 
facilitated by interactive visual interfaces” [1]. The goal of visual 
analytics  (VA)  is  to  extract  information,  perform  exploratory 
analyses,  and  validate  hypotheses 
interactive 
exploration  process  known  as  sensemaking 
this 
sensemaking loop, users proceed through a complex combination 
of proposing and evaluating hypotheses and schemas about their 
data, with the ultimate goal of gaining insight (i.e. “making sense 
of”  the  data).  A  wide  variety  of  statistical  models  have  been 

through  an 

[2]. 

In 

{aendert, chaohan, dipayanm, lhouse, leman, north}@vt.edu 
 Blacksburg, VA 24061 

model),  MDS  (a  deterministic  stress  minimization  model),  and 
GTM  (a  probabilistic  manifold  learning  model).  However,  the 
fundamental framework can be applied to numerous other models. 
Finally,  we  discuss  the  tradeoffs  between  these  models  for 
observation-level interaction. 
2 

RELATED WORK 

these  algorithms. 

The three methods in this paper were chosen either because of 
their  wide  usage  or  flexibility  in  modelling  non-linear  data.  A 
large and growing body of literature has shown their successful 
applications in visualization. For example, PCA has gained a lot 
of  success  in  the  area  of  image  classification,  with  applications 
such  as  face  recognition  [7-10].  MDS  has  been  used  in  graph 
layout for network visualization [11-13] due to its rich distance 
information.  GTM  is  good  at  visualizing  unstructured  data  like 
newsgroup  text  collections,  web  navigation  datasets  [14],  and 
datasets  which  have  complicated  structure,  for  instance,  protein 
sequences [15] and the standard Swiss-Roll dataset [16].   
Research  has  gone  into  creating  systems  that  allow  for 
interaction  with 
iPCA  [3]  allows  direct 
interaction with the parameters of PCA, through the use of visual 
controls.  In  adjusting  these  parameters,  users  can  observe  the 
corresponding change in the visualization. Buja et al. demonstrate 
an  interactive  version  of  MDS  in  which  users  can  define  static 
locations of a number of observations, and the algorithm positions 
the remaining observations into the layout [4]. We would consider 
this an example of an observation-level interaction, as users can 
“test” the location of specific observations, and see how the layout 
(and  thus  the  algorithm)  responds.  However,  the  interaction  is 
directly on pairwise dissimilarities, instead of updating of global 
dimension  weights  based  on  the  user’s  positioning  of  the 
observations. 
interactive  MDS 
algorithm  using  “object-centric  interaction”,  where  users  can 
explore  alternative  positions  of  observations  by  moving  them 
within  the  spatialization  [5].  This  is  similar  to  our  concept  of 
observation-level interaction, in that the interaction is occurring in 
the spatialization. However, the movement of an observation is to 
discover the proportional error contribution, and not to adjust the 
parameters  of  MDS.  Another  example  of  interacting  directly  in 
the spatialization is “Dust & Magnet”, an interactive visualization 
allowing users to understand large, multivariate datasets [17]. It is 
based on the metaphor of magnets, which can attract observations 
that share the attributes of the magnet. Thus, in placing multiple 
magnets into specific locations in the space, users can gain insight 
into  the  structure  of  the  data  through  seeing  how  observations 
respond to the attractors. Therefore, the interaction is performed 
on attractors (i.e., parameters), not on the observations. 
From  this  work,  we  learn  that  statistical  methods  are  widely 
used in visual analytics, and approaches to making these methods 
interactive  have  been  proposed.  However,  interactivity  in  these 
cases mainly refers to direct manipulation of model parameters. 
With observation-level interaction, we focus on interacting with 
the  observations  within  the  spatial  metaphor,  and  handle  the 
corresponding parameter updates through our methods. 
3 

Similarly,  Broekens  et  al.  describe  an 

OBSERVATION-LEVEL INTERACTION 

In  general,  observation-level  interaction  refers  to  interactions, 
occurring  within  a  spatialization,  that  enable  users  to  interact 
directly  with  data  points  (i.e.,  observations).  A  spatialization  in 
this  context  refers  to  a  two-dimensional  layout  calculated  from 
high-dimensional  data  where  the  metaphor  of  relative  spatial 
proximity represents similarity between documents. That is, data 
points placed closer together are more similar. Observation-level 

in 

interaction 

interaction  may  exhibit 

the  algorithm  computes  similarity.  Thus,  when 

interactions  are  therefore  tightly  coupled  with  the  underlying 
mathematical  models  creating  the  layout,  thus  allowing  the 
models to update parameters based on the interaction occurring. 
While  numerous  forms  of 
these 
characteristics  (e.g.,  moving  clusters  of  documents,  marking 
regions of interest within the spatialization, etc.), in this paper we 
will  focus  on  one  –  movement  of  observations.  From  previous 
studies, we found that movement of observations (in those cases 
documents) closer together is one way for the user to externalize 
the  analytical  reasoning  that  those  documents  are  somehow 
similar [6]. In this study, the spatial rearrangement of documents 
was  an  integral  part  of  each  intelligence  analysts’  sensemaking 
process.  Further,  this  study  points  out  that  users  perform 
observation-level 
two  ways,  exploratory  or 
expressive, based on the particular analytical reasoning associated 
with the interaction, and also how the system responds.  
During an exploratory interaction, users utilize the algorithm to 
explore the data and the space. For example, through dragging one 
observation within the layout, users gain insight into the structure 
of  the  data  by  observing  how  other  data  reacts  given  the 
algorithm. While an observation is dragged through the layout, the 
algorithm  adjusts  the  layout  of  the  remaining  data  according  to 
how 
the 
observation  is  dragged  towards  a  cluster  of  data,  similar  data 
points attract, while dissimilar ones repel. Additional information 
such  as  a  list  of  similar  and  dissimilar  parameters  can  also  be 
displayed.  Through  this  process,  users  learn  about  a  single 
observation,  and  how  it  relates  to  the  other  observations  in  the 
dataset.  
An expressive interaction is different, in that it allows users to 
“tell” the model that the criteria (i.e. the parameters, weights) used 
for  calculating  the  similarity  need  to  be  adjusted  globally.  For 
example,  as  a  user  reads  two  documents,  she  denotes  they  are 
similar by dragging them close together. If this were exploratory, 
the two documents would repel again. However, in an expressive 
form of this interaction, it is the responsibility of the underlying 
mathematical  model  to  calculate  and  determine  why  these 
documents  are  similar,  and  update  the  model  generating  the 
spatial layout accordingly. Using the methods below, we illustrate 
how both expressive and exploratory forms of observation-level 
interaction  are  enabled  through  modifications  made  to  three 
common statistical methods (PPCA, MDS, and GTM).  
4  METHODS INTEGRATING OBSERVATION-LEVEL INTERACTION 
A probabilistic model assumes a sampling distribution for the 
observed data and an uncertainty over the model parameters (e.g. 
PPCA and GTM discussed in Section 4.1 and 4.3 respectively). A 
deterministic method makes no such assumptions about the data 
or the parameters (e.g. Weighted MDS, discussed in Section 4.2). 
House  et  al.  describe  in  detail  the  underpinnings  of  the 
probabilistic framework, termed as “Bayesian Visual Analytics” 
(BaVA) [18]. The BaVA process begins with an initial display of 
the data. In turn the user may assess the display and decide if it 
matches her mental model of the data. If it does not, the user may 
convey  her  cognitive  feedback  f(c)  by  adjusting  the  locations  of 
two  observations  to  convey  her  mental  model  about  the  two 
observations.  The  user  might  also  explore  an  alternative  spatial 
location  of  an  observation  and  see  how  the  other  observation 
responds  to  such  an  interaction.  In  short,  iterations  of  user 
interaction  and  subsequent  regeneration  of  the  visualization  are 
modelled  as  sequential  updating  of  maximum  a  posteriori 
estimates  of  parameters.  The  deterministic  version  of 
the 
framework, termed as “Visual to Parametric Interaction” (V2PI), 
also  starts  with  an  initial  display  and  upon  obtaining  a  user 
feedback  sequentially  updates  the  parameters,  but  the  updated 

values  of  the  parameters  are  such  that  they  minimize  some 
measure of discrepancy between the expected configuration of the 
data under the user’s reasoning and the original data [19].  
For each of the models discussed in this paper, we present an 
overview of the model, describe the modifications made to allow 
observation-level interaction, and show a use case demonstrating 
how an end-user can interact with each model. Given that each of 
these models is designed for different types of data (varying  in 
structure,  size,  and  nature  of  the  data),  the  example  use  cases 
below each use different datasets to match the intended use of the 
models  with  the  use  case.  The  use  cases  are  performed  in 
prototype visualizations to show a proof of concept, and we are 
actively  working  to  incorporate  these  models  into  more  fully 
featured tools.  
PPCA 
4.1 

4.1.1  Overview 

Principal  Component  Analysis  (PCA)  [20-22]  is  a  common, 
deterministic  method  used  to  summarize  data  in  a  reduced 
dimensional  form.  The  summary  is  a  projection  of  a  high-
dimensional  dataset  in  the  directions  with  the  largest  variance. 
When only two directions are chosen, PCA may produce a spatial 
representation or map of the data that is easy to visualize. One 
problem with PCA is that important structures (e.g., clusters) in 
data may not correlate with variance. Thus, PCA spatializations 
may mask information in the data that analysts may find useful.    
Probabilistic PCA [23] is, simply, a probabilistic form of PCA. 
This  means  that  PPCA  is  not  a  deterministic  algorithm,  but  a 
statistical  modeling  approach  (specifically,  a  factor  modeling 
approach) that estimates low-dimensional representations of high-
dimensional  data.  Let  d=[d1,…,dn]  represents  a  p×n  high-
dimensional  data  matrix,  where  n  represents  the  number  of 
observations, p represents the number of columns, and di (for i∈ 
{1,…,n})  represents  a  p×1  vector  for  observation  i.  Also,  let 
r=[r1,…,rn] represent a low-dimensional analogy of d, such that r 
is q×n and q<p.  For our purposes, we set q=2.  PPCA models d as 
a function of r,  

d W r
,
i
i

,

,
µσ

2

=

 
No Wr
i

(

I
µ σ
+
p

,

 

2

)

  
where, No(.,.) represents the Multivariate Normal Distribution; µ 
represents  a  p×1  mean-vector  of  d;  W  is  a  p×q  transformation 
matrix  known  as  the  factor  loadings  of  d;  Ip  is  a  p×p  identity 
matrix; and σ2 represents the variance of each dimension in d.  By 
convention,  PPCA  models  each  ri  with  a  Multivariate  Normal 
distribution centered at zero and with unit variance: ri~No(02, I2).  
In  turn,  the  conditional  posterior  distribution  for  ri  is  No(η,Σr), 
where 
 

η
=

2

W W I
W d
(
)
1
(
σµ−
ʹ′
+
−
2
r W W
Iσ
2
2
−
ʹ′
Σ=
σ
+
2

ʹ′

i

(

−

) 1

)
                               (1) 

 
A spatialization of data d that relies on PPCA plots the posterior 
expectation  η.  Similar  to  PCA,  the  coordinates  η  rely  on  the 
variability observed in d. To see this, let Σd represent the marginal 
variance of di, (Σd=V[di |W,µ,σ2]). Since Σd=W´W+I2σ2, we can 
-1W(di  -µ)  which  shows  that  the  relationship 
rewrite  η  as  η=Σd
between Σd and η is well defined.   
The  final  step  in  PPCA  is  to  estimate  the  model  parameters, 
{W, µ, σ2, Σd}. We take a Bayesian approach. We specify either 

 

 

 

reference or flat priors for each unknown (as suggested by [23] 
and use Maximum A Posteriori (MAP) estimators to assess (and 
plot)  η.  For  example,  when  we  assign  π(Σd)  ∝1,  the  posterior 
distribution for Σd  is an Inverse Wishart (IW) distribution,  

d

d

,

,

)

d

∝

1)

IW(

(
π Σ

nS p n p

− −                             (2) 
 
Where  Sd  represents  the  empirical  variance  of  d.  The  MAP 
estimate of Σd is Sd.   
4.1.2 

User Guided PPCA 

To enable analysts to guide PPCA via the data visualization, we 
take  advantage  of  the  relationship  between  Σd  and  η.  Namely, 
changes in Σd will effect η, and changes in η will effect Σd, when 
we invert Equation (1).   
After  obtaining  an  initial  PPCA  display,  the  user  adjusts  the 
locations of two observations; i.e., adjusts two columns in η. If 
the two observations are moved close to one another, the analyst 
is conveying that in her mental map, the observations are more 
similar  than  what  they  appear  in  the  display;  and,  if  the 
observations are dragged apart, the analyst is conveying that the 
observations differ more than what they appear.    
The  challenge  in  BaVA  is  to  parameterize  the  cognitive 
feedback  and  update  the  visualization  [18].  First,  we  determine 
the dimensions of the data d for which the adjusted observations 
are similar and different. Second, we transform the adjustments to 
η into a hypothetical p×p variance matrix. We denote this matrix 
by f(p), as it is a quantified version of f(c). In f(p), the dimensions for 
which the adjusted observations are similar have small variances 
and  the  dimensions  for  which  adjusted  observations  differ  have 
large variances. Third, we consider the hypothetical variance f(p) to 
be a realization of a Wishart distribution that has an expectation 
equal to Σd. Finally, we apply Bayesian sequential updating [24, 
25] to adjust Equation (2) by the parametric feedback f(p),  
 

(

π Σ=
d

d f
,

(

p

)

)

IW(
+

pS
− −
d

vf
+

(

p

)

,

p n v p
,

 

1)

where, υ is solved from a specification κ(κ ∈ [0,1]) made by the 
analyst  that  states  how  much  weight  to  place  on  the  feedback 
relative to the data. Namely, the updated MAP estimate for Σd is a 
weighted average of the empirical variance Sd and feedback f(p) 
 

MAP

(

)
Σ=
d

f

)

p
(
+

v
v n
+
 

 

S

d

n
v n
+

thus υ= nκ/(1-κ). Now, the PPCA projection of the data d that is 
based on MAP(Σd) will portray both information in the data and 
expert feedback. 
4.1.3 

Example 

A sensitive issue for taxpayers, parents, children, educators, and 
policy  makers  is  whether  an  increase  in  money  devoted  to 
education  will  increase  education  quality.  Money  provides  a 
means  to  buy  modern  textbooks,  employ  experienced  teachers, 
and provide a variety of classes and/or extra curricular activities. 
Although,  do  the  students  who  benefit  from  these  high-priced 
resources actually improve academically? 
In 1999, Dr. Deborah Guber compiled a dataset for pedagogical 
purposes  to  address  this  question  [26].  Based  on  the  following 
variables, 
the  academic  success, 
educational expenses, and other related variables in 1997 for each 
U.S. state: the average exam score on the Standard Aptitude Test 

the  dataset  summarizes 

from 

the  National  Center 

(SAT);  the  average  expenditure  per  pupil  (EXP);  the  average 
number of faculty per pupil (FAC); the average salary for teachers 
(SAL); and the percentage of students taking the SAT (PER). To 
increase  the  complexity  of  the  dataset  slightly,  we  added  two 
variables 
for  Education 
Statistics(www.http:nces.ed.gov):  the  number  of  high  school 
graduates  (HSG)  and  the  average  household  income  (INC). We 
hypothesize that states that spend more on education will cluster 
with states with high SAT averages.   
To assess the hypothesis and explore the data, we implement 
the  BaVA  process  using  PPCA.  Figure  1a),  displays  our  initial 
view of the data. Notice that the visualization does not present any 
structure in the data.  Analysts in the field of education, notice that 
two  states  with  different  expectations  for  SAT  scores  are 
displayed  close  to  one  another.  Thus,  we  select  the  appropriate 
observations and drag them apart as an expressive interaction to 
obtain an updated view that is displayed in Figure 1b). There are 
two clusters in 1b). These clusters correspond with SAT scores 
above and below the national median.  
Based  on  our  hypothesis,  we  suspect  that  the  clustering 
structure in SAT relates to EXP. However, when we re-plot 1b) 
and label the upper and lower EXP 50% quantiles in Figure 1c), 
EXP  does  not  explain  the  clusters.  Thus,  we  used  a  bi-plot  to 
identify  which  variables  explain  the  structure  we  see  in  Figure 
1b).  When  we  mark  the  observations  above  and  below  the 
empirical PER median in Figure 1d), we see that PER and SAT 
clearly  relate  to  the  formation  of  clusters  in  the  dataset.  Thus, 

(a)  Initial                            (b) SAT Scores 

 

 

              (c) EXP                                  (d) PER      

 
Figure  1.  After  injecting  expert  feedback  into  Figure  1a),  we 
obtain  Figures  b)-c).  For  frame  of  reference,  we  marked  the 
two  points  moved  to  inject  feedback  by  `x'  in  Figure  b).  The 
configuration  of  points  in  each  graph  are  identical,  but  the 
observations  are  labeled  differently.  In  Figure  b),  symbols  `●’ 
and  `○’  mark  the  upper  and  lower  50%  quantiles  for  SAT 
scores respectively; in Figure c), symbols `●’ and `○’ mark the 
upper  and  lower  50%  quantiles  for  EXP  scores  respectively; 
and in Figure d), symbols `●’ and `○’ mark the upper and lower 
50%  quantiles  for  the  percentage  of  students  taking  the  SAT 
the  clusters 
(PER) 
in  each  graph 
correspond with SAT and PER, but not EXP. 

respectively.  Notice 

further analyses of SAT and EXP must control for PER.   

 

4.2  MDS 

We  extend  our  framework  to  another  deterministic  method, 
which  forms  the  basis  for  a  large  number  of  visualization 
techniques: Multi-Dimensional Scaling (MDS).  
4.2.1  Overview 

All complex data visualizations are based on high-dimensional 
datasets, which contain features corresponding to dimensions, and 
the relative importance of such features through a set of weights 
(wi).  Classically  weighted  multidimensional  scaling  deals  with 
mapping  a  high  dimensional  dataset  d=[d1,…,dn]  into  a  low 
dimensional (in our case two-dimensional) space r, by preserving 
pairwise distances between observations in the low dimensional 
representation.  Let  w  represent  the  p-vector  of  feature  weights:  
w={w1,…,wp}. Given a set of feature weights, the low dimensional 
spatial coordinates are found by solving:  

 

where 

min
r
r i
,...,
1

n

, 

r
i

−

r δ
w
(
i j
j
,

−

)

∑

j n

<≤

)

w
(
δ
i j
,

w
k

dist(

d

ik

d

)

jk

 

p

=−∑

k

1
=

such  that  ∑k  wk=1.  dist()  represents  any  distance  function  for 
measuring  individual  features  in  the  high  dimensional  space. 
Because  it  is  not  possible  to  estimate  weights  and  the  set  r 
simultaneously,  we  provide  a  uniform  weighting  of  the  space 
wi=1/p for our first iteration. 
User Guided MDS 
4.2.2 

the  display  and 

learn  from  certain  aspects  of 

Once  a  visualization  is  generated,  the  user  may  either  agree 
with 
the 
visualization, or disagree, based on their domain expertise. Hence, 
the  user  may  wish  to  interact  and  rearrange  a  few  of  the 
observations in the visualization. Given a spatial interaction in the 
form  of  adjusting  the  relative  position  of  a  set  of  points,  we 
compute a set of feature weights, which are consistent with both, 
the  users  adjustment  and  the  underlying  mathematical  model. 
These are computed by inverting the optimization, by fixing the 
locations  of  the  adjusted  points  and  finding  an  optimal  set  of 
weights,  which  are  consistent  with  the  visualization.  Explicitly, 
we solve for w such that  

Figure  2.  Visualization  of  the  1990  census  dataset  using 
classical MDS. 
 
 

 

%  

r
( )
δ
−
i j
,

w
k

dist

d

(

i k
( )

−

r
j k
( )

)

min
w
w i
,...,
1

p

j

p

∑ ∑

l k
<≤ =

1

 
and  ∑k  wk=1,  where  d(i)k  represents  the  kth  element  in  the 
observation of d that maps to ri in the adjusted visualization and l 
is  the  total  number  of  manipulated  observations.  It  should  be 
noted  that  computing  the  new  weights  is  extremely  fast,  and  is 
then followed by a full MDS step. Thus, the entire generation of a 
new view can be performed in real time, depending on the size of 
the dataset and the specific hardware used. 
4.2.3 

Example 

inconsistencies  with 

their  mental  model 

Consider  for  example  a  visualization  produced  by  a  standard 
MDS  technique.  In  this  example  we  focus  on  the  1990  census 
dataset [27] under a Classical Metric Scaling (CMS) [28], using a 
Hamming distance (due to the categorical nature of the dataset) 
for  measuring  features  in  the  high  dimensional  space.  Figure  2 
illustrates  results  obtained  under  a  Classical  Metric  Scaling 
(CMS).  
Given  this  visualization,  a  user  may  distinguish  3-5  main 
clusters, and inquire what they mean. We see two major ways a 
user  can  interact  with  the  visualization,  in  order  to  explore  the 
space, and learn about the underlying dataset. The first of these is 
by highlighting a subset of the data, based on some question the 
user seeks to answer, and then rearranging the visualization based 
on 
(expressive 
interactions). 
The second approach is to hone in on visual structure, and move 
points  in  the  visual  space  in  order  to  learn  what  the  structure 
relates to in terms of the feature space (exploratory interactions). 
Both  of  these  interactions  are  nearly  identical,  however  the 
motivation for the interactions will differ. We will illustrate both 
types of visual reasoning through an example based on the 1990 
census dataset. 
The user may wish to interact expressively and identify points 
in the space that pertain to high and low income groups. The user 
highlights individuals with incomes below 15K and over 60K, as 
shown  by 
  in  leftmost  panel  of  Figure  3,  respectively. 
Because of the close proximity of the highlighted groups in the 
main clusters, the user drags (denoted by ⊗) a few representative 
low and high-income individuals into sets of groups in each of the 
3  main  sub-clusters.  The  system  reports  back  a  set  of  weights, 
which  explain  how  much  a  particular  feature  explains  the 
arrangement of points suggested by the user. High weights relate 
to 
their 

low  weights  suggest 

features,  while 

important 

and 

 

Figure 4. A user performing an exploratory interaction to learn 

to 

this 

information, 

the  system  updates 

    what distinguishes two clusters. 
corresponding  features  do  not  relate 
the  user's  visual 
rearrangement. For our example, we learn not only that income 
level  (29%),  but  also  by  their  means  of  transportation  to  work 
(20%), whether or not they worked the full year (25%), and their 
level of education (10%) are related to the user's repositioning of 
points.  Given 
the 
visualization, as shown in center panel of Figure 3. We notice that 
in  the  resulting  visualization,  the  income  groups  are  clearly 
separated.  The  resulting  visualization  displays  a  much  richer 
spatialization than simply showing clusters relating to the income 
groups.  For  example,  we  highlight  individuals  that  actually 
worked  in  the  right  most  panel  of  Figure  3,  and  notice  these 
individuals are shown in distinct sub-clusters. 2 of the 4 clusters in 
which  individuals  work  pertain  to  low-income  groups,  and  the 
other 2 pertain to high-income groups (as illustrated by the 
 and 
 symbols).  
Figure  4  shows  how  the  user  might  perform  an  exploratory 
interaction in order to learn what explains the clustering structure 
between the working/low income groups. To suggest the clusters 
could be moved further away from each other than they appear in 
the  current  visualization,  the  system  reports  back  the  weights, 
which explains the differences in the groups. For this example, the 
user learns that one of these clusters contains individuals that have 
a reliable mode of transportation to work (93% explained). The 
visualization could be updated based on this information, or the 
user could simply document this fact and proceed by explaining 
other areas of the spatialization. As always, there are an endless 

 
Figure 3. A sequence of visualizations derived through observation-level interaction with a modified MDS method. (Left) The user moves a 
set of points into new locations, communicating his intuition that there may be additional structure within each cluster. (Middle) The updated 
visualization showing new clusters. (Right) Highlighting showing the separation of income groups in the updated visualization. 
 

 

 

number  of  possibilities  for  learning  about  a  high  dimensional 
dataset via visual expression/exploration. Another example of an 
exploratory interaction with MDS is demonstrated by Buja et al. 
in  which  users  can  constrain  observations  to  specific  spatial 
locations [4]. 
GTM 
4.3 

4.3.1  Overview 

Introduced  by  Bishop  et  al,  [29]  Generative  Topographic 
Mapping (GTM) is a nonlinear latent variable modeling approach 
for  high-dimensional  data  clustering  and  visualization.  It  is 
considered  to  be  a  probabilistic  alternative  for  both  the  Self-
Organizing  Map  (SOM)  algorithm  [30]  and  Nonlinear  PCA. 
Similar  to  PPCA,  GTM  estimates  a  latent  variable  r=[r1,…,rn] 
(q×n  matrix)  that  is  a  low-dimensional  representation  of  high-
dimensional  data  d=[d1,…,dn]  (p×n  matrix  such  that  p>q). 
However, unlike PPCA, the q-dimensional coordinates r in GTM 
map  nonlinearly  to  a  complex  manifold  m=[m1,…,mn]  that  is 
embedded in the high-dimensional space.  This manifold, ideally, 
in  data  d  and  represents 
characterizes 
geometrically the expected value for d in the Gaussian model,   
                               (3) 

important  structure 

    

d N W r
( ),
i
i

Φ

(

I β−
1
p

)

:

 

j

2

)

=Φ

    

exp(

r
( )
Φ=−
i

µ
−
j
2
2
σ

m W r
( )
i
i
r
i

To estimate a coordinate mi, GTM takes a weighted average of J 
radial  basis  functions  {Φ1(),…,ΦJ()}  (Φj()  represents  a  radially 
symmetric Gaussian kernel) given ri and parameters there in,  
 

,                                      (4) 
,                            (5) 
 
where  W  is  a  p×J  transformation  matrix;  Φ(ri)  is  a  J×1  vector 
such that Φ(ri)=[Φ1(ri),Φ2(ri)…,ΦJ(ri)]ʹ′; and µj is a q×1vector that 
centers  the  basis  functions.  The  center  coordinates  µ=[µ1,…,µJ] 
cover the q-dimensional latent space uniformly. Model parameters 
are estimated using the EM algorithm [31]. 
One  advantage  of  GTM  is  that,  by  construction,  it  lacks 
sensitivity to outliers.  For tractability, the coordinates of each ri 
are  limited  a  priori  to  a  finite  set  g  of  K  possibilities,  ri 
∈g={g1,…,gK} 
latent  space 
uniformly.    To  decide  which  value  for  ri  generates  di,  GTM 
estimates the posterior probability, i.e., responsibility, that ri=gk. 
Given a prior probability that ri=gk is 1/K for all k ∈{1,…,K}, let 
Rik  represent  the  posterior  responsibility  that  latent  variable  ri 
generates di, when ri=gk, 
 

the  q-dimensional 

that  covers 

 ,                            (6) 

R
ik

=

d r
(
π
=Φ
i
i
K
d r
(
∑
π=
i
i
l
1

g W
,
,
k
g W
,
=Φ
l

())
,

())

 
In  turn,  GTM  plots  the  posterior  mode,  expectation,  or  any 
quantile of ri given specifications g and estimates for {Ri1,…RiK}.    
4.3.2 

User Guided GTM 

GTM  is  a  complex  modeling  approach  that  relies  on  many 
tunable parameters that are hard to interpret. User Guided GTM 
(ugGTM)  will  allow  analysts  to  both  take  advantage  of  the 
benefits  of  GTM 
complicated  GTM 
parameterization.  Specifically,  analysts  may 
tag 
clusters,  tag  regions  of  the  visualization  space,  and  query 
differences in documents.  

and  guide 

label,  i.e., 

the 

Here, we illustrate ugGTM within the context of an example. 
We have a collection of 54 abstracts from proposals funded by the 
National Institute for Health (NIH). After standard preprocessing, 
we apply a ranking system that we will call an Importance Index 
(ImpI),  which  is  based  on  the  Gini  coefficient.  ImpI  considers 
both the frequency and uniqueness of words that are shared across 
documents and assigns a metric between 0 and 1.  Entities that 
occur  equally  frequently  in  all  the  documents  have  ImpI=0  and 
entities that occur in only one document has ImpI=1.  We selected 
the 1000 entities with the highest ImpI. One advantage of ImpI is 
that we can measure document similarity using Euclidean distance 
between  proposals.  Pairs  of  documents  with  small  Euclidean 
distances have comparable terms with similar frequency; and pairs 
of  documents  with  large  Euclidean  distances  have  few,  if  any, 
words in common. 
We apply GTM for J=16 and K=400 to obtain an initial display 
of the proposals, shown in Figure 5. Notice four clusters appear in 
Figure 5 that we labeled A, B, C, and D.   
Tagging  the  Clusters  and  the  Space.  To  understand  the 
meaning of the clusters, we determine the words that both overlap 
the  least  within  each  cluster  and  have  the  highest  ImpI’s.  
Specifically, we apply k-means [32] to the low-dimensional data 
coordinates to determine cluster memberships.  For each cluster 
we  sum  the  ImpI  vectors  across  the  documents  and  rank  the 
entities based on the ImpI sum. Entities ranked highest are those 
that 1) have importance in the corpus (as determined by the ImpI) 
and 2) have occurred most frequently.  Given top rankings from 
each cluster, we delete those shared by all four clusters. Table 1 
lists  the  unique  key  words  that  describe  each  cluster.  Group  A 
represents proposals that include brain related cancer studies and 
their clinical applications. Group B represents proposals related to 
human neural systems. Group C represents proposals that address 
genomic  and  transcriptomic  research  problems. 
  Group  D 
represents  proposals  about 
such  as 
infectious  diseases, 
tuberculosis, and immunity.  

 
Table 1. Cluster tags (top 10 keywords) for NIH abstract groups. 
 

    
As  described  previously  in  Equation  (3),  GTM  characterizes 
high-dimensional  data  as  random  perturbations  from  a  complex 
manifold m; E[di] = mi for all i ∈ [1,…,n]. To tag the visualization 
space, we select any spot, r+, in the visualization and use Equation 
(4) to estimate its corresponding location on the manifold, m+. The 
estimate m+ will be a 1000×1 vector of ImpI’s that we may use to 
rank  the  entities.  We  report  the  top  ranked  entities  to  tag  the 
space. For example, in Figure 5, we pick up a spot r+ (represented 

Group A 

Group B 

Group C 

Group D 

Shared by All 

Groups 

tumors, brains, stem, treatments, patients, 
generations, drugs, ordering, controlling, 
therapeutics 
stem, neuronal, brains, proteins, deliveries, 
regulations, neural, patients, differentiation, 
expression, treatments 
stem, genetically, regulations, drugs, 
structurally, proteins, genomics, epigenetics, 
RNAs, complexities 
Infections, treatments, tuberculosis, 
expression, patients, drugs, strains, 
resistance, vaccination, immunity 
cells, functionalization, diseases, 
developments, genes, cancerous , studying, 
researchers, proposing, mechanisms, 
specification 

by a pink circle) that locates roughly at the center of cluster D.  
Several  of  the  tagged  top  keywords  overlap  with  the  words 
describing cluster D. 
    
Document-Based  Query  and  Cluster  Reorganization.  It  is 
common for users to assess documents by searching for keywords. 
However,  keyword  searching  may  be  a  tedious  task  and  fail  to 
reveal  document  clusters  of  interest.  For  example,  keyword 
searches may identify documents with similar keywords, but used 
in different contexts; miss documents that contain combinations of 
the  keywords;  or  prioritize  words  that  have  little  relative 
importance for the user.  In response to the challenges of keyword 
searching,  many  analysts  rely  on  document  matching.  For 
document  matching,  entire  documents  can  be  used  to  identify 
which of the remaining documents in the corpus are most similar 
(to the chosen document). Hence such a matching algorithm is a 
document-based query of a corpus. 
In our ugGTM, users may query documents in the corpus by 
dragging a document of interest directly in the visualization and 
watching  how  the  remaining  documents  respond;  e.g.,  similar 
documents will follow the document being dragged and dissimilar 
documents will repel. The behaviour of the documents is similar 
in spirit to Dust and Magnets (DnM) [17]. In DnM, analysts may 
drag or shake magnets that represent variables in the dataset and 
watch  as  relevant  documents  follow  the  magnets.  However,  a 
major  difference  between  DnM  and  ugGTM  is  that  when  users 
drag  documents  (not  variables)  and  watch  how  the  remaining 
react, they are comparing documents based on all of the variables 
in  the  dataset  simultaneously.  In  turn,  users  may  learn  which 
variables are important for comparisons, based on tags within the 
visualization space. 
The interaction is possible because ugGTM gives control to the 
users of some parameters in the model via the visualization.  Let 
r* represent the low-dimensional coordinates for a document that 
an  analyst  has  chosen  to  drag.  Given  r*,  we  add  to  the  model 
described in Equations (3)-(6) by expanding sets g and Φ so that 
g={g1,…,  gK,  g*}  and  Φ={Φ1,…,ΦJ,Φ*},  where  Φ*  =  exp{-||ri-
µ*||2/2σ2}  and  g*=µ*=r*.  In 
the  posterior 
responsibility (Equation 6) that r* generates d* via m* to 1 (where, 
m* is defined by Equation (4) so that the mapping between the 
low-  and  high-  dimensional  coordinates 
the  moving 
observations is deterministic. 
To  propagate  the  effect  of  moving  r*  to  the  remaining 
visualization,  we  take  a  local  regression  approach  [33]  to 
characterize high-dimensional data di |{ ri=g*,m*} in that we scale 
di-m* by the square-root of function V given scaled distance Δi = 
||d*-di||/c so that,  

turn,  we  assign 

for 

(
π

d r
=Φ=
i
i

g W
*

,

,
−

)

⎛
⎜
⎝

β
2
π

⎞
⎟
⎠

exp{

V
β

)

i

(
Δ
2

d m
i

*

 
}

2

p
/2
−
−
 

 

 

2 and c=0.5. In turn, both 
where c is user-defined; e.g., V(Δi)=Δi
posterior responsibility estimates (Equation 6) and estimates for m 
(Equation 4) change.  Let mi
(c) and mi
(u) represent the current and 
user-adjusted manifold estimates for observation i.  We define the 
BaVA-GTM estimate for the manifold, mi
 

(c+1), by 

 

m
(
i

c

1)
+ =

δ
i

m
c
( )
+−
i

(1

δ
i

)

m
u
( )
i

, 

where δi=||ri-r*||/b and b=max{||r1-r*||,…,||rn-r*||} so that δi∈ [0,1].  
(c+1) controls the visualization so that only the 
This definition for mi

regions  of  interest  respond  to  user  interactions;  areas  that  are 
distant from the dragged observations do not change.   
Parameters g*, Φ*, V(Δi), δ  and m(c+1) in ugGTM work together 
in the following way. When a data point di is far from d*, V(Δi) 
will  be  large  and  thus  decrease  the  posterior    responsibility 
(Equation 6) that ri=g* generates di. Similarly, when di is near d*, 
the  corresponding  responsibility  will  increase.  Increases  in  the 
responsibility  for  ri=g*  will  cause  the  coordinates  for  ri  to 
gravitate toward r*. Thus, analysts may specify constant c in our 
definition Δi, depending upon how many document matches they 
seek  for  the  moving  document.  Also,  the  degree  to  which  the 
observations  gravitate  toward  r*  is  determined  by  δ  and  m(c+1). 
When the manifold shifts from m(c) to m(c+1), the meaning of the 
visualization space changes, as we demonstrate in our example.  
4.3.3 

Example 

For our NIH example, we apply ugGTM. We display an initial 
GTM view of the documents (the 54×1000 dataset) in Figure 5. 
Suppose a user identifies a specific document of interest, e.g., Doc 
7 (highlighted in yellow in Figure 5) to investigate. A preliminary 
investigation might involve a sequence of non-spatial interactions, 
such as, searching of multiple keywords, reading all or part of the 
document  etc.  However,  a  comprehensive  assessment  of  the 
document may require spatial interactions as well. The user might 
explore  space  tags  across  the  screen  and  determine  a  more 
appropriate location for the document of interest. In this case, Doc 
7 is closer to Group A, and is about developing new brain tumor 
therapies  and  tumor  stem  cell  quiescence.  The  keywords  this 
document shares with group A include tumors, brains, cancerous, 
therapeutics and chemotherapy. However, since Doc 7 relates to 
therapy developments for disease, it shares some keywords with 
Group  D;  e.g.,  treatments,  strategies,  patients,  drugs,  resistance, 
clinically.   
As an exploratory spatial interaction, the user drags Doc 7 to 
the  lower  left  corner  of  the  display  and  watches  how  the 
remaining  documents  react.  By  repositioning  Doc  7,  the  user 
redefines the spatialization of the screen, i.e., modifies the space 
tag  corresponding  to  a  location.  For  example,  when  we  tag  the 
same  coordinates  r+  in  Figure  6  (r+  are  the  coordinates  of  the 
space tagged in Figure 5), we learn that the top keywords include 
treatments  and  tumors  as  well  as  those  that  were  there  earlier. 
Recall that ugGTM uses every variable in the dataset to compare 
documents.  For  this  reason,  documents  that  mention  stem  cells 
and  other  important  keywords  in  Doc  7  follow  Doc  7.  As 
expected, many documents in Group D gravitate toward Doc 7. 
However,  a  few  documents  in  Group  B  also  followed.  Future 
work will allow users to weight the keywords in Doc 7, if desired. 
Also  Documents  with  ID  20,  22,  32  and  39  change  locations. 
Important  keywords  for  these  documents  include  the  following: 
Doc 20 discusses diagnosis of HIV infection in patients who live 
with  limited  access  to  therapeutic  treatments;  Doc  22  discusses 
expression characteristics of a drug-resistant gene; Docs 32 relates 
to  varying  yeast  strains;  and  Doc  39  relates  to  Lymphocyte 
Homing.  Docs  20  and  22  repelled  against  Doc  7  because  the 
redefined-manifold down-weighted their important entities in the 
lower left corner and up-weighted the entity tumor. Thus, Doc 20 
and Doc 22 shifted to Groups A and C respectively. Docs 32 and 
39  are  separated  slightly  from  Group  D  and  gravitated  toward 
Group C because they have a few words in common with each 
group, but not enough to place them in either corner. 
An interesting note about the updated manifold is the change in 
shape or magnification factor [34]. The colour in the background 
is  plotted  based  on  the  logarithm  of  the  magnification  factor 

Figure  5.  GTM  display  of  the  NIH  abstracts.  Black  dots  mark 
documents and labeled by their document ID. 
 
evaluated on a fine grid that covers the visualization space. Due to 
the  nonlinear  mapping  from  ri  to  mi,  equal  distances  in  the 
visualization do not necessarily imply equal distances in the high-
dimensional space. The magnification factor describes the rate of 
change  between  distance  or  area  in  the  latent  space  and  the 
corresponding  distance  or  area  on  the  manifold  and  can  be 
interpreted  as  a  description  of  how  wiggly  the  manifold  is. 
Overall,  the  magnification  factor  is  lower  in  Figure  6  than  in 
Figure 5 and the clusters formed in Figure 6 are mainly in low 
magnification  areas.  This  means  the  clusters  in  Figure  6  are  in 
flat, stable regions of the estimated manifold. Thus, observations 
in these clusters are closer to one another than observations shown 
in clusters within Figure 5. 
5 

DISCUSSION 

We present a comparison of key characteristics of the methods 
used in this paper in Table 2. Again, the purpose of this work is 
not to make a direct comparison of these three methods, but rather 
to  present  how  to  apply  observation-level  interaction  to  each 
method, and summarise our findings in the table.  
Mappings. The three methods discussed in the paper provide 
us  with  a  spatialization  of  the  data  within  the  bounds  of  their 

 

 

 

Figure 6. The updated view after moving doc 7 from top left to 
bottom left. 
algorithmic  complexity.  Points  that  are  close  in  the  higher 
dimensional space remain close to each other in the visualization 
in  all  the  algorithms  although  the  concept  of  proximity  varies 
depending on the algorithm. As an artifact of the algorithms, in 
both PPCA and MDS, the high dimensional data is assumed to be 
a linear mapping of the visualized representation while GTM is a 
non-linear mapping of the same. Hence, the same dataset might 
provide  widely  disparate  visualizations  for  different  algorithms. 
Spatially  this  might  translate  to  the  fact  that  based  on  the 
algorithm, the user’s spatial interaction might target different sets 
of observations. Each algorithm can potentially have its own set 
of diagnostics overlaid with the visualization that might aid the 
user  in  understanding  the  proximity  of  the  data  in  the  higher 
dimensions;  e.g.  visualizing  the  magnification  factor  along  with 
the data in GTM indicates the level of distortion. The goal of the 
user is to obtain a view in multiple steps that matches with his 
mental model irrespective of the algorithm used to visualize the 
data.  The  specific  steps  that  the  user  goes  through  should  be 
immaterial in so far as the final visualization is concerned and all 
the algorithms discussed here have the flexibility to provide that.  
PPCA relies on the assumption that a single linear projection 
exists  that  can  reveal  useful  structure.  MDS  provides  a  two- 
dimensional representation of the observations via penalization of 
any  distance  distortion  that  happens  in  the  two-dimensional 

Table 2. Comparison of the methods used in this paper.  

  
Mapping Type 
Method Characterisation  
Distribution Assumption 
Scalability (Observations) 
Scalability (Dimensions) 
Conceptual Clarity 
Running Time 
Outlier Robustness 

PPCA 
Linear 
Variance 
Probabilistic 

(cid:174)(cid:174)(cid:174)(cid:1)

(cid:174)(cid:1)

(cid:174)(cid:174)(cid:174)(cid:1)

(cid:174)(cid:174)(cid:1)

(cid:174)(cid:174)(cid:1)

(cid:174)(cid:174)(cid:174) = Good(cid:1) (cid:174)(cid:174) = Average(cid:1)

MDS 
Linear 
Similarity 
Deterministic 

(cid:174)(cid:1)

(cid:174)(cid:174)(cid:174)(cid:1)

(cid:174)(cid:174)(cid:174)(cid:1)

(cid:174)(cid:174)(cid:174)(cid:1)

(cid:174)(cid:174)(cid:1)

(cid:174) = Poor 

GTM 

Non-linear 
Manifold 
Probabilistic 

(cid:174)(cid:1)

(cid:174)(cid:174)(cid:1)

(cid:174)(cid:1)

(cid:174)(cid:1)

(cid:174)(cid:174)(cid:174)(cid:1)

representation  using  a  stress  function.  However,  the  linear 
projection assumption may not hold for complex datasets or, the 
visualization based on minimizing stress in MDS might not reveal 
all the information in the data. In PPCA, using variance to select 
the  direction  in  which  to  project  data  makes  sense  for  datasets 
with a global linear structure [23]; the projection will minimize 
the number of observations that overlap so that they are as visible 
as possible.  
However,  variance  estimates  and  hence  PPCA  visualizations 
are  sensitive  to  outliers  and  it  is  not  uncommon  for  PPCA  to 
display one or two outliers and a cloud of occluded points. Under 
Euclidean  distance,  MDS  is  algorithmically  the  same  as  PPCA 
and  will  suffer  from  the  same  sensitivity  to  outliers.  Assessing 
such  a  visualization  and  making  appropriate  adjustments  would 
be,  at  best,  challenging.  Thus,  a  more  complex  methodology  is 
often needed to summarize datasets, e.g., mixture PPCA or GTM. 
GTM being a topographic mapping places the outliers at one end 
of the screen or at a position that is distant from the region that 
has more structure. In our interactive framework, outliers can be 
brought closer to existing user defined clusters through redefining 
the principal components in PPCA, reweighting of the dimensions 
in MDS and constraining responsibilities in GTM; in all the cases 
the  user’s  observation-level  interaction  initiates  the  parameter 
update. 
Scalability. In terms of time complexity, GTM is O(KND) (K 
number  of  latent  points,  N  number  of  observations,  D  data 
dimensionality),  PPCA  is  O(qND)  (q  is  the  dimension  of  the 
latent space, usually equals 2) and MDS varies from O(qND) to 
O(N3).  The  effect  of  high  dimensionality  (i.e.  the  number  of 
columns for every observation) on the run-time will be similar for 
all three algorithms. The challenge in scalability (large N) is also 
of  the  same  order  for  the  three  algorithms  when  Euclidean 
distance is used.  
However  in  the  design  of  a  visual  analytic  system  that 
incorporates user interaction in the framework, the choice of the 
algorithm  should  be  based  not  only  on  the  run-time  of  the 
algorithm  but  also  on  the  cost  incurred  in  converting  the 
observation-level interaction or feedback to updated values of the 
parameters for the method.  In PPCA, it is the cost of evaluating 
the feedback matrix f(p); in MDS it is the cost of obtaining optimal 
feature weights w based on pair-wise distances of the observations 
that the user has moved; and in GTM, it is the cost of computing 
distances between data points and reference vectors. Under such 
considerations, we think MDS provides the quickest and easiest 
two-dimensional visualization of the data, followed by PPCA and 
GTM.  
We  maintain  a  probabilistic  framework  in  PPCA  and  GTM. 
Specifically  for  PPCA,  computation  is  quick  since  the  primary 
parameter  of  interest  Σd  has  a  posterior  distribution  and  a 
conjugate feedback distribution, and MAP(Σd) can be computed 
without MCMC.  Thus, analysts can explore the data in real time.  
GTM (although being most flexible in handling more complicated 
data occlusion issues that challenge MDS or PPCA) is based on 
an expectation-maximization algorithm and hence needs more run 
time to converge to the optimal parameter value. 
Sensitivity. The methods described in this paper will respond 
based on the interaction performed (i.e., number of observations 
moved, distance the observations were moved, etc.). For example, 
moving a single observation will generally result in a less drastic 
change in the layout compared to a similar interaction performed 
on a cluster of observations. Thus, the sensitivity of the models in 
terms of responding to the user’s intuition is dependent on how 
large the change or update is provided by the user’s interaction, 

the size of the dataset, as well as if the data supports the suggested 
updated  layout.  The  methods  will  attempt  to  find  the  “best  fit” 
given the user feedback, but will maintain mathematical validity 
(i.e., users cannot force the layout if the data does not support it). 
The  result  is  such  that  the  system  balances  the  user’s  intuition 
with  the  structure of  the  data  to  reduce  bias.  The  goal  of  these 
techniques is not to converge on a single structure or layout, but 
rather to allow exploration of many possible structures. 
Interaction. The examples of how observation-level interaction 
can occur within spatializations in this paper show only one form 
of interaction available to users within spatializations – movement 
of individual observations. The methods are expandable to allow 
more  complex 
interactions,  such  as  moving  clusters  of 
observations, annotating a region of the spatialization, and other 
interactions used for communicating the intuition of the user to 
the system. In a fully implemented visual analytics system, these 
interactions  may 
include  queries,  highlighting,  and  other 
interactions  from  which  analytical  reasoning  of  users  can  be 
interpreted.  
Implementation.  The  prototype  visualizations  shown  in  this 
paper are intended to provide working examples of the modified 
methods. Through the use cases, we highlighted how an end-user 
might  interact  with  such  systems.  We  plan  to  integrate  these 
methods  into  more  fully  functional  visual  analytics  tools.  That 
will allow us to perform a series of user studies to evaluate the 
usability  and  effectiveness  of  observation-level  interaction  in 
terms  of  providing 
the 
sensemaking process.  
6 

to  users,  and  supporting 

insight 

CONCLUSION 

In  this  paper,  we  described  how  modifications  of  powerful 
statistical methods allow user interaction at the observation-level. 
By  interacting  within  the  visualization  through  movement  of 
observations, users are able to perform exploratory and expressive 
interactions. Thus, users are able to perform sensemaking tasks, 
such as hypothesis validation, directly within the spatial metaphor. 
By keeping the interaction at the observation level, users are not 
required  to  transform  their  sensemaking  into  a  combination  of 
statistical parameter updates.  
In particular, we modified PPCA, MDS, and GTM using BaVA 
[18] and V2PI [19] approaches, so that users can focus on their 
spatial  analysis  of  data  rather  than  directly  updating  statistical 
parameters of models. We present three examples (one for each 
modified  method)  that  illustrate  the  effectiveness  of  these  new 
models. Based on the positive results in this paper, as well as the 
lessons  learned,  coupling  interaction  with  statistical  models 
provides  an  opportunity  to  explore  additional  forms  of  spatial 
interaction for visual analytic applications. 
ACKNOWLEDGEMENTS 
This research was funded by the National Science Foundation, 
Computer and Communications Foundations, grant #0937071. 
REFERENCES 
[1]  Thomas,  J.  J.,  Cook,  K.  A.,  National,  V.  and  Analytics,  C. 
Illuminating the path. IEEE Computer Society, 2005. 
[2] Pirolli, P. and Card, S. Sensemaking Processes of Intelligence 
Analysts  and  Possible  Leverage  Points  as  Identified  Though 
Cognitive  Task  Analysis  Proceedings  of  the  2005  International 
Conference on Intelligence Analysis, McLean, Virginia, 2005. 
[3] Jeong, D. H., Ziemkiewicz, C., Fisher, B., Ribarsky, W. and 
Chang,  R.  iPCA:  An  Interactive  System  for  PCA-based  Visual 
Analytics. Computer Graphics Forum, 28, 2009. 

[24]  Spiegelhalter,  D.  and  Lauritzen,  S.  Sequential  updating  of 
conditional  probabilities  on  directed  graphical 
structures. 
Networks, 20, 1990, 275-605. 
[25]  West,  M.  and  Harrison,  J.  Bayesian  Forecasting  and 
Dynamic Models (Springer Series in Statistics). Springer, 1997. 
[26]  Guber,  D.  Getting  What  You  Pay  For:  The  Debate  Over 
Equity  in  Public  School  Expenditures.  Journal  of  Statistics 
Education, 7, 2, 1999. 
[27]  Blake,  C.  and  Merz,  C.  J.  {UCI}  Repository  of  machine 
learning databases. 1998. 
[28] Schiffman, S., Reynolds, L. and Young, F. Introduction to 
Multidimensional  Scaling:  Theory,  Methods,  and  Applications. 
Academic Press, 1981. 
[29]  Christopher,  M.  B.  GTM:  The  generative  topographic 
mapping. 1998. 
[30] Kohonen, T., Kaski, S., Lagus, K., Salojarvi, J., Honkela, J., 
Paatero,  V.  and  Saarela,  A.  Self  Organization  of  a  Massive 
Document  Collection.  Transactions  on  Neural  Networks,  11,  3 
2000. 
[31] Dempster, A. P., Laird, N. M. and Rubin, D. B. Maximum 
likelihood from incomplete data via the EM algorithm. City, 1977. 
[32] MacQueen, J. Some methods for classification and analysis 
of  multivariate  observations.  Proceedings  of 
the  Berkeley 
Symposium  on  Mathematical  Statistics  and  Probability,  1,  281-
297, 1967, 14. 
[33] Hastie, T., Tibshirani, R. and Friedman, J. H. The Elements 
of Statistical Learning. Springer, 2003. 
[34]  Svensen,  J.  F.  M.  GTM:  the  generative  topographical 
mapping. Aston University, Birmingham, 1998. 
 

 

L. 

the  expert. 

in  Face  Verification.  In  Proceedings  of 

[4] Buja, A., Swayne, D. F., Littman, M., Dean, N., Hofmann, H. 
and  Chen, 
Interactive  Data  Visualization  with 
Multidimensional  Scaling.  Journal  of  Computational  and 
Graphical Statistics, 17, 2, 2008. 
[5]  Broekens,  J.,  Cocx,  T.  and  Kosters,  W.  A.  Object-centered 
interactive  multi-dimensional  scaling:  Ask 
In 
Proceedings  of  the  Eighteenth  Belgium-Netherlands  Conference 
on Artificial Intelligence, 2006. 
[6] Andrews, C., Endert, A. and North, C. Space to Think: Large, 
High-Resolution Displays for Sensemaking. In Proceedings of the 
CHI, 2010.  
[7] Conde, C., Ruiz, A. and Cabello, E. PCA vs Low Resolution 
Images 
the  12th 
International  Conference  on  Image  Analysis  and  Processing 
(2003). IEEE Computer Society.  
[8]  Gottumukkal,  R.  and  Asari,  V.  K.  An  improved  face 
recognition technique based on modular PCA approach. Pattern 
Recogn. Lett., 25, 4, 2004. 
[9]  Imran,  S.,  Bajwa,  S.  and  Hyder,  I.  PCA  based  Image 
Classification of Single-layered Cloud Types. Journal of Market 
Forces, 1, 2, 2005. 
[10]  Du,  Q.  and  Fowler,  J.  E.  Low-Complexity  Principal 
Component Analysis for Hyperspectral Image Compression. Int. 
J. High Perform. Comput. Appl., 22, 4, 2008. 
[11] Battista, D., Eades, P., Tamassia, R. and Tollis, I. Algorithms 
for Drawing Graphs: An Annotated Bibliography. Computational 
Geometry, 1994. 
[12] Zigelman, G., Kimmel, R. and Kiryati, N. Texture Mapping 
Using  Surface  Flattening  via  Multidimensional  Scaling.  IEEE 
Transactions  on  Visualization  and  Computer  Graphics,  8,  2, 
2002. 
[13]  Chen,  L.  Local  multidimensional  scaling  for  nonlinear 
dimension  reduction,  graph  layout  and  proximity  analysis. 
ScholarlyCommons@Penn, 2006. 
[14] Kaban, A. A Scalable Generative Topographic Mapping for 
Sparse Data Sequences. 2005. 
[15]  Olier,  I.,  Vellido,  A.  and  Giraldo,  J.  Kernel  generative 
topographic mapping. In Proceedings of the European Symposium 
on Artificial Neural Networks – Computational Intelligence and 
Machine Learning, 2010.  
[16] Cruz-Barbosa, R. and Vellido, A. Unfolding the Manifold in 
Generative  Topographic  Mapping.  In  Proceedings  of  the  3rd 
international workshop on Hybrid Artificial Intelligence Systems 
(Burgos, Spain, 2008). Springer-Verlag.  
[17]  Yi,  J.  S.,  Melton,  R.,  Stasko,  J.  and  Jacko,  J.  A.  Dust  & 
magnet:  multivariate  information  visualization  using  a  magnet 
metaphor. Information Visualization, 4, 4, 2005. 
[18]  House,  L.,  Leman,  S.  C.  and  Han,  C.  Bayesian  Visual 
Analytics  (BaVA).  In  revision,  Technical  Report:  FODAVA-10-
02, http://fodava.gatech.edu/node/342010). 
[19] Leman, S. C., House, L., Maiti, D., Endert, A. and North, C. 
A  Bi-directional  Visualization  Pipeline  that  Enables  Visual  to 
Parametric  Interation  (V2PI). NFS FODAVA Technical Report 
(FODAVA-10-41),  2011.  
[20] Pearson, K. On Lines and Planes of Closest Fit to Systems of 
Points in Space. City, 1901. 
[21]  Jolliffe,  I.  Principal  Component  Analysis.  John  Wiley  and 
Sons, Ltd, 2002. 
[22]  Torokhti,  A.  and  Friedland,  S.  Towards  theory  of  generic 
Principal Component Analysis. 
[23]  Tipping,  M.  E.  and  Bishop,  C.  M.  Probabilistic  Principal 
Component  Analysis.  Journal  of  the  Royal  Statistical  Society, 
SeriesB: Statistical Methodology, 61, 1999. 

","{""0"":{""0"":""users"",""1"":""clusters*"",""2"":""group"",""3"":""groups*""},""1"":{""0"":""parameters*"",""1"":""weights*"",""2"":""parameter*"",""3"":""variables*""},""2"":{""0"":""documents"",""1"":""model"",""2"":""models"",""3"":""methods""},""3"":{""0"":""interaction*"",""1"":""observation*"",""2"":""visual*"",""3"":""interactive*""},""4"":{""0"":""ppca"",""1"":""statistical*"",""2"":""sensemaking*"",""3"":""analytic*""},""pos"":{""0"":1,""1"":2,""2"":3,""3"":4}}",2011,{},False,False,conferencePaper,False,UQ2U6GFE,[],self.user,"{""C"":{""0"":8.6669674919,""1"":6.2786957891,""10"":5.591940414,""11"":5.0290747153,""12"":5.7973294258,""13"":12.7303348235,""14"":10.4861789882,""15"":11.9801351757,""16"":10.0704536389,""17"":8.8255333995,""18"":20.0610131578,""19"":9.1282046424,""2"":4.8053113186,""20"":8.5453678563,""21"":8.1882434545,""22"":5.1178994234,""23"":9.8737304135,""24"":4.8692659606,""25"":6.0240410884,""26"":7.7343398594,""27"":6.9093278992,""28"":11.2528548232,""29"":6.4573798078,""3"":6.2772243354,""30"":7.3725652396,""31"":6.4884730942,""32"":5.0404664965,""33"":17.778831315,""34"":6.9250798894,""35"":4.7079821461,""36"":12.1585847943,""37"":6.0714242713,""38"":5.7052393403,""39"":6.3677343272,""4"":7.2870970504,""40"":5.0172090712,""41"":8.5869566769,""42"":8.6942934958,""43"":4.7522997367,""44"":11.1301751003,""45"":7.1715154295,""46"":10.1719031321,""47"":5.2298725916,""48"":8.3550842568,""49"":9.4183392161,""5"":22.0601306374,""50"":7.1197365429,""51"":9.2767858063,""52"":8.045684241,""53"":5.8330339156,""54"":5.6969451418,""55"":4.8668086528,""56"":5.9008029797,""57"":6.349478126,""58"":6.349478126,""59"":4.9868715412,""6"":8.8883644501,""60"":5.5527366297,""61"":5.0734402026,""62"":6.5485636477,""63"":5.4039756017,""64"":5.0935289212,""65"":6.5693094138,""66"":4.693205569,""7"":10.8186072639,""8"":8.4180242191,""9"":22.6798644561},""Unnamed: 0"":{""0"":0,""1"":1,""10"":12,""11"":13,""12"":14,""13"":16,""14"":17,""15"":18,""16"":19,""17"":20,""18"":21,""19"":22,""2"":3,""20"":23,""21"":24,""22"":25,""23"":26,""24"":27,""25"":28,""26"":29,""27"":30,""28"":31,""29"":32,""3"":4,""30"":33,""31"":34,""32"":35,""33"":36,""34"":37,""35"":38,""36"":39,""37"":40,""38"":41,""39"":42,""4"":6,""40"":43,""41"":44,""42"":45,""43"":46,""44"":48,""45"":49,""46"":50,""47"":51,""48"":52,""49"":53,""5"":7,""50"":54,""51"":55,""52"":56,""53"":58,""54"":59,""55"":61,""56"":62,""57"":63,""58"":64,""59"":65,""6"":8,""60"":66,""61"":67,""62"":69,""63"":70,""64"":71,""65"":72,""66"":73,""7"":9,""8"":10,""9"":11},""count"":{""0"":130,""1"":124,""10"":62,""11"":58,""12"":58,""13"":44,""14"":42,""15"":42,""16"":34,""17"":32,""18"":32,""19"":30,""2"":106,""20"":28,""21"":28,""22"":28,""23"":28,""24"":28,""25"":26,""26"":26,""27"":26,""28"":26,""29"":24,""3"":84,""30"":24,""31"":22,""32"":22,""33"":22,""34"":20,""35"":20,""36"":20,""37"":18,""38"":18,""39"":16,""4"":72,""40"":16,""41"":16,""42"":16,""43"":14,""44"":14,""45"":14,""46"":14,""47"":12,""48"":12,""49"":12,""5"":72,""50"":12,""51"":12,""52"":10,""53"":10,""54"":10,""55"":8,""56"":8,""57"":8,""58"":8,""59"":8,""6"":70,""60"":8,""61"":8,""62"":8,""63"":8,""64"":8,""65"":8,""66"":6,""7"":68,""8"":68,""9"":66},""exemplar"":{""0"":""*"",""1"":null,""10"":null,""11"":""*"",""12"":""*"",""13"":null,""14"":null,""15"":null,""16"":null,""17"":""*"",""18"":null,""19"":null,""2"":null,""20"":""*"",""21"":null,""22"":""*"",""23"":""*"",""24"":""*"",""25"":""*"",""26"":null,""27"":null,""28"":""*"",""29"":null,""3"":""*"",""30"":null,""31"":""*"",""32"":null,""33"":null,""34"":""*"",""35"":null,""36"":null,""37"":null,""38"":null,""39"":""*"",""4"":null,""40"":null,""41"":""*"",""42"":null,""43"":null,""44"":null,""45"":null,""46"":""*"",""47"":null,""48"":null,""49"":""*"",""5"":null,""50"":null,""51"":null,""52"":null,""53"":null,""54"":""*"",""55"":null,""56"":null,""57"":null,""58"":null,""59"":null,""6"":null,""60"":null,""61"":null,""62"":null,""63"":null,""64"":""*"",""65"":""*"",""66"":null,""7"":""*"",""8"":null,""9"":null},""pos"":{""0"":1,""1"":1,""10"":2,""11"":1,""12"":2,""13"":3,""14"":4,""15"":5,""16"":5,""17"":2,""18"":3,""19"":6,""2"":2,""20"":4,""21"":7,""22"":6,""23"":3,""24"":2,""25"":7,""26"":8,""27"":8,""28"":4,""29"":9,""3"":2,""30"":10,""31"":3,""32"":11,""33"":12,""34"":4,""35"":13,""36"":14,""37"":5,""38"":15,""39"":4,""4"":1,""40"":16,""41"":5,""42"":5,""43"":17,""44"":9,""45"":10,""46"":11,""47"":18,""48"":19,""49"":6,""5"":1,""50"":12,""51"":20,""52"":21,""53"":22,""54"":7,""55"":23,""56"":8,""57"":24,""58"":25,""59"":13,""6"":3,""60"":14,""61"":26,""62"":27,""63"":28,""64"":15,""65"":6,""66"":29,""7"":3,""8"":1,""9"":4},""sigma_nor"":{""0"":1.7183672156,""1"":1.5284495821,""10"":1.6344697637,""11"":1.5840247246,""12"":1.6771256769,""13"":2.7018001821,""14"":2.4222700362,""15"":2.6298693795,""16"":2.4820607216,""17"":2.3234544594,""18"":4.0661649246,""19"":2.4036832349,""2"":1.430668733,""20"":2.3442929,""21"":2.2859511459,""22"":1.7843633089,""23"":2.5613013183,""24"":1.7437452155,""25"":1.9566303761,""26"":2.2440023129,""27"":2.1053801675,""28"":2.8351987033,""29"":2.0578222952,""3"":1.6281051176,""30"":2.2162479585,""31"":2.094160894,""32"":1.8354270776,""33"":4.1115532704,""34"":2.2085504999,""35"":1.7987590237,""36"":3.1758717229,""37"":2.0846972023,""38"":2.0145144762,""39"":2.180798693,""4"":1.7826075077,""40"":1.9116507729,""41"":2.6230703775,""42"":2.6444616705,""43"":1.8879481402,""44"":3.2138346483,""45"":2.3908750969,""46"":3.0146209915,""47"":2.0228888614,""48"":2.7030862248,""49"":2.9345019808,""5"":3.4108337271,""50"":2.4342147537,""51"":2.9036931056,""52"":2.7045303196,""53"":2.1982645393,""54"":2.1671267276,""55"":2.0091158342,""56"":2.2589206904,""57"":2.3673170592,""58"":2.3673170592,""59"":2.038122079,""6"":1.9708252507,""60"":2.1748306115,""61"":2.0590363833,""62"":2.4154145476,""63"":2.1388911231,""64"":2.063889659,""65"":2.4204265607,""66"":1.9874382431,""7"":2.201198989,""8"":1.9298364704,""9"":3.575293847},""topic"":{""0"":3,""1"":-1,""10"":2,""11"":1,""12"":0,""13"":2,""14"":2,""15"":2,""16"":-1,""17"":4,""18"":0,""19"":-1,""2"":-1,""20"":3,""21"":-1,""22"":2,""23"":4,""24"":1,""25"":2,""26"":2,""27"":-1,""28"":0,""29"":-1,""3"":3,""30"":-1,""31"":1,""32"":-1,""33"":-1,""34"":4,""35"":-1,""36"":-1,""37"":3,""38"":-1,""39"":1,""4"":0,""40"":-1,""41"":4,""42"":0,""43"":-1,""44"":2,""45"":2,""46"":2,""47"":-1,""48"":-1,""49"":0,""5"":2,""50"":2,""51"":-1,""52"":-1,""53"":-1,""54"":0,""55"":-1,""56"":0,""57"":-1,""58"":-1,""59"":2,""6"":-1,""60"":2,""61"":-1,""62"":-1,""63"":-1,""64"":2,""65"":4,""66"":-1,""7"":3,""8"":4,""9"":-1},""vector"":{""0"":""[ 1.0115447  1.5372189 -4.7642756  3.7855413  3.0714054 -1.0895586\n  4.4709353  1.4182904 -1.1296271 -1.2354861]"",""1"":""[ 1.3713948   1.5443282  -4.957152    4.5055895   3.2279036  -0.8997249\n  5.398203    2.8578682  -0.49354625 -0.70217365]"",""10"":""[ 0.78217334  2.1656024  -4.951198    4.3625593   3.8578563  -1.2159598\n  5.04624     2.4697795  -1.5654125  -1.3932396 ]"",""11"":""[ 1.1213971   2.0335515  -4.8925014   4.707945    3.7406273  -0.8120822\n  5.448026    2.868944   -0.94947624 -1.9568491 ]"",""12"":""[ 0.4691862   1.9402059  -4.6220016   4.752857    3.3101656  -0.70609105\n  5.7291474   3.0807865  -0.24770968 -0.7630851 ]"",""13"":""[ 0.76025814  2.362848   -4.966285    4.3663435   3.530856   -0.8479777\n  5.1430697   2.9603803  -1.1913081  -1.5372767 ]"",""14"":""[ 0.6143181  2.2407253 -4.4861417  4.3605103  3.715395  -0.5204989\n  4.9907656  2.9129984 -0.9675182 -1.779926 ]"",""15"":""[ 0.92379916  1.8414217  -4.339498    4.2157207   4.0488114  -0.8832897\n  4.692916    2.9540074  -1.4755272  -0.6689043 ]"",""16"":""[ 0.5896455   2.2192066  -4.8866534   4.615139    3.8268669  -1.1480676\n  5.3469596   3.2556412  -1.2459981  -0.51665944]"",""17"":""[ 0.45310366  1.6441625  -4.3647842   4.387406    3.3593585  -0.8654944\n  5.0632296   1.7146693  -0.5244865  -1.9970429 ]"",""18"":""[ 0.32262662  2.02342    -4.8315425   4.584403    3.416054   -0.86132216\n  5.640631    2.9937568  -0.5273345  -0.44997194]"",""19"":""[ 1.0402113  1.9726499 -5.0224185  4.0849166  3.4081419 -1.192298\n  4.7788916  2.6126592 -1.3944688 -1.1911396]"",""2"":""[ 0.93280756  1.987611   -4.612939    4.1159515   3.5753772  -0.8809574\n  4.674147    2.1490798  -1.3586695  -1.8312056 ]"",""20"":""[ 0.9403598   1.3572866  -4.8361483   3.9044042   2.9579794  -1.1212224\n  4.7170258   1.286425   -0.77217734 -1.2702321 ]"",""21"":""[ 0.37297007  1.655018   -4.149481    4.186138    3.537213   -0.8971535\n  4.691232    1.9241161  -0.8909649  -1.4519845 ]"",""22"":""[ 1.0680438   1.8013333  -4.082321    4.269781    4.3517923  -0.77954936\n  4.6205974   2.506747   -1.4247134  -1.1251216 ]"",""23"":""[ 0.9890319   1.2174658  -4.166717    4.2014074   3.1450663  -0.8161972\n  4.8971043   1.482632   -0.10785231 -1.4342659 ]"",""24"":""[ 0.65167934  2.0485296  -4.631962    4.55288     3.533275   -0.69163793\n  5.307064    2.4844546  -0.6767224  -2.076831  ]"",""25"":""[ 0.5819727  2.1248777 -4.257459   4.087003   3.9713538 -0.7342772\n  4.534046   2.5906138 -1.4580402 -1.2436693]"",""26"":""[ 1.5215645   1.2892646  -4.5178957   4.4896483   3.5150573  -0.79173577\n  5.119       2.8461297  -0.62507707 -1.1002525 ]"",""27"":""[ 0.95174205  1.748012   -4.768505    3.727659    3.156485   -0.9961924\n  4.4036417   1.6467514  -1.2524725  -1.4137286 ]"",""28"":""[ 0.35367703  2.12671    -4.757595    4.7105064   3.4417813  -0.7432091\n  5.6833425   3.2023768  -0.51307684 -0.8814607 ]"",""29"":""[ 0.7207268   1.4451855  -4.1400275   4.2263465   3.2085285  -0.7442852\n  4.7951846   1.7413423  -0.35722688 -1.7816592 ]"",""3"":""[ 0.70205104  1.69473    -4.505141    3.9662235   3.4350917  -1.0974096\n  4.501946    1.6653415  -1.3084682  -1.5754192 ]"",""30"":""[ 0.33240888  1.756841   -4.523221    4.5889444   3.583966   -0.9795535\n  5.379382    1.7072309  -0.6080578  -1.9325454 ]"",""31"":""[ 1.2248273   1.8156193  -4.8221087   4.7945833   3.9453473  -0.95569927\n  5.5264792   2.462243   -0.9469669  -1.8677442 ]"",""32"":""[ 1.3093826   1.9449248  -4.8986154   4.767322    3.8429854  -0.8591604\n  5.483241    2.9223437  -0.96635437 -1.7829452 ]"",""33"":""[ 1.4419498   1.175624   -4.4255466   4.4139414   3.1623666  -0.787407\n  5.357508    1.8252703   0.26953474 -1.1522859 ]"",""34"":""[ 0.5090439   1.4032077  -4.202655    4.2033386   3.2845953  -0.9010328\n  4.846257    1.3941875  -0.46258587 -1.6533154 ]"",""35"":""[ 1.0963542   1.7520225  -4.6339903   4.377106    3.3018413  -0.64563024\n  5.108015    2.7013423  -0.5458039  -1.6099159 ]"",""36"":""[-0.13397482  1.9141097  -4.626796    4.3909597   3.7355223  -1.1409289\n  5.231192    1.9694003  -1.0499791  -1.1865067 ]"",""37"":""[ 0.5964271   1.3258054  -4.7425      4.143148    3.153098   -1.207579\n  5.0141444   1.1893346  -0.63753533 -1.38655   ]"",""38"":""[ 0.686846   1.9906567 -4.865926   4.6765146  3.9077837 -1.0877985\n  5.452169   2.2459667 -1.1247689 -1.8298652]"",""39"":""[ 0.69837415  2.0248022  -4.821841    4.7409515   3.687666   -0.891427\n  5.565803    2.4662714  -0.80177385 -1.932495  ]"",""4"":""[ 1.0662782  1.9902498 -4.9965196  4.5700793  3.25195   -0.7087807\n  5.529332   3.2798316 -0.5007605 -0.8695624]"",""40"":""[ 0.36567366  1.3995631  -4.484826    4.2467985   3.3029401  -1.0842724\n  5.025177    1.2767414  -0.6030969  -1.5598897 ]"",""41"":""[ 1.3252145  1.0972401 -4.2833657  4.2881517  3.0764213 -0.7786528\n  5.122185   1.6130831  0.1754642 -1.2615004]"",""42"":""[ 0.9071484   2.183368   -4.8851466   4.817079    3.6728992  -0.7815636\n  5.647022    3.580838   -0.76522493 -0.83419585]"",""43"":""[ 1.0607046   1.3895913  -4.8722615   4.1186905   3.128586   -1.075642\n  4.9088073   1.7822723  -0.74282444 -1.2774253 ]"",""44"":""[ 0.6506428  2.218005  -4.4744873  4.163282   3.7386897 -0.6101102\n  4.7284913  2.9535432 -1.2754272 -1.4292367]"",""45"":""[ 1.0660168  1.5821812 -4.35268    4.347264   3.726988  -0.6778685\n  4.9688225  3.0812092 -0.919     -0.8072758]"",""46"":""[ 0.79395324  2.0698543  -4.01291     4.153792    4.22226    -0.5330424\n  4.556399    2.7128844  -1.4058557  -1.1400136 ]"",""47"":""[ 0.94631237  1.716414   -4.5652556   3.779103    3.3539848  -0.9879335\n  4.319914    1.8468238  -1.3686517  -1.3189031 ]"",""48"":""[ 0.9718698  2.1176283 -5.0495095  4.2607946  3.3848474 -1.0439746\n  5.0211806  2.9364538 -1.2252593 -1.1817279]"",""49"":""[ 0.67734385  2.2155817  -4.922701    4.724819    3.4284127  -0.6634957\n  5.722556    3.482622   -0.4951147  -0.7567182 ]"",""5"":""[ 0.9142986   2.0380845  -4.2156134   4.2140007   4.0433307  -0.57844687\n  4.666636    3.1999002  -1.3571364  -0.92399096]"",""50"":""[ 0.4761498   2.3040679  -4.7723      4.327674    3.4488304  -0.56043375\n  5.1927276   2.9933891  -0.8271315  -1.4534115 ]"",""51"":""[ 0.5920636  1.4853898 -4.9145308  4.193263   3.5224702 -1.4886118\n  4.9899025  1.572787  -1.2135632 -1.2682028]"",""52"":""[ 0.19772404  2.0138204  -4.575955    4.6361184   3.420122   -0.75410926\n  5.533187    2.7542431  -0.4976697  -1.2650608 ]"",""53"":""[ 0.27145207  1.5095907  -4.6183596   4.2365527   3.542216   -1.0242015\n  5.1637635   2.334299   -0.8764684  -0.46536124]"",""54"":""[ 0.70480657  2.2072387  -4.933235    4.570777    3.2943883  -0.5831615\n  5.5851827   3.2825434  -0.45940283 -1.027225  ]"",""55"":""[ 0.7473439   2.2322488  -4.8262324   4.6573567   3.804746   -0.95932746\n  5.3843703   3.4696422  -1.0960593  -0.56403524]"",""56"":""[ 0.6709605  2.2888875 -4.917338   4.7451096  3.5980825 -0.8222382\n  5.6319485  3.5953875 -0.7711725 -0.6375307]"",""57"":""[-0.01005646  1.6164249  -4.7181334   4.2449236   3.5107033  -1.193888\n  5.210052    2.0042572  -0.93949646 -0.60407686]"",""58"":""[ 0.5383183   1.7190747  -4.4975605   4.6268535   3.53468    -0.9037371\n  5.4340835   1.7828498  -0.43684772 -1.9806482 ]"",""59"":""[ 1.5652677   1.1593995  -4.588552    4.440614    3.4110923  -0.9281955\n  5.0932717   2.6694248  -0.5857111  -0.77142924]"",""6"":""[-0.15298015  1.8519315  -4.714121    4.3079677   3.6208432  -1.2541168\n  5.1887326   2.007789   -1.0981278  -0.87011224]"",""60"":""[ 1.0125778   1.7558738  -4.1792183   4.248202    3.998202   -0.66679573\n  4.722633    3.131034   -1.2401134  -0.6858327 ]"",""61"":""[ 1.514373    0.96351373 -4.381393    4.299019    3.4189322  -0.9676949\n  4.8394947   2.3801005  -0.6395942  -0.8145317 ]"",""62"":""[ 0.00903236  2.052062   -4.656101    4.40819     3.8543017  -1.0907212\n  5.1884413   2.135935   -1.1929485  -1.3357682 ]"",""63"":""[ 1.1641394  1.8297398 -4.058369   4.3902135  4.255794  -0.5960076\n  4.898064   2.3949087 -1.04765   -1.2286149]"",""64"":""[ 0.9833984  1.9565568 -4.0100565  4.307195   4.308439  -0.5677104\n  4.7514796  2.5175457 -1.2517458 -1.2177576]"",""65"":""[ 1.3475618   1.1728983  -4.162614    4.276196    3.1718216  -0.64866185\n  5.1650424   1.6864638   0.24428594 -1.2576205 ]"",""66"":""[ 1.3581411   1.0756525  -4.468286    4.3120756   3.4786272  -1.064643\n  4.894944    2.3393607  -0.77648604 -0.817152  ]"",""7"":""[ 0.72850335  1.3590751  -4.773723    3.994844    3.2314847  -1.3402723\n  4.735392    1.3340182  -1.0326586  -1.3366765 ]"",""8"":""[ 1.1331598  1.2258487 -4.2002163  4.427786   3.1973875 -0.7941358\n  5.3662696  1.687416   0.2941972 -1.2433448]"",""9"":""[ 0.31837255  2.0968676  -4.8851275   4.4545884   3.943586   -1.3166312\n  5.2241955   2.4075358  -1.4829537  -1.0060749 ]""},""vocab_index"":{""0"":1,""1"":2,""10"":16,""11"":18,""12"":19,""13"":24,""14"":27,""15"":28,""16"":34,""17"":35,""18"":37,""19"":39,""2"":5,""20"":41,""21"":42,""22"":43,""23"":44,""24"":45,""25"":48,""26"":50,""27"":54,""28"":55,""29"":56,""3"":6,""30"":59,""31"":60,""32"":67,""33"":68,""34"":69,""35"":70,""36"":76,""37"":84,""38"":88,""39"":105,""4"":10,""40"":106,""41"":107,""42"":108,""43"":109,""44"":134,""45"":135,""46"":136,""47"":156,""48"":158,""49"":160,""5"":11,""50"":162,""51"":163,""52"":205,""53"":212,""54"":213,""55"":229,""56"":260,""57"":264,""58"":265,""59"":275,""6"":12,""60"":276,""61"":280,""62"":282,""63"":283,""64"":284,""65"":285,""66"":395,""7"":13,""8"":14,""9"":15},""word"":{""0"":""interaction"",""1"":""user"",""10"":""model"",""11"":""parameters"",""12"":""clusters"",""13"":""models"",""14"":""methods"",""15"":""document"",""16"":""represents"",""17"":""statistical"",""18"":""group"",""19"":""layout"",""2"":""observations"",""20"":""interactive"",""21"":""analysis"",""22"":""paper"",""23"":""sensemaking"",""24"":""weights"",""25"":""process"",""26"":""keywords"",""27"":""feedback"",""28"":""groups"",""29"":""analytics"",""3"":""observation"",""30"":""variance"",""31"":""parameter"",""32"":""coordinates"",""33"":""impi"",""34"":""analytic"",""35"":""algorithms"",""36"":""income"",""37"":""linear"",""38"":""equation"",""39"":""variables"",""4"":""users"",""40"":""latent"",""41"":""uggtm"",""42"":""entities"",""43"":""computer"",""44"":""proposals"",""45"":""words"",""46"":""proceedings"",""47"":""notice"",""48"":""features"",""49"":""individuals"",""5"":""documents"",""50"":""treatments"",""51"":""magnification"",""52"":""scores"",""53"":""stem"",""54"":""patients"",""55"":""refers"",""56"":""states"",""57"":""upper"",""58"":""quantiles"",""59"":""query"",""6"":""level"",""60"":""corpus"",""61"":""searching"",""62"":""cost"",""63"":""springer"",""64"":""journal"",""65"":""fodava"",""66"":""matching"",""7"":""visual"",""8"":""ppca"",""9"":""figure""},""word*"":{""0"":""interaction*"",""1"":""user"",""10"":""model"",""11"":""parameters*"",""12"":""clusters*"",""13"":""models"",""14"":""methods"",""15"":""document"",""16"":""represents"",""17"":""statistical*"",""18"":""group"",""19"":""layout"",""2"":""observations"",""20"":""interactive*"",""21"":""analysis"",""22"":""paper*"",""23"":""sensemaking*"",""24"":""weights*"",""25"":""process*"",""26"":""keywords"",""27"":""feedback"",""28"":""groups*"",""29"":""analytics"",""3"":""observation*"",""30"":""variance"",""31"":""parameter*"",""32"":""coordinates"",""33"":""impi"",""34"":""analytic*"",""35"":""algorithms"",""36"":""income"",""37"":""linear"",""38"":""equation"",""39"":""variables*"",""4"":""users"",""40"":""latent"",""41"":""uggtm*"",""42"":""entities"",""43"":""computer"",""44"":""proposals"",""45"":""words"",""46"":""proceedings*"",""47"":""notice"",""48"":""features"",""49"":""individuals*"",""5"":""documents"",""50"":""treatments"",""51"":""magnification"",""52"":""scores"",""53"":""stem"",""54"":""patients*"",""55"":""refers"",""56"":""states"",""57"":""upper"",""58"":""quantiles"",""59"":""query"",""6"":""level"",""60"":""corpus"",""61"":""searching"",""62"":""cost"",""63"":""springer"",""64"":""journal*"",""65"":""fodava*"",""66"":""matching"",""7"":""visual*"",""8"":""ppca"",""9"":""figure""},""x2D"":{""0"":-2.5226707458,""1"":2.9297537804,""10"":0.4553644359,""11"":1.0817110538,""12"":2.6815237999,""13"":1.200206995,""14"":1.5328490734,""15"":1.984946847,""16"":3.6302495003,""17"":-1.2407755852,""18"":2.9110374451,""19"":0.6986338496,""2"":-1.4033626318,""20"":-2.8361604214,""21"":-1.5086219311,""22"":1.70421803,""23"":-2.2935426235,""24"":1.2236853838,""25"":1.4398310184,""26"":2.4948644638,""27"":-2.1648848057,""28"":3.0989813805,""29"":-1.6267693043,""3"":-1.8507864475,""30"":-0.8826799393,""31"":0.798091054,""32"":0.9664013386,""33"":-2.4063732624,""34"":-1.8041623831,""35"":1.7009871006,""36"":-0.5331525803,""37"":-2.4855799675,""38"":0.4722169638,""39"":0.6712286472,""4"":3.0316257477,""40"":-2.0558185577,""41"":-2.2243967056,""42"":3.3952872753,""43"":-2.6794557571,""44"":1.54471457,""45"":2.4678208828,""46"":1.5678188801,""47"":-2.0865399837,""48"":1.144218564,""49"":3.2050631046,""5"":2.2926464081,""50"":1.6151045561,""51"":-2.6352303028,""52"":2.2350327969,""53"":-0.7919249535,""54"":2.7839503288,""55"":3.6138756275,""56"":3.2622275352,""57"":-0.8545261025,""58"":-0.8086096048,""59"":2.7882275581,""6"":-0.5876284838,""60"":2.112514019,""61"":2.4765439034,""62"":-0.2728131115,""63"":1.6408547163,""64"":1.8425762653,""65"":-2.1343193054,""66"":2.6437613964,""7"":-2.5859749317,""8"":-2.4970550537,""9"":-0.0378346369},""y2D"":{""0"":1.8306958675,""1"":1.9414464235,""10"":2.7409844398,""11"":1.876103878,""12"":0.1142523736,""13"":2.5871398449,""14"":2.6957082748,""15"":4.1217579842,""16"":0.5063667893,""17"":0.7580196261,""18"":0.373345077,""19"":3.0281569958,""2"":2.1923046112,""20"":1.5624203682,""21"":1.2690834999,""22"":4.7404356003,""23"":0.3402621746,""24"":1.4764460325,""25"":4.180996418,""26"":2.78647542,""27"":2.0652205944,""28"":0.2114549726,""29"":0.5897285938,""3"":1.7270983458,""30"":1.2107298374,""31"":1.7233233452,""32"":1.9849488735,""33"":-0.1820468456,""34"":0.7380793691,""35"":1.9236668348,""36"":2.5400846004,""37"":1.1720985174,""38"":1.8550441265,""39"":1.5020998716,""4"":0.8901630044,""40"":1.0451828241,""41"":-0.0496331342,""42"":0.6598151326,""43"":1.4662847519,""44"":3.562782526,""45"":3.4487388134,""46"":4.4765295982,""47"":2.1180787086,""48"":2.772944212,""49"":0.260820806,""5"":4.3356289864,""50"":2.3097341061,""51"":2.0387408733,""52"":0.635250628,""53"":2.7569403648,""54"":0.5241287351,""55"":0.6261605024,""56"":0.3651190996,""57"":2.6721019745,""58"":0.9091744423,""59"":2.4003288746,""6"":2.49467206,""60"":4.0320897102,""61"":2.2602720261,""62"":2.3577818871,""63"":4.3209633827,""64"":4.5084104538,""65"":0.0054192338,""66"":2.4655001163,""7"":1.7863441706,""8"":-0.2655618191,""9"":2.7551810741}}",False,False,False,,"<p>The paper postulates that the process of sensemaking is not focused on a series of parameter adjustements, but instead, a series of perceived connections and patterns within the data.</p>
<p>So they discuss how can models for visual analytics tools be designed, so that users can express their reasoning in observations (the data) directly rather than of on the model parameters.</p>
<p>The main idea is that users are able to perform sensemaking tasks, such as hypothesis validation, directly within the spatial metaphor.</p>
<p>They also define two types of interactions exploratory and expressive.</p>
<p> </p>
<p>Exploratory: Users use the algorithm to explore the data and the space. For example moving one data point and looking how the other data reacts to it.</p>
<p>Expressive: Users are able to tell the model that the criteria used to calculate the parametres must be updated globally.  Dragging two documents together because they are similar.</p>
<p>Visual analytics definition: <strong>"" The science of analytical reasoning facilitated by interactive visual interfaces.""</strong> [1] <strong>The goal of visual analytics (VA) is to extract informaion, perform anayses, and validate hypotheses through an interactive exploration process know as sensemaking </strong>[2]</p>
<p>Incremental Principal Components analysis, iPCA [3], allows the user to change the weight for each dimension in calculating the direction of projection using multiple sliders.</p>
<p>Users are familiar and confortable interacting directly with the data in a spatial visualization, freely organizing and relocating observations as an integral part of their sensemaking process [cite 6]</p>
<p> They are two approaches for the feedback into the algorithm:</p>
<p>Bayesian Visual Analytics</p>
<p>And the determinist version Visual to parametric interaction</p>
<p> </p>
<p><strong>Visual analytics is the science of analytical reasoning facilitated by interactive visual interfaces. [1] The goal of visual analytics is to extract information, perform exploratory analyses and validate hypotheses through an interactive exploration process known as sensemaking [2]</strong></p>
<p>In this paper the authors define the differences between exploratory and expressive interactions.</p>
<p>Exploratory: Move an element and the similar elements to that one move towards it.</p>
<p>Expressive: Allows users to tell the model that the criteria used for calculating the similarity should be adjusted globally.</p>
<p>They mention their method is different from dust and magnet because in dust and magnet the interaction is performed on the attractors not on the observations directly</p>
<p>With this type of systems users are able to perform sensemaking tasks such as hypothesis validation, directly within the spatial metaphor.</p>
<p> </p>",Observation-level interaction with statistical models for visual analytics,"[ 1.46564558e-01 -4.82967794e-02 -9.84764174e-02 -2.57110357e-01
  5.48962355e-01 -4.72682901e-02  5.00611104e-02 -2.45082170e-01
 -4.52886313e-01 -2.05522273e-02 -7.34661985e-03 -6.22247159e-02
  1.89880282e-02 -1.79037482e-01  8.02970529e-02  6.41587079e-01
  1.24363363e-01 -8.93238094e-03 -1.25552565e-01  7.38119259e-02
  3.03382277e-01  4.03677106e-01  2.16340013e-02  2.98776031e-01
  2.33265802e-01  1.21822149e-01 -6.09036013e-02  3.34335625e-01
 -3.14431161e-01 -5.76517396e-02  2.74827421e-01  5.27098835e-01
  2.27705076e-01 -3.77455980e-01 -3.68446261e-01 -1.94509596e-01
 -2.85900235e-01  1.71448842e-01 -4.45871502e-02  4.83722419e-01
 -4.35194284e-01 -6.87791646e-01 -6.34156317e-02  2.54576709e-02
  8.31098184e-02 -8.99205208e-02 -4.91340071e-01 -1.41129225e-01
 -1.36142522e-01 -5.65576196e-01 -1.06599951e+00 -7.77865425e-02
 -1.51523978e-01 -4.33295935e-01 -2.38432601e-01  5.71263373e-01
  1.78107917e-01 -6.73074365e-01  2.51269102e-01  2.17920497e-01
 -2.24076174e-02 -2.68112212e-01 -1.30257487e-01 -2.43370190e-01
  2.30456647e-02  1.35291982e-02  4.44149256e-01  1.51083186e-01
 -3.79013449e-01  1.54364541e-01 -9.78069901e-02  2.52523184e-01
 -1.73621833e-01  3.65133137e-01 -7.21412122e-01  1.10199884e-01
 -4.00086015e-01  2.56970227e-01 -1.04218185e-01 -3.13169599e-01
 -2.97645211e-01  8.73070676e-03  9.86104459e-02 -3.07216197e-02
  2.04880923e-01  7.96762407e-01  2.69138157e-01  3.23936820e-01
 -2.55300879e-01  3.91784221e-01 -5.25998592e-01  9.88693312e-02
  5.35446554e-02  2.57201701e-01  7.17476904e-01 -1.73923820e-01
 -6.17827237e-01  2.12051436e-01  1.07943371e-01 -2.33648270e-02
  1.44050553e-01 -7.71097124e-01  5.87839074e-02 -5.63956797e-02
 -9.34104696e-02 -1.75135761e-01 -4.21181530e-01 -7.71241114e-02
 -4.67057139e-01  1.39418721e-01 -1.42792895e-01  3.36286724e-01
  2.64960468e-01 -6.06314003e-01 -2.51430154e-01 -3.63773629e-02
 -1.56657696e-01  4.02208775e-01  7.65524656e-02  7.84212723e-02
 -4.03197020e-01  3.36384207e-01 -2.42725294e-02  6.47053540e-01
  3.15945148e-01  1.69116244e-01 -1.10060260e-01  5.60592934e-02
  6.56772554e-01  3.23392272e-01  3.60267103e-01  3.17526422e-02
  1.11143731e-01 -1.07981473e-01 -5.08427978e-01 -2.23747641e-02
 -1.08935721e-01  5.06579690e-02 -2.66429931e-01 -7.12802485e-02
 -1.28048971e-01 -5.97037554e-01  5.39242089e-01  2.47129515e-01
  6.86889470e-01  1.90617859e-01 -1.85169354e-01 -6.33671284e-02
 -7.75831640e-02  6.97917342e-02 -4.33274716e-01  1.62389055e-01
 -8.33582997e-01  5.24217263e-02  9.53656994e-03  6.02977574e-01
 -3.48761171e-01  2.18126908e-01 -4.39949423e-01  2.41640970e-01
  1.90291181e-01 -1.72037750e-01 -2.39644885e-01  1.89455133e-02
  1.54167563e-01 -6.96757734e-01  8.05677399e-02  5.44038534e-01
 -2.85726041e-01 -2.97230840e-01  1.79618612e-01 -8.02234590e-01
  8.52356926e-02  1.69414729e-01  2.77164012e-01  1.80793539e-01
  1.59035809e-02 -2.58777469e-01  2.27927268e-01  9.10591960e-01
 -4.27820802e-01  3.16123486e-01 -2.08530411e-01 -4.57070768e-01
  3.55011970e-01  9.20878947e-02  2.59770572e-01 -6.33849144e-01
  4.69156444e-01  2.27910087e-01 -1.30390376e-01 -3.32914352e-01
 -4.49308157e-01 -4.25525159e-01  2.31403366e-01 -5.74826062e-01
  1.04919836e-01 -4.86540645e-02 -2.99146422e-03 -4.25487697e-01
 -2.52304733e-01 -1.16375182e-02  1.71469972e-02  1.60861760e-01
 -1.19607653e-02  2.05446973e-01  2.15026792e-02 -3.96670312e-01
 -7.47415721e-01 -1.91920474e-01 -2.53888726e-01  3.75823051e-01
 -3.46805453e-01  2.87806630e-01  2.97624826e-01  2.03462273e-01
  1.40363634e-01 -2.13330805e-01  2.21736729e-01  3.23747277e-01
  3.38892281e-01 -5.94594717e-01  1.69597536e-01  2.94846922e-01
  7.96477944e-02  1.70421982e+00  6.91043913e-01 -6.18375421e-01
  8.35637748e-01 -1.67523846e-01  1.96351945e-01 -1.29824996e-01
  2.41033018e-01 -2.71229476e-01 -1.65992141e-01  1.14595786e-01
  2.14336202e-01 -9.46850404e-02  4.39892858e-01 -1.86655045e-01
 -1.84686378e-01  2.09789827e-01  3.49295110e-01  2.04062670e-01
 -3.77333276e-02 -1.08792894e-01  3.38345945e-01 -1.92273572e-01
 -4.82020944e-01  1.98834896e-01 -2.12541968e-01  1.35379329e-01
 -2.80382454e-01 -2.25347087e-01 -8.94412026e-02  1.00015059e-01
 -3.59221809e-02 -3.58413815e-01 -8.21213499e-02  4.54019845e-01
  4.28116918e-01  2.55159676e-01  1.02768824e-01 -7.68518895e-02
  2.49616206e-01 -3.52593154e-01 -7.24170450e-03 -2.41262347e-01
  9.91646528e-01  5.13834417e-01 -5.11168361e-01 -3.25564772e-01
 -1.82071943e-02  6.15017116e-01 -4.44018930e-01 -3.74182105e-01
 -5.91225661e-02 -2.55998909e-01 -2.13209406e-01 -2.13306352e-01
  2.39803091e-01  1.25301346e-01  5.93004897e-02  3.08924671e-02
 -4.13480073e-01 -2.79707938e-01 -3.25584747e-02 -1.69611737e-01
  2.30531514e-01 -8.16447735e-02 -1.67352661e-01  5.29470384e-01
 -9.68178064e-02 -5.05857706e-01  5.71415305e-01  1.42230883e-01
  4.23863769e-01 -3.32621858e-02 -4.09850895e-01 -5.35514653e-01
 -4.24562335e-01 -2.64639929e-02  1.41013354e-01 -2.04489022e-01
  2.33010769e-01  2.00915992e-01 -4.00620848e-01 -6.46670520e-01
 -1.00771952e+01 -3.14524740e-01 -1.29083440e-01 -1.93046823e-01
  1.37839049e-01 -2.20153898e-01  2.20143914e-01 -7.02224001e-02
  5.18718325e-02 -1.56135380e-01 -1.41214699e-01 -1.77708015e-01
 -4.78166670e-01  1.21070705e-02  2.28339676e-02 -1.00776985e-01
  3.47122550e-01  1.39107965e-02 -2.18824334e-02  5.83978295e-01
 -3.44752580e-01 -4.52438354e-01  3.21893878e-02  4.28760499e-02
 -7.26934224e-02 -5.39192438e-01 -1.18471362e-01  5.43713748e-01
 -5.40859997e-01 -6.19258940e-01 -1.33886427e-01 -4.47871298e-01
 -3.97752494e-01  1.05730772e+00 -3.55172157e-01 -3.14152539e-01
 -2.98076540e-01 -3.81011844e-01  1.33836895e-01  3.37082505e-01
 -1.92972273e-02 -4.83151525e-01 -3.44289333e-01  2.10443120e-02
  7.33544469e-01 -7.63561204e-02  8.36584195e-02  5.46269178e-01
 -2.36189723e-01 -1.70892507e-01  2.19248123e-02 -1.06535241e-01
  2.05668673e-01 -4.44092214e-01 -1.03250228e-01 -2.03256011e-01
  5.69682598e-01  3.94370675e-01 -1.23988934e-01 -2.12111384e-01
  3.86324227e-01  5.54344468e-02 -2.59363651e-01  1.50454372e-01
  1.52312934e-01  1.49045408e-01 -7.09742785e-01 -9.36130583e-01
 -3.63725483e-01 -1.82675511e-01 -3.73959273e-01  1.48404956e-01
  4.18521345e-01 -1.43994069e+00 -4.75184530e-01 -6.74604714e-01
  2.76180267e-01 -9.02351961e-02 -3.17979842e-01 -2.68820673e-01
 -5.88573754e-01 -6.92442536e-01  3.24419260e-01 -3.97399217e-01
 -1.00517206e-01  1.79292932e-01 -1.59349486e-01 -4.60840464e-02
 -4.75973368e-01  3.51191700e-01 -2.08072811e-01  3.49245936e-01
  7.49772668e-01  2.46126175e-01  3.55982512e-01  2.07245201e-01
  5.68208396e-01 -2.00827807e-01 -1.23279028e-01  1.28511444e-01
  6.18775040e-02 -1.12157717e-01  2.03115895e-01 -4.34354275e-01
 -1.00679658e-02  4.91088256e-02 -6.78170264e-01  7.16113672e-02
  1.64617822e-01  4.42033082e-01  2.11070534e-02  2.47283161e-01
 -1.70088783e-01 -4.02863860e-01 -1.37331560e-01 -1.35542825e-01
 -2.38801882e-01  4.21155900e-01 -6.56825900e-02 -2.95954138e-01
 -3.62870455e-01  1.92068145e-01 -5.68539381e-01 -1.78613409e-01
  5.44476688e-01 -2.24410117e-01 -1.20758735e-01  2.59909779e-01
 -3.74227822e-01 -3.27752113e-01 -6.85646571e-03 -2.77937949e-01
  1.48060367e-01  9.88061354e-02  7.08051473e-02 -1.43117279e-01
 -6.72405213e-02 -1.27019390e-01 -7.70078063e-01  1.38505414e-01
  6.49197996e-01  2.49277472e-01  4.77631301e-01  1.74752101e-02
  2.01574750e-02 -1.21226162e-01 -3.45023453e-01  2.40295023e-01
  1.86543446e-02  3.19639683e-01 -1.12232544e-01 -6.45407498e-01
  5.49362451e-02 -3.94128948e-01  3.23286235e-01  1.37517065e-01
  3.78334075e-01 -3.55707884e-01  6.58644959e-02 -3.16662878e-01
  2.83636957e-01  3.63744907e-02  5.35978451e-02 -1.11037858e-01
 -3.29200894e-01  2.54626662e-01 -7.89410546e-02 -3.70045081e-02
  3.89835238e-01 -4.96270686e-01 -3.39253247e-01  1.59582317e-01
  4.96798247e-01 -3.64682704e-01  5.38965315e-02  3.10970128e-01
  3.34879875e-01  1.88877866e-01 -4.55147743e-01  7.33886898e-01
  2.49465942e-01  1.94225997e-01 -9.80563536e-02  4.75590259e-01
  5.93411922e-01  4.16151732e-01  2.69311190e-01 -1.57483861e-01
  1.00849286e-01  2.76537597e-01 -6.38640940e-01  1.06729373e-01
  8.70370306e-03 -1.59817979e-01  6.72436655e-02 -4.27250743e-01
  3.55851173e-01 -2.40835205e-01 -2.25609422e-01  7.86576048e-02
 -1.34706751e-01 -3.86750072e-01 -8.21889043e-02  3.06398124e-01
 -1.64173152e-02 -6.92590252e-02  1.09067768e-01  2.52917886e-01
 -4.42189246e-01 -2.48477265e-01 -5.35671413e-01 -1.85896069e-01
  1.83211282e-01 -5.13475597e-01  2.56504893e-01  1.18224666e-01
 -2.59208381e-01 -3.86200994e-01 -7.11285949e-01  3.15536946e-01
 -2.95756124e-02  4.71576415e-02  1.24516338e-01 -5.94635755e-02
  8.43914524e-02 -9.29273292e-02  8.92494991e-02 -8.21953118e-02
 -3.10782880e-01 -8.16615596e-02  1.90210454e-02 -1.61941326e+00
 -2.30512291e-01 -2.08026003e-02 -2.46321455e-01 -3.90603095e-01
 -6.17385328e-01  3.54746766e-02  5.65658286e-02 -5.22411346e-01
  8.95478800e-02 -3.29619020e-01  1.59119457e-01 -2.96970457e-01
 -8.73408020e-02 -2.21224263e-01 -5.46424270e-01 -1.22169949e-01
 -1.85011506e-01 -9.76125011e-04  1.87325194e-01 -7.78021514e-02
 -1.95476890e-01 -5.89653790e-01  4.09636945e-01 -8.90503526e-02
  3.51623669e-02 -4.49659050e-01 -1.58701196e-01  2.14419618e-01
 -3.47378969e-01 -2.27229446e-01 -7.03787953e-02  1.50398850e-01
 -5.20789921e-01  2.08723903e-01  3.85469832e-02 -5.20342588e-03
  2.70739049e-01 -2.99334377e-01  8.70688558e-02 -6.27310038e-01
 -1.88793436e-01  3.81026149e-01 -4.16022837e-01 -3.16864640e-01
 -1.92661807e-01  4.06670988e-01 -2.32488289e-02 -3.83139580e-01
  7.72363394e-02 -1.86257020e-01  3.18584472e-01  7.24396259e-02
  2.90358007e-01  5.37872091e-02 -2.96952754e-01  1.03774741e-01
  5.85376695e-02 -8.73092338e-02  9.61727202e-02  2.18837455e-01
 -2.98224747e-01  2.07378939e-01 -2.20494822e-01  5.99389613e-01
  6.61102474e-01  5.14508903e-01 -3.75610858e-01  1.02597237e-01
  7.82291144e-02  2.20433891e-01  5.89408696e-01  3.14027727e-01
 -2.47256413e-01 -4.10137288e-02  2.07153987e-02 -7.22655714e-01
 -7.12294430e-02 -5.62083423e-01 -1.53020740e-01 -7.38020018e-02
  5.42829216e-01  3.45735729e-01  1.63547650e-01 -3.72236669e-01
 -2.26461560e-01  1.09451845e-01  4.58926469e-01 -5.27017973e-02
 -4.48123515e-01  2.62955487e-01  6.16049111e-01 -4.11143392e-01
 -2.43692815e-01  3.52570832e-01 -3.19545507e-01 -4.63631392e-01
 -4.04483795e-01  5.49157977e-01  1.37340605e-01  1.64944574e-01
  1.25062585e-01 -6.99772537e-02  2.96575278e-01 -9.20153037e-02
  1.20950483e-01 -1.12106755e-01  9.43937972e-02  1.13555364e-01
  2.55100608e-01  2.37708271e-01 -3.06350827e-01  2.49794498e-01
  2.62170970e-01 -2.84634411e-01 -7.73386657e-02  5.14822721e-01
 -1.25320747e-01  3.75991315e-01  1.23401158e-01  1.87405333e-01
  1.78888857e-01  1.71185583e-01  1.84974581e-01 -2.48467103e-01
 -3.53664383e-02  1.46805272e-01  1.48642465e-01  4.24114317e-01
  2.06465334e-01  2.99171895e-01  1.19545914e-01 -9.48372245e-01
 -1.13620825e-01 -2.17962250e-01  4.92359668e-01  3.07834446e-01
  5.00856698e-01 -2.56162941e-01  1.80809140e-01  3.94691110e-01
 -1.73589773e-02  6.74565807e-02  2.86567420e-01  1.62959278e-01
 -2.43508264e-01 -3.37434769e-01 -1.95669174e-01  7.09523186e-02
 -2.95152307e-01  1.26684606e-01  1.49108648e-01 -1.76842973e-01
 -4.53699768e-01 -4.01036561e-01 -3.06133032e-01  2.23400727e-01
  1.53235778e-01  1.07633322e-01 -4.27895151e-02  5.30900419e-01
  8.14748704e-01 -2.32530802e-01 -1.91112086e-01 -2.35738531e-02
  2.11347290e-03  1.76207256e-02  7.70235837e-01 -1.97967380e-01
  2.15245053e-01 -1.14431664e-01 -2.36302182e-01 -4.81422655e-02
 -1.12715580e-01 -3.15920830e-01 -3.90687943e-01  4.34916317e-01
 -5.82032144e-01 -3.83824617e-01  4.63190675e-01  2.88007081e-01
 -1.13913864e-01  4.29540932e-01  7.34622702e-02  3.38755995e-01
  2.68282175e-01  1.20822996e-01 -4.50478971e-01  1.49329469e-01
 -3.26817155e-01 -6.56174719e-01  6.17324233e-01 -3.21734846e-01
  2.28008851e-02  7.77929544e-01 -3.11201692e-01 -1.70009866e-01
  1.23002008e-01  8.64529163e-02  3.25426668e-01  5.87379932e-01
 -2.47800738e-01  1.00992568e-01 -3.78911719e-02  1.17820466e-03
 -1.26059726e-02  4.08824742e-01 -1.29385710e-01 -1.81981008e-02
 -4.67657655e-01  5.12221336e-01  3.63856703e-01 -2.83176154e-02
  9.26714689e-02  3.14924747e-01 -4.25804891e-02  8.88919458e-02
 -3.23021650e-01 -4.81503338e-01 -4.92632419e-01 -7.72098154e-02
 -2.31739670e-01 -2.29273453e-01  2.16232345e-01  4.01138186e-01
 -5.23677051e-01 -5.41865528e-01 -5.84342629e-02 -1.69697195e-01]",UQ2U6GFE,False,False,"[9.233318328857422, -0.22801105678081512]"
