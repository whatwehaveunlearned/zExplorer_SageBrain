index,abstract,abstract_bert_vector,author,bert_vector,citationArticles,citations,citationsList,clusterID,conclusion_bert_vector,globalID,notes,organization,pages,parent_item,pdf_file,tags,text,title,topics,type,url,user,versions,words,year
7YWBXAWZ,False,"[-0.030565344, 0.40195534, -0.029056245, 0.00034797608, 0.705256, -0.06765047, -0.38409764, 0.19878381, -0.24142097, -0.3798023, 0.22558115, -0.1642173, -0.39457482, 0.11980966, 0.045966163, 0.38569778, -0.12911315, 0.06753476, -0.10833416, 0.29493022, -0.085032605, 0.5867579, -0.1788268, 0.419396, 0.38044396, 0.103452675, -0.23122945, 0.12460858, -0.5334638, 0.23819575, 0.10602569, 0.6463332, -0.023657192, -0.35419202, 0.030970065, -0.04035595, -0.52358174, -0.6857009, -0.21619661, 0.35639352, -0.3998379, -0.27678192, 0.10297387, 0.13774537, 0.07865921, -0.23227753, -0.6097027, -0.15705407, -0.1361827, -0.38845426, -1.4937944, 0.43635595, -0.0025775472, 0.069406666, 0.104744636, 0.65289307, 0.04931458, -0.550322, 0.28735942, -0.0029874379, -0.2850953, -0.07909207, -0.37337318, 0.21194449, 0.33386064, -0.14128782, 0.110972844, -0.0360918, -0.7486513, 0.30119586, -0.47365993, 0.2434729, -0.48484385, 0.41190913, -0.9234437, -0.035905123, -0.2297342, 0.06275503, -0.14856732, 0.023003977, -0.5652274, 0.30682322, -0.060762472, -0.2739505, 0.49027947, 0.81273687, -0.089523576, 0.5008611, -0.08111176, 0.013838967, -0.33579677, -0.2798262, -0.14798844, 0.27310574, 0.9494032, -0.14709629, -0.24307945, 0.23756447, -0.47816163, 0.08663986, ...]",{},"[-0.5239642, 0.2815089, 0.66657376, -0.98539186, -0.2565517, -0.22703472, -0.21077776, -0.19881798, 0.14913358, 0.023518069, -0.55979735, -0.87224555, 0.08547609, 0.60788155, -0.04553873, 0.9742873, 0.17961466, -0.068797685, -0.5278236, 0.092368215, 0.5515824, 0.6502718, -0.0045992364, 0.08589948, -0.026428817, 0.094641164, -0.025672862, 0.18034211, -0.037126184, 0.54827815, 0.14025313, 0.23500587, -0.31956774, -0.13021865, 0.36122078, -0.24634689, 0.032382995, -0.53435105, 0.4237397, 0.13223638, 0.38110095, -0.3097484, -0.13417539, -0.14391953, 0.41502017, 0.14378874, -0.23209952, -0.18523033, -0.32759267, -0.16391334, -0.83631116, -0.17565818, -0.1369438, -0.456633, -0.17131566, 0.475759, 0.1449265, -0.32272133, -0.37395468, -0.15492672, 0.17791681, -0.5115082, 0.35103798, 0.50621456, -0.192711, -0.21329819, -0.7135363, 0.66842824, -0.1529657, -0.04502295, -0.17434654, 0.59607, 0.270149, 0.4247381, 0.18243791, -0.024389744, -0.19971254, 0.123407096, -0.104524, -0.07670084, 0.11877261, 0.24279013, 0.51760215, -0.102696106, 0.24834257, 0.24349464, 0.14901237, -0.46072057, -0.3172826, 0.16483843, -0.17937204, 0.16457716, -0.10000534, -0.08123558, -0.022053963, 0.10868805, -0.5361573, -0.41272414, 0.07468862, -0.42822552, ...]",False,False,False,False,"[0.051000386, 0.08688955, 0.13086021, 0.4001267, 0.45861927, 0.05567062, 0.07629725, 0.18731397, -0.04515389, -0.26343554, 0.048072852, 0.18751276, -0.0721807, 0.2103174, -0.17713936, 0.32713413, 0.21936955, 0.08374916, 0.22349304, -0.2422369, -0.043867435, 0.33349037, -0.46346456, 0.15324993, 0.30688044, 0.118819036, -0.038885593, -0.3398164, -0.29570848, -0.100550674, 0.19483714, 0.6905059, -0.20360021, -0.49004745, 0.21408388, 0.11582691, -0.28553694, -0.06572989, -0.5720007, 0.2364408, -0.24121353, -0.18164217, -0.04297894, -0.15791765, -0.31693804, -0.15142494, -0.34352776, 0.0012132955, -0.16566324, -0.30549395, -1.1965151, 0.11936049, -0.37119183, 0.10379883, -0.052033525, 0.5902625, 0.34521502, -0.31733543, 0.1804307, 0.41810647, -0.06893038, -0.017222807, -0.06073114, 0.02511115, 0.27182186, -0.113406755, -0.06582211, -0.47214425, -0.26823518, 0.5463655, -0.36862072, 0.10104861, -0.49738824, 0.09329802, -1.0391264, 0.04157546, -0.25090703, 0.13841736, -0.11712636, 0.04156559, -0.29063407, 0.25595868, -0.23179094, -0.16985151, 0.52598405, 0.7210659, 0.3758417, 0.56904536, -0.29164574, 0.17310116, -0.028155072, -0.09869825, 0.05350847, 0.26298636, 0.6411293, -0.0754477, 0.028106347, -0.0661321, 0.11344537, 0.04439325, ...]",7YWBXAWZ,,False,False,7YWBXAWZ,N6NB5V6C,[],"volume xx (200y), number z, pp. 1–29

8
1
0
2

 

b
e
f
2
2

 

 
 
]
l
m

.
t
a
t
s
[
 
 

1
v
4
5
9
7
0

.

2
0
8
1
:
v
i
x
r
a

the state of the art in

integrating machine learning into visual analytics

a. endert1, w. ribarsky2, c. turkay3, w. wong4, i. nabney5, i. d´ıaz blanco6, f. rossi7

1georgia tech, usa

2university of north carolina, charlotte, usa

3city university of london, uk

4middlesex university, uk

5aston university, uk

6university of oviedo, spain

7paris 1 panth´eon sorbonne university, paris

abstract
visual analytics systems combine machine learning or other analytic techniques with interactive data visualization
to promote sensemaking and analytical reasoning. it is through such techniques that people can make sense of large,
complex data. while progress has been made, the tactful combination of machine learning and data visualization
is still under-explored. this state-of-the-art report presents a summary of the progress that has been made by
highlighting and synthesizing select research advances. further, it presents opportunities and challenges to enhance
the synergy between machine learning and visual analytics for impactful future research directions.

categories and subject descriptors (according to acm ccs): human-centered computing - visualization, visual
analytics

1. introduction

we are in a data-driven era. increasingly more domains
generate and consume data. people have the potential to un-
derstand phenomena in more depth using new data analysis
techniques. additionally, new phenomena can be uncovered
in domains where data is becoming available. thus, making
sense of data is becoming increasingly important, and this is
driving the need for systems that enable people to analyze
and understand data.

however, this opportunity to discover also presents chal-
lenges. reasoning about data is becoming more complicated
and diﬃcult as data scales and complexities increase. people
require powerful tools to draw valid conclusions from data,
while maintaining trustworthy and interpretable results.

we claim that visual analytics (va) and machine learn-
ing (ml) have complementing strengths and weaknesses
to address these challenges. visual analytics (va) is a
multi-disciplinary domain that combines data visualization
with machine learning (ml) and other automated tech-
niques to create systems that help people make sense of
data [tc05, ksf∗08, kei02, kmsz06]. over the years, much
work has been done to establish the foundations of this area,

submitted to computer graphics forum (6/2018).

create research advances in select topics, and form a com-
munity of researchers to continue to evolve the state of the
art.

currently, va techniques exist that make use of select
ml models or algorithms. however, there are additional
techniques that can apply to the broader visual data analysis
process. doing so reveals opportunities for how to couple user
tasks and activities with such models. similarly, opportunities
exist to advance ml models based on the cognitive tasks
invoked by interactive va techniques.

this state-of-the-art report brieﬂy summarizes the ad-
vances made at the intersection of ml and va. it describes
the extent to which machine learning methods are utilized in
visual analytics to date. further, it illuminates the opportuni-
ties within both disciplines that can drive important research
directions in the future. much of the content and inspiration
for this paper originated during a dagstuhl seminar titled,
“bridging machine learning with information visualization
(15101)” [kmrv15].

2

endert et al. / integrating machine learning into visual analytics

1.1. report organization

this report is organized as follows. section 2 of the report
discusses three categories of models: human reasoning, visual
analytics and information visualization, and machine learning.
the models describing the cognitive activity of sensemaking
and analytical reasoning characterize the processes that hu-
mans engage in cognitively to gain understanding of data.
the models and frameworks for visual analytics depict sys-
tematic descriptions of how computation and analytics can
be incorporated in the systematic construction and design
of visual analytic applications. finally, the machine learning
community has several models that illustrate how models
are trained, used, and interactively steered.

section 3 categorizes the integration of machine learning
techniques into visual analytic systems. section 4 discusses
how such systems have been used in speciﬁc domains to solve
real-world challenges. section 5 discusses a research direc-
tion for integrating steerable dimension reduction techniques
into visual analytics. finally, section 6 discusses open chal-
lenges and opportunities for ml and va. while the current
work shows how some progress has been made in bringing
these two communities closer together, there are several open
challenges.

2. models and frameworks

to ground the discussion of embedding ml techniques into
va systems for data analysis and knowledge discovery, we
describe three categories of models and frameworks below.
first, we discuss existing models meant to describe the cog-
nitive stages people progress through while analyzing data.
these models show the complex processes people go through
to gain insight from data, which developed systems must sup-
port. second, we discuss existing models and frameworks that
describe interaction and information design of visual analytic
applications. these models illustrate how data transforma-
tion and analytic computation are involved in generating the
visual representations of data in tools. user interaction is
critical in tuning and steering the parameters of these models.
finally, we show select ml frameworks that emphasize the
importance of training data and ground truth for generating
accurate and eﬀective computational models. in addition, we
describe the main techniques developed in the ml ﬁeld to
integrate user feedback in the training process.

2.1. models of sensemaking and knowledge

discovery

one should emphasize that a primary purpose of data analyt-
ics is for people to understand, and gain insights into, their
data [cms99,chr06]. thus, it is important to understand the
cognitive processes of people as they reason about data. it is
from such an understanding that “human-in-the-loop” appli-
cation designs are realized. prior work exists that provides
models and design guidelines for visual analytics.

sense-making is the process of “structuring the unknown”

figure 1: the “sensemaking loop” (from [pc05]) illustrating
the cognitive stages people go through to gain insight from
data.

by organising data into a framework that enables us “to
comprehend, understand, explain, attribute, extrapolate,
and predict” [anc12]. it is this activity of structuring–the
ﬁnding and assembly of data into meaningful explanatory
sequences [li57]–that enables us to turn ever more com-
plex observations of the world into ﬁndings we can under-
stand “explicitly in words and that serves as a springboard
into action” [wso05]. by attempting to articulate the un-
known, we are driven more by “plausibility rather than
accuracy” [wei95] as we create plausible explanations that
can be used to evolve and test our understanding of the
situation or the data. decision makers are often faced with
inaccurate representations of the world [ept∗05] and have
to ﬁll-in the gaps with strategies such as “story-telling” to
create stories that explain the situation.

one of the earliest models to describe the iterative process
of data analysis as “sensemaking” [rspc93] is presented
in figure 1 and illustrates the well-known (and probably
the most frequently cited) pirolli and card sensemaking
model [pc05]. proposed in the context of intelligence analysis,
it is useful for showing how information is handled through
the process of searching and retrieving relevant information,
organizing, indexing and storing the information for later use,
structuring the information to create a schema or a way to
explain what has been observed, the formulation and testing
of hypotheses, which then leads to the determination of a
conclusion, and a sharing of that conclusion. this notional
model depicts the cognitive stages of people as they use
visual analytic tools to gain understanding of their data.

from pirolli and card’s perspective, sensemaking can be
categorized into two primary phases: foraging and synthesis.
foraging refers to the stages of the process where models
ﬁlter and users gather collections of interesting or relevant
information. this phase emphasizes the computational ability
of models, as the datasets are typically much larger than
what a user can handle. then, using that foraged information,
users advance through the synthesis stages of the process,
where they construct and test hypotheses about how the

submitted to computer graphics forum (6/2018).

endert et al. / integrating machine learning into visual analytics

3

foraged information may relate to the larger plot. in contrast
to foraging, synthesis is more “cognitively intensive”, as much
of the insights stem from the user’s intuition and domain
expertise. most existing visualization tools focus on either
foraging or synthesis, separating these two phases.

as with all models of cognitive processes, there have been
criticisms. for instance, while there are feedback loops and
repeat loops, and cycles within cycles, it still is somewhat a
linear model. it describes the data transaction and informa-
tion handling and transformation processes, “... rather than
how analysts work and how they transition” [ks11]. human
analysts carry out their work within this framework, but
their thinking and reasoning processes are much less linear
and structured. for example, although recognised as a part
of the sense-making loop, there is little explanation about the
thinking and reasoning strategies that are invoked to formu-
late hypotheses. this is a critical aspect of the sense-making
process: how are explanations of the situation or data formed
in the mind of the human in order that the explanation can
be used to test one’s understanding of the data or situation?
later in this section, we report on work that is attempting
to unravel this aspect of how analysts think.

another useful model that can be employed to describe
the human-centered sense-making process is the “data-frame
model” by klein et al. [kmh06b, kmh06a]. their model
(figure 2) depicts an exchange of information between the
human and the data in terms of frames. people make sense of
a situation by interpreting the data they are presented with
in relation to what they already know to create a new under-
standing. a user has an internal “frame” that represents her
current understanding of the world. the data connects with
the frame. as she continues to explore a particular dataset,
her frames of the world are mapped against the information
she uncovers. if the information supports a speciﬁc frame,
that frame is thought to strengthen in a process they call
elaboration. as she understands the situation better, she
searches for more relevant information, learning that there
may be other factors to the problem than originally thought
or known, therefore driving the demand for more information,
and building her frame. however, when evidence is discovered
through exploration that contradicts or refutes the existence
of such a mental frame, the frame can either be augmented
or a new one created. this is the important process that
leads her to question her earlier conclusions or assumptions
made to arrive at these conclusions. additionally new frames
can also be created to reframe the problem. in situations
where data is missing or ambiguous or unknown, reframing
enables her to articulate the problem in diﬀerent ways that
may allow her to change her information search strategy
and perhaps even her goals. one of the key beneﬁts of the
data-frame model is that it points to the importance of de-
signing visual analytics in a way that encourages analysts to
question their data and their understanding, and to facilitate
visualizations and transformations that enable reframing of
their understanding of the situation.

recently a set of knowledge generation and synthesis mod-

submitted to computer graphics forum (6/2018).

figure
making [kmh06b].

2:

the data-frame model

of

sense-

els have been proposed that comprehensively attack a central
issue of visual analytics: developing a human-computer sys-
tem that enables analytic reasoning to produce actionable
knowledge. the ﬁrst of these models was proposed by sacha
et. al. [sss∗14] and is shown in figure 3. one sees looping
structures and components familiar from pirolli and card’s
sensemaking model, as depicted in figure 1 above. however,
the computer and human regions of the model, and their re-
lationship with each other, are now explicitly expressed, and
the paper shows a clear relationship, via interaction, between
the human and both the visualization and the model. the pa-
per also describes detailed steps for the data-visualization and
data-model pipelines (the latter in terms of kdd processes
that couple, for example, to machine learning algorithms).
whereas the sensemaking model was conceptual, this model
is concrete and shows, better than other models, where to put
computing and (via interactive interfaces) human-in-the-loop
steps in order to build an actual system.

the sacha et al. model has recently been generalized to
produce a more complete knowledge generation and synthesis
(kgs) model [rf16]. the kgs model explicityly accounts for
both prior knowledge (placed between data, visualization,
and model in figure 3) and user knowledge (placed between
action and finding). prior knowledge is quite important
for any exploration involving experts or based on expertise;
experts will want to know immediately the relationship of new
knowledge to existing domain knowledge. user knowledge
is built up during complex reasoning, where it can then
be the basis for generating additional knowledge or can be
synthesized with prior knowledge to produce more general
truths. the kgs model posits an iterative process that
addresses high level reasoning, such as inductive, deductive,
and abductive reasoning, in the knowledge generation and
exploration loops. it is based on a framework by gahegan
et al. [gwhr01] that was developed for giscience but is
generalizable.

these models provide a roadmap for visualization and
analytics processes, and for the role of human-computer in-
teraction. in particular, they illuminate the relationships
among machine learning, visualization, and analytics rea-

4

endert et al. / integrating machine learning into visual analytics

figure 3: human-computer knowledge generation model
of sacha et al. [sss∗14].

figure 4: the information visualization pipeline [hee06]
depicting the data transformation and visual mapping process
for constructing visualizations.

soning processes including exploration and knowledge gen-
eration. for example, klein’s data frame model, discussed
above, would ﬁt in this structure, providing a focus for ml
components while the models in figure 3 would show how
to connect the data frame model with interactive visualiza-
tion and hypothesis-building. there are no va systems that
embody all the components of the sacha and kgs models,
but there are some (e.g., vairoma [cdw∗16]) that include
parts of the model. typically in these systems, ml is a static
pre-processing step applied to the data at the beginning.
for example, in vairoma time-dependent, hierarchical topic
modeling is applied to large text collections [cdw∗16]. how-
ever, the kgs model shows how interactive ml can be placed
in the human-computer process and how it relates to interac-
tive visualization and reasoning. there is further discussion
of interactivity in vaml systems below. the discussion in
sacha et al. [sss∗14] implies two main roles for ml; one is to
transform unstructured or semi-structured data into a form
more meaningful for human exploration and insight discov-
ery. the other is to use unsupervised or semi-supervised ml
to guide the analysis itself by suggesting the best visualiza-
tions, sequences of steps in the exploration, veriﬁcation, or
knowledge generation processes, guarding against cognitive
bias, etc. in addition, since the kgs model was derived with
reference to cognitive science principles [grf09], there is a
possibility for merging ml with cognitive models to produce
even more powerful human-machine models. to illustrate,
one could explore fu and pirolli’s snif-act cognitive ar-
chitecture model [fp07], which connects human exploration
and information foraging in a sensemaking context. this
could be married with ml approaches to reﬁne and focus the
parameters of the ml approach for particular exploration
strategies.

2.2. models of interactivity in visual analytics

frameworks or pipelines for information visualization have
been previously developed [hee06, van05]. for example, the

information visualization pipeline depicted in figure 5 shows
how data characteristics are extracted and assigned visual
attributes or encodings, ultimately creating a visualization.
the designs of visualizations adhering to this pipeline exhibit
two primary components of the visual interface: the visualiza-
tion showing the information, and a graphical user interface
(gui) consisting of graphical controls or widgets. the graph-
ical controls in the gui (e.g., sliders, knobs, etc.) allow
users to directly manipulate the parameters they control. for
example, “direct manipulation” [shn83] user interfaces for
information visualizations enable users to directly augment
the values of data and visualization parameters to see the
corresponding change in the visualization (e.g., using a slider
to set the range of home prices and observing the ﬁltering
of results in a map showing homes for sale). this model
is a successful user interaction framework for information
visualizations.

visual analytic systems have adopted this method for user
interaction, but with the distinct diﬀerence of including ana-
lytic models or algorithms, as discussed earlier in this section.
for example, in addition to ﬁltering the data by selecting
ranges for home prices, users could be given graphical con-
trols over model parameters such as weighting the mixture
of eigenvectors of a principal component analysis (pca) di-
mension reduction (dr) model to produce two-dimensional
views showing pairwise similarity of homes across all of the
available dimensions. to users who lack expertise in such
models, this may pose fundamental usability challenges.

in contrast, prior work has proposed frameworks to per-
form model steering via machine learning techniques applied
to the user interactions performed during visual data analysis,
called semantic interaction [efn12b]. semantic interaction is
an approach to user interaction for visual data exploration in
which analytical reasoning of the user is inferred and in turn
used to steer the underlying models implicitly (illustrated in
figure 5). the goal of this approach to user interaction is
to enable co-reasoning between the human and the analytic
model (or models) used to create the visualization (coupling
cognition and computation) without requiring the user to
directly control the models.

the approach of semantic interaction is to overload the
visual metaphor through which the insights are obtained (i.e.,
the visualization of information created by computational
models) and the interaction metaphor through which hy-
potheses and assertions are communicated (i.e., interaction
occurs within the visual metaphor). semantic interaction
enables users to directly manipulate data within visualiza-
tions, from which tacit knowledge of the user is captured,
and the underlying analytic models are steered. the analytic
models can be incrementally adapted based on the user’s
sensemaking process and domain expertise explicated via
the user interactions with the system (as described in the
models of section 2.1).

the semantic interaction pipeline (shown in figure 5) takes
an approach of directly binding model steering techniques
to the interactive aﬀordances created by the visualization.

submitted to computer graphics forum (6/2018).

endert et al. / integrating machine learning into visual analytics

5

figure 5: the semantic interaction pipeline [efn12b] show-
ing how the user interactions in a spatial visualization can be
incorporated into the computation of a visual analytic system.

for example, a distance function used to determine the
relative similarity between two data points (often visually
depicted using distance in a spatial layout), can serve as
the interactive aﬀordance to allow users to explore that
relationship. therefore, the user interaction is directly in the
visual metaphor, creating a bi-directional medium between
the user and the analytic models [lhm∗11].

2.3. machine learning models and frameworks

there is not as much work in machine learning models and
frameworks. most of the proposals correspond to some form of
de facto industrial standards, such as the semma (sample,
explore, modify, model, and assess) methodology adver-
tised by sas institute inc. among those, a vendor neutral
framework, crisp-dm [she00], is somewhat comparable to
knowledge discovery and visual analytics frameworks. there
are six phases in the framework: business (or problem) un-
derstanding; data understanding (developed through explo-
ration of the data and discussion with data owners); data
preparation (including feature extraction, noise removal, and
transformation); modeling; evaluation (testing the quality of
the model, and particularly its generalization performance);
deployment (embedding the model in practice). in some
versions of this framework, there is an additional link from
deployment back to business understanding - this represents
the fact that the underlying data generator may change over
time. the model needs continuous evaluation in deployment
and when performance degrades, the process starts again.
perhaps more importantly, all the steps of the framework
are embedded in a general loop comparable to the ones ob-
served in other frameworks. this emphasize the feedback
from the latter stage of the process (evaluation in numerous
machine learning applications) to the early stages (e.g. data
preparation in crisp-dm).

as pointed out in e.g. [ackk14], the traditional imple-
mentation of the machine learning workﬂow leads to long
development cycles where end users (who are also domain
experts) are asked to give feedback on the modeling results.
this feedback is used by machine learning experts to tune the
whole processing chain, especially at the data preparation
stage. ideally, this feedback should take the form of speciﬁc
and formal user inputs, for example positive and negative
feedback on exemplars (such as “those two objects should not
belong to the same cluster” or “this object is misclassiﬁed”).

user feedback in this formal, expressive form lends it-
self very well to steering and training machine learning
models, for example via interactive machine learning ap-

submitted to computer graphics forum (6/2018).

proaches [pth13]. figure 6 shows an early model of inter-
active machine learning that emphasizes the feedback that
users give to train classiﬁers [foj03]. through multiple iter-
ations of feedback, the classiﬁer gets more training examples,
and is thus able to more closely approximate the phenomena
or concept being classiﬁed in the data.

to further establish an ml framework, we note the follow-
ing. machine learning tasks are traditionally divided into two
broad categories, supervised tasks and unsupervised tasks.
in supervised learning, the goal is to construct a model that
maps an input to an output, using a set of examples of
this mapping, the training set. the quality of the model is
evaluated via a ﬁxed loss criterion. up till recently, it has
generally been considered that human input is not needed in
the model construction phase. on the contrary, it could lead
to undetected overﬁtting. indeed the expected quality of the
model on future data (its so-called generalization ability) is
generally estimated via an independent set of examples, the
test set. allowing the user (or a program) to tune the model
using this set will generally reduce the generalization ability
of the model and prevent any sound evaluation of this ability
(unless yet another set of examples is available).

supervision via examples can be seen as a direct form of
user control over the training process. allowing the user to
modify the training set interactively provides an indirect way
of integrating user inputs into the model construction phase.
in addition, opportunities for user feedback and control are
available before and after this modeling step (e.g., using
the crisp-dm phases). for instance, user feedback can be
utilized at the feature selection, error preferences, and other
steps. leveraging those opportunities (including training
set modiﬁcation) has been the main focus of interactive
machine learning approaches. for instance, tools such as the
crayons system from [foj03] allow the user to add new
training data by specifying in a visual way positive and
negative examples. this speciﬁc type of user feedback in the
form of labelling new examples is exactly the focus of the
active learning framework [set09] in machine learning. this
learning paradigm is a variation over supervised learning
in which ml algorithms are able to determine interesting
inputs for which they do not know the desired outputs (in
the training set), in such a way that given those outputs the
predictive performances of the model would greatly improve.
interestingly active learning is not the paradigm used in
e.g. [foj03]. it seems indeed that in real world applications,
active learning algorithms tend to ask too many questions
and possibly to similar ones, as reported in e.g., [gb11].
more generally, the need for speciﬁc and formal user inputs
can create usability issues with regards to people and their
tasks, as pointed out in e.g., [ackk14,ehr∗14]. that is, the
actions taken by the user to train the systems are often not
the actions native to the exploratory data analysis described
in the previously mentioned frameworks. this is starting
to become more commonly used in the ml community, as
exempliﬁed by [bh12]. in this paper the authors consider
additional questions a system can ask a user, beyond just
labelling. they focus in particular on class conditional queries

6

endert et al. / integrating machine learning into visual analytics

figure 6: a model for interactive machine [foj03] learning
depicting user feedback for model training.

– the system shows the user unlabeled examples and asks
him or her to select one that belongs to a given class (if one
exists).

in unsupervised learning, the data has no input/output
structure and the general goal is to summarize the data in
some way. for instance, as discussed further below, dimension
reduction techniques build low dimensional approximations
of the data from their high dimensional initial representation;
clustering groups data into similar objects; etc. unsuper-
vised learning is generally considered ill posed in the ml
ﬁeld in the following sense: most of the tasks of unsupervised
learning (clustering, dimensionality reduction, etc.) have only
an informal description to which numerous formal models
can be related. those models are very diﬃcult to compare
on a theoretical point of view as well as on a practical one.
in unsupervised learning, the need for user input, steering
and control is therefore broadly accepted and techniques to
include user feedback into e.g., clustering have been studied
for some time. variations over unsupervised methods that
take explicitly into account some form of additional infor-
mation are generally called semi-supervised methods. the
supervision is frequently provided by external data in an
automated way, but those methods can lead to principled
ways of integrating user feedback.

it should be noted however that most of the methodolog-
ical development in machine learning that can be used to
integrate user feedback, from active learning to triplet based
constraints [vdmw12], are seldom evaluated in the context
of visualization systems. in general, the feedback process is
either simulated or obtained via oﬀ line and slow process (e.g.
amazon’s mechanical turk for triplet in [wkkb15]). thus
while speciﬁc frameworks that enable user feedback have
been deﬁned by the ml community, the practical relevance
of the recent ones in the context of interactive visualization
remains untested.

2.4. comparison to another classiﬁcation

framework

a recent paper by sacha et al. [szs∗16] overlaps with this
star report. it focuses on the speciﬁc area of dimensionality
reduction and how these techniques integrate with interactive
visualization in visual analytics systems. the paper builds
around a systematic analysis of visualization literature, which

reveals seven common interaction scenarios. the evaluation
leads to the identiﬁcation of future research opportunities.

the current paper provides a signiﬁcantly broader survey
of machine learning methods coupled with interaction, while
sacha et al. [szs∗16] probe deeper in one important area.
in addition to dimension reduction, the current paper deals
with ml methods for clustering, classiﬁcation, and regression.
there is some overlap in the literature covered in the two
papers. however, the literature reviewed in the current paper
cites ml methods that are already coupled with interactive
visualization systems plus those that are not yet (but it
would be beneﬁcial if they were); sacha et al. deal mostly
with ml methods that are already coupled with interactive
visualizations.

the two papers complement each other with sacha’s deeper
analysis in dr strengthening the wider analysis in the cur-
rent paper, and vice versa. the human-in-the-loop process
model in [szs∗16] has similarities with the use of the human-
machine interaction loop in the current paper; they also share
a common origin. the classiﬁcations used in sacha et al’s
structured analysis are diﬀerent than those in the current
paper’s taxonomy, although one could be mapped into the
other, with modiﬁcations. however, there are also multiple
similarities; in particular, classiﬁcation according to “modify
parameters and computation domain” and “deﬁne analytical
expectations” in sections 3.2 and 3.3 of the current paper
map to various interaction scenarios in sacha et al. [szs∗16].
for example, the ﬁrst classiﬁcation maps to data manipula-
tion, dr parameter tuning, and dr type selection scenarios
in sacha et al’s model. the second classiﬁcation, in permit-
ting the user to tell the system (based on results it gives)
expectations that are consistent with domain knowledge,
maps to feature selection and emphasis and deﬁning con-
straints scenarios. the current paper then goes beyond dr,
including for each classiﬁcation a discussion of clustering,
classiﬁcation, and regression methods. this broadens and
strengthens the discussion from sacha et al. [szs∗16].

3. categorization of machine learning techniques

currently used in visual analytics

the visual analytic community has developed systems that
leverage speciﬁc machine learning techniques. in this sec-
tion, we give an overview of the existing ways that machine
learning has been integrated into va applications from two
transversal perspectives: the types of ml algorithms and the
so-called interaction intent. we pay special attention to the
“interaction intent” as described below, because this focuses
on human-in-the-loop aspects that are central to va systems.
there are also other papers where the main role of visu-
alization is on communicating the results of computations
to improve comprehension [tjhh14] that are not directly
covered in this section. some of the most signiﬁcant of these
papers, referring to va systems, are described in section 4.

along the ﬁrst perspective, we consider the diﬀerent types
of ml algorithms that have been considered within visual an-
alytics literature. although one might think of several other

submitted to computer graphics forum (6/2018).

endert et al. / integrating machine learning into visual analytics

7

possible ways to categorize the algorithms [alp14, fht01],
here we adopt a high-level task-oriented taxonomy and cate-
gorize the algorithms under the following headings: dimension
reduction, clustering, classiﬁcation, regression/correlation
analysis. we observe that ml algorithms to tackle these
tasks are frequently adopted in visual analytics applications
since these analytical tasks often require the joint capabilities
of computation and user expertise. to brieﬂy summarize:
i) dimension reduction methods help analysts to distill the
information in high-dimensional data so that conventional vi-
sualization methods can be employed and important features
are identiﬁed ii) clustering methods help to identify groups
of similar instances which can be done both in a supervised
or unsupervised manner iii) classiﬁcation methods are often
supervised and help to build models to associate labels to
data instances, and ﬁnally iv) regression/correlation analysis
methods help to investigate relations between features in
the data and to understand/generate causal links to explain
phenomena.

within the domain of visualisation, we initiated our survey

starting with publications from the following resources:

journals: ieee transactions on visualization and com-
puter graphics, computer graphics forum, ieee computer
graphics and applications, information visualization

conferences: ieee visual analytics science and technol-
ogy (partially published as a special issue of ieee tvcg),
ieee symposium on information visualization (infovis)
(published as a special issue of ieee tvcg since 2006),
ieee paciﬁc visualization symposium (paciﬁcvis), eurovis
workshop on visual analytics (eurova)

within the domain of machine learning, we initiated our
survey starting with publications from the following re-
sources:

journals: journal of machine learning research, neuro-
computing, ieee transactions on knowledge and data en-
gineering

along the second perspective, we focus on the user side of
the process. we name this aspect as interaction intent and
categorize the actions taken by users within visual analysis
in terms of the methods through which the analyst tries to
improve the ml result.

conferences: international conference on machine learn-
ing (icml), acm sigkdd international conference on
knowledge discovery and data mining, european sympo-
sium on artiﬁcial neural networks, computational intelli-
gence and machine learning (esann)

this perspective of our taxonomy resonates with the “user
intent” categories suggested by yi et al. [yaksj07] for low-
level interactions within infovis applications. our focus,
however, is targeted on higher-level analytical intents within
the narrower scope of visual analytics applications that in-
volve ml methods. with this motivation in mind, we suggest
two broad categories for “intents”: modify parameters and
computation domain and deﬁne analytical expectations. table
1 shows the organization of literature along the dimensions
of algorithm type vs the two categories of user intent. here
we survey the existing literature within the scope of this
characterization.

3.1. review methodology

the literature summarized and categorized in this section
are taken from impactful ml and visualization conferences
and journals. they were chosen and categorized based on
discussions the authors had at the dagstuhl seminar titled,
“bridging machine learning with information visualization
(15101)” [kmrv15], and later reﬁned through a more exten-
sive literature review.

within this report, we review existing literature on the
integration of machine learning and visualisation from three
diﬀerent perspectives – models and frameworks, techniques,
and application areas. when identifying the relevant works
in these domains, we follow a structured methodology and
identiﬁed the diﬀerent scopes of investigation for these three
diﬀerent perspectives. one important note to make is, due
to our focus on the integration of the two ﬁelds, we scanned
resources from both the visualisation and machine learning
domain.

submitted to computer graphics forum (6/2018).

we then scanned the relevant papers identiﬁed in the
above resources and performed a backward and forward
literature investigation using google scholar. in producing
the taxonomy of works within section 3, we labelled the
publication both in terms of the analytical task and the
integration strategy incorporated.

3.2. modify parameters and computation domain

here we list techniques where interaction has been instru-
mental in modifying the parameters of an algorithm, deﬁning
the measures used in the computations, or even changing
the algorithm used. another common form of interaction
here is to enable users to modify the computational domain
to which the algorithm is applied. such operations are of-
ten facilitated through interactive visual representations of
data points and data variables where analysts can select
subsets of data and run the algorithms on these selections
within the visual analysis cycle to observe the changes in
the results and to reﬁne the models iteratively. the types
of techniques described in this section can be considered as
following a “direct manipulation” [shn83] approach where
the analysts explicitly interact with the algorithm before
or during the computation and observe how results change
through visualization.

dimension reduction one class of algorithms that is
widely incorporated in such explicit modiﬁcation strategy
is dimension reduction. since high-dimensional spaces are
often cognitively challenging to comprehend, combinations of
visualization and dimension reduction methods have demon-
strated several beneﬁts. johansson and johansson [jj09]
enable the user to interactively reduce the dimensionality

8

endert et al. / integrating machine learning into visual analytics

dimension
reduction

clustering

modify parameters &
computation domain
[jj09], [fja∗11], [fwg09], [sdmt16],
[wm04], [nm13], [tfh11], [tllh12],
[jbs08], [adt∗13], [jzf∗09]
[kan12], [rpn∗08], [sbtk08], [rk04],
[ss02], [lss∗12], [lsp∗10], [tls∗14],
[tprh11a], [aw12], [rpn∗08], [hscw13],
[tprh11b], [ptrv13], [hhe∗13], [wtp∗99],
[ynm∗13], [sgg∗14]

deﬁne
analytical expectations
[ehm∗11],
[ebn13], [blbc12],
[hbm∗13], [gnrm08], [ihg13],
[pzs∗15], [kcpe16], [kkw∗16]
[hog∗12], [cp13], [bdw08], [ccm08],
[kk08]
[bbm04], [abv14], [kkp05],

[kp11],

classiﬁcation [pes∗06], [mk08], [mbd∗11], [vdevw11],
[clkp10],

[kpb14], [aab∗10], [aar∗09],
[kgl∗15]
[pbk10], [mp13], [mme∗12], [tllh12],
[klg∗16]

regression

[set09], [sk10], [bkss14], [pspm15]

[mgjh08], [mgs∗14] [lkt∗14] [ykj16]

table 1: in section 3, we review the existing literature in visual analytics following a 2d categorization that organizes the
literature along two perspectives: algorithm type (rows) and interaction intent (columns).

of a data set with the help of quality metrics. the visually
guided variable ordering and ﬁltering reduces the complexity
of the data and provides the user a comprehensive control
over the whole process. the authors later use this methodol-
ogy in the analysis of high-dimensional data sets involving
microbial populations [fja∗11]. an earlier work that merges
visualization and machine learning approaches is by fuchs
et al. [fwg09]. the authors utilize machine learning tech-
niques within the visual analysis process to interactively
narrow down the search space and assist the user in iden-
tifying plausible hypotheses. in a recent paper, stahnke et
al. [sdmt16] devised a probing technique using interactive
methods through which analysts can modify the parameters
of a multi-dimensional scaling projection. the visualization
plays a key role here to display the diﬀerent dimension contri-
butions to the projections and to communicate the underlying
relations that make up the clusters displayed on top of the
projection results.

in mdsteer [wm04], an embedding is guided by user in-
teraction leading to an adapted multidimensional scaling of
multivariate data sets. such a mechanism enables the analyst
to steer the computational resources accordingly to areas
where more precision is needed. this technique is an early
and good example of how a deep involvement of the user
within the computational process has the potential to lead to
more precise results. nam and mueller [nm13] provide the
user with an interface where a high-dimensional projection
method can be steered according to user input. they provide
“key” computational results to guide the user to other relevant
results through visual guidance and interaction. turkay et
al. introduce the dual-analysis approach [tfh11] to support
analysis processes where computational methods such as
dimension reduction [tllh12] are used. the authors incor-
porate several statistical measures to inform analysts on the
relevance and importance of variables. they provide several

perspectives on the characteristics of the dimensions that
can be interactively recomputed so that analysts are able
to make multi-criteria decisions whilst using computational
methods. j¨anicke et al. [jbs08] utilize a two-dimensional
projection method where the analysis is performed on a pro-
jected 2d space called the attribute cloud. the resulting
point cloud is then used as the medium for interaction where
the user is able to brush and link the selections to other
views of the data. in these last group of examples, the capa-
bility to run the algorithms on user-deﬁned subsets of the
data through visually represented rich information is the key
mechanism to facilitate better-informed, more reliable data
analysis processes.

clustering clustering is one of the most popular algorithms
that have been integrated within visual analytics applications.
since visual representations are highly critical in interpreting
and comprehending the characteristics of clusters produced
by the algorithms, direct modiﬁcation of clustering algo-
rithms are often facilitated through interactive interfaces
that display new results “on-demand”. gcluto [rk04] is an
interactive clustering and visualization system where the au-
thors incorporate a wide range of clustering algorithms. this
is an early example where multiple clustering algorithms can
be run on-the-ﬂy with varying parameters and results can be
visually inspected. in hierarchical clustering explorer [ss02],
seo and shneiderman describe the use of an interactive dendo-
gram coupled with a colored heatmap to represent clustering
information within a coordinated multiple view system.

other examples include work accomplished using the ca-
leydo software for pathway analysis and associated experi-
mental data by lex et al. [lss∗12, lsp∗10]. in their tech-
niques, the authors enable analysts to investigate multiple
runs of clustering algorithms and utilize linked, integrated
visualizations to support the interpretation and validation

submitted to computer graphics forum (6/2018).

endert et al. / integrating machine learning into visual analytics

9

of clusters. along the same lines, turkay et al. present an
interactive system that addresses both the generation and
evaluation stages within the clustering process and provides
interactive control to users to reﬁne grouping criteria through
investigations of measures of clustering quality [tprh11a].
in a follow-up work [tls∗14], within the domain of clustering
high-dimensional data sets, integrated statistical computa-
tions are shown to be useful to characterize the complex
groupings that analysts encounter in such data sets. figure 7
demonstrates how the authors incorporated statistical analy-
sis results to indicate important features for data groups. in
this work, the most discriminative features (indicated with
red dots as opposed to blue ones that are less important)
for the clustering result of a high-dimensional data set are
represented as integrated linked views. the user is able to
select these features in one clustering result (e.g., within the
clustering result in the right-most column in figure 7) and
observe whether the same features are represented in others,
e.g., in the left-most column.

schreck et al. [sbtk08] propose a framework to interac-
tively monitor and control kohonen maps to cluster trajec-
tory data. the authors state the importance of integrating
the expert within the clustering process for achieving good
results. kandogan [kan12] discusses how clusters can be
found and annotated through an image-based technique. his
technique involves the use of “just-in-time” clustering and
annotation, and the principal role for visualisation and inter-
action is to aid the interpretation of the structures observed,
and provide a deeper insight into why and how particular
structures are formed.

an important role for visualization is to get the user
engaged in progressive and iterative generation of clus-
ters [rpn∗08]. in such approaches, the user is presented
with content that is built step-by-step and gains additional
insight in each iteration to decide whether to continue, alter,
or terminate the current calculations. such levels of inter-
activity, of course, require the solutions to be responsive
and capable of returning results within acceptable delays.
ahmed and weaver [aw12] address this problem through
forward-caching expected interaction possibilities and pro-
viding users with clustering results without breaking the
responsive analytical ﬂow.

visual analytics applications that involve clustering al-
gorithms within the analysis of complex dynamic networks
have also been developed [hscw13]. the use of visualisation
is in particular critical with such dynamic relational data
sets due to the limitations in interpreting the algorithmic
results; well-designed combinations of visual summaries can
assist analysts in this respect. in the domain of molecular
dynamics simulation, there are some examples of tight inte-
grations of interactive visualizations, clustering algorithms,
and statistics to support the validity of the resulting struc-
tures [tprh11b], [ptrv13].

classiﬁcation being a relevant and widely utilized tech-
nique, classiﬁcation algorithms have also found their place

submitted to computer graphics forum (6/2018).

within visual analytics applications. common roles for inter-
active visualization are ﬁltering the feature space, iteratively
observing and ﬁxing problems, and when the classiﬁcation
tasks involve multiple mediums such as space, time and
abstract features, providing multiple perspectives to the al-
gorithmic results.

a conceptual framework on how classiﬁcation tasks can
be supported by interactive visualizations is presented by
may and kohlhammer [mk08]. their approach improved the
classiﬁcation of data using decision trees in an interactive
manner. they proposed the use of a technique called kvmaps
to inform users on classiﬁcation quality thus enabling the it-
erative reﬁnement of the results. the authors later proposed
a technique called smartstripes [mbd∗11] where they inves-
tigated the relations between diﬀerent subsets of features and
entities. interactive visual representations have been used to
help create and understand the underlying structures within
decision trees [vdevw11]. the authors not only presented
the overall structure of decision trees, but also provided in-
tuitive visual representations of attribute importance within
the diﬀerent levels of the tree. such interactive visualizations
are critical in unraveling the computed information hidden
within the layers and can be quite instrumental in increasing
the trust in such computational models. similar insights can
be gained on other models (additive ones, e.g. naive bayes,
in [pes∗06] and more general ones in [sk10]) by explaining
individual classiﬁcation. in these papers, the authors display
the contribution of features to the classiﬁcation made by
the model and enable what-if scenarios, such “how would
the classiﬁcation change if this particular feature was set to
another value?”

in ivisclassiﬁer by choo et al. [clkp10], the authors
improve classiﬁcation performance through interactive visu-
alizations. their technique supports a user-driven classiﬁ-
cation process by reducing the search space, e.g., through
recomputing latent dirichlet allocation (lda) [bnj03] with
a user-selected subset of data deﬁned through ﬁltering in
additional coordinated views. klemm et al. [kgl∗15] investi-
gate the use of interactive visualisation to compare multiple
decision trees in investigating relations within non-image
and image based features for a medical application. they
visualise the quality aspects of classiﬁers to infer observations
on the predictive power of the features.

krause et al. [kpb14] address the important process of
feature selection within model building for classiﬁcation pur-
poses. through visual representations of cross-validation runs
for feature ranking with various algorithms, their method
supports the decisions made while including or excluding
particular features from a classiﬁcation model (see figure 8).
their approach enables users to be part of the predictive
model building process and, as also demonstrated by the
authors, leads to better performing/easier to interpret mod-
els. their methodology is based on producing glyphs for the
features of a data set to represent how important each one
is within a number of classiﬁcation models. in addition, the
glyphs are also used as elements for visual selections and

10

endert et al. / integrating machine learning into visual analytics

figure 7: visualization of clustering results, together with
associated on-the-ﬂy computations to identify discriminating
features of groups, are used here to aid analysts in interpreting
the clusters and reﬁning them further [tls∗14].

enable analysts to interactively apply modelling on subsets
of features.

classiﬁcation of spatio-temporal patterns is one of the
complex tasks that requires the involvement of user input
and eﬃcient algorithms due to the complex nature of struc-
tures found in such data sets. andrienko et al. [aab∗10]
investigate how self organizing maps (soms) are integrated
into the visual analysis process. they integrate a som ma-
trix where the user can interactively modify the parameters
and observe the changes in the results in various visual repre-
sentations, e.g., where space is represented in time, and the
time is represented in space. again involving spatio-temporal
data, an interactive process where a clustering algorithm
assists users to pick relevant subsets in building classiﬁers
has shown to be eﬀective in categorizing large collections of
trajectories [aar∗09].

regression identifying the multivariate relations within
data variables, in particular when their numbers are high,
is one of the critical tasks in most data analysis routines.
in order to evaluate to what degree observed relations can
be attributed to underlying phenomena and to build causal
interpretations, visual analytics approaches have shown good
potential. visualization has shown to be eﬀective in validat-
ing predictive models through interactive means [pbk10].
the authors visually relate several n-dimensional func-
tions to known models through integrated visualizations
within a model building process. they observed that such
a visualization-powered approach not only speeds up model
building but also increases the trust and conﬁdence in the
results. m¨uhlbacher and piringer [mp13] discuss how the
process of building regression models can beneﬁt from inte-
grating domain knowledge. berger et al. [bpfg11] introduce

figure 8: visual summaries to indicate the relevance of
features over cross-validation runs support analysts in making
informed decisions whilst selecting features for a classiﬁcation
model [kpb14].

an interactive approach that enables the investigation of
the parameter space with respect to multiple target values.
malik et al. [mme∗12] describe a framework for interactive
auto-correlation. this is an example where the correlation
analysis is tightly coupled with the interactive elements in
the visualization solution. correlation analysis has been in-
tegrated as an internal mechanism to investigate how well
lower-dimensional projections relate to the data that they
represent [tllh12]. the use of relational representations
here supports analysts to evaluate how local projection mod-
els behave in preserving the correlative structures in the data.
in a recent paper, klemm et al. [klg∗16] demonstrates the
use of visualisation to show all combinations of several inde-
pendent features with a speciﬁc target feature. the authors
demonstrate how the use of template regression models, inter-
actively modiﬁable formulas and according visual representa-
tions help experts to derive plausible statistical explanations
for diﬀerent target diseases in epidemiological studies.

3.3. deﬁne analytical expectations

unlike the papers in the previous category where the user
explicitly modiﬁes the parameters and the settings of an
algorithm, the works we review under this section follow a
diﬀerent strategy and involve users in communicating ex-
pected results to the computational method. in these types of
interactive methods, the user often observes the output of an
algorithm and tell the machine which aspect of the output
is inconsistent with the existing knowledge, i.e., correcting
the algorithm. furthermore, analysts can also communicate
examples of relevant, domain-knowledge informed relations
to be preserved in the ﬁnal result. since this is a relatively
recent approach to facilitate the interaction between the user
and the algorithms, the number of works in this category
is not as high as the previous section. in the following, we
review such works again under a categorization of diﬀerent
ml algorithm types involved. notice that integrating user
knowledge in this way in unsupervised learning contexts
falls into the general semi-supervised framework, which is a

submitted to computer graphics forum (6/2018).

endert et al. / integrating machine learning into visual analytics

11

principled way in ml for making unsupervised problems less
ill-posed.

dimension reduction dimension reduction algorithms
are suitable candidates for such approaches due to the often
“unsupervised” nature of the algorithms and the possibility
that errors and losses within the reduction phase are high,
in particular with datasets with high numbers of dimen-
sions. as one of the early works along these lines, endert
et al. [ehm∗11] introduce observation level interactions to
assist computational analysis tools to deliver more inter-
pretable/reliable results. the authors describe such oper-
ations as enabling the direct manipulation for visual ana-
lytics [ebn13]. in this line of work, the underlying idea is
to provide mechanisms to users to reﬂect their knowledge
about the data through interactions that directly modify
computational results. one typical interaction is through
moving observations in a projection such that the modi-
ﬁed version is more similar to the expectation of the an-
alyst [ehm∗11, blbc12]. this line of research has been
expanded to focus on the interpretability of linear [kcpe16]
and non-linear dr models [kkw∗16]. hu et al. [hbm∗13]
complemented such visualization level interaction methods
with further interaction mechanisms. the authors aim to
understand users’ interaction intent better and give them
mechanisms to also highlight preferences on unmoved points.

in their model-driven visual analytics system, garg et
al. [gnrm08] suggest the use of a ”pattern painting” mech-
anism that enables analysts to paint interesting structures in
the visualization which are then turned into logical rules that
can be fed into a projection algorithm to build an eﬀective
model.

an interesting supervised point of view has been proposed
in [ihg13] on the dimension reduction steering. the main
idea is to introduce an information theoretic criterion that
evaluates the uncertainty in the representation, considering
that the original high dimensional points are noisy. given
this criterion, the authors apply an active learning approach
to select points that are maximally informative: if the user
can move one of those points to its desired position, the
uncertainty of the representation will be maximally reduced
(compared to the reduction expected with other points). the
experimental evaluation shows that the optimal points tend
to be more uniformly distributed over the projected data
set than with other selection methods, possibly reducing
some of the drawbacks of active learning summarized in
e.g. [ackk14].

clustering there are a number of works where user knowl-
edge is incorporated to feed a clustering algorithm with
expected results. hossain et al. makes use of a scattergather
technique to iteratively break up or merge clusters to gen-
erate groupings that meet analysts’ expectations [hog∗12].
(see figure 9.) in their technique, the expert iteratively intro-
duces constraints on a number of required relations and the
algorithms take these constraints into consideration to gener-
ate more eﬀective groupings. the users state whether clusters

submitted to computer graphics forum (6/2018).

figure 9: scatter gather [hog∗12] is a technique to interac-
tively gather feedback from analysts in response to algorithmic
output and reﬁne user-generated constraints to improve the
clustering.

in the current segmentation should be broken up further or
brought back together. upon inspection of a clustering result,
the user interactively constructs a scatter gather constraint
matrix which represents a preferred clustering setting from
her perspective. the algorithm then considers this input
along with the clustering result to come up with an “op-
timized” result. in a number of papers, the user has been
involved even further to modify clustering results. in order
to support a topic modeling task through clustering, choo
et al. [cp13] enable users to interactively work on topic
clusters through operations such as splitting, merging and
also reﬁning clusters by pointing to example instances or
keywords.

more generally, clustering is one of the ﬁrst tasks of ma-
chine learning to include ways to take into account expert
knowledge, originally in the form of contiguity constraints
(see [mur85] for an early survey): the expert speciﬁes a prior
neighborhood structure on data points (for instance related
to geographical proximity) and the clusters are supposed to
respect this structure (according to some notion of agree-
ment). while the original methodology falls typically into
the oﬄine slow steering category, it has been extended to
more general and possibly online steering based on two main
paradigms for constraints clustering [bdw08]: the pairwise
paradigm (with must-link /cannot-link constraints) and the
triplet paradigm (with constraints of the form x must be
closer to y than to z).

an early example of the pairwise paradigm is provided
by [ccm08]. the authors describe a document clustering
method that takes into account feedback of the form: this
document should not belong to this cluster, this document

12

endert et al. / integrating machine learning into visual analytics

should be in this cluster, those two documents should be
(or should not be) in the same cluster (this mixes pointwise
constraints, with pairwise ones). active learning has been
integrated into this paradigm in [bbm04]. a variation over
the pairwise approach which consists in issuing merge and/or
split requests at the cluster level has been proposed and
studied in [abv14].

constraints based on triplet are more recent and were
proposed in the context of clustering by [kkp05,kk08]. the
main advantage of specifying triplet based constraints over
pairwise ones is that they allow relative qualitative feedback
rather than binary ones. they are also known to be more
stable than pairwise comparisons [kg90].

classiﬁcation classiﬁcation tasks are suitable for methods
where users communicate known/expected/wrong classiﬁ-
cation results back to the algorithm. the ideas employed
under this section show parallels to the active learning
methodologies develop in the ml literature [set09] where
the algorithms have capabilities to query the user for inter-
mediate guidance during the learning process. in their visual
classiﬁcation methodology, paiva et al. [pspm15] demon-
strates that eﬀective classiﬁcation models can be built when
users’ interactive input, for instance, to select wrongly la-
beled instances, can be employed to update the classiﬁcation
model. along the similar lines, behrisch et al. [bkss14]
demonstrate how users’ feedback on the relevance of fea-
tures in classiﬁcation tasks can be incorporated into decision
making processes. they model their process in an iterative
dialogue between the user and the algorithm and name these
stages as relevance feedback and model learning. this work
serves as a good example of how user feedback might lead to
better performing, ﬁt-for-purpose classiﬁcation models.

regression although examples in this category are limited
in numbers, deﬁning the “expected” has shown great poten-
tial to support interactive visual steering within the context
of ensemble simulation analysis [mgjh08, mgs∗14]. in their
steerable computational simulation approach, matkovic et
al. [mgjh08] demonstrate how a domain expert (an engineer)
can interactively deﬁne and reﬁne desired simulation outputs
while designing an injection system. their three-level steering
process enables the expert to deﬁne desired output values
through selections in multiple views of simulation outputs.
the expert then moves on to visually explore the control
variables of the simulation and assess whether they are feasi-
ble and reﬁne/re-run the simulation models accordingly. the
authors went on to incorporate a regression model within
this process to further optimise the simulation results based
on users’ interactive inputs [mgs∗14]. with this addition
to the workﬂow, the experts again indicate desired output
characteristics visually and a regression model followed by
an optimization supports the process to quickly converge to
eﬀective simulation parameters. the critical role that the
users play in these examples is to express their expert knowl-
edge to identify and communicate suitable solutions to the
algorithmic processes which in turn try and optimize for
those.

4. application domains

the integration of ml techniques into va systems has been
exempliﬁed in diﬀerent domains, described below. each of
these domains present unique and important challenges, thus
diﬀerent combinations of interactive visualizations and ml
techniques are used. some of these techniques are related to,
but go beyond the classiﬁcations in section 3. for instance,
dimension reduction, clustering, etc. since they must be
closely embedded in the va system and can be attached
to higher level meanings. however, most are relevant to the
deﬁne analytical expectations category in table 1. the
examples given in this section generally make use of one or
more technique categories in section 3, depending on the
particular domain for which the applications are designed
for.

4.1. text analytics and topic modeling

text corpora are frequently analyzed using visual analytic
systems. text is a data format that lends itself nicely to
speciﬁc computational processes, as well as human reasoning.
various text analytics methods have seen a lot of use in visual
analytics systems over the past 6-7 years. a main reason is
that these methods have proved useful in organizing large,
unstructured text collections around meaningful topics or
concepts. the text collections considered have been diverse
including research publications, wikipedia entries, streaming
social media such as twitter, facebook entries, patents,
technical reports, and other types.

visual analytic tools have been used to support informa-
tion foraging by representing high-dimensional information,
such as text, in an easily comprehensible two-dimensional
view. in such views, the primary representation is one where
information that is relatively closer to other information is
more similar (a visualization method borrowed from cartogra-
phy [sku02]). these applications allow users to ﬁnd relevant
information and gain new insights into topics or trends within
the data. an early example of combining machine learning
with visual analytics for analyzing text is a system called in-
spire [wtp∗99]. one of the views of the system, the galaxy
view shown in figure 10, displays documents clustered by
similarity. using dimension reduction techniques, this view
encodes relative similarity as distance (documents near each
other are more similar). the high-dimensional representa-
tion of the text documents is created by keyword extraction
from each document (deﬁning a dimension), and weightings
on the keywords determined computationally using popular
methods such as tf-idf, etc. [recc10].

visual analytic tools have also been used to support syn-
thesis by enabling users to externalize their insights during
an investigation. in a spatial workspace where users can
manually manipulate the location of information, users build
spatial structures to capture their synthesis of the infor-
mation over time - a process referred to as “incremental
formalism” [sm99, sha∗01]. andrews et al. found that intel-
ligence analysts can make use of such spatial structures as

submitted to computer graphics forum (6/2018).

endert et al. / integrating machine learning into visual analytics

13

figure 10: in-spire [wtp∗99], a va system for text corpora. in-spire combines computational metrics with interactive
visualizations.

a means to externalize insights during sensemaking, manu-
ally placing relevant documents in clusters on a large, high-
resolution display [aen10]. additionally, they found that the
large display workspace promoted a more spatially-oriented
analysis. tools, such as i2 analyst’s notebook [i2], jigsaw’s
“tablet view” [sgl08], nspace2 [ekhw08, wsp∗06], an-
alyst’s workspace [an12], and others have also found it
helpful to provide users with a workspace where spatial rep-
resentations of information can be manually organized.

more recently, researchers have developed techniques such
as latent semantic analysis (lsa) for extracting and repre-
senting the contextual meaning of words [ld97]. lsa pro-
duces a concept space that could then be used for document
classiﬁcation and clustering. also, probabilistic topic models
have emerged as a powerful technique for ﬁnding semantically
meaningful topics in an unstructured text collection [bl09].
researchers from the knowledge discovery and visualization
communities have developed tools and techniques to support
visualization and exploration of large text corpora based
on both lsa (e.g., [dws∗12, cds09]) and topic models
(e.g., [iyu08, lzp∗09, wls∗10, ost∗10]).

the latent dirichlet allocation (lda) model of blei et
al. [bnj03], which represents documents as combinations
of topics that are generated, in the unsupervised case, au-
tomatically has proved particularly useful when integrated
in a visual analytics system. the lda model postulates a
latent topical structure in which each document is character-
ized as a distribution over topics and most prominent words
for each topic are determined based on this distribution.
each topic is then described by a list of leading keywords
in ranked order. when combined with va techniques, lda
provides meaningful, usable topics in a variety of situations
(e.g., [gs04, zc07, dwcr11]). recent developments in the
ml community provide ways to reﬁne and improve topic

submitted to computer graphics forum (6/2018).

models by integrating user feedback, e.g. moving words from
one topic to another [hbgss14].

there have been extensions of lda-based techniques and
other text analytics by investigating texts in the combina-
tion ¡topic, time, location, people¿. this permits the anal-
ysis of the ebb and ﬂow of topics in time and according
to location [dwcr11, dws∗12, lyk∗12]. time-sensitivity
is revealed not only in topics but in keyword distribu-
tions [dws∗12]. lately there has been work to add peo-
ple and demographic analysis as well [dce∗15]. combining
topic, time, and location analysis leads to identiﬁcation of
events, deﬁned as “meaningful occurrences in space and
time” [kbk11, dws∗12, cdw∗16, lyk∗12]. here the topic
analysis can greatly help in pinpointing the meaning. in
addition, combining topic modeling with named entity ex-
traction methods, such as lingpipe [20008], can greatly en-
hance the time, location, and even people structure since
these quantities can be automatically extracted from the text
content [mjr∗11, cdw∗16].

at this point,

it is worthwhile to describe a visual
analytics system that combines all these characteristics.
vairoma [cdw∗16] (shown in figure 11) creates a nar-
rative that tells the whole 3,000 year history of rome, the
empire, and the state of italy derived from a collection of
189,000 wikipedia articles. the articles are selected from the
nearly 5m english language article collection in wikipedia
using a short list of keyword, but otherwise the initial topic
modeling and named entity extraction are done automati-
cally. the interface for vairoma is displayed in figure 11.
the individual topics are depicted as color-coded streams in
the timeline view (a). the circular topic view in (c) pro-
vides a compact way of depicting topics, the weights of their
contributions for a given time range, and topic keywords.
the navigable map view in (b) provides immediate updates

14

endert et al. / integrating machine learning into visual analytics

of geographic distribution of articles (based on locating the
geographic entities in the text) in terms of hotspots for a
selected time range and topic. the window (f) lists article
titles for selected geographic view, time range, and topic. in
figure 11, one can clearly see event peaks for selected topics
having to do with roman government and military battles in
the period from 500 bc to 500 ad. the interlinked windows
in the interface plus key topics and event peaks permit a user
to quickly peruse the main events in ancient roman history,
including the rise of christianity and the catholic church,
trade with india and the far east, and other events that one
might not ﬁnd in looking narrowly at, say, just the history
of the roman empire. in this case, the user can focus from
thousands of articles to a few hundred articles overall, which
she can then quickly peruse. see the vairoma article for
more details.

vairoma shows the power of the overall model depicted
in figure 3. though it is not complete w.r.t. this model (no
current va system is), it provides an integrated approach
to data handling, interactive visualization, ml (in this case
topic modeling) combined with other techniques, and ex-
ploration and knowledge building techniques. it shows the
power of an integrated approach. the approach is general
and is now being applied to large, heterogeneous collections
of climate change documents. in addition, full text journal
article collections are being analyzed using extensions of the
topic modeling and entity extraction methods. this shows
that once ¡topic, time, location, people¿ features and event
signatures can be extracted, analyses based on these ana-
lytics products can integrate a wide range of heterogeneous
collections.

4.2. multimedia visual analytics

visual analytic applications have also been developed to
allow people to explore multimedia (i.e., images, video, au-
dio). for example, ivisclassiﬁer shows how facial expression
features can be incrementally explored and classiﬁed by
a combination of image feature-detection algorithms and
user feedback [clkp10]. through interactively adding and
removing images from classiﬁers, the model learns the fa-
cial expressions that are interesting (and similar) to the
user. it combines analytic models such as feature extraction
and classiﬁcation with visual analytic approaches. multi-
facet is another example of visually analyzing multimedia
data [hhe∗13]. multifacet presents facets of each data type
to users as interactive ﬁlters. thus, the process of interac-
tively selecting attributes of diﬀerent data types helps create
groups of conceptually interesting and related information.

as image and video data is often combined with text data
(or textual metadata attached to the images or videos), fus-
ing the feature space between these datatypes is an open
challenge. automated approaches are error-prone, and of-
ten require user intervention and guidance when semantic
concepts and relationship need to maintained across data
types [cbn∗12]. similarly, an example of a much more spe-
ciﬁc application is given in [bm13] where the authors present

a steering mechanism for source separation in a single mono-
phonic recording. the user can annotate a standard time-
frequency display to roughly deﬁne the diﬀerent sources.
errors made by the algorithm can be annotated to improve
further the separation.

4.3. streaming data: finance, cyber security,

social media

streaming data is a growing area of interest for visual ana-
lytics. data are no longer isolated and static, but instead are
part of a sensor-laden ecosystem that senses and stores data
at increasing frequencies. thus, visual analytic systems that
integrate machine learning models have great potential. ex-
amples of domains that generate streaming data include the
ﬁnancial industry, cyber security, social media, and others.

in ﬁnance, for example, finvis is a visual analytics sys-
tem that helps people view and plan their personal ﬁnance
portfolio [rse09]. the system incorporates uncertainty and
risk models to compute metrics about a person’s portfolio,
and uses interactive visualizations to show these results to
users. similarly, ziegler et al. presented a visual analytic sys-
tem to help model a user’s individual preferences for short,
medium, and long-term stock performance [znk08] and later
extended their approach to real-time market data [zjgk10].
figure 12 is an example of how visualisations can provide
an in-depth understanding of the groupings (clusterings) of
ﬁnancial time series. here, ﬁnancial market data for assets
in 3 countries and 28 market sectors from 2006 and 2009 are
depicted. the red bars indicate the crash of the stock market
in 2008 and the visualisation enables the user to identify the
overall changes but also notice subtle variations such as the
lack of a response in some countries for particular sectors.

cyber security is a domain fraught with fast data streams
and alerts. examples of machine learning techniques often
incorporated into systems that support this domain include
sequence and pattern-based modeling, rule-based alerting,
and others [bek14]. people in charge of the safety and relia-
bility of large networks analyze large amounts of streaming
data and alerts throughout their day, thus the temporal com-
ponent of making a decision from the analysis is emphasized.
for example, fisher et al. presented event browser, a vi-
sual analytic system for analyzing and monitoring network
events [fmk12]. their work emphasizes how diﬀerent tasks
of the analyst have to happen at diﬀerent time scales. that
is, some tasks are “real-time”, while others can be taken
“oﬄine” and performed for a longer duration of time. the
persistent updating of new data into the oﬄine tasks presents
challenges.

social media data can also be analyzed using visual an-
alytic systems. for example, storylines [zc07] and even-
triver [lyk∗12] are two examples of how visual analytic
applications can help people understand the evolution of
events, topics, and themes from news sources and social
media feeds. in these systems, similar machine learning tech-
niques are used as for text. however, the temporality of the
data is more directly emphasized and taken into account.

submitted to computer graphics forum (6/2018).

endert et al. / integrating machine learning into visual analytics

15

figure 11: overview of vairoma interface. the interface has three main views: timeline view (a), geographic view (b)
and topic view (c). a user-generated annotation is shown in the timeline view.

lu et al. [lkt∗14] showed how appropriate social media
analysis could have predictive power, in their case predicting
movie box oﬃce grosses from early word of mouth discus-
sion on twitter, youtube, and imdb. a dictionary-based
sentiment analysis was used along with analytics from the
r statistical computing environment and the weka machine
learning workbench. this permitted a choice of modeling in
terms of multivariate regression, support vector machines,
and neural networks. the paper promoted an integrated vi-
sual analytics approach where the interactive visualizations,
based on d3, permitted users to investigate comments and
sentiment, classify similar movies, and follow trends and
identify features. the user could then improve a base line
regression model based on trends and features identiﬁed in
the visaulizations. results of the use cases were positive
with several of the non-expert participants being able to
outperform experts in predicting opening weekend grosses
for 4 ﬁlms, according to the criteria set up by the authors.
the paper has the usual limitation of supervised learning
approaches in that a training dataset must ﬁrst be collected
and analyzed as a preliminary step, but it does successfully
allow for improvement of the analytic model within the va
environment. also, like many papers dealing with more com-
plex analysis, it deﬁnes a process for best use of the system;
this appears to be an important and eﬀective approach for
va + ml systems.

yeon et al. [ykj16] covered similar ground in their identi-
ﬁcation and analysis of interesting past abnormal events as
a precursor for predicting future events. here, as in lu et al.
and in other papers using ml, context and analytic power
is obtained from combining multiple sources (in this case
social media and news media). yeon et al. identify contextual
pattern in these past events, which permit them to make
predictions for future events in similar contexts. an interac-

submitted to computer graphics forum (6/2018).

figure 12: aggregated visual representations and clustering
have been used in supporting the real-time analysis of temporal
sector-based market data [zjgk10].

tive interface involving spatio-temporal depiction of events
plus identiﬁcation of other features permits the choosing of
interesting events and speciﬁcation of their contexts. trends
for the unfolding of future events and possible unfolding story
lines can then be created. the authors evaluated their va
system with three use cases.

4.4. biological data

biology, and in particular, bio-informatics are ﬁelds that are
increasingly becoming data-rich and the use of visualisation
empowered analysis methods are proving highly useful and
eﬀective [gob∗10]. although most computational analysis
solutions only incorporate visualization as a communication
medium and do not make use of interaction, there are a num-
ber of examples where va and ml approaches operate in
integration. within the context of epigenomic data analysis,
younesy et al. [ynm∗13] present how a number of ill-deﬁned
patterns and characteristics within the data can be identiﬁed
and analysed through the help of interactive visualizations

16

endert et al. / integrating machine learning into visual analytics

and integrated clustering modules. they demonstrate how
user-deﬁned constraints can be utilised to steer clustering
algorithms where the results are compared visually. grottel
et al. [grve07] discuss how interactive visual representa-
tions can be instrumental in interpreting dynamic clusters
within molecular simulations. in addition to these, interac-
tive visualisations have been shown to support bi-cluster
analysis [sgg∗14]. the authors utilize an interactive layout
where fuzzy bi-clusters are investigated for multi-tissue type
analysis. biclustering is an algorithmic technique to solve for
coordinated relationships computed from high-dimensional
data representations [mo04], and has been used in other
domains, including text analysis [snr14, smnr16, fsb∗13].

in addition to the above methods where the focus is mainly
on investigating clusters, there are also works where in-
teractively speciﬁed high-dimensional data projections are
utilised to characterize and compare diﬀerent cancer sub-
types [adt∗13]. in their tool called visne, the authors
demonstrate how user-driven, locally applied projections
preserve particular relations and they argue that such meth-
ods are instrumental in interpreting any multi-dimensional
single-cell technology generated data.

5. embedding steerable ml algorithms into

visual analytics

as discussed above at several points and categorized in sec-
tion 3, one area of research that has been recently attracting
much interest in the machine learning and data visualization
communities is the development of interactive approaches
binding visualizations to steerable ml algorithms. this goes
beyond typical interactive ml methods in that it places
interaction at the same level as visualization and ml, thus
producing a powerful extension of visual analytics. as ex-
plained in [van05], [psco09], interaction provides feedback
in the visualization process, allowing the user to manipulate
the parameters that deﬁne a visualization on the basis of
the knowledge acquired in previous iterations. in particu-
lar, low latency interaction with large update rates of the
visual display provides higher levels of user involvement in
the analysis [emj∗11], triggering low level attention and
processing mechanisms (such as tracking moving items),
where the user’s senso-motor actions have immediate ef-
fects in the displayed information. despite interaction mech-
anisms having extensively been discussed in the visualiza-
tion literature [van05], [psco09], the relationships between
these parameters and the resulting visualization are in most
cases of a simple nature, including changes of scale, displace-
ments, brushing, etc., specially for low latency interaction.
as pointed out in [vl13], hardly ever are complex interac-
tions or transformations based on intelligent data analysis
undertaken at this level. this fact is certainly surprising,
especially considering that ml is a mature discipline and the
power of today’s hardware, as well as programming languages
and libraries make it possible to use algorithms (or adapted
versions of them) as intermediates between the user actions
and the visualization, even at low latency levels.

the dr algorithms discussed in section 3, which con-
struct a mapping from a high dimensional input space onto
a typically 2d or 3d visualization space, would be partic-
ularly useful for extended va approaches. to build such
mappings, dr algorithms seek to preserve neighborhood
relationships among the items in both spaces, resulting in
representations that follow the so called “spatialization prin-
ciple” (based on the cartographic principle where closeness
≈ similarity [sku02]). placing similar items in close positions
results in highly intuitive arrangements of items in a visual
map that serves as a basis for developing insightful visual-
izations of high dimensional elements [ves99, kp11, ebn13].
moreover, the connection that dr mappings make between
something that can be “seen” and a high dimensional feature
space suggests using the visual map as a canvas where classi-
cal interaction mechanisms (zoom, pan, brushing & linking,
etc.) can be used to explore high dimensional data.

however, interaction can go far beyond this point by al-
lowing the user to steer the dr algorithm through the vi-
sualization by direct modiﬁcation of its parameters or by
making transformations on the input data. as discussed in
section 3, this idea has been explicitly formulated in [cp13]
as iteration-level interactive visualization, which aims at vi-
sualizing intermediate results at various iterations and let-
ting the users interact with those results in real time. in a
slightly more formal way, as shown in [dcv16], an interac-
tive dr algorithm –the argument can be extended to other
ml algorithms– can be considered as a dynamically evolving
system, driven by a context that includes the input data and
the algorithm’s parameters

˙y = f (y, u),

v = g(y)

(1)

where y is the internal state of the algorithm, v is the outcome
of the algorithm (e.g. a visualization), which depends on
the internal state, and u = {x, w} is a context vector that
contains the input data x and the algorithm parameters w.
in a general framework, the user will steer the algorithm
by manipulating w based on his/her knowledge acquired
from the visualization v. under a ﬁxed context u0 –i.e. no
changes in the input data or the algorithm parameters–, the
internal state y in model (1) will keep on changing until it
reaches convergence to a steady state condition 0 = f (y0, u0).
changes in the algorithms parameters w or in the input
data x will make the internal state evolve to a new steady
state condition 0 = f (y1, u1), and hence result in a new
visualization v1. for a continuous f (·) –typically for non-
convex algorithms, based on gradient descent approaches–
the representation v(t) will smoothly change, resulting in
animated transitions that provide a continuous feedback to
the user. despite the fact that this behavior opens a broad
spectrum of novel and advanced user interaction modes and
applications, this is still a rather unexplored topic.

many possibilities may arise from this approach, all based

on changes in diﬀerent elements of the context vector u:
• one fundamental subset of parameters that conveys a
great deal of user insight are the input data metrics, which

submitted to computer graphics forum (6/2018).

(cid:107)a(cid:107)ω =(cid:80)

(cid:80)

endert et al. / integrating machine learning into visual analytics

17

r

can be expressed as a weight matrix ω = (ωrs) being
s arωrsas, whose parameters are included
in w. prior knowledge on the relevance of features can
be easily considered allowing user-driven modiﬁcations in
the diagonal elements of ωii ⊂ w. an example related to
this idea is the ipca [jzf∗09], an interactive tool that
visualizes the results of pca analysis using multiple coor-
dinated views and a rich set of user interactions, including
modiﬁcation of dimension contributions. a similar idea on
the stochastic neighbor embedding algorithm (sne) was
also proposed in [dcp∗14].
• the user might also have insight on the similarities be-
tween items. in [blbc12], a system called dis-function was
developed, featuring dr visualization that allows the user
to modify the distance matrix dij = (cid:107)ai − aj(cid:107)ω between
items i, j, by moving points in the visualization based
on his/her understanding of their similarity, and see new
results after a recomputation of the projections with the
new metrics.
• also, prior knowledge on class information can be inserted
by the user, suggesting techniques to increase the similar-
ity of items belonging to the same class. in [pzs∗15] a
method is proposed to allow the user to include prior class
knowledge in the dr projections by extending the original
dataset with transformations of the original feature space
based on his existing class knowledge.
• finally, the input data x in model (1) may change with
time (x = x(t)), suggesting the use of idr on streaming
data to provide live visualizations v(t) that convey time
varying information; in this case, user interaction is possi-
ble through timeline sliders, making it possible to explore
how input data items and their relationships evolve in time
by moving back and forth in time.

these cases imply a substantially more advanced kind of
feedback to the user than traditional interaction mechanisms.
placing these capabilities in a visual analytics framework
greatly empowers them. as described in figures 2 and 3,
such a framework supports analytic reasoning, the discov-
ery of much deeper insights, and the creation of actionable
knowledge. the mere fact of being part of sensemaking and
knowledge feedback loops (a virtuous cycle) suggests that
there is huge potential and a broad spectrum of possibilities
in the integration of ml algorithms discussed in this paper,
where even the simplest ones may have multiplicative eﬀects.
for certain types of analysis, such as following animated tran-
sitions, this sort of interaction mechanism must be achieved
in a ﬂuid manner, with low latencies and fast update rates.
however, this is not necessarily required for all knowledge
generation and synthesis activities, as discussed next.

levels of interactive response a long-recognized up-
per threshold for latency in wimp and mobile interfaces
is 0.1 second. faced with higher latencies, users start to
lose the connection between their actions and the visual re-
sponse, commit more typing or selection errors, and become
frustrated [hb11]. this limit has also been discussed as an
upper threshold for coherent animations (though completely

submitted to computer graphics forum (6/2018).

smooth animations would require a lower latency) and for
a range of interactions in immersive vr. however, the de-
tailed eﬀects of particular latency thresholds depend on the
task. for embedded analytics tools in va systems, such as
steerable ml methods, it is useful to deﬁne a wider range of
interactive responses [rf16]:
• real-time regime: ¡ 0.1 second. interactions such as mov-
ing a time slider to control an animation of time-dependent
behavior or changing the weighting factors of leading di-
mensions in an interactive pca tool [jzf∗09] to reveal
changes in the projected surface fall into this regime. such
interactions can be employed for rapid exploration and
spotting of trends.
• direct manipulation regime: 0.1 to 2-3 seconds. analytic
reasoning tends to involve more complicated interlinking
of rich visualizations with ml methods. for example, the
vairoma geographic window shows multiple hierarchical
hotspot clusters (figure 11) when a time range and topic
are selected, but there is a delay of 2-3 seconds before the
result is displayed. the user must peruse this distribution
and its areas of concentration, which can take several
seconds or more. during interface evaluation the delay was
not noted and does not seem to hinder the user’s reasoning
process [cdw∗16], perhaps because the user is thinking
about the selection when it is made, and what it may
mean, which then ﬂows into her reasoning process once
the result appears. the same seems to be true when the
user makes a selection of a geographic region or a topic and
experiences a similar delay until updates in the timeline
or other linked windows appear.
• batch regime: 10 seconds or more. here the cognitive ﬂow
of human reasoning is interrupted. to minimize eﬀects of
this interruption, the best analytics at this level of response
might be those that launch a new reasoning direction (e.g.,
recalculation of textual topics based on a revised set of
keywords).

these levels of response are related to performance timings
from enactive cognition [gsfs06], suggesting that this model
can be applied here. an important conclusion of this discus-
sion is that it is not necessary to have real-time response
for certain interactive ml algorithms; delays up to 2-3 sec-
onds and perhaps more might be digestible by the user. this
could substantially reduce the burden of interactive response
for ml algorithms. of course, further user studies of these
algorithms in action should be carried out.

6. open challenges and opportunities for ml and

va

collaboration between ml and va can beneﬁt and drive
innovation in both disciplines. advances in ml can be used
by va researchers to create more advanced applications for
data analysis. this includes the optimization of currently
integrated techniques, but also the discovery of additional
techniques that ﬁt into the broad range of analytic tasks
covered by visual analytic applications [aes05, lpp∗06].
similarly, as advances are made in va applications, the user

18

endert et al. / integrating machine learning into visual analytics

requirements and needs can drive new ml algorithms and
techniques.

below, we list a collection of current challenge and oppor-

tunities at the intersection of ml and va.

6.1. creating and training models from user

interaction data

ml models are typically built and modiﬁed based on ample
training data that contain positive and negative ground truth
examples. while many domains and tasks can be solved with
ample training data, there exist scenarios, as discussed in this
paper, where not enough training data is available. for these
cases, it becomes important to incorporate user feedback
into the computation in order to guide and parametrize the
computational model being used. this raises the challenges
of how to incorporate user feedback into computation in an
eﬀective and expressive, yet usable manner?

the concept of interactive machine learning has taken into
account user feedback to steer and train these models. for
example, users can provide positive or negative feedback to
give support for or against suggestions or classiﬁcations made
by the model. the models adjust over time based on this
input.

however, there is the ability to look beyond labeling, or
conﬁrming and refuting suggestions as way to incorporate
user feedback [ecnz15] - what about the remaining user
interaction that people perform during visual data explo-
ration? user interaction logs contain rich information about
the process and interests of the user. examples of the kinds
of inferences that can be made from the user interaction
logs are shown in more detail earlier in the report. thus,
the opportunity exists for ml techniques to leverage the
real-time user interaction data generated from the analysts
using the system to steer the computation.

systems that take into account a broader set of user inter-
actions enable people more expressivity in conveying their
mental model, preferences, and subject matter expertise. fur-
ther, taking into account the broader set of user interaction
allows users of the system to stay more engaged in the act
of visual data exploration, as opposed to actively training
the model and system.

figure 13 shows a model for how multiple types of user
input can be incorporated into the machine learning mod-
els driving visual analytic techniques. as is shown in this
model, two broad types of models can be created from user
interaction: data models and user models. in general, data
models refer to weighted data items and attributes. these
can be weighted computationally, or via user feedback. fur-
ther, these weights can be computed based on inferences
on the user interaction (i.e., to approximate user interest
of focus). user models typically refer to computational ap-
proximations of the state of the user (e.g., cognitive load,
personality traits [boz∗14], etc.)

in addition to steering existing models (such as dimension

figure 13: a model from [ecnz15] showing how multiple
types of user input can be used to steer machine learning
models in va.

reduction models, topic models, etc.), such user feedback can
indicate the need for novel models to be created. by focusing
on the user interaction, new discoveries can be made about
the processes and analytic tasks of people during data analy-
sis. this continued study, or science of, interaction [psco09]
can lead to advances in the machine learning community in
the way of new algorithms or techniques that model analytic
tasks or processes of people.

6.2. balancing human and machine eﬀort,

responsibility, and tasks

for mixed-initiative systems, it is a common notion that
there exists a balance of eﬀort between the user and the
machine [hor99]. this eﬀort can be divided by decomposing
the larger task into sub-tasks that are either better suited
to the person, or more quickly performed by the system.
similarly, these tasks often break down into being more well-
deﬁned and quantitative (i.e., solved by computation), or
subjective and less formally deﬁned (and thus needing input
from the user). for example, a mixed-initiative visual analytic
system for grouping and clustering can take into account the
exemplar data items that are grouped by the user, generate a
data model from those examples, and organize the remaining
data points [dfb11].

however, there remains the need for generalizable empirical
evidence to inform researchers about how to balance this
eﬀort between the user and the machine. it is not clear the
extent to which tasks should be divided, or co-completed.
typical data analysis sessions involve many user tasks and
sub-tasks [aes05], and dividing the eﬀort of these tasks
between the user and the system is challenging.

it is also unclear exactly how to measure the amount of ef-
fort expended by both the user and the system. for example,
in a visual analytic system that helps people cluster docu-
ments, endert et al. used a measure of how many documents
were moved and grouped by the user and how many were
automatically grouped by the system [efn12a]. however,

submitted to computer graphics forum (6/2018).

endert et al. / integrating machine learning into visual analytics

19

there exist opportunities to consider additional metrics for
the balance of eﬀort in mixed-initiative systems that can
drive the possibility of novel evaluations of eﬀectiveness.

6.3. complex computation systems can lead to

automation surprise

by coupling machine learning with visual analytics systems,
we can develop complex systems made up of many inter-
related and inter-dependent “black boxes” of automated com-
ponents for data analysis, knowledge discovery and extraction.
complex systems will typically comprise many instances of
known and hidden inter-dependencies between components
and yield outputs that are emergent where the interactions
among agents and individual units may be deterministic.
the global behaviour of the system as a whole may conform
with rules that are only sometimes deducible from knowledge
of the interactions and topology of the system. this makes
it diﬃcult to know exactly which inputs contribute to an
observed output, and the extent of each factor’s contribu-
tions [ss11, orm]. sarter and woods [swb97] observed that
interactions between these tightly coupled automated “black
boxes” can create consequences and automation surprises
that arise from a lack of awareness of system state and the
state of the world. this creates potential for error, compla-
cency from trusting the technology, placing new demands on
attention, coordination and workload.

at the risk of saying the obvious, an approach proposed
by norman [nor86] to address some of the problems of
controlling complex systems is based on observability and
feedback. they are crucial for ﬁguring out how a system
works, and they help us aﬃrm the mental models that drive
our thinking and analysis of a problem or a device. poor
observability of automated advanced intelligent processes
makes it diﬃcult to evaluate if outcomes from the automated
computations are within the bounds of normal or acceptable
behavior, or whether our instructions to the system were
correctly executed or what else was included in the execution
that was not intended. good mapping between designed
action and desired action helps us anticipate and learn how
to interact with the system. good mapping also helps us see
the connection between what the system was instructed to
do, and the outcome of carrying out that instruction.

one of the major challenges then, is for visual analytics
designers to create designs that “... facilitate the discovery
of meaningfulness of the situation ... not as a property of the
mind, but rather as a property of the situation or functional
problems that operators are trying to solve ... [by] develop-
ing representations that specify the meaningful properties
of a work domain ... so that operators can discover these
meaningful properties and can guide their actions appropri-
ately” [bf11].

to create such a design, there is a need to have a conception
of the analytical thinking and reasoning process that extends
beyond the information handling and manipulation aspects
that are frequently described. a focus group study with 20

submitted to computer graphics forum (6/2018).

figure 14: characterizing the thinking terrain of ana-
lysts [won14].

intelligence analysts [wv12], think-aloud studies with 6 an-
alysts performing a simulated intelligence task [rawc14],
and think-aloud studies with 6 librarians carrying out a
surrogate task of creating explanations from a literature
review task [kaw∗13] provide insight into this analytical
thinking and reasoning process. the results of these studies
indicate that analyst make use of the various inference mak-
ing strategies described in section 2.1 - induction, deduction
and adduction - depending upon what data they have, the
rules for interpreting the data, and premise they are starting
with and the conclusions they would make or would like to
make. furthermore, very often they would test the validity of
the propositions they arrive at by practicing critical thinking
- where they attempt to assess the quality and validity of
their thinking and the data they use, the criteria they use for
forming judgments, and so forth. in fact, critical thinking is
so important that many intelligence analysis training schools
have introduced it into their training.

one thing else that is observed to happen alongside all
of this is somewhat more subtle: analysts are constantly
trying to explain the situation, sometimes re-constructing
the situation from pieces of data and from inferential claims;
and then carrying out searches or further analysis to ﬁnd
necessary data back the claims. this process of explana-
tion is crucial to making sense and how it is used to link
data, context and inferences. it often starts oﬀ as a highly
tentative explanation that is based on very weak data or
hunches. the analyst then explores this possibility, making
conjectures, suppositions and inferential claims, from which
they then connect with further data (testing their relevance
and signiﬁcance), elaborate, question, and often reframe and
discard, their ideas, and eventually building up the story
so that it eventually becomes robust enough to withstand
interrogation.

we see a progression - not necessarily in a linear manner
- where explanations reﬂect tentative, creative and playful,
and generative thinking, and then transitions towards think-
ing strategies that are more critical, evaluative, deliberate
and ﬁnal (see figure 14 for an illustration depicting this

20

endert et al. / integrating machine learning into visual analytics

discussion). one can assume a continuum where at one end
we have a tentative explanation we call a “loose story” that
accounts for the data, and at the other end the loose story
has evolved into a strong and more formal argument such
that it is rigorous and able to withstand interrogation, say,
in a court of law.

at the “formal argument” end of the continuum, there is
much lower uncertainty. the analyst is more deﬁnite about
what the data and their relationships mean, and very likely
has become more committed to a particular path of investiga-
tion. at this end, the emphasis is on verifying that the data
used to construct the conclusions, the claims being made
based on the data, and the conclusions themselves, are valid.

the combined machine learning and visual analytics tools
to be built should ﬂuidly link the generative, creative, play-
ful and tentative exploration activities that encourage the
exploration of alternatives, appreciation of the context, and
the avoidance of pre-mature commitment, with the more
evaluative, critical inquiry that leads to a deliberate, ﬁnal
and rigorous explanation. this is the notion of the design
principle of ﬂuidity and rigour.

6.4. visualizing intermediate results and

computational process

many kinds of ml algorithms undergo a continuous con-
vergence process towards the ﬁnal solution. in general, only
this ﬁnal solution is rendered into a visualization, which may
incorporate classical interaction mechanisms (zoom, pan,
brushing, focus&context, etc.). this convergence is often
done within a ﬁxed context, that includes the training set,
the algorithm parameters and the cost function. these ele-
ments often convey a large amount of insight for the user,
but since they remain ﬁxed during convergence users are
deprived of the beneﬁts of interaction. what if the user could
steer these ﬁxed elements “during” convergence?.

a promising topic, involving innovation by both va and
ml communities, is rendering visualizations of the intermedi-
ate results during convergence, allowing the user to tunesteer
the ml algorithms by changing these elements. designing ad
hoc ml algorithms with this approach in mind that pave the
way for new and useful kinds of interaction mechanisms opens
new and exciting research paths. there has been some prior
work on this topic. for example, stolper et al. developed a
system for progressive visual analytics, where intermediate
results of a sequence-mining algorithm running on medical
treatment events can be shown to clinicians [spg14]. their
work gave analysts the ability to see broader results sooner
to help decide if the entire computation needed to be ex-
ecuted. similarly, systems to show partial query results of
large datasets [fpds12] and partial dimension reduction and
clustering results [tkbh17] have been recently developed..
these works raise important questions about the tradeoﬀ
between accuracy and execution time of these algorithms,
and also about how to incorporate user feedback into com-
putation during runtime.

6.5. enhancing trust and interpretability

a key element of the visualization approach is its ability
to generate trust in the user. unlike pure machine learn-
ing techniques, in a data visualization the user “sees” the
data and information as a part of the analysis. when the
visualization is interactive, the user will be part of the loop
and involved in driving the visualization. in such a context,
the development of a mental model goes hand in hand with
the visualization, as everything is part of the process. this
tight involvement of the user in the development of the visu-
alization based on the results of previous iterations, along
with the highly visual component of human thinking, can
make this approach generate a great amount of trust in the
user. however, such “trust” can have diﬀerent meanings at
diﬀerent levels of cognition. an apparently trustable result
at an intuitive level can arouse suspicions at a higher cog-
nitive level, demanding methods for statistical conﬁrmation
of the results. on a broad view, two diﬀerent levels can be
identiﬁed:

1. a “qualitative level”, that would make heavy use of percep-
tion visualization principles along with interaction mech-
anisms to present data in an intuitive way. the commu-
nication in both senses (from and to the interface) will
typically seek to: a) adapt to individual’s perception mech-
anism so that the information throughput and knowledge
increment on the user is maximized; and b) in a higher
level, to adapt to the human cognitive process so that data
and information is presented in a way that is intuitive
to the user. the means to carry out this approach would
rely on classical visualization methods (adequate use of
visual encodings and spatial layouts) and on interaction
techniques, including brushing, linking, coordinated views,
animated transitions, etc., but also in much more powerful
approaches such as user-driven steering of ml algorithms
(such as dr, clustering, etc.) resulting in the reconﬁgu-
ration of the visualization on the basis of changes in the
context such as time varying data or changes in the user
focus on diﬀerent types of analysis.

2. a “quantitative level” is, however, needed to provide sound
statistical validation of the former visualization results.
taken in an isolated way, this level would lack insight.
however, its outcomes are supposed to be trustworthy so
the user can consider them as deﬁnite validations. quanti-
tative approaches –mainly belonging to the realm of ml–
are in essence deterministic, which makes them less prone
to human errors and reproducible. this helps to stan-
dardize decisions and provides congruence, accurateness,
uniformity and coherence in the results.
however, quantitative approaches tend to avoid the need
for user intervention by trying to automate the process.
in general they do not look for human feedback but un-
dertake as many human tasks as possible in the process,
automating it to the maximum possible extent, aiming to
avoid any kind of human subjectivity and seeking rigor
(statistical, mathematical). but many problems in real
life are built on sparse bits of knowledge coming from
diverse domains. moreover, such knowledge is often made

submitted to computer graphics forum (6/2018).

endert et al. / integrating machine learning into visual analytics

21

of vague or imprecise mental models. purely quantitative
approaches cannot operate with such small, diverse and
“fuzzy” bricks; they need solid foundations to be operative.

the previous division is only conceptual. both approaches
can (and should) be combined. for instance, a statistical
validation of one or more facts can be displayed on top of the
qualitative visualization by making use of visual encodings
and text labels. we encourage visual analytics designers to
seek eﬃcient combinations between qualitative and quan-
titative approaches, looking for concurrent visualization of
actual problem data and sophisticated computed features,
both coexisting in the same representation. the mere fact of
representing statistical validations sharing the same layout
and structure as the original data in a same visualization
allows the user to internalize that quantitative information
allowing her to connect it to its domain knowledge, with an
unquestionable positive eﬀect on trust and conﬁdence in the
results.

6.6. beyond current methods

currently, many of the applications of machine learning in vi-
sual analytics relate to dimensionality reduction. in addition,
as discussed in section 4, there are a diﬀerent sort of ml
methods based on bayesian inferencing and including topic
modeling and textual analytics approaches. these are becom-
ing more prominent. while these applications are undeniably
an important use of machine learning, we contend that con-
sideration of the role of the user opens up several new ﬁelds
of study where machine learning can play an important role.
first amongst these is the role of machine learning in creating
a computational model for the user’s analytical process. this
complements cognitive task analysis and aims to model how
domain expert users use visual analytics to tackle important
tasks, and how they reason about the problem. this will
enable better system design to support expert strategies and
provide support to less-trained users.

every user interaction has two primary functions: i) to
communicate a direct explicit intent from the user to the
analytical system and receive an appropriate response (e.g.
if the user requests a zoom into a particular area, the system
should create that zoomed-in visual display), and ii) to carry
out an indirect implicit piece of analytical reasoning.

the point is that every user choice in the visual analytics
frame is equivalent to a statistical choice in the mathematical
frame: we need users to make appropriate choices that do
not invalidate the (implied) statistical analysis that they are
carrying out. motivated by the analysis of how users carry out
visual analytics, particularly the concepts of sense-making
and knowledge generation, the ﬁrst step to understanding
the details of this process is to compile a complete log of
users’ analytical process and the information that they record.
this is the base dataset that can be used for traceability,
responsibility and provenance: providing an argued case for
others (such as collaborators or managers) to critique and use
to make decisions. however, beyond this use, the database is

submitted to computer graphics forum (6/2018).

also a resource to mine in order to clarify the decisions that
are made in the course of visual analytics, leading to the
potential to develop adaptable interfaces and a greater depth
of understanding of users’ mental models, which can then
be used to guide other, perhaps less skilled or experienced,
users.

it would not be feasible (nor practically useful) to track
every single change in a visualisation. it is essential that
the process involves minimal interruption to cognitive ﬂow
(so as to avoid damaging the very process we are trying to
understand). however, it would be helpful to prompt the
user for feedback (preferably in visual ways), in the form of
annotations, at certain key points of the analysis. we propose
using machine learning (e.g. to look for breakpoints in the
way information is displayed) as cues for these prompts. the
process model can also learn from user interaction (with
appropriate additional guidance). for example, if the user
‘undoes’ a particular action, it could mean “i don’t want this:
my choice was wrong” or “the visualisation is useful, but it
is a dead end and i need to back-track”. other simple user
interactions that can connect to reasoning processes include
brushing data points (which corresponds to selecting and
labelling a subset of data) and linking (which corresponds
to hypothesising correlations between variables and data
points).

as a complement to this database of successful analytic
practice, what many users need is a way of avoiding bad
practice (or errors). a catalogue of ‘typical’errors that is
searchable (using case-based reasoning tools) could be crowd-
sourced from teachers (and their students!) or training
courses.

how can machine learning aid the understanding of user
processes? at the simplest level, user interactions are a linear
sequence of actions: discovering the underlying sequence and
the transitions between items is relatively straight-forward,
since a markov (or hidden markov) model can easily be
trained to uncover this structure. however, an unstructured
and unannotated sequential list does not contain enough
structure to infer the analytical process. firstly, we need to
understand the reasons why a user has made choices (which
requires annotations). secondly, it is clear that the analytical
process is not a simple sequence of logical choices leading
inexorably to a goal. instead, the process involves exploratory
analysis – trying a range of options and assessing which is
the most successful – and back-tracking when results show
that a particular line of inquiry is fruitless. these transform
what is, in terms of a graphical model, a one-dimensional
structure, into a tree or directed acyclic graph.

the theory of bayesian belief networks (bbns) is rele-
vant here. there are two aspects of the model that can be
learned: the conditional probability tables (cpts) for the
links from all the parents of a particular node; and the struc-
ture of the network (the presence or absence of directed links)
which represents the conditional (in)dependence of variables.
learning the cpts for a given network structure is straight-
forward: with suitably chosen bayesian priors (a dirichlet

22

endert et al. / integrating machine learning into visual analytics

distribution), it is a matter of counting co-occurrences of
value pairs in a dataset [sdlc93]. learning the structure of
a bbn is much more complex: in fact, the general case is np-
hard [chi96]. some special cases (such as trees) are tractable,
but in this domain it is preferable to ﬁx the structure based
on our understanding of the users’ analytical process. models
for this process, such as crisp-dm [wh00] (used in data
mining) or those drawn from the infovis community (such
as the semantic interaction pipeline), are currently rather
high-level, and a more detailed task analysis is necessary
before the requisite level of detail for a full computational
model can be achieved.

once a computational user model for the analytic process
is established, there are a number of other ways machine
learning and visual analytics can be brought into dialogue.

1. semi-automated report generation. machine learning can
be used to infer links and relations between concepts, data,
and analytical results, while frequentist or bayesian statis-
tical analysis can be used to attach a statistical signiﬁcance
to each ﬁnding. this could be presented to the user as a
checklist of automatically discovered analytical ﬁndings
(or hints) that the user can accept or reject.

2. annotations can be categorised using automated topic
analysis (for example by natural language processing that
uses probabilistic graphical models [lhe10]). the value
of this is to link annotations and ﬁnd common approaches
to tasks.

3. model-based layout. the goal

is to provide a semi-
automated way of modifying the layout of visual infor-
mation. one aspect of this is related to the steerable dr
discussed in section 5. this can be extended to learning
the criteria that analysts use: for example, how the user
selects principal components.

4. extreme value theory [dhf07] to identify low-frequency
(but potentially high-value) data points or variables. re-
cent research in this area supports the automated identiﬁ-
cation of outliers even in the multivariate case.

5. integrated prior knowledge and data. often the expert
user will have a great deal of prior cognitive knowledge
embodied in a computational model of a physical system
(e.g. geochemists supporting hydrocarbon exploration; me-
teorologists). machine learning can be used to generate an
emulator, a technique for model reduction that reduces the
exceptionally high computational burden imposed by many
physical models, while retaining the key features of the
original model and allowing much greater user interaction
for tasks such as sensitivity analysis and control [co10].

it is clear from the discussion throughout this paper that
there are barriers to the closer integration of machine learning
and visual analytics. one of the main technical barriers is
that the current software tools are strongly divided between
the research communities. visualization tools are strong
at close control over the form and layout of information,
and user interaction: some tend to be written as bespoke
integrated tools, such as tableau (http://www.tableau.com),
orange (orange.biolab.si) and jmp (www.jpm.com). on the
other hand, the most advanced machine-learning tools are

often written as libraries in numerical or statistical languages
(such as matlab, e.g. [nab02] and r), as well, as in high level
general purpose languages, like java (with weka, a widely
used collection of ml algorithms for data mining tasks, or
the stanford nlp tools with advanced ml algorithms for
natural language processing) or python (with powerful and
widely adopted data analysis and ml libraries like scipy,
scikit-learn, pandas, etc.); all of them focus on supporting
the (often) challenging task of learning complex models from
data but provide limited graphical display and interaction.
the best solution to this problem, short of reimplementing
large toolkits in other languages is to take a client-server
approach: a backend server running a good mathematical
package for the machine-learning components complemented
by web services and html+js clients, able to take advantage
of the huge and growing spectrum of javascript libraries and
frameworks (such as d3js) to provide interactive information
visualisation.

7. conclusions

this paper provides a comprehensive survey of machine learn-
ing methods, and visual analytics systems that eﬀectively
integrate machine learning. based on this survey, we present
a set of opportunities that oﬀer a rich set of ideas to further
the integration between these two scientiﬁc areas. among
these are formalizing and establishing steerable ml, gener-
ally providing coupled interaction and visualization methods
that oﬀer substantially more advanced user feedback. there
is the opportunity to better determine how tasks should be
divided between humans and machines, perhaps in a dynamic
manner, including determining metrics for a balance of eﬀort
between these two components. the paper shows how recent
models and frameworks could be used to develop consider-
ably more powerful visual analytic systems with integrated
machine learning. the summary and discussion presented
in this paper seeks to excite and challenge researchers from
the two disciplines to work together to tackle the challenges
raised, ultimately creating more impactful systems to help
people gain insight into data.

8. acknowledgments

the authors would like to acknowledge that much of the
content and inspiration for this paper originated during a
dagstuhl seminar titled, “bridging machine learning with
information visualization (15101)” [kmrv15]. in addition,
funding for the authors was provided in part by the analysis
in motion initiative at pnnl, spanish ministry of economy
& competitivity and feder funds, under grant dpi2015-
69891-c2-2-r

9. author bios

alex endert is an assistant professor in the school of
interactive computing at georgia tech, where he directs
the visual analytics lab. in 2013, his work on semantic
interaction was awarded the ieee vgtc vpg pioneers

submitted to computer graphics forum (6/2018).

endert et al. / integrating machine learning into visual analytics

23

group doctoral dissertation award, and the virginia tech
cs best dissertation award.

william ribarsky is the bank of america endowed chair
and director of the charlotte visualization center at unc
charlotte. he is one of the founders of the ﬁeld of visual
analytics and was chair of the ieee visualization analytics
science and technology (vast) steering committee until
october, 2015.

cagatay turkay is a lecturer (assistant prof.) at the de-
partment of computer science at city, university of london.
he carries out his research at the gicentre and develops
methods where interactive visualisations and computational
tools are used in tandem for informed analysis processes.

william wong is a professor of human-computer inter-
action at middlesex university, london. he is the head of
the interaction design centre. his research interest include
investigating the problems of visual analytics in sense-making
domains with high information density, such as intelligence
analysis, ﬁnancial systemic risk analysis, and low literacy
users.

ian nabney is a professor at aston university. he is di-
rector of the system analytics research institute. his re-
search interests are in machine learning, particularly in data
visualisation, time series, and bayesian methods. his appli-
cation interests are broad, and include condition monitoring,
biomedical engineering, and urban science.

ignacio d´ıaz blanco is an associate professor at the de-
partment of electrical engineering at the university of
oviedo. he researches in intelligent data analysis, data visual-
ization, control and signal processing to understand, diagnose
and optimize processes and complex systems.

fabrice rossi is a professor at paris 1 panth´eon sorbonne
university. he is a member of the samm research group and
the head of the statistical learning team of this group. his
research interests include machine learning and data analysis.
he is particularly interested in interpretable systems.

references

[20008] alias-i. 2008. lingpipe 4.0.1, 2008. url: http://

alias-i.com/lingpipe. 13

[aab∗10] andrienko g., andrienko n., bremm s., schreck
t., von landesberger t., bak p., keim d.: space-in-time
and time-in-space self-organizing maps for exploring spatiotem-
poral patterns. in computer graphics forum (2010), vol. 29,
wiley online library, pp. 913–922. 8, 10

[aar∗09] andrienko g., andrienko n., rinzivillo s., nanni
m., pedreschi d., giannotti f.: interactive visual clustering
of large collections of trajectories. in visual analytics science
and technology, 2009. vast 2009. ieee symposium on (2009),
ieee, pp. 3–10. 8, 10

[abv14] awasthi p., balcan m., voevodski k.: local algo-
rithms for interactive clustering. in proceedings of the 31st
international conference on machine learning (2014), xing
e. p., jebara t., (eds.), vol. 32 of jmlr proceedings, jmlr.org,
pp. 550–558. 8, 12

submitted to computer graphics forum (6/2018).

[ackk14] amershi s., cakmak m., knox w. b., kulesza
t.: power to the people: the role of humans in interactive
machine learning. ai magazine 35, 4 (2014), 105–120. 5, 11

[adt∗13] amir e.-a. d., davis k. l., tadmor m. d., si-
monds e. f., levine j. h., bendall s. c., shenfeld d. k.,
krishnaswamy s., nolan g. p., pe’er d.: visne enables
visualization of high dimensional single-cell data and reveals
phenotypic heterogeneity of leukemia. nature biotechnology 31,
6 (2013), 545–552. 8, 16

[aen10] andrews c., endert a., north c.: space to think:
large high-resolution displays for sensemaking. in proceedings
of the sigchi conference on human factors in computing
systems (2010), acm, pp. 55–64. 13

[aes05] amar r., eagan j., stasko j.: low-level components
of analytic activity in information visualization. in ieee sym-
posium on information visualization, 2005. infovis 2005
(2005), pp. 111–117. doi:10.1109/infvis.2005.1532136. 17,
18

[alp14] alpaydin e.: introduction to machine learning. mit

press, 2014. 7

[an12] andrews c., north c.: analyst’s workspace: an
embodied sensemaking environment for large, high-resolution
displays. in 2012 ieee conference on visual analytics science
and technology (vast) (2012), pp. 123–131. doi:10.1109/
vast.2012.6400559. 13

[anc12] ancona d.: framing and acting in the unknown. s.
snook, n. nohria, & r. khurana, the handbook for teaching
leadership (2012), 3–19. 2

[aw12] ahmed z., weaver c.: an adaptive parameter space-
filling algorithm for highly interactive cluster exploration.
in procedings of ieee symposium on visual analytics science
and technology (vast) (2012). 8, 9

[bbm04] basu s., banerjee a., mooney r. j.: active
semi-supervision for pairwise constrained clustering.
in
proceedings of the 2004 siam international conference on
data mining (2004), pp. 333–344. url: http://epubs.siam.
org/doi/abs/10.1137/1.9781611972740.31,
arxiv:http:
//epubs.siam.org/doi/pdf/10.1137/1.9781611972740.31,
doi:10.1137/1.9781611972740.31. 8, 12

[bdw08] basu s., davidson i., wagstaff k.: constrained
clustering: advances in algorithms, theory, and applications.
crc press, 2008. 8, 11

[bek14] best d. m., endert a., kidwell d.: 7 key chal-
lenges for visualization in cyber network defense. in pro-
ceedings of the eleventh workshop on visualization for cyber
security (new york, ny, usa, 2014), vizsec ’14, acm, pp. 33–
40. doi:10.1145/2671491.2671497. 14

[bf11] bennett k. b., flach j. m.: display and interface

design: subtle science, exact art. crc press, 2011. 19

[bh12] balcan m. f., hanneke s.: robust interactive learning.
in proceedings of the 25th annual conference on learning
theory (colt) (edinburgh, scotland, june 2012), vol. 23 of
jmlr workshop and conference proceedings. 5

[bkss14] behrisch m., korkmaz f., shao l., schreck t.:
feedback-driven interactive exploration of large multidimen-
sional data supported by visual classiﬁer. in visual analytics
science and technology (vast), 2014 ieee conference on
(2014), ieee, pp. 43–52. 8, 12

[bl09] blei d., lafferty j.: text mining: theory and appli-

cations, chapter topic models, 2009. 13

[blbc12] brown e. t., liu j., brodley c. e., chang r.:
dis-function: learning distance functions interactively. in vi-
sual analytics science and technology (vast), 2012 ieee
conference on (2012), ieee, pp. 83–92. 8, 11, 17

24

endert et al. / integrating machine learning into visual analytics

[bm13] bryan n. j., mysore g. j.: an eﬃcient posterior
regularized latent variable model for interactive sound source
separation. in proceedings of the 30th international conference
on machine learning (icml) (atlanta, georgia, usa, 2013),
dasgupta s., mcallester d., (eds.), vol. 28 of jmlr workshop
and conference proceedings. 14

[bnj03] blei d. m., ng a. y., jordan m. i.: latent dirichlet
allocation. the journal of machine learning research 3 (2003),
993–1022. 9, 13

[boz∗14] brown e. t., ottley a., zhao h., lin q., sou-
venir r., endert a., chang r.: finding waldo: learning
about users from their interactions. 18

[bpfg11] berger w., piringer h., filzmoser p., gr¨oller
e.: uncertainty-aware exploration of continuous parameter
spaces using multivariate prediction. computer graphics forum
30, 3 (2011), 911–920. 10

[cbn∗12] choo j., bohn s., nakamura g., white a. m.,
park h.: heterogeneous data fusion via space alignment using
nonmetric multidimensional scaling. in sdm (2012), siam,
pp. 177–188. 14

[ccm08] cohn d., caruana r., mccallum a.:

semi-
supervised clustering with user feedback. in constrained clus-
tering: advances in algorithms, theory, and applications, basu
s., davidson i., wagstaﬀ k., (eds.). crc press, 2008, ch. 2,
pp. 17–32. 8, 11

[cds09] crossno p. j., dunlavy d. m., shead t. m.:
lsaview: a tool for visual exploration of latent semantic model-
ing. in visual analytics science and technology, 2009. vast
2009. ieee symposium on (2009), ieee, pp. 83–90. 13

[cdw∗16] cho i., dou w., wang d. x., sauda e., ribarsky
w.: vairoma: a visual analytics system for making sense of
places, times, and events in roman history. visualization and
computer graphics, ieee transactions on 22, 1 (2016), 210–
219. 4, 13, 17

[chi96] chickering d. m.: learning bayesian networks is np-
complete. in learning from data. springer, 1996, pp. 121–130.
22

[chr06] chris n.: toward measuring visualization insight. 6–9.

doi:10.1109/mcg.2006.70. 2

[clkp10] choo j., lee h., kihm j., park h.: ivisclassiﬁer:
an interactive visual analytics system for classiﬁcation based
on supervised dimension reduction. in visual analytics science
and technology (vast), 2010 ieee symposium on (2010),
ieee, pp. 27–34. 8, 9, 14

[cms99] card s. k., mackinlay j. d., shneiderman b.:
readings in information visualization: using vision to think.
morgan kaufmann publishers inc., 1999. 2

[co10] conti s., ohagan a.: bayesian emulation of com-
plex multi-output and dynamic computer models. journal of
statistical planning and inference 140, 3 (2010), 640–651. 22

[cp13] choo j., park h.: customizing computational meth-
ods for visual analytics with big data. computer graphics
and applications, ieee 33, 4 (2013), 22–28. doi:10.1109/mcg.
2013.39. 8, 11, 16

[dce∗15] dou w., cho i., eltayeby o., choo j., wang x.,
ribarsky w.: demographicvis: analyzing demographic infor-
mation based on user generated content. in visual analytics
science and technology (vast), 2015 ieee conference on
(2015), ieee, pp. 57–64. 13

[dcp∗14] d´ıaz i., cuadrado a. a., p´erez d., garc´ıa f. j.,
verleysen m.: interactive dimensionality reduction for vi-
sual analytics. in european symposium on artiﬁcial neural
networks, computational intelligence and machine learning
(bruges, belgium, 2014). 17

[dcv16] d´ıaz i., cuadrado a. a., verleysen m.: a state-
space model on interactive dimensionality reduction. in euro-
pean symposium on artiﬁcial neural networks, computational
intelligence and machine learning (bruges, belgium, april
2016), verleysen m., (ed.), pp. 647–652. 16

[dfb11] drucker s. m., fisher d., basu s.: helping users
sort faster with adaptive machine learning recommendations.
springer-verlag, pp. 187–203. 18

[dhf07] de haan l., ferreira a.: extreme value theory: an

introduction. springer science & business media, 2007. 22

[dwcr11] dou w., wang x., chang r., ribarsky w.: par-
alleltopics: a probabilistic approach to exploring document col-
lections. in visual analytics science and technology (vast),
2011 ieee conference on (2011), ieee, pp. 231–240. 13

[dws∗12] dou w., wang x., skau d., ribarsky w., zhou
m. x.: leadline: interactive visual analysis of text data through
event identiﬁcation and exploration. in visual analytics science
and technology (vast), 2012 ieee conference on (2012),
ieee, pp. 93–102. 13

[ebn13] endert a., bradel l., north c.: beyond con-
trol panels: direct manipulation for visual analytics. ieee
computer graphics and applications 33, 4 (2013), 6–13. doi:
10.1109/mcg.2013.53. 8, 11, 16

[ecnz15] endert a., chang r., north c., zhou m.: seman-
tic interaction: coupling cognition and computation through
usable interactive analytics. ieee computer graphics and ap-
plications 35, 4 (july 2015), 94–99. doi:10.1109/mcg.2015.91.
18

[efn12a] endert a., fiaux p., north c.: semantic interac-
tion for sensemaking: inferring analytical reasoning for model
steering. visualization and computer graphics, ieee trans-
actions on 18 (2012), 2879–2888. 12. doi:10.1109/tvcg.2012.
260. 18

[efn12b] endert a., fiaux p., north c.: semantic interac-
tion for visual text analytics. in proceedings of the sigchi
conference on human factors in computing systems (2012),
acm, pp. 473–482. 4, 5

[ehm∗11] endert a., han c., maiti d., house l., leman
s. c., north c.: observation-level interaction with statistical
models for visual analytics. in ieee vast (2011), pp. 121–
130. 8, 11

[ehr∗14] endert a., hossain m. s., ramakrishnan n.,
north c., fiaux p., andrews c.: the human is the
loop: new directions for visual analytics. journal of intel-
ligent information systems (jan. 2014), 1–25. doi:10.1007/
s10844-014-0304-9. 5

[ekhw08] eccles r., kapler t., harper r., wright w.:
stories in geotime. information visualization 7 (2008), 3–17.
1. doi:10.1145/1391107.1391109. 13

[emj∗11] elmqvist n., moere a. v., jetter h.-c., cernea
d., reiterer h., jankun-kelly t.: fluid interaction for in-
formation visualization. information visualization 10, 4 (2011),
327–340. 16

[ept∗05] elm w., potter s., tittle j., woods d., gross-
man j., patterson e.: finding decision support requirements
for eﬀective intelligence analysis tools. in proceedings of the hu-
man factors and ergonomics society annual meeting (2005),
vol. 49, sage publications, pp. 297–301. 2

[fht01] friedman j., hastie t., tibshirani r.: the elements
of statistical learning, vol. 1. springer series in statistics springer,
berlin, 2001. 7

[fja∗11] fernstad s., johansson j., adams s., shaw j.,
taylor d.: visual exploration of microbial populations. in
biological data visualization (biovis), 2011 ieee symposium
on (2011), pp. 127 –134. 8

submitted to computer graphics forum (6/2018).

endert et al. / integrating machine learning into visual analytics

25
[hbm∗13] hu x., bradel l., maiti d., house l., north c.,
leman s.: semantics of directly manipulating spatializations.
visualization and computer graphics, ieee transactions on
19, 12 (2013), 2052–2059. 8, 11

[fmk12] fischer f., mansmann f., keim d. a.: real-
time visual analytics for event data streams. in proceedings
of the 27th annual acm symposium on applied comput-
ing (new york, ny, usa, 2012), sac ’12, acm, pp. 801–
806. url: http://doi.acm.org/10.1145/2245276.2245432,
doi:10.1145/2245276.2245432. 14

[foj03] fails j. a., olsen jr d. r.:

interactive machine
learning. in proceedings of the 8th international conference on
intelligent user interfaces (2003), acm, pp. 39–45. 5, 6

[fp07] fu w.-t., pirolli p.: snif-act: a cognitive model of
user navigation on the world wide web. human–computer
interaction 22, 4 (2007), 355–412. 4

[fpds12] fisher d., popov i., drucker s., schraefel m.:
trust me, i’m partially right: incremental visualization lets
analysts explore large datasets faster. in proceedings of the
sigchi conference on human factors in computing systems
(new york, ny, usa, 2012), chi ’12, acm, pp. 1673–1682.
doi:10.1145/2207676.2208294. 20

[fsb∗13] fiaux p., sun m., bradel l., north c., ramakr-
ishnan n., endert a.: bixplorer: visual analytics with bi-
clusters. computer 46, 8 (2013), 90–94. 16

[fwg09] fuchs r., waser j., gr¨oller m. e.: visual hu-
man+machine learning. ieee tvcg 15, 6 (2009), 1327–1334.
8

[gb11] guillory a., bilmes j.: simultaneous learning and
covering with adversarial noise.
in proceedings of the 28th
international conference on machine learning (icml-11)
(new york, ny, usa, june 2011), getoor l., scheﬀer t., (eds.),
icml ’11, acm, pp. 369–376. 5

[gnrm08] garg s., nam j. e., ramakrishnan i., mueller
k.: model-driven visual analytics. in visual analytics science
and technology, 2008. vast’08. ieee symposium on (2008),
ieee, pp. 19–26. 8, 11

[gob∗10] gehlenborg n., o’donoghue s., baliga n., goes-
mann a., hibbs m., kitano h., kohlbacher o., neuweger
h., schneider r., tenenbaum d., et al.: visualization of
omics data for systems biology. nature methods 7 (2010),
s56–s68. 15

[grf09] green t. m., ribarsky w., fisher b.: building
and applying a human cognition model for visual analytics.
information visualization 8 (2009), 1–13. 1. doi:10.1057/
palgrave.ivs.2008.28. 4

[grve07] grottel s., reina g., vrabec j., ertl t.: visual
veriﬁcation and analysis of cluster detection for molecular dy-
namics. ieee transactions on visualization and computer
graphics 13, 6 (2007), 1624–1631. doi:http://dx.doi.org/10.
1109/tvcg.2007.70614. 16

[gs04] griffiths t. l., steyvers m.: finding scientiﬁc topics.
proceedings of the national academy of sciences 101, suppl 1
(2004), 5228–5235. 13

[gsfs06] gray w. d., sims c. r., fu w.-t., schoelles m. j.:
the soft constraints hypothesis: a rational analysis approach
to resource allocation for interactive behavior. psychological
review 113, 3 (2006), 461. 17

[gwhr01] gahegan m., wachowicz m., harrower m.,
rhyne t.-m.: the integration of geographic visualization
with knowledge discovery in databases and geocomputation.
cartography and geographic information science 28, 1 (2001),
29–44. 3

[hb11] hoober s., berkman e.: designing mobile interfaces.

” o’reilly media, inc.”, 2011. 17

[hbgss14] hu y., boyd-graber j., satinoff b., smith a.:
interactive topic modeling. machine learning 95, 3 (2014),
423–469. doi:10.1007/s10994-013-5413-0. 13

submitted to computer graphics forum (6/2018).

[hee06] heer j.: prefuse manual, 2006. url: http://prefuse.

org. 4

[hhe∗13] henry m. j., hampton s., endert a., roberts
i., payne d.: multifacet: a faceted interface for browsing
large multimedia collections. in 2013 ieee international
symposium on multimedia (ism) (dec. 2013), pp. 347–350.
doi:10.1109/ism.2013.66. 8, 14

[hog∗12] hossain m. s., ojili p. k. r., grimm c., m¨uller
r., watson l. t., ramakrishnan n.: scatter/gather clus-
tering: flexibly incorporating user feedback to steer clustering
results. visualization and computer graphics, ieee transac-
tions on 18, 12 (2012), 2829–2838. 8, 11

[hor99] horvitz e.: principles of mixed-initiative user inter-
faces. in proceedings of the sigchi conference on human
factors in computing systems (new york, ny, usa, 1999),
chi ’99, acm, pp. 159–166. doi:10.1145/302979.303030. 18
[hscw13] hadlak s., schumann h., cap c. h., wollenberg
t.: supporting the visual analysis of dynamic networks by
clustering associated temporal attributes. visualization and
computer graphics, ieee transactions on 19, 12 (2013), 2267–
2276. 8, 9

[i2]

i2 analyst’s notebook. url: http://www.i2inc.com/

products/analysts_notebook/. 13

[ihg13]

iwata t., houlsby n., ghahramani z.: active
learning for interactive visualization.
in proceedings of the
sixteenth international conference on artiﬁcial intelligence
and statistics, aistats 2013 (scottsdale, az, usa, april
2013), vol. 31 of jmlr proceedings, jmlr.org, pp. 342–
350.
url: http://dblp.uni-trier.de/db/conf/aistats/
aistats2013.html#iwatahg13. 8, 11

[iyu08]

iwata t., yamada t., ueda n.: probabilistic latent
semantic visualization: topic model for visualizing documents. in
proceedings of the 14th acm sigkdd international conference
on knowledge discovery and data mining (2008), acm, pp. 363–
371. 13

[jbs08]

j¨anicke h., b¨ottinger m., scheuermann g.: brush-
ing of attribute clouds for the visualization of multivariate data.
ieee transactions on visualization and computer graphics
(2008), 1459–1466. 8

[jj09]

johansson s., johansson j.: interactive dimensionality
reduction through user-deﬁned combinations of quality metrics.
visualization and computer graphics, ieee transactions on
15, 6 (2009), 993–1000. 7, 8

[jzf∗09]

jeong d. h., ziemkiewicz c., fisher b., ribarsky
w., chang r.: ipca: an interactive system for pca-based
visual analytics. computer graphics forum 28, 3 (2009),
767–774. doi:10.1111/j.1467-8659.2009.01475.x. 8, 17

[kan12] kandogan e.: just-in-time annotation of clusters,
outliers, and trends in point-based data visualizations.
in
visual analytics science and technology (vast), 2012 ieee
conference on (2012), ieee, pp. 73–82. 8, 9

[kaw∗13] kodagoda n., attfield s., wong b., rooney c.,
choudhury s.: using interactive visual reasoning to support
sense-making: implications for design. visualization and com-
puter graphics, ieee transactions on 19, 12 (2013), 2217–2226.
19

[kbk11] krstaji´c m., bertini e., keim d. a.: cloudlines:
compact display of event episodes in multiple time-series. vi-
sualization and computer graphics, ieee transactions on 17,
12 (2011), 2432–2439. 13

26

endert et al. / integrating machine learning into visual analytics

[kcpe16] kim h., choo j., park h., endert a.: interaxis:
steering scatterplot axes via observation-level interaction. vi-
sualization and computer graphics, ieee transactions on 22,
1 (jan 2016), 131–140. doi:10.1109/tvcg.2015.2467615. 8, 11
[kei02] keim d. a.: information visualization and visual data
mining. visualization and computer graphics, ieee transac-
tions on 8 (2002), 1–8. 1. 1

[kg90] kendall m., gibbons j. d.: rank correlation methods.

oxford university press, 1990. 12

[kgl∗15] klemm p., glaer s., lawonn k., rak m., vlzke
h., hegenscheid k., preim b.: interactive visual analysis of
lumbar back pain - what the lumbar spine tells about your life. in
proceedings of the 6th international conference on information
visualization theory and applications (visigrapp 2015)
(2015), pp. 85–92. doi:10.5220/0005235500850092. 8, 9

[kk08] kumar n., kummamuru k.: semisupervised clustering
with metric learning using relative comparisons. ieee trans-
actions on knowledge and data engineering 20, 4 (april 2008),
496–503. doi:10.1109/tkde.2007.190715. 8, 12

[kkp05] kumar n., kummamuru k., paranjpe d.: semi-
supervised clustering with metric learning using relative com-
parisons.
in fifth ieee international conference on data
mining (icdm’05) (nov 2005). doi:10.1109/icdm.2005.128.
8, 12

[kkw∗16] kwon b. c., kim h., wall e., choo j., park h.,
endert a.: axisketcher: interactive nonlinear axis mapping
of visualizations through user drawings. ieee transactions on
visualization and computer graphics (2016). 8, 11

[klg∗16] klemm p., lawonn k., glaßer s., niemann u.,
hegenscheid k., volzke h., preim b.: 3d regression heat map
analysis of population study data. visualization and computer
graphics, ieee transactions on 22, 1 (2016), 81–90. 8, 10

[kmh06a] klein g., moon b., hoffman r.: making sense
of sensemaking 1: alternative perspectives. ieee intelligent
systems 21, 4 (2006), 70–73. doi:10.1109/mis.2006.75. 3

[kmh06b] klein g., moon b., hoffman r.: making sense
of sensemaking 2: a macrocognitive model. ieee intelligent
systems 21, 5 (2006), 88–92. doi:10.1109/mis.2006.100. 3

[kmrv15] keim d. a., munzner t., rossi f., verleysen
m. (eds.):. bridging information visualization with machine
learning (dagstuhl seminar 15101) (dagstuhl, germany, 2015),
vol. 5, schloss dagstuhl–leibniz-zentrum fuer informatik. url:
http://drops.dagstuhl.de/opus/volltexte/2015/5266, doi:
http://dx.doi.org/10.4230/dagrep.5.3.1. 1, 7, 22

[kmsz06] keim d. a., mansmann f., schneidewind j.,
ziegler h.: challenges in visual data analysis. ieee com-
puter society. doi:10.1109/iv.2006.31. 1

[kp11] kaski s., peltonen j.: dimensionality reduction for
data visualization. ieee signal processing magazine 28, 2
(2011), 100–104. doi:10.1109/msp.2010.940003. 8, 16

[kpb14] krause j., perer a., bertini e.: infuse: interactive
feature selection for predictive modeling of high dimensional
data. visualization and computer graphics, ieee transac-
tions on 20, 12 (2014), 1614–1623. 8, 9, 10

[ks11] kang y.-a., stasko j.: characterizing the intelligence
analysis process: informing visual analytics design through
a longitudinal ﬁeld study.
in visual analytics science and
technology (vast), 2011 ieee conference on (2011), ieee,
pp. 21–30. 3

[ksf∗08] kerren a., stasko j., fekete j.-d., north
c., keim d., andrienko g., g¨org c., kohlhammer j.,
melanc¸on g.: visual analytics: deﬁnition, process, and
challenges.
in information visualization, vol. 4950 of lec-
ture notes in computer science. springer berlin / heidelberg,
2008, pp. 154–175. doi:10.1007/978-3-540-70956-5_7. 1

[ld97] landauer t. k., dumais s. t.: a solution to plato’s
problem: the latent semantic analysis theory of acquisition, in-
duction, and representation of knowledge. psychological review
104, 2 (1997), 211. 13

[lhe10] lin c., he y., everson r.: a comparative study
of bayesian models for unsupervised sentiment detection. in
proceedings of the fourteenth conference on computational
natural language learning (2010), association for computa-
tional linguistics, pp. 144–152. 22

[lhm∗11] leman s. c., house l., maiti d., endert a.,
north c.: a bi-directional visualization pipeline that en-
ables visual to parametric interation (v2pi). tech. rep., 2011.
fodava-10-41. 5

[li57] lonergan b. j., insight a.: a study of human under-

standing. new york 298 (1957). 2

[lkt∗14] lu y., kr¨uger r., thom d., wang f., koch s.,
ertl t., maciejewski r.: integrating predictive analytics and
social media. in 2014 ieee conference on visual analytics
science and technology (vast) (oct 2014), pp. 193–202. doi:
10.1109/vast.2014.7042495. 8, 15

[lpp∗06] lee b., plaisant c., parr c. s., fekete j.-d.,
henry n.: task taxonomy for graph visualization. in proceed-
ings of the 2006 avi workshop on beyond time and errors:
novel evaluation methods for information visualization (2006),
acm, pp. 1–5. 17

[lsp∗10] lex a., streit m., partl c., kashofer k., schmal-
stieg d.: comparative analysis of multidimensional, quantita-
tive data. ieee transactions on visualization and computer
graphics (proceedings visualization / information visualiza-
tion 2010) 16, 6 (2010), 1027–1035. 8

[lss∗12] lex a., streit m., schulz h.-j., partl c., schmal-
stieg d., park p. j., gehlenborg n.: stratomex: visual
analysis of large-scale heterogeneous genomics data for cancer
subtype characterization. computer graphics forum (eurovis
’12) 31, 3 (2012), 1175?1184. doi:10.1111/j.1467-8659.2012.
03110.x. 8

[lyk∗12] luo d., yang j., krstajic m., ribarsky w., keim
d.: eventriver: visually exploring text collections with tempo-
ral references. visualization and computer graphics, ieee
transactions on 18, 1 (2012), 93–105. 13, 14

[lzp∗09] liu s., zhou m. x., pan s., qian w., cai w.,
lian x.: interactive, topic-based visual text summarization
and analysis. in proceedings of the 18th acm conference on
information and knowledge management (2009), acm, pp. 543–
552. 13

[mbd∗11] may t., bannach a., davey j., ruppert t.,
kohlhammer j.: guiding feature subset selection with an inter-
active visualization. in visual analytics science and technology
(vast), 2011 ieee conference on (2011), ieee, pp. 111–120.
8, 9

[mgjh08] matkovi´c k., graˇcanin d., jelovi´c m., hauser
h.: interactive visual steering-rapid visual prototyping of a
common rail injection system. visualization and computer
graphics, ieee transactions on 14, 6 (2008), 1699–1706. 8, 12
[mgs∗14] matkovic k., gracanin d., splechtna r.,
jelovic m., stehno b., hauser h., purgathofer w.: vi-
sual analytics for complex engineering systems: hybrid visual
steering of simulation ensembles. visualization and computer
graphics, ieee transactions on 20, 12 (2014), 1803–1812. 8,
12

[mjr∗11] maceachren a. m., jaiswal a., robinson a. c.,
pezanowski s., savelyev a., mitra p., zhang x., blanford
j.: senseplace2: geotwitter analytics support for situational
awareness. in visual analytics science and technology (vast),
2011 ieee conference on (2011), ieee, pp. 181–190. 13

submitted to computer graphics forum (6/2018).

endert et al. / integrating machine learning into visual analytics

27

(http://serc.carleton.edu/nagtworkshops/complexsystems/introduction.html).
19

[mk08] may t., kohlhammer j.: towards closing the analysis
gap: visual generation of decision supporting schemes from
raw data. in computer graphics forum (2008), vol. 27, wiley
online library, pp. 911–918. 8, 9

[mme∗12] malik a., maciejewski r., elmqvist n., jang y.,
ebert d. s., huang w.: a correlative analysis process in a
visual analytics environment. in visual analytics science and
technology (vast), 2012 ieee conference on (2012), ieee,
pp. 33–42. 8, 10

[mo04] madeira s. c., oliveira a. l.: biclustering algorithms
for biological data analysis: a survey. ieee/acm transactions
on computational biology and bioinformatics (tcbb) 1, 1
(2004), 24–45. 16

[mp13] muhlbacher t., piringer h.: a partition-based frame-
work for building and validating regression models. visualiza-
tion and computer graphics, ieee transactions on 19, 12
(2013), 1962–1971. 8, 10

[mur85] murtagh f.: a survey of algorithms for contiguity-
constrained clustering and related problems. the computer
journal 28, 1 (1985), 82–88. 11

[nm13] nam j., mueller k.: tripadvisorn-d: a tourism-
inspired high-dimensional space exploration framework with
overview and detail. visualization and computer graphics,
ieee transactions on 19, 2 (2013), 291–305. 8

[nor86] norman d. a.: cognitive engineering. user centered
system design: new perspectives on human-computer interac-
tion 3161 (1986). 19

[orm] ormand c.: what constitutes a complex system?

[ost∗10] oesterling p., scheuermann g., teresniak s.,
heyer g., koch s., ertl t., weber g. h.: two-stage
framework for a topology-based projection and visualization
of classiﬁed document collections. in visual analytics science
and technology (vast), 2010 ieee symposium on (2010),
ieee, pp. 91–98. 13

[pbk10] piringer h., berger w., krasser j.: hypermoval:
interactive visual validation of regression models for real-time
simulation. in proceedings of the 12th eurographics / ieee
- vgtc conference on visualization (aire-la-ville, switzer-
land, switzerland, 2010), eurovis’10, eurographics association,
pp. 983–992. url: http://dx.doi.org/10.1111/j.1467-8659.
2009.01684.x, doi:10.1111/j.1467-8659.2009.01684.x. 8, 10
[pc05] pirolli p., card s.: the sensemaking process and
leverage points for analyst technology as identiﬁed through cog-
nitive task analysis. in proceedings of international conference
on intelligence analysis (2005), vol. 5, pp. 2–4. 2

[pes∗06] poulin b., eisner r., szafron d., lu p., greiner
r., wishart d. s., fyshe a., pearcy b., macdonell c., an-
vik j.: visual explanation of evidence with additive classiﬁers.
in proceedings, the twenty-first national conference on ar-
tiﬁcial intelligence and the eighteenth innovative applications
of artiﬁcial intelligence conference, july 16-20, 2006, (boston,
massachusetts, usa, july 2006), aaai press, pp. 1822–1829.
url: http://www.aaai.org/library/aaai/2006/aaai06-301.
php. 8, 9

[psco09] pike w. a., stasko j., chang r., o’connell
t. a.: the science of interaction. information visualization 8,
4 (2009), 263–274. 16, 18

[pspm15] paiva j. g. s., schwartz w. r., pedrini h.,
minghim r.: an approach to supporting incremental visual
data classiﬁcation. visualization and computer graphics, ieee
transactions on 21, 1 (2015), 4–17. 8, 12

[pth13] porter r., theiler j., hush d.: interactive ma-

submitted to computer graphics forum (6/2018).

chine learning in data exploitation. computing in sci-
ence and engineering 15, 5 (2013), 12–20. doi:http://doi.
ieeecomputersociety.org/10.1109/mcse.2013.74. 5

[ptrv13] parulek j., turkay c., reuter n., viola i.: vi-
sual cavity analysis in molecular simulations. bmc bioinfor-
matics 14, 19 (2013), 1–15. 8, 9

[pzs∗15] p´erez d., zhang l., schaefer m., schreck t.,
keim d., d´ıaz i.: interactive feature space extension for multi-
dimensional data projection. neurocomputing 150, part (2015),
611–626.
url: http://www.sciencedirect.com/science/
article/pii/s0925231214012879, doi:http://dx.doi.org/10.
1016/j.neucom.2014.09.061. 8, 17

[rawc14] rooney c., attfield s., wong b. w., choudhury
s.: invisque as a tool for intelligence analysis: the construction
of explanatory narratives. international journal of human-
computer interaction 30, 9 (2014), 703–717. 19

[recc10] rose s., engel d., cramer n., cowley w.: au-
tomatic keyword extraction from individual documents. john
wiley & sons, ltd, pp. 1–20. doi:10.1002/9780470689646.ch1.
12

[rf16] ribarsky w., fisher b.: the human-computer system:
towards an operational model for problem-solving. in hawaii
international conference on systems science (hicss 2016)
(2016). 3, 17

[rk04] rasmussen m., karypis g.: gcluto–an interactive
clustering, visualization, and analysis system., university of
minnesota, department of computer science and engineering,
cse. tech. rep., umn technical report: tr, 2004. 8

[rpn∗08] rinzivillo s., pedreschi d., nanni m., giannotti
f., andrienko n., andrienko g.: visually driven analy-
sis of movement data by progressive clustering. information
visualization 7, 3 (2008), 225–239. 8, 9

[rse09] rudolph s., savikhin a., ebert d. s.: finvis: ap-
plied visual analytics for personal ﬁnancial planning. in visual
analytics science and technology, 2009. vast 2009. ieee
symposium on (2009), ieee, pp. 195–202. 14

[rspc93] russell d. m., stefik m. j., pirolli p., card
s. k.: the cost structure of sensemaking. in proceedings of the
interact’93 and chi’93 conference on human factors in
computing systems (1993), acm, pp. 269–276. 2

[sbtk08]

schreck t., bernard j., tekusova t., kohlham-
mer j.: visual cluster analysis of trajectory data with interac-
tive kohonen maps. in ieee symposium on visual analytics
science and technology, 2008. vast’08 (2008), pp. 3–10. 8, 9

[sdlc93]

spiegelhalter d. j., dawid a. p., lauritzen s. l.,
cowell r. g.: bayesian analysis in expert systems. statistical
science (1993), 219–247. 22

[sdmt16]

stahnke j., dork m., muller b., thom a.: prob-
ing projections: interaction techniques for interpreting arrange-
ments and errors of dimensionality reductions. visualization
and computer graphics, ieee transactions on 22, 1 (2016),
629–638. 8

[set09]

settles b.: active learning literature survey. com-
puter sciences technical report 1648, university of wisconsin–
madison, 2009. 5, 8, 12

[sgg∗14]

streit m., gratzl s., gillhofer m., mayr a.,
mitterecker a., hochreiter s.: furby: fuzzy force-directed
bicluster visualization. bmc bioinformatics 15, suppl 6 (2014),
s4. 8, 16

[sgl08]

stasko j., goerg c., liu z.: jigsaw: supporting
investigative analysis through interactive visualization.
in-
formation visualization 7 (2008), 118–132. 2. doi:10.1145/
1466620.1466622. 13

endert et al. / integrating machine learning into visual analytics

28
[sha∗01]

shipman f., hsieh h., airhart r., maloor p.,
moore j. m., shah d.: emergent structure in analytic
workspaces: design and use of the visual knowledge builder.
pp. 132–139. 12

[she00]

shearer c.: the crisp-dm model: the new blueprint for
data mining. journal of data warehousing 5, 4 (2000), 13–22. 5
shneiderman b.: direct manipulation: a step beyond
programming languages. computer 16, 8 (1983), 57–69. doi:
10.1109/mc.1983.1654471. 4, 7

[shn83]

[sk10]

strumbelj e., kononenko i.:

an eﬃcient ex-
planation of
individual classiﬁcations using game theory.
journal of machine learning research 11 (2010), 1–18.
url: http://doi.acm.org/10.1145/1756006.1756007, doi:
10.1145/1756006.1756007. 8, 9

[sku02]

skupin a.: a cartographic approach to visualizing
conference abstracts. ieee computer graphics and applica-
tions 22 (2002), 50–58. doi:10.1109/38.974518. 12, 16

[sm99]

shipman f., marshall c.: formality considered harm-
ful: experiences, emerging themes, and directions on the use
of formal representations in interactive systems. comput.
supported coop. work 8 (1999), 333–352. 4. doi:10.1023/a:
1008716330212. 12

[smnr16]

sun m., mi p., north c., ramakrishnan n.: biset:
semantic edge bundling with biclusters for sensemaking. ieee
transactions on visualization and computer graphics 22, 1
(2016), 310–319. 16

[snr14]

sun m., north c., ramakrishnan n.: a ﬁve-level
design framework for bicluster visualizations. ieee transactions
on visualization and computer graphics 20, 12 (2014), 1713–1722.
16

[spg14]

stolper c. d., perer a., gotz d.: progressive visual
analytics: user-driven visual exploration of in-progress analytics.
visualization and computer graphics, ieee transactions on
20, 12 (2014), 1653–1662. 20

[ss02]

seo j., shneiderman b.: interactively exploring hierar-
chical clustering results. ieee computer 35, 7 (2002), 80–86.
8

[ss11]

satinover j., sornette d.: taming manias: on the
origins, inevitability, prediction and regulation of bubbles and
crashes, chapter of the book “governance and control of ﬁnan-
cial systems: a resilience engineering perspective,”. published
by ashgate publishing group in their resilience engineering
perspectives series (2011). 19

[sss∗14]

sacha d., stoffel a., stoffel f., kwon b. c.,
ellis g., keim d. a.: knowledge generation model for vi-
sual analytics. visualization and computer graphics, ieee
transactions on 20, 12 (2014), 1604–1613. 3, 4

[swb97]

sarter n. b., woods d. d., billings c. e.: au-
tomation surprises. handbook of human factors and ergonomics
2 (1997), 1926–1943. 19

[szs∗16]

sacha d., zhang l., sedlmair m., lee j. a., pel-
tonen j., weiskopf d., north s. c., keim d. a.: visual
interaction with dimensionality reduction: a structured liter-
ature analysis. ieee trans. on visualization and computer
graphics (2016). 6

[tc05] thomas j. j., cook k. a.: illuminating the path: the
research and development agenda for visual analytics. ieee
computer society press, 2005. 1

[tfh11] turkay c., filzmoser p., hauser h.: brushing
dimensions-a dual visual analysis model for high-dimensional
data. visualization and computer graphics, ieee transac-
tions on 17, 12 (2011), 2591–2599. 8

[tjhh14] turkay c., jeanquartier f., holzinger a.,
hauser h.: on computationally-enhanced visual analysis of

heterogeneous data and its application in biomedical informat-
ics. in interactive knowledge discovery and data mining in
biomedical informatics. springer, 2014, pp. 117–140. 6

[tkbh17] turkay c., kaya e., balcisoy s., hauser h.:
designing progressive and interactive analytics processes for
high-dimensional data analysis. ieee transactions on visual-
ization & computer graphics 23, 1 (2017), 131–140. 20

[tllh12] turkay c., lundervold a., lundervold a.,
hauser h.: representative factor generation for the inter-
active visual analysis of high-dimensional data. visualization
and computer graphics, ieee transactions on 18, 12 (2012),
2621–2630. 8, 10

[tls∗14] turkay c., lex a., streit m., pfister h., hauser
h.: characterizing cancer subtypes using dual analysis in
caleydo stratomex. ieee computer graphics and applications
34, 2 (2014), 38–47. doi:http://doi.ieeecomputersociety.
org/10.1109/mcg.2014.1. 8, 9, 10

[tprh11a] turkay c., parulek j., reuter n., hauser h.:
integrating cluster formation and cluster evaluation in inter-
active visual analysis. in proceedings of the 27th spring con-
ference on computer graphics (2011), acm, pp. 77–86. 8,
9

[tprh11b] turkay c., parulek j., reuter n., hauser
h.:
interactive visual analysis of temporal cluster struc-
tures. computer graphics forum 30, 3 (2011), 711–720. url:
http://dx.doi.org/10.1111/j.1467-8659.2011.01920.x. 8, 9
[van05] van wijk j. j.: the value of visualization. in 16th
ieee visualization 2005 (vis 2005) (2005), ieee computer
society, p. 11. doi:10.1109/vis.2005.102. 4, 16

[vdevw11]

van den elzen s., van wijk j. j.: baobabview:
interactive construction and analysis of decision trees. in vi-
sual analytics science and technology (vast), 2011 ieee
conference on (2011), ieee, pp. 151–160. 8, 9

[vdmw12]

van der maaten l., weinberger k.: stochastic
triplet embedding. in 2012 ieee international workshop on
machine learning for signal processing (sept 2012), pp. 1–6.
doi:10.1109/mlsp.2012.6349720. 6

[ves99] vesanto j.: som-based data visualization methods.
intelligent data analysis 3, 2 (1999), 111–126. doi:10.3233/
ida-1999-3203. 16

[vl13] verleysen m., lee j. a.: nonlinear dimensionality
reduction for visualization. in neural information processing
(2013), springer, pp. 617–622. 16

[wei95] weick k. e.: sensemaking in organizations, vol. 3.

sage, 1995. 2

[wh00] wirth r., hipp j.: crisp-dm: towards a standard
process model for data mining. in proceedings of the 4th inter-
national conference on the practical applications of knowledge
discovery and data mining (2000), citeseer, pp. 29–39. 22

[wkkb15] wilber m. j., kwak i. s., kriegman d., be-
longie s.: learning concept embeddings with combined
human-machine expertise. in 2015 ieee international con-
ference on computer vision (iccv) (dec 2015), pp. 981–989.
doi:10.1109/iccv.2015.118. 6

[wls∗10] wei f., liu s., song y., pan s., zhou m. x., qian
w., shi l., tan l., zhang q.: tiara: a visual exploratory text
analytic system. in proceedings of the 16th acm sigkdd in-
ternational conference on knowledge discovery and data mining
(2010), acm, pp. 153–162. 13

[wm04] williams m., munzner t.: steerable, progressive mul-
tidimensional scaling. in proceedings of the ieee symposium
on information visualization (washington, dc, usa, 2004),
ieee computer society, pp. 57–64. 8

submitted to computer graphics forum (6/2018).

endert et al. / integrating machine learning into visual analytics

29

[won14] wong b.: how analysts think (?): early observations.
in intelligence and security informatics conference (jisic),
2014 ieee joint (2014), ieee, pp. 296–299. 19

[wso05] weick k. e., sutcliffe k. m., obstfeld d.: orga-
nizing and the process of sensemaking. organization science
16, 4 (2005), 409–421. 2

[wsp∗06] wright w., schroh d., proulx p., skaburskis
a., cort b.: the sandbox for analysis: concepts and methods.
acm, pp. 801–810. doi:10.1145/1124772.1124890. 13

[wtp∗99] wise j. a., thomas j. j., pennock k., lantrip
d., pottier m., schur a., crow v.: visualizing the non-
visual: spatial analysis and interaction with information for text
documents. morgan kaufmann publishers inc., pp. 442–450. 8,
12, 13

[wv12] wong b. w., varga m.: black holes, keyholes and
brown worms: challenges in sense making. in proceedings of
the human factors and ergonomics society annual meeting
(2012), vol. 56, sage publications, pp. 287–291. 19

[yaksj07] yi j. s., ah kang y., stasko j. t., jacko j. a.:
toward a deeper understanding of the role of interaction in in-
formation visualization. visualization and computer graphics,
ieee transactions on 13, 6 (2007), 1224–1231. 7

[ykj16] yeon h., kim s., jang y.: predictive visual ana-
lytics of event evolution for user-created context. journal of
visualization (2016), 1–16. 8, 15

[ynm∗13] younesy h., nielsen c. b., m¨oller t., alder o.,
cullum r., lorincz m. c., karimi m. m., jones s. j.: an
interactive analysis and exploration tool for epigenomic data.
in computer graphics forum (2013), vol. 32, wiley online
library, pp. 91–100. 8, 15

[zc07] zhu w., chen c.: storylines: visual exploration and
analysis in latent semantic spaces. computers & graphics 31,
3 (2007), 338–349. 13, 14

[zjgk10] ziegler h., jenny m., gruse t., keim d. a.: vi-
sual market sector analysis for ﬁnancial time series data. in
visual analytics science and technology (vast), 2010 ieee
symposium on (2010), ieee, pp. 83–90. 14, 15

[znk08] ziegler h., nietzschmann t., keim d. a.: visual
analytics on the ﬁnancial market: pixel-based analysis and
comparison of long-term investments. in information visualisa-
tion, 2008. iv’08. 12th international conference (2008), ieee,
pp. 287–295. 14

submitted to computer graphics forum (6/2018).

",The State of the Art in Integrating Machine Learning into Visual Analytics,"{""pos"":{""0"":1,""1"":2,""2"":3,""3"":4},""7"":{""0"":""users"",""1"":""conference*"",""2"":""proceedings*"",""3"":""people""},""0"":{""0"":""ieee"",""1"":""di\ufb00erent"",""2"":""sacha*"",""3"":""keim""},""2"":{""0"":""generally*"",""1"":""expected*"",""2"":""helps*"",""3"":""trying*""},""11"":{""0"":""models*"",""1"":""framework*"",""2"":""frameworks*"",""3"":""paradigm*""},""3"":{""0"":""high"",""1"":""vast"",""2"":""similar"",""3"":""integrated""},""9"":{""0"":""computer"",""1"":""science*"",""2"":""technology*"",""3"":""university*""},""1"":{""0"":""modify"",""1"":""describe"",""2"":""select*"",""3"":""improve""},""5"":{""0"":""model"",""1"":""figure*"",""2"":""domain*"",""3"":""frame""},""8"":{""0"":""human"",""1"":""analytic*"",""2"":""sensemaking"",""3"":""cognitive*""},""4"":{""0"":""interaction*"",""1"":""reasoning"",""2"":""sense"",""3"":""understanding*""},""6"":{""0"":""clustering*"",""1"":""algorithms*"",""2"":""algorithm"",""3"":""computation*""},""10"":{""0"":""methods*"",""1"":""approaches*"",""2"":""structures*"",""3"":""mechanisms*""}}",journalArticle,http://arxiv.org/abs/1802.07954,self.user,False,"{""Unnamed: 0"":{""0"":0,""1"":1,""2"":2,""3"":3,""4"":4,""5"":5,""6"":6,""7"":7,""8"":8,""9"":10,""10"":11,""11"":12,""12"":13,""13"":14,""14"":15,""15"":16,""16"":17,""17"":18,""18"":19,""19"":21,""20"":22,""21"":23,""22"":24,""23"":25,""24"":26,""25"":27,""26"":28,""27"":30,""28"":31,""29"":32,""30"":33,""31"":34,""32"":35,""33"":36,""34"":37,""35"":38,""36"":39,""37"":40,""38"":41,""39"":42,""40"":43,""41"":44,""42"":45,""43"":46,""44"":47,""45"":49,""46"":50,""47"":52,""48"":53,""49"":54,""50"":55,""51"":56,""52"":57,""53"":58,""54"":59,""55"":60,""56"":61,""57"":62,""58"":63,""59"":64,""60"":65,""61"":66,""62"":67,""63"":68,""64"":69,""65"":70,""66"":71,""67"":72,""68"":73,""69"":74,""70"":75,""71"":76,""72"":77,""73"":78,""74"":79,""75"":81,""76"":82,""77"":83,""78"":84,""79"":86,""80"":87,""81"":88,""82"":89,""83"":90,""84"":91,""85"":92,""86"":93,""87"":94,""88"":95,""89"":96,""90"":97,""91"":98,""92"":99,""93"":100,""94"":101,""95"":102,""96"":103,""97"":104,""98"":105,""99"":106,""100"":107,""101"":108,""102"":109,""103"":110,""104"":112,""105"":113,""106"":114,""107"":115,""108"":116,""109"":117,""110"":118,""111"":119,""112"":120,""113"":121,""114"":122,""115"":123,""116"":124,""117"":125,""118"":126,""119"":127,""120"":128,""121"":129,""122"":130,""123"":131,""124"":132,""125"":133,""126"":134,""127"":136,""128"":137,""129"":138,""130"":139,""131"":140,""132"":141,""133"":142,""134"":143,""135"":144,""136"":145,""137"":146,""138"":147,""139"":148,""140"":149,""141"":150,""142"":151,""143"":152,""144"":153,""145"":154,""146"":155,""147"":157,""148"":162,""149"":163,""150"":164,""151"":165,""152"":166,""153"":167,""154"":169,""155"":170,""156"":171,""157"":172,""158"":173,""159"":174,""160"":175,""161"":176,""162"":177,""163"":178,""164"":179,""165"":180,""166"":181,""167"":182,""168"":183,""169"":184,""170"":185,""171"":186,""172"":187,""173"":188,""174"":189,""175"":190,""176"":191,""177"":192,""178"":193,""179"":194,""180"":195,""181"":198},""C"":{""0"":6.5629629242,""1"":14.8634416215,""2"":14.4105852368,""3"":79.73414091,""4"":11.68001603,""5"":5.3341458644,""6"":12.0861515723,""7"":9.88115466,""8"":10.2685531435,""9"":11.1908477173,""10"":5.7932293569,""11"":7.5549367986,""12"":7.3244657343,""13"":5.3362740712,""14"":8.2156615479,""15"":4.452736206,""16"":7.9652810032,""17"":4.9345718652,""18"":8.3156873334,""19"":29.533534567,""20"":7.7569084703,""21"":11.7729738086,""22"":14.6752022069,""23"":13.2392877177,""24"":8.7046943689,""25"":4.8771625127,""26"":15.6541332881,""27"":8.2909559101,""28"":7.9833832679,""29"":31.6033360753,""30"":19.8224191465,""31"":12.2489974492,""32"":7.1586074418,""33"":6.3077353367,""34"":7.9742548424,""35"":11.7902396052,""36"":4.9345729905,""37"":12.2215829708,""38"":11.2600811669,""39"":23.5318919255,""40"":4.8824734039,""41"":7.9149702083,""42"":4.6603072686,""43"":7.7481558042,""44"":5.1588784211,""45"":4.5910889654,""46"":5.4520880528,""47"":8.4561357722,""48"":6.3780992491,""49"":5.6624196895,""50"":11.017570604,""51"":11.5878697523,""52"":17.8292611591,""53"":4.771930723,""54"":5.7340346553,""55"":6.4534125135,""56"":9.8220750101,""57"":4.8212518087,""58"":4.6398647909,""59"":9.7521808197,""60"":8.0683908593,""61"":5.5467615272,""62"":9.1700516217,""63"":5.7103143908,""64"":12.1163350082,""65"":5.8870201495,""66"":9.118413991,""67"":4.5007652581,""68"":5.6885281663,""69"":6.8056660783,""70"":9.1998088865,""71"":12.8764235977,""72"":5.6307838954,""73"":6.6973152615,""74"":9.4204784785,""75"":5.5140070598,""76"":4.5078238463,""77"":4.8051172898,""78"":10.9430864466,""79"":8.2595427706,""80"":7.7738905442,""81"":7.5876930496,""82"":4.6079473526,""83"":6.4514562031,""84"":5.5891139262,""85"":6.3000737023,""86"":7.7831981235,""87"":4.930488996,""88"":4.7062078012,""89"":6.6252168073,""90"":4.9790494683,""91"":11.8595327076,""92"":5.8369694808,""93"":4.9081985332,""94"":7.2681280302,""95"":5.3655876912,""96"":4.4822632611,""97"":7.270948808,""98"":7.9067417663,""99"":4.8385599707,""100"":5.12799709,""101"":6.4818835444,""102"":8.4998027061,""103"":8.1200798211,""104"":12.895963532,""105"":4.6521841149,""106"":5.2140729366,""107"":7.1654424535,""108"":4.7169087154,""109"":5.5043231692,""110"":4.8717033784,""111"":7.4873567669,""112"":6.5312948119,""113"":6.4882100908,""114"":4.4526322428,""115"":8.1579479047,""116"":6.0178035686,""117"":4.5120068905,""118"":4.8732850637,""119"":5.6016054639,""120"":8.545241529,""121"":6.9311711739,""122"":6.4765615713,""123"":9.2755882614,""124"":5.1354540743,""125"":4.8491449138,""126"":9.0949453849,""127"":7.6157696637,""128"":6.9313324974,""129"":6.1683552814,""130"":7.1220839605,""131"":5.466340642,""132"":7.6544555541,""133"":6.7588895325,""134"":5.8911589999,""135"":6.468017519,""136"":7.2182823989,""137"":4.7848867976,""138"":4.6460884945,""139"":7.0561829743,""140"":8.3394776793,""141"":5.443446406,""142"":5.8917716259,""143"":6.6387795771,""144"":6.4865639042,""145"":8.2436161752,""146"":5.9208792099,""147"":5.0072564669,""148"":4.6621787298,""149"":6.4933113113,""150"":5.7228392262,""151"":4.7482861029,""152"":4.7413054135,""153"":4.8252920244,""154"":6.5193252317,""155"":6.5751316377,""156"":5.2245914069,""157"":6.4964712001,""158"":6.4995705781,""159"":6.1567547748,""160"":4.7170331639,""161"":5.8854222545,""162"":6.287264498,""163"":6.214736498,""164"":4.8664510627,""165"":4.7896785127,""166"":4.5810976905,""167"":4.6365455367,""168"":4.5035899249,""169"":4.6094213523,""170"":4.4450679383,""171"":4.7129159026,""172"":4.5017036238,""173"":4.5244143668,""174"":4.635200241,""175"":4.6055215195,""176"":4.6324871121,""177"":4.5661430717,""178"":4.4669176275,""179"":4.6910339984,""180"":4.6542924859,""181"":4.7307336911},""count"":{""0"":486,""1"":386,""2"":308,""3"":222,""4"":220,""5"":194,""6"":186,""7"":162,""8"":146,""9"":126,""10"":116,""11"":110,""12"":108,""13"":108,""14"":104,""15"":96,""16"":94,""17"":94,""18"":92,""19"":88,""20"":82,""21"":82,""22"":76,""23"":74,""24"":72,""25"":72,""26"":72,""27"":70,""28"":68,""29"":64,""30"":58,""31"":58,""32"":56,""33"":54,""34"":54,""35"":54,""36"":52,""37"":52,""38"":52,""39"":52,""40"":50,""41"":50,""42"":50,""43"":50,""44"":48,""45"":46,""46"":46,""47"":42,""48"":42,""49"":42,""50"":42,""51"":42,""52"":40,""53"":38,""54"":36,""55"":36,""56"":36,""57"":34,""58"":34,""59"":34,""60"":34,""61"":34,""62"":34,""63"":34,""64"":32,""65"":32,""66"":32,""67"":32,""68"":32,""69"":30,""70"":30,""71"":30,""72"":28,""73"":28,""74"":28,""75"":26,""76"":26,""77"":26,""78"":26,""79"":24,""80"":24,""81"":24,""82"":24,""83"":24,""84"":24,""85"":22,""86"":22,""87"":22,""88"":22,""89"":22,""90"":22,""91"":22,""92"":20,""93"":20,""94"":20,""95"":20,""96"":20,""97"":20,""98"":20,""99"":18,""100"":18,""101"":18,""102"":18,""103"":18,""104"":18,""105"":16,""106"":16,""107"":16,""108"":16,""109"":16,""110"":16,""111"":16,""112"":14,""113"":14,""114"":14,""115"":14,""116"":14,""117"":12,""118"":12,""119"":12,""120"":12,""121"":12,""122"":12,""123"":12,""124"":12,""125"":12,""126"":12,""127"":12,""128"":12,""129"":12,""130"":12,""131"":12,""132"":10,""133"":10,""134"":10,""135"":10,""136"":10,""137"":10,""138"":10,""139"":10,""140"":10,""141"":10,""142"":10,""143"":10,""144"":10,""145"":10,""146"":10,""147"":10,""148"":8,""149"":8,""150"":8,""151"":8,""152"":8,""153"":8,""154"":8,""155"":8,""156"":8,""157"":8,""158"":8,""159"":8,""160"":8,""161"":8,""162"":8,""163"":8,""164"":8,""165"":8,""166"":6,""167"":6,""168"":6,""169"":6,""170"":6,""171"":6,""172"":6,""173"":6,""174"":6,""175"":6,""176"":6,""177"":6,""178"":6,""179"":6,""180"":6,""181"":6},""sigma_nor"":{""0"":1.5345313117,""1"":2.0345211752,""2"":2.1009971403,""3"":7.0,""4"":2.0566025443,""5"":1.6163568588,""6"":2.1583097166,""7"":2.0353731433,""8"":2.1103853336,""9"":2.2609661939,""10"":1.7687773806,""11"":1.9603169062,""12"":1.9430159038,""13"":1.7402757796,""14"":2.0479536507,""15"":1.6734399269,""16"":2.0593577129,""17"":1.7300485976,""18"":2.1059298358,""19"":4.499199668,""20"":2.0878844561,""21"":2.5520651812,""22"":2.9446750213,""23"":2.7913200458,""24"":2.2548749144,""25"":1.7860163806,""26"":3.1061555478,""27"":2.2163133165,""28"":2.1902514189,""29"":5.2635622889,""30"":3.8529922477,""31"":2.832948065,""32"":2.1610862223,""33"":2.0572773717,""34"":2.2887635422,""35"":2.8188189641,""36"":1.8765666704,""37"":2.9052575058,""38"":2.7695244553,""39"":4.5019084227,""40"":1.8795947233,""41"":2.3149003998,""42"":1.8477034515,""43"":2.2909547004,""44"":1.9308594641,""45"":1.8586139868,""46"":1.9866390265,""47"":2.4786333784,""48"":2.1576967818,""49"":2.047165634,""50"":2.8742270883,""51"":2.9623053611,""52"":3.9803054796,""53"":1.936573339,""54"":2.1095167196,""55"":2.227842611,""56"":2.7819324932,""57"":1.9751874285,""58"":1.9446606082,""59"":2.8050460693,""60"":2.5216699256,""61"":2.0972882553,""62"":2.7070756982,""63"":2.1248136479,""64"":3.2496328745,""65"":2.1757625216,""66"":2.7328218649,""67"":1.9367863158,""68"":2.1415445279,""69"":2.3608771466,""70"":2.7841596225,""71"":3.4341820741,""72"":2.1762990108,""73"":2.369946353,""74"":2.8643840566,""75"":2.1793902559,""76"":1.9914899915,""77"":2.047008227,""78"":3.193246817,""79"":2.7338311394,""80"":2.6403939486,""81"":2.6045704315,""82"":2.0312814566,""83"":2.3859638378,""84"":2.2200532634,""85"":2.3900764196,""86"":2.6846122893,""87"":2.1180885696,""88"":2.0735482358,""89"":2.4546470691,""90"":2.1277322655,""91"":3.4941375959,""92"":2.3310992645,""93"":2.14030529,""94"":2.6250968627,""95"":2.23426505,""96"":2.0528069851,""97"":2.6256763247,""98"":2.7562849164,""99"":2.1543557071,""100"":2.2160098045,""101"":2.5044062881,""102"":2.9342508947,""103"":2.8533646842,""104"":3.8706937694,""105"":2.1437940145,""106"":2.2682502506,""107"":2.700471174,""108"":2.1581302673,""109"":2.3325395728,""110"":2.1924166961,""111"":2.7717739695,""112"":2.6093410807,""113"":2.5993863031,""114"":2.1290635473,""115"":2.9851812708,""116"":2.4906982998,""117"":2.1746270671,""118"":2.2620197726,""119"":2.4381995003,""120"":3.1502611157,""121"":2.759819662,""122"":2.649850209,""123"":3.3269310105,""124"":2.3254381045,""125"":2.2561803027,""126"":3.283233741,""127"":2.9254231183,""128"":2.759858686,""129"":2.5752955209,""130"":2.806001209,""131"":2.4054791214,""132"":3.0063784667,""133"":2.7786374014,""134"":2.5579748583,""135"":2.7046690947,""136"":2.8954603025,""137"":2.2766515346,""138"":2.2413553391,""139"":2.8542386676,""140"":3.1805785421,""141"":2.4441222326,""142"":2.5581306482,""143"":2.7480936241,""144"":2.709385412,""145"":3.1562011087,""146"":2.5655326621,""147"":2.3331998003,""148"":2.2780250013,""149"":2.769702647,""150"":2.562823088,""151"":2.3011457032,""152"":2.2992713174,""153"":2.3218225731,""154"":2.7766876481,""155"":2.7916722334,""156"":2.4290385018,""157"":2.7705511092,""158"":2.7713833236,""159"":2.679333808,""160"":2.2927539725,""161"":2.6064782779,""162"":2.7143769906,""163"":2.6949024879,""164"":2.3328741918,""165"":2.3122599845,""166"":2.2769730135,""167"":2.2927526784,""168"":2.2549154108,""169"":2.285033523,""170"":2.2382608894,""171"":2.3144865935,""172"":2.2543785964,""173"":2.2608417494,""174"":2.2923698265,""175"":2.2839236863,""176"":2.2915977087,""177"":2.2727171427,""178"":2.2444789988,""179"":2.3082593162,""180"":2.2978032066,""181"":2.3195572815},""vocab_index"":{""0"":0,""1"":2,""2"":3,""3"":8,""4"":9,""5"":10,""6"":12,""7"":13,""8"":16,""9"":18,""10"":19,""11"":21,""12"":22,""13"":23,""14"":25,""15"":26,""16"":27,""17"":28,""18"":29,""19"":32,""20"":33,""21"":34,""22"":35,""23"":38,""24"":39,""25"":40,""26"":41,""27"":43,""28"":44,""29"":48,""30"":54,""31"":55,""32"":57,""33"":58,""34"":59,""35"":60,""36"":61,""37"":62,""38"":63,""39"":64,""40"":65,""41"":66,""42"":67,""43"":68,""44"":71,""45"":74,""46"":77,""47"":85,""48"":86,""49"":88,""50"":89,""51"":90,""52"":93,""53"":94,""54"":97,""55"":98,""56"":102,""57"":107,""58"":108,""59"":113,""60"":114,""61"":115,""62"":116,""63"":117,""64"":118,""65"":119,""66"":120,""67"":127,""68"":128,""69"":133,""70"":134,""71"":135,""72"":145,""73"":147,""74"":148,""75"":152,""76"":159,""77"":161,""78"":165,""79"":167,""80"":176,""81"":178,""82"":181,""83"":183,""84"":184,""85"":188,""86"":193,""87"":199,""88"":204,""89"":205,""90"":207,""91"":208,""92"":213,""93"":224,""94"":228,""95"":229,""96"":233,""97"":237,""98"":239,""99"":240,""100"":262,""101"":263,""102"":264,""103"":265,""104"":267,""105"":273,""106"":284,""107"":296,""108"":299,""109"":313,""110"":314,""111"":319,""112"":363,""113"":380,""114"":381,""115"":382,""116"":383,""117"":410,""118"":417,""119"":419,""120"":430,""121"":441,""122"":448,""123"":450,""124"":452,""125"":455,""126"":457,""127"":460,""128"":462,""129"":463,""130"":464,""131"":465,""132"":497,""133"":498,""134"":521,""135"":529,""136"":538,""137"":540,""138"":544,""139"":547,""140"":562,""141"":564,""142"":572,""143"":574,""144"":575,""145"":577,""146"":580,""147"":584,""148"":619,""149"":652,""150"":679,""151"":710,""152"":737,""153"":739,""154"":763,""155"":764,""156"":768,""157"":769,""158"":770,""159"":772,""160"":776,""161"":777,""162"":779,""163"":786,""164"":790,""165"":791,""166"":825,""167"":845,""168"":852,""169"":873,""170"":874,""171"":875,""172"":910,""173"":911,""174"":1010,""175"":1034,""176"":1049,""177"":1058,""178"":1083,""179"":1086,""180"":1096,""181"":1142},""word"":{""0"":""data"",""1"":""user"",""2"":""visualization"",""3"":""ieee"",""4"":""model"",""5"":""computer"",""6"":""models"",""7"":""interaction"",""8"":""process"",""9"":""clustering"",""10"":""knowledge"",""11"":""systems"",""12"":""results"",""13"":""algorithms"",""14"":""users"",""15"":""time"",""16"":""human"",""17"":""methods"",""18"":""feedback"",""19"":""conference"",""20"":""analytic"",""21"":""techniques"",""22"":""science"",""23"":""figure"",""24"":""tasks"",""25"":""high"",""26"":""classi\ufb01cation"",""27"":""topic"",""28"":""example"",""29"":""proceedings"",""30"":""transactions"",""31"":""algorithm"",""32"":""text"",""33"":""reasoning"",""34"":""people"",""35"":""authors"",""36"":""domain"",""37"":""features"",""38"":""technology"",""39"":""vast"",""40"":""section"",""41"":""parameters"",""42"":""exploration"",""43"":""di\ufb00erent"",""44"":""paper"",""45"":""sensemaking"",""46"":""space"",""47"":""training"",""48"":""framework"",""49"":""approaches"",""50"":""examples"",""51"":""input"",""52"":""http"",""53"":""context"",""54"":""sense"",""55"":""cognitive"",""56"":""international"",""57"":""understanding"",""58"":""computation"",""59"":""similar"",""60"":""view"",""61"":""integrated"",""62"":""symposium"",""63"":""clusters"",""64"":""north"",""65"":""topics"",""66"":""frameworks"",""67"":""literature"",""68"":""regression"",""69"":""intelligence"",""70"":""frame"",""71"":""sacha"",""72"":""types"",""73"":""technique"",""74"":""events"",""75"":""design"",""76"":""discussed"",""77"":""constraints"",""78"":""keim"",""79"":""university"",""80"":""relevant"",""81"":""thinking"",""82"":""unsupervised"",""83"":""modify"",""84"":""result"",""85"":""describe"",""86"":""situation"",""87"":""called"",""88"":""turkay"",""89"":""simulation"",""90"":""media"",""91"":""items"",""92"":""speci\ufb01c"",""93"":""ones"",""94"":""papers"",""95"":""de\ufb01ne"",""96"":""works"",""97"":""case"",""98"":""theory"",""99"":""select"",""100"":""projection"",""101"":""bayesian"",""102"":""ribarsky"",""103"":""engineering"",""104"":""hauser"",""105"":""stages"",""106"":""structures"",""107"":""generally"",""108"":""improve"",""109"":""mechanisms"",""110"":""response"",""111"":""springer"",""112"":""expectations"",""113"":""advanced"",""114"":""study"",""115"":""e\ufb00ort"",""116"":""press"",""117"":""methodology"",""118"":""expected"",""119"":""paradigm"",""120"":""sets"",""121"":""found"",""122"":""streaming"",""123"":""location"",""124"":""helps"",""125"":""cases"",""126"":""latency"",""127"":""jmlr"",""128"":""york"",""129"":""chang"",""130"":""park"",""131"":""society"",""132"":""produce"",""133"":""steps"",""134"":""observe"",""135"":""subsets"",""136"":""represented"",""137"":""image"",""138"":""demonstrate"",""139"":""category"",""140"":""articles"",""141"":""timeline"",""142"":""convergence"",""143"":""quantitative"",""144"":""trying"",""145"":""professor"",""146"":""wang"",""147"":""ramakrishnan"",""148"":""phases"",""149"":""metaphor"",""150"":""resources"",""151"":""introduce"",""152"":""analyzed"",""153"":""combining"",""154"":""regime"",""155"":""seconds"",""156"":""carrying"",""157"":""claims"",""158"":""tentative"",""159"":""annotations"",""160"":""sigchi"",""161"":""basu"",""162"":""siam"",""163"":""fiaux"",""164"":""streit"",""165"":""zhang"",""166"":""structuring"",""167"":""frames"",""168"":""placed"",""169"":""preparation"",""170"":""generalization"",""171"":""deployment"",""172"":""journals"",""173"":""conferences"",""174"":""target"",""175"":""spire"",""176"":""images"",""177"":""predicting"",""178"":""e\ufb00ects"",""179"":""delay"",""180"":""grouped"",""181"":""aaai""},""threshold"":{""0"":4.4379804273,""1"":4.4379804273,""2"":4.4379804273,""3"":4.4379804273,""4"":4.4379804273,""5"":4.4379804273,""6"":4.4379804273,""7"":4.4379804273,""8"":4.4379804273,""9"":4.4379804273,""10"":4.4379804273,""11"":4.4379804273,""12"":4.4379804273,""13"":4.4379804273,""14"":4.4379804273,""15"":4.4379804273,""16"":4.4379804273,""17"":4.4379804273,""18"":4.4379804273,""19"":4.4379804273,""20"":4.4379804273,""21"":4.4379804273,""22"":4.4379804273,""23"":4.4379804273,""24"":4.4379804273,""25"":4.4379804273,""26"":4.4379804273,""27"":4.4379804273,""28"":4.4379804273,""29"":4.4379804273,""30"":4.4379804273,""31"":4.4379804273,""32"":4.4379804273,""33"":4.4379804273,""34"":4.4379804273,""35"":4.4379804273,""36"":4.4379804273,""37"":4.4379804273,""38"":4.4379804273,""39"":4.4379804273,""40"":4.4379804273,""41"":4.4379804273,""42"":4.4379804273,""43"":4.4379804273,""44"":4.4379804273,""45"":4.4379804273,""46"":4.4379804273,""47"":4.4379804273,""48"":4.4379804273,""49"":4.4379804273,""50"":4.4379804273,""51"":4.4379804273,""52"":4.4379804273,""53"":4.4379804273,""54"":4.4379804273,""55"":4.4379804273,""56"":4.4379804273,""57"":4.4379804273,""58"":4.4379804273,""59"":4.4379804273,""60"":4.4379804273,""61"":4.4379804273,""62"":4.4379804273,""63"":4.4379804273,""64"":4.4379804273,""65"":4.4379804273,""66"":4.4379804273,""67"":4.4379804273,""68"":4.4379804273,""69"":4.4379804273,""70"":4.4379804273,""71"":4.4379804273,""72"":4.4379804273,""73"":4.4379804273,""74"":4.4379804273,""75"":4.4379804273,""76"":4.4379804273,""77"":4.4379804273,""78"":4.4379804273,""79"":4.4379804273,""80"":4.4379804273,""81"":4.4379804273,""82"":4.4379804273,""83"":4.4379804273,""84"":4.4379804273,""85"":4.4379804273,""86"":4.4379804273,""87"":4.4379804273,""88"":4.4379804273,""89"":4.4379804273,""90"":4.4379804273,""91"":4.4379804273,""92"":4.4379804273,""93"":4.4379804273,""94"":4.4379804273,""95"":4.4379804273,""96"":4.4379804273,""97"":4.4379804273,""98"":4.4379804273,""99"":4.4379804273,""100"":4.4379804273,""101"":4.4379804273,""102"":4.4379804273,""103"":4.4379804273,""104"":4.4379804273,""105"":4.4379804273,""106"":4.4379804273,""107"":4.4379804273,""108"":4.4379804273,""109"":4.4379804273,""110"":4.4379804273,""111"":4.4379804273,""112"":4.4379804273,""113"":4.4379804273,""114"":4.4379804273,""115"":4.4379804273,""116"":4.4379804273,""117"":4.4379804273,""118"":4.4379804273,""119"":4.4379804273,""120"":4.4379804273,""121"":4.4379804273,""122"":4.4379804273,""123"":4.4379804273,""124"":4.4379804273,""125"":4.4379804273,""126"":4.4379804273,""127"":4.4379804273,""128"":4.4379804273,""129"":4.4379804273,""130"":4.4379804273,""131"":4.4379804273,""132"":4.4379804273,""133"":4.4379804273,""134"":4.4379804273,""135"":4.4379804273,""136"":4.4379804273,""137"":4.4379804273,""138"":4.4379804273,""139"":4.4379804273,""140"":4.4379804273,""141"":4.4379804273,""142"":4.4379804273,""143"":4.4379804273,""144"":4.4379804273,""145"":4.4379804273,""146"":4.4379804273,""147"":4.4379804273,""148"":4.4379804273,""149"":4.4379804273,""150"":4.4379804273,""151"":4.4379804273,""152"":4.4379804273,""153"":4.4379804273,""154"":4.4379804273,""155"":4.4379804273,""156"":4.4379804273,""157"":4.4379804273,""158"":4.4379804273,""159"":4.4379804273,""160"":4.4379804273,""161"":4.4379804273,""162"":4.4379804273,""163"":4.4379804273,""164"":4.4379804273,""165"":4.4379804273,""166"":4.4379804273,""167"":4.4379804273,""168"":4.4379804273,""169"":4.4379804273,""170"":4.4379804273,""171"":4.4379804273,""172"":4.4379804273,""173"":4.4379804273,""174"":4.4379804273,""175"":4.4379804273,""176"":4.4379804273,""177"":4.4379804273,""178"":4.4379804273,""179"":4.4379804273,""180"":4.4379804273,""181"":4.4379804273},""vector"":{""0"":""[-5.3796916   8.343364   -3.8851743   0.17247605  6.64103    -1.9661545\n  4.8644037  -1.5543897   3.0178087   7.886362  ]"",""1"":""[-5.4863615   8.236409   -3.8138466  -0.24402271  6.6090164  -1.7761399\n  5.1547956  -1.3883702   3.9441588   6.9456263 ]"",""2"":""[-5.512496    8.459999   -4.0720286   0.30780053  6.5418453  -2.0173094\n  4.329849   -1.850619    2.4661791   7.479009  ]"",""3"":""[-4.701319   5.6839905 -5.632639   1.8308475  5.37125   -0.6594872\n  3.9998162 -1.7787232  1.8165828  5.620533 ]"",""4"":""[-5.359296    8.874866   -4.3641944  -0.20448175  6.3273344  -1.9227405\n  5.2117667  -1.6688701   2.2505772   7.227703  ]"",""5"":""[-5.370841   8.171834  -4.127999   0.605329   6.450131  -1.7419354\n  4.1355386 -1.7245444  2.5680315  7.3623056]"",""6"":""[-5.4182405  8.963648  -4.077017  -0.3129154  6.3092594 -1.770553\n  5.5409718 -1.2885174  2.8797588  7.4132648]"",""7"":""[-4.832595    8.174083   -4.937477   -0.17786857  7.3402495  -1.9977777\n  4.947449   -1.1944834   2.329068    7.8266377 ]"",""8"":""[-5.1688337e+00  8.6737289e+00 -4.3737369e+00 -5.3965235e-03\n  6.8013916e+00 -1.6917061e+00  5.2203379e+00 -7.6325721e-01\n  2.7374697e+00  7.9943256e+00]"",""9"":""[-5.4274983   8.657665   -3.8720396   0.32059395  6.0805187  -1.8205812\n  5.0765104  -1.7924287   2.4769783   7.9639015 ]"",""10"":""[-4.9926357   8.023318   -4.7545385   0.33231464  6.8257027  -1.7396257\n  4.266627   -1.4150608   2.3068833   7.5974317 ]"",""11"":""[-5.3485      8.903752   -3.9552603  -0.12933236  6.1064754  -1.5178839\n  5.6237183  -1.0486969   3.036072    7.6644816 ]"",""12"":""[-4.967321    8.109537   -4.3885875  -0.23629585  7.1430383  -1.8270862\n  5.14885    -1.1076312   3.3373675   7.7166653 ]"",""13"":""[-5.584733    8.742161   -3.736641    0.43352023  6.189283   -1.7354746\n  4.8071632  -1.4388947   2.645034    7.9452453 ]"",""14"":""[-5.3804913  8.138446  -3.9061625 -0.2649857  6.6855645 -1.7341797\n  5.179609  -1.328298   4.014445   6.887739 ]"",""15"":""[-5.3147607   8.415345   -4.760724   -0.35665792  7.1897016  -2.0872936\n  4.742715   -1.0622727   2.783051    7.2446623 ]"",""16"":""[-5.1560073  7.79339   -4.4039335  0.7030782  6.6202884 -1.6970953\n  3.8592827 -1.7022308  2.5808604  7.2758093]"",""17"":""[-5.337219    8.892807   -4.075077   -0.06074565  6.3424077  -1.5591055\n  5.365962   -0.90722644  2.8911474   7.8959875 ]"",""18"":""[-4.849014    8.262416   -4.787245   -0.22763279  7.438295   -2.0922902\n  5.088189   -1.1925102   2.390485    8.00551   ]"",""19"":""[-4.969811    7.2809596  -4.2666087   0.22144496  6.966707   -1.9333358\n  4.6449614  -1.6741111   3.6811066   6.8150606 ]"",""20"":""[-5.0923977  8.130037  -4.5484195  0.615876   6.357339  -1.6154109\n  4.1966376 -1.6106231  2.0807166  7.7095833]"",""21"":""[-5.2363353   8.779139   -4.1986313   0.04420361  6.4839616  -1.4826591\n  5.2413473  -0.82625425  2.839808    7.8078127 ]"",""22"":""[-5.213172    7.922045   -4.3150616   0.59727097  6.486287   -1.6040039\n  4.05698    -1.6762815   2.688666    7.062146  ]"",""23"":""[-5.358211   8.724986  -4.4934053 -0.3099913  6.5265093 -2.0279355\n  5.0743318 -1.7274444  2.3262882  6.9417834]"",""24"":""[-5.2441297   8.223056   -4.0207915  -0.05172435  6.8487816  -1.936185\n  5.329634   -1.0667939   3.5665812   7.677256  ]"",""25"":""[-4.4077716   7.3648305  -5.921381   -0.72674555  7.9829154  -2.0318975\n  4.4227657  -0.23399448  3.3167982   7.01347   ]"",""26"":""[-5.3818464   8.447035   -3.943139    0.48393846  5.87684    -1.6101829\n  5.031287   -1.5958116   2.5349703   7.7547693 ]"",""27"":""[-4.9096327  7.5927978 -4.426503  -0.2157855  6.923644  -1.8485157\n  5.1079216 -1.4510001  3.7236354  6.7965927]"",""28"":""[-4.9295216  8.406901  -4.608748  -0.7957179  7.1097984 -1.9143524\n  5.616022  -1.0872831  3.3566248  7.288234 ]"",""29"":""[-4.9968786   7.4187326  -4.1834383   0.08871128  7.001066   -1.9343829\n  4.8122883  -1.6037503   3.8302703   6.9078064 ]"",""30"":""[-5.203739    7.949986   -3.9736114   0.03926384  6.9238887  -2.084244\n  5.076976   -1.4712323   3.5427704   7.597248  ]"",""31"":""[-5.6028733   8.705262   -3.7347167   0.54576385  6.239715   -1.7370796\n  4.6574793  -1.407998    2.5815115   7.9738536 ]"",""32"":""[-5.3045044  8.29408   -4.2983794 -0.5192624  6.745919  -2.098441\n  5.1750884 -1.7496039  3.1785307  6.589309 ]"",""33"":""[-4.9045925   8.479887   -4.954168   -0.25497842  6.8919516  -1.746563\n  5.1054897  -1.1379164   2.2211807   7.7794857 ]"",""34"":""[-5.323955    8.043213   -3.9651659  -0.23497468  6.7626443  -1.7636336\n  5.1590567  -1.2929718   4.0217752   6.9381323 ]"",""35"":""[-5.2334847  7.900849  -4.0237837 -0.1372797  6.6747103 -1.671454\n  4.9804616 -1.5087861  3.892932   6.71005  ]"",""36"":""[-5.3273315   8.609856   -4.456316   -0.58272815  6.6606956  -2.115105\n  5.18422    -1.7443755   2.691108    6.909912  ]"",""37"":""[-5.3044157  8.669904  -4.175875  -0.3867452  6.4892926 -1.633399\n  5.461215  -1.0430895  3.3369157  7.068929 ]"",""38"":""[-5.3064165   8.141025   -4.245428    0.45823044  6.600974   -1.7707634\n  4.220784   -1.622355    2.6647263   7.261029  ]"",""39"":""[-4.493212    7.3706617  -5.802658   -0.63266486  7.8692594  -2.027297\n  4.3855267  -0.36029583  3.3035097   6.9488688 ]"",""40"":""[-4.9497213   7.897963   -4.4659724  -0.46545365  6.919104   -1.9726237\n  5.35563    -1.4260603   3.5729446   6.8490252 ]"",""41"":""[-5.5229664   8.91603    -3.9546509  -0.16280818  6.3687234  -1.8109934\n  5.404179   -1.077307    2.9916162   7.79096   ]"",""42"":""[-5.3723674   8.233274   -4.5095196   0.22969857  6.836211   -1.959402\n  4.107343   -1.535305    2.5019262   7.2602377 ]"",""43"":""[-4.5691457  5.77471   -5.3863697  1.8212347  5.4437723 -0.6693801\n  3.7748585 -1.6564884  1.8674637  5.3104115]"",""44"":""[-5.0256367   7.4472594  -4.177938    0.19896981  6.736921   -1.6392872\n  4.6747327  -1.67169     3.7675579   6.6836677 ]"",""45"":""[-5.05178    7.917485  -4.7849703  0.6949429  6.4118385 -1.6269287\n  4.113501  -1.6768469  1.8887266  7.4243712]"",""46"":""[-5.410115    8.316987   -4.588011    0.05735702  6.888376   -2.0216827\n  4.247271   -1.4260322   2.5554783   7.166183  ]"",""47"":""[-5.146991    8.252117   -4.384262    0.51945496  6.7557273  -1.7544773\n  4.4238825  -1.323416    2.3784506   7.879447  ]"",""48"":""[-5.2799397   8.946726   -4.465947   -0.40091342  6.347655   -1.8910741\n  5.6206346  -1.3191137   2.402941    7.479742  ]"",""49"":""[-5.311826   8.892943  -4.1397376 -0.1720237  6.401207  -1.5134019\n  5.474223  -0.7815516  3.0260613  7.79666  ]"",""50"":""[-5.0075946   8.422175   -4.2711554  -0.66263795  6.8279314  -1.8351655\n  5.6649795  -1.2379245   3.5665522   7.1811395 ]"",""51"":""[-4.873982    8.295293   -4.7498803  -0.22850157  7.4110904  -2.0942078\n  5.112601   -1.1914752   2.4118755   8.023219  ]"",""52"":""[-4.6429987   7.427746   -5.5774603  -0.62631625  7.5167727  -1.7293354\n  4.6947956  -0.60703194  3.21625     6.7485576 ]"",""53"":""[-5.0423837   8.5486765  -4.7901034  -0.59879196  6.967659   -2.1054096\n  5.4900403  -1.30997     2.5592258   7.4072022 ]"",""54"":""[-4.9689274  8.548986  -4.941859  -0.5734032  7.0014176 -1.9884747\n  5.4036846 -1.1984981  2.4452517  7.491008 ]"",""55"":""[-5.1453533  7.920633  -4.507555   0.7370601  6.487934  -1.6618243\n  3.959154  -1.7171078  2.2280009  7.4144607]"",""56"":""[-5.055145    7.490347   -4.3455644   0.49517497  6.800588   -1.7792939\n  4.0911283  -1.7209822   3.159887    6.9593472 ]"",""57"":""[-4.8329263   8.273493   -5.1436796  -0.34362423  7.17984    -1.8690647\n  4.9973626  -1.1048155   2.2619033   7.5833793 ]"",""58"":""[-5.5587597   8.571878   -3.855008    0.50669074  6.3367147  -1.8344439\n  4.4843726  -1.6218971   2.524766    7.778178  ]"",""59"":""[-4.401946    7.3404617  -5.951197   -0.8023111   7.956206   -1.8617176\n  4.560308   -0.24152733  3.2650442   6.956064  ]"",""60"":""[-4.996036    8.425435   -4.9996185  -0.43766874  6.8695145  -1.9217458\n  5.1378856  -1.2863666   2.3793263   7.1524606 ]"",""61"":""[-4.4168205   7.3283415  -6.097524   -0.9973075   8.173368   -1.5679139\n  4.699185   -0.18694802  2.988834    7.024647  ]"",""62"":""[-4.9483705   7.3363943  -4.28862     0.18099253  6.845108   -1.780964\n  4.729476   -1.6150919   3.701339    6.715854  ]"",""63"":""[-5.4206605   8.659789   -3.846275    0.13729256  6.184517   -1.8450062\n  5.2170467  -1.7284647   2.7489362   7.8490763 ]"",""64"":""[-5.0488124  8.211869  -5.016602  -0.5075577  7.097592  -1.9736485\n  4.9341197 -1.1018583  2.8238366  6.912868 ]"",""65"":""[-5.052698    7.7938485  -4.1173315  -0.18041234  6.8560576  -1.908732\n  5.305755   -1.3819594   3.89311     7.0821877 ]"",""66"":""[-5.41376     9.054021   -4.2213345  -0.31950375  6.256427   -1.7778525\n  5.615274   -1.1461961   2.6542213   7.5531635 ]"",""67"":""[-5.093638    7.7793694  -4.2148676   0.15773875  6.575987   -1.5292876\n  4.6516104  -1.592729    3.4600356   6.743441  ]"",""68"":""[-5.3232546   8.732137   -4.2120366   0.14988561  6.1402884  -1.802997\n  5.0750084  -1.7341253   2.204109    7.654963  ]"",""69"":""[-5.0987277   7.9781275  -4.5701237   0.59837806  6.663723   -1.7264055\n  4.046817   -1.6047076   2.2624552   7.552095  ]"",""70"":""[-5.3675056   8.637828   -4.6001062  -0.50711304  6.780991   -2.115529\n  5.236053   -1.4073955   2.6624565   6.884361  ]"",""71"":""[-4.4271684   5.426744   -5.735168    2.0301912   5.288608   -0.38578022\n  3.690876   -1.5441273   1.9978974   5.53929   ]"",""72"":""[-5.2758718   8.628014   -3.998874   -0.37689805  6.4720597  -1.6637924\n  5.662324   -1.0713879   3.5433598   7.4035892 ]"",""73"":""[-5.22955    8.786195  -4.2822943  0.0799533  6.4328837 -1.5783032\n  5.148329  -1.0059421  2.5417511  7.8693743]"",""74"":""[-5.061052    7.7784557  -4.2225     -0.10160325  7.0785246  -2.104292\n  5.1026106  -1.4215779   3.6067932   7.2512746 ]"",""75"":""[-5.1941953  8.388804  -4.4586005  0.2118833  6.438925  -1.5869055\n  4.7134447 -1.326824   2.5340421  7.005682 ]"",""76"":""[-4.3711734  7.4587927 -6.251301  -1.206422   8.174655  -1.4451221\n  4.9083385 -0.0276198  2.986475   7.179851 ]"",""77"":""[-5.5664053   8.96312    -4.1541667  -0.30536535  6.419736   -1.9809887\n  5.363888   -1.1762962   2.768513    7.6501412 ]"",""78"":""[-4.2836556   5.808856   -5.3377786   1.779455    5.3794956  -0.76732105\n  3.7937467  -1.4259359   1.8353759   5.1679783 ]"",""79"":""[-5.1115646  7.577424  -4.3735614  0.5238391  6.545871  -1.5748003\n  4.183052  -1.661493   3.0698538  6.726031 ]"",""80"":""[-4.489187   7.353429  -5.815654  -0.7753489  7.830766  -1.7919399\n  4.6270456 -0.4087594  3.2313216  6.8808217]"",""81"":""[-4.896338   8.413152  -5.125796  -0.3830402  7.0868607 -1.786866\n  5.0423975 -1.0317296  2.2387874  7.6379333]"",""82"":""[-5.3371344  8.567041  -4.048424   0.417055   6.1621637 -1.8057457\n  4.883882  -1.7875882  2.2929149  7.9720006]"",""83"":""[-3.933036    7.2372828  -6.5683546  -1.1258116   8.316118   -1.8875991\n  4.592475    0.43666658  3.3128846   7.027699  ]"",""84"":""[-4.8237734   8.214733   -4.849689   -0.68462026  7.4175544  -1.885775\n  5.360656   -0.85223234  3.223457    7.5582833 ]"",""85"":""[-3.8933926   7.376247   -6.670706   -1.276299    8.181463   -1.8838544\n  4.7287283   0.32131144  3.1338646   7.030811  ]"",""86"":""[-4.830174   8.209188  -4.800812  -0.4485934  7.2794857 -1.9755363\n  5.3404512 -1.176213   2.846288   7.638777 ]"",""87"":""[-4.3644280e+00  7.4570704e+00 -6.1986370e+00 -1.1846786e+00\n  8.3118563e+00 -1.4958625e+00  4.8776264e+00 -2.4277098e-03\n  2.8732574e+00  7.1782866e+00]"",""88"":""[-4.365292   5.526697  -5.6278896  1.9047481  5.273777  -0.5007734\n  3.8047485 -1.5207112  1.9163114  5.447461 ]"",""89"":""[-5.516439    8.622676   -4.050281    0.31801412  6.439753   -1.9438593\n  4.495054   -1.7608088   2.3688416   7.502684  ]"",""90"":""[-5.143628    7.624326   -4.19943     0.34758297  6.8412676  -1.9197941\n  4.3038826  -1.800892    3.2636085   6.9656696 ]"",""91"":""[-5.2142406   8.124434   -4.0071564  -0.29117596  6.804629   -1.9272635\n  5.415841   -1.3175      3.8266437   7.2418737 ]"",""92"":""[-5.0365715  7.8734236 -4.7031937  0.7554255  6.299081  -1.5441878\n  4.152965  -1.603059   1.9729289  7.4931846]"",""93"":""[-5.0954585  8.405236  -4.2726035 -0.5839686  6.7692385 -1.7421659\n  5.607016  -1.1286575  3.599725   7.2106824]"",""94"":""[-5.0026865   7.439018   -4.161255    0.05884081  6.876932   -1.7785871\n  4.849115   -1.6115137   3.9240003   6.755425  ]"",""95"":""[-4.55        5.4723983  -5.401927    1.9512893   5.180077   -0.50653386\n  3.678459   -1.5884337   1.7460018   5.417949  ]"",""96"":""[-5.1500506   8.318351   -4.2622766  -0.27609783  6.5860257  -1.5148306\n  5.087214   -1.351243    3.3332016   6.884735  ]"",""97"":""[-4.867437    8.351073   -4.73994    -0.62587047  7.2030187  -1.910174\n  5.507544   -1.0689205   3.068461    7.555382  ]"",""98"":""[-5.0786734   8.695537   -4.609954   -0.15037452  6.3141093  -1.6827985\n  5.3211823  -1.3901443   2.241639    7.600282  ]"",""99"":""[-3.9881992  7.342017  -6.484602  -1.1335832  8.403836  -1.9013604\n  4.700937   0.3234107  3.1548386  7.0757127]"",""100"":""[-5.3830705   8.626021   -4.438455   -0.15461563  6.513643   -2.0257704\n  4.847209   -1.8199666   2.3059316   6.986048  ]"",""101"":""[-5.4676976   8.603413   -3.8815985   0.49610582  5.920426   -1.6763816\n  4.942336   -1.6450208   2.4125264   7.851705  ]"",""102"":""[-4.3405375  5.7641296 -5.4425836  1.8636194  5.3683167 -0.7040223\n  3.7690783 -1.4757856  1.8599789  5.2734456]"",""103"":""[-5.230704    8.0363     -4.281466    0.52572113  6.49013    -1.6158701\n  4.212715   -1.577236    2.7210698   7.0942054 ]"",""104"":""[-4.5432887  5.522754  -5.627316   1.8786365  5.2398653 -0.5911381\n  3.929723  -1.6728321  1.7710227  5.480145 ]"",""105"":""[-5.2908363   8.628181   -4.102194   -0.04995091  6.831293   -1.7995652\n  5.434526   -0.66032404  3.2659414   7.8661103 ]"",""106"":""[-5.36467    8.899487  -4.065861  -0.2618559  6.268959  -1.6024042\n  5.619569  -1.0062002  3.0785606  7.502189 ]"",""107"":""[-4.566296    7.862839   -5.530155   -0.8921151   7.7419558  -1.7751497\n  5.130097   -0.45868737  3.1191587   7.3215094 ]"",""108"":""[-4.0166645   7.2737856  -6.4669304  -1.0679839   8.286321   -1.9017569\n  4.585622    0.32735094  3.2935932   7.0307503 ]"",""109"":""[-5.435065    9.103071   -3.9519844  -0.14680223  6.224783   -1.554306\n  5.5408106  -0.9615249   2.9240427   7.7588725 ]"",""110"":""[-4.8667655   8.234418   -4.8764963  -0.31640372  7.3635154  -1.9950163\n  5.096455   -1.0937405   2.5975418   7.7739406 ]"",""111"":""[-4.6590123  5.523541  -5.7250676  1.9612368  5.3131695 -0.5107548\n  3.9111798 -1.7217125  1.851295   5.6374803]"",""112"":""[-4.777683   8.112911  -5.194948  -0.5380003  7.5227203 -1.903026\n  5.0860667 -0.8267068  2.6709664  7.6743317]"",""113"":""[-4.4741554   7.36052    -5.933356   -0.8315395   8.006659   -1.7101945\n  4.6039166  -0.28542593  3.1336658   7.035259  ]"",""114"":""[-4.9890413  7.863081  -4.405668   0.2359639  6.513412  -1.4619603\n  4.702616  -1.4692643  3.0594485  6.952722 ]"",""115"":""[-4.559645    5.911456   -5.2500396   1.6754818   5.4214096  -0.79268056\n  3.8985457  -1.625465    1.7710626   5.3652015 ]"",""116"":""[-5.0439544   7.4418583  -4.222821    0.29893288  6.9041033  -1.8915714\n  4.4431996  -1.7414513   3.5097485   6.88586   ]"",""117"":""[-5.166685    8.678056   -4.3804526   0.10299455  6.363722   -1.5702994\n  5.0936465  -1.1436392   2.4258065   7.774218  ]"",""118"":""[-4.528642    7.8203306  -5.688611   -0.869135    7.9032826  -1.7921104\n  5.04508    -0.45407125  2.8146975   7.482543  ]"",""119"":""[-5.2238398   8.964335   -4.488213   -0.29721898  6.2767715  -1.797773\n  5.5433702  -1.3355452   2.2531478   7.569477  ]"",""120"":""[-5.4645348  8.786337  -3.9832363 -0.422056   6.492001  -1.7950369\n  5.6403227 -1.0803698  3.4335783  7.260321 ]"",""121"":""[-4.501543    7.512398   -6.0771866  -1.1999027   8.268359   -1.4283918\n  5.005706   -0.12122931  2.894078    7.216342  ]"",""122"":""[-5.356619    8.115834   -4.100058    0.37720636  6.6785364  -1.9506577\n  4.279658   -1.8089482   2.7971401   7.280852  ]"",""123"":""[-5.208629    8.284104   -4.865459   -0.48922956  7.164326   -2.1006997\n  4.819014   -1.1665205   2.8784115   6.892745  ]"",""124"":""[-4.6378856   8.048244   -5.545664   -0.94312304  7.799976   -1.5595636\n  5.130118   -0.2856909   2.8646321   7.4151673 ]"",""125"":""[-4.9551682  8.363169  -4.4715195 -0.5408958  7.029984  -1.7715814\n  5.534281  -1.0351546  3.3821008  7.5275135]"",""126"":""[-5.4023085  8.470651  -3.925402   0.3364605  6.60743   -1.9448992\n  4.7922497 -1.5134974  2.6848278  8.089148 ]"",""127"":""[-4.534571    5.7440634  -5.4839115   1.7718487   5.271451   -0.77002877\n  4.0310893  -1.6382713   1.7481414   5.4907737 ]"",""128"":""[-4.738171   5.4692183 -5.762203   2.0343795  5.362741  -0.2894559\n  3.7902164 -1.7066228  1.9768448  5.83384  ]"",""129"":""[-4.5046453   5.340323   -5.741109    2.023829    5.1857576  -0.38997564\n  3.7533941  -1.5645094   1.9039917   5.5277987 ]"",""130"":""[-5.202988    7.8531055  -4.4678483   0.39615527  6.5632305  -1.6408353\n  4.2169847  -1.5807067   2.838804    6.752082  ]"",""131"":""[-5.2058654   7.8036013  -4.2271976   0.52491343  6.522844   -1.6086392\n  4.1810017  -1.6816384   3.005789    6.94647   ]"",""132"":""[-4.028775    7.3445816  -6.5431323  -1.1600394   8.280922   -1.719908\n  4.7511616   0.47471195  3.1597717   7.1456203 ]"",""133"":""[-5.2915015   8.684723   -4.147875   -0.05885747  6.779404   -1.7433422\n  5.397682   -0.6874709   3.1550865   7.9098606 ]"",""134"":""[-3.8969572   7.3078647  -6.640542   -1.2012438   8.261402   -1.8760735\n  4.690277    0.45190623  3.1964364   7.0684233 ]"",""135"":""[-5.4710283   8.693269   -3.8369966  -0.32504904  6.438151   -1.8322854\n  5.601714   -1.2451624   3.5008364   7.4132333 ]"",""136"":""[-4.341426    7.398589   -6.2913103  -1.2795203   8.370247   -1.4149101\n  4.878152    0.05933759  2.8517184   7.175594  ]"",""137"":""[-5.3265176   8.55606    -4.5357037  -0.52537674  6.7356663  -2.1046154\n  5.1348433  -1.6245986   2.7090807   6.771849  ]"",""138"":""[-3.954396    7.3362136  -6.613658   -1.2264242   8.2443495  -1.7255836\n  4.8002176   0.47813335  3.0875502   7.126342  ]"",""139"":""[-5.230825   8.167556  -3.9719164 -0.2650046  6.5804524 -1.8859534\n  5.5107794 -1.4319091  3.726186   7.2133937]"",""140"":""[-5.1404057  7.8349576 -4.0513954 -0.2264764  6.7900515 -1.7921743\n  5.2110624 -1.4534314  4.009844   6.9030757]"",""141"":""[-5.025961   7.9152875 -4.389492  -0.3394467  6.986939  -2.1163583\n  5.2769794 -1.4562773  3.4706893  7.0168724]"",""142"":""[-5.3703666  8.528346  -4.1991253  0.211907   6.3345957 -1.8875471\n  4.729203  -1.8464284  2.3387735  7.360002 ]"",""143"":""[-5.0529423   8.070328   -4.5451617   0.53889984  6.3475413  -1.5281179\n  4.1725235  -1.4985386   2.2733245   7.659427  ]"",""144"":""[-4.629501    7.966807   -5.629734   -0.9730535   7.8636827  -1.5379347\n  5.067821   -0.26428762  2.8390749   7.34986   ]"",""145"":""[-5.062297    7.5902658  -4.3259177   0.33535114  6.545143   -1.5314978\n  4.470019   -1.6060768   3.3289557   6.6582594 ]"",""146"":""[-4.5363736  5.3446918 -5.8227234  2.088352   5.2023444 -0.4086688\n  3.7962742 -1.619088   1.8944935  5.6008635]"",""147"":""[-4.3799496  5.7345357 -5.561872   1.8770701  5.439941  -0.6484743\n  3.7612288 -1.5257785  2.041105   5.444591 ]"",""148"":""[-5.316848    8.742115   -4.081282   -0.07879978  6.673509   -1.7054901\n  5.456725   -0.7211091   3.1801882   7.890907  ]"",""149"":""[-5.221077   8.856282  -4.5610075 -0.3365313  6.4353094 -1.9002131\n  5.4150567 -1.422167   2.2620413  7.429061 ]"",""150"":""[-5.376182    8.259715   -4.463725    0.11837834  6.8444543  -1.966384\n  4.30906    -1.3808324   2.7275746   7.3173127 ]"",""151"":""[-3.9539096  7.3199124 -6.574859  -1.201919   8.350324  -1.8348554\n  4.727737   0.3815054  3.0966253  7.0739923]"",""152"":""[-4.407183    7.485582   -6.2506166  -1.2856992   8.205426   -1.3269806\n  4.9896927  -0.06618147  2.8508084   7.2048845 ]"",""153"":""[-4.3381114  7.4822946 -6.135182  -1.0165731  8.270094  -1.6294954\n  4.7774353 -0.0728014  2.8441615  7.152022 ]"",""154"":""[-5.2738557   8.946211   -4.3028183  -0.28613603  6.1649256  -1.6963248\n  5.699266   -1.2126114   2.5957942   7.540908  ]"",""155"":""[-5.495209    8.551506   -4.322802   -0.39775687  7.000852   -2.055193\n  5.1027217  -1.0500646   3.2427926   7.270531  ]"",""156"":""[-4.330626    7.562143   -6.1000624  -1.0357306   8.319891   -1.6678958\n  4.841453   -0.04842168  2.795599    7.213311  ]"",""157"":""[-4.935645    8.439568   -4.5244946  -0.48578757  6.9060297  -1.6402462\n  5.4908233  -1.0208716   3.2075665   7.5576935 ]"",""158"":""[-4.5166516   7.500867   -5.7922587  -0.7777977   7.86413    -1.7120552\n  4.7136717  -0.34527823  3.14097     7.1207023 ]"",""159"":""[-5.3466983   8.2456455  -4.1511755  -0.41222274  6.6960454  -2.0189583\n  5.1075835  -1.7418205   3.3347013   6.6496344 ]"",""160"":""[-4.69648    5.8117933 -5.5777783  1.7414087  5.3752723 -0.8162274\n  4.126533  -1.7767398  1.8332424  5.7212605]"",""161"":""[-4.338197   5.6038094 -5.6912336  1.9217379  5.2969475 -0.5008254\n  3.7724025 -1.4880989  2.036903   5.530478 ]"",""162"":""[-4.451289    5.344892   -5.8264966   2.1148047   5.2291884  -0.33399624\n  3.6845934  -1.5445393   1.9897602   5.590478  ]"",""163"":""[-4.4824104  5.685239  -5.4398475  1.7544669  5.2570343 -0.7235122\n  3.9877036 -1.6080624  1.6997294  5.3900585]"",""164"":""[-4.468524    5.781273   -5.3018055   1.7065412   5.3945365  -0.73673075\n  3.8585222  -1.5867616   1.8410566   5.2532306 ]"",""165"":""[-4.50263     5.358576   -5.7709384   2.0584474   5.2037864  -0.41650462\n  3.755305   -1.5806378   1.9080515   5.553762  ]"",""166"":""[-4.8462434   8.28757    -5.137769   -0.1948127   7.1381836  -1.7091265\n  4.9465966  -0.81584275  2.2628002   7.7221556 ]"",""167"":""[-5.4469113   8.695475   -4.37355    -0.50496095  6.724692   -2.047342\n  5.3707027  -1.2957035   2.963687    6.984507  ]"",""168"":""[-4.4404554   7.326681   -6.200783   -1.213586    8.3709955  -1.3673253\n  4.881779   -0.09603188  2.9128528   7.0714335 ]"",""169"":""[-5.1005282   8.345263   -4.473243    0.32234654  6.982977   -1.8078516\n  4.6865754  -1.0563122   2.4515326   8.003502  ]"",""170"":""[-5.2211537   8.702308   -4.325309    0.12774818  6.160648   -1.7332977\n  5.163488   -1.5854375   2.1923013   7.8133645 ]"",""171"":""[-5.138975    8.28658    -4.404262    0.38898978  6.8910003  -1.8189347\n  4.542882   -1.2586156   2.455274    7.8419356 ]"",""172"":""[-5.130994    7.643866   -4.07859     0.02785873  6.773435   -1.7721119\n  4.834275   -1.6290324   3.8329437   6.7826414 ]"",""173"":""[-5.077937    7.4970155  -4.158951    0.13852333  6.9070797  -1.9244794\n  4.7327323  -1.6328033   3.6725497   6.9139795 ]"",""174"":""[-4.957615   8.142618  -5.1297584 -0.6429762  7.437382  -2.069457\n  4.9259796 -0.9138054  2.904989   7.08049  ]"",""175"":""[-5.2375145   8.470124   -4.5352087  -0.01794901  6.4799085  -1.7239588\n  4.862798   -1.4015453   2.5240781   6.8437214 ]"",""176"":""[-5.3352923  8.44334   -4.267674  -0.5017438  6.6823673 -2.0070794\n  5.2173853 -1.6260818  3.1518352  6.7869954]"",""177"":""[-4.5552545  7.8914237 -5.752173  -0.8926872  7.921539  -1.6887003\n  5.004044  -0.3643996  2.6925437  7.4342337]"",""178"":""[-4.715991   5.7802563 -5.417971   1.7901143  5.4244866 -0.6848323\n  3.8810115 -1.7656912  1.7921358  5.4539514]"",""179"":""[-5.126237    8.347863   -4.4250927   0.22677274  7.0615582  -1.9126078\n  4.7697983  -1.1169761   2.5305247   8.06758   ]"",""180"":""[-4.4016194  7.359745  -6.240955  -1.2081683  8.277974  -1.3875053\n  4.8406568 -0.0655033  2.8816323  7.111462 ]"",""181"":""[-5.560449   8.458955  -3.769955   0.6818772  6.231166  -1.7043628\n  4.4477215 -1.5043021  2.6343575  7.80817  ]""},""topic"":{""0"":-1,""1"":-1,""2"":-1,""3"":0,""4"":5,""5"":9,""6"":11,""7"":4,""8"":-1,""9"":6,""10"":-1,""11"":-1,""12"":-1,""13"":6,""14"":7,""15"":-1,""16"":8,""17"":10,""18"":-1,""19"":7,""20"":8,""21"":-1,""22"":9,""23"":5,""24"":-1,""25"":3,""26"":-1,""27"":-1,""28"":-1,""29"":7,""30"":-1,""31"":6,""32"":-1,""33"":4,""34"":7,""35"":7,""36"":5,""37"":-1,""38"":9,""39"":3,""40"":-1,""41"":-1,""42"":-1,""43"":0,""44"":7,""45"":8,""46"":-1,""47"":-1,""48"":11,""49"":10,""50"":-1,""51"":-1,""52"":-1,""53"":-1,""54"":4,""55"":8,""56"":7,""57"":4,""58"":6,""59"":3,""60"":4,""61"":3,""62"":7,""63"":-1,""64"":-1,""65"":7,""66"":11,""67"":7,""68"":6,""69"":8,""70"":5,""71"":0,""72"":-1,""73"":-1,""74"":-1,""75"":-1,""76"":3,""77"":-1,""78"":0,""79"":9,""80"":3,""81"":4,""82"":6,""83"":1,""84"":-1,""85"":1,""86"":4,""87"":3,""88"":0,""89"":-1,""90"":-1,""91"":7,""92"":8,""93"":-1,""94"":7,""95"":0,""96"":-1,""97"":-1,""98"":-1,""99"":1,""100"":-1,""101"":6,""102"":0,""103"":9,""104"":0,""105"":-1,""106"":10,""107"":2,""108"":1,""109"":10,""110"":4,""111"":0,""112"":-1,""113"":3,""114"":-1,""115"":0,""116"":7,""117"":-1,""118"":2,""119"":11,""120"":-1,""121"":3,""122"":9,""123"":-1,""124"":2,""125"":-1,""126"":-1,""127"":0,""128"":0,""129"":0,""130"":9,""131"":9,""132"":1,""133"":-1,""134"":1,""135"":-1,""136"":3,""137"":5,""138"":1,""139"":-1,""140"":7,""141"":-1,""142"":-1,""143"":8,""144"":2,""145"":-1,""146"":0,""147"":0,""148"":-1,""149"":-1,""150"":-1,""151"":1,""152"":3,""153"":3,""154"":11,""155"":-1,""156"":3,""157"":-1,""158"":3,""159"":-1,""160"":0,""161"":0,""162"":0,""163"":0,""164"":0,""165"":0,""166"":4,""167"":5,""168"":3,""169"":-1,""170"":-1,""171"":-1,""172"":7,""173"":7,""174"":-1,""175"":-1,""176"":5,""177"":2,""178"":0,""179"":-1,""180"":3,""181"":-1},""exemplar"":{""0"":null,""1"":null,""2"":null,""3"":null,""4"":null,""5"":null,""6"":""*"",""7"":""*"",""8"":null,""9"":""*"",""10"":null,""11"":null,""12"":null,""13"":""*"",""14"":null,""15"":null,""16"":null,""17"":""*"",""18"":null,""19"":""*"",""20"":""*"",""21"":null,""22"":""*"",""23"":""*"",""24"":null,""25"":null,""26"":null,""27"":null,""28"":null,""29"":""*"",""30"":null,""31"":null,""32"":null,""33"":null,""34"":null,""35"":null,""36"":""*"",""37"":null,""38"":""*"",""39"":null,""40"":null,""41"":null,""42"":null,""43"":null,""44"":null,""45"":null,""46"":null,""47"":null,""48"":""*"",""49"":""*"",""50"":null,""51"":null,""52"":null,""53"":null,""54"":null,""55"":""*"",""56"":null,""57"":""*"",""58"":""*"",""59"":null,""60"":null,""61"":null,""62"":""*"",""63"":null,""64"":null,""65"":null,""66"":""*"",""67"":null,""68"":null,""69"":""*"",""70"":null,""71"":""*"",""72"":null,""73"":null,""74"":null,""75"":null,""76"":""*"",""77"":null,""78"":null,""79"":""*"",""80"":null,""81"":""*"",""82"":null,""83"":null,""84"":null,""85"":null,""86"":null,""87"":""*"",""88"":null,""89"":null,""90"":null,""91"":null,""92"":""*"",""93"":null,""94"":""*"",""95"":null,""96"":null,""97"":null,""98"":null,""99"":""*"",""100"":null,""101"":""*"",""102"":null,""103"":null,""104"":null,""105"":null,""106"":""*"",""107"":""*"",""108"":null,""109"":""*"",""110"":""*"",""111"":null,""112"":null,""113"":null,""114"":null,""115"":null,""116"":null,""117"":null,""118"":""*"",""119"":""*"",""120"":null,""121"":null,""122"":null,""123"":null,""124"":""*"",""125"":null,""126"":null,""127"":null,""128"":null,""129"":""*"",""130"":null,""131"":""*"",""132"":null,""133"":null,""134"":""*"",""135"":null,""136"":""*"",""137"":""*"",""138"":""*"",""139"":null,""140"":null,""141"":null,""142"":null,""143"":null,""144"":""*"",""145"":null,""146"":""*"",""147"":null,""148"":null,""149"":null,""150"":null,""151"":""*"",""152"":""*"",""153"":null,""154"":""*"",""155"":null,""156"":null,""157"":null,""158"":null,""159"":null,""160"":null,""161"":null,""162"":""*"",""163"":null,""164"":null,""165"":""*"",""166"":null,""167"":null,""168"":null,""169"":null,""170"":null,""171"":null,""172"":null,""173"":null,""174"":null,""175"":null,""176"":""*"",""177"":""*"",""178"":null,""179"":null,""180"":""*"",""181"":null},""word*"":{""0"":""data"",""1"":""user"",""2"":""visualization"",""3"":""ieee"",""4"":""model"",""5"":""computer"",""6"":""models*"",""7"":""interaction*"",""8"":""process"",""9"":""clustering*"",""10"":""knowledge"",""11"":""systems"",""12"":""results"",""13"":""algorithms*"",""14"":""users"",""15"":""time"",""16"":""human"",""17"":""methods*"",""18"":""feedback"",""19"":""conference*"",""20"":""analytic*"",""21"":""techniques"",""22"":""science*"",""23"":""figure*"",""24"":""tasks"",""25"":""high"",""26"":""classi\ufb01cation"",""27"":""topic"",""28"":""example"",""29"":""proceedings*"",""30"":""transactions"",""31"":""algorithm"",""32"":""text"",""33"":""reasoning"",""34"":""people"",""35"":""authors"",""36"":""domain*"",""37"":""features"",""38"":""technology*"",""39"":""vast"",""40"":""section"",""41"":""parameters"",""42"":""exploration"",""43"":""di\ufb00erent"",""44"":""paper"",""45"":""sensemaking"",""46"":""space"",""47"":""training"",""48"":""framework*"",""49"":""approaches*"",""50"":""examples"",""51"":""input"",""52"":""http"",""53"":""context"",""54"":""sense"",""55"":""cognitive*"",""56"":""international"",""57"":""understanding*"",""58"":""computation*"",""59"":""similar"",""60"":""view"",""61"":""integrated"",""62"":""symposium*"",""63"":""clusters"",""64"":""north"",""65"":""topics"",""66"":""frameworks*"",""67"":""literature"",""68"":""regression"",""69"":""intelligence*"",""70"":""frame"",""71"":""sacha*"",""72"":""types"",""73"":""technique"",""74"":""events"",""75"":""design"",""76"":""discussed*"",""77"":""constraints"",""78"":""keim"",""79"":""university*"",""80"":""relevant"",""81"":""thinking*"",""82"":""unsupervised"",""83"":""modify"",""84"":""result"",""85"":""describe"",""86"":""situation"",""87"":""called*"",""88"":""turkay"",""89"":""simulation"",""90"":""media"",""91"":""items"",""92"":""speci\ufb01c*"",""93"":""ones"",""94"":""papers*"",""95"":""de\ufb01ne"",""96"":""works"",""97"":""case"",""98"":""theory"",""99"":""select*"",""100"":""projection"",""101"":""bayesian*"",""102"":""ribarsky"",""103"":""engineering"",""104"":""hauser"",""105"":""stages"",""106"":""structures*"",""107"":""generally*"",""108"":""improve"",""109"":""mechanisms*"",""110"":""response*"",""111"":""springer"",""112"":""expectations"",""113"":""advanced"",""114"":""study"",""115"":""e\ufb00ort"",""116"":""press"",""117"":""methodology"",""118"":""expected*"",""119"":""paradigm*"",""120"":""sets"",""121"":""found"",""122"":""streaming"",""123"":""location"",""124"":""helps*"",""125"":""cases"",""126"":""latency"",""127"":""jmlr"",""128"":""york"",""129"":""chang*"",""130"":""park"",""131"":""society*"",""132"":""produce"",""133"":""steps"",""134"":""observe*"",""135"":""subsets"",""136"":""represented*"",""137"":""image*"",""138"":""demonstrate*"",""139"":""category"",""140"":""articles"",""141"":""timeline"",""142"":""convergence"",""143"":""quantitative"",""144"":""trying*"",""145"":""professor"",""146"":""wang*"",""147"":""ramakrishnan"",""148"":""phases"",""149"":""metaphor"",""150"":""resources"",""151"":""introduce*"",""152"":""analyzed*"",""153"":""combining"",""154"":""regime*"",""155"":""seconds"",""156"":""carrying"",""157"":""claims"",""158"":""tentative"",""159"":""annotations"",""160"":""sigchi"",""161"":""basu"",""162"":""siam*"",""163"":""fiaux"",""164"":""streit"",""165"":""zhang*"",""166"":""structuring"",""167"":""frames"",""168"":""placed"",""169"":""preparation"",""170"":""generalization"",""171"":""deployment"",""172"":""journals"",""173"":""conferences"",""174"":""target"",""175"":""spire"",""176"":""images*"",""177"":""predicting*"",""178"":""e\ufb00ects"",""179"":""delay"",""180"":""grouped*"",""181"":""aaai""},""pos"":{""0"":1,""1"":2,""2"":3,""3"":1,""4"":1,""5"":1,""6"":1,""7"":1,""8"":4,""9"":1,""10"":5,""11"":6,""12"":7,""13"":2,""14"":1,""15"":8,""16"":1,""17"":1,""18"":9,""19"":2,""20"":2,""21"":10,""22"":2,""23"":2,""24"":11,""25"":1,""26"":12,""27"":13,""28"":14,""29"":3,""30"":15,""31"":3,""32"":16,""33"":2,""34"":4,""35"":5,""36"":3,""37"":17,""38"":3,""39"":2,""40"":18,""41"":19,""42"":20,""43"":2,""44"":6,""45"":3,""46"":21,""47"":22,""48"":2,""49"":2,""50"":23,""51"":24,""52"":25,""53"":26,""54"":3,""55"":4,""56"":7,""57"":4,""58"":4,""59"":3,""60"":5,""61"":4,""62"":8,""63"":27,""64"":28,""65"":9,""66"":3,""67"":10,""68"":5,""69"":5,""70"":4,""71"":3,""72"":29,""73"":30,""74"":31,""75"":32,""76"":5,""77"":33,""78"":4,""79"":4,""80"":6,""81"":6,""82"":6,""83"":1,""84"":34,""85"":2,""86"":7,""87"":7,""88"":5,""89"":35,""90"":36,""91"":11,""92"":6,""93"":37,""94"":12,""95"":6,""96"":38,""97"":39,""98"":40,""99"":3,""100"":41,""101"":7,""102"":7,""103"":5,""104"":8,""105"":42,""106"":3,""107"":1,""108"":4,""109"":4,""110"":8,""111"":9,""112"":43,""113"":8,""114"":44,""115"":10,""116"":13,""117"":45,""118"":2,""119"":4,""120"":46,""121"":9,""122"":6,""123"":47,""124"":3,""125"":48,""126"":49,""127"":11,""128"":12,""129"":13,""130"":7,""131"":8,""132"":5,""133"":50,""134"":6,""135"":51,""136"":10,""137"":5,""138"":7,""139"":52,""140"":14,""141"":53,""142"":54,""143"":7,""144"":4,""145"":55,""146"":14,""147"":15,""148"":56,""149"":57,""150"":58,""151"":8,""152"":11,""153"":12,""154"":5,""155"":59,""156"":13,""157"":60,""158"":14,""159"":61,""160"":16,""161"":17,""162"":18,""163"":19,""164"":20,""165"":21,""166"":9,""167"":6,""168"":15,""169"":62,""170"":63,""171"":64,""172"":15,""173"":16,""174"":65,""175"":66,""176"":7,""177"":5,""178"":22,""179"":67,""180"":16,""181"":68},""x2D"":{""0"":10.516160965,""1"":6.6977701187,""2"":9.9630289078,""3"":-14.664727211,""4"":8.7696256638,""5"":9.5274772644,""6"":8.0959424973,""7"":4.5810551643,""8"":8.5476999283,""9"":10.0578346252,""10"":10.0365934372,""11"":7.8800706863,""12"":6.1868920326,""13"":10.4380702972,""14"":6.7652001381,""15"":5.2459864616,""16"":9.6126394272,""17"":8.3388252258,""18"":4.5939278603,""19"":7.5836539268,""20"":10.1012716293,""21"":8.6063137054,""22"":9.2956638336,""23"":8.4038829803,""24"":6.6323947906,""25"":-4.0818610191,""26"":10.1115016937,""27"":7.2200264931,""28"":6.0628027916,""29"":7.4384441376,""30"":6.7134270668,""31"":10.4718284607,""32"":7.659599781,""33"":4.4526410103,""34"":6.8037223816,""35"":6.9499464035,""36"":8.0551309586,""37"":7.0539212227,""38"":9.3436861038,""39"":-3.9009468555,""40"":7.1790509224,""41"":8.0940599442,""42"":9.5578994751,""43"":-15.2295646667,""44"":7.5220956802,""45"":10.1983032227,""46"":9.4740314484,""47"":10.1423444748,""48"":8.5749664307,""49"":8.2303142548,""50"":6.6450676918,""51"":4.6548428535,""52"":-3.8780543804,""53"":5.0641064644,""54"":4.8935132027,""55"":9.9173164368,""56"":8.4159965515,""57"":4.6267104149,""58"":10.4049901962,""59"":-3.9542865753,""60"":4.7912316322,""61"":-3.4275479317,""62"":7.5411496162,""63"":10.20216465,""64"":5.1867570877,""65"":6.9749727249,""66"":8.4273509979,""67"":8.0660066605,""68"":9.7657718658,""69"":10.0677747726,""70"":7.9156441689,""71"":-14.2575044632,""72"":7.0199408531,""73"":8.7658014297,""74"":7.145781517,""75"":9.0199174881,""76"":-3.1610996723,""77"":8.2529182434,""78"":-15.1205053329,""79"":8.5979709625,""80"":-3.8597536087,""81"":4.523952961,""82"":10.0120506287,""83"":0.0649424717,""84"":5.5736432076,""85"":0.4193520546,""86"":5.1914014816,""87"":-3.0517950058,""88"":-14.5582008362,""89"":9.9945020676,""90"":8.1488485336,""91"":6.6877775192,""92"":10.1301250458,""93"":6.7476511002,""94"":7.3842124939,""95"":-14.5962677002,""96"":7.3660840988,""97"":5.6765370369,""98"":8.9342479706,""99"":0.1393268108,""100"":8.7004699707,""101"":10.0752925873,""102"":-15.0280284882,""103"":9.0659732819,""104"":-14.5012493134,""105"":8.1832227707,""106"":7.8963546753,""107"":-3.2202477455,""108"":0.0653863922,""109"":8.1004285812,""110"":4.8093757629,""111"":-14.2628688812,""112"":4.8786740303,""113"":-3.9234359264,""114"":8.4327001572,""115"":-15.114944458,""116"":7.7501587868,""117"":8.9199724197,""118"":-3.2657935619,""119"":8.7760639191,""120"":7.1967120171,""121"":-2.7770040035,""122"":9.3279685974,""123"":5.3449521065,""124"":-3.1243832111,""125"":6.1816883087,""126"":10.3729610443,""127"":-14.7726163864,""128"":-14.0668287277,""129"":-14.2027978897,""130"":8.8014631271,""131"":8.7928705215,""132"":0.1764801443,""133"":8.2593603134,""134"":0.2294192463,""135"":7.1508674622,""136"":-2.964548111,""137"":7.7987885475,""138"":0.3344862461,""139"":6.8350548744,""140"":6.9217476845,""141"":7.175383091,""142"":9.7081327438,""143"":10.0229063034,""144"":-3.2330126762,""145"":8.2034282684,""146"":-13.9991340637,""147"":-14.7270870209,""148"":8.2045402527,""149"":8.7824029922,""150"":9.5067663193,""151"":0.2276981473,""152"":-3.0289032459,""153"":-3.2710814476,""154"":8.4091796875,""155"":6.9851408005,""156"":-3.1714913845,""157"":6.1335172653,""158"":-3.6748869419,""159"":7.4974350929,""160"":-14.7201499939,""161"":-14.5031690598,""162"":-14.0268259048,""163"":-14.9436922073,""164"":-15.1976852417,""165"":-14.1614704132,""166"":4.4175071716,""167"":7.6299862862,""168"":-3.0739815235,""169"":10.1284294128,""170"":9.6846065521,""171"":10.0202980042,""172"":7.267786026,""173"":7.5024547577,""174"":5.1735496521,""175"":8.6401729584,""176"":7.5876221657,""177"":-3.2718863487,""178"":-14.9275121689,""179"":10.0873527527,""180"":-3.1678380966,""181"":10.4151668549},""y2D"":{""0"":3.6384270191,""1"":3.0937945843,""2"":3.2757561207,""3"":-0.4963481128,""4"":4.6498842239,""5"":1.7912919521,""6"":5.620016098,""7"":3.9443261623,""8"":6.4568443298,""9"":4.394200325,""10"":2.1136116982,""11"":6.0079774857,""12"":3.9113647938,""13"":4.0077266693,""14"":2.9402899742,""15"":4.751083374,""16"":1.4232327938,""17"":6.1799559593,""18"":3.9884619713,""19"":1.6766346693,""20"":1.7050919533,""21"":6.3219242096,""22"":1.5402014256,""23"":4.3252978325,""24"":3.6460506916,""25"":5.8747653961,""26"":4.2849116325,""27"":2.5806400776,""28"":4.1627087593,""29"":1.8176060915,""30"":3.4224529266,""31"":3.9272720814,""32"":3.9757421017,""33"":4.2061543465,""34"":2.9734187126,""35"":2.6422140598,""36"":4.1453557014,""37"":4.5050787926,""38"":1.9738729,""39"":5.6979694366,""40"":3.3177294731,""41"":5.9033622742,""42"":2.1800215244,""43"":-0.5708015561,""44"":1.8905010223,""45"":1.7468394041,""46"":2.5127522945,""47"":2.3461101055,""48"":5.3452291489,""49"":6.3803319931,""50"":4.247674942,""51"":4.015253067,""52"":5.8498134613,""53"":4.3209719658,""54"":4.2626037598,""55"":1.5625524521,""56"":1.4666301012,""57"":4.4023165703,""58"":3.8709630966,""59"":5.8327417374,""60"":4.490334034,""61"":5.3739213943,""62"":1.6868952513,""63"":4.2373313904,""64"":4.5900950432,""65"":3.0113179684,""66"":5.6994919777,""67"":1.7127064466,""68"":4.4096655846,""69"":1.7144460678,""70"":4.2436571121,""71"":-1.3407586813,""72"":4.7945365906,""73"":6.1033344269,""74"":3.172467947,""75"":3.182240963,""76"":4.8827352524,""77"":5.7876582146,""78"":-0.6782286763,""79"":1.5062425137,""80"":5.9066619873,""81"":4.3173789978,""82"":4.1954674721,""83"":-3.1312427521,""84"":4.148496151,""85"":-2.7794270515,""86"":4.0474886894,""87"":4.987578392,""88"":-1.1436582804,""89"":3.5888679028,""90"":1.5721385479,""91"":3.3470880985,""92"":1.6697034836,""93"":4.1849794388,""94"":1.9246072769,""95"":-1.1138212681,""96"":3.8131670952,""97"":4.0935287476,""98"":5.1488857269,""99"":-3.0530638695,""100"":4.1420640945,""101"":4.1362214088,""102"":-0.7476218939,""103"":1.6894440651,""104"":-0.8839938045,""105"":6.5606303215,""106"":6.0033254623,""107"":6.052113533,""108"":-3.1274933815,""109"":6.0473527908,""110"":3.9472515583,""111"":-0.896394968,""112"":4.2930321693,""113"":5.7565803528,""114"":1.7545057535,""115"":-0.5099330544,""116"":1.6720079184,""117"":5.6654586792,""118"":6.0127720833,""119"":5.2231097221,""120"":4.9483346939,""121"":4.7731556892,""122"":1.8733005524,""123"":4.6732244492,""124"":5.9308896065,""125"":4.2136483192,""126"":3.8001899719,""127"":-0.4663701952,""128"":-1.1054598093,""129"":-1.246209383,""130"":1.6236134768,""131"":1.6486508846,""132"":-3.0132184029,""133"":6.5682353973,""134"":-2.9670770168,""135"":4.9640593529,""136"":4.9258346558,""137"":4.0608401299,""138"":-2.8620486259,""139"":3.502986908,""140"":2.8353972435,""141"":3.356613636,""142"":3.8286850452,""143"":1.763448,""144"":5.9130716324,""145"":1.560477376,""146"":-1.1843817234,""147"":-0.9567252398,""148"":6.5867376328,""149"":5.0905427933,""150"":2.3492965698,""151"":-2.9683954716,""152"":4.9552965164,""153"":5.3243865967,""154"":5.646695137,""155"":4.3549695015,""156"":5.1726007462,""157"":4.2441506386,""158"":5.9957752228,""159"":3.7535007,""160"":-0.4871699512,""161"":-1.2582467794,""162"":-1.392592907,""163"":-0.6588600278,""164"":-0.6030697227,""165"":-1.2549687624,""166"":4.2012228966,""167"":4.2059898376,""168"":5.014811039,""169"":2.562936306,""170"":4.5929584503,""171"":2.5036351681,""172"":2.0760605335,""173"":1.7568186522,""174"":4.5598669052,""175"":3.8530673981,""176"":4.0393915176,""177"":5.9844288826,""178"":-0.3673359156,""179"":2.6140630245,""180"":5.0764551163,""181"":3.8747999668}}",2017
LBDAM34S,False,"[-0.15178432, 0.15192266, 0.04933064, -0.014174219, 0.29179, 0.19263664, 0.3064308, -0.021809014, -0.43893442, -0.28325024, 0.16498357, -0.3877595, -0.10227441, -0.024904918, 0.090107575, 0.58922935, 0.22662696, 0.3660466, -0.27285385, 0.13321629, -0.13019925, 0.52065617, -0.28288928, 0.72890586, 0.4867777, -0.31135806, -0.12945221, -0.40974492, -0.5131947, 0.047632743, -0.08170025, 0.7132276, 0.3511933, -0.55964124, -0.24522491, -0.04164273, -0.6016551, -0.4104825, 0.09077862, -0.03588119, -0.19024843, 0.033015884, -0.40692937, -0.42184377, 0.3290206, -0.30225918, -0.16466878, -0.5781703, -0.09160034, -0.33947137, -1.5880169, 0.19459657, 0.04418971, -0.18395537, -0.38403624, 1.0308692, -0.18356103, -0.4313777, 0.1881, 0.0014042349, -0.25277808, -0.2457337, 0.081962205, 0.069377854, -0.44641083, -0.19182575, 0.4266278, -0.06222148, -0.48939824, 0.5998514, -0.56607246, 0.52616936, -0.033388704, 0.32974792, -1.0333022, -0.09242769, 0.2312942, 0.23473722, -0.18955229, 0.17518356, -0.5501514, 0.44354984, 0.033945538, -0.35802066, 0.8724594, 0.3755903, 0.0013971733, 0.06617758, 0.045467462, 0.17058972, -0.19808628, -0.24110685, -0.35349435, 0.22675717, 0.7917496, -0.026769271, -0.4875607, 0.27734017, -0.08489506, 0.2212602, ...]",{},"[-0.1457519, 0.13367872, -0.34383675, -0.15360163, 0.5483928, 0.1218277, -0.080832995, 0.021194518, -0.4272867, -0.15318137, 0.26368573, -0.04014213, 0.2577082, -0.065326795, -0.13293916, 1.0613885, -0.107163996, -0.10701444, -0.3044987, -0.16247287, -0.016011674, 0.1287874, 0.09590945, 0.5809, 0.29515502, -0.09932794, 0.040428057, 0.26935738, -0.22403328, 0.32636735, 0.17779952, 0.5664115, 0.024071775, -0.2695604, 0.10853695, 0.17176014, -0.106098115, -0.15026215, -0.07566185, 0.6795396, -0.63422155, -0.337381, -0.109767, -0.07903706, 0.08495917, -0.0989233, -0.107811555, -0.07213511, 0.174522, -0.44685864, -1.2323004, -0.22829455, 0.1971167, -0.44407794, -0.16350885, 0.6401886, -0.11044821, -0.5088065, 0.29004198, -0.11301592, -0.105747096, 0.11119502, -0.23354791, 0.016047027, 0.2629074, -0.36916733, 0.32978848, 0.32597673, -0.52791077, -0.03605535, -0.24180071, 0.08305525, -0.40913025, 0.2730119, -0.619251, 0.15731092, -0.16988666, 0.31756505, -0.11176566, -0.17708999, -0.1903623, 0.14900532, 0.22025217, -0.066204146, 0.38502842, 0.75540155, 0.18372332, 0.43454823, -0.2525988, -0.060494676, -0.37378138, -0.13260956, -0.430789, 0.54897857, 0.5799362, -0.14683916, -0.41327336, 0.013538568, -0.2002998, 0.18560271, ...]",False,False,False,False,"[-0.32328948, -0.5496176, -0.0022940098, -0.2237495, 0.44923574, -0.059027318, 0.24367972, -0.51882344, -0.05041145, 0.10951373, 0.05752582, -0.3909382, 0.4087142, 0.059422422, -0.3068601, 0.48040593, 0.0034171566, -0.39565602, 0.31559882, -0.012098643, 0.24166816, -0.22864334, -0.51869816, 0.30493355, 0.029926455, -0.11037257, 0.5414436, -0.4771287, -0.100528285, 0.11642589, 0.34472978, 0.3641013, 0.0016613102, -0.5264095, 0.019437997, 0.3734011, -0.30107525, -0.032460034, 0.03114079, -0.14803612, -0.19534016, -0.47229236, -0.08009324, 0.2393315, -0.09179118, -0.28986034, 0.092998244, -0.06396802, -0.31578928, -0.27596974, -0.78118515, 0.08630817, -0.13445614, -0.18080993, -0.407741, 0.5831915, 0.29981795, -0.39723054, -0.2611693, 0.0915898, 0.084460154, 0.09044068, 0.09626562, -0.27051657, -0.11177542, -0.26729834, 0.34157777, 0.56451917, 0.13580981, 0.18848081, -0.119620085, 0.35433978, -0.29838866, 0.27251682, -0.451643, -0.20151225, 0.2300634, 0.3484308, -0.12528442, -0.21214022, -0.33608395, 0.20158003, -0.5838042, -0.109100536, 0.2466692, 0.72864705, 0.6596312, -0.3428721, -0.5947858, 0.34083465, -0.34625363, 0.1933444, -0.04293462, 0.39111426, 0.60350573, -0.030297244, -0.24489826, -0.07103388, -0.0061289673, -0.03943264, ...]",LBDAM34S,,False,False,LBDAM34S,GKXAWLGW,[],"the effect of semantic interaction on foraging in text analysis

john wenskovitch*

virginia tech

computer science

lauren bradel†
department of defense

michelle dowling‡

virginia tech

computer science

leanna house§

virginia tech

statistics

chris north¶
virginia tech

computer science

abstract
completing text analysis tasks is a continuous sensemaking loop
of foraging for information and incrementally synthesizing it into
hypotheses. past research has shown the advantages of using spa-
tial workspaces as a means for synthesizing information through
externalizing hypotheses and creating spatial schemas. however,
spatializing the entirety of datasets becomes prohibitive as the num-
ber of documents available to the analysts grows, particularly when
only a small subset are relevant to the task at hand. starspire is a
visual analytics tool designed to explore collections of documents,
leveraging users’ semantic interactions to steer (1) a synthesis model
that aids in document layout, and (2) a foraging model to automat-
ically retrieve new relevant information. in contrast to traditional
keyword search foraging (ksf), “semantic interaction foraging”
(sif) occurs as a result of the user’s synthesis actions. to quantify
the value of semantic interaction foraging, we use starspire to
evaluate its utility for an intelligence analysis sensemaking task. se-
mantic interaction foraging accounted for 26% of useful documents
found, and it also resulted in increased synthesis interactions and
improved sensemaking task performance by users in comparison to
only using keyword search.
index terms:
human-centered computing—visualization—
empirical studies in visualization; human-centered computing—
visualization—visual analytics

1 introduction
prior research has highlighted the utility of spatializations to support
the sensemaking process for text analysis [4–6, 11, 16, 21, 23, 30, 34,
48, 52, 53]. by providing a continuous physical workspace, analysts
can externalize their hypotheses and organize data into meaningful
schemas. however, manually arranging documents is a tedious
and time-consuming task. analysts must read each document and
assess its relevance before deciding where the text belongs in an
incrementally evolving spatialization. this task is exacerbated in
realistic sensemaking scenarios because datasets are rarely small
enough to display in full, even on a large, high-resolution display.
additionally, only a small subset of available documents is typically
relevant to the analyst’s sensemaking task. analysts must then apply
a combination of searching for documents and organizing them
spatially. more speciﬁcally, analysts are tasked with two primary
challenges: foraging for relevant information, and synthesizing the
information into a coherent structure and narrative [10, 35].

these foraging and synthesizing tasks are combined in the visual
analytics tool starspire [12], which uses a spatial metaphor to serve
as a means of communicating with underlying document relevance
and spatial layout models. as the analyst synthesizes information,
starspire encodes their interactions in the workspace to update

*e-mail: jw87@vt.edu
†e-mail: lcbrade@nsa.gov
‡e-mail: dowlingm@vt.edu
§e-mail: lhouse@vt.edu
¶e-mail: north@cs.vt.edu

an underlying user model that captures the analyst’s interest foci
quantitatively. these are semantic interactions in the sense that
they directly reﬂect the analyst’s analytical thought process about
the meaning of the data (such as organizing documents, highlighting
and annotating text, etc.), rather than about manipulating model
parameters (e.g., sliders on keyword weights). the user model is
then used to support the foraging and synthesis processes.

to support the foraging process, the updated user model is used to
determine document relevance and to curate the working set of docu-
ments displayed in the workspace. therefore, in addition to allowing
for traditional keyword search foraging (ksf) for documents (i.e.,
a user types in keywords and retrieves relevant documents), the
updated user model initiates semantic interaction foraging (sif)
to automatically forage for documents that may be relevant to the
analyst. sif displays new documents that the model infers may be
of interest to the analyst based on their prior synthesis actions. to
support the synthesis process, the updated user model is also used to
adjust the spatial layout, allowing the analyst to organize and visual-
ize the working set using a “proximity ≈ similarity” metaphor [20].
these two processes work together in a contextual manner. syn-
thesis actions by the analyst within the spatial workspace (contextual
input) serve to initiate sif algorithms, and the resulting newly-
foraged documents are automatically positioned within the space
(contextual output) by the synthesis layout algorithm.

this capability for sif raises several research questions. does sif
retrieve useful relevant information? does it retrieve information that
might not be found using ksf alone? how does it affect analysts’
interactions, sensemaking process, and analytic performance? to
evaluate the utility of semantic interaction foraging for sensemaking
tasks, in particular the translation of semantic interactions into sif,
we conducted a comparative user study using a text dataset with
a known ground truth from the vast 2007 challenge [36]. for
foraging, the control condition offered only ksf. the experimental
condition also offered sif in addition to ksf.

we found in this study that ksf and sif are complementary
foraging techniques, each with beneﬁts and limitations regarding
the set of documents that each are best at retrieving. we found that
the introduction of sif into starspire led to a boost in participant
comprehension of the scenario in the study dataset, led to an in-
crease in the number of user interactions with the workspace, and
led to the discovery of some relevant documents that were rarely
located by ksf alone. sif shows clear effects on which documents
participants retrieved, how these documents were retrieved, how
the participants interacted with these documents, and the overall
information synthesis of the participants.

the contributions of this paper are:
• the design and results of a study to determine the effects of

sif on the sensemaking process using starspire.

• an analysis of the study results to understand how sif can

beneﬁt the exploration of large document collections.

• reﬂections on using ksf and sif in visual analytics systems.

2 related work
2.1 semantic interaction
previous work has demonstrated the success of semantic interaction
for manipulating underlying models (e.g., force-directed, multidi-
mensional scaling) to shield users from the complexity of these

algorithms [22]. by manipulating the data instead of altering model
parameters explicitly, users are able to maintain focus on their analy-
ses, thus staying in the “cognitive zone” [17, 26]. similar techniques
have also been proposed in the user modeling community [2, 3].

inspired by pnnl’s in-spire [37, 51], systems such as force-
spire [20] and starspire [12] allow users to directly manipulate
data points, which are then translated to parametric model feedback.
dis-function [14] and andromeda [41] follow a similar approach
with quantitative data. these systems are limited by the size of
the datasets that can be analyzed. as the number of data points
and/or the data dimensionality increases, the execution time of the
spatial layout models increases to the point where a quick interaction-
feedback loop is no longer supported.

2.2 visualizing and interacting with text
to visualize large text corpora, typograph [19] uses varying levels
of data abstraction by utilizing extracted topics, keywords, and docu-
ment snippets. users can drill down to see the documents at different
levels of detail. the multi-model semantic interaction technique in
starspire, in comparison, addresses the scalability challenge by
continually updating a small working set of documents. documents
in starspire are either not present, iconiﬁed, or open. we previ-
ously presented a visualization pipeline that outlines how interac-
tions are captured, interpreted, and leveraged to compose a working
set of documents to visualize [12]. the multi-model visualization
pipeline demonstrates how models can be interchanged to best suit
the analyst’s needs [12]. this pipeline was previously demonstrated
using a display layout and a document relevance model, but could
easily be extended to include clustering [47], large-scale informa-
tion retrieval [25], or data streaming and sampling algorithms. for
example, vizster combines a clustering algorithm and a graph layout
algorithm to visualize social networks [29].

work by ruotsalo et al. has demonstrated the use of direct ma-
nipulation to inﬂuence information retrieval algorithms [39]. user
interactions within a radial topic spatialization were used to infer
possible user intent and thereby tune search results, working on the
principle that searches evolve incrementally [44]. this is similar to
the incremental formalism seen in sensemaking and spatial organiza-
tion [43]. they found that these interactions did not replace the need
for conducting traditional keyword searches, but that the users in the
condition that allowed for the use of the spatial interface performed
better than those who did not have this technique available. these
results closely mimic the results of our user study – inferring user in-
terests through interactions in a spatialization does not replace ksf,
yet it augments the underlying models, allowing users to identify
more pertinent pieces of information.

2.3 foraging for text
other systems provide mechanisms for visualizing search results
beyond the typical ranked list (e.g., term distribution charts [28], self-
organizing semantic maps [31]), but these methods have not received
widespread adoption and do not provide the nuanced spatial interac-
tions that intent radar does [39]. while ranked lists are well-suited
to narrow and speciﬁc searches, they may not be as well-suited for
complex sensemaking tasks. for example, conducting a literature
review requires exploring multiple facets of a topic. a simple ranked
list of results does not yield insight into documents that are mix-
tures of different topics. thus, recommendation systems typically
separate foraging and synthesis, presenting results in a separate list.
however, starspire integrates recommendation systems into the
sensemaking process by placing recommendations in context with
the user’s current analytical workspace.

2.4 recommendation systems
recommendation systems work by assigning a predicted “rating”
or “preference” score to individual items based on the relevance of

that item to an analyst [38]. starspire falls under the “content-
based ﬁltering” approach to recommendation systems, in which
these preference scores are determined by proﬁles of both the item
in question and the user exploring the collection of all items [15].

the foraging engine of starspire is also closely related to query-
by-example systems, which utilize a set of user-deﬁned query ob-
jects. query-by-example systems can be found in the literature
across many types of data, including unstructured text documents [8],
multimedia [27, 40], and musical selections [24].

our intent with this study was not to create a new algorithm for
a recommendation system; rather, we sought to evaluate the use of
semantic interaction techniques in support of document recommen-
dations. while the starspire foraging backend is relatively simple,
the weights applied to each category of semantic interaction allow
for ease of experimentation during the development of the system
and can be tuned to each scenario. in the future, these weights could
be learned either automatically or based on a large-scale study with
additional datasets. we assert that many recommendation systems
could be used as a foraging backend to starspire, which should
give even better performance than the heuristic system described in
section 3 and table 1.

3 starspire design
starspire is a visual analytics system prototype developed to
demonstrate semantic interaction with sif. many of the implemen-
tation details for starspire can be found in [12], though we brieﬂy
summarize the components relevant to the study here. in particular,
starspire contains the following concepts:

1. a working set of documents, extracted from a universal set
by an information retrieval model and relevance threshold,
representative of the foraging process. this model computes
the relevance of a document as a combination of the extracted
entities within each document and the term weights in the user
interest model. this relevance calculation combined with a
threshold serves as a ﬁlter for which documents are displayed
in the workspace.

2. a spatialization of the working set of documents, organized by
a spatial display layout model, representative of the synthesis
process. this model computes a weighted, force-directed
layout of the documents, with a document similarity function
of co-occurring terms weighted by the term weights in the user
interest model. the model places similar documents nearer
each other in the layout.

3. a high-dimensional user interest model, learned from the
user’s semantic interactions on the working set and spatial-
ization. the model consists of weights on terms to represent
the user’s interest level. the user model is input to the retrieval
and layout model algorithms.

4. sif occurs as a result of semantic interactions that update the
user interest model, which is then input into the retrieval model,
thereby updating the current working set that is displayed on
screen by the layout model. in contrast, ksf bypasses the
interest model and directly manipulates the working set.

starspire (fig. 1) provides users with a spatial workspace to
view and incrementally arrange documents in a large display space
(similar to the analyst’s workspace [6]). documents are visualized
using a node-link diagram, and are shown as iconiﬁed nodes or as
open text windows. to avoid a cluttered workspace, edges linking
documents (based on term co-occurrence) are only shown radiating
from the currently selected node. we designed a set of semantic
interactions (some of which are listed in table 1) by observing
real-world analysts who offered usability feedback in informal and
formal test settings to tune the parameters. this system is built
upon the foundation of forcespire [20], which implemented the

table 1: starspire’s available semantic interactions and their associated parametric impact on the user interest model. effects on the term
weights ranged from 15% to 40% depending on interaction.

semantic interaction
open document
minimize document
remove document
overlap documents (cluster)
highlight text in document
annotate document (notes)
search (ksf)
move or un/pin document

effect on user interest model
increase weight of terms in the document, and automatically pin.
reduce weight of terms in the document.
reduce weight of terms in the document; remove document from working set.
increase weight of terms co-occurring in the overlapped documents.
increase weight of highlighted terms, add terms to model (if not already present).
increase weight of terms in the annotation, add terms to model (if not already present).
increase weight of search terms, add terms to model (if not already present), adjust relevance threshold.
adjust layout model constraints (layout model only; no effect on user interest model).

that operate solely on the layout without updating the user’s interest
model. overall, the system was designed to reﬂect the incremental
nature of the human sensemaking process [35], such that semantic
interactions have an incremental effect on retrieval and layout.

3.3 keyword search and semantic interaction foraging
starspire allows for two types of foraging: keyword search and
semantic interaction. the system explicitly searches for matching
documents when the user executes a keyword search. executing
ksf in this manner serves a dual purpose. first, nodes are color
coded according to search hits, which can be used to identify relevant
documents already on the screen. second, documents are foraged
from the database that are not currently displayed in the workspace.
starspire uses sif when users highlight text, write annotations
on a document, or overlap documents. sif ﬁrst determines which
term weights increased in the model as a result of the interaction.

synthesis portion of the process and provided the weighted, force-
directed spatial layout. starspire adds the foraging portion of the
process, enabling data retrieval beyond what is already displayed
in the workspace. starspire also enables a richer set of visual
encodings to reﬂect term weights and document relevance.

3.1 visual encodings
nodes are encoded with node size and saturation to reﬂect docu-
ment relevance based on the underlying user interest model (fig. 1).
these encodings are updated during semantic interactions to reﬂect
incremental and constantly evolving user sensemaking. edges are
labeled with the top-weighted terms that co-occur in both documents,
and line thickness encodes the total weight of co-occurring terms to
reveal how much the documents have in common.

terms are extracted from documents using lingpipe [9] and are
underlined in the documents. based on the user interest model,
starspire automatically highlights text using a yellow gradient
saturation scale to indicate important terms. this allows for quick
skimming of documents to determine if they are worth further inves-
tigation. user-created highlights are shown in a distinct green color
to differentiate from system-generated highlights. highlighting turns
plain text ﬁles into visual glyphs that make them easier to locate
again on a large, high-resolution display [11, 46].

starspire also provides visual cues to help users navigate the
workspace. node outline color is used to indicate read or unread
status, and node hue is mapped to speciﬁc keyword searches (ksf)
the user has executed. each node is labeled with the document title,
which can aid in choosing what documents to read as well as locating
previously read documents.

3.2 semantic interactions
the semantic interactions and their effect on the user model is
described in table 1. these semantic interactions inﬂuence the
parameters of the user model, either increasing or decreasing the
weights of the associated terms. additionally, terms can be added
or removed from the model through these interactions. in order
to allow users to change the course of their analysis without being
limited by initial paths of investigation, term weights slowly decay
over time to slightly emphasize more recent interactions.

the semantic interactions provide feedback to the user interest
model and thereby steer the underlying foraging and synthesis mod-
els. after each interaction, the system determines which documents
continue to meet the relevance threshold based on the updated user
interest model. the relevance threshold can also vary depending
on the interaction. for example, removing a document raises the
relevance threshold temporarily, allowing more irrelevant documents
to be pruned from the workspace. conversely, explicitly executing
a search lowers the relevance threshold temporarily to allow more
documents to be added to the workspace. moving nodes and pinning
them to ﬁxed locations in the spatialization are the only interactions

figure 1: starspire visual encodings showing document relevance
(node size and saturation) and term importance (saturation of auto-
matic yellow highlighting of text).

next, starspire uses these terms to search the repository of all
documents in the database that are not currently displayed in the
workspace. this forms a set of documents that are candidates for
addition to the workspace. these documents are then ranked in terms
of relevance by matching them to the user’s interest model. the
top n documents that surpass the relevance threshold are then added
into the workspace where they are laid out according to the current
display layout model, placing the search results in context of the
user’s current work. this eliminates the user’s need to swap views to
execute a query, review results, and add information to the synthesis
space. in this manner, synthesis-related actions are leveraged to
forage for information, while foraging actions aid in synthesizing
information by updating the visual encodings and spatial layout.

for example, when a user overlaps two documents that they think
are related, starspire increases the weight on the terms shared
between those two documents in the user interest model, inferring
their importance to the user. starspire then forages for additional
documents containing those terms, ranks the documents on relevance
to the user interest model, and adds the most relevant to the working
set and inserts them into the layout model shown on the screen.

ksf is the traditional method of obtaining potentially relevant
documents. adding sif functionality enables the system to passively
search for information as the analyst is synthesizing documents into
their workspace. because it is based on the user interest model, sif
utilizes many more search terms than are typically contained in ksf
queries. this allows for richer matching to ﬁnd new documents that
closely ﬁt the user’s perception of what is important, and can help to
overcome the difﬁculties users have in choosing good search terms.

4 study design
the goal of this study is to quantify the impact, if any, of introducing
contextualized sif into the sensemaking process. speciﬁcally, how
does starspire with sif compare to starspire without sif? to ac-
complish this, we conducted a comparative user study with sif+ksf
(referred to as the “sif+ksf” group) as the test condition and only
ksf (referred to as the “ksf” group) as the control condition.

4.1 task description
to ensure that users would not be able to simply read all documents
in the dataset, and thus would have to forage for a small subset
of relevant documents, we chose the large vast 2007 challenge
dataset named blue iguanodon1 [36]. this dataset presents a law
enforcement/counterterrorism scenario composed of multiple latent
subplots within the overarching scenario of illegal exotic animal
sales. participants were asked to explore these documents to investi-
gate the scenario. the documents themselves include news articles,
blog posts, photographs, hand-drawn comics, and spreadsheets. all
of the data, except for the spreadsheets, was used in this study. be-
cause starspire does not currently contain support for images, all
images and comics were transcribed to describe their contents. this
resulted in 1486 documents. these documents were processed using
lingpipe [9] for entity extraction. after eliminating all entities that
only appeared a single time, 1440 entities remained in the term set.
the original blue iguanodon dataset does not contain a clear
starting point, but to aid the participants, we slightly modiﬁed the
task description to indicate a starting document for analysis: an
article describing an outbreak of a disease called “monkeypox” and
implying that chinchillas may be carriers of this disease. their goal
was to identify the cause of this outbreak. the task is suitable for
students as well as professionals, requiring no specialized analytical
experience or domain knowledge. also, there is a ground truth for
the task: the vast 2007 challenge has an associated scoring guide,
which enabled us to quantitatively evaluate the quality of analysis.

1in addition to the contest summary paper cited above, more information
about the 2007 vast challenge and the blue iguanodon dataset can be
found at http://www.cs.umd.edu/hcil/vastcontest07/.

participants used starspire on six 30” lcd panels, tiled in a
2x3 grid, on a 24-megapixel display system. this apparatus was
chosen to give users ample space to perform spatial synthesis, and
avoid the need to close documents purely for lack of space. large
high-resolution displays have been shown to have many beneﬁts for
cognitively intensive sensemaking tasks [5, 7, 18].

participants were given identical training on starspire with a
smaller dataset of 111 short text documents. after a demonstration
of the tool’s functionality, participants were instructed to solve an
analytical task in order to grow comfortable using starspire’s in-
terface. participants were then given 75 minutes to complete the
sensemaking task, requiring participants to explore the 1486 docu-
ment set to identify the hidden plots regarding illicit activity. the
task required participants to sort out and synthesize relevant informa-
tion from many documents into a coherent hypothesized narrative.
all participants used the full allotted time. although it was unlikely
to detect all of the interconnected subplots in this short time frame,
a reasonable and uniform time for analysis helped to prevent fatigue
and ensure quality analysis. to motivate participants, monetary
prizes in addition to the initial compensation were granted to the top
three performing participants.

after completing the 75-minute analytical session, participants
answered survey questions pertaining to the who, what, and where
of the plot, and described their overall hypothesis. all participants
had access to their ﬁnal workspace during the survey to be able to
reference their annotations and open documents. next, the partic-
ipants drew and annotated their spatial organizational schema on
paper. finally, users completed a survey to give feedback on their
analytical strategy, difﬁculties encountered, and how starspire
helped or hindered their analysis. the proctor conducted a brief
semi-structured interview for any remaining comments. also, par-
ticipants were able to pause and ask questions at any point during
the sensemaking session. the entire session, from informed consent
to ﬁnal survey and interview, spanned approximately two hours.

we collected logs of all interactions performed by users as well
as snapshots of the underlying model parameter values, took screen-
shots every minute, and saved their ﬁnal workspaces so that they
could be loaded and examined at a later date.

4.2 participants
we recruited 18 graduate and undergraduate students from vary-
ing academic backgrounds. participant ages ranged from 18 to 42
(µ = 23, σ = 5.6). twelve participants were male and six were
female. twelve were computer science students, ﬁve from engineer-
ing disciplines, and one from mathematics. six participants were
graduate students, and twelve were undergraduates. each participant
was randomly assigned a condition (ksf or sif+ksf, described in
the next subsection) such that each condition had an equal number
of participants.

figure 2: a participant interacting with starspire.

4.3 study conditions
this study consisted of two conditions. the test condition is referred
to as the “sif+ksf” group, in which participants had access to the
full starspire system. participants assigned to this group could
use both semantic interaction foraging and keyword search foraging
when exploring the document collection. in other words, starspire
foraged for new documents to recommend to each participant based
on their explicit keyword searches, as well as by their interactions
in opening, minimizing, removing, overlapping, highlighting, and
annotating documents. the semantic interactions provided to these
participants are listed in table 1.

the control condition is referred to as the “ksf” group. partici-
pants assigned to this group could only forage for new documents
via explicit keyword searches that they typed into search boxes.
participants still had the ability to perform the semantic interac-
tions listed in table 1 that updated the user model, but automatic
foraging did not occur as a result of those actions. for example,
participants could still highlight phrases within the documents to
support their own synthesis process and to support the layout and
automatic highlighting, but starspire did not automatically forage
for documents related to those phrases or the updated model. the
starspire system was identical in both conditions, except that the
sif functionality was turned off in the ksf condition. participants
were unaware of the different conditions for the study, and no change
to the user interface was evident to the ksf participants.

5 study results
using a combination of log ﬁles, screenshots, solution sheets, sur-
veys, and interviews, we quantitatively and qualitatively evaluate
how sif impacted the sensemaking process. speciﬁcally, we ex-
amine (1) how well users performed, (2) how well they foraged for
relevant documents, (3) which relevant documents they discovered
and how they found them, (4) what interactions they performed, and
(5) what strategies they applied.

each of the following subsections begins with a summary of the
research question addressed, followed by the study results and a
discussion of their signiﬁcance. we report both signiﬁcant and non-
signiﬁcant results, showing both conclusions drawn from this study
as well as directions for further investigation.

5.1 sif+ksf participants averaged higher scores
in this subsection, we investigate how the introduction of sif af-
fected the participant scores resulting from their exploration of the
blue iguanodon document collection. we found that sif+ksf group
members exhibited signiﬁcantly higher average scores.

5.1.1 results
using the published scoring rules from the vast 2007 chal-
lenge [36], we computed a performance score for each participant.
participant scores ranged from 1 to 17. the maximum possible
score was 58, although we did not expect participants to approach
this value given the time constraints of this study. no participants
identiﬁed any subplots outside of the plot indicated in the starting
document. the highest possible score considering only the initial
plot was 27. the scores were higher in the sif+ksf group than in
the ksf group (sif+ksf: µ = 8.0, σ = 5.4, min = 3, max = 17;
ksf: µ = 4.2, σ = 3.3, min = 1, max = 10). the individual scores
with their means are shown in fig. 3.

due to the small sample size (n = 9 for each group), we ﬁrst per-
formed two shapiro-wilk tests [42] for normality, to learn whether
or not the participant scores in each group were normally distributed.
the non-signiﬁcant outcomes of this test at the α = 0.05 level
(w = 0.064 for the sif+ksf group, w = 0.229 for the ksf group)
indicated that the scores were approximately normally distributed.
following this, we performed a t-test assuming unequal variance,
using the alternative hypothesis that the sif+ksf scores would be

figure 3: score (left y-axis scale), precision, and recall (right y-axis
scale) of foraging performance by all participants. mean group scores
are shown as blue diamonds. we found a statistically signiﬁcant
difference between conditions in score, but not in precision and recall.

higher than the ksf scores. at a signiﬁcance level of α = 0.05,
we found that the sif+ksf group scores were signiﬁcantly higher
than the ksf group scores (t = 1.8045, d f = 13, p = 0.0471). this
process of non-signiﬁcant shapiro-wilk test preceding an unequal
variance t-test was used for all other inferential statistics presented
in the following subsections.

5.1.2 discussion
the results from this section show that, on average, participants in
the sif+ksf group understood the plot to a greater degree than
those in the ksf group. though the p-value is near the α = 0.05
signiﬁcance threshold, this is due in part to the small sample size
of 9 participants in each group. the mean score for sif+ksf par-
ticipants was nearly double that of the ksf participants. however,
we also note that the inclusion of sif produced a higher variance in
scores than participants who were only afforded ksf. we suspect
that this is due in part to the variable number of semantic interactions
performed by sif+ksf participants – both the choice and frequency
of semantic interactions used inﬂuences the set of documents that
are foraged, and thereby inﬂuences how well the participant under-
stands the plot. we discuss further explanations for the effect of the
inclusion of sif on documents foraged in the next two subsections.

5.2 no change to precision and recall between groups
in this subsection, we investigate how the introduction of sif af-
fected precision and recall scores for foraging performance. we
found no signiﬁcant difference in foraging precision and recall be-
tween the sif+ksf and ksf groups.

5.2.1 results
in evaluating the foraging performance of participants, we compute
precision, recall, and f-measure values for the relevant documents
found by each participant. these results are summarized in table 2.
we compute precision to be the number of relevant documents found
divided by the total number of documents retrieved and recall as
the number of relevant documents found divided by the number of
relevant documents in the known solution. f-measure is computed
as 2∗ precision∗ recall/(precision + recall). in this scenario, there
were 33 documents relevant to the known solution. we used the
participant log ﬁles to identify which documents were retrieved into
the workspace in order to calculate precision, recall, and f-measure
(shown in fig. 3).

the sif+ksf group averaged a precision score of 0.14 (σ =
0.07), a recall score of 0.59 (σ = 0.13), and an f-measure of 0.21

table 2: scores, counts of documents retrieved, and precision-recall
statistics for each condition.

score (out of 27)
unique relevant docs retrieved (out of 33)
total unique docs retrieved (out of 1486)
precision
recall
f-measure

sif+ksf

avg.
8.0
19.3
178.0
0.14
0.59
0.21

ksf avg.

all avg.

4.6
18.1
145.2
0.14
0.55
0.21

6.1
18.7
161.6
0.14
0.57
0.21

(σ = 0.09). similarly, the ksf group averaged a precision score of
0.14 (σ = 0.04), a recall score of 0.55 (σ = 0.06), and an f-measure
of 0.21 (σ = 0.05). it is noteworthy that both groups had very similar
precision, recall, and f-measure scores. this result is counter to
our initial hypothesis, which was that sif would increase recall but
might penalize precision.

we did not observe a signiﬁcant difference between sif+ksf
and ksf conditions in the total number of unique documents re-
trieved (t = 0.8681, d f = 12, p = 0.4024). across conditions,
the number of unique documents retrieved ranged from 70 to
315 (µ = 162, σ = 80), which corresponds to 4.7% to 21.2% of
the entire dataset retrieved. the sif+ksf participants retrieved
between 70 and 315 unique documents (µ = 178, σ = 102), and the
ksf condition participants retrieved between 90 and 239 documents
(µ = 145, σ = 50). although these documents were imported into
the workspace, not all of them were read. this in and of itself is a
promising result. participants were able to mentally ﬁlter out many
of the irrelevant documents in their synthesis phase.

5.2.2 discussion
because we are evaluating the inﬂuence of semantic interactions on
foraging, our computations of precision and recall used the number
of documents (and relevant documents) retrieved, rather than using a
similar measure such as number of documents opened or interacted
with. this choice allows us to measure what the system is giving the
analysts to read, rather than exploring what the analysts are focusing
on. it is certainly possible that altering these computations could
affect our non-signiﬁcant results.

overall, it is interesting to note that the foraging results for the
sif+ksf group consistently show a standard deviation twice that of
the ksf group. this is further evidence that sif introduces greater
variability into the foraging process. the number of documents
retrieved from the dataset varied based on user analytical strategy.

5.3 sif and ksf serve complementary document for-

aging roles

in this subsection, we investigate how the introduction of sif affects
the set of relevant documents retrieved and how they were retrieved.
we found that ksf and sif each have their own advantages towards
retrieving certain sets of documents, and that highlighting was the
primary semantic interaction used to retrieve documents.

table 3: quantity and percentage of relevant documents retrieved
using the various interaction methods for the two conditions.

relevant docs retrieved (includes re-ﬁnds)
total from sif

sif from highlight
sif from annotate
sif from overlap

ksf from search

sif+ksf

22.4

5.8 (26%)
5.0 (22%)
0.2 (1%)
0.6 (3%)
16.7 (74%)

ksf
20.1

20.1 (100%)

5.3.1 results
document discovery results are summarized in fig. 4. of the
relevant documents in the collection, the “chinsurrection” docu-
ments were almost universally found by every ksf participant (one
ksf participant missed one of the documents). in contrast, some
sif+ksf participants missed them. these documents are central to
the main plot of the investigation, which most of the participants at
least partially solved. all of these documents contain the name of
the central nefarious character, “cesar gil,” that most of the users
cited in their solutions. all ksf group users explicitly searched on
his name, but three of the sif+ksf users did not, and consequently
some of those three missed a subset of these documents.

in contrast, the other relevant documents were found more often
by the sif+ksf participants. in particular, three of these documents
were not found by any of ksf users, yet were found by 3/9 of the
sif+ksf users. one of these documents contained supporting evi-
dence for the main plot described above, but did not identify cesar
gil by name. the other two documents contained information rele-
vant to a second subplot that interconnects with the main plot, about
another character named “rbear,” although none of the participants
succeeded in solving this plot. this character’s name was never
explicitly searched for by any of the participants, so it is likely this
information was retrieved through sif, perhaps exploiting other key-
words in common between the two plots, such as “monkeypox” (a
highly weighted term in the ﬁnal states of many of the participants’
user interest models). this indicates that it was valuable to have the
sif mechanism to expand the scope of investigation to this other
relevant but less obviously connected information, beyond keywords
on which users might not think to explicitly search.

the sif+ksf group located some relevant documents through
their semantic interaction foraging ability, while the ksf group
used only the keyword search means. the percentages are shown
in table 3. we examined the interaction logs of the participants in
the sif+ksf condition to determine if they retrieved relevant docu-
ments via semantic interactions that executed sif retrieval. eight
out of nine sif+ksf users retrieved new relevant documents using
sif. including re-ﬁnds (relevant documents that were located, re-
moved from the working set by the user, and then located again),
sif accounted for 26% of the total number of relevant documents
retrieved by the sif+ksf group. for individual sif+ksf users, this
percentage ranged from 0% to 100%, demonstrating the wide variety
of user strategies. this also suggests that users succeeded in ﬁnding
useful information via sif, information that might not have been
found through explicit ksf. by far, most of the sif-retrieved rele-
vant documents were retrieved as a result of highlight interactions,
indicating the importance of this type of semantic interaction.

5.3.2 discussion
from this analysis of foraging behavior, we can see beneﬁts of both
sif and ksf. ksf is useful when speciﬁc terms of interest are
known; a keyword search for “cesar gil” added many of the “chin-
surrection” documents into the working set, indicating that ksf is
still valuable for foraging, especially for terms that are more obvious
targets of investigation. simultaneously, ksf is limited when those
precise search terms are not present in other relevant documents. sif,
in contrast, can locate documents related to the current direction of
exploration without the analyst knowing precisely what to search for,
but with the limitation that sif may not locate all of the documents
that an analyst may be seeking. this limitation can be addressed by
more accurate learning and retrieval models in the future.

interestingly, the sif+ksf group earned higher analysis scores
on average, despite not ﬁnding all of the core “chinsurrection” doc-
uments. instead, they earned higher scores by building up a more
complete plot with the supplemental documents they found through
sif. the sensemaking process is boosted by sif locating this broader
supplemental information, beyond the obvious core documents.

figure 4: the difference between the number of sif+ksf group participants and ksf group participants who found each relevant document.
positive scores (above the horizontal axis) mean that more sif+ksf participants found the document, while negative scores (below the horizontal
axis) mean that more ksf participants found the document. more sif+ksf participants found a majority of the documents, but more ksf
participants found the core “chinsurrection” documents.

5.4 sif+ksf participants performed more synthesis in-

teractions

ious interactions (e.g., some preferred annotating over highlighting,
others preferred overlapping documents).

in this subsection, we investigate how the introduction of sif af-
fected the number of semantic interactions performed by participants.
we observed signiﬁcant differences between study conditions in
terms of how much information users externalized to the workspace
via some synthesis-related actions, which may have contributed
to the potential trend of improved performance by the sif+ksf
participants compared to the ksf participants.

5.4.1 results
in order to track how users synthesized information, we once again
analyzed the interaction logs (fig. 5). we identiﬁed the follow-
ing semantic interactions as being directly related to synthesis
through the externalization of the user’s thought processes: high-
lighting, annotating, and document overlapping (clustering). the
sif+ksf condition participants performed signiﬁcantly more high-
lights (t = 2.3227, d f = 16, p = 0.0169) and signiﬁcantly more
annotations (t = 2.0809, d f = 9, p = 0.0336). there was no sig-
niﬁcant difference between the number of times that users clus-
tered documents by overlapping them (sif+ksf µ = 15.6; ksf
µ = 11.2), nor was there a signiﬁcant difference in the number of
keyword searches performed by each group (sif+ksf µ = 19.2;
ksf µ = 18.0). users varied in their preferences for performing var-

figure 5: the panels from left to right show the total number of
highlight, annotation, document overlap, and search interactions per-
formed by each participant. means are shown as blue diamonds. the
highlight and annotation conditions are signiﬁcantly different, with the
sif+ksf group performing more actions than the ksf group in both.
the overlap and search conditions are not signiﬁcantly different.

5.4.2 discussion
we can infer from these results that the sif+ksf users externalized
more of their understanding of the dataset and hypotheses about what
information was relevant. overall, these participants provided more
feedback to the user model regarding their interests. this feedback
was not only used to retrieve documents, but also to augment the
spatialization in terms of document positioning, visual encodings,
and automatic text highlighting. this process serves to continually
give analysts visual feedback on what documents it believes will be
most relevant or interesting for the analyst to read. therefore, the
system is more likely to indicate good documents on the display for
the user to open and read next based on their interests. both study
conditions were provided with this relevance feedback based on
their underlying interest model, although the sif+ksf participants
beneﬁted from this feature more than ksf participants.

furthermore, user’s highlighting and annotating documents aids
in auto-highlighting of the text in open documents, making them
easier to skim. it also helps transform open documents into distin-
guishable visual glyphs that aids in re-ﬁnding information, making
analysts more efﬁcient in navigating the workspace and referencing
the workspace for ﬁlling out their ﬁnal solution reports [11, 46].

the signiﬁcant difference between study conditions may have
been a result of a positive-reinforcing feedback loop. as users made
highlights in documents or wrote notes, the system retrieved and
identiﬁed documents that it believed the users would be interested in.
this may have encouraged the users in the sif+ksf condition to
continue performing these actions. thus, synthesis-related actions
foraged for information, both on and off the screen, which led to
more data being interpreted and formulated into hypotheses. it is
interesting though that this did not seem to signiﬁcantly reduce their
use of search. this might suggest a possible design opportunity for
more clear visual connection between ksf and sif.

5.5 participants exhibited a variety of strategies
in this subsection, we investigate the structure and layout of the
ﬁnal workspaces for both groups of participants. overall, participant
strategies for use of the workspace mirrored previous results about
sensemaking with large display spaces [5, 7]. users organized a
variety of spatial representations of the document collection as part
of their distributed cognitive process.

figure 6: final workspace of (left) user ksf #9 showing the spatial organization of documents, annotations, and search boxes that label the
space, and (right) user sif+ksf #4 showing a large central pool of unopened documents, with opened documents arranged on the periphery.

5.5.1 results
the ﬁnal screenshots of user workspaces shared a common artifact,
likely caused by a low relevance threshold that kept a high number
of documents on the display. most participants’ ﬁnal workspaces
contained a central pool of unopened document nodes with docu-
ments arranged around the periphery of the display. the nodes in
the central pool represented weakly relevant information. nodes
that were highly relevant to a speciﬁc cluster of documents were
positioned near the cluster.

users were asked to sketch spatial representations of their ﬁnal
workspaces – how they perceived the space. users adopted different
methods for labeling the space, even within their own drawings,
which would make automatic cluster detection and classiﬁcation
difﬁcult [21]. for example, users created speciﬁc tags for areas of
the display that directly matched extracted entities (e.g., monkeypox,
cesar gil), but they also tagged areas of the space with cognitively
meaningful labels (e.g., who, what, where). this behavior has been
previously observed, where users label their spatial workspaces in
fuzzy and complicated manners that would be difﬁcult to match by
another person or algorithm [13].

the number of open documents on the ﬁnal workspaces varied
greatly, from 2 to 35 (µ = 15.56, σ = 10.51). there was also sub-
stantial variance within each condition. the sif+ksf condition
participants kept a range of 2 to 34 documents open on their ﬁnal
workspace (µ = 14.78, σ = 11.69). the ksf condition participants
ranged in keeping 3 to 35 documents open (µ = 16.33, σ = 9.84).
the lack of signiﬁcant difference implies that any trend in perfor-
mance between the conditions cannot be explained by the number
of open documents alone.

interestingly, participants who had very few documents open on
their ﬁnal workspace still drew spatial schemas indicating where
they had opened and then minimized or closed documents. for
example, participant sif+ksf #1 opened documents 57 times, but
only had two documents open on his ﬁnal workspace, neither of
which were relevant to the solution. in fact, participant sif+ksf #1
did not have any relevant documents on his ﬁnal workspace, open or
closed. he preferred a neat and clutter-free workspace and deleted
documents after he had read and processed the information. for
reference, this participant retrieved 20 relevant documents and had
the second highest score. the highest scoring participant overall,
sif+ksf #8, assumed quite the opposite strategy. she retrieved a
total of 310 documents, 28 of which were relevant. she also opened
documents 57 times, yet she kept 16 open on her ﬁnal workspace,
11 of which were relevant to the overall solution.

in the ksf condition, participants ksf #1 and ksf #2 had the
highest scores in their group. they also adopted differing strategies
in terms of keeping documents on the display. ksf #2 retrieved
117 documents, 21 of which were relevant. she had 15 documents
open on her ﬁnal workspace, 10 of which were relevant. ksf #1
retrieved 118 documents, 15 of which were relevant. he had 6 docu-

ments open on his ﬁnal workspace, but none were relevant. however,
three documents were opened and then minimized, indicating that
they were read.

5.5.2 discussion
we found no correlation between any of these organizational strategy
metrics and user performance. this can be attributed to individual
differences in analytical strategies, such as user ability, the desire
to keep a neat workspace (or not minding having the display ﬁlled
with open and closed documents), or needing to focus on one or two
documents at a time so as not to get distracted. these preferences
were explained during the post-study surveys and semi-structured
interviews. we see that starspire supports a variety of analytical
strategies and user preferences without a particular strategy having
an adverse impact on sensemaking quality and performance. our
results also replicate previous work that demonstrates how users
remember spatial locations of items on a large, physical workspace,
both during data analysis and after the fact when the display is
empty [5, 32].

6 discussion
we begin this section by summarizing the lessons learned from this
study, and discussing ways by which these lessons can be applied
beyond starspire and into visual analytics in general (section 6.1).
following this, we discuss two issues that surfaced through our ob-
servations of participants and analysis of the study data. the ﬁrst
was a sometimes overwhelming number of documents staying on
the display, which suggests a need to modify the relevance threshold
(section 6.2). the second is the problem of cognitive tunneling,
which we noticed when no participants identiﬁed additional subplots
in the data (section 6.3). we discuss these issues and suggest meth-
ods for alleviating the problems in future work. we also discuss
a feature that proved to be surprisingly important to the users, the
automatic text highlighting (section 6.4). in addition, we discuss
the potential for tuning semantic interactions to individual users
(section 6.5), and the limitations of our study (section 6.6).

6.1 general principles
throughout the experimental results detailed in the previous section,
we saw that incorporating a “passive” foraging mechanism like
sif that retrieves documents based on a learned user model can
recommend documents to analysts that they may not have found
via traditional keyword search means. the result of these document
recommendations is that analysts gain a better understanding of the
underlying plot in the document collection (evidenced by their higher
scores), and interact with the workspace more, leading to a feedback
cycle that continues to improve document recommendations with
each additional interaction. at the same time, the quality of the
documents recommended (measured by the foraging precision and
recall scores) is not reduced.

ksf and sif represent independent, complementary mechanisms
for information retrieval, each with strengths and weaknesses. as
such, sif should not be used by system designers as a replacement
for keyword search. indeed, the inclusion of a search box can greatly
beneﬁt the usability of a visualization system as datasets increase in
size [1]. rather, our ﬁndings suggest that implicit or passive search
mechanisms can be included in visualization systems to draw the
user’s attention to related objects that may not necessarily include
identical search terms.

similarly, our ﬁndings suggest that interactions alone are sufﬁ-
cient to drive these search mechanisms, building a user model by
interpreting the interest of a user based on how they interact with
other documents. we noted previously (section 2.4) that our learning
rules to generate a user model are relatively simple, and that more
thorough recommendation systems that follow an interaction-driven
approach could certainly outperform our ﬁndings. however, our
results show that even this simple approach can cause substantial
improvement. we additionally assert that existing visualization sys-
tems could make use of our simple approach of mapping interactions
to weight modiﬁcations, ultimately to the beneﬁt of a user.

for example, andromeda [41] allows users to manipulate projec-
tions to learn a set of attribute weights that will best approximate the
user-provided projection. to use this mechanism, a user uses drag-
and-drop interactions to manipulate the current projection, dragging
observations to various positions in the workspace to communicate
desired similarity/dissimilarity relationships. the new weights are
not learned until the user has ﬁnished their repositioning interac-
tions and click an “update layout” button. with a starspire-like
approach, the system can begin to learn the user’s desired simi-
larity/dissimilarity goals while the user is still performing these
interactions. as the user moves more observations, andromeda
could begin to recommend additional observations to reposition, and
could even recommend the positions to place the additional observa-
tions. such suggestions could lead to better reprojection results as
the feedback from user to system is increased.

similarly, intent radar [39] allows users to manipulate a pro-
jection of keywords centered about a “radar” display. users can
reposition keywords closer to the center of the radar to indicate that
a particular keyword is more important to their interests. using the
starspire approach, the system could learn from this sequence of
interactions, perhaps discovering documents that contain these key-
words and recommending other keywords within those documents.

6.2 relevance threshold
in this study, it appears that the relevance threshold may have been
set too low, causing too much irrelevant information to remain on
the display. this was observed during the pilot study, but we chose
to maintain this relevance threshold level so that the system would
not over-prune the workspace, which can be more problematic. as
a result, many users ended up with a central “pool” of data and
arranged their open documents on the perimeter.

participants retrieved a widely varying number of documents (µ =
161.61, σ = 79.52). the number of documents removed also varied
greatly (µ = 31.50, σ = 20.34). this can be attributed to differences
in analytical strategies by the participants. during the post-study
interviews, it was revealed that some users (e.g., ksf #1) preferred
to keep a clutter-free workspace and keep as few documents open as
possible. others (e.g., sif+ksf #8) did not feel overwhelmed by the
excess information and preferred having a great deal of information
to pull from. these two participants earned the highest scores in
their groups. the data gathered in this study show that the variation
in clutter represented by the participants’ layouts did not correlate
with their performance; however, it is reasonable to assume that an
excessive amount of clutter would impact task performance.

in order to support these varied styles, it may be prudent to alter
the document relevance threshold to adapt to each user instead of

having static values based on interactions. the model could incre-
mentally learn from the interactions users perform and update as
needed. for example, if a user has a tendency to delete documents
from the workspace, the threshold for keeping documents should
be raised so that more are automatically pruned from the display.
an alternative to this strategy may be to begin with a more strict
threshold to only show closely-related documents. then, once a
foraging saturation is reached, the threshold could be lowered incre-
mentally to bring in new documents. likewise, if the system is able
to detect a large number of documents that are just under the current
relevance threshold, say related to a new subplot that has just been
encountered, the relevance threshold could be lowered to bring in
all of those new documents.

6.3 cognitive tunneling
while the blue iguanodon dataset contained multiple subplots, no
users branched out to identify any other plot aside from the main
plot mentioned in the starting document. some participants pursued
alternative hypotheses for this subplot, but none correctly identiﬁed
adjacent subplots. interestingly, a few participants read documents
containing information on different subplots, and one even executed
searches for relevant entities involved in a second subplot. however,
they did not include this information in their solution. our instruc-
tions to the study participants did not indicate that there was only
a single plot within the dataset; we merely provided them with the
starting document and allowed them to begin exploring. participants
may have implicitly assumed that they should focus on the speciﬁc
plot hinted at in the starting document, ignoring other interesting
threads that they uncovered in the data. this indicates that many of
the participants in both study conditions fell victim to a phenomenon
similar to cognitive tunneling [33] or satisfaction of search [45], in
which an analyst narrows their attention to target an initial discovery,
ignoring other possibilities.

one explanation for this issue is due to how information was
retrieved and synthesized by participants. documents added to the
workspace were those containing terms that most closely matched
the user’s model for both study conditions. this could have led to
conﬁrmation bias and a tendency to ignore alternatives in the plot.
that said, conﬁrmation bias is a feature of participants, not retrieval
systems. for example, an analyst investigating the question “do
chinchillas have monkeypox?” could initiate a search that returns in-
formation that both conﬁrms and refutes the question. the decision
to pursue one conclusion or the other occurs during the synthesis
process that follows the search. indeed, results from section 5.3
show that introducing sif may work to alleviate the effects of con-
ﬁrmation bias, because sif returns related documents that may not
be found through traditional keyword search. our results show that
sif presented participants with a broader set of documents, many
with more subtle ties to the currently investigated hypothesis.

this cognitive tunneling effect can also be attributed to each user
being provided with an explicit starting point in the analysis. while
this was intended to focus the investigation of the study participants
during a time-limited task and reducing the variation between users,
it also has the effect of limiting open-ended investigation within the
document set. the automatic and dynamic highlighting may further
inﬂuence this effect by “steering” the participants towards searching
for highlighted terms and missing potentially useful documents that
are not signiﬁcantly highlighted. studies from the visual search
community have noted that prevalence [50] and detectability [49]
play signiﬁcant roles in target location.

one way to alleviate this problem is to introduce novel documents
to the workspace in addition to highly relevant documents. ruotsalo
et al. achieved this by sampling from a distribution of documents
according to their relevance [39]. this allowed for closely related
documents to be shown as results, but also occasionally to show
novel documents. again echoing the idea of detectability for visual

search, it is advantageous to visually indicate novel documents
within the spatialization to draw user focus to them. we noted that
participants tended to open large, bright documents, even if they
were in a cluster of many documents. how to integrate the notion of
veering away from the user’s model to highlight novel information
within the current multi-model semantic interaction pipeline remains
an open research challenge.

another possibility is to provide large-scale overview spatializa-
tions of the full document collection. forcespire accomplished
this by simply displaying the entire document collection at start-up,
but therefore only worked for small document collections [20]. star-
spire abandoned that approach in order to handle larger document
collections, instead focusing on retrieval. this leads to opportunities
to integrate other types of overviews of large document collections,
such as sampling, clustering, and topic modeling [17].

6.4 automatic text highlighting
according to user comments, the user-tuned automatic text high-
lighting (shown in the interface in fig. 1) proved to be one of most
valuable features in starspire. this feature gave the users a subtle
yet salient visual representation of the underlying interest model.
the highlights had the potential to change with each interaction,
thus continuously representing the current underlying model’s state,
reﬂecting which terms the user interest model had placed the most
emphasis on. this visual feedback about the state of the model was
conveniently presented, in context, directly within the documents
and served as a form of “explainable ai”.

however, automatic highlighting proved to be much more useful
than merely giving feedback. participants leveraged the automatic
highlighting to (1) determine which documents in a collection are
worth reading, and (2) determine which portions of a document
to focus on, particularly in longer documents. thus, starspire
gave users feedback at multiple levels of data abstraction through
a visual metaphor that users found easy to interpret. at the graph
level (many documents), the node relevance size-encoding and text
highlighting served to guide users toward relevant documents to
read. they could quickly identify pertinent documents with a quick
glance at the highlighted terms. at the individual document level,
text highlighting directed users to portions of the document to read.
this was particularly useful to home in on speciﬁc paragraphs in
long documents, and to identify where multiple reports contain
similar information that the user has already read before, allowing
them to skip over that content. further, no users complained about
the system recommending improper documents. the incremental
dynamics of the working set, layout, and visual encodings did not
appear to frustrate them. these features appeared to help direct the
user’s attention, but further research is necessary to measure any
increased analyst efﬁciency produced by auto-highlighting.

6.5 tuning semantic interactions
participants employed vastly different strategies in conducting their
analysis. for example, foraging performance was similar across the
participants, but how they went about foraging varied greatly. it is
not unreasonable to assume that users had different preferences in
terms of what interactions they performed. currently, interactions
are interpreted the same way for all users. we may be able to tune
the impact of the interactions to better approximate the preferences
of each individual user, perhaps using machine learning methods to
tune the parameters of the semantic interactions.

for example, if a user repeatedly closes documents that were
retrieved as a result of highlighting sentences in a document, the
system could reduce the impact that highlighting has on extracted
entities. in this manner, we can attempt to avoid over-assuming the
intent of users. instead, we can begin with a baseline interpretation
of interactions and incrementally tune these interpretations through
a meta-level semantic interaction learning process.

6.6 limitations
three noteworthy limitations to this study include the small number
of participants, the single document set used, and the short task time
duration. first, it is possible that we could have discovered stronger
signiﬁcance levels and more signiﬁcant results with additional par-
ticipants, reducing some of the variance in the participant scores
and behaviors. additionally, using only the blue iguanodon set of
documents in this study limits the generalizability of our ﬁndings.
this is due to the large amount of noise in the document set (since
many documents are irrelevant to the main plot), as well as the short
average length of these documents. it is certainly possible that these
ﬁndings could differ with a collection of longer documents. finally,
while supporting longer-term sensemaking sessions is certainly a
goal of this work, the current study focuses on short two hour ses-
sions. it would be interesting to see the value of sif functionality in
multi-day scenarios.

an additional consideration in the study design is that, while the
ksf group did not have the advantage of sif, they did have other
advantages associated with semantic interaction and the user interest
model, such as automatic highlighting, relevance-based node sizing,
etc. most ksf-only systems would likely not include these features.
thus, the actual difference between the experimental condition and
the control condition in this study was perhaps smaller than it would
be in a realistic setting. the results found in this study might actually
be ampliﬁed when comparing sif to traditional ksf approaches.

7 conclusions and future work
we conducted a comparative user study with starspire to examine
the impact of sif on the sensemaking process. the study showed
that foraging performance was similar between conditions. however,
the group afforded with sif functionality performed signiﬁcantly
more synthesis-related semantic interactions. they externalized
more information (a process associated with synthesis) and injected
more feedback into the underlying user interest model. the system
was then able to forage and identify a broader set of relevant infor-
mation in the spatial workspace. this led to improved sensemaking
task performance, for foraging large textual information and syn-
thesizing a coherent and complete hypothesis narrative, as scored
against a known ground-truth solution. participants in the sif+ksf
condition retrieved 26% of their total relevant documents through
sif on average. executing traditional keyword searches retrieved
the remaining 74% of relevant documents. sif and ksf proved to
be effective complementary retrieval techniques.

based on this user study, participants were able to solve a portion
of the given sensemaking task while retrieving and reading only a
small portion of the overall dataset. however, there was not a clear
superior analytical strategy, which demonstrates that starspire
supports multiple avenues for sensemaking. we also identiﬁed
potential improvements for starspire and its underlying layout
and relevance models that inform the design of future semantic
interaction systems. the automatic text highlighting and node size
relevance encoding, both features enabled by semantic interactions
that learn a user interest model, were especially appreciated by users.
we intend to implement the identiﬁed changes, including altering
the relevance model to include novel documents in addition to the
documents that most closely match the current user interest model.
after these proposed changes are made, we plan to conduct a longi-
tudinal study to observe long-term usage of starspire on real-world
data. example tasks include conducting an in-depth literature review
and learning about a current event in the news.

acknowledgments
this research was supported by nsf grants iis-1218346 and iis-
1447416. the authors would like to recognize the role of comments
from reviewers and discussions with infovis lab @ vt research
group members in improving this work.

references

[1] j. abello, f. v. ham, and n. krishnan. ask-graphview: a large scale
graph visualization system. ieee transactions on visualization and
computer graphics, 12(5):669–676, sept 2006. doi: 10.1109/tvcg.
2006.120

[2] j.-w. ahn and p. brusilovsky. adaptive visualization for exploratory
information processing & management,

information retrieval.
49(5):1139–1164, 2013. doi: 10.1016/j.ipm.2013.01.007

[3] j.-w. ahn, p. brusilovsky, d. he, j. grady, and q. li. personalized web
exploration with task models. in proceedings of the 17th international
conference on world wide web, www ’08, pp. 1–10. acm, new
york, ny, usa, 2008. doi: 10.1145/1367497.1367499

[4] j. alsakran, y. chen, y. zhao, j. yang, and d. luo. streamit: dynamic
visualization and interactive exploration of text streams. in 2011 ieee
paciﬁc visualization symposium, pp. 131–138, march 2011. doi: 10.
1109/pacificvis.2011.5742382

[5] c. andrews, a. endert, and c. north. space to think: large high-
resolution displays for sensemaking. in proceedings of the sigchi
conference on human factors in computing systems, chi ’10, pp.
55–64. acm, new york, ny, usa, 2010. doi: 10.1145/1753326.
1753336

[6] c. andrews and c. north. analyst’s workspace: an embodied sense-
making environment for large, high-resolution displays. in 2012 ieee
conference on visual analytics science and technology (vast), pp.
123–131, oct 2012. doi: 10.1109/vast.2012.6400559

[7] c. andrews and c. north. the impact of physical navigation on spatial
organization for sensemaking. ieee transactions on visualization
and computer graphics, 19(12):2207–2216, dec 2013. doi: 10.1109/
tvcg.2013.205

[8] m. q. w. baldonado and t. winograd. sensemaker: an information-
exploration interface supporting the contextual evolution of a user’s
interests. in proceedings of the acm sigchi conference on human
factors in computing systems, chi ’97, pp. 11–18. acm, new york,
ny, usa, 1997. doi: 10.1145/258549.258563

[9] b. baldwin and b. carpenter. lingpipe. available from world wide

web: http://alias-i.com/lingpipe, 2003.

[10] e. a. bier, s. k. card, and j. w. bodnar. entity-based collaboration
tools for intelligence analysis. in 2008 ieee symposium on visual
analytics science and technology, pp. 99–106, oct 2008. doi: 10.
1109/vast.2008.4677362

[11] l. bradel, a. endert, k. koch, c. andrews, and c. north. large high
resolution displays for co-located collaborative sensemaking: display
usage and territoriality. international journal of human-computer
studies, 71(11):1078–1088, 2013. doi: 10.1016/j.ijhcs.2013.07.004

[12] l. bradel, c. north, l. house, and s. leman. multi-model semantic
in 2014 ieee conference on visual
interaction for text analytics.
analytics science and technology (vast), pp. 163–172, oct 2014. doi:
10.1109/vast.2014.7042492

[13] l. bradel, j. z. self, a. endert, m. s. hossain, c. north, and n. ra-
makrishnan. how analysts cognitively “connect the dots”. in 2013
ieee international conference on intelligence and security informat-
ics, pp. 24–26, june 2013. doi: 10.1109/isi.2013.6578780

[14] e. t. brown, j. liu, c. e. brodley, and r. chang. dis-function:
learning distance functions interactively. in 2012 ieee conference on
visual analytics science and technology (vast), pp. 83–92, oct 2012.
doi: 10.1109/vast.2012.6400486

[15] p. brusilovski, a. kobsa, and w. nejdl. the adaptive web: methods
and strategies of web personalization. springer science & business
media, 2007.

[16] g. chin, jr., o. a. kuchar, and k. e. wolf. exploring the analytical
in proceedings of the sigchi
processes of intelligence analysts.
conference on human factors in computing systems, chi ’09, pp.
11–20. acm, new york, ny, usa, 2009. doi: 10.1145/1518701.
1518704

[17] a. endert, l. bradel, and c. north. beyond control panels: direct
manipulation for visual analytics. ieee computer graphics and ap-
plications, 33(4):6–13, july 2013. doi: 10.1109/mcg.2013.53

[18] a. endert, l. bradel, j. zeitz, c. andrews, and c. north. designing
large high-resolution display workspaces. in proceedings of the inter-

national working conference on advanced visual interfaces, avi ’12,
pp. 58–65. acm, new york, ny, usa, 2012. doi: 10.1145/2254556.
2254570

[19] a. endert, r. burtner, n. cramer, r. perko, s. hampton, and k. cook.
typograph: multiscale spatial exploration of text documents. in 2013
ieee international conference on big data, pp. 17–24, oct 2013. doi:
10.1109/bigdata.2013.6691709

[20] a. endert, p. fiaux, and c. north. semantic interaction for sensemak-
ing: inferring analytical reasoning for model steering. ieee trans-
actions on visualization and computer graphics, 18(12):2879–2888,
dec 2012. doi: 10.1109/tvcg.2012.260

[21] a. endert, s. fox, d. maiti, s. leman, and c. north. the semantics of
clustering: analysis of user-generated spatializations of text documents.
in proceedings of the international working conference on advanced
visual interfaces, avi ’12, pp. 555–562. acm, new york, ny, usa,
2012. doi: 10.1145/2254556.2254660

[22] a. endert, c. han, d. maiti, l. house, s. leman, and c. north.
observation-level interaction with statistical models for visual ana-
in 2011 ieee conference on visual analytics science and
lytics.
technology (vast), pp. 121–130, oct 2011. doi: 10.1109/vast.2011.
6102449

[23] p. fiaux, m. sun, l. bradel, c. north, n. ramakrishnan, and a. endert.
bixplorer: visual analytics with biclusters. computer, 46(8):90–94,
august 2013. doi: 10.1109/mc.2013.269

[24] a. ghias, j. logan, d. chamberlin, and b. c. smith. query by hum-
in pro-
ming: musical information retrieval in an audio database.
ceedings of the third acm international conference on multimedia,
multimedia ’95, pp. 231–236. acm, new york, ny, usa, 1995.
doi: 10.1145/217279.215273

[25] c. gormley and z. tong. elasticsearch: the deﬁnitive guide. o’reilly

media, inc., 1st ed., 2015.

[26] t. m. green, w. ribarsky, and b. fisher. building and applying a
human cognition model for visual analytics. information visualization,
8(1):1–13, 2009. doi: 10.1057/ivs.2008.28

[27] a. gupta and r. jain. visual information retrieval. commun. acm,

40(5):70–79, may 1997. doi: 10.1145/253769.253798

[28] m. a. hearst. tilebars: visualization of term distribution information
in full text information access. in proceedings of the sigchi confer-
ence on human factors in computing systems, chi ’95, pp. 59–66.
acm press/addison-wesley publishing co., new york, ny, usa,
1995. doi: 10.1145/223904.223912

[29] j. heer and d. boyd. vizster: visualizing online social networks. in
ieee symposium on information visualization, pp. 32–39, oct 2005.
doi: 10.1109/infvis.2005.1532126

[30] y. kang, c. gorg, and j. stasko. how can visual analytics assist
investigative analysis? design implications from an evaluation. ieee
transactions on visualization and computer graphics, 17(5):570–583,
may 2011. doi: 10.1109/tvcg.2010.84

[31] x. lin, d. soergel, and g. marchionini. a self-organizing semantic
in proceedings of the 14th annual
map for information retrieval.
international acm sigir conference on research and development
in information retrieval, sigir ’91, pp. 262–269. acm, new york,
ny, usa, 1991. doi: 10.1145/122860.122887

[32] k. logan. spatial history: using spatial memory to recall informa-

tion. phd thesis, virginia tech, 2012.

[33] a. mack and i. rock. inattentional blindness, vol. 33. mit press

cambridge, ma, 1998.

[34] k. a. olsen, r. r. korfhage, k. m. sochats, m. b. spring, and j. g.
williams. visualization of a document collection: the vibe system.
information processing & management, 29(1):69–81, 1993. doi: 10.
1016/0306-4573(93)90024-8

[35] p. pirolli and s. card. the sensemaking process and leverage points
for analyst technology as identiﬁed through cognitive task analysis. in
proceedings of international conference on intelligence analysis, vol. 5,
2005.

[36] c. plaisant, g. grinstein, j. scholtz, m. whiting, t. o’connell,
s. laskowski, l. chien, a. tat, w. wright, c. grg, z. liu, n. parekh,
k. singhal, and j. stasko. evaluating visual analytics at the 2007
vast symposium contest. ieee computer graphics and applications,
28(2):12–21, march 2008. doi: 10.1109/mcg.2008.27

[37] pnnl. in-spire visual document analysis, 2010.
[38] f. ricci, l. rokach, and b. shapira. introduction to recommender
in recommender systems handbook, pp. 1–35.

systems handbook.
springer, 2011.

[39] t. ruotsalo, j. peltonen, m. eugster, d. głowacka, k. konyushkova,
k. athukorala, i. kosunen, a. reijonen, p. myllym¨aki, g. jacucci,
and s. kaski. directing exploratory search with interactive intent
modeling. in proceedings of the 22nd acm international conference
on information & knowledge management, cikm ’13, pp. 1759–1764.
acm, new york, ny, usa, 2013. doi: 10.1145/2505515.2505644

[40] d. p. russ burtner, shawn bohn. interactive visual comparison of
multimedia data through type-speciﬁc views, 2013. doi: 10.1117/12.
2004735

[41] j. z. self, r. vinayagam, j. t. fry, and c. north. bridging the gap
between user intention and model parameters for data analytics. in sig-
mod 2016 workshop on human-in-the-loop data analytics (hilda
2016), p. 6, june 2016.

[42] s. s. shapiro and m. b. wilk. an analysis of variance test for normality

(complete samples). biometrika, 52(3/4):591–611, 1965.

[43] f. m. shipman and c. c. marshall. formality considered harmful:
experiences, emerging themes, and directions on the use of formal rep-
resentations in interactive systems. computer supported cooperative
work (cscw), 8(4):333–352, 1999. doi: 10.1023/a:1008716330212
[44] j. teevan, s. t. dumais, and e. horvitz. personalizing search via
automated analysis of interests and activities. in proceedings of the
28th annual international acm sigir conference on research and
development in information retrieval, sigir ’05, pp. 449–456. acm,
new york, ny, usa, 2005. doi: 10.1145/1076034.1076111

[45] a. m. treisman and g. gelade. a feature-integration theory of atten-
tion. cognitive psychology, 12(1):97 – 136, 1980. doi: 10.1016/0010
-0285(80)90005-5

[46] k. vogt, l. bradel, c. andrews, c. north, a. endert, and d. hutchings.
co-located collaborative sensemaking on a large high-resolution
display with multiple input devices, pp. 589–604. springer berlin
heidelberg, berlin, heidelberg, 2011. doi: 10.1007/978-3-642-23771
-3 44

[47] j. wenskovitch and c. north. observation-level interaction with clus-
in proceedings of the
tering and dimension reduction algorithms.
2nd workshop on human-in-the-loop data analytics, hilda’17, pp.
14:1–14:6. acm, new york, ny, usa, 2017. doi: 10.1145/3077257.
3077259

[48] j. a. wise, j. j. thomas, k. pennock, d. lantrip, m. pottier, a. schur,
and v. crow. visualizing the non-visual: spatial analysis and interaction
with information from text documents. in proceedings of visualization
1995 conference, pp. 51–58, oct 1995. doi: 10.1109/infvis.1995.
528686

[49] j. m. wolfe and t. s. horowitz. five factors that guide attention in

visual search. nature human behaviour, 1(3):0058, 2017.

[50] j. m. wolfe and m. j. v. wert. varying target prevalence reveals
two dissociable decision criteria in visual search. current biology,
20(2):121 – 124, 2010. doi: 10.1016/j.cub.2009.11.066

[51] p. c. wong, e. g. hetzler, c. posse, m. a. whiting, s. havre,
n. cramer, a. r. shah, m. singhal, a. turner, and j. thomas. in-spire
infovis 2004 contest entry. in infovis, vol. 4, pp. 51–52, 2004.

[52] w. wright, d. schroh, p. proulx, a. skaburskis, and b. cort. the
sandbox for analysis: concepts and methods. in proceedings of the
sigchi conference on human factors in computing systems, chi
’06, pp. 801–810. acm, new york, ny, usa, 2006. doi: 10.1145/
1124772.1124890

[53] j. s. yi, r. melton, j. stasko, and j. a. jacko. dust & magnet: multi-
variate information visualization using a magnet metaphor. information
visualization, 4(4):239–256, 2005. doi: 10.1057/palgrave.ivs.9500099

",The Effect of Semantic Interaction on Foraging in Text Analysis,"{""pos"":{""0"":1,""1"":2,""2"":3,""3"":4,""4"":5,""5"":6},""2"":{""0"":""participants*"",""1"":""participant*"",""2"":""conference*"",""3"":""proceedings*"",""4"":""discussion"",""5"":""symposium*""},""0"":{""0"":""starspire*"",""1"":""ieee*"",""2"":""york*"",""3"":""endert"",""4"":""bradel"",""5"":""andrews""},""4"":{""0"":""number*"",""1"":""task*"",""2"":""threshold*"",""3"":""score*"",""4"":""table*"",""5"":""survey*""},""1"":{""0"":""relevant"",""1"":""relevance"",""2"":""north"",""3"":""vast*"",""4"":""automatic"",""5"":""international*""},""5"":{""0"":""visualization*"",""1"":""analytics*"",""2"":""computer*"",""3"":""computing*"",""4"":""graphics*"",""5"":""technology*""},""3"":{""0"":""retrieved*"",""1"":""open"",""2"":""recall"",""3"":""displayed*"",""4"":""opened*"",""5"":""begin""},""6"":{""0"":""model*"",""1"":""interactions*"",""2"":""terms*"",""3"":""conditions*"",""4"":""factors*"",""5"":""observations*""}}",journalArticle,,self.user,False,"{""Unnamed: 0"":{""0"":0,""1"":1,""2"":2,""3"":3,""4"":4,""5"":5,""6"":6,""7"":7,""8"":8,""9"":9,""10"":12,""11"":13,""12"":14,""13"":15,""14"":16,""15"":17,""16"":18,""17"":19,""18"":20,""19"":21,""20"":22,""21"":23,""22"":24,""23"":25,""24"":26,""25"":28,""26"":29,""27"":30,""28"":31,""29"":32,""30"":33,""31"":34,""32"":35,""33"":36,""34"":37,""35"":38,""36"":40,""37"":41,""38"":42,""39"":43,""40"":44,""41"":45,""42"":46,""43"":47,""44"":48,""45"":49,""46"":50,""47"":51,""48"":52,""49"":53,""50"":54,""51"":55,""52"":56,""53"":57,""54"":58,""55"":60,""56"":61,""57"":63,""58"":64,""59"":65,""60"":66,""61"":67,""62"":68,""63"":69,""64"":70,""65"":71,""66"":72,""67"":73,""68"":74,""69"":75,""70"":76,""71"":77,""72"":79,""73"":82,""74"":83,""75"":84,""76"":85,""77"":86,""78"":87,""79"":88,""80"":90,""81"":91,""82"":92,""83"":93,""84"":94,""85"":95,""86"":96,""87"":97,""88"":98,""89"":99},""C"":{""0"":16.9875217506,""1"":7.1451543549,""2"":28.9940517197,""3"":12.302561314,""4"":6.4328183042,""5"":5.5844577069,""6"":5.8125237982,""7"":7.2993758381,""8"":13.0983490157,""9"":6.0517623844,""10"":6.6366257561,""11"":7.4453979328,""12"":8.8879059776,""13"":9.1034000164,""14"":9.8134101783,""15"":17.3396527338,""16"":8.0941509905,""17"":5.8504231457,""18"":13.3313930917,""19"":5.7707883783,""20"":7.3274725848,""21"":9.4203435338,""22"":11.4798970635,""23"":12.0629689361,""24"":7.3959792362,""25"":6.3960451807,""26"":6.4354734863,""27"":8.4368630574,""28"":8.0329964393,""29"":10.6304932163,""30"":23.8867083616,""31"":18.5814458093,""32"":14.7290531238,""33"":7.6069847552,""34"":15.2771935531,""35"":7.6694325623,""36"":6.27055156,""37"":20.6232543054,""38"":7.047925716,""39"":17.0861363405,""40"":5.8809968088,""41"":7.5464519195,""42"":6.2220439263,""43"":7.008198428,""44"":15.7290586377,""45"":4.6906851905,""46"":14.1184372869,""47"":6.3665823674,""48"":5.176114872,""49"":6.1730654472,""50"":7.6698164349,""51"":12.6247152038,""52"":7.3940072544,""53"":6.4781703792,""54"":5.1451962852,""55"":4.8661938107,""56"":5.3071603265,""57"":5.1213009427,""58"":4.9082990129,""59"":6.1828665904,""60"":5.0292468452,""61"":5.8686297479,""62"":7.3751803307,""63"":7.0307414804,""64"":6.5309617165,""65"":7.9207876655,""66"":8.5238755636,""67"":4.6888100866,""68"":8.3345388287,""69"":4.6524575694,""70"":5.0626697649,""71"":6.1893245256,""72"":5.1661885883,""73"":5.1416672383,""74"":5.7670323239,""75"":6.4807762237,""76"":4.7993016318,""77"":4.762950461,""78"":4.9743100728,""79"":5.0280963374,""80"":4.7191055717,""81"":4.5969532638,""82"":5.8857239179,""83"":4.5662170161,""84"":4.5723645015,""85"":4.6488158555,""86"":4.5722516666,""87"":4.5603134989,""88"":4.6222473971,""89"":4.622220721},""count"":{""0"":412,""1"":198,""2"":182,""3"":154,""4"":122,""5"":120,""6"":116,""7"":110,""8"":104,""9"":104,""10"":94,""11"":90,""12"":90,""13"":84,""14"":74,""15"":74,""16"":68,""17"":68,""18"":66,""19"":60,""20"":54,""21"":54,""22"":50,""23"":46,""24"":46,""25"":42,""26"":40,""27"":40,""28"":40,""29"":38,""30"":38,""31"":36,""32"":34,""33"":34,""34"":34,""35"":34,""36"":30,""37"":30,""38"":28,""39"":28,""40"":26,""41"":26,""42"":26,""43"":26,""44"":26,""45"":24,""46"":22,""47"":20,""48"":20,""49"":20,""50"":20,""51"":20,""52"":18,""53"":16,""54"":16,""55"":14,""56"":14,""57"":12,""58"":12,""59"":12,""60"":12,""61"":12,""62"":12,""63"":12,""64"":12,""65"":12,""66"":10,""67"":10,""68"":10,""69"":10,""70"":10,""71"":10,""72"":10,""73"":8,""74"":8,""75"":8,""76"":8,""77"":8,""78"":8,""79"":8,""80"":8,""81"":8,""82"":8,""83"":6,""84"":6,""85"":6,""86"":6,""87"":6,""88"":6,""89"":6},""sigma_nor"":{""0"":2.7143797415,""1"":2.233823021,""2"":4.517349694,""3"":2.8963018677,""4"":2.3195757991,""5"":2.2189803381,""6"":2.2585230685,""7"":2.4701461933,""8"":3.2712887294,""9"":2.326686867,""10"":2.444969656,""11"":2.5783572726,""12"":2.7849031249,""13"":2.8553697121,""14"":3.0415567741,""15"":4.2182797222,""16"":2.8185885595,""17"":2.4543848332,""18"":3.6964212926,""19"":2.4901823742,""20"":2.8118122491,""21"":3.1874076163,""22"":3.6228171284,""23"":3.80757314,""24"":2.9109866343,""25"":2.762128927,""26"":2.7936483703,""27"":3.2011204366,""28"":3.1188953827,""29"":3.6909064451,""30"":6.4469984591,""31"":5.4265433234,""32"":4.6770932328,""33"":3.1284740433,""34"":4.7962806295,""35"":3.142052665,""36"":2.8988239466,""37"":6.1773380409,""38"":3.1150229405,""39"":5.4698409047,""40"":2.8751216919,""41"":3.2769554169,""42"":2.9574080488,""43"":3.1470879686,""44"":5.2512189779,""45"":2.6157857322,""46"":5.0648229587,""47"":3.1231494911,""48"":2.807186146,""49"":3.0717879431,""50"":3.4690423416,""51"":4.7841277139,""52"":3.4575267193,""53"":3.2631344613,""54"":2.8816726142,""55"":2.8450096332,""56"":2.9766463425,""57"":2.9708467698,""58"":2.9042765292,""59"":3.3026216065,""60"":2.9420767797,""61"":3.2044120635,""62"":3.6752596034,""63"":3.5676109209,""64"":3.4114129977,""65"":3.8457801782,""66"":4.1406977833,""67"":2.8806713645,""68"":4.0784904261,""69"":2.8687275966,""70"":3.003504488,""71"":3.3736715091,""72"":3.0375160201,""73"":3.0803543144,""74"":3.2973032041,""75"":3.5449120812,""76"":2.9615823523,""77"":2.9489715649,""78"":3.0222955067,""79"":3.0409547997,""80"":2.9337610898,""81"":2.8913845514,""82"":3.3384791669,""83"":2.9071817068,""84"":2.9094420466,""85"":2.9375520827,""86"":2.9094005589,""87"":2.9050110705,""88"":2.9277832521,""89"":2.9277734437},""vocab_index"":{""0"":0,""1"":1,""2"":2,""3"":3,""4"":4,""5"":5,""6"":6,""7"":7,""8"":9,""9"":10,""10"":13,""11"":15,""12"":16,""13"":17,""14"":19,""15"":20,""16"":21,""17"":22,""18"":24,""19"":27,""20"":31,""21"":32,""22"":36,""23"":39,""24"":41,""25"":45,""26"":46,""27"":47,""28"":50,""29"":53,""30"":54,""31"":55,""32"":56,""33"":58,""34"":59,""35"":60,""36"":66,""37"":69,""38"":72,""39"":73,""40"":74,""41"":76,""42"":80,""43"":83,""44"":84,""45"":88,""46"":93,""47"":101,""48"":102,""49"":103,""50"":105,""51"":106,""52"":117,""53"":120,""54"":132,""55"":142,""56"":163,""57"":172,""58"":192,""59"":195,""60"":197,""61"":199,""62"":200,""63"":201,""64"":202,""65"":203,""66"":217,""67"":219,""68"":264,""69"":267,""70"":271,""71"":272,""72"":274,""73"":331,""74"":333,""75"":338,""76"":352,""77"":355,""78"":356,""79"":360,""80"":362,""81"":364,""82"":366,""83"":429,""84"":468,""85"":495,""86"":496,""87"":505,""88"":520,""89"":522},""word"":{""0"":""documents"",""1"":""user"",""2"":""participants"",""3"":""model"",""4"":""users"",""5"":""document"",""6"":""information"",""7"":""relevant"",""8"":""starspire"",""9"":""interactions"",""10"":""foraging"",""11"":""search"",""12"":""study"",""13"":""visual"",""14"":""terms"",""15"":""group"",""16"":""relevance"",""17"":""results"",""18"":""retrieved"",""19"":""interest"",""20"":""number"",""21"":""scores"",""22"":""systems"",""23"":""visualization"",""24"":""open"",""25"":""participant"",""26"":""task"",""27"":""analytics"",""28"":""threshold"",""29"":""recall"",""30"":""conference"",""31"":""precision"",""32"":""north"",""33"":""plot"",""34"":""\ufb01nal"",""35"":""conditions"",""36"":""vast"",""37"":""ieee"",""38"":""signi\ufb01cant"",""39"":""proceedings"",""40"":""computer"",""41"":""human"",""42"":""weights"",""43"":""score"",""44"":""york"",""45"":""automatic"",""46"":""endert"",""47"":""table"",""48"":""node"",""49"":""weight"",""50"":""measure"",""51"":""international"",""52"":""higher"",""53"":""bradel"",""54"":""recommendation"",""55"":""computing"",""56"":""discussion"",""57"":""displayed"",""58"":""subsection"",""59"":""opened"",""60"":""central"",""61"":""begin"",""62"":""graphics"",""63"":""andrews"",""64"":""factors"",""65"":""technology"",""66"":""mail"",""67"":""re\ufb02ect"",""68"":""unique"",""69"":""preferred"",""70"":""\ufb01ndings"",""71"":""novel"",""72"":""sigchi"",""73"":""referred"",""74"":""students"",""75"":""survey"",""76"":""suggest"",""77"":""clutter"",""78"":""having"",""79"":""features"",""80"":""tvcg"",""81"":""symposium"",""82"":""sigir"",""83"":""list"",""84"":""session"",""85"":""missed"",""86"":""character"",""87"":""core"",""88"":""observations"",""89"":""bias""},""threshold"":{""0"":4.5439721979,""1"":4.5439721979,""2"":4.5439721979,""3"":4.5439721979,""4"":4.5439721979,""5"":4.5439721979,""6"":4.5439721979,""7"":4.5439721979,""8"":4.5439721979,""9"":4.5439721979,""10"":4.5439721979,""11"":4.5439721979,""12"":4.5439721979,""13"":4.5439721979,""14"":4.5439721979,""15"":4.5439721979,""16"":4.5439721979,""17"":4.5439721979,""18"":4.5439721979,""19"":4.5439721979,""20"":4.5439721979,""21"":4.5439721979,""22"":4.5439721979,""23"":4.5439721979,""24"":4.5439721979,""25"":4.5439721979,""26"":4.5439721979,""27"":4.5439721979,""28"":4.5439721979,""29"":4.5439721979,""30"":4.5439721979,""31"":4.5439721979,""32"":4.5439721979,""33"":4.5439721979,""34"":4.5439721979,""35"":4.5439721979,""36"":4.5439721979,""37"":4.5439721979,""38"":4.5439721979,""39"":4.5439721979,""40"":4.5439721979,""41"":4.5439721979,""42"":4.5439721979,""43"":4.5439721979,""44"":4.5439721979,""45"":4.5439721979,""46"":4.5439721979,""47"":4.5439721979,""48"":4.5439721979,""49"":4.5439721979,""50"":4.5439721979,""51"":4.5439721979,""52"":4.5439721979,""53"":4.5439721979,""54"":4.5439721979,""55"":4.5439721979,""56"":4.5439721979,""57"":4.5439721979,""58"":4.5439721979,""59"":4.5439721979,""60"":4.5439721979,""61"":4.5439721979,""62"":4.5439721979,""63"":4.5439721979,""64"":4.5439721979,""65"":4.5439721979,""66"":4.5439721979,""67"":4.5439721979,""68"":4.5439721979,""69"":4.5439721979,""70"":4.5439721979,""71"":4.5439721979,""72"":4.5439721979,""73"":4.5439721979,""74"":4.5439721979,""75"":4.5439721979,""76"":4.5439721979,""77"":4.5439721979,""78"":4.5439721979,""79"":4.5439721979,""80"":4.5439721979,""81"":4.5439721979,""82"":4.5439721979,""83"":4.5439721979,""84"":4.5439721979,""85"":4.5439721979,""86"":4.5439721979,""87"":4.5439721979,""88"":4.5439721979,""89"":4.5439721979},""vector"":{""0"":""[-0.60962254 -2.4431422  -1.2245369   4.893097   -0.8894656  -3.0660958\n  4.544764    5.8638597   2.4020076   1.8848143 ]"",""1"":""[-0.9592141 -2.9159493 -1.3780692  5.1938863 -1.7238    -2.872589\n  4.978005   5.736319   2.388166   1.3800068]"",""2"":""[-0.9040314 -2.560691  -1.642073   5.470694  -1.2086674 -2.9773088\n  5.0527534  5.866626   1.8498801  1.4763559]"",""3"":""[-0.62813467 -2.3675532  -1.4698159   4.509263   -1.5040307  -2.6996558\n  4.575173    5.74155     2.7359931   1.4259771 ]"",""4"":""[-0.9481141 -2.537274  -1.4245348  5.108834  -1.3734626 -2.9835885\n  5.033532   5.7316737  2.531111   1.5027133]"",""5"":""[-0.44715902 -2.5021186  -1.4141692   4.823105   -0.9034976  -2.8417294\n  3.8756058   6.0503883   1.6445353   1.5664079 ]"",""6"":""[-0.39621612 -2.6669917  -1.2231538   4.900225   -0.9135151  -2.7663064\n  4.510017    5.7464437   2.3150804   2.0904858 ]"",""7"":""[-0.251102   -3.3659027  -0.81756914  4.742008   -0.9062932  -1.8110672\n  3.411945    5.503479    2.0582817   2.364377  ]"",""8"":""[-1.6503798 -2.7833061 -0.6090353  5.5343175 -1.5978483 -2.1355066\n  4.118533   6.1512847  1.6061667  1.3905758]"",""9"":""[-0.78283286 -2.1350963  -1.5210927   4.6869617  -1.2190694  -2.7466006\n  4.759825    5.953127    2.5545392   1.4096901 ]"",""10"":""[-0.87447643 -2.010911   -1.3827233   4.6845374  -0.9300755  -2.6346695\n  4.2062473   6.1509004   2.1107316   1.2941755 ]"",""11"":""[-0.9310866 -2.2089827 -1.3323061  4.735086  -0.5955647 -2.6357996\n  3.9363906  6.146192   1.9788187  1.3814565]"",""12"":""[-0.9347683 -2.3745227 -1.2670449  4.9423347 -0.8801732 -2.3024614\n  3.8889563  6.165048   1.6067533  1.3609267]"",""13"":""[-0.47484916 -3.401243   -0.8737755   4.7772684  -1.5681077  -2.1368127\n  4.4093156   5.6162148   2.8732533   2.0070941 ]"",""14"":""[-0.8824391 -2.1793733 -1.3264755  4.70498   -0.7692027 -2.930285\n  4.623341   5.965925   2.669732   1.6624064]"",""15"":""[-0.8686451 -3.0663433 -1.8539875  5.1346645 -1.0253358 -2.3671353\n  4.178034   5.8477545  1.5411178  1.0559586]"",""16"":""[-0.29975873 -3.1627038  -1.1514517   4.737159   -0.62652874 -2.183909\n  3.8715994   5.7455196   2.1702266   2.2222369 ]"",""17"":""[-1.0031767 -2.3407192 -1.3714267  4.7737412 -0.6198834 -2.72046\n  4.2797103  6.1394744  2.3152466  1.5537307]"",""18"":""[-0.23531114 -3.8352194  -1.1117638   4.38535    -0.47919753 -1.4527609\n  2.295818    5.8086486   1.5808331   1.8228278 ]"",""19"":""[-0.31433448 -2.8958306  -1.1366879   4.8400087  -0.67469364 -2.119461\n  4.0111074   5.7313604   2.0415082   2.209145  ]"",""20"":""[-0.739746  -3.3891165 -1.8182901  4.7011633 -0.6801511 -2.3227968\n  3.5418315  5.913643   1.6962273  1.1619743]"",""21"":""[-0.7488304 -2.950176  -1.7974902  4.5428343 -0.3697176 -2.6431532\n  3.8328974  6.3179755  2.1461647  1.470476 ]"",""22"":""[-0.8099353 -2.51594   -1.1726726  4.7604933 -1.4582695 -2.6898668\n  4.679561   5.5505376  2.8944144  1.6816101]"",""23"":""[-0.6047774 -3.2394776 -0.8747695  4.9049654 -1.7632692 -2.3749962\n  4.834581   5.6575847  3.0391557  1.9113092]"",""24"":""[-0.3824368 -3.6784115 -0.7945519  4.5908833 -0.9618344 -1.4842588\n  2.690257   5.6322722  1.8329597  2.0138698]"",""25"":""[-0.84096557 -2.6921835  -1.7158006   5.4734497  -1.1837597  -2.9127233\n  4.9197516   5.877033    1.6461232   1.4368138 ]"",""26"":""[-0.8157671 -2.8990998 -1.7113258  4.9584208 -0.8439977 -2.176878\n  3.9464638  5.9572124  1.5555217  1.1285046]"",""27"":""[-0.7793137 -2.9958463 -0.8625964  5.0151415 -1.7942711 -2.5681589\n  4.9949207  5.6712265  2.9955444  1.8219236]"",""28"":""[-0.48995513 -3.4195552  -1.7596287   4.721642   -0.59093726 -2.5403106\n  3.5562727   5.8533974   1.658475    1.5487624 ]"",""29"":""[-0.26922107 -3.4401948  -1.1797343   4.4499636  -0.5393071  -1.7839228\n  2.6532753   5.98282     1.5718333   1.7901424 ]"",""30"":""[-0.827084  -2.7757692 -1.5127174  5.74137   -1.3388057 -2.874711\n  4.8562303  5.9399185  1.2773067  1.5361197]"",""31"":""[-0.4611326 -3.3772151 -1.1919148  4.5350924 -0.7628596 -2.057199\n  3.752757   5.9885488  2.4484324  1.9060143]"",""32"":""[-0.8800157  -2.968004   -0.50041527  4.8548326  -1.5337727  -1.7737594\n  3.615144    5.3724766   2.4009624   1.9792738 ]"",""33"":""[-0.44039372 -2.762707   -1.8183945   4.2885656  -1.4467449  -2.4672904\n  4.6549873   5.974409    2.8266141   1.1841931 ]"",""34"":""[-1.4921441  -2.6712492  -0.64008087  5.3044295  -1.3302598  -1.983965\n  3.8912244   6.1542473   1.6771079   1.4722091 ]"",""35"":""[-0.939976   -2.1795866  -1.2674648   4.691755   -0.88645864 -2.8471117\n  4.643118    5.9078064   2.803937    1.6696103 ]"",""36"":""[-0.4448724 -3.3354516 -0.5348687  4.7823186 -1.3548362 -1.6248032\n  3.4911394  5.301345   2.3473191  2.3400528]"",""37"":""[-1.4835899 -3.3226962 -0.8071458  5.6345944 -2.0654664 -2.5277934\n  4.507961   6.011166   1.7713745  1.210023 ]"",""38"":""[-1.4658464 -2.666955  -0.6138393  5.319374  -1.3449749 -1.997731\n  3.9370196  6.1371465  1.6999425  1.5288947]"",""39"":""[-0.7314446 -2.60083   -1.5472485  5.649256  -1.1410924 -2.9426236\n  4.9242725  5.9497705  1.4367192  1.6787332]"",""40"":""[-0.68845236 -3.1828768  -1.1076847   4.8872766  -1.8176214  -2.4427426\n  4.5933576   5.4211407   2.7500925   1.6189933 ]"",""41"":""[-0.50240624 -3.280893   -0.8251535   4.845222   -1.6278884  -1.9728571\n  4.122564    5.315961    2.6002758   2.024094  ]"",""42"":""[-0.70520824 -3.085385   -1.4970237   4.416649   -0.43276712 -2.270584\n  3.8150446   6.071964    2.4592187   1.566483  ]"",""43"":""[-0.6202827  -3.131178   -1.7869865   4.5577693  -0.45408475 -2.4825811\n  3.5731816   6.273116    1.8374698   1.418615  ]"",""44"":""[-1.422239   -3.3642423  -0.71680886  5.510717   -2.1733196  -2.5291185\n  4.6077337   5.846089    2.1532369   1.3629571 ]"",""45"":""[-0.36487982 -3.6189332  -0.7690168   4.5689454  -1.1920899  -1.695476\n  3.471579    5.6429267   2.5260913   2.1373782 ]"",""46"":""[-1.8561101 -3.1387658 -0.625952   5.7841043 -1.8458416 -2.1072667\n  4.1452537  5.9195523  1.5786277  1.2759125]"",""47"":""[-0.5676221 -3.1454725 -1.8677139  4.7897553 -0.612223  -2.7818174\n  3.820288   5.98187    1.6464645  1.4856436]"",""48"":""[-1.0117127 -3.1824405 -1.1040435  5.2554483 -1.9678993 -2.6658487\n  4.785885   5.6836686  2.3718505  1.4488446]"",""49"":""[-0.60648113 -3.1619878  -1.4796497   4.436034   -0.497525   -2.245242\n  3.7543893   5.9733124   2.3417466   1.5825787 ]"",""50"":""[-0.59019375 -3.1483788  -1.3586892   4.535049   -0.5508419  -2.0862257\n  3.2184215   6.2039485   1.8042536   1.5619622 ]"",""51"":""[-0.40915298 -3.3506343  -0.77914757  4.8769574  -1.3093581  -1.8521274\n  3.8741376   5.409578    2.337494    2.1977715 ]"",""52"":""[-0.52918714 -3.4902687  -0.5329994   4.770531   -1.2915877  -1.5260224\n  3.242623    5.4347625   2.213607    2.2117274 ]"",""53"":""[-1.7868901 -3.0070317 -0.5387795  5.7148137 -1.8057595 -2.1254387\n  4.221138   6.027381   1.6076485  1.3467528]"",""54"":""[-0.33081716 -2.5162585  -1.4369113   4.4596334  -0.87687856 -2.5180535\n  3.6004121   6.0294614   1.8325968   1.5815535 ]"",""55"":""[-0.7767017 -3.1552954 -1.0074416  5.0268393 -1.8912966 -2.5090828\n  4.7768507  5.5526714  2.7540934  1.6831397]"",""56"":""[-0.545665  -2.845174  -1.4987017  5.2996492 -0.9825453 -2.6923\n  4.591139   5.853308   1.6274514  1.8569038]"",""57"":""[-0.35456485 -3.762114   -1.1453452   4.3712792  -0.5946262  -1.5491232\n  2.425437    5.7986794   1.7737846   1.7805815 ]"",""58"":""[-0.42323866 -3.073294   -1.6243868   5.094203   -0.95563203 -2.7741525\n  4.2584066   5.755171    1.6343685   1.8528465 ]"",""59"":""[-0.3120967  -3.757877   -0.96420085  4.414657   -0.75200397 -1.5002832\n  2.2628484   5.8310657   1.6446292   1.9994984 ]"",""60"":""[-0.6090984  -3.275889   -0.43597877  4.8229847  -1.4909589  -1.5842698\n  3.459656    5.2563257   2.3841443   2.2496264 ]"",""61"":""[-0.4630152  -3.4520607  -1.0660521   4.629853   -0.83288604 -1.7910508\n  2.7509205   5.8650527   1.5414386   1.7235191 ]"",""62"":""[-0.5953701 -3.2571194 -1.0271643  4.8327475 -1.7285912 -2.4115436\n  4.721756   5.6604385  2.945318   1.7914766]"",""63"":""[-1.6265713 -3.2610087 -0.654824   5.6227183 -2.1248474 -2.450827\n  4.599414   5.971812   1.9956024  1.234197 ]"",""64"":""[-0.91141045 -2.3443387  -1.2090328   4.7175946  -0.94838727 -2.6995103\n  4.612518    5.8010373   2.8606677   1.7611154 ]"",""65"":""[-0.57191545 -2.8702457  -1.1107402   4.7958183  -1.61881    -2.4471235\n  4.582928    5.4110394   2.8094687   1.8401084 ]"",""66"":""[-0.75667644 -3.059265   -1.4936861   4.5970817  -0.9536751  -2.5650344\n  3.8194916   5.7640457   2.0951042   1.1992308 ]"",""67"":""[-1.5181332 -3.2328544 -0.7743781  5.500106  -1.7889029 -2.2776866\n  4.0541153  6.0606008  1.6349609  1.2557704]"",""68"":""[-0.32331005 -3.4424713  -0.66148156  4.685833   -1.1503745  -1.6661279\n  3.3522165   5.4040127   2.3019865   2.3491375 ]"",""69"":""[-0.23529367 -3.6474512  -0.911415    4.4923043  -0.7556202  -1.5301734\n  2.604824    5.694104    1.7551811   2.0380132 ]"",""70"":""[-1.4547431 -2.5645406 -0.7695737  5.3678946 -1.3394182 -2.2199266\n  4.15708    6.190324   1.6620499  1.4706239]"",""71"":""[-0.46574032 -2.7316937  -1.7785562   4.3024397  -1.4507763  -2.4733167\n  4.6275244   5.937278    2.838706    1.2105035 ]"",""72"":""[-1.385189  -3.13559   -0.9230758  5.8068714 -1.9669312 -2.63358\n  4.7032247  5.9752836  1.5800511  1.336832 ]"",""73"":""[-0.21616977 -3.7603948  -0.99824405  4.478464   -0.6518535  -1.4568572\n  2.3947983   5.7509007   1.5538511   1.892644  ]"",""74"":""[-1.0205563 -2.508299  -1.5011216  5.257553  -1.3092803 -2.9664006\n  5.012471   5.82415    2.2629762  1.4226124]"",""75"":""[-0.93972933 -2.5160685  -1.3713906   4.8249283  -0.77553743 -2.4264398\n  3.8689194   6.030664    1.7580165   1.2853708 ]"",""76"":""[-0.38361254 -3.3886425  -1.2523233   4.490345   -0.64853495 -1.8736374\n  2.7953074   5.919949    1.6300954   1.6919553 ]"",""77"":""[-0.38443655 -3.2485037  -1.225304    4.860528   -0.88326466 -2.3103783\n  4.2731724   5.767165    2.2756696   2.0667918 ]"",""78"":""[-0.6327901  -3.4459612  -1.6285632   4.521193   -0.58120203 -2.0386674\n  3.1941304   5.921848    1.7973342   1.310639  ]"",""79"":""[-0.6964918 -2.5517557 -1.3534344  4.495268  -1.3195097 -2.5717878\n  4.477942   5.6550074  2.9526062  1.5771725]"",""80"":""[-1.5772399 -3.126744  -0.6697623  5.716949  -2.0995061 -2.4416974\n  4.578314   5.922487   1.8727545  1.3791907]"",""81"":""[-0.86246145 -2.778005   -1.4418433   5.659456   -1.3153872  -2.8271194\n  4.8539968   5.928984    1.4006261   1.5914328 ]"",""82"":""[-1.2239732 -3.0069075 -1.0531405  5.7500515 -1.7845098 -2.6960537\n  4.7659025  5.9569907  1.5603302  1.4289283]"",""83"":""[-0.57039845 -3.1879773  -1.7751304   4.766436   -0.73744655 -2.5750191\n  3.6207001   5.8913937   1.544378    1.3416106 ]"",""84"":""[-0.8073037 -2.7167473 -1.6814334  5.5707335 -1.1772199 -2.8014708\n  4.7247195  5.9661775  1.3089584  1.3960962]"",""85"":""[-0.2747129  -3.8293247  -0.9713761   4.521465   -0.72627354 -1.4044571\n  2.3584476   5.7201285   1.5121467   1.8350772 ]"",""86"":""[-0.5764272 -2.7038264 -1.6515933  4.391976  -1.4540706 -2.531151\n  4.5368795  5.8038282  2.8153346  1.26744  ]"",""87"":""[-0.5347414 -3.2478294 -0.5755737  4.784608  -1.4798356 -1.7171557\n  3.6590655  5.2787023  2.487103   2.2269518]"",""88"":""[-0.70444584 -2.177746   -1.3941742   4.570111   -0.9502726  -2.620745\n  4.349872    6.0377054   2.410763    1.596373  ]"",""89"":""[-0.46707937 -2.7874882  -1.2490379   4.772924   -0.5597827  -2.2826865\n  4.137592    5.8572817   2.1911478   2.0676308 ]""},""topic"":{""0"":-1,""1"":-1,""2"":2,""3"":6,""4"":-1,""5"":-1,""6"":-1,""7"":1,""8"":0,""9"":6,""10"":-1,""11"":-1,""12"":-1,""13"":-1,""14"":6,""15"":-1,""16"":1,""17"":-1,""18"":3,""19"":-1,""20"":4,""21"":-1,""22"":-1,""23"":5,""24"":3,""25"":2,""26"":4,""27"":5,""28"":4,""29"":3,""30"":2,""31"":-1,""32"":1,""33"":-1,""34"":-1,""35"":6,""36"":1,""37"":0,""38"":-1,""39"":2,""40"":5,""41"":-1,""42"":-1,""43"":4,""44"":0,""45"":1,""46"":0,""47"":4,""48"":-1,""49"":-1,""50"":-1,""51"":1,""52"":1,""53"":0,""54"":-1,""55"":5,""56"":2,""57"":3,""58"":-1,""59"":3,""60"":1,""61"":3,""62"":5,""63"":0,""64"":6,""65"":5,""66"":-1,""67"":0,""68"":1,""69"":3,""70"":-1,""71"":-1,""72"":0,""73"":3,""74"":-1,""75"":4,""76"":3,""77"":1,""78"":3,""79"":5,""80"":0,""81"":2,""82"":-1,""83"":4,""84"":2,""85"":3,""86"":-1,""87"":1,""88"":6,""89"":1},""exemplar"":{""0"":null,""1"":null,""2"":""*"",""3"":""*"",""4"":null,""5"":null,""6"":null,""7"":null,""8"":""*"",""9"":""*"",""10"":null,""11"":null,""12"":null,""13"":null,""14"":""*"",""15"":null,""16"":null,""17"":null,""18"":""*"",""19"":null,""20"":""*"",""21"":null,""22"":null,""23"":""*"",""24"":null,""25"":""*"",""26"":""*"",""27"":""*"",""28"":""*"",""29"":null,""30"":""*"",""31"":null,""32"":null,""33"":null,""34"":null,""35"":""*"",""36"":""*"",""37"":""*"",""38"":null,""39"":""*"",""40"":""*"",""41"":null,""42"":null,""43"":""*"",""44"":""*"",""45"":null,""46"":null,""47"":""*"",""48"":null,""49"":null,""50"":null,""51"":""*"",""52"":""*"",""53"":null,""54"":null,""55"":""*"",""56"":null,""57"":""*"",""58"":null,""59"":""*"",""60"":""*"",""61"":null,""62"":""*"",""63"":null,""64"":""*"",""65"":""*"",""66"":null,""67"":""*"",""68"":""*"",""69"":""*"",""70"":null,""71"":null,""72"":""*"",""73"":""*"",""74"":null,""75"":""*"",""76"":null,""77"":null,""78"":null,""79"":null,""80"":""*"",""81"":""*"",""82"":null,""83"":""*"",""84"":""*"",""85"":""*"",""86"":null,""87"":""*"",""88"":""*"",""89"":null},""word*"":{""0"":""documents"",""1"":""user"",""2"":""participants*"",""3"":""model*"",""4"":""users"",""5"":""document"",""6"":""information"",""7"":""relevant"",""8"":""starspire*"",""9"":""interactions*"",""10"":""foraging"",""11"":""search"",""12"":""study"",""13"":""visual"",""14"":""terms*"",""15"":""group"",""16"":""relevance"",""17"":""results"",""18"":""retrieved*"",""19"":""interest"",""20"":""number*"",""21"":""scores"",""22"":""systems"",""23"":""visualization*"",""24"":""open"",""25"":""participant*"",""26"":""task*"",""27"":""analytics*"",""28"":""threshold*"",""29"":""recall"",""30"":""conference*"",""31"":""precision"",""32"":""north"",""33"":""plot"",""34"":""\ufb01nal"",""35"":""conditions*"",""36"":""vast*"",""37"":""ieee*"",""38"":""signi\ufb01cant"",""39"":""proceedings*"",""40"":""computer*"",""41"":""human"",""42"":""weights"",""43"":""score*"",""44"":""york*"",""45"":""automatic"",""46"":""endert"",""47"":""table*"",""48"":""node"",""49"":""weight"",""50"":""measure"",""51"":""international*"",""52"":""higher*"",""53"":""bradel"",""54"":""recommendation"",""55"":""computing*"",""56"":""discussion"",""57"":""displayed*"",""58"":""subsection"",""59"":""opened*"",""60"":""central*"",""61"":""begin"",""62"":""graphics*"",""63"":""andrews"",""64"":""factors*"",""65"":""technology*"",""66"":""mail"",""67"":""re\ufb02ect*"",""68"":""unique*"",""69"":""preferred*"",""70"":""\ufb01ndings"",""71"":""novel"",""72"":""sigchi*"",""73"":""referred*"",""74"":""students"",""75"":""survey*"",""76"":""suggest"",""77"":""clutter"",""78"":""having"",""79"":""features"",""80"":""tvcg*"",""81"":""symposium*"",""82"":""sigir"",""83"":""list*"",""84"":""session*"",""85"":""missed*"",""86"":""character"",""87"":""core*"",""88"":""observations*"",""89"":""bias""},""pos"":{""0"":1,""1"":2,""2"":1,""3"":1,""4"":3,""5"":4,""6"":5,""7"":1,""8"":1,""9"":2,""10"":6,""11"":7,""12"":8,""13"":9,""14"":3,""15"":10,""16"":2,""17"":11,""18"":1,""19"":12,""20"":1,""21"":13,""22"":14,""23"":1,""24"":2,""25"":2,""26"":2,""27"":2,""28"":3,""29"":3,""30"":3,""31"":15,""32"":3,""33"":16,""34"":17,""35"":4,""36"":4,""37"":2,""38"":18,""39"":4,""40"":3,""41"":19,""42"":20,""43"":4,""44"":3,""45"":5,""46"":4,""47"":5,""48"":21,""49"":22,""50"":23,""51"":6,""52"":7,""53"":5,""54"":24,""55"":4,""56"":5,""57"":4,""58"":25,""59"":5,""60"":8,""61"":6,""62"":5,""63"":6,""64"":5,""65"":6,""66"":26,""67"":7,""68"":9,""69"":7,""70"":27,""71"":28,""72"":8,""73"":8,""74"":29,""75"":6,""76"":9,""77"":10,""78"":10,""79"":7,""80"":9,""81"":6,""82"":30,""83"":7,""84"":7,""85"":11,""86"":31,""87"":11,""88"":6,""89"":12},""x2D"":{""0"":-3.848815918,""1"":-1.9782557487,""2"":-2.207972765,""3"":-2.9991886616,""4"":-2.3968908787,""5"":-4.8375587463,""6"":-4.3088560104,""7"":-8.318860054,""8"":0.457601279,""9"":-3.0984959602,""10"":-4.2309727669,""11"":-4.53139925,""12"":-4.6630663872,""13"":-2.3464920521,""14"":-3.5322468281,""15"":-5.1935558319,""16"":-6.5249228477,""17"":-4.134393692,""18"":-10.4723472595,""19"":-6.2977027893,""20"":-6.2299108505,""21"":-5.906370163,""22"":-2.6426374912,""23"":-2.1693928242,""24"":-9.9139966965,""25"":-2.2979261875,""26"":-5.3881082535,""27"":-2.0070621967,""28"":-6.1260771751,""29"":-9.9943742752,""30"":-2.107937336,""31"":-6.5500245094,""32"":-7.4141802788,""33"":-3.1732370853,""34"":0.2463514954,""35"":-3.4635629654,""36"":-7.7084889412,""37"":0.33406654,""38"":0.2466566712,""39"":-2.218521595,""40"":-2.2943270206,""41"":-7.3164973259,""42"":-6.2971668243,""43"":-6.108189106,""44"":0.2223633528,""45"":-8.0119390488,""46"":0.7261506319,""47"":-5.6908955574,""48"":-1.6932997704,""49"":-6.2636933327,""50"":-6.6985216141,""51"":-7.7060475349,""52"":-8.0975208282,""53"":0.5458561778,""54"":-5.3113541603,""55"":-1.9455531836,""56"":-2.683031559,""57"":-10.1801099777,""58"":-4.7182273865,""59"":-10.2693071365,""60"":-7.5217952728,""61"":-10.053404808,""62"":-2.3538057804,""63"":0.6053102612,""64"":-3.379134655,""65"":-2.5391805172,""66"":-5.6224370003,""67"":0.44434762,""68"":-7.9679021835,""69"":-10.292049408,""70"":0.2033451349,""71"":-3.0052111149,""72"":-0.0472719297,""73"":-10.2803277969,""74"":-2.3289515972,""75"":-4.9318752289,""76"":-9.8083410263,""77"":-6.0756864548,""78"":-6.5288167,""79"":-2.8060426712,""80"":0.3043648601,""81"":-2.2687163353,""82"":-0.2737278342,""83"":-5.913236618,""84"":-2.4054329395,""85"":-10.160276413,""86"":-2.9993026257,""87"":-7.6593728065,""88"":-3.8378293514,""89"":-6.1488566399},""y2D"":{""0"":-1.22331357,""1"":-0.7005985379,""2"":-1.9819104671,""3"":-0.4437848032,""4"":-0.9244271517,""5"":-2.358042717,""6"":-0.9927779436,""7"":2.0298750401,""8"":-3.3584289551,""9"":-0.8033278584,""10"":-1.6897311211,""11"":-1.9462865591,""12"":-2.1991741657,""13"":0.8263068795,""14"":-0.9074568152,""15"":-2.8424041271,""16"":-0.9905320406,""17"":-1.3982146978,""18"":0.6741257906,""19"":-0.8172721863,""20"":-2.8021500111,""21"":-2.1742749214,""22"":-0.2086719126,""23"":0.6588571072,""24"":0.7004072666,""25"":-2.1639671326,""26"":-2.7584550381,""27"":0.4439003766,""28"":-2.7533419132,""29"":0.3120255768,""30"":-2.3959908485,""31"":-1.3028819561,""32"":1.6961169243,""33"":0.0207471419,""34"":-3.3517622948,""35"":-0.9017157555,""36"":2.2234954834,""37"":-2.598788023,""38"":-3.4771914482,""39"":-2.4682896137,""40"":0.3627581596,""41"":1.4274866581,""42"":-1.8866291046,""43"":-2.4510307312,""44"":-2.4598281384,""45"":2.112172842,""46"":-2.9152970314,""47"":-2.6319508553,""48"":-0.112975277,""49"":-1.9110212326,""50"":-2.2334697247,""51"":1.702570796,""52"":2.0290620327,""53"":-3.0863146782,""54"":-2.1235799789,""55"":0.5298811197,""56"":-2.4472770691,""57"":0.9086845517,""58"":-2.7408463955,""59"":0.8342289925,""60"":1.887873292,""61"":0.4432829916,""62"":0.5256921649,""63"":-2.6063494682,""64"":-0.6230559349,""65"":0.3856605291,""66"":-2.7309494019,""67"":-3.0063476562,""68"":2.1756060123,""69"":0.8399714231,""70"":-3.4930484295,""71"":-0.2328219265,""72"":-2.6808722019,""73"":0.675278604,""74"":-1.2795497179,""75"":-2.316010952,""76"":0.1629600376,""77"":-0.9742184877,""78"":-2.5529267788,""79"":-0.1469613612,""80"":-2.6825680733,""81"":-2.3275873661,""82"":-2.6002585888,""83"":-2.8232550621,""84"":-2.4137818813,""85"":0.5897915363,""86"":-0.0945248827,""87"":1.9563115835,""88"":-1.019331336,""89"":-1.1141015291}}",2018
8QJPPCPZ,False,"[-0.52365613, 0.5398778, 0.09980932, 0.1454877, 0.25759348, -0.11815787, -0.17519699, 0.2610237, -0.105921574, -0.4053989, 0.0055270786, 0.01762518, -0.08012281, 0.07822208, -0.14728105, 0.44408795, 0.11763652, -0.10604253, -0.023112018, 0.23029514, 0.15285636, 0.3341633, -0.13994835, 0.24488744, 0.32604548, -0.17394426, 0.043031085, 0.32397306, -0.41972992, 0.09544506, 0.1972095, 0.5894566, -0.12011661, -0.6358027, -0.09195889, -0.117761195, -0.4351194, -0.27092168, -0.3260157, 0.20099588, -0.23949052, -0.1022722, -0.11330983, -0.12286264, -0.2337336, -0.36178517, -0.25269878, -0.10661262, 0.037349693, -0.35213417, -1.4196968, 0.16020803, -0.17611673, 0.24390158, 0.08912067, 0.43125674, 0.4850637, -0.42939225, 0.32119316, -0.001625573, -0.3665934, 0.06726381, -0.13579401, -0.30939072, 0.13095292, 0.19097716, 0.39792195, -0.1964612, -0.5888242, 0.5117576, -0.4671853, 0.15898418, -0.29846248, 0.059808463, -0.98147464, 0.011215775, -0.03373789, -0.032621756, -0.08473695, 0.08897424, -0.40135765, 0.8024443, 0.30160472, -0.53777945, 0.65839815, 0.18323202, -0.02134915, 0.6682864, -0.19357492, 0.046947174, 0.15633784, 0.10863631, -0.09855631, -0.032575127, 0.71260214, -0.14107876, -0.023971388, 0.0011028108, -0.10355501, 0.034213234, ...]",{},"[0.017749824, -0.27278405, 0.09125522, -0.26342165, 0.8011544, 0.00016029552, -0.086652376, -0.18939957, -0.56258297, -0.11672248, -0.16690978, -0.3474644, 0.25198412, 0.15236558, -0.2392005, 0.88497704, -0.38091886, -0.2721017, -0.07572977, 0.077711314, 0.15895167, -0.25662202, 0.012840538, 0.53247, 0.10702643, -0.038546227, -0.094460934, -0.02752568, -0.27265897, 0.19212715, 0.326948, 0.65046495, 0.03395265, -0.48302078, 0.13352917, -0.035971593, -0.30614492, -0.09046067, -0.16643454, 0.6442305, -0.25580543, -0.28211188, 0.005901823, -0.30214968, 0.16498943, -0.016433954, -0.27295893, -0.06072659, -0.04747303, -0.30972785, -1.4434001, -0.18596621, 0.0051417183, -0.67496943, 0.003407371, 0.659665, -0.1803819, -0.70375365, 0.32332343, 0.3746075, -0.18100052, -0.040669575, -0.09339497, 0.033305164, 0.4688569, -0.34203234, 0.15862489, 0.35186726, -0.5339347, 0.23810905, -0.07970148, -0.12190573, -0.06815231, 0.610923, -0.84324175, -0.04008453, 0.11530475, 0.12093911, 0.2696889, -0.30152127, -0.11659473, 0.24505056, -0.01424494, 0.033644926, 0.59221166, 0.92527044, -0.27873176, 0.64772284, -0.45650855, 0.32014206, -0.08885286, 0.036768667, -0.2899358, 0.44336995, 0.89920884, -0.321556, -0.4716785, 0.096036285, 0.054089647, -0.13015266, ...]",False,False,False,False,"[-0.521199, -0.15241322, 0.19467, -0.019654073, 0.33532563, 0.2336848, 0.22425167, 0.16345741, -0.18031177, 0.110215865, 0.06702453, -0.36134675, 0.1997205, -0.019295186, -0.08075986, 0.45178908, -0.09972671, -0.091032706, -0.24165086, -0.14331959, 0.70174056, -0.12629078, -0.54100335, 0.11407817, 0.3448391, 0.329107, 0.038276747, -0.43730918, -0.41905844, -0.0716962, -0.23884507, 0.23245668, 0.13344693, -0.418622, -0.27947256, 0.03564299, -0.18047367, 0.18084408, -0.028883466, -0.04501064, -0.34261173, -0.1359873, 0.35182106, -0.047662243, 0.26295933, -0.090963125, -0.059103288, -0.36779743, -0.17597502, -0.03624345, -0.68310577, 0.39185077, 0.19414236, -0.31885496, -0.16214405, 0.3082636, 0.16945237, -0.48931137, 0.09248655, 0.13872533, -0.084354, -0.36497223, -0.076423384, -0.22054721, -0.18990706, -0.47616833, 0.48186368, 0.5189199, -0.40354955, 0.43668678, -0.10697727, 0.31485692, -0.13994616, 0.13083407, -0.25286755, -0.27826995, 0.05600156, 0.27061003, -0.12625387, 0.032319028, -0.27033365, 0.1485794, 0.21926077, -0.16584851, 0.10147095, 0.419277, 0.00728719, 0.23252359, -0.24317382, 0.1163241, -0.37007594, -0.084791444, 0.25533316, 0.05517201, 0.22221026, -0.449763, -0.43011552, -0.009366346, -0.01805756, -0.29673043, ...]",8QJPPCPZ,,False,False,8QJPPCPZ,6VMGJTXT,[],"multi-model semantic interaction for text analytics 

lauren bradel, chris north, leanna house, scotland leman 

semantic interaction. 
fig. 1. starspire spatial workspace showing clusters of open documents and numerous iconified documents selected and arranged through 
abstract—  semantic  interaction  offers  an  intuitive  communication  mechanism  between  human  users  and  complex  statistical 
models. by shielding the users from manipulating model parameters, they focus instead on directly manipulating the spatialization, 
thus  remaining  in  their  cognitive  zone.  however,  this  technique  is  not  inherently  scalable  past  hundreds  of  text  documents.  to 
remedy this, we present the concept of multi-model semantic interaction, where semantic interactions can be used to steer multiple 
models at multiple levels of data scale, enabling users to tackle larger data problems. we also present an updated visualization 
pipeline model for generalized multi-model semantic interaction. to demonstrate multi-model semantic interaction, we introduce 
starspire, a visual text analytics prototype that transforms user interactions on documents into both small-scale display layout 
updates as well as large-scale relevancy-based document selection. 
index terms— visual analytics, semantic interaction, sensemaking, text analytics. 

 
introduction 

to  manage  different  portions  of 

1 
the problem of “too much data” has become a significant challenge 
in unstructured text sensemaking. analysts are expected to “connect 
the  dots”  across  many  documents  [19],  requiring  analysts  to  work 
across  multiple  models 
the 
sensemaking loop [28]. 
during  foraging,  analysts  work  at  the  large  scale  (beyond  data 
displayed  on  the  screen).  because  the  number  of  documents 
available  far  outweighs  the  number  of  relevant  documents  (e.g. 
millions of documents with hundreds or fewer relevant documents), 
the  low  signal-to-noise  ratio  makes  this  a  “needle  in  a  haystack” 
problem. thus, analysts need methods of honing in on and finding 
additional relevant documents. additionally, analysts must find all of 
the relevant documents in order to avoid missing important pieces of 
information. relevance models are helpful at this scale. 
 during  synthesis,  analysts  work  at  the  small  scale  (e.g.  the 

information  on 

foraging  and  synthesis,  using  multiple  models 

amount of data that comfortably fits onto a display) with hundreds or 
fewer  documents.  a  common  synthesis  strategy  is  to  spatially 
organize 
the  display  [1].  spatialization  and 
dimensionality reduction models are helpful at this scale [10]. the 
analyst then performs synthesis on these documents to make sense of 
them, but may have need for additional information.   
thus,  the  sensemaking  process  consists  of  continuous  iteration 
between 
to 
accomplish  different  sensemaking-related  tasks.  however,  current 
tools require the analyst to break from synthesis actions to forage for 
additional information, which interrupts their cognitive processes. 
we propose unifying the sensemaking loop by coupling synthesis 
with foraging, and therefore coupling the corresponding models and 
interactions,  resulting  in  a  multi-model  approach.  in  other  words, 
synthesis  activities  can  be  interpreted  to  forage  for  additional 
relevant information and filter out irrelevant data. likewise, foraging 
activities can influence synthesized structure.  to accomplish this, a 
method of usable control over coupled models is needed. 
models which support computing data relevance (foraging) and 
spatial layout (synthesis) typically require parametric interaction, but 
most analysts are not experts in these underlying models and are ill-
equipped to interact directly with the parameters. instead, semantic 
interaction  (si)  techniques  convert  user  interactions  within  a 
spatialization into parametric feedback, enabling a spatialization that 

•  lauren bradel, chris north, leanna house, and scotland leman are with 
virginia tech. e-mail: [lbradel1, north, lhouse, leman]@vt.edu 
manuscript  received  31  march  2014;  accepted  1  august  2014;  posted 

online 13 october 2014; mailed on 4 october 2014. 

for information on obtaining reprints of this article, please send  
e-mail to: tvcg@computer.org. 

 
 

 

is jointly created by user and algorithm [12, 14]. these techniques 
shield  the  user  from  the  complexity  of  underlying  spatialization 
algorithms  and  allow  them  to  focus  on  data  analysis.  however, 
semantic interaction has been limited to steering a single underlying 
model with fewer than 1000 data points.  
our goal is to generalize semantic interaction to simultaneously 
steer  multiple  models.  this  involves  new  challenges  in  mapping 
semantic interactions to multiple model parameters in a coordinated 
way  and  conveying  combined  model  output  via  visual  feedback. 
specifically, we instantiate this for the purpose of leveraging models 
at  different  levels  of  data  scale  to  support  larger  datasets.  in  our 
method,  users  invoke  semantic  interaction  techniques  in  order  to 
incrementally adjust a spatial layout model as well as influence what 
information is presented to them via a relevancy model.  
we present three contributions: (1) the concept, named multi-
model  semantic  interaction  (msi),  is  an  alternative  to  explicitly 
controlling  parameters  in  multiple  models.  (2)  we  formalize  this 
extension  in  the  form  of  an  updated  visualization  pipeline  that 
reflects  the  generalizability  of  semantic  interaction  to  multiple 
models.  (3)  to  demonstrate  multi-scale  semantic  interaction,  we 
present  starspire 
[figure  1],  a  visual  analytics  prototype 
implementing msi for unstructured text data, which has been tested 
on  datasets  up  to  10,000  text  documents.  we  conclude  with  a 
discussion of multi-scale semantic interaction and research directions 
moving forward. 
table  1.  multiple  levels  of  data  scale  and  their  associated  models, 
visualizations, and feedback mechanisms. 

scale of 
interaction 
sensemaking 
loop 
model purpose 

usage 
description 

model  

model 
parameters 
model metrics 
visualization 

interactive 
feedback 

small  

synthesis 

large 

foraging 

spatially project small 
scale data points onto the 
display, e.g. based on 
similarity 
system lays out displayed 
data, according to user’s 
spatial organization 
feedback 
dimensionality reduction 

dimension weights 

extract useful data 
from large scale, e.g. 
based on relevance or 
coverage 
system selects data 
to display based on 
relevance according 
to user’s interests 
relevance-based data 
selection 
dimensions weights 

similarity metric 
similarity mapped to 
visual proximity 

relevance metric 
relevance mapped to 
working set, glyph 
size, and saturation 
semantic interactions (see table 2) update the 

dimension weights 

2  related work 
spatializations are frequently employed to aid sensemaking (foraging 
and  synthesis)  of  unstructured  text  documents  [2,  21,  30,  33,  34]. 
large,  high-resolution  displays  in  particular  have  been  found 
beneficial in affording a large, flexible workspace that allows users 
to externalize knowledge and create semantic schemas [1]. however, 
this  knowledge  externalization 
through 
parametric interactions (e.g. [22]), many of which require users to go 
outside  the  spatial  metaphor  by  manipulating  control  panels  [11]. 
furthermore, parametric interaction does not easily scale to big data 
problems. in unstructured text data, dimensions map to the terms or 
entities contained in the documents. thus, the dimensionality of the 
data grows extremely large as the number of documents increases. 
aside  from  navigating  through  the  flood  of  dimensions,  altering 
multiple models becomes extremely tedious. if multiple models are 
used for layout and/or retrieval, the user must update the dimensional 

typically  achieved 

is 

landmarks 

to  adjust 

to  manipulate  spatial 

weights or parameters for each model. to remove this redundancy, 
we prefer to contain the interaction within the spatial metaphor and 
translate interactions into parametric feedback. 
for  tools  that  allow  users  to  stay  within  the  spatial  metaphor, 
parametric interaction is still common. for example, dust & magnet 
allows  users 
the 
spatialization of multi-variate data [35]. however, these landmarks 
are attributes of the data, not points themselves. the users only have 
control  over  the  parameters  in  the  space.  similarly,  vibe  allows 
users to designate keywords as spatial landmarks [27]. in msi, users 
can  designate  specific  data  points  as  spatial  landmarks.  these 
landmarks  attract  other  data  points  (e.g.  documents)  based  on  the 
high-dimensional data instead of a single attribute or dimension. 
systems  exist  which  allow  users  to  directly  manipulate  data 
points, interpret this feedback via a dimensionality reduction model 
to  generate  a  new  spatialization  that  better  reflect  the  user’s 
understanding  of  the  high-dimensional  data  [6,  14,  20].  these 
methods  inherently  suffer  from  scalability  issues.  users  expect  a 
quick interaction-feedback loop in order to remain in their “cognitive 
zone” [16], but calculations on thousands, let alone millions, of data 
points take from minutes to hours to complete. it is more practical to 
perform dimensionality reduction on a subset of a much larger data 
set  and  use  information  retrieval  techniques  to  retrieve  additional 
information to add to the workspace. 
msi  is  perhaps  most  similar  to  adaptive  query-by-example 
systems. these systems, such as adaptive information retrieval [3], 
use relevance feedback to augment future retrieval requests to return 
results that are better tuned to the user(s). attempts have been made 
to visualize information retrieval results (e.g. term distribution charts 
[18], self-organizing semantic maps [25]), but these techniques have 
not been widely adopted. information retrieval results are typically 
visualized as a ranked list of results [26]. presenting results in this 
format  is  suitable  for  targeted  queries  where  the  user  may  view  a 
handful of results at most (e.g. a web search for a specific culinary 
recipe). however, when the user is presented with hundreds of viable 
documents  worth  reading  (e.g.  an  intelligence  analysis  task)  that 
relate in complicated, intricate, and fuzzy ways, a linear list becomes 
less than ideal [5]. 
card  presents  a  survey  of  visualization  techniques  for  huge 
amounts of unstructured text data [7]. these techniques include, but 
are  not  limited  to,  dimensionality  reduction  (e.g.  [33]),  semantic 
maps (e.g. [25]), hierarchies (e.g. [4]), and link-node diagrams (e.g. 
[24]).  we  have  chosen 
to  explore  dimensionality  reduction 
techniques and link-node diagrams for representing unstructured text 
data,  but  we  recognize  the  potential  to  explore  other  visual 
representations in the future.  
choo  and  park  provide  an  overview  on  scaling  computational 
methods  to  the  problem  of  big  data  [8].  in  our  research,  we  have 
chosen  the  data  scale  confinement  solution.  by  constraining  the 
visualized  data  to  a  subset  of  the  actual  dataset,  dimensionality 
reduction  calculations  grow  much  more  efficient  than  computing 
across the entire dataset. this motivates our multi-scale approach to 
sensemaking. after performing information retrieval requests on the 
entire data set to procure a subset, the subset can be run through a 
suitable spatial layout model. 
we have developed multi-model semantic interaction in order to 
accommodate the need to work with extremely large amounts of data 
interpreting 
while  staying  within 
interactions to manipulate multiple data models. 
3  semantic interaction 
semantic interaction serves as means for analysts to work with data 
within a spatialization instead of altering algorithms or the raw data 
[figure 2]. this is particularly important when the analyst is a non-
expert in the layout model(s). 
to develop semantic interaction, we first observed analysts, both 
novice and expert, completing sensemaking tasks and recorded the 
actions  analysts  undertook  [1,  5,  13].  we  then  harnessed  these 

the  spatial  metaphor  and 

can interact. the interactions done within the spatialization are then 
interpreted to influence the layout and/or retrieval models. thus, the 
user is able to work with multiple models working at multiple levels 
of scale through interactions done on the data in the spatialization. 
for example, if a user executes a search for a term, documents 
containing this term in the spatial workspace would be drawn closer 
to the search node and the system would query the larger  “behind 
the  scenes”  dataset  for  this  term  and  add  the  top  n  retrieved 
documents  that  surpass  a  relevance  threshold,  ranked  by  the 
importance  the  user  has  given  to  entities.  this  is  an  incremental 
formalism approach [29] wherein the system considers the history of 
interactions  to  gradually  construct  and  refine  the  user’s  interest 
model of the data. in addition to just retrieving documents, multi-
scale semantic interaction augments the relevance model to tune the 
results to the user’s interests. 
in terms of the sensemaking loop [28], synthesis actions  are used 
to drive foraging activities and many foraging activities are able to 
be  conducted  implicitly  instead  of  explicitly.  for  example,  as  the 
user constructs a cluster by dragging documents together, the system 
can  search  the  entire  dataset  for  documents  that are  similar  to  the 
shared  terms  in  the  clustered  documents  and  add  them  to  the 
workspace.  foraging  actions  such  as  these  that  are  conducted 
through implicit means allow for a richer and more nuanced query 
than explicit actions. for example, an explicit search for additional 
documents  may  take  the  form  of  a  boolean  search.  an  implicitly 
constructed  query  could  go  beyond  boolean  values  to  indicate  the 
relative importance of terms as well as include a far greater number 
of  terms  than  the  user  is  likely  to  enter.  this  method  of  implicit 
query formation attempts to return semantically relevant information 
to the user and seeks to fill in gaps of knowledge that a strict boolean 
search might miss. 
in  addition  to  bringing  information  into  the  spatial  workspace, 
multi-model  semantic 
irrelevant 
information.  if  a  user  indicates  that  a  document  or  term  is 
uninteresting or not relevant to their current investigation, the system 
will  interpret  this  interaction  to  update  the  user’s  interest  model 
parameters  to  reflect  this.  accordingly,  information  related  to  this 
document or term would be filtered or removed from the display and 
would  be  less  likely  to  be  returned  from  information  retrieval 
requests. 
multi-model  semantic  interaction  conveys  the  output  of  the 
multiple  models  through  visual  encodings  to  convey  document 
relevance and relationships between documents. this serves to give 
the user immediate visual feedback regarding their interactions. 
4.1 
we present an updated visualization pipeline to reflect multi-scale 
semantic 
is 
constructed  by  taking  the  data,  or  a  working  set  of  the  data  as 
determined by a relevance model, and passing it through a display 
layout model. the user then perceives the spatialization and has the 
option of interacting with the data within the spatial metaphor. all 
interactions are interpreted and directed to the appropriate inverted 
model(s). the inverted models then are combined, if necessary, and 
the new parameters are stored in the user’s high dimensional model 

updated visualization pipeline 

interaction  also 

filters  out 

interaction  [figure  3].  the 

initial  spatialization 

levels  bottom:  semantic 

fig. 2. top: original visualization pipeline showing user interaction at 
the  algorithmic  and  data 
interaction 
visualization pipeline showing user interaction within the spatialization, 
which is then interpreted by the model to extract parameters (stored in 
the system as “soft data”), which are used to update the spatialization. 
actions such that the system could learn from the user which terms 
were  important  to  them  in  their  analysis,  resulting  in  semantic 
interaction  [12].  previously,  we  have  applied  this  technique  to 
unstructured text data in a modified force-directed layout, allowing 
the semantic interactions to update the spatial layout, which used a 
“near  =  similar”  metaphor.  alternatively,  semantic  interaction  has 
been applied to additional dimensionality reduction models, namely 
multi-dimensional  scaling  (mds),  principle  component  analysis 
(pca), and generative topographic mapping (gtm) [14]. semantic 
interaction  has  been  practically  applied  to  multi-dimensional 
scaling  using  multivariate  data,  although  the  interactions  were 
limited to moving and highlighting data points [20]. 
while current forms of semantic interactions have shown to be 
successful,  they  are  limited  in  the  number  of  data  items  they  can 
handle  simultaneously  (less  than  1000)  and  have  been  limited  to 
steering a single model (spatial layout). thus, semantic interaction 
alone is not adequate for tackling the challenge of big data.  
4  multi-model semantic interaction 
we  addressed  the  scalability  concern  by  developing  a  generalized 
semantic 
interaction  pipeline  where  multiple  models  can  be 
leveraged,  providing  functionality  across  multiple  levels  of  data 
scale. the result of this pipeline is a spatialization with which the 
user can interact, externalizing their knowledge of the data. these 
interactions are then converted into parametric feedback in order to 
update  the  underlying  model(s),  and  ultimately,  update  the  spatial 
representation of the data to reflect these changes [fig. 3]. 
using  [table  1]  as  a  guide  for  interaction  and  visualization  at 
multiple levels of data scale, we see that small amounts of data map 
to dimensionality reduction models, while large amounts of data map 
to retrieval models. using semantic interaction techniques, we seek 
to communicate with and between these various models in order to 
update the spatialization, select potentially relevant new information, 
and filter out irrelevant data. 
at the large scale, semantic interactions are mapped to retrieval 
requests, which serve to constrain the amount of data piped into a 
display  layout  model  by  extracting  a  working  set  of  relevant 
documents, which then creates a spatialization with which the user 

fig. 3. generalized multi-scale semantic interaction visualization pipeline. any number of models can be inserted for use in this pipeline. once 
the user perceives the spatialization, they can choose to interact in it. this interaction feedback is interpreted as input to one or many inverted 
models. the updated model parameters are stored, which are then used, along with the original data, to create an updated spatialization. 

of the data. this high dimensional model is then coupled with the 
dataset  to  pass  through  the  retrieval  and  projection  portion  of  the 
loop, resulting in an updated spatialization. this pipeline currently 
assumes a single shared set of model parameters. possible extensions 
of this pipeline include multiple user models for the data (e.g. the 
user believes the data should be arranged in a different manner than 
what the user believes should be displayed). 
not  all  semantic  interactions  will  necessarily  influence  every 
model or have the same impact. we offer a few examples to illustrate 
this point. highlighting a phrase in a document typically indicates its 
importance,  while  minimizing  a  document  when  space  is  not 
constricted  typically  indicates  the  unimportance  of  its  contents. 
moving points around the display would naturally update the display 
layout,  but  would  not  necessarily  fetch  new  data  points  for  the 
workspace.  
furthermore,  updates  to  the  underlying  models  should  be 
executed wisely. updating a model that impacts the entirety of the 
data  set  will  likely  be  a  slow  operation,  whereas  a  display  layout 
model operating on a small subset of the data can be executed much 
quicker. therefore, it is practical to update the display layout model 
with each semantic interaction, but it may not be practical to do so 
for the information retrieval model. obviously, if a user explicitly 
queries for information, it should be returned promptly. otherwise, it 
may  be  a  better  option  to  check  for  new  potentially  relevant 
information and/or update the underlying model every n interactions. 
5  starspire 
starspire (semantic translation of actions for retrieval – spatial 
paradigm  for  information  retrieval  and  exploration)  is  a  visual 
analytics  tool  prototype  that  implements  multi-model  semantic 
interaction  techniques  using  two  models  (relevancy  and  display 
layout)  [figure  4].  starspire  is  built  upon  the  foundation  of 
forcespire,  a  semantic  interaction  visual  analytics  tool  prototype 
for  exploring  unstructured  text  documents  [12].  starspire  and 
forcespire share a flexible spatial workspace (driven by a modified 
force-directed  layout  [12,  15])  and  several  semantic  interactions. 
this  system  extends  upon  previous  work  to  integrate  relevance-
based retrieval and layout models, provides richer visual encodings, 
leveraged.  starspire 
and  adds 
interactions 
dynamically  adjusts  how  many  data  points  are  displayed  by  using 
heuristic-based  relevance  metrics.  while 
its  predecessor  was 
designed specifically for use on large, high-resolution displays, the 
push-and-pull  nature  of  displayed  data  in  starspire  has  made  it 
usable regardless of display size. 
5.1 
within the spatial workspace, document nodes are visually encoded 
to relate their relevance to the user’s high dimensional understanding 
of the data [figure 5]. node size and saturation are encoded to reflect 
how closely a document matches the entities the user has deemed 
important. node size and saturation are calculated by summing all of 
the entity weights in a document, ranking these values, and sorting 
them  into  quartiles.  quartiles  were  chosen  instead  of  absolute 

visual encodings 

the  semantic 

to 

interactions 

ranking  to  optimize  the  node  drawing  process,  minimizing  the 
number  of  calculations  and  changes  required  with  each  user 
interaction. this was done to promote a quick interaction-feedback 
loop. 
these  encodings  give  the  illusion  of  a  third  dimension  in  the 
workspace where more important documents are in the foreground 
while less important documents fade into the background. however, 
unlike  a  true  three-dimensional  layout,  document  nodes  cannot 
overlap each other, preventing occlusion. 
additionally, starspire provides visual cues for navigating the 
workspace.  node  color  is  used  to  indicate  search  term  matches. 
instead  of  showing  all  links  between  all  documents,  starspire 
restricts  the  edges  shown  to  those  connected  to  the  selected  node. 
entities shared between documents are labelled on the edge, but are 
restricted  to  the  top  four  entities,  determined  by  their  importance 
weights. all nodes are labelled with their document’s titles in order 
to allow for easier navigation in the space and to allow users to track 
a  specific  node’s  movement  throughout  the  space.  each  node’s 
outline color is used to denote its read or unread status in order to 
allow analysts to see which documents they have read and closed. 
within each document, search terms are identified and the text color 
is changed to allow the terms to stand out for easier identification. 
these encodings were identified and/or adjusted through an informal 
usability requirements analysis of starspire. 
5.2 
starspire  begins  with  a  blank  spatial  workspace  with  documents 
loaded  into  memory.  the  user  then  executes  a  search  to  add 
documents  to  the  workspace.  this  grants  the  user  flexibility  for 
where  to  start  their  analysis  and  mimics  an  analyst  executing  a 
database  search  to  return  a  set  of  documents  with  which  to  begin 
their  analysis.  granted,  this  supported  use  case  assumes  that  the 
analyst  is  conducting  a  directed  sensemaking  task.  this  does  not 
support the use case of being handed a stack of documents and told 
to  “see  if  there  is  anything  suspicious.”  in  this  scenario,  other 
methods, such as topic modelling, would be useful to aid the analyst 
in finding a starting point for their analysis. 
documents  are  laid  out  using  a  modified  force-directed  layout 
where the spring attractive force between two nodes is determined by 
summing the weights of shared entities. thus, the layout’s input is 
the displayed data for the current timestep and the weight vector for 
the  previous 
is  determined  by 
interpreting  user  interactions  [table  2].  the  set  of  displayed 
documents is determined from a document relevance model. 
users can then interact with the data to incrementally formalize 
their understanding of the data. these interactions include moving 
nodes,  pinning  nodes  to  create  spatial  landmarks,  resizing  nodes, 
collapsing open nodes, annotating documents, searching for terms, 
highlighting 
linking  document  nodes.  with  each 
interaction, the display layout updates to allow nodes to move about 
the space to reflect the new entity-weighting scheme. additionally, 
the visual encodings are updated to reflect document relevance based 
on the entity weights. 

timestep.  the  weight  vector 

terms,  and 

fig. 4. implemented version of the multi-scale semantic interaction visualization pipeline. in starspire, a relevance model and a display layout 
model are used. with each user interaction, the perceived importance of terms updates, changing the spatial and the working set of data is 
modified. the dashed black arrow indicates typical force-directed layout interactions that do not influence the user’s interest model parameters. 

fig. 5. starspire workspace, which is a node-link diagram connected by shared entities using a modified force-directed layout. nodes represent 
closed documents, which are color-coded based on search terms. node size and saturation encode document relevance, based on how well the 
document matches the user-driven entity-weighting scheme. node outline color denotes read/unread status (white for unread, black for read). all 
nodes are labelled with their file names for easy tracking of documents as they move in the workspace. edges radiate from the selected document 
node, labelled with shared entities. 

moving nodes and pinning nodes have no impact on the entity 
weighting scheme, but serve to rearrange the spatial workspace to 
reflect the user’s organizational schema. these are traditional force-
directed layout actions. 
resizing a document to make it larger or smaller increases or 
decreases the weight value of each entity contained in the document, 
respectively.  this  is  interpreted  as  relevance  feedback  and  the 
system updates the working set of documents appropriately.  
minimizing  a  document  decreases  the  weight  values  of  all 
entities  contained  in  the  document.  closing  a  document  also 
decreases the weight values of all entities contained in the document, 
but at a higher magnitude than minimization [figure 6]. 
resizing  a  node  to  make  it  larger  or  smaller  increases  or 
decreases the weight values of all entities contained in the document, 
respectively. resizing a node is accomplished by selecting a node 
and using the mouse scroll button to alter the node’s size. if a node is 
made larger, the system queries for additional similar documents. if a 
node  is  made  smaller,  the  system  tracks  this  feedback  to  be  less 
likely to retrieve similar documents in the future. 
annotating  a  document  adds  the  [new]  terms  to  the  typed-in 
document  and  increases  their  weight  values.  the  system  retrieves 
documents matching the entities contained in the annotation. 
searching for a term increases that term’s associated weight and 
retrieves  documents  matching  the  search  term.  this  action  returns 
more matching documents than other semantic interactions because 
it is an explicit request for related information. 
highlighting a term or phrase increases the weight values of all 
highlighted  entities  and 
the 
highlighted entities. 
overlapping  documents  increases  the  weight  values  of  all 
common  entities  between  the  two  overlapping  documents  and 
retrieves  documents  matching  the  shared  entities  between  the 
documents. 
with each semantic interaction, the spatial layout updates and, if 
necessary, the system queries for new relevant documents and adds 

retrieves  documents  matching 

relevance-based retrieval 

them, if any, to the workspace. because starspire is designed to 
test the usability of semantic interactions operating across multiple 
models (and theoretically vastly different levels of data scale), we 
have thus far only tested the system on smaller datasets (e.g. on the 
order  of  10,000  documents).  as  a  result,  starspire  is  capable  of 
updating all models (display layout and information retrieval) with 
each user interaction as well as storing the entire dataset in memory. 
this  will  likely  not  be  the  case  with  much  larger  datasets.  future 
implementations  will  likely  require  database  support  or  leverage 
cloud-based architectures. 
5.3 
we selected a simple modified linear search algorithm to serve as the 
relevance model. when starspire increases an entity’s importance, 
it searches the backend database for additional documents to add to 
the  workspace  and  adds  the  top  n  search  results  that  exceed  a 
relevance  metric  [figure  7].  currently,  a  maximum  of  twenty 
documents are added if the user executes a search and a maximum of 
eight documents are added from all other semantic interactions that 
result  in  a  request  for  more  information.  additional  data  can  be 
obtained, if available, by repeating the interaction. this allows for 
progressive disclosure of information to keep too much information 
being added to the display at one time, which could overwhelm the 
analyst. the spatial layout then updates to accommodate these new 
data points. 
the  current  relevancy-based  threshold  allows  for  a  variable 
number of documents in the working set of data. by not restricting 
the number of documents that can be present on the screen, the user 
is  capable  of  maintaining  as  much  information  as  inferred  to  be 
relevant  to  their  sensemaking  task.  in  the  future,  this  could  be 
updated  to  allow  for  additional  heuristics,  such  as  the  number  of 
opened/closed document nodes, node proximity to the center of the 
workspace,  or  how  recently  a  document  has  been  added  to  the 
workspace. 

table 2. starspire’s interpretation of semantic interactions in terms of 
the parametric updates to the model of the user’s interests. 
interaction 
resize document 
minimize document 
close document 

model parameter effect 
scale all weights of terms in the document 
down-weight terms by 25% 
down-weight terms by or 40%, remove from 
working set 
scale all weights of terms in the document 
up-weight terms by a constant, add terms to 
model 
up-weight term by a constant, add terms to 
model, adjust relevance threshold as needed 
up-weight terms by a constant 
up-weight shared terms by a constant 

resize node 
annotation 

search 

highlight 
overlap documents 

respectively 

 
new  information  can  be  added  to  the  display  implicitly  or 
explicitly.  the  user  can  explicitly  query  for  new  documents  by 
executing  a  search.  implicit  queries  are  constructed  using  the 
interpreted  semantic  interactions  [table  2].  these  implicit  queries 
are typically more complex than the explicit queries, which include 
single terms. the implicit queries often include multiple terms and 
their associated relative importance. 
documents  that  fall  below  the  current  relevance  threshold  are 
removed  from  the  display,  leaving  the  user  with  a  working  set  of 
documents that match the user’s interests in the data. 
this retrieval process was chosen in order to support incremental 
changes  to  the  information  on  the  display  as  well  as  real-time 
interaction. if data were not merely added (or subtracted) from the 
displayed documents, the user could be presented with an entirely 
new  set  of  displayed  data,  which  could  be  disorienting.  thus,  we 
prefer an incremental approach. 
the  psuedocode  for  starspire’s  retrieval  algorithm  is  as 
follows: 
 
retrievedocuments(docsdisp, docshid, wt, wt-1, limit): 
//docsdisp = list of documents displayed 
//docshid = list of documents not displayed 
//  wt,  wt-1  =  array  of  entity  weights  at  timestep  t  and  t-1, 
//limit = maximum documents to add to the display 
1. 
2. 
3. 
4. 
5. 
6. 
7. 
8. 
9. 
10. 
11. 
12. 
13. 
14. 
15. 
16. 
17. 
18. 
19. 
20. 
21. 

docmatches = empty list of documents 
δw[] = wt – wt-1 
for i = 1 : docshid.length 
     weight = 0 
     for j = 1 : δw.length 
          if(docshid[i].hasentity(wt.entity) 
               weight += δw[j] 
     if(weight > 0) 
          docmatches.add(docshid[i]) 
for i = 1 : docmatches.length 
     docmatches[i].relevance =  
for i = 1 : docdisp.length 
     docdisp[i].relevance =  
docsranked[] = sort(docmatches) based on relevance 
for i = 1 : min(limit, docsranked.length) 
     docsdisp.add(docsranked[i]) 
     docshid.remove(docsranked[i]) 
docsdisp[] = sort(docsdisp) based on relevance 
for i = 1 : docsdisp.length 
     docsdisp[i].rank = i 
return docsdisp 

sum(e.weight for each entity e in docmatches[i] 

sum(e.weight for each entity e in docdisp[i]) 

 
in  the  algorithm,  the  positive  changes  in  entity  weights  are 
identified  to  determine  which  terms  have  increased  in  importance 
and  should  be  used  to  identify  new  documents  to  add  to  the 
workspace.  step  two  computes  the  dot  product  between  the  entire 

backend  dataset  with  the  change  in  entity  weights  vector  (δw), 
which  results  in  a  single  number  for  each  document.  to  optimize 
performance, we discard all documents whose value is zero, because 
they do not contain any entities whose weights were increased within 
the past timestep. this results in the set of documents docmatches, 
which are candidates for addition to the workspace. the weights of 
entities contained in these candidate documents are summed using 
the current weighting scheme to obtain a score that reflects how well 
each document matches what the user has deemed important in the 
dataset  thus  far.  these  values  are  then  sorted  and  the  top  n 
documents are added to the list of documents included in the spatial 
workspace  at  timestep  t  and  removed  from  the  set  of  hidden 
documents (i.e. documents in the dataset not included in the spatial 
workspace). this results in the set of documents displayed at the next 
timestep, t+1. the algorithm returns this modified set of documents 
(which could be the same as the previous timestep if no documents 
are  chosen  to  be  added).  the  updated  rank  of  each  displayed 
document  is  stored  as  an  attribute  of  each  document.  this  rank 
information allows the system to apply appropriate visual encodings 
to  denote  how  closely  documents  match  the  user-imparted  entity 
importance values. 
 the documents returned from the information retrieval algorithm 
are then used as input, along with the current weighting scheme at 
timestep  t,  to  the  modified  force-directed  layout  to  determine  the 
two-dimensional layout of the data points for timestep t+1. 
we chose to select candidate documents first instead of applying 
the  weight  vector  across  all  documents  in  the  dataset  in  order  to 
provide  an  incremental  update  to  the  displayed  data.  if  we  had 
applied  w(t)  to  the  entire  dataset,  it  is  possible  that  the  displayed 
data would be much different in each iteration.  
similarly,  selecting  candidate  documents  and  eliminating  all 
documents which do not contain any of the newly increased entities 
allows  us  to  optimize  the  retrieval  process.  this  is  crucial  for 
maintaining a quick interaction-feedback loop. 
the  linear  nature  of  this  algorithm  prevents  it  from  scaling  to 
much larger document collections. more advanced retrieval methods, 
either  running  in  real  time  or  as  a  background  process,  could  be 
substituted in order to handle larger amounts of data. 
6  usage scenario 

(“blue 

activities 

“unexpected 

iguanodon”) 

concerning  wildlife 

to  demonstrate  starspire’s  functionality,  we  used  the  vast 
2007  challenge  dataset 
[17].  because 
starspire  is  currently  designed  to  operate  on  unstructured  text 
documents only, we omitted all images and spreadsheets from the 
dataset, resulting in approximately 1,500 text files. blog entries that 
were included in the data were converted into text files, one for each 
blog entry. preliminary entity extraction was done on the dataset.  
the  challenge  task  is  an  open-ended  sensemaking  task  to 
investigate 
law 
enforcement, endangered species issues, and ecoterrorism” [17]. we 
present the following usage scenario to demonstrate how starspire 
can leverage the msi technique. 
the  user  began  with  a  search  for  “chinchilla.”  this  was 
unsurprising,  because  the  dataset  contained  a  directory  titled 
“chinchillas.” she read through several documents, arranging them 
in  the  display  based  on  document  similarity.  the  user  then  began 
highlighting information regarding chinchillas, which branched into 
additional  endangered  species.  this  loosely  structured  analysis 
continued until the user read a document concerning a musical artist 
owning an extremely large number of exotic animals whose actions 
did not seem to match his words regarding animal conservation. the 
analyst denoted this as suspicious and began investigating it further. 
this investigation was driven through highlighting the artist’s name 
and  the  name  of  his  animal  sanctuary,  which  imported  many 
documents onto the display, some of which had a large node size. 
the analyst opened the largest new nodes first. 
[figure 8] shows the evolution of the user’s spatial organization 
schemas through the sensemaking task. clusters of documents were 

fig.  6.  multi-model  semantic  interaction  in  starspire:  document  relevance  feedback.  left:  the  user  explicitly  searches  for  documents 
containing the term “pok.” documents matching this search term are added to the display and arranged using a “near = similar” metaphor. 
middle:  the  user  selects  the  outlying  document,  opens  it,  then  closes  the  document  to  remove  it  from  the  workspace.  right:  the  system 
decreases the entity weights of the terms contained in the deleted document. the system updates the visual encodings to reflect this relevancy 
feedback and updates the display layout. 

the  choice  of  documents 

moved  around  the  screen  and  a  mixture  of  visual  encodings  and 
document  proximity  motivated 
to 
investigate next. furthermore, it can be seen that the user initially 
executed  two  searches  to  obtain  some  initial  documents,  but  then 
opted for other multi-scale semantic interaction techniques to obtain 
new documents (e.g. highlighting, linking documents – denoted by 
the purple bars, and annotating documents). document annotations 
were used to record hypotheses and insights (e.g. “r’bert is r’bear?” 
and “r’bear might have monkeypox”). in the later stages of analysis, 
searches were used primarily to label the space, serving as reminders 
of  which  documents  concerns  which  persons  or  topics.  however, 
they  were  also  used  to  ensure  that  important  information  or 
documents had not been overlooked. 
once  the  user  identified  suspicious  activity  regarding  a  large 
exotic animal reservation, it became apparent that many documents 
were  interconnected  via  several  subplots.  as  her  understanding  of 
the dataset evolved, so did her spatial representation. for example, 
two documents that were initially considered “not quite relevant, but 
interesting  enough  to  not  minimize”  concerning  an  outbreak  of  a 
disease were initially placed in the upper right hand corner of the 
display.  after  realizing  that  the  owner  of  the  large  exotic  animal 
sanctuary  had  contracted  the  same  disease,  she  moved  the  two 
documents down next to the exotic animal sanctuary documents. 
highlights,  document  annotations,  and  document  linking  were 
primarily used to obtain new documents in the workspace. searches 
were  executed  to  check  for  additional  information  on  important 

persons,  but  also  used  to  label  the  spatial  workspace.  after 
approximately  ninety  minutes  of  analyzing  the  data,  the  user 
concluded  that  she  had  a  sufficient  understanding  of  the  plot  and 
subplots in the data. 
the user’s results were compared with the known ground truth 
solution. the user correctly identified four out of five subplots in the 
data. the use added 145 documents to the workspace, which is 10% 
of the actual dataset. 47 documents were opened and 33 remained 
open at the conclusion of the sensemaking session. the user made 
eight  searches,  four  document  annotations,  and  21  highlights.  45 
documents were added through searches, whereas the remaining 100 
documents  were  added 
through  other  multi-scale  semantic 
interactions (e.g. highlight, annotate, document proximity). 
out of 26 documents relevant to the final solution, the user had 
added 18 of them to the workspace. six of these 18 documents were 
added through an explicit search, while twelve were added through 
implicit multi-scale semantic interactions. 13% (6/45) of documents 
added  through  explicit  searches  were  relevant  to  the  solution,  and 
12%  (12/100)  of  documents  added  through  implicit  searches  were 
relevant  to  the  solution.  therefore,  the  documents  that  originated 
from  multi-scale  semantic  interactions  were  similar  in  quality  to 
those that originated from explicit searches from the user. 
out of approximately 1,500 documents, 47 were read. thus, the 
analyst was able to construct 80% (four out of five subplots) of the 
solution while only reading 3.13% of the documents in the dataset. 
while  the  results  of  this  usage  scenario  appear  promising,  further 

fig.  7.  multi-model  semantic  interaction  in  starspire.  left:  the  user  explicitly  searches  for  documents  containing  the  word  “chinchilla.” 
documents  matching  this  search  term  are  added  to  the  display  and  arranged.  middle:  the  user  selects  a  document  to  read.  to  prevent 
occlusion, nodes are pushed aside but still maintain their relationships to other documents as much as possible. right: the user highlights the 
entity “peta.” eight new documents are retrieved and added to the display. documents rearrange due to the shift in weighting scheme – 
documents that contain “chinchilla” and “peta” (as well as other shared terms) are brought closer together in the middle, documents that 
contain only “chinchilla” are pushed to the top and left, and documents that only contain “peta” are pushed to the bottom and right. 

work is required to evaluate the performance of msi techniques as 
compared to existing si techniques. 
7  discussion 
7.1 

comparison to existing techniques 

most similar to our system prototype is forcespire [10], which 
implements  semantic 
the 
exploration  of  small  text  datasets.  however,  forcespire  operates 
using a single model (display layout), which hinders data analysis 

techniques  and  allows 

interaction 

fig. 8. organizational schema evolution throughout the use case. top: 
early  analysis  into  chinchillas  and  endangered  species  that  are 
growing 
in  popularity  with  a  seemingly  unrelated  outbreak  of 
monkeypox. middle: intermediate analysis that has linked chinchillas, 
the  monkeypox  outbreak,  and  a  rapper  keeping  a  suspicious  exotic 
animal  sanctuary.  bottom:  final  spatial 
the 
relationships  between  multiple  subplots  in  the  dataset,  along  with 
searches  that  have  been  executed  to  label  the  space  as  well  as 
hypotheses entered as annotations to documents. 

layout  showing 

in  starspire 

(several  seconds) 

compared to starspire. 
data loading and processing takes much longer in forcespire  
(several  minutes) 
than 
for 
moderately sized datasets on the order of 1,000 to 1,500 documents. 
most  of  this  delay  is  computing  the  force-directed  layout  and  the 
relationship between all documents. because starspire stores most 
of the data and only displays a smaller working set of documents, 
processing is much faster. for these same reasons, the interaction-
feedback loop is slower in forcespire. thus, the large scale model 
relieves much of the computational overhead from the small scale 
model. 
furthermore,  we  have  extended  the  visual  encodings  to  give  a 
richer  overview  of  the  displayed  documents  and  have  enabled  the 
users to provide positive and negative relevance feedback, which is 
reflected in a separate model. 
instead  of  comparing  these  tools  directly,  we  will  design  a 
comparative  user  study  using  starspire  with  msi  techniques 
enabled and with only si techniques enabled. users will be presented 
with  a  subset  of  the  data  on  the  screen,  alleviating  forcespire’s 
inability  to  display  more  than  a  few  hundred  documents  on  the 
screen. with the si-only condition, they will be required to explicitly 
request additional information through either through written queries 
or query-by-example (e.g. “show me more like this document”). this 
will allow for a comparison between the two techniques in regard to 
how information is retrieved and interacted with in the workspace. 
many  existing  systems  transform  user  interactions  into  model 
feedback to drive a spatial layout. dis-function [6] enables users to 
inject feedback into a spatialization model by repositioning points, 
allowing  the  system  to  incrementally  update  the  distance  function 
driving  the  low-dimensional  projection  of  high-dimensional  data. 
similarly,  visual  to  parametric  interaction  [20]  infers  analytic 
reasoning  from  users  moving  and/or  highlighting  data  points  in  a 
spatial  projection  of  high-dimensional  data.  these  interactions  are 
converted into parametric updates to change the spatial layout. work 
in  observation-level 
[14]  also  allows  document 
repositioning to drive an underlying spatialization model. however, 
all of these techniques are limited to using a single model, whereas 
our  technique  leverages  multiple  models  that  are  capable  of 
operating at different levels of data scale. 
document selection models 
7.2 

interaction 

the  model  used  here  is  only  one  example  of  many  possible 
models for document selection. we chose this approach in order to 
focus on the interactions within starspire and their mappings to the 
parameters  driving  the  retrieval  results.  however,  this  approach  is 
not  practical  for  extremely  large  datasets  with  large  numbers  of 
entities. the relevancy-based retrieval algorithm used in starspire 
runs in o(nm) time where n is the number of documents and m is the 
number  of  entities,  due  to  the  initial  search  process.  we  have 
optimized the algorithm to perform the sorting operations on a subset 
of  the  possible  documents  to  improve  this  runtime.  however,  the 
worst-case scenario is that all, or nearly all, documents in the dataset 
match  an  entity  that  has  been  upweighted  (e.g.  “the”).  even  in 
average and best case scenarios, this algorithm is not an ideal choice 
for scaling to extremely large datasets. parallelization is one option 
for  speeding  up  the  algorithm,  but  we  also  wish  to  consider 
alternative models for retrieval. 
future  implementations  of  multi-model  semantic  interaction 
should  consider  the  streaming  and  ever-growing  nature  of  data. 
accordingly, streaming or a mixture of dynamic and static models 
could  be  employed.  further  methods  of  handling  this  type  and 
amount of data could take a multi-threaded or parallel approach. 
in addition to optimizations for algorithm performance, different 
models  could  be  leveraged  at  the  display  layout  and  information 
retrieval  levels.  different  models  naturally  lend  themselves  to 
different  interactions.  for  example,  moving  data  points  or  pinning 
them as spatial landmarks could be interpreted by algorithms such as 
latent semantic indexing [9], principal component analysis [23], or 
multi-dimensional scaling [31], among others, to adjust the lower-

dimensional space of all of the documents to create a representation 
that better fits the user’s high-dimensional understanding of the data, 
thus producing subjectively better search results. 
7.3  multi-model visualization pipeline 

the  flexibility  of  generalized  multi-model  semantic  interaction 
enables researchers to explore many alternative models, methods of 
interpreting interactions, and mappings to analytical reasoning.  
there are multiple options for routing of interactions to models. 
for some interactions (e.g. changing data point distances), it may be 
appropriate to propagate the interaction to each underlying model up 
the  levels  of  scale.  however,  for  other  interactions  (e.g.  giving 
relevance feedback on a document), it may be more appropriate to 
send this feedback directly to a specific model. further complicating 
matters, the same interaction may have a different intent based on 
context. for example, a user may construct a cluster of documents. 
the clustered documents could be important and relevant to the user, 
or  the  user  could  be  grouping  them  in  order  to  filter  out  other 
irrelevant documents from the main display area. in this example, it 
is possible that this distinction could be captured by the proximity of 
the cluster to the periphery or center of the display.  investigating 
alternative  approaches  to  enabling  users  to  naturally  express  these 
intents  within  the  visual  interactions  remains  an  open  research 
question. 
it may be appropriate to maintain several models for each level of 
data  scale  and  dynamically  adapt  which  is  used  based  on  which 
model is able to best incorporate the user’s feedback. for example, 
having multiple display layout models allows the system to choose 
the one that converges the best or has the lowest deviation from the 
user’s  feedback.  we  plan  on  investigating  how  the  notion  of 
competing  models  changes  the  performance  of  the  system,  both 
qualitatively  and  quantitatively.  maintaining  multiple  models  for 
accomplishing a single task could result in a better approximation of 
the  high-dimensional  data,  and  we  will  investigate  methods  for 
providing visual feedback to inform users of these switches.  
due to the runtime of these algorithms and the time required to 
invert  the  models  to  compute  a  new  representation,  it  may  not  be 
practical  to  apply  interactive  feedback  to  every  model  at  each 
interaction. slower models could be told to invert and execute after a 
certain  number  of  interactions  and  instructed  to  run  in  the 
background. however, display-level models should be updated with 
each  interaction  in  order  to  provide  the  user  with  immediate 
feedback.  therefore,  whichever  models  are  chosen  to  drive  the 
spatial layout should execute quickly. 
7.4 

limitations 

starspire  is  currently  designed  for  text  analysis.  multimedia 
cannot currently be incorporated in the tool. future implementations 
could  overcome  this  limitation  by  using  metadata  and  user-
designated  tags  for  multimedia  files.  although  starspire  is  not 
equipped  to  handle  generic  high-dimensional  data,  multi-model 
semantic interaction techniques can be applied across data types. as 
multi-model semantic interaction is an extension of observation-level 
interaction for high-dimensional data [32], these systems (ex. [6, 20]) 
are suitable for extension to multi-model semantic interaction. 
we have applied multi-model semantic interaction techniques to 
sensemaking  tasks,  but  have  not  attempted  other  analytical  tasks, 
such  as  social  network  analysis.  additionally,  we  have  not  yet 
empirically evaluated if users understand and accept the mappings of 
interactions  to  model  feedback.  this  will  be  conducted  in  future 
work. 
starspire  has  currently  been  tested  on  over  10,000  text 
documents that had an entity extractor run on them, resulting in over 
20,000 distinct entities. total loading time was under one minute and 
interactions  could  be  completed  in  close  to  real  time  (queries  are 
typically executed in under three seconds). due to the nature of the 
retrieval model, the execution time depends largely on the size of the 
set of candidate documents, which need to be sorted and ranked, then 

compared against a relevance threshold. this problem is exacerbated 
by  document  collections  with  extremely  large  numbers  of  entities. 
therefore, broad searches tend to have slower response times. this 
limitation  could  be  overcome  by  implementing  more  sophisticated 
and  optimized  algorithms.  starspire  is  not  equipped  to  handle 
much larger datasets (e.g. on the order of 100,000 documents and 
higher).  moving  to  a  database  or  cloud-based  architecture  and 
implementing different algorithms could overcome this limitation. 
8  conclusion 

includes 

interaction 

future  work 

in  this  paper,  we  have  introduced  the  concept  of  multi-model 
semantic interaction, which harnesses user interactions to manipulate 
underlying  models.  we  have  presented  an  instantiation  of  this 
technique that operates across multiple levels of data scale. along 
with  this  technique,  we  introduced  a  generalized  visualization 
pipeline  for  semantic  interaction  using  multiple  models.  we  have 
shown  an  example 
implementation  of  multi-model  semantic 
interaction  techniques  through  the  visual  analytics  tool  prototype, 
starspire. using this prototype, we demonstrated the functionality 
of  multi-model  semantic 
techniques.  finally,  we 
concluded  with  a  discussion  of  multi-model  semantic  interaction 
techniques. 
we  plan  on  conducting  a  comparative  user  study  using 
starspire to observe the differences between explicitly constructed 
queries and the addition of implicitly constructed queries. this will 
serve  to  compare  multi-model  semantic  interaction  with  semantic 
interaction. the study will use one of the vast challenge datasets 
in order to quantitatively evaluate user performance. 
investigating  additional  multi-model 
semantic  interaction  techniques,  visual  encodings,  and  models. 
additionally,  we  plan  on  creating  a  visual  representation  of  the 
dataset to grant users an overview of the document content. we wish 
to practically apply multi-model semantic interaction techniques to 
much  larger  datasets,  including  streaming  data.  this  will  likely 
require 
implementing  additional  algorithms  and  cloud-based 
architectures. 
we  hope  that  multi-model  semantic  interaction  will  serve  as  a 
usable means of interacting with multiple models for data analytics. 
acknowledgments 
this work was supported in part by nsf grant iis-1218346. 
references 
[1]  andrews,  c.,  endert,  a.  and  north,  c.  space  to  think:  large  high-
resolution  displays  for  sensemaking  proceedings  of  the  sigchi 
conference on human factors in computing systems, acm, 2010, 55-64. 
[2]  andrews,  c.  and  north,  c.  analyst’s  workspace:  an  embodied 
sensemaking environment for large, high-resolution displays ieee 
visual analytics science and technology, ieee, 2012, 123-131. 

[3]  belew,  r.k.,  adaptive  information  retrieval:  using  a  connectionist 
representation  to  retrieve  and  learn  about  documents.  in  acm  sigir 
forum, (1989), acm, 11-20. 

[4]  benedikt, m., cyberspace: some proposals. in cyberspace, (1991), mit 

press, 119-224. 

[5]  bradel,  l.,  self,  j.z.,  endert,  a.,  hossain,  m.s.,  north,  c.  and 
ramakrishnan,  n.,  how  analysts  cognitively  ""connect  the  dots"".  in 
intelligence  and  security  informatics  (isi),  2013  ieee  international 
conference on, (2013), 24-26. 

[6]  brown,  e.t.,  liu,  j.,  brodley,  c.e.  and  chang,  r.,  dis-function: 
learning  distance  functions  interactively.  in  visual  analytics  science 
and technology (vast), 2012 ieee conference on, (2012), ieee, 83-
92. 

international acm sigir conference on research and development in 
information retrieval, (1991), acm, 262-269. 

[26]  maron, m.e. and kuhns, j.l. on relevance, probabilistic indexing and 
information retrieval. journal of the acm (jacm), 1960, 7 (3). 216-
244. 

[27]  olsen,  k.a.,  korfhage,  r.r.,  sochats,  k.m.,  spring,  m.b.  and 
williams,  j.g.  visualization  of  a  document  collection:  the  vibe 
system. information processing & management, 1993, 29 (1). 69-81. 

[28]  pirolli, p. and card, s. the sensemaking process and leverage points 
for analyst technology as identified through cognitive task analysis 
international conference on intelligence analysis, 2005. 

[29]  shipman  iii,  f.m.  and  marshall,  c.c.  formality  considered  harmful: 
experiences,  emerging  themes,  and  directions  on  the  use  of  formal 
representations in interactive systems. computer supported cooperative 
work (cscw), 1999, 8 (4). 333-352. 

[30]  stasko,  j.,  görg,  c.  and  liu,  z.  jigsaw:  supporting  investigative 
analysis  through  interactive  visualization.  information  visualization, 
2008, 7 (2). 118-132. 

[31]  torgerson,  w.  multidimensional  scaling:  i.  theory  and  method. 

psychometrika, 1952, 17 (4). 401-419. 

[32]  vogt, k., bradel, l., andrews, c., north, c., endert, a. and hutchings, 
d. co-located collaborative sensemaking on a large high-resolution 
display with multiple input devices conference on human-computer 
interaction, springer, 2011, 589-604. 

[33]  wise, j.a., thomas, j.j., pennock, k., lantrip, d., pottier, m., schur, 
a.  and  crow,  v.,  visualizing  the  non-visual:  spatial  analysis  and 
interaction  with  information  from  text  documents.  in  information 
visualization, 1995. proceedings., (1995), ieee, 51-58. 

[34]  wright, w., schroh, d., proulx, p., skaburskis, a. and cort, b., the 
sandbox  for  analysis:  concepts  and  methods.  in  proceedings  of  the 
sigchi conference on human factors in computing systems, (2006), 
acm, 801-810. 

[35]  yi,  j.s.,  melton,  r.,  stasko,  j.  and  jacko,  j.a.  dust  &  magnet: 
multivariate  information  visualization  using  a  magnet  metaphor. 
information visualization, 2005, 4 (4). 239-256. 

[7]  card,  s.k.  visualizing  retrieved  information:  a  survey.  computer 

graphics and applications, ieee, 1996, 16 (2). 63-67. 

[8]  choo, j. and park, h. customizing computational methods for visual 
analytics  with  big  data.  ieee  computer  graphics  and  applications, 
2013, 33 (4). 22-28. 

[9]  deerwester,  s.,  dumais,  s.t.,  furnas,  g.w.,  landauer,  t.k.  and 
harshman,  r.  indexing  by  latent  semantic  analysis.  journal  of  the 
american society for information science, 1990, 41 (6). 391-407. 

[10]  endert,  a.  semantic  interaction  for  visual  analytics:  inferring 
analytical reasoning for model steering, virginia polytechnic institute 
and state university, 2012. 

[11]  endert,  a.,  bradel,  l.  and  north,  c.  beyond  control  panels:  direct 
manipulation for visual analytics. computer graphics and applications, 
ieee, 2013, 33 (4). 6-13. 

[12]  endert, a., fiaux, p. and north, c. semantic interaction for visual text 
anayltics proceedings of the sigchi conference on human factors in 
computing systems, acm, 2012, 473-482. 

[13]  endert, a., fox, s., maiti, d., leman, s. and north, c. the semantics of 
clustering: analysis of user-generated spatializations of text documents 
proceedings  of  the  international  working  conference  on  advanced 
visual interfaces, acm, capri island, italy, 2012, 555-562. 

[14]  endert,  a.,  han,  c.,  maiti,  d.,  house,  l.,  leman,  s.  and  north,  c., 
observation-level interaction with statistical models for visual analytics. 
in  visual  analytics  science  and  technology  (vast),  2011  ieee 
conference on, (2011), ieee, 121-130. 

[15]  fruchterman,  t.m.  and  reingold,  e.m.  graph  drawing  by  force-
directed placement. software: practice and experience, 1991, 21 (11). 
1129-1164. 

[16]  green,  t.m.,  ribarsky,  w.  and  fisher,  b.  building  and  applying  a 
human cognition model for visual analytics. information visualization, 
2009, 8 (1). 1-13. 

[17]  grinstein, g., plaisant, c., laskowski, s., o'connell, t., scholtz, j. and 
whiting, m., vast 2007 contest-blue iguanodon. in ieee symposium 
on visual analytics science and technology, (2007), ieee, 231-232. 

[18]  hearst, m.a., tilebars: visualization of term distribution information in 
full text information access. in proceedings of the sigchi conference 
on human factors in computing systems, (1995), acm press/addison-
wesley publishing co., 59-66. 

[19]  hossain, m.s., andrews, c., ramakrishnan, n. and north, c., helping 
intelligence  analysts  make  connections.  in  scalable  integration  of 
analytics and visualization, (2011). 

[20]  hu,  x.,  bradel,  l.,  maiti,  d.,  house,  l.  and  north,  c.  semantics  of 
directly  manipulating  spatializations.  visualization  and  computer 
graphics, ieee transactions on, 2013, 19 (12). 2052-2059. 

[21]  i2. analyst notebook, www.i2.co.uk, 2007. 
[22]  jeong, d.h., ziemkiewicz, c., fisher, b., ribarsky, w. and chang, r., 
ipca:  an  interactive  system  for  pca‚äêbased  visual  analytics.  in 
computer graphics forum, (2009), wiley online library, 767-774. 

[23]  jolliffe, i.t. principal component analysis. springer-verlag new york, 

[24]  lamping, j., rao, r. and pirolli, p., a focus+ context technique based 
on hyperbolic geometry for visualizing large hierarchies. in proceedings 
of  the  sigchi  conference  on  human  factors  in  computing  systems, 
(1995), acm press/addison-wesley publishing co., 401-408. 

[25]  lin, x., soergel, d. and marchionini, g., a self-organizing semantic 
map  for  information  retrieval.  in  proceedings  of  the  14th  annual 

1986. 

",Multi-model semantic interaction for text analytics,"{""pos"":{""0"":1,""1"":2,""2"":3,""3"":4},""0"":{""0"":""search"",""1"":""added"",""2"":""searches*"",""3"":""modified*""},""2"":{""0"":""weight*"",""1"":""reduction*"",""2"":""length*"",""3"":""constant*""},""4"":{""0"":""visualization*"",""1"":""spatialization*"",""2"":""analytics*"",""3"":""dimensionality""},""1"":{""0"":""multi*"",""1"":""human"",""2"":""animal*"",""3"":""exotic*""},""3"":{""0"":""documents"",""1"":""models*"",""2"":""information"",""3"":""terms""}}",conferencePaper,http://ieeexplore.ieee.org/document/7042492/,self.user,False,"{""Unnamed: 0"":{""0"":0,""1"":1,""2"":2,""3"":3,""4"":4,""5"":5,""6"":6,""7"":7,""8"":8,""9"":9,""10"":10,""11"":11,""12"":12,""13"":13,""14"":14,""15"":15,""16"":16,""17"":17,""18"":18,""19"":19,""20"":20,""21"":21,""22"":22,""23"":23,""24"":24,""25"":25,""26"":26,""27"":27,""28"":28,""29"":29,""30"":30,""31"":31,""32"":33,""33"":34,""34"":35,""35"":36,""36"":37,""37"":38,""38"":39,""39"":40,""40"":41,""41"":42,""42"":43,""43"":44,""44"":45,""45"":46,""46"":47,""47"":48,""48"":49,""49"":50,""50"":51,""51"":52,""52"":53,""53"":54,""54"":55,""55"":56,""56"":57,""57"":58,""58"":59,""59"":60,""60"":62,""61"":63,""62"":64,""63"":65,""64"":66,""65"":67,""66"":68},""C"":{""0"":9.3683420506,""1"":6.7714604384,""2"":8.2739043137,""3"":6.1699977263,""4"":12.2194066119,""5"":14.9687258375,""6"":5.6998674018,""7"":6.6715821979,""8"":6.7642167346,""9"":6.5677556754,""10"":6.5996080475,""11"":6.0524492255,""12"":6.6837989664,""13"":5.999839367,""14"":13.0948776567,""15"":9.9466910742,""16"":25.8034484167,""17"":10.2710679979,""18"":7.7413806884,""19"":20.6434058174,""20"":12.4771746792,""21"":6.401740121,""22"":20.5825001448,""23"":11.055433094,""24"":5.2022314726,""25"":8.3064955628,""26"":16.839377112,""27"":11.7445695188,""28"":5.2311307638,""29"":9.9341492755,""30"":8.2052800073,""31"":6.0514030324,""32"":7.165090443,""33"":9.6159423065,""34"":6.7592648265,""35"":6.6421386411,""36"":5.4028469428,""37"":4.8059657891,""38"":5.3090436983,""39"":13.5332029799,""40"":11.7269360947,""41"":10.6587403469,""42"":6.0133214027,""43"":11.5238679106,""44"":10.0301087886,""45"":10.1429565523,""46"":7.7734537339,""47"":5.0484226527,""48"":7.0512339865,""49"":6.2214376599,""50"":7.0061310867,""51"":6.2114353917,""52"":6.2114353917,""53"":6.7434412298,""54"":6.749824881,""55"":7.431461881,""56"":5.3798487603,""57"":5.7325721666,""58"":6.3979163053,""59"":6.6083884937,""60"":6.6225592332,""61"":4.8201141065,""62"":4.9740510843,""63"":5.2065676675,""64"":5.1374560228,""65"":4.9011978809,""66"":5.5405730254},""count"":{""0"":286,""1"":220,""2"":178,""3"":166,""4"":120,""5"":114,""6"":108,""7"":88,""8"":74,""9"":58,""10"":52,""11"":48,""12"":46,""13"":46,""14"":46,""15"":44,""16"":44,""17"":40,""18"":38,""19"":38,""20"":34,""21"":32,""22"":28,""23"":26,""24"":26,""25"":26,""26"":24,""27"":22,""28"":22,""29"":20,""30"":20,""31"":20,""32"":18,""33"":18,""34"":16,""35"":16,""36"":16,""37"":16,""38"":16,""39"":16,""40"":16,""41"":16,""42"":14,""43"":14,""44"":12,""45"":12,""46"":12,""47"":10,""48"":10,""49"":10,""50"":10,""51"":10,""52"":10,""53"":10,""54"":10,""55"":10,""56"":8,""57"":8,""58"":8,""59"":8,""60"":8,""61"":8,""62"":8,""63"":8,""64"":8,""65"":8,""66"":8},""sigma_nor"":{""0"":2.4658431622,""1"":2.3130008268,""2"":2.5511085178,""3"":2.3380876775,""4"":3.2632900523,""5"":3.680375947,""6"":2.4225404492,""7"":2.6472293683,""8"":2.7415611138,""9"":2.8246480521,""10"":2.8853777335,""11"":2.815800754,""12"":2.9659234812,""13"":2.8251043338,""14"":4.2858883381,""15"":3.6739832026,""16"":7.0,""17"":3.8237031173,""18"":3.3046521555,""19"":6.1794542825,""20"":4.48054269,""21"":3.0970612545,""22"":6.7339034162,""23"":4.4121047952,""24"":2.8986033455,""25"":3.7012936515,""26"":6.0325897497,""27"":4.7680695812,""28"":2.9770102469,""29"":4.354698267,""30"":3.8629337141,""31"":3.2502787453,""32"":3.6307647882,""33"":4.3536407994,""34"":3.5761620645,""35"":3.5402401642,""36"":3.1601568153,""37"":2.9770969367,""38"":3.1313879214,""39"":5.6536883665,""40"":5.09971712,""41"":4.7721078754,""42"":3.4088390015,""43"":5.1717970632,""44"":4.8208822669,""45"":4.8586799736,""46"":4.0650286903,""47"":3.2066883218,""48"":3.9119053878,""49"":3.6197228337,""50"":3.8960240444,""51"":3.6162008993,""52"":3.6162008993,""53"":3.8035273788,""54"":3.8057751491,""55"":4.0457887925,""56"":3.3826193058,""57"":3.5137589456,""58"":3.7611283833,""59"":3.8393801989,""60"":3.8446487625,""61"":3.1745145995,""62"":3.2317470924,""63"":3.3181948313,""64"":3.2924996945,""65"":3.204660875,""66"":3.4423752558},""vocab_index"":{""0"":0,""1"":1,""2"":3,""3"":5,""4"":6,""5"":7,""6"":8,""7"":10,""8"":14,""9"":22,""10"":24,""11"":29,""12"":30,""13"":31,""14"":35,""15"":36,""16"":37,""17"":40,""18"":42,""19"":43,""20"":47,""21"":50,""22"":58,""23"":59,""24"":60,""25"":64,""26"":70,""27"":73,""28"":77,""29"":80,""30"":83,""31"":86,""32"":92,""33"":103,""34"":104,""35"":109,""36"":114,""37"":117,""38"":119,""39"":121,""40"":122,""41"":123,""42"":140,""43"":141,""44"":164,""45"":165,""46"":166,""47"":192,""48"":196,""49"":202,""50"":203,""51"":205,""52"":206,""53"":207,""54"":208,""55"":209,""56"":262,""57"":266,""58"":267,""59"":268,""60"":271,""61"":274,""62"":278,""63"":279,""64"":280,""65"":282,""66"":283},""word"":{""0"":""documents"",""1"":""data"",""2"":""model"",""3"":""semantic"",""4"":""document"",""5"":""models"",""6"":""information"",""7"":""multi"",""8"":""starspire"",""9"":""terms"",""10"":""techniques"",""11"":""search"",""12"":""users"",""13"":""visualization"",""14"":""node"",""15"":""spatialization"",""16"":""weight"",""17"":""analytics"",""18"":""entity"",""19"":""added"",""20"":""nodes"",""21"":""weights"",""22"":""ieee"",""23"":""north"",""24"":""analysts"",""25"":""searches"",""26"":""conference"",""27"":""synthesis"",""28"":""systems"",""29"":""foraging"",""30"":""dimensionality"",""31"":""values"",""32"":""reduction"",""33"":""timestep"",""34"":""human"",""35"":""computer"",""36"":""increases"",""37"":""modified"",""38"":""read"",""39"":""docsdisp"",""40"":""endert"",""41"":""proceedings"",""42"":""matching"",""43"":""docmatches"",""44"":""docshid"",""45"":""length"",""46"":""animal"",""47"":""determined"",""48"":""color"",""49"":""exotic"",""50"":""subplots"",""51"":""sigchi"",""52"":""factors"",""53"":""science"",""54"":""technology"",""55"":""graphics"",""56"":""labelled"",""57"":""resizing"",""58"":""retrieves"",""59"":""constant"",""60"":""docsranked"",""61"":""chinchilla"",""62"":""middle"",""63"":""right"",""64"":""annotations"",""65"":""andrews"",""66"":""international""},""threshold"":{""0"":4.7615466666,""1"":4.7615466666,""2"":4.7615466666,""3"":4.7615466666,""4"":4.7615466666,""5"":4.7615466666,""6"":4.7615466666,""7"":4.7615466666,""8"":4.7615466666,""9"":4.7615466666,""10"":4.7615466666,""11"":4.7615466666,""12"":4.7615466666,""13"":4.7615466666,""14"":4.7615466666,""15"":4.7615466666,""16"":4.7615466666,""17"":4.7615466666,""18"":4.7615466666,""19"":4.7615466666,""20"":4.7615466666,""21"":4.7615466666,""22"":4.7615466666,""23"":4.7615466666,""24"":4.7615466666,""25"":4.7615466666,""26"":4.7615466666,""27"":4.7615466666,""28"":4.7615466666,""29"":4.7615466666,""30"":4.7615466666,""31"":4.7615466666,""32"":4.7615466666,""33"":4.7615466666,""34"":4.7615466666,""35"":4.7615466666,""36"":4.7615466666,""37"":4.7615466666,""38"":4.7615466666,""39"":4.7615466666,""40"":4.7615466666,""41"":4.7615466666,""42"":4.7615466666,""43"":4.7615466666,""44"":4.7615466666,""45"":4.7615466666,""46"":4.7615466666,""47"":4.7615466666,""48"":4.7615466666,""49"":4.7615466666,""50"":4.7615466666,""51"":4.7615466666,""52"":4.7615466666,""53"":4.7615466666,""54"":4.7615466666,""55"":4.7615466666,""56"":4.7615466666,""57"":4.7615466666,""58"":4.7615466666,""59"":4.7615466666,""60"":4.7615466666,""61"":4.7615466666,""62"":4.7615466666,""63"":4.7615466666,""64"":4.7615466666,""65"":4.7615466666,""66"":4.7615466666},""vector"":{""0"":""[-6.4374657  4.821447  -1.8861451 -6.8558965 -3.8518262  2.1810358\n -6.4220276 -6.998512  -0.91681   -1.0500344]"",""1"":""[-6.3142796   4.81835    -2.3721793  -7.0667834  -3.8340306   2.598635\n -6.233884   -6.6162586  -1.1514118  -0.45443532]"",""2"":""[-7.195566    4.8567863  -2.6595616  -6.577208   -3.866307    2.806714\n -5.779187   -6.743504   -1.4389039  -0.73453057]"",""3"":""[-6.818041    4.6760817  -2.026215   -6.676916   -4.1322093   2.4765325\n -6.5734468  -6.2442617  -0.4868601  -0.78111136]"",""4"":""[-6.530409    4.780406   -1.908582   -6.8154316  -4.050297    2.2332015\n -6.3882217  -6.839903   -0.59556913 -1.0735656 ]"",""5"":""[-6.9860973   4.9913244  -2.451929   -6.8275223  -3.6503751   2.8552082\n -5.819517   -6.858279   -1.7744796  -0.48096696]"",""6"":""[-6.27929     4.909438   -2.1288097  -7.0690465  -3.7488308   2.4364233\n -6.188902   -6.9504337  -1.3568261  -0.71271354]"",""7"":""[-7.9230037  4.53668   -2.2080724 -6.212982  -3.9910119  2.622366\n -5.6039534 -6.262812  -0.7351593 -0.8384604]"",""8"":""[-7.166679    5.060097   -1.6283273  -7.03461    -4.4737215   3.1101966\n -6.8217826  -6.090286   -0.37800854  0.17948097]"",""9"":""[-7.009068    4.823468   -2.2024758  -6.523976   -3.2239025   2.435799\n -6.0354137  -6.844697   -1.6366808  -0.80545235]"",""10"":""[-6.5966454  5.063068  -2.107604  -6.843733  -3.375593   2.6346102\n -5.996655  -6.76803   -1.6100118 -0.4344753]"",""11"":""[-7.710999    4.4367948  -1.7257785  -6.3008065  -3.8546705   2.304742\n -6.4663935  -5.8553824   0.27307463 -0.55604494]"",""12"":""[-6.7581954   5.0896835  -2.1961057  -7.199467   -3.9588182   2.808874\n -6.135609   -7.224998   -1.7992347  -0.55517185]"",""13"":""[-6.362227    5.1712008  -1.9326395  -7.2815967  -4.002899    2.957937\n -6.3255363  -6.361278   -1.0069878   0.11483142]"",""14"":""[-6.714324   5.133518  -1.8445336 -7.306399  -4.881027   3.0235271\n -6.6664824 -6.487142  -0.5273408 -0.2716332]"",""15"":""[-6.5921354   5.1893015  -1.7044693  -7.246024   -4.1380324   3.0496736\n -6.610163   -6.2116814  -0.7702698   0.26820928]"",""16"":""[-7.781576    4.4718227  -2.4841907  -6.2291093  -3.45347     2.766628\n -6.240371   -6.14638    -1.3323246  -0.49733382]"",""17"":""[-6.371862    5.06012    -2.1906893  -7.3126364  -4.071659    2.8096755\n -6.0032287  -6.7017965  -1.0843037  -0.13898285]"",""18"":""[-6.593899   4.9395165 -2.2596278 -6.8716354 -3.9511979  2.4785795\n -5.880177  -7.0403457 -1.2744049 -1.0018622]"",""19"":""[-8.470366    4.0645967  -1.7758379  -5.617187   -3.0762653   2.076376\n -6.4240723  -5.7371087   0.09686673 -0.73931885]"",""20"":""[-6.6434407   5.083967   -1.9371277  -7.255277   -4.6471252   2.9617448\n -6.7452493  -6.5670285  -0.8281495  -0.37619287]"",""21"":""[-7.455046    4.597913   -2.4072125  -6.4320006  -3.4719765   2.770996\n -6.3650837  -6.2936907  -1.4670168  -0.46630558]"",""22"":""[-6.9114847   5.160666   -1.4225626  -7.258004   -4.793649    2.8511753\n -6.5435953  -6.7911587  -0.23317678 -0.30062696]"",""23"":""[-8.013586    4.2885056  -2.2967377  -6.1407046  -3.6764438   2.618888\n -5.701621   -5.939711   -0.6262491  -0.64973754]"",""24"":""[-6.720311    5.035049   -2.2805626  -7.136905   -3.840177    2.7707067\n -6.025045   -7.1054025  -1.7372127  -0.45261958]"",""25"":""[-7.6777      4.5305767  -1.5927197  -6.2706065  -3.6083732   2.2149827\n -6.44006    -6.0484004   0.19102009 -0.43791914]"",""26"":""[-6.9444847   4.8780503  -1.7526742  -6.922331   -4.0910664   2.3364677\n -5.9571886  -7.130889   -0.78500247 -0.7982197 ]"",""27"":""[-6.396211    5.099335   -1.9813186  -7.083144   -3.6619797   2.7775846\n -6.2791767  -6.508206   -1.2773272  -0.10752036]"",""28"":""[-6.753053   5.0001855 -2.2896163 -6.8410153 -3.6327257  2.6044908\n -5.8381352 -7.079287  -1.7435919 -0.8011942]"",""29"":""[-7.5311685   4.7379575  -2.0326219  -6.6770854  -4.421367    2.8478374\n -6.451189   -6.097641   -0.35804567 -0.4044292 ]"",""30"":""[-6.6846385   5.1350017  -1.7583013  -7.1807837  -4.104279    3.108382\n -6.794418   -6.0771847  -0.85357016  0.3032885 ]"",""31"":""[-7.033482   4.707854  -2.5345607 -6.526181  -3.3446798  2.6325915\n -5.992936  -6.5897484 -1.6082964 -0.6060053]"",""32"":""[-7.77874    4.532744  -2.1258926 -6.045745  -3.2417758  2.5818691\n -6.538401  -6.1303473 -1.0667791 -0.4820725]"",""33"":""[-6.788199    5.152031   -1.7170998  -7.254729   -4.595795    3.108953\n -6.8298635  -6.2863274  -0.59213156  0.05213703]"",""34"":""[-7.5742     4.6523643 -2.5423868 -6.5692067 -4.1528487  2.8389306\n -5.4861245 -6.384258  -0.9289189 -0.6677869]"",""35"":""[-6.8946624   5.091528   -2.3367934  -7.1220527  -4.2922287   3.0391781\n -5.6270285  -6.6280694  -1.1112205  -0.30257332]"",""36"":""[-8.125656    4.3975973  -1.9830704  -5.7934527  -3.1201127   2.4277158\n -6.581808   -6.101235   -0.72284293 -0.5496611 ]"",""37"":""[-8.561414    4.1820107  -1.9595557  -5.5593605  -3.1194282   2.3422146\n -6.2715545  -5.9289346  -0.16301757 -0.5969831 ]"",""38"":""[-8.484816    4.1945486  -1.7146456  -5.5803733  -3.1809988   2.0795317\n -6.455651   -5.9765573   0.23333374 -0.77421963]"",""39"":""[-6.7312126   5.0629935  -1.5280389  -7.1911836  -4.576371    2.6097775\n -6.4844527  -7.0187187  -0.43473557 -0.6490427 ]"",""40"":""[-7.362592    4.9926343  -1.5716101  -6.9310613  -4.556894    2.983865\n -6.6771646  -6.2515726  -0.19424912 -0.02108547]"",""41"":""[-7.0058837  4.7510705 -1.7313184 -6.730614  -3.7963507  2.167329\n -6.2032638 -7.0988064 -0.9297873 -0.9220548]"",""42"":""[-7.9652057   4.4462576  -1.7860647  -6.11144    -3.5877373   2.4575694\n -6.292672   -5.8491035   0.02507896 -0.33621824]"",""43"":""[-7.8811274  4.6619067 -1.5182658 -6.254732  -3.7562358  2.5673573\n -6.406403  -6.066456   0.0849442 -0.120459 ]"",""44"":""[-6.6253095   5.1408176  -1.4946202  -7.231145   -4.4126987   2.6081786\n -6.4838347  -7.064095   -0.57128686 -0.5315763 ]"",""45"":""[-7.879501   4.4731183 -2.3176577 -6.2687335 -3.5928252  2.6718848\n -6.2847795 -6.29623   -1.0651622 -0.5707787]"",""46"":""[-7.7067494   4.742351   -2.437989   -6.642841   -4.360891    2.9584506\n -5.722636   -6.4497666  -0.89031434 -0.56221855]"",""47"":""[-8.573214    4.209102   -2.0579307  -5.592856   -3.224673    2.4880183\n -6.10802    -5.973558   -0.23083091 -0.5147753 ]"",""48"":""[-7.315135    4.7630324  -2.2433515  -6.7596045  -3.8455575   2.9177423\n -5.834098   -6.146347   -0.75562024 -0.0689356 ]"",""49"":""[-7.9073176   4.6631317  -2.336793   -6.4574485  -4.275737    2.8145154\n -5.502726   -6.51805    -0.82149255 -0.70831203]"",""50"":""[-6.88441    4.82504   -2.0356247 -6.7254267 -3.5310357  2.428562\n -6.389445  -6.990401  -1.5555182 -0.7596654]"",""51"":""[-6.9363246   5.1747274  -1.3513995  -7.178558   -4.5306826   2.7666688\n -6.5569596  -6.83935    -0.36389685 -0.17385697]"",""52"":""[-6.950195   4.873339  -2.3415883 -6.6784954 -3.3815887  2.6216984\n -6.080297  -6.9040494 -1.8338629 -0.6375557]"",""53"":""[-6.9591603   4.9547524  -2.2084143  -7.0197244  -4.2359724   2.8251867\n -5.46838    -6.6191845  -0.87668943 -0.42649737]"",""54"":""[-6.781963    5.0585537  -2.256641   -7.016909   -4.0157046   2.8228161\n -5.5766044  -6.7436275  -1.1864703  -0.42060584]"",""55"":""[-6.7543745  5.0614347 -2.1704078 -7.1310763 -4.082761   3.0397894\n -5.972562  -6.366522  -1.007345  -0.0308328]"",""56"":""[-8.597434    4.1148124  -1.8927253  -5.544241   -3.1608272   2.2480347\n -6.264792   -5.871556    0.05198025 -0.68832546]"",""57"":""[-6.8118668   5.0641446  -2.0447364  -7.0951624  -4.150555    3.1460485\n -6.5156364  -6.1309423  -0.92691123  0.14198422]"",""58"":""[-8.086118    4.3398356  -1.682028   -5.9548154  -3.4448936   2.2121336\n -6.4636207  -5.9122987   0.19259925 -0.5476532 ]"",""59"":""[-8.097246   4.4120884 -2.1949832 -5.882328  -3.27097    2.5483701\n -6.337781  -6.200278  -0.9522002 -0.6175769]"",""60"":""[-7.9483080e+00  4.8131452e+00 -1.3833264e+00 -6.3278179e+00\n -3.9454436e+00  2.7733705e+00 -6.5016856e+00 -6.2605333e+00\n -5.2363701e-02  1.0195056e-03]"",""61"":""[-7.6238966   4.8861732  -2.2017179  -6.8035083  -4.526441    3.0723264\n -5.9694653  -6.4659243  -0.73194325 -0.35657594]"",""62"":""[-7.969404    4.434346   -2.2157238  -6.1367846  -3.5502067   2.6097872\n -5.740363   -5.9890094  -0.69223565 -0.50544614]"",""63"":""[-8.236504    4.3093414  -2.195194   -5.948168   -3.4789748   2.5950146\n -5.7815294  -5.9259286  -0.4271601  -0.51924604]"",""64"":""[-6.4960947   4.744181   -1.9375046  -6.815309   -4.0630836   2.3351686\n -6.6691017  -6.544547   -0.6320937  -0.89513093]"",""65"":""[-7.2185082   4.976782   -1.6436864  -7.052631   -4.8120713   2.8056996\n -6.2118206  -6.718168   -0.18194105 -0.53113854]"",""66"":""[-7.7641582   4.562696   -2.3357859  -6.4095035  -4.112007    2.6884165\n -5.46724    -6.385421   -0.77871    -0.76770055]""},""topic"":{""0"":3,""1"":-1,""2"":-1,""3"":-1,""4"":-1,""5"":3,""6"":3,""7"":1,""8"":-1,""9"":3,""10"":3,""11"":0,""12"":-1,""13"":4,""14"":-1,""15"":4,""16"":2,""17"":4,""18"":-1,""19"":0,""20"":-1,""21"":-1,""22"":-1,""23"":-1,""24"":3,""25"":0,""26"":-1,""27"":3,""28"":3,""29"":-1,""30"":4,""31"":3,""32"":2,""33"":4,""34"":1,""35"":-1,""36"":-1,""37"":0,""38"":0,""39"":-1,""40"":-1,""41"":-1,""42"":0,""43"":0,""44"":-1,""45"":2,""46"":1,""47"":0,""48"":-1,""49"":1,""50"":3,""51"":-1,""52"":3,""53"":-1,""54"":4,""55"":4,""56"":0,""57"":4,""58"":0,""59"":2,""60"":-1,""61"":-1,""62"":1,""63"":-1,""64"":-1,""65"":-1,""66"":1},""exemplar"":{""0"":null,""1"":null,""2"":null,""3"":null,""4"":null,""5"":""*"",""6"":null,""7"":""*"",""8"":null,""9"":null,""10"":null,""11"":null,""12"":null,""13"":""*"",""14"":null,""15"":""*"",""16"":""*"",""17"":""*"",""18"":null,""19"":null,""20"":null,""21"":null,""22"":null,""23"":null,""24"":null,""25"":""*"",""26"":null,""27"":null,""28"":""*"",""29"":null,""30"":null,""31"":""*"",""32"":""*"",""33"":null,""34"":null,""35"":null,""36"":null,""37"":""*"",""38"":""*"",""39"":null,""40"":null,""41"":null,""42"":""*"",""43"":null,""44"":null,""45"":""*"",""46"":""*"",""47"":null,""48"":null,""49"":""*"",""50"":null,""51"":null,""52"":""*"",""53"":null,""54"":null,""55"":""*"",""56"":""*"",""57"":""*"",""58"":""*"",""59"":""*"",""60"":null,""61"":null,""62"":null,""63"":null,""64"":null,""65"":null,""66"":""*""},""word*"":{""0"":""documents"",""1"":""data"",""2"":""model"",""3"":""semantic"",""4"":""document"",""5"":""models*"",""6"":""information"",""7"":""multi*"",""8"":""starspire"",""9"":""terms"",""10"":""techniques"",""11"":""search"",""12"":""users"",""13"":""visualization*"",""14"":""node"",""15"":""spatialization*"",""16"":""weight*"",""17"":""analytics*"",""18"":""entity"",""19"":""added"",""20"":""nodes"",""21"":""weights"",""22"":""ieee"",""23"":""north"",""24"":""analysts"",""25"":""searches*"",""26"":""conference"",""27"":""synthesis"",""28"":""systems*"",""29"":""foraging"",""30"":""dimensionality"",""31"":""values*"",""32"":""reduction*"",""33"":""timestep"",""34"":""human"",""35"":""computer"",""36"":""increases"",""37"":""modified*"",""38"":""read*"",""39"":""docsdisp"",""40"":""endert"",""41"":""proceedings"",""42"":""matching*"",""43"":""docmatches"",""44"":""docshid"",""45"":""length*"",""46"":""animal*"",""47"":""determined"",""48"":""color"",""49"":""exotic*"",""50"":""subplots"",""51"":""sigchi"",""52"":""factors*"",""53"":""science"",""54"":""technology"",""55"":""graphics*"",""56"":""labelled*"",""57"":""resizing*"",""58"":""retrieves*"",""59"":""constant*"",""60"":""docsranked"",""61"":""chinchilla"",""62"":""middle"",""63"":""right"",""64"":""annotations"",""65"":""andrews"",""66"":""international*""},""pos"":{""0"":1,""1"":1,""2"":2,""3"":3,""4"":4,""5"":2,""6"":3,""7"":1,""8"":5,""9"":4,""10"":5,""11"":1,""12"":6,""13"":1,""14"":7,""15"":2,""16"":1,""17"":3,""18"":8,""19"":2,""20"":9,""21"":10,""22"":11,""23"":12,""24"":6,""25"":3,""26"":13,""27"":7,""28"":8,""29"":14,""30"":4,""31"":9,""32"":2,""33"":5,""34"":2,""35"":15,""36"":16,""37"":4,""38"":5,""39"":17,""40"":18,""41"":19,""42"":6,""43"":7,""44"":20,""45"":3,""46"":3,""47"":8,""48"":21,""49"":4,""50"":10,""51"":22,""52"":11,""53"":23,""54"":6,""55"":7,""56"":9,""57"":8,""58"":10,""59"":4,""60"":24,""61"":25,""62"":5,""63"":26,""64"":27,""65"":28,""66"":6},""x2D"":{""0"":6.5324087143,""1"":5.8671565056,""2"":4.6861581802,""3"":7.1579771042,""4"":6.9129056931,""5"":5.0143222809,""6"":6.03160429,""7"":2.7041945457,""8"":6.7067966461,""9"":5.3612537384,""10"":5.4678282738,""11"":1.141379714,""12"":5.2367696762,""13"":5.9162793159,""14"":7.2691779137,""15"":6.2957649231,""16"":2.5063836575,""17"":5.5162200928,""18"":5.8813810349,""19"":0.6900542378,""20"":6.9961857796,""21"":2.881499052,""22"":7.5715479851,""23"":2.0490460396,""24"":5.1798501015,""25"":1.2472673655,""26"":6.9007029533,""27"":5.7122707367,""28"":5.3573074341,""29"":4.5874099731,""30"":6.4733247757,""31"":4.9833378792,""32"":2.2953197956,""33"":6.9428348541,""34"":3.2644879818,""35"":4.8018989563,""36"":1.740244627,""37"":1.029650569,""38"":0.9104721546,""39"":7.7962341309,""40"":6.8944277763,""41"":6.7247166634,""42"":1.4403041601,""43"":1.4789327383,""44"":7.5599212646,""45"":2.3600594997,""46"":3.5575730801,""47"":1.1446955204,""48"":4.1306600571,""49"":3.2046909332,""50"":5.829659462,""51"":7.4643893242,""52"":5.3155941963,""53"":4.5706262589,""54"":5.0731344223,""55"":5.2099204063,""56"":0.6705600619,""57"":6.0178451538,""58"":1.0932801962,""59"":2.0802733898,""60"":1.7348723412,""61"":3.8745250702,""62"":1.8104227781,""63"":1.5769572258,""64"":7.0247564316,""65"":7.6288318634,""66"":3.0234143734},""y2D"":{""0"":-0.6172815561,""1"":-0.7826533318,""2"":0.1750703454,""3"":-1.0229946375,""4"":-0.684981823,""5"":0.3976996839,""6"":-0.250377655,""7"":-1.5338840485,""8"":-2.9085202217,""9"":0.9355752468,""10"":0.2536204457,""11"":1.267180562,""12"":-0.2420564145,""13"":-2.0231442451,""14"":-2.638977766,""15"":-2.4225997925,""16"":-0.5512923598,""17"":-1.562323451,""18"":-0.0762753338,""19"":0.4542037249,""20"":-2.3598539829,""21"":-0.3023218215,""22"":-2.2881002426,""23"":-1.0170558691,""24"":0.0105416635,""25"":1.0949395895,""26"":-0.3072910309,""27"":-1.3587071896,""28"":0.5188546777,""29"":-2.6583142281,""30"":-2.6638221741,""31"":0.7408979535,""32"":-0.3088805079,""33"":-2.6818535328,""34"":-1.9193643332,""35"":-1.4284963608,""36"":0.073849909,""37"":0.1606327444,""38"":0.316622138,""39"":-1.7646169662,""40"":-2.8595516682,""41"":-0.244220376,""42"":0.8889681101,""43"":1.2275247574,""44"":-1.7301299572,""45"":-0.7929307222,""46"":-1.9824379683,""47"":0.0152044892,""48"":-2.0734026432,""49"":-1.8787491322,""50"":0.4222971797,""51"":-2.180331707,""52"":0.7064602375,""53"":-1.6103817225,""54"":-1.0364096165,""55"":-1.9591414928,""56"":0.5208120942,""57"":-2.4570627213,""58"":0.9166502953,""59"":-0.1875252277,""60"":1.3783123493,""61"":-2.3083479404,""62"":-0.6724330187,""63"":-0.325101465,""64"":-0.817666173,""65"":-2.4051582813,""66"":-1.7605229616}}",2014
HDQVL9W2,False,"[0.2297431, 0.48465502, 0.09407979, -0.18796375, 0.38374713, 0.24440472, -0.27863914, 0.119430915, -0.6978076, -0.5337612, -0.038864844, -0.25974858, -0.29717177, 0.24155529, -0.080871485, 0.93048906, -0.18169846, 0.11296689, -0.34670186, 0.21610431, 0.0130633805, 0.45664364, -0.15198041, 0.42064342, 0.47688815, -0.27497342, -0.088223025, -0.042578887, -0.48245734, -0.020199446, 0.059320364, 0.74176055, 0.07781845, -0.23852655, 0.16948521, 0.15022436, -0.40588295, -0.29947007, 0.027678812, 0.4059225, -0.42098778, -0.26707608, 0.08822036, 0.07156364, 0.102008305, -0.21158779, -0.5309333, -0.32550257, -0.19266082, 0.024167435, -1.5875021, 0.15644117, -0.09072879, 0.18562458, -0.4219089, 0.7923161, 0.029684337, -0.76217926, 0.29547358, 0.08772425, -0.12777872, -0.17438954, -0.13046648, -0.050941505, 0.44727853, -0.04960396, 0.34596115, -0.15762603, -0.50363106, 0.18516678, -0.27082503, 0.14195469, -0.49457833, 0.3478907, -0.67924803, 0.26402977, 0.03595389, 0.38455918, -0.17765684, -0.23440476, -0.6605908, 0.27806863, 0.14501461, -0.27170712, 0.5224064, 0.41353554, -0.19181198, 0.4730395, -0.48289186, 0.25918406, -0.10840662, 0.07009192, -0.27431375, -0.0040521957, 1.0893698, -0.18716401, -0.6919419, 0.22752355, -0.16684918, 0.09564566, ...]",{},"[-0.13792717, -0.1542536, 0.2689855, 0.00012489886, 0.86614466, 0.15649903, -0.22890344, 0.30776143, -0.48763385, -0.39073884, 0.015639603, -0.14518438, -0.37724522, 0.29017967, -0.014664136, 1.0880275, -0.13049494, 0.098255984, 0.05677722, -0.07522997, -0.10851975, 0.1438006, 0.14098297, 0.46580166, 0.27161533, -0.2005684, -0.22487545, 0.08355253, -0.031930298, 0.25023806, 0.11125807, 0.33515167, -0.14931913, -0.31492782, 0.3002578, -0.4061598, -0.33003727, 0.42085624, 0.07238804, 0.60458666, -0.68286985, -0.6612165, -0.13294572, -0.35486102, 0.28305948, 0.118503846, -0.00728244, -0.6091899, -0.08737531, -0.3312801, -1.2810842, -0.15000962, -0.464782, -0.20907076, 0.06517534, 0.3368823, 0.061714552, -1.0129648, 0.44440255, 0.0015941882, -0.22724745, 0.08020943, -0.6218185, 0.25831997, 0.0689414, -0.5105669, -0.03320881, 0.06075667, -0.54470015, 0.42940482, 0.10802403, 0.07583344, -0.34916106, 0.120327175, -0.19895214, 0.11192665, -0.5704056, 0.3921736, -0.05824156, -0.347646, -0.17234027, 0.4989814, 0.40495887, -0.002870894, 0.36379206, 0.7647433, -0.12865314, 0.5082871, -0.08318611, 0.43325564, -0.46642348, 0.18096474, -0.3899065, 0.23543632, 0.36691776, -0.63426155, -0.45399153, 0.056029648, -0.22056723, 0.05729053, ...]",False,False,False,False,"[-0.4785253, 0.36263672, 0.24839932, -0.16225754, 0.5119353, -0.24065863, -0.17964981, 0.1867118, -0.1466711, -0.49233487, 0.051712688, -0.26908156, 0.4122599, 0.46607885, -0.096525475, 0.55718136, -0.26385447, -0.290889, 0.09165403, 0.04680962, 0.1522274, 0.46933606, -0.09838008, 0.42424363, 0.2368095, -0.3427454, 0.3624469, 0.10335104, -0.20836027, 0.2253728, 0.09804927, 0.19463608, -0.46928376, -0.19284643, -0.2870971, 0.087035045, -0.15458892, -0.5987655, -0.367506, 0.08203431, -0.03622866, -0.04312975, 0.1317639, -0.3265255, -0.106705844, -0.17810571, -0.18560417, -0.35394228, -0.033942875, -0.37791893, -0.90460455, -0.14591642, -0.04023302, 0.035900712, -0.29574877, 0.5547057, 0.1560326, -0.19925453, 0.11669087, 0.14478812, -0.26986614, 0.09026761, -0.09785731, -0.209697, 0.48568675, 0.03223412, 0.2407403, -0.122100465, -0.37628743, 0.37595913, -0.41417846, -0.23294735, -0.3657359, 0.5699494, -1.0238782, 0.2972513, 0.20884952, 0.36620238, -0.071312614, -0.086227156, -0.5580221, 0.6361664, -0.2617033, -0.2748652, 0.37676346, 0.7683784, 0.38089183, 0.4407046, -0.37533295, 0.3070625, 0.11550342, 0.011778669, -0.25197682, 0.421936, 0.74171805, -0.29653034, 0.15787406, -0.0016535282, -0.09141523, 0.14450198, ...]",HDQVL9W2,"<p>The paper claims that current analytical methods make users interact with the statistical model by using sliders menus and text requiring them to go outside of the visual metaphor.</p>
<p>They define <strong>semantic interaction</strong> as an interaction that seeks to enable analysts to spatially interact with the models directly inside the statistical metaphor, using interactions that derive from their analytic process, such as searching, highlighting, annotating and repositioning documents. The focus of semantic interaction is on interacting with data directly not with the dimensions for example as in dust and magnet. <strong>I dont know whats the problem for doing both</strong></p>
<p>Semantic Interaction is based on the following principles:</p>
<p>1. Visual: Near= similar [citation 22]</p>
<p>2. Use the interactions within the visual metaphor [citation 4]</p>
<p>3. Interpret and map the interactions to the parameters of the model by updating weights and information</p>
<p>4. Shield users from the complexity</p>
<p>5. Model learns incrementally based on the interaction</p>
<p>6. Provide instant feedback of the updated model within the visual metaphor</p>
<p>7. Reuse learned model parameters in future,</p>
<p>Space to think found cognitive advantages associated with the manual creation of layout information.</p>
<p>[Cite 17] found that allowing users to create informal relationships within information is beneficial, as it does not require users to formalize these relationships.</p>
<p>Relevance Feedback has been used for content-based image retrieval by moving images closer or separate from each other to portray pair-wise similarity [cite 24]</p>
<p>Semantic interaction leverages the cognitive connection formed between the user and the spatial layout.</p>
<p>The captured interactions define a new type of data, the important part of this interactions is discovering intent from the specific interaction. For example we can give more importance to a piece of text that has been highlighted. This new data stored in the interaction is named as <strong>soft data</strong> in comparison with <strong>hard data</strong> extracted from the actual information.</p>
<p> </p>
<p><strong>Table of interactions and associated analytic reasoning in page 5, table 1.</strong></p>
<p> </p>
<p>The system is called <strong>ForceSpire </strong> documents are visualized as nodes that have more or less mass depending on the size of the document. Values are calculated using TFIDF</p>
<p> </p>
<p>Interactions:</p>
<p>Document Movement: Dragging, pinning or linking.</p>
<p>    Dragging changes similarity of documents</p>
<p>    Pinning gives meaning to the space surrounding a document</p>
<p>    Linking changes the relationships among documents</p>
<p> Highlighting: Gives importance to the highlighted text.</p>
<p> Annotations: Adds semantic meaning to a document or a link or the space.</p>
<p>Search: If the search is a new term it creates the term if not it gives more importance to the already created term.</p>
<p><strong>FUTURE WORK</strong><br />What interactions to capture and store, which parameters in the model to update, how to store the soft data. Which models have a good metaphor that can be extended upon.   </p>",False,False,HDQVL9W2,UYMW6IC5,[],"semantic interaction for visual text analytics 
chris north 
alex endert 
virginia tech 
virginia tech 

patrick fiaux 
virginia tech 

blacksburg, va usa 

aendert@vt.edu 

blacksburg, va usa 

pfiaux@vt.edu 

 

blacksburg, va usa 

north@vt.edu 

by 

for 

through 

abstract 
visual analytics emphasizes sensemaking of large, complex 
datasets 
interactively  exploring  visualizations 
generated 
example, 
statistical  models. 
dimensionality  reduction  methods  use  various  similarity 
metrics to visualize textual document collections in a spatial 
metaphor,  where  similarities  between  documents  are 
approximately  represented  through  their  relative  spatial 
distances  to  each  other  in  a  2d  layout.  this  metaphor  is 
designed to mimic analysts’ mental models of the document 
collection  and  support  their  analytic  processes,  such  as 
clustering similar documents together. however, in current 
methods, users must interact with such visualizations using 
controls  external  to  the  visual  metaphor,  such  as  sliders, 
menus, or text fields, to directly control underlying model 
parameters  that  they  do  not  understand  and  that  do  not 
relate  to  their  analytic  process  occurring  within  the  visual 
metaphor.  in  this  paper,  we  present  the  opportunity  for  a 
new  design  space  for  visual  analytic  interaction,  called 
semantic  interaction,  which  seeks  to  enable  analysts  to 
spatially interact with such models directly within the visual 
metaphor using interactions that derive from their analytic 
process,  such  as  searching,  highlighting,  annotating,  and 
repositioning  documents.  further,  we  demonstrate  how 
semantic  interactions  can  be  implemented  using  machine 
learning 
tool,  called 
forcespire, for interactive analysis of textual data within 
a  spatial  visualization.    analysts  can  express  their  expert 
domain knowledge about the documents by simply moving 
them,  which  guides  the  underlying  model  to  improve  the 
overall layout, taking the user’s feedback into account. 
author keywords 
visualization; visual analytics; interaction 
acm classification keywords 
h5.m.  information  interfaces  and  presentation  (e.g.,  hci): 
miscellaneous.  
general terms 
design; human factors; theory 

in  a  visual  analytic 

techniques 

 
permission to  make digital or hard copies of all or part of this work for 
personal or classroom use is granted without fee provided that copies are 
not made or distributed for profit or commercial advantage and that copies 
bear this notice and the full citation on the first page. to copy otherwise, 
or  republish,  to  post  on  servers  or  to  redistribute  to  lists,  requires  prior 
specific permission and/or a fee. 
chi’12, may 5–10, 2012, austin, texas, usa. 
copyright 2012 acm 978-1-4503-1015-4/12/05...$10.00. 
 

 

introduction 
visual analytics bases its success on combining the abilities 
of statistical models, visualization, and human intuition for 
users to gain insight into large, complex datasets [23]. this 
success often hinges on the ability for users to interact with 
the  information,  manipulating  the  visualization  based  on 
their  domain  expertise,  interactively  exploring  possible 
connections, and investigating hypotheses. it is through this 
interactive exploration that users are able to make sense of 
complex  datasets,  a  process  referred  to  as  sensemaking 
[19].  
the  two  primary  parts  of  sensemaking  are  foraging  and 
synthesis. foraging refers to the stages of the process where 
users filter and gather collections of interesting or relevant 
information.  then,  using  that  information,  users  advance 
through  the  synthesis  stages  of  the  process,  where  they 
construct  and  test  hypotheses  about  how  the  foraged 
information  may  relate  to  the  larger  plot.  tools  exist  that 
support users for either foraging or synthesis – but not both. 
in  this  paper  we  present  semantic  interaction,  combining 
the  foraging  abilities  of  statistical  models  with  the  spatial 
synthesis abilities of analysts. semantic interaction is based 
on the following principles: 
1. visual  “near=similar”  metaphor  supports  analysts’ 
spatial  cognition,  and  is  generated  by  statistical  models 
and similarity metrics. [22] 

2. use  semantic  interactions  within  the  visual  metaphor, 
based  on  common  interactions  occurring  in  spatial 
analytic  processes  [4]  such  as  searching,  highlighting, 
annotating, and repositioning documents.  

3. interpret  and  map  the  semantic  interactions  to  the 
underlying parameters of the model, by updating weights 
and adding information. 

4. shield  the  users  from  the  complexity  of  the  underlying 

mathematical models and parameters. 

5. models  learn  incrementally  by  taking  into  account 
interaction during the entire analytic process, supporting 
analysts’ process of incremental formalism [10]. 

6. provide  visual  feedback  of  the  updated  model  and 

learned parameters within the visual metaphor. 

7. reuse  learned  model  parameters  in  future  or  streaming 

data within the visual metaphor. 

to  demonstrate  the  concept  of  semantic  interaction,  we 
present  a  prototype  visual  analytics  tool,  forcespire,  for 
spatial analysis of textual information. in forcespire, the 
user  interaction  takes on  a deeper,  more  integrated role in 

the  exploratory  spatial  analytic  process.  this  is  done 
through capturing the semantic interaction, interpreting the 
analytical  reasoning  associated  with  the  interaction,  and 
updating the statistical model, and ultimately updating the 
spatialization.  hence,  users  are  able  to  leverage  semantic 
interaction  to  explore  and  analyze  the  data  interactively, 
while  the  system  is  responsible  for  properly  updating  the 
underlying statistical model.  
related work 
foraging tools 

 

figure  1.  a  model  of  interaction  with  foraging  tools.  users 
interact  directly  with  the  statistical  model  (red),  then  gain 
insight  through  observing  the  change  in  the  visualization 
(blue). 
we  categorize  foraging  tools  by  their  ability  to  pass  data 
through  complex  statistical  models  and  visualize  the 
computed structure of the dataset for the user to gain insight 
(figure  1).  thus,  users  interact  with  these  tools  primarily 
through directly manipulating the parameters of the model 
used  for  computing  the  structure.  as  such,  users  are 
required  to  translate  their  domain  expertise  and  semantics 
about  the  information  to  determine  which  (and  by  how 
much) to adjust these parameters. the following examples 
further describe this category of tools. 
visualizations such as in-spire’s “galaxy view” (shown 
in  figure  3)  present  users  with  a  spatial  layout  of  textual 
information where similar documents are proximally close 
to  one  another  [25].  an  algorithm  creates  the  layout  by 
mapping the high-dimensional collection of text documents 
down  to  a  two-dimensional  view.  in  these  spatializations, 
the  spatial  metaphor  is  one  from  which  users  can  infer 
meaning  of  the  documents  based  on  their  location.  the 
notion  of  distance  between  documents  represents  how 
similar the two documents are (i.e., more similar documents 
are  placed  closer  together).  for  instance,  a  cluster  of 
documents  represents  a  group  of  similar  documents,  and 
documents  placed  between  two  clusters  implies  those 
documents are connected to both clusters. these views are 
beneficial  as  they  allow  users  to  visually  gain  a  quick 
overview  of  the  information,  such  as  what  key  themes  or 
groups  exist  within  the  dataset.  the  complex  statistical 
models  that  compute  similarity  between  documents  are 
based on the structure within the data, such as term or entity 
frequency. in order to interactively change the view, users 
are  required  to  directly  adjust  keyword  weights,  add  or 
remove documents/keywords, or provide more information 
on how to parse the documents for keywords/entities upon 
import. 

 

to  a 

to  understand 

the 

[15].  through  adjusting 

similarly, an interactive visualization tool called ipca uses 
principal  component  analysis  (pca)  to  reduce  high-
dimensional  data  down 
two-dimensional  plot, 
providing  users  with  sliders  and  other  visual  controls  for 
directly  adjusting  numerous  parameters  of  the  algorithm, 
such  as  individual  eigenvalues,  eigenvectors,  and  other 
components  of  pca 
the 
parameters,  the  user  can  observe  how  the  visualization 
changes.  this  allows  users  to  gain  insight  into  a  dataset, 
given  they  have  a  thorough  understanding  of  pca, 
necessary 
the 
changes they are making to the model parameters. 
alsakran  et  al.  presented  a  visualization 
system, 
streamit,  capable  of  spatially  arranging  text  streams 
based  on  keyword  similarity  [3].  again,  users  can 
interactively  explore  and  adjust  the  spatial  layout  through 
directly  changing  the  weight  of  keywords  that  they  find 
important.  in  addition,  streamit  allows  for  users  to 
conduct  a  temporal  investigation  of  how  clusters  change 
over time. 
synthesis tools 

implications  behind 

 

figure  2.  a  model  of  interaction  with  synthesis  tools.  users 
manually  create  a  spatial  layout  of  the  information  to 
maintain and organize their insights about the data. 
synthesis  tools  focus  on  allowing  users  to  organize  and 
maintain their hypotheses and insight regarding the data in 
a  spatial  medium.  in  large  part,  this  is  done  through 
presenting users with a flexible spatial workspace in which 
they  can  organize  information  through  creating  spatial 
structures,  such  as  clusters,  timelines,  stories,  etc.  (figure 
2). in doing so, users externalize their thought processes (as 
well  as  their  insights)  into  a  spatial  layout  of  the 
information. 
for example, analyst’s notebook [2] provides users with a 
spatial workspace where information can be organized, and 
connections  between  specific  pieces  of  information  (e.g., 
entities, documents, events, etc.) can be created. similarly, 
the sandbox [26] enables users to create a series of cases 
(collections  of 
information)  which  can  be  organized 
spatially within the workspace.  
from  previous  studies,  we  found  cognitive  advantages 
associated  with  the  manual  creation  of  a  spatial  layout  of 
the  information  [4].  by  providing  users  a  workspace  in 
which  to  manually  create  spatial  representations  of  the 
information, users were able to externalize their semantics 
of the information into the workspace. that is, they created 
spatial  structures  (e.g.,  clusters,  timelines,  etc.),  and  both 
the structures as well as the locations relative to remaining 
layout  carried  meaning  to  the  users  with  regards  to  their 
sensemaking process. marshall et al. have pointed out that 

this 

interaction  (and 

from  the  sensemaking  loop  presented  by  pirolli  and  card 
[19],  we  learn  that  in  intelligence  analysis,  that  analytic 
process  consists  not  only  of  the  information  that  is 
explicitly  within  the  dataset  being  analyzed,  but  also  the 
domain knowledge of the analyst performing the analysis. it 
is through this domain knowledge that analysts interact and 
explore  the  dataset  to  “make  sense”  of  the  information. 
thus,  we  believe 
the  domain 
knowledge  associated  with  it)  is  equally  important  as  the 
raw data, and must be incorporated into the visualization by 
tightly coupling the model with the interaction. 
from this body of work, we most notably come away with 
an understanding that 1) analysts fundamentally understand 
the spatial metaphor used in many spatial visualizations, 2) 
many  of  these  systems  are  constructed  using  complex 
mathematical  algorithms  to  transform  high-dimensional 
data  to  two  dimensions,  and  3)  in  most  cases  these 
algorithms  can  be  controlled  by  analysts  largely  through 
visual  controls  (e.g.,  sliders,  knobs,  etc.)  to  directly  adjust 
parameters of the algorithms, updating the spatial layout. 
semantic interaction 

 

figure 4. a model of semantic interaction. users are able to 
interact directly in the spatial metaphor. the system updates 
the corresponding parameters of the statistical model based on 
the analytic reasoning of the users. finally, the model updates 

the visualization based on the changes, thus unifying the 
synthesis and foraging stages of the sensemaking loop. 

in the purest sense, semantic interaction refers to interaction 
occurring  within  a  spatial  visualization,  with  the  added 
benefit that it is tightly coupled to the model calculating the 
spatial layout (figure 4). given the previous work of what 
interaction  in  visual  analytic  tools  is,  semantic  interaction 
occupies a new design space for interaction. it merges the 
ability to change the statistical model while maintaining the 
flexibility  and  familiar  methods  for  interacting  within  the 
metaphor  of  spatial  visualizations.  users  can  benefit  from 
semantic  interactions  in  that  they  can  interact  within  a 
metaphor  which 
they  are  familiar  with,  performing 
interactions  which  are  part  of  the  spatial  analytic  process 
[4], without having to focus on formal updates to the model.  
semantic  interaction  leverages  the  cognitive  connection 
formed  between  the  user  and  the  spatial  layout.  the 
following intelligence analysis scenario is representative of 
the strategies and interactions of analysts when performing 
an  intelligence  analysis  task  of  textual  documents  in  a 
spatial visualization, as previously found by andrews et al. 
[4],  and  further  motivates  and  explains  the  concept  of 
semantic interaction: 

 
figure  3.  the  in-spire  galaxy  view  showing  a 
spatializtiation  of  documents  represented  as  dots.  each 
cluster of dots represents a group of similar documents.  
 
allowing users to create such informal relationships within 
information  is  beneficial,  as  it  does  not  require  users  to 
formalize these relationships [17].  
from this related work, we believe a trend is emerging in 
how interaction is currently handled in many visual analytic 
systems where complex statistical models are used – users 
are  required  to  go  outside  of  the  metaphor.  that  is,  while 
the  visual  representation  given  to  users  is  spatial,  the 
methods of interaction require users to step outside of that 
metaphor  and  interact  directly  with  the  parameters  of  the 
statistical model using visual controls, toolbars, etc.  
there  has  been  some  work  in  providing  more  easy  to  use 
interactions  for  updating  statistical  models.  for  example, 
relevance feedback has been used for content-based image 
retrieval, where users are able to move images towards or 
away  from  a  single  image  in  order  to  portray  pair-wise 
similarity  or  dissimilarity  [24].  from  there,  an  image 
retrieval algorithm determines the features and dimensions 
shared between the images that the user has determined as 
being  similar.  we  view  this  as  one  example  where  the 
interaction stays in the spatial metaphor of the visualization.  
also, spatializations of document sets exist that allow users 
to place “points of interest” into the spatial layout. in vibe, 
users are allowed to define multiple points of interest in the 
spatial  layout  that  correspond  to  a  series  of  keywords 
describing  a  subject  matter  of  interest  to  the  user  [18]. 
similarly,  dust  &  magnet  [27]  allows  users  to  place  a 
series  of  “magnets”  representing  keywords  into  the  space 
and observe how documents are attracted or repelled from 
the  locations  of  these  magnets.  through  both  of  these 
systems, users can interact in the spatial metaphor through 
these  placements  of  “nodes”  representing  keywords. 
however, the focus of semantic interaction is on interacting 
with  data  (i.e.,  documents),  an 
important  distinction 
discussed in the following section. 

 

 

 
figure  5.  (top)  the  basic  version  of  the  “visualization 
pipeline”.  interaction  can  be  performed  on  directly  the 
algorithm  (blue  arrow)  or  the  data  (red  arrow).  (bottom) 
our  modified  version  of 
for  semantic 
interaction,  where  the  user  interacts  within  the  spatial 
metaphor (purple arrow). 

the  pipeline 

during her analysis, an intelligence analyst finds a 
suspicious  and 
interesting  phrase  within  a 
document. while reading through the document, she 
highlights  the  phrase  “suspicious  individuals  were 
spotted  at  the  airport”,  in  order  to  more  easily 
recall  this  information  later.  after  she  finishes 
reading the document, she moves the document into 
the  bottom  right  corner  of  her  workspace,  in  the 
proximity of other documents related to an event at 
an airport. to remind herself of her hypothesis, she 
annotates  the  document  with  “might  be  related  to 
revolution  now  terrorist  group”.  now,  with  the 
goal  of 
the 
“airport”, she searches for the term, continuing her 
investigation. 

further  examining 

the  events  at 

investigating 

that  each  of 

instead  point  out 

the  analytic  process  of 

in addition to the three forms of semantic interaction in the 
scenario,  table  1  provides  a  list  of  various  forms  of 
semantic  interaction,  including  how  each  can  be  used 
within 
textual 
information  spatially.  we  do  not  claim  that  this  list  is 
complete,  but 
these 
interactions  can  relate  to  a  user’s  reasoning  within  the 
analytic process.  
designing for semantic interaction 
in order for analysts to interact with information in a spatial 
metaphor, it must first be created. following the model of 
the visualization pipeline [13], this creation calls for a series 
of  mathematical  transformations,  turning  raw  data  into  a 
spatial  layout  –  much  the  way  many  of  the  visualizations 
mentioned  previously  are  constructed.  however,  these 
visualizations  fit  this  model,  as  their  user  interactions  are 
primarily  focused  on  directly  modifying  the  statistical 
model  (as  well  as  other  attributes  of  the  visualization  or 
data  transformation).  designing  for  semantic  interaction 
requires  a  fundamentally  different  model  for  how  tools 
integrate  user  interaction  –  one  that  can  capture  the 
interaction,  interpret  the  associated  analytical  reasoning, 
and update the appropriate mathematical parameters.  
figure  5  illustrates  this  model,  where  the  spatialization  is 
treated  a  medium  through  which  the  user  can  perceive 

 

figure 6. overview of how nodes and edges in forcespire’s 
force-directed layout are created from documents (doc) and 
entities (ent), respectively.  

 

 

it 

interaction, 

information  and  gain  insight,  as  well  as  interact  and 
perform  his  analysis.  through  expanding  the  pipeline  to 
accommodate  for  semantic 
is  a  more 
appropriate match to the user’s sensemaking process. 
capturing the semantic interaction 
a  non-trivial  first  step  in  the  model  is  capturing  the  user 
interaction.  much  research  has  been  done  in  this  area, 
primarily  for  the  purpose  of  maintaining  process  history 
(e.g., [5], [21], [12], etc.). when considering how to capture 
interaction,  one  decision  to  be  made  is  at  what  “level”  to 
capture  it.  for  example,  glassbox  [6]  captures  interaction 
at a rudimentary level (i.e. mouse clicks and key strokes), 
while  graphical  history  [14]  keeps  track  of  a  series  of 
previous  visualizations  as  a  user  changes  the  visualization 
during the exploration of the data.  
semantic  interaction  is  captured  at  a  data  level,  as  the 
interactions  occur  on  the  data,  and  within  the  spatial 
metaphor.  using 
the 
interaction being captured would be: 

the  earlier  analytic  scenario, 

•  the highlighted phrase 
•  when the highlighting occurs (timestamp) 
•  the color chosen for the highlight 
•  the document in which the highlight occurs 
•  the new document location 
•  the text of the annotation 

by  capturing  (and  storing)  the  interaction  history,  we  can 
interpret the analytical reasoning of the user. thus, we not 
only capture the interaction, but also use it. 
interpreting the associated analytical reasoning 
in interpreting the interaction, the goal is for the system to 
determine  the  analytical  reasoning  associated  with  the 
interactions  and  update  the  model  accordingly.  from 
previous findings [4], we can associate analytical reasoning 
with  forms  of  semantic  interaction  (see  table  1).  it  is 
essentially the model’s task to determine  why, in terms of 
the data, the interaction occurred. to answer this question, 
we do not propose that this model can accurately gauge user 
intent.  instead,  the  goal  is  to  calculate,  based  on  the  data, 

figure 7. using forcespire on a 32 megapixel large, 
high-resolution display. 

 

 
what information is consistent with the captured interaction. 
for  instance,  we  associate  text  highlighting  with  adding 
importance to the text being highlighted. we do not claim 
that we can associate the interaction of highlighting to the 
intuition that spurred the analyst to highlight the text, which 
is far more challenging, and arguably impossible. 
we refer to the captured and interpreted interactions as soft 
data, in comparison to the hard data that is extracted from 
the raw textual information (e.g., term or entity frequency, 
titles,  document  length,  etc.).  we  define  soft  data  as  the 
stored result of user interaction as interpreted by the system. 
in  representing  interaction  as  soft  data,  the  algorithm  can 
calculate  and  reconfigure  the  spatial  layout  accordingly. 
figure  5  illustrates  how  our  approach  differs  from  the 
traditional visualization pipeline. 
there has been previous work in capturing and interpreting 
reasoning from user interaction. for instance, dou et al. [7] 
performed  a  study  where  financial  analysts  were  asked 
analyze  a  dataset  using  wirevis,  an  interactive  financial 
transaction visualization. the tool developers then analyzed 
the captured interaction, and assumptions were made about 
the  reasoning  of  the  analysts  at  specific  points  in  the 
investigation. these results were compared to the analysts’ 
self-recorded  reasoning,  and  found  to  be  accurate  up  to 
82%. while our work has similar goals (i.e., interpreting the 
analytical reasoning associated with the analysts through an 
evaluation  of  the  interaction)  our  model  does  so  through 
tightly  integrating  the  interaction  with  the  underlying 
mathematical model. in doing so, the interpretation can be 
done algorithmically. 
updating the underlying model 
through  metric  learning  of  distance  weights,  the  layout 
uses  the  soft  data  to  update  the  underlying  model. 
depending  on  the  algorithm  used  to  compute  the  spatial 
layout,  the  precise  parameters  being  updated  will  vary.  in 
general,  this  will  refer  to  weighting  of  a  combination  of 
dimensions  that  will  help  guide  the  model  as  to  which 
dimensions the user finds important.  
forcespire: system overview 
forcespire  is  a  visual  analytics  prototype  designed  for 
specific 
(document 
movement,  text  highlighting,  search,  and  annotation)  for 

forms  of 

interaction 

semantic 

 

figure  8.  moving  the  document  shown  by  the  arrow, 
forcespire  adapts  the  layout  accordingly.  documents 
sharing entities with the document being moved follow. 

 

interactively exploring textual data. the system has a single 
spatial  view  (shown  in  figure  12),  where  a  collection  of 
documents is represented spatially based on similarity (i.e., 
documents closer together are more similar).  
forcespire is designed for large, high-resolution displays 
(such  as  the  one  shown  in  figure  7).  as  semantic 
interaction emphasizes the importance of context in which 
the  interaction  takes  place  (e.g.,  highlighting  text  in  the 
context  of  the  document),  having  the  full  detail  text 
available  in  the  context  of  the  spatial  layout  is  beneficial 
over having a single document viewer. further, the physical 

table  1.  forms  of  semantic  interaction.  each  interaction 
corresponds  to  reasoning  of  users  within  the  analytic 
process. 

form of semantic 

interaction 

document movement 

text highlighting 

pinning  document 
location 
annotation, “sticky note” 

to 

document coloring 

level of visual detail 

query terms 
 

associated analytic reasoning 

• similarity/dissimilarity 
• create 

spatial  construct 

timeline, list, story, etc) 

• test 

hypothesis, 

see 
document “fits” in region 

(.e.g 

how 

• mark 

importance  of  phrase 

(collection of entities) 

• augment  visual  appearance  of 

document for reference 

to 

in 

• give 

semantic  meaning 

space/layout 

• put 

semantic 

information 

workspace, within context 
• create visual group/cluster 
• mark group membership 
• change 

ease 

of 

visually 
referencing  information  (e.g.  full 
detail = more important = easy to 
reference) 

• expressive search for entity 

(and 

to  match 

is  positioning 

semantic interaction in forcespire 
the  semantic  interactions  in  forcespire  are:  placing 
information  at  specific  locations,  highlighting,  searching, 
and annotating in order to incrementally change the spatial 
layout 
their  mental  model.  the  primary 
parameters  of  the  force-directed  model  that  are  being 
updated  through  this  learning  model  are  the  importance 
values of the entities.  
document  movement.  the  predominant  interaction  in  a 
spatial  workspace 
repositioning) 
documents.  in  previous  work,  we  have  demonstrated  how 
users can perform both exploratory and expressive forms of 
this type of interaction [9]. in forcespire, we allow for the 
following  exploratory  interaction  (i.e.,  interaction  that 
allows users to explore the structure of the current model, 
but  does  not  change  it).  users  are  able  to  interactively 
explore the information by dragging a document within the 
workspace, pinning a document to a particular location (see 
figure  8),  as  well  as  linking  two  documents.  when 
dragging a document, the force-directed system responds by 
finding the lowest energy state of the remaining documents 
given  the  current  location  of  the  dragged  document. 
mathematically, this adds a constraint to the stress function 
being  optimized  (in  this  case  the  force-directed  model). 
this  allows  users  to  explore  the  relationship  of  that 
document in comparison to the remaining documents.  
in addition to the exploratory dragging of a document, users 
have the ability to pin a document. by pinning a document, 
users  are  able  to  incrementally  add  semantic  meaning  to 
locations in their workspace. by specifying key documents 
to  user-defined  locations,  the  layout  of  the  remaining 
documents will adapt to these constraints. thus, users can 
explore  how  documents  are  positioned  based  on  their 
similarity  (or  dissimilarity)  to  the  pinned  documents.  for 
instance,  if  the  layout  places  a  document  between  two 
pinned  documents, 
the  particular 
document holds a link between the two pinned documents, 
sharing entities that occur in both. 
finally,  users  can  perform  an  expressive  form  of  this 
interaction  by  linking  two  documents,  performed  by 
dragging  one  document  onto  another  pinned  document.  in 
doing so, forcespire calculates the similarity between the 
documents,  and  increases  the  importance  value  of  the 
entities  shared  between  both  documents.  as  a  result,  the 
layout will place more emphasis on the characteristics that 
make those two documents similar. 
highlighting.  when  highlighting  a  term,  forcespire 
creates an entity from the term (if not already one), and the 
importance  value  of  that  term  is  increased.  similarly, 
highlighting  a  phrase  results  in  the  phrase  being  first 
parsed for entities, then increasing the importance value of 
each  of  those  entities.  for  example,  figure  11  shows  the 
effect of highlighting the terms “colorado” and “missiles” 
in the document pointed to with the arrow. as a result, the 

it  may 

imply 

that 

 
figure  9.  the  effect  of  adding  an  annotation  (“these 
individuals  may  be  related  to  revolution  now”)  to  the 
document shown with an arrow. as  a result,  the document 
becomes 
linked  with  other  documents  mentioning  the 
terrorist organization “revolution now”.  

presence of these displays creates an environment in which 
the  virtual  information  (in  this  case  the  documents)  can 
occupy  persistent  physical  space.  as  a  result,  users  are 
further  immersed  into  the  spatial  metaphor,  as  they  can 
point and quickly refer to information based on the physical 
locations.  
constructing the spatial metaphor 
the spatial layout of the text documents is determined by a 
modified  version  a  force-directed  graph  model  [11].  this 
model  functions  on  the  principle  of  nodes  with  a  mass 
connected  by  springs  with  varying  strengths.  thus,  each 
node has attributes of attraction and repulsion: nodes repel 
other  nodes,  and  two  nodes  attract  each  other  only  when 
connected  by  a  spring  (edge).  the  optimal  layout  is  then 
computed  by  iteratively  calculating  these  forces  until  the 
lowest energy state of all the nodes is reached. a complete 
description of this algorithm can be found in [11].  
we  apply  this  model  to  textual  information  by  treating 
documents  as  nodes  (an  overview  is  shown  in  figure  6). 
the entire textual content of each document is parsed into a 
collection  of  entities  (i.e.,  keywords).  the  number  of 
entities corresponds to the mass of each document (heavier 
nodes  do  not  move  as  fast  as  lighter  nodes).  a spring  (or 
edge) represents one or more matching entities between two 
nodes.  therefore,  the  initial  distance  metric  is  a  based  on 
co-occurrence  of  terms  between  documents.  for  example, 
two  documents  containing  the  term  “airport”  will  be 
connected  by  a  spring.  the  strength  of  a  spring  (i.e.  how 
close together it tries to place two nodes) is based on two 
factors:  the  number  of  entities  two  documents  have  in 
common,  and  the  importance  value  associated  with  each 
shared entity (initially, importance values are created using 
a  standard  tfidf  method  [16]).  the  sum  of  all  importance 
values add up to 1. 
the resulting spatial layout is one where similarity between 
documents  is  represented  by  distance  relative  to  other 
documents.  similarity  in  this  system  is  defined  by  the 
strength of the spring between two documents. a stronger 
spring  (and  therefore  a  larger  amount  of  shared  entities) 
will pull two documents closer together, and thus represent 
two similar documents. 

 

 
figure  10.  searching  for  the  term  ”atlanta”,  documents 
containing the term highlight green within the context of the 
spatial  layout.  additionally,  the  importance  value  of  entity 
“atlanta” is increased. 

other  documents  containing  that  term  are  clustered  more 
tightly. 
searching.  when  coming  across  a  term  of  particular 
interest, analysts usually search on that term in order to find 
other  occurrences.  in  a  spatial  workspace,  this  is  of 
particular  importance,  because  the  answer  to  “where  the 
term  is  also  found”  is  not  only  given  in  terms  of  what 
documents,  but  also  where  in  the  layout  those  documents 
occur. the positions of documents containing the term are 
shown in context of the entire dataset, from which users can 
infer the importance of that term (as shown in figure 10).  
forcespire  first  creates  an  entity  from  the  search  term 
(unless  it  is  already  one),  then  increases  the  importance 
value  of  the  search  term.  figure  10  gives  an  example  of 
how a search result appears in forcespire. searching for 
the  term  “atlanta”,  documents  that  contain  the  term  are 
highlighted  green,  and  links  are  drawn  to  show  where  the 
resulting documents are in relation to the current document.  
annotation.  annotations  (i.e.,  “sticky  notes”)  are  also 
viewed as a form of semantic interaction, occurring within 
the analytic process, from which analytic reasoning can be 
inferred. when a user creates a note regarding a document, 
that semantic information should be added to the document. 
for example, if document a refers to “revolution now” (a 
suspicious  terrorist  group),  and  document  b  refers  to  “a 
group of suspicious individuals”, and the user has reason to 
believe  these  individuals  are  related  to  revolution  now, 
adding a note to document b stating “these individuals may 
be  related  to  revolution  now”  is  one  way  for  the  user  to 
add semantic meaning to the document.  
forcespire  handles  the  addition  of  the  note  (shown  in 
figure 9) by 1) parsing the note for any currently existing 
entities,  then  2)  increasing  the  importance  value  of  each, 
and 3) creating any new springs between other documents 
sharing these entities. in the example in figure 9, edges are 
created between document b and document a (as well as 
any  other  documents  that  mention  “revolution  now”). 
additionally,  if  the  note  contains  any  new  entities  not 
currently in the model, they are created, with the intent that 

 

 
figure 11. the effect of highlighting a phrase containing the 
entites  “colorado”  and  “missiles”.  documents  containing 
these  entities  move  closer,  as  the  increase  in  importance 
value increases the edge strength.  

the 

importance  values  of 

any future entities that may match to that note can be linked 
at that time. forcespire also handles cases where notes are 
edited,  with  text  added  or  removed  from  the  note,  by 
updating  the  entities  associated  with  the  document,  and 
adjusting 
these  entities 
accordingly. 
model updates 
each  of  the  semantic  interactions  in  forcespire  impacts 
the  model  by  updating  the  importance  values  of  entities, 
and  the  mass  of  each  document.  the  calculation  for 
updating the importance value of an entity is the same for 
each interaction. if an entity was “hit” (i.e., it was included 
in  a  highlight,  it  was  searched,  it  was  in  a  note,  etc.), 
forcespire increases its importance value by 10%. as the 
sum  of  all  importance  values  of  entities  adds  up  to  1, 
forcespire  subtracts  an  equal  amount  from  all  other 
entities’ importance values. as a result, importance values 
decay over time, and entities that are rarely used during the 
analysis  have  less  impact  on  the  layout.  the  mass  of  a 
document  uses  a  similar  calculation,  in  that  each  time  a 
document  is  “hit”  (i.e.,  text  was  highlighted,  it  was  the 
result of a search hit, etc.), it increases by 10%.  
when  undoing  an 
standard 
the 
“control+z”  keyboard  shortcut,  a  linear  history  of  the 
interactions will be reversed, and the importance values of 
affected  entities  will  be  returned  to  their  prior  values  (as 
well  as  document  masses).  as  for  the  locations  of  the 
documents,  the  reverted  importance  values  and  document 
masses  will  be  responsible  for  updating 
layout. 
however, this does not guarantee that the layout will return 
to  the  exact  previous  view,  and  the  user  may  find  it 
necessary to perform small adjustments. 
the model updates used in forcespire serve as an initial 
approach at how to couple semantic interactions with model 
updates. other, more complex methods may exist, and we 
encourage  further  research  in  this  area.  sensemaking  is  a 
complex exploratory process. as such, semantic interaction 

interaction  using 

the 

through 

more  central  documents.  while  reading 
the 
documents, he highlighted phrases of interest. for example, 
he highlighted the phrase “nizar a. is now known to have 
spent six months in afghanistan”. in doing so, forcespire 
increased  the  importance  value  of  the  entities  within  the 
phrase,  particularly  “afghanistan”  and  “nizar  a”.  as  a 
result, the layout forms more tightly around those entities. 
each change incrementally changes the layout. 
continuing  with  his  investigation,  he  began  searching  for 
words  of  interest  (e.g.,  “weapons”,  “colorado”,  “atlanta”, 
etc.). forcespire provided him with quick visual feedback 
on where in the dataset each terms showed up (the search 
result  for  “atlanta”  is  shown  in figure  10).  in  addition  to 
gaining an overview of the distribution of the term within 
the  dataset  (by  highlighting  each  document  containing  the 
term  green),  forcespire  treats  performing  a  search  as 
either  creating  a  new  entity  from  the  search  term,  or 
increasing the importance value if an entity corresponding 
to the search term already exists. as a result of the multiple 
search terms and highlights corresponding to locations (e.g., 
“atlanta”,  “los  angeles”,  “missouri”,  etc.),  forcespire 
adapts  the  spatialization  by  creating  a  more  geographic-
oriented layout (shown in the “mid stage” layout in figure 
12).  
during  further  investigation,  he  began  opening  more 
documents and adding annotations to documents where he 
found  information  missing  that  he  knew.  for  example, 
figure  9  shows  how  he  opened  one  document  where 
“suspicious individuals” were mentioned. earlier, he read a 
document  containing 
terrorist 
organization  named  “revolution  now”.  while  reading 
about  the  suspicious  individuals,  the  other  information  in 
the document triggered him to make a connection between 
these  individuals  and  revolution  now.  he  made  added  a 
note  to  the  document  about  the  suspicious  individuals 
stating  “these  individuals  may  be  related  to  revolution 
now”. as a result, forcespire parsed the note for entities, 
added  them  to  the  document,  and  pulled  the  document 
closer to other documents containing the entity “revolution 
now”.  
after  continuing  his  investigation  in  this  manner,  he 
ultimately  made  the  connections  within  the  dataset  to 
uncover  the  terrorist  plot.  the  progression  of  the  spatial 
layout,  shown  in figure 12, shows the final layout, where 
he  was  able  to  pinpoint  regions  of  the  layout  as  being 
important  in  his  finding.  some  of  the  spatial  locations  of 
clusters  are  a  result  of  him  pinning  documents  to  that 
region (e.g., “atlanta”, “los angeles”, etc.). these pinned 
documents are shown in red. perhaps more interestingly is 
not the regions that were created as a result of him pinning 
documents  to  that  location,  but  rather  how  the  remaining 
documents respond in the layout. for example, in the final 
state  shown  in  figure  12,  a  group  of  documents  began  to 
emerge  in  the  middle  of  all  the  pinned  locations.  upon 
examining  these  documents,  he  discovered  that  these 

information  about  a 

the 

layout 

 

interaction, 

instances  during 

 
figure 12. the incremental change of the spatial layout (main 
view  of  forcespire)  from  the  initial  to  the  final  state. 
through  semantic 
incrementally 
changed  based  on the  semantic  input of the user. we labeled 
the regions based on what the user told us the regions meant to 
him at each stage. 
can  enable  analysts  to  explore  their  hypothesis  in-situ, 
while  the  provenance  of  their  insights  is  captured  and 
stored. an open area of research is what analyzing the soft 
data might reveal about the analytic process. for instance, if 
the  importance  values  of  entities  converge  on  a  small 
number  of  entities,  specific  biases  might  be  revealed. 
similarly, 
the  analysis  when  new 
hypotheses  are  being  explored  may  be  indicated  by 
diverging importance values. 
use case 
we  demonstrate  the  functionality  of  forcespire  through 
the  following  use  case.  in  this  scenario,  we  simulate  an 
intelligence  analysis  scenario  where  the  task  is  to  find  a 
hidden terrorist plot in a pre-constructed, ficticious textual 
dataset.  the  dataset  consists  of  50 
text  documents, 
containing  a  complex  terrorist  plot  (explosives  are  being 
transported to various cities in the u.s. using trucks). the 
combination of the task of finding the hidden terrorist plot 
and  the  textual  dataset  is  representative  of  daily  work 
performed  by  professional  intelligence  analysts  [8].  the 
analysis  described  below  lasted  70  minutes,  and  was 
performed  by  an  individual  computer  science  graduate 
student.  
the user began the investigation by loading the collection 
of  documents  into  forcespire.  the  documents  were 
automatically  parsed  for  entities  using 
the  lingpipe 
keyword  extraction  library  [1].  from  these  entities,  an 
initial layout was generated, shown in figure 12(top). from 
this  layout,  he  began  investigation  by  reading  through  the 

 

interpreting 

leverage 

interactions 

discussion 
unifying the sensemaking loop 
with the fundamentally different role occupied by semantic 
interaction, we explore a new design space for interaction in 
visual analytic tools. with the addition of soft data, and a 
model  capable  of 
the  user’s  analytical 
reasoning,  we 
that  are  already 
occurring in the spatial analytic process to further aid users 
in their sensemaking process.  
with  semantic  interaction,  the  amount  of  formalization 
between foraging and sensemaking (figure 13) on the part 
of the user is reduced. for instance, in moving a document, 
users  can  formulate  a  hypothesis  based  on  that  document, 
expecting  similar  documents 
to  follow.  forcespire 
attempts to update the layout based on the interaction, and 
gives the user feedback. thus, the foraging stage occurs as 
a  result  of  the  hypothesis  being  formed  through  semantic 
interaction.  by  not  forcing  users  to  over-formalize  their 
analytic  reasoning  too  early  in  order  to  forage  for  the 
relevant  information,  semantic  interaction  creates  a  more 
seamless 
transition  between 
foraging  and  synthesis, 
unifying the sensemaking loop.  
future work 
semantic 
interaction,  as  a  concept,  opens  up  many 
possibilities for further research, such as: what interactions 
to  capture  and  store,  which  parameters  of  the  model  to 
update,  how  to  store  the  soft  data,  and  which  models 
present a metaphor that can be extended upon.  
in  order  to  make  more  concrete  claims  regarding  the 
usability  and  effectiveness  of  forcespire  (and  thus,  of 
semantic  interaction),  a  formal  user  study  is  needed.  our 
plan is to introduce forcespire to professional intelligence 
analysts  and  have  them  solve  scenarios  that  model  their 
daily  task,  such  as  one  of  the  vast  datasets  [2020].  the 
observations  and  feedback  from  these  users  will  provide 
ecological validity for semantic interaction. 
conclusion 
in  this  paper  we  have  discussed  how  the  concept  of 
semantic  interaction  leads  to  a  new  design  space  for 
interaction 
information. 
semantic  interactions  occur  directly  within  the  spatial 
metaphor,  support  spatial  cognition,  and  exploit  spatial 
analytic  interactions.  we  describe  semantic  interaction, 
discussing  the  three  components  required  –  capturing  the 
interaction, 
the  analytical  reasoning,  and 
updating  the  mathematical  model.  further,  we  present 
forcespire, designed for semantic interaction with textual 
information, discussing its functionality and demonstrating 
how it can be used through a use case. lastly, we discuss 
how  semantic  interaction  has  the  opportunity  to  unify  the 
sensemaking  loop,  creating  a  more  seamless  analytic 
process.  in  allowing  users  to  interact  within  the  spatial 
metaphor, they can remain more focused on their analysis 
of  the  data,  without  having  to  become  experts  in  the 
underlying mathematical models of the system.  

in  spatializations  of 

interpreting 

textual 

 

figure  13.  the  sensemaking  loop,  illustrating  the  complex 
sequence  of  steps  used  by  intelligence  analysts  in  order  to 
gain insight into data.  
 
documents  are  about  the  terrorist  organization  using  “u-
haul”  or  “ryder”  trucks  for  transportation  between  these 
locations. forcespire placing these documents in between 
these  cities  in  the  layout  was  helpful,  as  these  documents 
contain  information  “connecting”  the  events  in  these 
locations.  immediately  after  noticing  this  event,  he  also 
made use of the expressive form of interaction, performed 
by dragging two of these documents together to determine 
what  made  them  similar.  after  seeing  that  it  was  indeed 
terms  such  as  “ryder”  and  “u-haul”,  the  layout  formed 
more tightly around these terms. 
forcespire interpreted the analytical reasoning of the user 
through the creation of new entities that were not found by 
the  initial  keyword  extraction,  as  well  as  the  increase  of 
importance values of existing entities. this is evidenced by 
the  creation  of  39  new  entities  during  the  course  of  the 
analysis.  lingpipe  extracted  89  initial  entities  from  this 
dataset,  and  at  the  time  of  completing  our  investigation 
forcespire  included  128.  examples  of  newly  created 
entities  are  “big  event”,  “grenades”,  “fisher  island”, 
“weapons”,  and  others.  the  ability  for  new  entities  to  be 
created  via  semantic  interaction  did  not  interfere  with  the 
fluid sensemaking process of the user. instead, it aided the 
process  by  creating  new  entities,  which  in  turn  created 
semantically relevant connections within the dataset. 
in  addition  to  creating  new  entities,  existing  entities 
dynamically  changed  their  importance  value  based  on  the 
semantic 
interpreted 
reasoning 
interactions.  examples  of  entities 
their 
importance  values  are  “atlanta”,  “revolution  now”, 
“colorado”,  “l.a.”,  and  others.  as  a 
the 
forcespire incrementally adapted the layout based on the 
user  input.  this  shows  that  adjusting  importance  values, 
creating entities, and changing locations of key documents 
helped  the  user  discover  the  structure  of  the  dataset,  and 
ultimately make out the hidden terrorist plot.  

of 
that  changed 

analytical 

result, 

the 

 

acknowledgements 
this research was funded by the nsf grant ccf-0937071 
and the dhs center of excellence. 
references 
1.  alias-i. 2008. lingpipe 4.0.1. city, 2008. 
2.  i2 analyst's notebook. city. 
3.  alsakran, j., chen, y., zhao, y., yang, j. and luo, d. 

streamit: dynamic visualization and interactive 
exploration of text streams. in proceedings of the ieee 
pacific visualization symposium, 2011.  

4.  andrews, c., endert, a. and north, c. space to think: 
large, high-resolution displays for sensemaking. in 
proceedings of the chi '10, 2010.  

5.  callahan, s. p., freire, j., santos, e., scheidegger, c. e., 

c, silva, u. t. and vo, h. t. vistrails: visualization 
meets data management. in proceedings of the 
sigmod international conference on management of 
data (chicago, il, usa, 2006). acm.  

6.  cowley, p., haack, j., littlefield, r. and hampson, e. 

glass box: capturing, archiving, and retrieving 
workstation activities. in proceedings of the workshop 
on continuous archival and retrival of personal 
experences (santa barbara, california, usa, 2006). 
acm.  

7.  dou, w., jeong, d. h., stukes, f., ribarsky, w., 

lipford, h. r. and chang, r. recovering reasoning 
processes from user interactions. ieee computer 
graphics and applications, 2009. 

8.  endert, a., andrews, c., fink, g. a. and north, c. 

professional analysts using a large, high-resolution 
display. in proceedings of the ieee vast extended 
abstract (2009).  

9.  endert, a., han, c., maiti, d., house, l., leman, s. c. 

and north, c. observation-level interaction with 
statistical models for visual analytics. ieee vast, 
2011. 

10. frank m. shipman, i. and marshall, c. c. formality 

considered harmful: experiences, emerging themes, 
and directions on the use of formal representations 
ininteractive systems. acm cscw, 8, 4, 1999, 333-352. 

11. fruchterman, t. m. j. and reingold, e. m. graph 

drawing by force-directed placement. software: practice 
and experience, 21, 11 1991, 1129-1164. 

12. gotz, d. interactive visual synthesis of analytic 

knowledge. ieee vast, 2006. 
13. heer, j. prefuse manual, 2006. 
14. heer, j., mackinlay, j., stolte, c. and agrawala, m. 

graphical histories for visualization: supporting 
analysis, communication, and evaluation. ieee 
transactions on visualization and computer graphics, 
14, 6 , 2008, 1189-1196. 

 

15. jeong, d. h., ziemkiewicz, c., fisher, b., ribarsky, w. 

and chang, r. ipca: an interactive system for pca-
based visual analytics. computer graphics forum, 28, 
2009, 767-774. 

16. karen a statistical interpretation of term specificity 

and its application in retrieval. journal of 
documentation, 28, 1972, 11-21. 

17. marshall, c. c., frank m. shipman, i. and coombs, j. 

h. viki: spatial hypertext supporting emergent 
structure. in proceedings of the european conference on 
hypermedia technology (edinburgh, scotland, 1994). 
acm.  

18. olsen, k. a., korfhage, r. r., sochats, k. m., spring, 
m. b. and williams, j. g. visualization of a document 
collection: the vibe system. information process 
management, 29, 1 1993, 69-81. 

19. pirolli, p. and card, s. sensemaking processes of 

intelligence analysts and possible leverage points as 
identified though cognitive task analysis proceedings 
of the international conference on intelligence 
analysis,2005, 6. 

20. plaisant, c., grinstein, g., scholtz, j., whiting, m., 

o'connell, t., laskowski, s., chien, l., tat, a., wright, 
w., gorg, c., zhicheng, l., parekh, n., singhal, k. and 
stasko, j. evaluating visual analytics at the 2007 
vast symposium contest. computer graphics and 
applications, ieee, 28, 2 2008, 12-21. 

21. shrinivasan, y. b. and wijk, j. j. v. supporting the 

analytical reasoning process in information 
visualization. in proceedings of the chi '08 (florence, 
italy, 2008). acm.  

22. skupin, a. a cartographic approach to visualizing 
conference abstracts. ieee computer graphics and 
applications, pp. 50-58, january/february, 2002. 

23. thomas, j. j., cook, k. a., national, v. and analytics, 
c. illuminating the path. ieee computer society, 2005. 
24. torres, r. s., silva, c. g., medeiros, c. b. and rocha, 

h. v. visual structures for image browsing. in 
proceedings of the conference on information and 
knowledge management (new orleans, la, usa, 
2003). acm.  

25. wise, j. a., thomas, j. j., pennock, k., lantrip, d., 

pottier, m., schur, a. and crow, v. visualizing the non-
visual: spatial analysis and interaction with information 
for text documents. morgan kaufmann publishers, 1999. 

26. wright, w., schroh, d., proulx, p., skaburskis, a. and 

cort, b. the sandbox for analysis: concepts and 
methods. in proceedings of the chi '06 (new york, 
ny, 2006). acm.  

27. yi, j. s., melton, r., stasko, j. and jacko, j. a. dust & 
magnet: multivariate information visualization using a 
magnet metaphor. information visualization, 4, 4, 2005, 
239-256. 

",Semantic interaction for visual text analytics,"{""pos"":{""0"":1,""1"":2,""2"":3,""3"":4,""4"":5},""1"":{""0"":""ieee*"",""1"":""atlanta*"",""2"":""virginia*"",""3"":""tech*"",""4"":""blacksburg""},""3"":{""0"":""users*"",""1"":""entities*"",""2"":""models"",""3"":""tools"",""4"":""workspace""},""0"":{""0"":""importance"",""1"":""result"",""2"":""interact*"",""3"":""directly*"",""4"":""value""},""2"":{""0"":""spatial*"",""1"":""semantic*"",""2"":""visual*"",""3"":""visualization"",""4"":""dimensional*""}}",conferencePaper,,self.user,False,"{""Unnamed: 0"":{""0"":0,""1"":1,""2"":2,""3"":3,""4"":4,""5"":5,""6"":6,""7"":7,""8"":8,""9"":9,""10"":10,""11"":11,""12"":12,""13"":13,""14"":14,""15"":15,""16"":16,""17"":17,""18"":18,""19"":19,""20"":20,""21"":21,""22"":22,""23"":23,""24"":24,""25"":25,""26"":26,""27"":27,""28"":28,""29"":29,""30"":30,""31"":31,""32"":32,""33"":33,""34"":34,""35"":35,""36"":36,""37"":37,""38"":38,""39"":39,""40"":40,""41"":41,""42"":42,""43"":43,""44"":44,""45"":45,""46"":46,""47"":47,""48"":48,""49"":49,""50"":50,""51"":51,""52"":54,""53"":55,""54"":56,""55"":57},""C"":{""0"":7.2848872773,""1"":8.7500788697,""2"":19.9176817341,""3"":5.0091155864,""4"":6.10784078,""5"":13.6390249506,""6"":5.4376104745,""7"":10.58337383,""8"":7.633272827,""9"":5.9298993686,""10"":16.3118178679,""11"":7.8016054686,""12"":11.9889398587,""13"":5.3710290453,""14"":5.9795156066,""15"":8.722432648,""16"":6.4049889016,""17"":9.4925714079,""18"":6.6073391207,""19"":4.6489736931,""20"":4.8593026338,""21"":8.7669936395,""22"":4.4977930176,""23"":10.4155810887,""24"":10.0894101761,""25"":5.9501903633,""26"":5.1097411038,""27"":9.5530385662,""28"":5.2354497707,""29"":10.2311602559,""30"":14.231974754,""31"":13.1393054417,""32"":5.6759369401,""33"":6.8774539129,""34"":5.4671744282,""35"":4.5996316311,""36"":6.3680531712,""37"":5.2142210552,""38"":6.2300983189,""39"":4.4803287121,""40"":5.9426864206,""41"":5.2416101829,""42"":6.3157706186,""43"":5.3690801073,""44"":6.852109183,""45"":7.2214548521,""46"":4.5504038732,""47"":6.2639356526,""48"":5.1767086885,""49"":4.7147070268,""50"":4.7147070268,""51"":4.7045181642,""52"":4.689257153,""53"":4.6385661802,""54"":4.6436278912,""55"":4.5033242745},""count"":{""0"":186,""1"":174,""2"":128,""3"":124,""4"":116,""5"":116,""6"":102,""7"":90,""8"":76,""9"":66,""10"":66,""11"":64,""12"":56,""13"":54,""14"":48,""15"":34,""16"":32,""17"":32,""18"":30,""19"":26,""20"":26,""21"":26,""22"":24,""23"":24,""24"":24,""25"":22,""26"":22,""27"":22,""28"":20,""29"":20,""30"":20,""31"":18,""32"":16,""33"":14,""34"":12,""35"":12,""36"":12,""37"":12,""38"":10,""39"":10,""40"":10,""41"":10,""42"":10,""43"":10,""44"":10,""45"":10,""46"":8,""47"":8,""48"":8,""49"":6,""50"":6,""51"":6,""52"":6,""53"":6,""54"":6,""55"":6},""sigma_nor"":{""0"":3.0280690022,""1"":3.2678615597,""2"":5.2912709516,""3"":2.8513296582,""4"":3.0650607061,""5"":4.3612572741,""6"":3.0033674152,""7"":4.0526616731,""8"":3.5931758267,""9"":3.3120327741,""10"":5.6173562131,""11"":3.7498810217,""12"":4.8474222638,""13"":3.2871946459,""14"":3.502707326,""15"":4.5162168601,""16"":3.8765890308,""17"":4.8050441714,""18"":3.9825716441,""19"":3.4453781561,""20"":3.5138922852,""21"":4.7868129079,""22"":3.431840663,""23"":5.4178650643,""24"":5.3084012944,""25"":3.9734652662,""26"":3.6823245884,""27"":5.2215306977,""28"":3.7762481302,""29"":5.5663761015,""30"":7.0,""31"":6.7677846808,""32"":4.0606103273,""33"":4.616653473,""34"":4.1218879698,""35"":3.7558255453,""36"":4.502016602,""37"":4.0151534947,""38"":4.5378879383,""39"":3.7617205486,""40"":4.4103970149,""41"":4.0994117793,""42"":4.5758906816,""43"":4.1559552226,""44"":4.8138011482,""45"":4.9776364684,""46"":3.8468607363,""47"":4.6494320267,""48"":4.1402047348,""49"":3.963703514,""50"":3.963703514,""51"":3.9586456216,""52"":3.9510698445,""53"":3.9259061442,""54"":3.9284188476,""55"":3.858770191},""vocab_index"":{""0"":0,""1"":1,""2"":2,""3"":3,""4"":4,""5"":5,""6"":6,""7"":9,""8"":10,""9"":13,""10"":14,""11"":15,""12"":16,""13"":17,""14"":21,""15"":29,""16"":32,""17"":33,""18"":34,""19"":40,""20"":41,""21"":43,""22"":45,""23"":50,""24"":52,""25"":56,""26"":58,""27"":60,""28"":66,""29"":68,""30"":69,""31"":77,""32"":85,""33"":107,""34"":110,""35"":128,""36"":133,""37"":134,""38"":144,""39"":154,""40"":159,""41"":171,""42"":172,""43"":173,""44"":174,""45"":175,""46"":216,""47"":222,""48"":223,""49"":224,""50"":225,""51"":226,""52"":244,""53"":269,""54"":280,""55"":302},""word"":{""0"":""interaction"",""1"":""documents"",""2"":""document"",""3"":""spatial"",""4"":""semantic"",""5"":""users"",""6"":""model"",""7"":""entities"",""8"":""forcespire"",""9"":""visual"",""10"":""importance"",""11"":""data"",""12"":""visualization"",""13"":""metaphor"",""14"":""term"",""15"":""statistical"",""16"":""result"",""17"":""values"",""18"":""models"",""19"":""interact"",""20"":""directly"",""21"":""value"",""22"":""tools"",""23"":""nodes"",""24"":""search"",""25"":""foraging"",""26"":""workspace"",""27"":""note"",""28"":""individuals"",""29"":""containing"",""30"":""proceedings"",""31"":""ieee"",""32"":""atlanta"",""33"":""computer"",""34"":""domain"",""35"":""arrow"",""36"":""context"",""37"":""pinned"",""38"":""dimensional"",""39"":""series"",""40"":""pipeline"",""41"":""increases"",""42"":""began"",""43"":""vast"",""44"":""conference"",""45"":""graphics"",""46"":""particular"",""47"":""regions"",""48"":""management"",""49"":""virginia"",""50"":""tech"",""51"":""blacksburg"",""52"":""copies"",""53"":""organize"",""54"":""algorithms"",""55"":""associate""},""threshold"":{""0"":4.4572625489,""1"":4.4572625489,""2"":4.4572625489,""3"":4.4572625489,""4"":4.4572625489,""5"":4.4572625489,""6"":4.4572625489,""7"":4.4572625489,""8"":4.4572625489,""9"":4.4572625489,""10"":4.4572625489,""11"":4.4572625489,""12"":4.4572625489,""13"":4.4572625489,""14"":4.4572625489,""15"":4.4572625489,""16"":4.4572625489,""17"":4.4572625489,""18"":4.4572625489,""19"":4.4572625489,""20"":4.4572625489,""21"":4.4572625489,""22"":4.4572625489,""23"":4.4572625489,""24"":4.4572625489,""25"":4.4572625489,""26"":4.4572625489,""27"":4.4572625489,""28"":4.4572625489,""29"":4.4572625489,""30"":4.4572625489,""31"":4.4572625489,""32"":4.4572625489,""33"":4.4572625489,""34"":4.4572625489,""35"":4.4572625489,""36"":4.4572625489,""37"":4.4572625489,""38"":4.4572625489,""39"":4.4572625489,""40"":4.4572625489,""41"":4.4572625489,""42"":4.4572625489,""43"":4.4572625489,""44"":4.4572625489,""45"":4.4572625489,""46"":4.4572625489,""47"":4.4572625489,""48"":4.4572625489,""49"":4.4572625489,""50"":4.4572625489,""51"":4.4572625489,""52"":4.4572625489,""53"":4.4572625489,""54"":4.4572625489,""55"":4.4572625489},""vector"":{""0"":""[-5.8227015  -4.4301505   1.0134696  -5.1273465   0.22581181 -0.36213237\n -2.127823   -1.3182105  -0.39640668  0.32012698]"",""1"":""[-5.9860616  -3.2477548   1.0834382  -5.3674192  -0.26576492  0.59491545\n -1.8851802  -1.259394   -1.1575713  -0.08989164]"",""2"":""[-5.7498846  -3.432139    1.0670209  -5.3104725  -0.0206354   0.22130883\n -1.4187446  -1.4108554  -1.1565256   0.02197853]"",""3"":""[-6.157022   -4.2489204   0.03009858 -5.3806257   0.25375476 -0.15299645\n -2.4346209  -1.7896143  -0.36398515  0.19479473]"",""4"":""[-6.133236   -4.0973644   0.27555528 -5.525619    0.09835575 -0.37772617\n -2.277571   -1.8149692  -0.3534128   0.22374853]"",""5"":""[-6.279577   -3.158095    1.238457   -5.092377   -0.81169707  0.68245023\n -2.571407   -0.62951714 -0.7904898   0.20428231]"",""6"":""[-5.660341   -3.6802766   1.4458795  -4.962807   -0.08848748  0.02379678\n -2.5010488  -0.7852257  -0.25138983  0.05117903]"",""7"":""[-6.396164   -2.771052    1.311416   -5.2616944  -0.7901566   0.40997458\n -2.5526161  -0.6229703  -0.6392512   0.23407124]"",""8"":""[-6.2354894  -2.8836179   1.1824156  -5.3115497  -0.75849617  0.13242328\n -2.5699472  -0.8185825  -0.38144705  0.18948914]"",""9"":""[-5.999183   -4.290751    0.06846149 -5.2627664  -0.03895366  0.10184319\n -2.5132093  -1.8158301  -0.18973212  0.04704328]"",""10"":""[-6.003846   -3.3236432   1.1881053  -5.1554227   0.41448763 -0.4723003\n -1.6950725  -1.030578   -0.59365433  0.37124917]"",""11"":""[-6.310434   -3.7327502   0.6032116  -5.2337675  -0.1869777   0.4916717\n -2.9152617  -1.0854801  -0.85666054  0.13654804]"",""12"":""[-6.0761633  -4.0336123   0.44861522 -5.1895475  -0.15204574  0.31290445\n -2.9275062  -1.477856    0.02283964 -0.06951041]"",""13"":""[-5.782244   -3.723461    1.0331209  -5.2316666   0.09818756 -0.28303847\n -2.1795485  -1.4280587   0.0947952  -0.01431399]"",""14"":""[-5.5998425  -3.7487228   1.0320873  -5.3319135   0.08507998 -0.15022357\n -1.4962031  -1.6270112  -0.5950466  -0.04063483]"",""15"":""[-6.2582855  -4.0144863   0.19262922 -5.3458514   0.01908398  0.12474636\n -2.7589116  -1.5056288  -0.56205827  0.16988246]"",""16"":""[-5.531168   -3.1607702   1.1984847  -5.0555296   0.2654368  -0.42768782\n -1.0494131  -1.0727534  -0.84147143  0.297819  ]"",""17"":""[-5.896568   -3.120654    1.3498743  -4.968219   -0.11740558 -0.02419476\n -2.1478453  -0.597642   -0.67573005  0.31440467]"",""18"":""[-5.926821   -3.5185835   1.3805847  -4.962127   -0.3365813   0.36325735\n -2.7224717  -0.666683   -0.33070496  0.07530753]"",""19"":""[-5.5748506  -4.5059366   1.2709643  -5.127256    0.36843327 -0.64681804\n -1.2141038  -1.3453577  -1.0847512   0.5607982 ]"",""20"":""[-5.7951245  -4.0133815   1.2590456  -5.206806    0.55157435 -0.70871973\n -1.1171973  -1.3991102  -0.9445022   0.52794355]"",""21"":""[-5.690499   -3.3759077   1.3021721  -4.927033    0.17916906 -0.31925714\n -1.7630568  -0.74412125 -0.7222104   0.37463498]"",""22"":""[-6.2168331e+00 -3.8887188e+00  1.2350584e+00 -5.1340165e+00\n -2.9415047e-01  4.7110814e-01 -2.8609700e+00 -1.0117689e+00\n -1.0992427e-01 -1.3850292e-03]"",""23"":""[-6.368496   -3.4251015   1.0386266  -5.1908436  -0.8628721   0.6895842\n -2.8946953  -0.90229374 -0.46317834  0.0742427 ]"",""24"":""[-5.642006   -3.9835567   0.82281685 -5.391898   -0.06784916 -0.00594609\n -1.436676   -1.7520592  -0.95343864  0.04694726]"",""25"":""[-5.9854693  -4.4312277   0.40460214 -5.4681387  -0.021565   -0.1928175\n -2.0789857  -1.8742929  -0.5306317   0.17980102]"",""26"":""[-6.1658964e+00 -4.0942435e+00  8.2878417e-01 -5.1240578e+00\n -2.8195202e-01  5.7799375e-01 -2.9931560e+00 -1.2844126e+00\n  5.6744609e-03 -1.2228535e-01]"",""27"":""[-5.723219   -3.158617    1.1973696  -5.185456    0.43516377 -0.43608537\n -1.10191    -1.2830044  -0.70794445  0.22590438]"",""28"":""[-6.18908    -2.9510167   1.3154118  -5.114049   -0.66762346  0.45062858\n -2.2298598  -0.6261993  -0.85800755  0.27060705]"",""29"":""[-5.658363   -3.3712852   1.1470761  -5.145186    0.30669874 -0.49684906\n -0.8052347  -1.1682638  -1.2118864   0.4771124 ]"",""30"":""[-5.6705403  -3.6815639   1.0623193  -5.0051174  -0.11741943  0.641673\n -2.0440984  -1.0281215  -0.9652449  -0.17163534]"",""31"":""[-6.489624   -4.568381    0.79252356 -5.3573723  -0.96714723  0.98908913\n -2.6598253  -1.581616   -0.6629181  -0.14483622]"",""32"":""[-6.32843    -4.7841845   0.5148634  -5.340384   -0.7963314   0.87539876\n -2.5471807  -1.7979392  -0.4898842  -0.09932549]"",""33"":""[-6.1972985  -4.2677474   0.60135585 -5.1097527  -0.5279857   0.8741367\n -2.9714935  -1.3387843  -0.4524811  -0.1378822 ]"",""34"":""[-6.4422355  -3.7154374   1.1497172  -5.474709    0.05695979 -0.01469979\n -2.3980148  -1.2032807  -0.44306135  0.10966269]"",""35"":""[-5.8984604  -3.655876    1.0160328  -5.210739   -0.17021793 -0.15673544\n -2.3992558  -1.3473322   0.2175823   0.01096125]"",""36"":""[-6.056331   -3.428196    1.1691514  -5.3574023   0.32843077 -0.41971818\n -1.7354522  -1.3330735  -0.39462805  0.18837036]"",""37"":""[-5.579297   -3.7100966   1.1667572  -5.170918    0.39002955 -0.5859064\n -0.72567284 -1.3163136  -1.2597662   0.48790023]"",""38"":""[-6.1489353  -4.307087    0.12188289 -5.381558   -0.07493941 -0.04075456\n -2.6796958  -1.7669208  -0.17985572  0.12764485]"",""39"":""[-5.5364704e+00 -3.6050937e+00  1.3132110e+00 -4.8493237e+00\n -1.1573546e-01  2.5999424e-01 -2.2650259e+00 -7.5644338e-01\n -5.4214191e-01  3.4779718e-03]"",""40"":""[-6.1180234  -3.791812    0.8250317  -5.2327213  -0.09734006  0.46481192\n -3.1207654  -1.032146   -0.6974838  -0.11022586]"",""41"":""[-5.5847793  -3.3751407   1.2065374  -5.0175085   0.17083979 -0.49792746\n -1.0332814  -0.9189572  -1.1122814   0.5230748 ]"",""42"":""[-5.423301   -4.131685    1.2565869  -5.0591326   0.18318278 -0.44711664\n -0.91298455 -1.1601429  -1.4513233   0.5467394 ]"",""43"":""[-6.073395   -3.3935702   0.7945168  -5.3065424   0.3704999  -0.70506996\n -1.133717   -1.3330582  -0.8671375   0.5879564 ]"",""44"":""[-5.748684   -3.8608968   1.0312876  -5.061883   -0.16755462  0.65157235\n -2.0258105  -1.1674563  -0.9497031  -0.1613036 ]"",""45"":""[-6.006937   -4.0965395   0.34204805 -5.117315   -0.38211066  0.58662754\n -2.834664   -1.4664543  -0.24722216 -0.11267299]"",""46"":""[-6.0291085  -3.4590201   1.1348162  -5.3280535   0.533634   -0.65083206\n -1.175351   -1.4085025  -0.771168    0.42956725]"",""47"":""[-6.248408   -3.0955584   1.3051193  -5.186064   -0.45851862  0.14778218\n -2.581693   -0.638687   -0.5250129   0.20261493]"",""48"":""[-6.2105045  -4.0988836   1.1189296  -5.2855296  -0.00980988  0.359766\n -2.5668907  -1.1842135  -0.52262807 -0.01551112]"",""49"":""[-6.477718   -4.735714    0.58106047 -5.34287    -0.7792365   1.0387902\n -2.7566304  -1.6908216  -0.5593281  -0.15044393]"",""50"":""[-6.2997184  -4.550303    0.5933373  -5.2344294  -0.64339226  0.9447876\n -2.8064334  -1.5768063  -0.5007938  -0.18591465]"",""51"":""[-6.3089533  -4.6431036   0.713474   -5.344464   -1.0094471   0.8726735\n -2.40023    -1.7237711  -0.5875509  -0.15260948]"",""52"":""[-5.9402657e+00 -3.0960846e+00  1.2002958e+00 -5.1815181e+00\n -4.3518898e-01  6.1009693e-01 -2.0590327e+00 -9.4826812e-01\n -1.0389909e+00  3.9486857e-03]"",""53"":""[-5.505053   -4.356949    1.2227176  -5.192218    0.27248973 -0.3676518\n -1.0325412  -1.4711989  -1.3161557   0.3997499 ]"",""54"":""[-6.335831   -3.7076154   0.9382613  -5.175535   -0.64475757  0.66921633\n -2.9829257  -1.0013287  -0.45731208  0.0538678 ]"",""55"":""[-5.5770063  -4.2169967   1.1741462  -5.2841153   0.33254793 -0.4754561\n -1.0466776  -1.6141245  -1.0908978   0.31436482]""},""topic"":{""0"":-1,""1"":-1,""2"":-1,""3"":2,""4"":2,""5"":3,""6"":-1,""7"":3,""8"":-1,""9"":2,""10"":0,""11"":-1,""12"":2,""13"":-1,""14"":-1,""15"":-1,""16"":0,""17"":-1,""18"":3,""19"":0,""20"":0,""21"":0,""22"":3,""23"":-1,""24"":-1,""25"":-1,""26"":3,""27"":0,""28"":3,""29"":0,""30"":3,""31"":1,""32"":1,""33"":-1,""34"":-1,""35"":-1,""36"":0,""37"":0,""38"":2,""39"":3,""40"":-1,""41"":0,""42"":0,""43"":0,""44"":-1,""45"":-1,""46"":0,""47"":3,""48"":-1,""49"":1,""50"":1,""51"":1,""52"":-1,""53"":0,""54"":3,""55"":0},""exemplar"":{""0"":null,""1"":null,""2"":null,""3"":""*"",""4"":""*"",""5"":""*"",""6"":null,""7"":""*"",""8"":null,""9"":""*"",""10"":null,""11"":null,""12"":null,""13"":null,""14"":null,""15"":null,""16"":null,""17"":null,""18"":null,""19"":""*"",""20"":""*"",""21"":null,""22"":null,""23"":null,""24"":null,""25"":null,""26"":null,""27"":null,""28"":""*"",""29"":""*"",""30"":null,""31"":""*"",""32"":""*"",""33"":null,""34"":null,""35"":null,""36"":null,""37"":""*"",""38"":""*"",""39"":null,""40"":null,""41"":null,""42"":null,""43"":null,""44"":null,""45"":null,""46"":null,""47"":""*"",""48"":null,""49"":""*"",""50"":""*"",""51"":null,""52"":null,""53"":null,""54"":null,""55"":null},""word*"":{""0"":""interaction"",""1"":""documents"",""2"":""document"",""3"":""spatial*"",""4"":""semantic*"",""5"":""users*"",""6"":""model"",""7"":""entities*"",""8"":""forcespire"",""9"":""visual*"",""10"":""importance"",""11"":""data"",""12"":""visualization"",""13"":""metaphor"",""14"":""term"",""15"":""statistical"",""16"":""result"",""17"":""values"",""18"":""models"",""19"":""interact*"",""20"":""directly*"",""21"":""value"",""22"":""tools"",""23"":""nodes"",""24"":""search"",""25"":""foraging"",""26"":""workspace"",""27"":""note"",""28"":""individuals*"",""29"":""containing*"",""30"":""proceedings"",""31"":""ieee*"",""32"":""atlanta*"",""33"":""computer"",""34"":""domain"",""35"":""arrow"",""36"":""context"",""37"":""pinned*"",""38"":""dimensional*"",""39"":""series"",""40"":""pipeline"",""41"":""increases"",""42"":""began"",""43"":""vast"",""44"":""conference"",""45"":""graphics"",""46"":""particular"",""47"":""regions*"",""48"":""management"",""49"":""virginia*"",""50"":""tech*"",""51"":""blacksburg"",""52"":""copies"",""53"":""organize"",""54"":""algorithms"",""55"":""associate""},""pos"":{""0"":1,""1"":2,""2"":3,""3"":1,""4"":2,""5"":1,""6"":4,""7"":2,""8"":5,""9"":3,""10"":1,""11"":6,""12"":4,""13"":7,""14"":8,""15"":9,""16"":2,""17"":10,""18"":3,""19"":3,""20"":4,""21"":5,""22"":4,""23"":11,""24"":12,""25"":13,""26"":5,""27"":6,""28"":6,""29"":7,""30"":7,""31"":1,""32"":2,""33"":14,""34"":15,""35"":16,""36"":8,""37"":9,""38"":5,""39"":8,""40"":17,""41"":10,""42"":11,""43"":12,""44"":18,""45"":19,""46"":13,""47"":9,""48"":20,""49"":3,""50"":4,""51"":5,""52"":21,""53"":14,""54"":10,""55"":15},""x2D"":{""0"":-3.2857728004,""1"":-1.9952207804,""2"":-1.3631898165,""3"":-4.5880460739,""4"":-4.04637146,""5"":-3.3151934147,""6"":-2.5356624126,""7"":-3.2030491829,""8"":-3.4272437096,""9"":-4.401945591,""10"":0.0427369513,""11"":-4.2337026596,""12"":-4.5127577782,""13"":-2.7208185196,""14"":-0.930337131,""15"":-4.6396884918,""16"":0.7439396977,""17"":-2.4291012287,""18"":-2.9666814804,""19"":-0.1852715611,""20"":0.0092161344,""21"":-0.1780328006,""22"":-3.6396324635,""23"":-3.6966748238,""24"":-1.3045325279,""25"":-4.1178078651,""26"":-4.4481368065,""27"":0.3426430821,""28"":-2.8866965771,""29"":0.7633683085,""30"":-1.8662034273,""31"":-5.706861496,""32"":-5.5259308815,""33"":-4.8996019363,""34"":-3.1653676033,""35"":-3.0125639439,""36"":-0.4179185331,""37"":0.5669670701,""38"":-4.5925049782,""39"":-2.2086379528,""40"":-4.0157995224,""41"":0.6450989246,""42"":0.3057315946,""43"":0.4079017341,""44"":-1.694019556,""45"":-4.7918510437,""46"":0.0118474821,""47"":-2.9857087135,""48"":-3.6011736393,""49"":-5.8408298492,""50"":-5.3298144341,""51"":-5.5944628716,""52"":-2.3900721073,""53"":-0.0844915807,""54"":-3.9866816998,""55"":0.1042326093},""y2D"":{""0"":-0.0557466932,""1"":2.9116411209,""2"":3.0972459316,""3"":-0.3835911155,""4"":-0.4066136479,""5"":2.5166912079,""6"":1.4151898623,""7"":2.8804349899,""8"":2.7301263809,""9"":-0.1450230777,""10"":3.3824667931,""11"":1.7034671307,""12"":0.7513058782,""13"":0.3351677358,""14"":3.552628994,""15"":0.1360803545,""16"":3.7208504677,""17"":2.2071306705,""18"":1.7020232677,""19"":5.0839056969,""20"":4.3492007256,""21"":3.1670620441,""22"":1.3668074608,""23"":2.154037714,""24"":3.4200408459,""25"":-0.3312157393,""26"":1.2177696228,""27"":3.5457470417,""28"":2.7517747879,""29"":4.2250971794,""30"":2.56798172,""31"":1.5529977083,""32"":1.6911010742,""33"":1.46304214,""34"":0.8590633869,""35"":0.4674939811,""36"":3.4989202023,""37"":4.6099791527,""38"":-0.0591555052,""39"":1.8270990849,""40"":1.3329890966,""41"":4.2364664078,""42"":4.948266983,""43"":3.9779677391,""44"":2.4516694546,""45"":1.0034710169,""46"":3.8816313744,""47"":2.3615803719,""48"":0.9144797921,""49"":1.3551292419,""50"":1.3613368273,""51"":1.6894335747,""52"":2.805273056,""53"":4.8488378525,""54"":1.6754300594,""55"":4.6708292961}}",2012
